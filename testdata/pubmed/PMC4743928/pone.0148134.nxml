<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">26849061</article-id><article-id pub-id-type="pmc">4743928</article-id><article-id pub-id-type="publisher-id">PONE-D-15-45546</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0148134</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability Theory</subject><subj-group><subject>Random Variables</subject><subj-group><subject>Covariance</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical Mechanics</subject><subj-group><subject>Convection</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Earth Sciences</subject><subj-group><subject>Atmospheric Science</subject><subj-group><subject>Meteorology</subject><subj-group><subject>Weather</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical Mechanics</subject><subj-group><subject>Continuum Mechanics</subject><subj-group><subject>Fluid Mechanics</subject><subj-group><subject>Fluid Dynamics</subject><subj-group><subject>Fluid Flow</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Physics</subject><subj-group><subject>Classical Mechanics</subject><subj-group><subject>Continuum Mechanics</subject><subj-group><subject>Fluid Mechanics</subject><subj-group><subject>Fluid Dynamics</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Earth Sciences</subject><subj-group><subject>Atmospheric Science</subject><subj-group><subject>Meteorology</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Mathematical and Statistical Techniques</subject><subj-group><subject>Statistical Methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Statistics (Mathematics)</subject><subj-group><subject>Statistical Methods</subject><subj-group><subject>Forecasting</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Predicting Flow Reversals in a Computational Fluid Dynamics Simulated Thermosyphon Using Data Assimilation</article-title><alt-title alt-title-type="running-head">Predicting Flow Reversals in a CFD Simulated Thermosyphon Using DA</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Reagan</surname><given-names>Andrew J.</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author"><name><surname>Dubief</surname><given-names>Yves</given-names></name><xref ref-type="aff" rid="aff002"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Dodds</surname><given-names>Peter Sheridan</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Danforth</surname><given-names>Christopher M.</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib></contrib-group><aff id="aff001">
<label>1</label>
<addr-line>Department of Mathematics &#x00026; Statistics, Vermont Complex Systems Center, Computational Story Lab, &#x00026; the Vermont Advanced Computing Core, The University of Vermont, Burlington, VT 05405, United States of America</addr-line>
</aff><aff id="aff002">
<label>2</label>
<addr-line>School of Engineering, Vermont Complex Systems Center &#x00026; the Vermont Advanced Computing Core, The University of Vermont, Burlington, VT 05405, United States of America</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Ugaz</surname><given-names>Victor M</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>Texas A&#x00026;M University, UNITED STATES</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="con" id="contrib001"><p>Conceived and designed the experiments: AJR YD PSD CMD. Performed the experiments: AJR. Analyzed the data: AJR YD PSD CMD. Wrote the paper: AJR.</p></fn><corresp id="cor001">* E-mail: <email>andrew.reagan@uvm.edu</email></corresp></author-notes><pub-date pub-type="collection"><year>2016</year></pub-date><pub-date pub-type="epub"><day>5</day><month>2</month><year>2016</year></pub-date><volume>11</volume><issue>2</issue><elocation-id>e0148134</elocation-id><history><date date-type="received"><day>16</day><month>10</month><year>2015</year></date><date date-type="accepted"><day>13</day><month>1</month><year>2016</year></date></history><permissions><copyright-statement>&#x000a9; 2016 Reagan et al</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Reagan et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:type="simple" xlink:href="pone.0148134.pdf"/><abstract><p>A thermal convection loop is a annular chamber filled with water, heated on the bottom half and cooled on the top half. With sufficiently large forcing of heat, the direction of fluid flow in the loop oscillates chaotically, dynamics analogous to the Earth&#x02019;s weather. As is the case for state-of-the-art weather models, we only observe the statistics over a small region of state space, making prediction difficult. To overcome this challenge, data assimilation (DA) methods, and specifically ensemble methods, use the computational model itself to estimate the uncertainty of the model to optimally combine these observations into an initial condition for predicting the future state. Here, we build and verify four distinct DA methods, and then, we perform a twin model experiment with the computational fluid dynamics simulation of the loop using the Ensemble Transform Kalman Filter (ETKF) to assimilate observations and predict flow reversals. We show that using adaptively shaped localized covariance outperforms static localized covariance with the ETKF, and allows for the use of less observations in predicting flow reversals. We also show that a Dynamic Mode Decomposition (DMD) of the temperature and velocity fields recovers the low dimensional system underlying reversals, finding specific modes which together are predictive of reversal direction.</p></abstract><funding-group><funding-statement>This work was made possible by funding from the Vermont Space Grant Consortium, NASA EPSCoR, NSF-DMS Grant No. 0940271, the Mathematics &#x00026; Climate Research Network and the Vermont Advanced Computing Center.</funding-statement></funding-group><counts><fig-count count="11"/><table-count count="0"/><page-count count="19"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All relevant data is available via GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/andyreagan/julia-openfoam">https://github.com/andyreagan/julia-openfoam</ext-link>).</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All relevant data is available via GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/andyreagan/julia-openfoam">https://github.com/andyreagan/julia-openfoam</ext-link>).</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>Prediction of the future state of complex systems is a fundamental challenge of science and engineering, and ultimately integral to the functioning of society. Some of these systems include weather [<xref rid="pone.0148134.ref001" ref-type="bibr">1</xref>], health [<xref rid="pone.0148134.ref002" ref-type="bibr">2</xref>], the economy [<xref rid="pone.0148134.ref003" ref-type="bibr">3</xref>], marketing [<xref rid="pone.0148134.ref004" ref-type="bibr">4</xref>] and transportation [<xref rid="pone.0148134.ref005" ref-type="bibr">5</xref>]. For weather in particular, predictions are made using supercomputers integrating numerical weather models, projecting our current best guess of the atmospheric state into the future. The accuracy of these predictions depends on the accuracy of the models themselves, and the quality of our knowledge of the current state of the atmosphere.</p><p>Model accuracy has improved with better meteorological understanding of weather processes and advances in computing technology [<xref rid="pone.0148134.ref006" ref-type="bibr">6</xref>]. To solve the initial value problem, techniques developed over the past 50 years are now broadly known as <italic>data assimilation</italic> (DA). Formally, data assimilation is the process of using all available information, including short-range model forecasts and physical observations, to estimate the current state of a system as accurately as possible [<xref rid="pone.0148134.ref007" ref-type="bibr">7</xref>]. The best-guess of the current state is often referred to as the <italic>analysis</italic> state.</p><p>Here, we employ a fluid dynamics experiment as a test bed for improving numerical weather prediction algorithms, focusing specifically on data assimilation methods. Our approach is inspired by the historical development of current methodologies, and provides a tractable system for rigorous analysis. The experiment is a thermal convection loop, which by design simplifies our problem into the prediction of natural convection. The thermosyphon, a type of natural convection loop or non-mechanical heat pump, can be likened to a toy model of climate [<xref rid="pone.0148134.ref008" ref-type="bibr">8</xref>]. The dynamics of thermal convection loops have been explored under both periodic [<xref rid="pone.0148134.ref009" ref-type="bibr">9</xref>] and chaotic [<xref rid="pone.0148134.ref007" ref-type="bibr">7</xref>, <xref rid="pone.0148134.ref010" ref-type="bibr">10</xref>&#x02013;<xref rid="pone.0148134.ref019" ref-type="bibr">19</xref>] regimes. A full characterization of the computational behavior of a loop under flux boundary conditions by Louisos et. al. describes four regimes: chaotic convection with reversals, high Rayleigh number (Ra) aperiodic stable convection, steady stable convection, and conduction/quasi-conduction [<xref rid="pone.0148134.ref020" ref-type="bibr">20</xref>]. For the remainder of this work, we focus on the chaotic flow regime.</p></sec><sec id="sec002"><title>Physical Experiment and Computational Model</title><p>The reduced order system describing a thermal convection loop was originally derived by Gorman [<xref rid="pone.0148134.ref013" ref-type="bibr">13</xref>] and Ehrhard and M&#x000fc;ller [<xref rid="pone.0148134.ref014" ref-type="bibr">14</xref>]. Here we present this three dimensional system in non-dimensionalized form. In <xref ref-type="supplementary-material" rid="pone.0148134.s002">S2 Appendix</xref>, we present a more complete derivation of these equations, following the derivation of Harris [<xref rid="pone.0148134.ref008" ref-type="bibr">8</xref>]. For the mean fluid velocity <inline-formula id="pone.0148134.e001"><alternatives><graphic xlink:href="pone.0148134.e001.jpg" id="pone.0148134.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, temperature difference between the 3 o&#x02019;clock and 9 o&#x02019;clock positions <inline-formula id="pone.0148134.e002"><alternatives><graphic xlink:href="pone.0148134.e002.jpg" id="pone.0148134.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula> (also referred to presently as &#x00394;<italic>T</italic><sub>3&#x02212;9</sub>), and deviation from conductive temperature profile <inline-formula id="pone.0148134.e003"><alternatives><graphic xlink:href="pone.0148134.e003.jpg" id="pone.0148134.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives></inline-formula>, these equations are:
<disp-formula id="pone.0148134.e004"><alternatives><graphic xlink:href="pone.0148134.e004.jpg" id="pone.0148134.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
<disp-formula id="pone.0148134.e005"><alternatives><graphic xlink:href="pone.0148134.e005.jpg" id="pone.0148134.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula>
<disp-formula id="pone.0148134.e006"><alternatives><graphic xlink:href="pone.0148134.e006.jpg" id="pone.0148134.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow><mml:mrow><mml:mi mathvariant="normal">d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:msub><mml:mi>x</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mn>3</mml:mn></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:mi>K</mml:mi><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mo stretchy="false">|</mml:mo></mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mrow><mml:mo stretchy="false">|</mml:mo><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
The function <italic>h</italic>(<italic>x</italic>) is a defined piece-wise analytic polynomial, and is provided in the full derivation in <xref ref-type="supplementary-material" rid="pone.0148134.s002">S2 Appendix</xref>. The parameters <italic>&#x003b1;</italic>, <italic>&#x003b2;</italic>, and <italic>K</italic>, along with scaling factors for time and each model variable can be fit to data using standard parameter estimation techniques.</p><p>Operated by Dave Hammond, UVM&#x02019;s Scientific Electronics Technician, the experimental thermosyphons access the chaotic regime of state space found in the principled governing equations. We quote the detailed setup from Darcy Glenn&#x02019;s undergraduate thesis [<xref rid="pone.0148134.ref021" ref-type="bibr">21</xref>] and provide <xref ref-type="fig" rid="pone.0148134.g001">Fig 1</xref> for details of the experiment:</p><fig id="pone.0148134.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g001</object-id><label>Fig 1</label><caption><title>Schematic of the experimental, and computational, setup from Harris <italic>et al.</italic> (2012).</title><p>The loop radius is given by <italic>R</italic> and inner radius by <italic>r</italic>. The top temperature is labeled <italic>T</italic><sub><italic>c</italic></sub> and bottom temperature <italic>T</italic><sub><italic>h</italic></sub>, gravity <italic>g</italic> is defined downward, the angle <italic>&#x003d5;</italic> is prescribed from the 6 o&#x02019;clock position, and temperature difference between 3 o&#x02019;clock and 9 o&#x02019;clock positions &#x00394;<italic>T</italic><sub>3&#x02212;9</sub> is labeled.</p></caption><graphic xlink:href="pone.0148134.g001"/></fig><disp-quote><p>The [thermosyphon] is a bent semi-flexible plastic tube with a 10-foot heating rope wrapped around the bottom half of the upright circle. The tubing used is light-transmitting clear THV from McMaster-Carr, with an inner diameter of 7/8 inch, a wall thickness of 1/16 inch, and a maximum operating temperature of 200F. The outer diameter of the circular thermosyphon is 32.25 inches. Together, the tubing inner diameter and outer diameter of the thermosyphon produce a ratio of approximately 1:36. There are 1 inch &#x02018;windows&#x02019; when the heating cable is coiled in a helix pattern around the outside of the tube, so the heating is not exactly uniform. The bottom half is then insulated using aluminum foil, which allowed fluid in the bottom half to reach 176F. A forcing of 57 V, or 105 Watts, is required for the heating cable so that chaotic motion is observed. Temperature is measured at the 3 o&#x02019;clock and 9 o&#x02019;clock positions using unsheathed copper thermocouples from Omega.</p></disp-quote><p>We confirm that the experiment accesses the chaotic regime of state space using a time series of the temperature difference as measured at the 3 o&#x02019;clock and 9 o&#x02019;clock positions in <xref ref-type="fig" rid="pone.0148134.g002">Fig 2</xref>. We first test our ability to predict this experimental thermosyphon using synthetic data.</p><fig id="pone.0148134.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g002</object-id><label>Fig 2</label><caption><title>A time series of the physical thermosyphon, from the Undergraduate Honor&#x02019;s Thesis of Darcy Glenn [<xref rid="pone.0148134.ref021" ref-type="bibr">21</xref>].</title><p>The temperature difference (plotted) is taken as the difference between temperature sensors in the 3 and 9 o&#x02019;clock positions. The sign of the temperature difference indicates the flow direction, where positive values are clockwise flow. We note that the experimental thermosyphon is not perfectly balanced, resulting in non-symmetric residence in each flow direction.</p></caption><graphic xlink:href="pone.0148134.g002"/></fig><p>We perform all computational simulations of the thermal convection loop with the open-source finite volume C++ library OpenFOAM [<xref rid="pone.0148134.ref022" ref-type="bibr">22</xref>]. The open-source nature of this software enables its integration with the data assimilation framework that our present work provides.</p><p>We consider the incompressible Navier-Stokes equations with the Boussinesq approximation to model the flow of water inside a thermal convection loop. For brevity, we omit the equations themselves, and include them in <xref ref-type="supplementary-material" rid="pone.0148134.s001">S1 Appendix</xref>. The solver in OpenFOAM that we use, with some modification, is <monospace>buoyantBoussinesqPimpleFoam</monospace>. Solving is accomplished by the Pressure-Implicit Split Operator (PISO) algorithm [<xref rid="pone.0148134.ref023" ref-type="bibr">23</xref>]. We find that modification of the code is necessary for laminar operation.</p><p>We create both 2-dimensional and 3-dimensional meshes using OpenFOAM&#x02019;s native meshing utility <monospace>blockMesh</monospace> shown in Figs <xref ref-type="fig" rid="pone.0148134.g003">3</xref> and <xref ref-type="fig" rid="pone.0148134.g004">4</xref>. After creating a mesh, we refine the mesh near the walls to capture boundary layer phenomena and renumber the mesh for solving speed. We use the <monospace>refineWallMesh</monospace> utility to refine the mesh near walls, and the <monospace>renumberMesh</monospace> utility to renumber the mesh. The resulting 2D mesh contains 80,000 points (80 across the diameter and 1000 around).</p><fig id="pone.0148134.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g003</object-id><label>Fig 3</label><caption><title>A snapshot of the mesh used for CFD simulations.</title><p>Shown is an initial stage of heating for a fixed value boundary condition, 2D, laminar simulation with a mesh of 40000 cells without wall refinement with walls heated at 340K on the bottom half and cooled to 290K on the top half. The cells have been colored with a truncated temperature range (299&#x02013;301K) to highlight the flow structures.</p></caption><graphic xlink:href="pone.0148134.g003"/></fig><fig id="pone.0148134.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g004</object-id><label>Fig 4</label><caption><title>The 3D mesh viewed as a wire-frame from within.</title><p>Here there are 900 cells in each slice (not shown), for a total mesh size of 81,000 cells. Simulations using this computational mesh are prohibitively expensive for use in a real time ensemble forecasting system, but are possible offline.</p></caption><graphic xlink:href="pone.0148134.g004"/></fig><p>Available boundary conditions (BCs) we find to be stable in OpenFOAM&#x02019;s solver are constant gradient, fixed value conditions, and turbulent heat flux. Constant gradient simulations are stable, but the behavior is empirically different from our physical system. While it is possible that a fixed value BC is acceptable due to the thermal diffusivity and thickness of the walls of the experimental setup, we find that this is also inadequate. Simulations with a turbulent heat flux BC implemented through the <monospace>externalWallHeatFluxTemperature</monospace> library are unstable with the laminar turbulence model we use and resulted in physically unrealistic results. We employ the third-party library <monospace>groovyBC</monospace> to use a gradient condition that computes the flux using a fixed external temperature <italic>T</italic><sub>inf</sub> and fixed wall heat transfer coefficient <italic>h</italic> as
<disp-formula id="pone.0148134.e007"><alternatives><graphic xlink:href="pone.0148134.e007.jpg" id="pone.0148134.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x02202;</mml:mi><mml:mi>T</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x02202;</mml:mi><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:mi>h</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>T</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>T</mml:mi><mml:mtext>inf</mml:mtext></mml:msub><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where we choose <italic>h</italic> to be the reference value for aluminum (the material used in the experimental setup).</p><p>With the mesh, BCs, and solver chosen, we now simulate the flow. From the data of <inline-formula id="pone.0148134.e008"><alternatives><graphic xlink:href="pone.0148134.e008.jpg" id="pone.0148134.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mrow><mml:mi>T</mml:mi><mml:mo>,</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:mo>,</mml:mo><mml:mover accent="true"><mml:mi>u</mml:mi><mml:mo>&#x020d7;</mml:mo></mml:mover></mml:mrow></mml:math></alternatives></inline-formula> and <italic>p</italic> that are saved at each timestep (temperature, cell face flux, velocity, and pressure, respectively), we extract the mass flow rate and average temperature at the 12, 3, 6 and 9 o&#x02019;clock positions on the loop. Since <italic>&#x003d5;</italic> is saved as a face-value flux, we compute the mass flow rate over the cells <italic>i</italic> of top (12 o&#x02019;clock) slice as
<disp-formula id="pone.0148134.e009"><alternatives><graphic xlink:href="pone.0148134.e009.jpg" id="pone.0148134.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>i</mml:mi></mml:munder><mml:msub><mml:mi>&#x003d5;</mml:mi><mml:mrow><mml:mi>f</mml:mi><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>&#x003c1;</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(4)</label></disp-formula>
where <italic>f</italic>(<italic>i</italic>) corresponds the face perpendicular to the loop angle at cell <italic>i</italic> and <italic>&#x003c1;</italic> is reconstructed from the Boussinesq approximation <italic>&#x003c1;</italic> = <italic>&#x003c1;</italic><sub>ref</sub>(1 &#x02212; <italic>&#x003b2;</italic>(<italic>T</italic> &#x02212; <italic>T</italic><sub>ref</sub>)).</p></sec><sec sec-type="materials|methods" id="sec003"><title>Methods</title><sec id="sec004"><title>Data Assimilation</title><p>We perform initial tests of the data assimilation algorithms described here with the Lorenz &#x02018;63 system, which is analogous to the above equations with Lorenz&#x02019;s <italic>&#x003b2;</italic> = 1, and <italic>K</italic> = 0. The canonical choices of <italic>&#x003c3;</italic> = 10, <italic>&#x003b2;</italic> = 8/3 and <italic>&#x003c1;</italic> = 28 produce the well known butterfly attractor, and we use these values for all examples here. From these tests, we will find the optimal data assimilation parameters (inflation factors) for predicting time series with this system. Having done so, we then focus our efforts on making prediction using computational fluid dynamics models.</p><p>We first implement the 3D-Var filter. Simply put, 3D-Var is the variational (cost-function) approach to finding the analysis. It has been shown that 3D-var solves the same statistical problem as optimal interpolation (OI) [<xref rid="pone.0148134.ref024" ref-type="bibr">24</xref>]. The usefulness of the variational approach comes from the computational efficiency, when solved with an iterative method. Specifically, the multivariate 3D-Var amounts to finding the <bold>x</bold><sub><italic>a</italic></sub> that minimizes the cost function
<disp-formula id="pone.0148134.e010"><alternatives><graphic xlink:href="pone.0148134.e010.jpg" id="pone.0148134.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>J</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi mathvariant="bold">B</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="bold">x</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:mi>H</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">x</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(5)</label></disp-formula></p><p>Next, we implement the &#x0201c;gold-standard&#x0201d; Extended Kalman Filter (EKF). The tangent linear model (TLM) is precisely the model (written as a matrix) that transforms a perturbation at time <italic>t</italic> to a perturbation at time <italic>t</italic> + &#x00394;<italic>t</italic>, analytically equivalent to the Jacobian of the model. Using the notation of Kalnay [<xref rid="pone.0148134.ref025" ref-type="bibr">25</xref>], this amounts to making a forecast with the nonlinear model <italic>M</italic>, and updating the error covariance matrix <bold>P</bold> with the TLM <italic>L</italic>, and adjoint model <italic>L</italic><sup><italic>T</italic></sup>:
<disp-formula id="pone.0148134.e011"><alternatives><graphic xlink:href="pone.0148134.e011.jpg" id="pone.0148134.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>a</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">P</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:msup><mml:mi mathvariant="bold">P</mml:mi><mml:mi>a</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi>L</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>T</mml:mi></mml:msubsup><mml:mo>+</mml:mo><mml:mi mathvariant="bold">Q</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <bold>Q</bold> is the noise covariance matrix (model error). In the experiments with Lorenz&#x02019;63 presented in this section, <bold>Q</bold> = 0 since our model is perfect. In numerical weather prediction, <bold>Q</bold> must be approximated, e.g., using statistical moments on the analysis increments [<xref rid="pone.0148134.ref026" ref-type="bibr">26</xref>&#x02013;<xref rid="pone.0148134.ref028" ref-type="bibr">28</xref>].</p><p>The analysis step is then written as (for <italic>H</italic> the observation operator):
<disp-formula id="pone.0148134.e012"><alternatives><graphic xlink:href="pone.0148134.e012.jpg" id="pone.0148134.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>a</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold">d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(6)</label></disp-formula>
<disp-formula id="pone.0148134.e013"><alternatives><graphic xlink:href="pone.0148134.e013.jpg" id="pone.0148134.e013g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M13"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">P</mml:mi><mml:mi>a</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi mathvariant="bold">I</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="bold">P</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(7)</label></disp-formula>
where
<disp-formula id="pone.0148134.e014"><alternatives><graphic xlink:href="pone.0148134.e014.jpg" id="pone.0148134.e014g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M14"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">d</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mi mathvariant="bold">y</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:mi mathvariant="bold">H</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:msup><mml:mi>x</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
is the innovation. We compute the Kalman gain matrix to minimize the analysis error covariance <inline-formula id="pone.0148134.e015"><alternatives><graphic xlink:href="pone.0148134.e015.jpg" id="pone.0148134.e015g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M15"><mml:msubsup><mml:mi>P</mml:mi><mml:mi>i</mml:mi><mml:mi>a</mml:mi></mml:msubsup></mml:math></alternatives></inline-formula> as
<disp-formula id="pone.0148134.e016"><alternatives><graphic xlink:href="pone.0148134.e016.jpg" id="pone.0148134.e016g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M16"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">K</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mi mathvariant="bold">P</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msubsup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi mathvariant="bold">R</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi mathvariant="bold">H</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:msup><mml:mi mathvariant="bold">P</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
where <bold>R</bold><sub><italic>i</italic></sub> is the observation error covariance. Since we are making observations of the truth with random normal errors of standard deviation <bold>&#x003f5;</bold>, the observational error covariance matrix <bold>R</bold> is a diagonal matrix with <italic>&#x003f5;</italic> along the diagonal. The most difficult (and most computationally expensive) part of the EKF is deriving and integrating the TLM. For this reason, the EKF is not used operationally, and later we will turn to statistical approximations of the EKF using ensembles of model forecasts. With our CFD model we have no such TLM, and we provide more detail on the TLM approaches applicable to the Lorenz&#x02019;63 system in <xref ref-type="supplementary-material" rid="pone.0148134.s003">S3 Appendix</xref>.</p><p>The computational cost of the EKF is mitigated through the approximation of the error covariance matrix <bold>P</bold><sub><italic>f</italic></sub> from the model itself, without the use of a TLM. One such approach is the use of a forecast ensemble, where a collection of models (ensemble members) are used to statistically sample model error propagation. With ensemble members spanning the model analysis error space, the forecasts of these ensemble members are then used to estimate the model forecast error covariance.</p><p>The only difference between this approach and the EKF, in general, is that the forecast error covariance <bold>P</bold><sup><italic>f</italic></sup> is computed from the ensemble members, without the need for a tangent linear model:
<disp-formula id="pone.0148134.e017"><alternatives><graphic xlink:href="pone.0148134.e017.jpg" id="pone.0148134.e017g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M17"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi mathvariant="bold">P</mml:mi><mml:mi>f</mml:mi></mml:msup><mml:mo>&#x02248;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>K</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mfrac><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>&#x02260;</mml:mo><mml:mi>l</mml:mi></mml:mrow></mml:munder><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>k</mml:mi><mml:mi>f</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mover><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mi>f</mml:mi></mml:msubsup><mml:mo>)</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msubsup><mml:mi mathvariant="bold">x</mml:mi><mml:mi>k</mml:mi><mml:mi>f</mml:mi></mml:msubsup><mml:mo>-</mml:mo><mml:msubsup><mml:mover><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mi>l</mml:mi><mml:mi>f</mml:mi></mml:msubsup><mml:mo>)</mml:mo></mml:mrow><mml:mi>T</mml:mi></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p><p>The ETKF introduced by Bishop is one type of square root filter, and we present it here to provide background for the formulation of the LETKF [<xref rid="pone.0148134.ref029" ref-type="bibr">29</xref>]. For a square root filter in general, we begin by writing the covariance matrices as the product of their matrix square roots. Because <bold>P</bold><sub><italic>a</italic></sub> and <bold>P</bold><sub><italic>f</italic></sub> are symmetric positive-definite (by definition), we can write
<disp-formula id="pone.0148134.e018"><alternatives><graphic xlink:href="pone.0148134.e018.jpg" id="pone.0148134.e018g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M18"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">P</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:msubsup><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>a</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:mo>,</mml:mo><mml:mspace width="1.em"/><mml:msub><mml:mi mathvariant="bold">P</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:msubsup><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>f</mml:mi><mml:mi>T</mml:mi></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(8)</label></disp-formula>
where <bold>Z</bold><sub><italic>a</italic></sub> and <bold>Z</bold><sub><italic>f</italic></sub> are the matrix square roots of <bold>P</bold><sub><italic>a</italic></sub> and <bold>P</bold><sub><italic>f</italic></sub>. We are not concerned that this decomposition is not unique, and note that <bold>Z</bold> must have the same rank as <bold>P</bold> which will prove computationally advantageous. The power of the SRF is now seen as we represent the columns of the matrix <bold>Z</bold><sub><italic>f</italic></sub> as the difference from the ensemble members from the ensemble mean, to avoid forming the full forecast covariance matrix <bold>P</bold><sub><italic>f</italic></sub>. The ensemble members are updated by applying the model <italic>M</italic> to the states <bold>Z</bold><sub><italic>f</italic></sub> such that an update is performed by
<disp-formula id="pone.0148134.e019"><alternatives><graphic xlink:href="pone.0148134.e019.jpg" id="pone.0148134.e019g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M19"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>f</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>M</mml:mi><mml:msub><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(9)</label></disp-formula>
To summarize, the steps for the ETKF are to <xref ref-type="disp-formula" rid="pone.0148134.e004">Eq (1)</xref> form <inline-formula id="pone.0148134.e020"><alternatives><graphic xlink:href="pone.0148134.e020.jpg" id="pone.0148134.e020g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M20"><mml:mrow><mml:msubsup><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>f</mml:mi><mml:mi>T</mml:mi></mml:msubsup><mml:msup><mml:mi mathvariant="bold">H</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi mathvariant="bold">R</mml:mi><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi mathvariant="bold">H</mml:mi><mml:msub><mml:mi mathvariant="bold">Z</mml:mi><mml:mi>f</mml:mi></mml:msub></mml:mrow></mml:math></alternatives></inline-formula>, assuming that computing <bold>R</bold><sup>&#x02212;1</sup> is easy, and <xref ref-type="disp-formula" rid="pone.0148134.e005">Eq (2)</xref> compute its eigenvalue decomposition, and apply it to <bold>Z</bold><sub><italic>f</italic></sub>.</p><p>The LEKF implements a strategy that becomes important for large simulations: localization. Namely, the analysis is computed for each grid-point using only local observations, without the need to build matrices that represent the entire analysis space. Localization removes long-distance correlations from <bold>B</bold> and allows greater flexibility in the global analysis by allowing different linear combinations of ensemble members at different spatial locations [<xref rid="pone.0148134.ref030" ref-type="bibr">30</xref>]. The general formulation of the LEKF by Ott goes as follows, quoting directly from [<xref rid="pone.0148134.ref031" ref-type="bibr">31</xref>]:
<list list-type="order"><list-item><p>Globally advance each ensemble member to the next analysis timestep. Steps 2&#x02013;5 are performed for each grid point.</p></list-item><list-item><p>Create local vectors from each ensemble member.</p></list-item><list-item><p>Project that point&#x02019;s local vectors from each ensemble member into a low dimensional subspace as represented by perturbations from the mean.</p></list-item><list-item><p>Perform the data assimilation step to obtain a local analysis mean and covariance.</p></list-item><list-item><p>Generate local analysis ensemble of states.</p></list-item><list-item><p>Form a new global analysis ensemble from all of the local analyses.</p></list-item><list-item><p>Wash, rinse, and repeat.</p></list-item></list></p><p>Proposed by Hunt <italic>et al.</italic> (2007) with the stated objective of computational efficiency, the LETKF is named from its most similar algorithms from which it draws [<xref rid="pone.0148134.ref032" ref-type="bibr">32</xref>]. With the formulation of the LEKF and the ETKF given, the LETKF can be described as a synthesis of the advantages of both of these approaches. The LETKF is the method sufficiently efficient for implementation on the full OpenFOAM CFD model of 240,000 model variables, and so we present it in more detail and follow the notation of Hunt <italic>et al.</italic> (2007). As in the LEKF, we explicitly perform the analysis for each grid point of the model. The choice of observations to use for each grid point can be selected a priori, and tuned adaptively. Starting with a collection of background forecast vectors {<bold>x</bold><sub><italic>b</italic>(<italic>i</italic>)</sub>: <italic>i</italic> = 1, &#x02026;, <italic>k</italic>}, we perform steps 1 and 2 in a global variable space, then steps 3&#x02013;8 for each grid point:
<list list-type="order"><list-item><p>Apply <italic>H</italic> to <bold>x</bold><sub><italic>b</italic>(<italic>i</italic>)</sub> to form <bold>y</bold><sub><italic>b</italic>(<italic>i</italic>)</sub>, average the <bold>y</bold><sub><italic>b</italic></sub> for <inline-formula id="pone.0148134.e021"><alternatives><graphic xlink:href="pone.0148134.e021.jpg" id="pone.0148134.e021g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M21"><mml:mover><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>&#x000af;</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, and form <bold>Y</bold>
<italic>b</italic>.</p></list-item><list-item><p>Similarly form <bold>X</bold><sub><italic>b</italic></sub>. Now for each grid point:</p></list-item><list-item><p>Form the local vectors.</p></list-item><list-item><p>Compute <bold>C</bold> = (<bold>Y</bold><sub><italic>b</italic></sub>)<sup><italic>T</italic></sup>
<bold>R</bold><sup>&#x02212;1</sup> (perhaps by solving <bold>R</bold>
<bold>C</bold><sup><italic>T</italic></sup> = <bold>Y</bold><sub><italic>b</italic></sub>.</p></list-item><list-item><p>Compute <inline-formula id="pone.0148134.e022"><alternatives><graphic xlink:href="pone.0148134.e022.jpg" id="pone.0148134.e022g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M22"><mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">P</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mi mathvariant="bold">I</mml:mi><mml:mo>/</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="bold">C</mml:mi><mml:msub><mml:mi mathvariant="bold">Y</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula> where <italic>&#x003c1;</italic> &#x0003e; 1 is a tun-able covariance inflation factor.</p></list-item><list-item><p>Compute <inline-formula id="pone.0148134.e023"><alternatives><graphic xlink:href="pone.0148134.e023.jpg" id="pone.0148134.e023g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M23"><mml:mrow><mml:msub><mml:mi mathvariant="bold">W</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">P</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:math></alternatives></inline-formula>.</p></list-item><list-item><p>Compute <inline-formula id="pone.0148134.e024"><alternatives><graphic xlink:href="pone.0148134.e024.jpg" id="pone.0148134.e024g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M24"><mml:mrow><mml:msub><mml:mover><mml:mi mathvariant="bold">w</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">P</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>a</mml:mi></mml:msub><mml:mi mathvariant="bold">C</mml:mi><mml:mo>(</mml:mo><mml:msub><mml:mi mathvariant="bold">y</mml:mi><mml:mi>o</mml:mi></mml:msub><mml:mo>-</mml:mo><mml:msub><mml:mover><mml:mi mathvariant="bold">y</mml:mi><mml:mo>&#x000af;</mml:mo></mml:mover><mml:mi>b</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> and add it to the column of <bold>W</bold><sub><italic>a</italic></sub>.</p></list-item><list-item><p>Multiply <bold>X</bold><sub><italic>b</italic></sub> by each <bold>w</bold><sub><italic>a</italic>(<italic>i</italic>)</sub> and add <inline-formula id="pone.0148134.e025"><alternatives><graphic xlink:href="pone.0148134.e025.jpg" id="pone.0148134.e025g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M25"><mml:msub><mml:mover accent="true"><mml:mi mathvariant="bold">x</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>b</mml:mi></mml:msub></mml:math></alternatives></inline-formula> to get {<bold>x</bold><sub><italic>a</italic>(<italic>i</italic>)</sub>:<italic>i</italic> = 1, &#x02026;, <italic>k</italic>} to complete each grid point.</p></list-item><list-item><p>Combine all of the local analysis into the global analysis.</p></list-item></list></p><p>We implement the LETKF on our mesh using the full 80 cells across with zone sizes of center 10, and sides 15, resulting in 3200 local variables for 100 zones. In parallel, these 100 local computations can all be carried out simultaneously over an arbitrary number of processors.</p></sec><sec id="sec005"><title>Adaptive covariance localization</title><p>Using the &#x0201c;square&#x0201d; sections of the loop to localize, we shift the zone to the left or right to follow the dominate flow direction at the center of that local window. In <xref ref-type="fig" rid="pone.0148134.g005">Fig 5</xref> a schematic of localization using square, circular, and adaptive location shows a situation in which adaptive localization will potentially capture more relevant information for finding the analysis state of any given cell. As we note in the caption of <xref ref-type="fig" rid="pone.0148134.g005">Fig 5</xref>, while we are motivated by localization around flow structures like Panel C, we simply shift the covariance in Panel A so that our method is most general and computationally efficient.</p><fig id="pone.0148134.g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g005</object-id><label>Fig 5</label><caption><title>Schematic of the adaptive covariance localization.</title><p>In Panel A we see a zonal (square) covariance that is most similar to the covariance used for both control experiments and sliding covariance experiments. Panel B shows a localized covariance using a &#x0201c;local radius&#x0201d;, and Panel C shows an idealized, fully adaptive covariance. While we are motivated by localization around flow structures like Panel C, we simply shift the covariance in Panel A so that our method is most general and computationally efficient.</p></caption><graphic xlink:href="pone.0148134.g005"/></fig><p>Denote the velocity vector of cells on a perpendicular slice of the loop at <inline-formula id="pone.0148134.e026"><alternatives><graphic xlink:href="pone.0148134.e026.jpg" id="pone.0148134.e026g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M26"><mml:mover accent="true"><mml:mi>U</mml:mi><mml:mo>&#x020d7;</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, the tangent vector to the slice <inline-formula id="pone.0148134.e027"><alternatives><graphic xlink:href="pone.0148134.e027.jpg" id="pone.0148134.e027g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M27"><mml:mover accent="true"><mml:mi>U</mml:mi><mml:mo>&#x020d7;</mml:mo></mml:mover></mml:math></alternatives></inline-formula> by <inline-formula id="pone.0148134.e028"><alternatives><graphic xlink:href="pone.0148134.e028.jpg" id="pone.0148134.e028g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M28"><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo>&#x020d7;</mml:mo></mml:mover></mml:math></alternatives></inline-formula>, the zone width as <italic>z</italic><sub>max</sub> and then the localization shift <italic>&#x003b1;</italic><sub>local</sub> for that slice of the loop is taken to be
<disp-formula id="pone.0148134.e029"><alternatives><graphic xlink:href="pone.0148134.e029.jpg" id="pone.0148134.e029g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mtext>local</mml:mtext></mml:msub><mml:mo>=</mml:mo><mml:mtext>floor</mml:mtext><mml:mo>(</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mover accent="true"><mml:mi>U</mml:mi><mml:mo>&#x020d7;</mml:mo></mml:mover><mml:mo>&#x000b7;</mml:mo><mml:mover accent="true"><mml:mi>T</mml:mi><mml:mo>&#x020d7;</mml:mo></mml:mover><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mo form="prefix" movablelimits="true">max</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>U</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>z</mml:mi><mml:mtext>max</mml:mtext></mml:msub><mml:mo>)</mml:mo><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(10)</label></disp-formula></p></sec><sec id="sec006"><title>Dynamic mode decomposition</title><p>We employ the &#x0201c;standard&#x0201d; algorithm of Tu to compute the Dynamic Mode Decomposition [<xref rid="pone.0148134.ref033" ref-type="bibr">33</xref>]. Tu&#x02019;s &#x0201c;standard&#x0201d; algorithm is as follows with <italic>X</italic> and <italic>Y</italic> taken as the first and last <italic>N</italic> &#x02212; 1 columns of the snapshot matrix <italic>D</italic>:
<disp-formula id="pone.0148134.e030"><alternatives><graphic xlink:href="pone.0148134.e030.jpg" id="pone.0148134.e030g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M30"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mi>X</mml:mi></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>U</mml:mi><mml:mo>&#x003a3;</mml:mo><mml:mi>V</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="right"><mml:mrow><mml:mo>(</mml:mo><mml:mtext>Take</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>SVD</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>of</mml:mtext><mml:mspace width="0.277778em"/><mml:mi>X</mml:mi><mml:mo>.</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msup><mml:mi>U</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>Y</mml:mi><mml:mi>V</mml:mi><mml:msup><mml:mo>&#x003a3;</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd><mml:mtd columnalign="right"><mml:mrow><mml:mo>(</mml:mo><mml:mtext>Build</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>the</mml:mtext><mml:mi>A</mml:mi><mml:mtext>matrix</mml:mtext><mml:mo>.</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>A</mml:mi><mml:mo>&#x002dc;</mml:mo></mml:mover><mml:mi>w</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>&#x003bb;</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="right"><mml:mrow><mml:mo>(</mml:mo><mml:mtext>Compute</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>eigenvectors</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>and</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>values</mml:mtext><mml:mo>.</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>&#x003b8;</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mi>w</mml:mi></mml:mrow></mml:mtd><mml:mtd><mml:mo>=</mml:mo></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>U</mml:mi><mml:mi>w</mml:mi></mml:mrow></mml:mtd><mml:mtd columnalign="right"><mml:mrow><mml:mo>(</mml:mo><mml:mtext>Compute</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>corresponding</mml:mtext><mml:mspace width="4.pt"/><mml:mtext>modes</mml:mtext><mml:mo>.</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula></p><p>Given a system state <italic>U</italic>* we project this state onto the DMD basis by taking the real part of <italic>&#x003a6;</italic> = re(<italic>U</italic>* &#x022c5; <italic>w</italic>) and use the psuedoinverse to compute the projection as
<disp-formula id="pone.0148134.e031"><alternatives><graphic xlink:href="pone.0148134.e031.jpg" id="pone.0148134.e031g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M31"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:msup><mml:mo>&#x003a6;</mml:mo><mml:mi>T</mml:mi></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:mo>&#x003a6;</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mo>&#x003a6;</mml:mo><mml:mi>T</mml:mi></mml:msup><mml:mo>&#x000b7;</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mo>*</mml:mo></mml:msup><mml:mo>.</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives></disp-formula>
This projection is a vector which contains the linear coefficients on the basis of DMD modes for the given state.</p></sec></sec><sec sec-type="results" id="sec007"><title>Results</title><sec id="sec008"><title>Data assimilation</title><p>We confirm the performance of the DA methods described above by testing each (on the Lorenz&#x02019;63 system) for increasingly long times between observations, by increasing the DA window length in <xref ref-type="fig" rid="pone.0148134.g006">Fig 6</xref>. As the time between observations increases, the nonlinearity of the Lorenz&#x02019;63 system results in the failure of the EKF and difficultly for the EnKF with small ensemble size. The ETKF and EnSRF perform the best of the methods tested and we chose the ETKF for future use with the CFD model.</p><fig id="pone.0148134.g006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g006</object-id><label>Fig 6</label><caption><title>The RMS error (not scaled by climatology) for our EKF and EnKF filters.</title><p>Error is measured as the difference between forecast and truth at the end of an assimiliation window for the latter 2500 assimiliation windows in a 3000 assimilation window Lorenz&#x02019;63 run. Error is measured in the only observed variable, <italic>x</italic><sub>1</sub>. Increasing the assimilation window led to an decrease in predictive skill, as expected.</p></caption><graphic xlink:href="pone.0148134.g006"/></fig><p>The results in <xref ref-type="fig" rid="pone.0148134.g006">Fig 6</xref> rely on tuned covariance inflation, both additive and multiplicative, pre-computed for each window and DA technique. We choose optimal additive inflation <italic>&#x003bc;</italic> and multiplicative inflation &#x00394; by selecting for the lowest error in an exhaustive search through a maximum factors of 1.5 in each, an example is shown in <xref ref-type="fig" rid="pone.0148134.g007">Fig 7</xref>. We use these optimal data assimilation parameters (inflation factors) for the remainder of this work.</p><fig id="pone.0148134.g007" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g007</object-id><label>Fig 7</label><caption><title>The RMS error averaged over 100 model runs of length 1000 windows is reported for the ETKF for varying additive and multiplicative inflation factors &#x00394; and <italic>&#x003bc;</italic>.</title><p>Each of the 100 model runs starts with a random IC, and the analysis forecast starts randomly. The window length here is 390 seconds. The filter performance RMS is computed as the RMS value of the difference between forecast and truth at the assimilation window for the latter 500 windows, allowing a spin-up of 500 windows.</p></caption><graphic xlink:href="pone.0148134.g007"/></fig></sec><sec id="sec009"><title>Limited observations &#x00026; adaptive covariance</title><p>An initial test of prediction skill with limited observations in a twin model experiment showed that we needed 1000 spatial measurements of the temperature to predict flow reversals within 1 assimilation window. In an attempt to decrease the required observations to a experimentally realizable number, we implement a simple, adaptively localized covariance for data assimilation. Since we first saw a modest improvement in the prediction skill with full temperature observations, we hope that this improvement increases and is sufficient to get down to needing as few as 32 observations to predict reversals 1 assimilation window (of length 10 seconds) into the future.</p><p>In <xref ref-type="fig" rid="pone.0148134.g008">Fig 8</xref> we see that over an assimilation of 200 seconds, the ensemble converges on the hidden, true state. To test the performance of flow reversal prediction, we take the average of the ensemble flow direction (the average of each value of <italic>&#x003d5;</italic>) as the predicted flow direction, and count how often we predict reversals both when they do and do not occur. Varying both the number of model variables and the strength of covariance shifting in <xref ref-type="fig" rid="pone.0148134.g009">Fig 9</xref>, we find that covariance shifting improves flow reversal prediction skill even when spatial observation density is decreased. With full observations (spacing of 1), we obtain a the best predictions with a covariance shift of 2. For 1/2 and 1/5 observations [a spacing of 2 (5) to observe every other (fifth) variable], we again have the best predictions with a shift of 2. And for a spacing of 10, observing every 10th variable, we achieve greater prediction skill with a covariance shift of 10.</p><fig id="pone.0148134.g008" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g008</object-id><label>Fig 8</label><caption><title>Convergence of 20 ensembles using sliding windows, starting from initially random states.</title><p>Here, as in most of the experiments, only temperature is observed and assimilated. Flux is computed as in <xref ref-type="disp-formula" rid="pone.0148134.e009">Eq (4)</xref>, on the left hand side of the thermosyphon, and scaled by a factor of 10<sup>8</sup>. Assimilation takes place every 10 model seconds.</p></caption><graphic xlink:href="pone.0148134.g008"/></fig><fig id="pone.0148134.g009" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g009</object-id><label>Fig 9</label><caption><title>Prediction skill as fraction of reversals that we correctly predicted across different numbers of observations and sliding windows of localized covariance.</title><p>Decreasing observation density makes the prediction problem more difficult while at the same time make the data assimilation stable numerically, and we see a decrease in prediction skill with no covariance shifting. With covariance shifting, skill improves for each observational density and most dramatically with less observation density.</p></caption><graphic xlink:href="pone.0148134.g009"/></fig><p>Computing the average flow direction inside a localized covariance zone is straightforward, and computationally easy since the velocity is immediately available, making incorporation of this scheme into any data assimilation method easy. Since observations are also sparse in large weather models, we expect that using an adaptive local covariance scheme could lead to improved prediction skill with sparse observations [<xref rid="pone.0148134.ref034" ref-type="bibr">34</xref>].</p></sec><sec id="sec010"><title>Dynamic mode decomposition</title><p>To incorporate limited observations into a high-dimensional CFD simulation, we combine ideas from both CFD literature and data assimilation to make predictions. We proceed with Tu&#x02019;s algorithm using snapshots every 10 seconds for the first 900 seconds of model time. A full picture of this time series can be found in the Figure in <xref ref-type="supplementary-material" rid="pone.0148134.s004">S4 Appendix</xref>.</p><p>In this reduced space, we extract the modes that correspond to the instability leading to flow reversals. With a known low-dimensional model of the thermosyphon dynamics, we take this opportunity to test whether DMD can discover the underlying system. The time series of the model state projection onto a specific DMD mode will represent the time dynamics of a mode that is representative of a single low dimensional variable.</p><p>To look at all of the modes at once, we examine the average magnitude of the projection from all model states onto each mode in comparison to the projection of all states that 1, 3, 5, and 7 time steps before a reversal. The magnitude of the mode projection of a predictive mode before a reversal should stand out against the projection average across all states, and decay back towards the average further from the reversal in time. For modes 21 and 79, we directly observe in <xref ref-type="fig" rid="pone.0148134.g010">Fig 10</xref> that the average projection from states just 1 second before reversal is the most different from the average state projection, and the further away from the reversal the more similar the states become to the average.</p><fig id="pone.0148134.g010" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g010</object-id><label>Fig 10</label><caption><title>The log<sub>10</sub> average projection onto each DMD mode for different sets of model states.</title><p>DMD constructed as snapshots every 10 seconds for the first 900 seconds of model time, and model states from the first 2000 seconds are all projected onto the DMD modes. All states average shown in black, and the average of the subset of states that occur 1 second, 3 seconds, 5 seconds, and 7 seconds before a reversal are shown in other colors. The symmetry of the loop generates modes that often come in pairs.</p></caption><graphic xlink:href="pone.0148134.g010"/></fig><p>We are particularly interested in whether the mode projection time series is predictive of flow reversals, as is true with the hidden system. The insets of Panel A and Panel B in <xref ref-type="fig" rid="pone.0148134.g011">Fig 11</xref> show two such timeseries, with stars indicating the time of flow reversals. Individually, these modes increase in amplitude when flow reversals happen. As a dominant mode, the time series of Mode 2 tracks closely to the timeseries from which the modes were generated, while the dynamics of the projection of Mode 79 are less obvious.</p><fig id="pone.0148134.g011" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0148134.g011</object-id><label>Fig 11</label><caption><p>Panel A: The temperature profile of the thermosyphon of Mode 2, with inset of the projection of time series states onto Mode 2 (the projection coefficient). The color scale on the thermosyphon spans the values 1 to 0 in the DMD mode. The inset figure is the projection coefficient from time 100 to time 5000, with the projection range being shown from -300 to 300 (as in Panel C) and the starred reversals labeled as in Panel C. Panel B: Likewise, the temperature profile of the thermosyphon of Mode 79, with inset of the projection of time series states onto Mode 79 (the projection coefficient). The color scale and inset figure axes are the same as Panel A. Panel C: A butterfly-shaped phase plane shows the value of the projection onto modes 2 and 79 for each time in the first 2000 time steps of our ground truth model run. In blue and green stars the states that occur directly before a flow are highlighted, and are isolated into separate quadrants of phase space.</p></caption><graphic xlink:href="pone.0148134.g011"/></fig><p>By combining the state projection onto specific mode time series into a phase plane, the combined signal from two modes is used for discovering states that separate reversals in direction and from other states in the phase plane. In <xref ref-type="fig" rid="pone.0148134.g011">Fig 11</xref> we see that the dominant dynamics from mode 2 plotted with those of mode 79 are able to strongly separate reversals into quadrants of the low-dimensional space. This result indicates that DMD could be used to improve predictability of reversals.</p></sec></sec><sec id="sec011"><title>Concluding Remarks</title><p>The first output of our work is a general data assimilation framework for MATLAB and Julia. By utilizing an object-oriented (OO) design, the model and data assimilation algorithm code are separate and can be changed independently. The principal advantage of this approach is the ease of incorporation of new models and DA techniques (code available at <ext-link ext-link-type="uri" xlink:href="https://github.com/andyreagan/julia-openfoam">https://github.com/andyreagan/julia-openfoam</ext-link>).</p><p>We next present the results pertaining to the accuracy of forecasts for synthetic data (twin model experiments). There are many possible experiments given the choice of assimilation window, data assimilation algorithm, localization scheme, model resolution, observational density, observed variables, and observation quality. We focused on considering the effect of observations and observational locations on the resulting forecast skill, and we find that there is a threshold for the required number of observations to make useful predictions. In general, and unsurprisingly, we see that increasing observational density leads to improved forecast accuracy. With too few observations, the data assimilation is unable to recover the underlying dynamics. Using adaptively localized covariance holds promise for data assimilation with data-scarce models, to overcome the lack of data.</p><p>The ability of DMD to recover the lower dimensional dynamics is expected but with 240,000 variables is nonetheless an accomplishment. When modeling systems for which there are unknown but useful dimension reductions, as demonstrated here, DMD can be a useful tool to find such dimension reductions. When computational model runs are exceedingly costly or time consuming, the best-guess state projection onto DMD modes provides insights into the system dynamics that could not otherwise be obtained.</p><p>The numerical coupling of CFD to experiment by DA should be generally useful to improve the skill of CFD predictions of experiments. In addition, the CFD model can provide better knowledge of unobservable quantities of interest in fluid flow that use the experimental data to find the analysis state provided by DA. Adaptive covariance localization further enhances the benefit provided by DA in this context.</p></sec><sec sec-type="supplementary-material" id="sec012"><title>Supporting Information</title><supplementary-material content-type="local-data" id="pone.0148134.s001"><label>S1 Appendix</label><caption><title>Computational Details and Explicit Equations Used.</title><p>(PDF)</p></caption><media xlink:href="pone.0148134.s001.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0148134.s002"><label>S2 Appendix</label><caption><title>The Ehrhard and M&#x000fc;ller Equations.</title><p>(PDF)</p></caption><media xlink:href="pone.0148134.s002.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0148134.s003"><label>S3 Appendix</label><caption><title>Data Assimiliation.</title><p>(PDF)</p></caption><media xlink:href="pone.0148134.s003.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0148134.s004"><label>S4 Appendix</label><caption><title>Additional DMD Details.</title><p>(PDF)</p></caption><media xlink:href="pone.0148134.s004.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ref-list><title>References</title><ref id="pone.0148134.ref001"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Hsiang</surname><given-names>SM</given-names></name>, <name><surname>Burke</surname><given-names>M</given-names></name>, <name><surname>Miguel</surname><given-names>E</given-names></name>. <article-title>Quantifying the Influence of Climate on Human Conflict</article-title>. <source>Science</source>. <year>2013</year>;<volume>341</volume> (<issue>6151</issue>). <comment>Available from: <ext-link ext-link-type="uri" xlink:href="http://www.sciencemag.org/content/341/6151/1235367.abstract">http://www.sciencemag.org/content/341/6151/1235367.abstract</ext-link></comment>
<pub-id pub-id-type="doi">10.1126/science.1235367</pub-id>
<pub-id pub-id-type="pmid">24031020</pub-id></mixed-citation></ref><ref id="pone.0148134.ref002"><label>2</label><mixed-citation publication-type="journal">
<name><surname>Ginsberg</surname><given-names>J</given-names></name>, <name><surname>Mohebbi</surname><given-names>MH</given-names></name>, <name><surname>Patel</surname><given-names>RS</given-names></name>, <name><surname>Brammer</surname><given-names>L</given-names></name>, <name><surname>Smolinski</surname><given-names>MS</given-names></name>, <name><surname>Brilliant</surname><given-names>L</given-names></name>. <article-title>Detecting influenza epidemics using search engine query data</article-title>. <source>Nature</source>. <year>2008</year>;<volume>457</volume>(<issue>7232</issue>):<fpage>1012</fpage>&#x02013;<lpage>1014</lpage>. <pub-id pub-id-type="doi">10.1038/nature07634</pub-id></mixed-citation></ref><ref id="pone.0148134.ref003"><label>3</label><mixed-citation publication-type="journal">
<name><surname>Sornette</surname><given-names>D</given-names></name>, <name><surname>Zhou</surname><given-names>WX</given-names></name>. <article-title>Predictability of large future changes in major financial indices</article-title>. <source>International Journal of Forecasting</source>. <year>2006</year>;<volume>22</volume>(<issue>1</issue>):<fpage>153</fpage>&#x02013;<lpage>168</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijforecast.2005.02.004</pub-id></mixed-citation></ref><ref id="pone.0148134.ref004"><label>4</label><mixed-citation publication-type="other">Asur S, Huberman BA. Predicting the future with social media. In: Web Intelligence and Intelligent Agent Technology (WI-IAT), 2010 IEEE/WIC/ACM International Conference on. vol. 1. IEEE; 2010. p. 492&#x02013;499.</mixed-citation></ref><ref id="pone.0148134.ref005"><label>5</label><mixed-citation publication-type="other">Savely R, Cockrell B, Pines S. Apollo Experience Report&#x02014;Onboard Navigational and Alignment Software. Technical Report. 1972;.</mixed-citation></ref><ref id="pone.0148134.ref006"><label>6</label><mixed-citation publication-type="journal">
<name><surname>Bauer</surname><given-names>P</given-names></name>, <name><surname>Thorpe</surname><given-names>A</given-names></name>, <name><surname>Brunet</surname><given-names>G</given-names></name>. <article-title>The quiet revolution of numerical weather prediction</article-title>. <source>Nature</source>. <year>2015</year>;<volume>525</volume>(<issue>7567</issue>):<fpage>47</fpage>&#x02013;<lpage>55</lpage>. <pub-id pub-id-type="doi">10.1038/nature14956</pub-id>
<pub-id pub-id-type="pmid">26333465</pub-id></mixed-citation></ref><ref id="pone.0148134.ref007"><label>7</label><mixed-citation publication-type="journal">
<name><surname>Yang</surname><given-names>SC</given-names></name>, <name><surname>Baker</surname><given-names>D</given-names></name>, <name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Cordes</surname><given-names>K</given-names></name>, <name><surname>Huff</surname><given-names>M</given-names></name>, <name><surname>Nagpal</surname><given-names>G</given-names></name>, <etal>et al</etal>
<article-title>Data Assimilation as Synchronization of Truth and Model: Experiments with the Three-Variable Lorenz System*</article-title>. <source>Journal of the atmospheric sciences</source>. <year>2006</year>;<volume>63</volume>(<issue>9</issue>):<fpage>2340</fpage>&#x02013;<lpage>2354</lpage>. <pub-id pub-id-type="doi">10.1175/JAS3739.1</pub-id></mixed-citation></ref><ref id="pone.0148134.ref008"><label>8</label><mixed-citation publication-type="other">Harris KD, Ridouane EH, Hitt DL, Danforth CM. Predicting flow reversals in chaotic natural convection using data assimilation. arXiv preprint arXiv:11085685. 2011;.</mixed-citation></ref><ref id="pone.0148134.ref009"><label>9</label><mixed-citation publication-type="journal">
<name><surname>Keller</surname><given-names>JB</given-names></name>. <article-title>Periodic oscillations in a model of thermal convection</article-title>. <source>J Fluid Mech</source>. <year>1966</year>;<volume>26</volume>(<issue>3</issue>):<fpage>599</fpage>&#x02013;<lpage>606</lpage>. <pub-id pub-id-type="doi">10.1017/S0022112066001423</pub-id></mixed-citation></ref><ref id="pone.0148134.ref010"><label>10</label><mixed-citation publication-type="journal">
<name><surname>Welander</surname><given-names>P</given-names></name>. <article-title>On the oscillatory instability of a differentially heated fluid loop</article-title>. <source>International Geophysics Series</source>. <year>1995</year>;<volume>59</volume>.</mixed-citation></ref><ref id="pone.0148134.ref011"><label>11</label><mixed-citation publication-type="journal">
<name><surname>Creveling</surname><given-names>H</given-names></name>, <name><surname>PAZ</surname><given-names>D</given-names></name>, <name><surname>Baladi</surname><given-names>J</given-names></name>, <name><surname>Schoenhals</surname><given-names>R</given-names></name>. <article-title>Stability characteristics of a single-phase free convection loop</article-title>. <source>Journal of Fluid Mechanics</source>. <year>1975</year>;<volume>67</volume>(<issue>part 1</issue>):<fpage>65</fpage>&#x02013;<lpage>84</lpage>. <pub-id pub-id-type="doi">10.1017/S0022112075000171</pub-id></mixed-citation></ref><ref id="pone.0148134.ref012"><label>12</label><mixed-citation publication-type="journal">
<name><surname>Gorman</surname><given-names>M</given-names></name>, <name><surname>Widmann</surname><given-names>P</given-names></name>. <article-title>Chaotic flow regimes in a convection loop</article-title>. <source>Phys Rev Lett</source>. <year>1984</year>;(<volume>52</volume>):<fpage>2241</fpage>&#x02013;<lpage>2244</lpage>. <pub-id pub-id-type="doi">10.1103/PhysRevLett.52.2241</pub-id></mixed-citation></ref><ref id="pone.0148134.ref013"><label>13</label><mixed-citation publication-type="journal">
<name><surname>Gorman</surname><given-names>M</given-names></name>, <name><surname>Widmann</surname><given-names>P</given-names></name>, <name><surname>Robbins</surname><given-names>K</given-names></name>. <article-title>Nonlinear dynamics of a convection loop: a quantitative comparison of experiment with theory</article-title>. <source>Physica D</source>. <year>1986</year>;(<volume>19</volume>):<fpage>255</fpage>&#x02013;<lpage>267</lpage>. <pub-id pub-id-type="doi">10.1016/0167-2789(86)90022-9</pub-id></mixed-citation></ref><ref id="pone.0148134.ref014"><label>14</label><mixed-citation publication-type="journal">
<name><surname>Ehrhard</surname><given-names>P</given-names></name>, <name><surname>M&#x000fc;ller</surname><given-names>U</given-names></name>. <article-title>Dynamical behaviour of natural convection in a single-phase loop</article-title>. <source>Journal of Fluid mechanics</source>. <year>1990</year>;<volume>217</volume>:<fpage>487</fpage>&#x02013;<lpage>518</lpage>. <pub-id pub-id-type="doi">10.1017/S0022112090000817</pub-id></mixed-citation></ref><ref id="pone.0148134.ref015"><label>15</label><mixed-citation publication-type="journal">
<name><surname>Yuen</surname><given-names>P</given-names></name>, <name><surname>Bau</surname><given-names>H</given-names></name>. <article-title>Optimal and adaptive control of chaotic convection</article-title>. <source>Phys Fluids</source>. <year>1999</year>;(<volume>11</volume>):<fpage>1435</fpage>&#x02013;<lpage>1448</lpage>. <pub-id pub-id-type="doi">10.1063/1.870007</pub-id></mixed-citation></ref><ref id="pone.0148134.ref016"><label>16</label><mixed-citation publication-type="journal">
<name><surname>Jiang</surname><given-names>Y</given-names></name>, <name><surname>Shoji</surname><given-names>M</given-names></name>. <article-title>Spatial and temporal stabilities of flow in a natural circulation loop: influences of thermal boundary condition</article-title>. <source>J Heat Trans</source>. <year>2003</year>;(<volume>125</volume>):<fpage>612</fpage>&#x02013;<lpage>623</lpage>. <pub-id pub-id-type="doi">10.1115/1.1571846</pub-id></mixed-citation></ref><ref id="pone.0148134.ref017"><label>17</label><mixed-citation publication-type="journal">
<name><surname>Burroughs</surname><given-names>E</given-names></name>, <name><surname>Coutsias</surname><given-names>E</given-names></name>, <name><surname>Romero</surname><given-names>L</given-names></name>. <article-title>A reduced-order partial differential equation model for the flow in a thermosyphon</article-title>. <source>Journal of Fluid Mechanics</source>. <year>2005</year>;<volume>543</volume>:<fpage>203</fpage>&#x02013;<lpage>238</lpage>. <pub-id pub-id-type="doi">10.1017/S0022112005006361</pub-id></mixed-citation></ref><ref id="pone.0148134.ref018"><label>18</label><mixed-citation publication-type="journal">
<name><surname>Desrayaud</surname><given-names>G</given-names></name>, <name><surname>Fichera</surname><given-names>A</given-names></name>, <name><surname>Marcoux</surname><given-names>M</given-names></name>. <article-title>Numerical investigation of natural circulation in a 2D-annular closed-loop thermosyphon</article-title>. <source>International journal of heat and fluid flow</source>. <year>2006</year>;<volume>27</volume>(<issue>1</issue>):<fpage>154</fpage>&#x02013;<lpage>166</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijheatfluidflow.2005.04.002</pub-id></mixed-citation></ref><ref id="pone.0148134.ref019"><label>19</label><mixed-citation publication-type="journal">
<name><surname>Ridouane</surname><given-names>EH</given-names></name>, <name><surname>Danforth</surname><given-names>CM</given-names></name>, <name><surname>Hitt</surname><given-names>DL</given-names></name>. <article-title>A 2-D numerical study of chaotic flow in a natural convection loop</article-title>. <source>International Journal of Heat and Mass Transfer</source>. <year>2010</year>;<volume>53</volume>(<issue>1</issue>):<fpage>76</fpage>&#x02013;<lpage>84</lpage>. <pub-id pub-id-type="doi">10.1016/j.ijheatmasstransfer.2009.10.003</pub-id></mixed-citation></ref><ref id="pone.0148134.ref020"><label>20</label><mixed-citation publication-type="journal">
<name><surname>Louisos</surname><given-names>WF</given-names></name>, <name><surname>Hitt</surname><given-names>DL</given-names></name>, <name><surname>Danforth</surname><given-names>CM</given-names></name>. <article-title>Chaotic flow in a 2D natural convection loop with heat flux boundaries</article-title>. <source>International Journal of Heat and Mass Transfer</source>. <year>2013</year>;<volume>61</volume>:<fpage>565</fpage>&#x02013;<lpage>576</lpage>.</mixed-citation></ref><ref id="pone.0148134.ref021"><label>21</label><mixed-citation publication-type="other">Glenn D. Characterizing weather in a thermosyphon: an atmosphere that hangs on a wall; 2013. Undergraduate Honors Thesis, University of Vermont.</mixed-citation></ref><ref id="pone.0148134.ref022"><label>22</label><mixed-citation publication-type="other">Jasak H, Jemcov A, Tukovic Z. OpenFOAM: A C++ library for complex physics simulations. In: International Workshop on Coupled Methods in Numerical Dynamics, IUC, Dubrovnik, Croatia; 2007. p. 1&#x02013;20.</mixed-citation></ref><ref id="pone.0148134.ref023"><label>23</label><mixed-citation publication-type="journal">
<name><surname>Issa</surname><given-names>RI</given-names></name>. <article-title>Solution of the implicitly discretised fluid flow equations by operator-splitting</article-title>. <source>Journal of Computational physics</source>. <year>1986</year>;<volume>62</volume>(<issue>1</issue>):<fpage>40</fpage>&#x02013;<lpage>65</lpage>. <pub-id pub-id-type="doi">10.1016/0021-9991(86)90099-9</pub-id></mixed-citation></ref><ref id="pone.0148134.ref024"><label>24</label><mixed-citation publication-type="journal">
<name><surname>Lorenc</surname><given-names>AC</given-names></name>. <article-title>Analysis methods for numerical weather prediction</article-title>. <source>Quarterly Journal of the Royal Meteorological Society</source>. <year>1986</year>;<volume>112</volume>(<issue>474</issue>):<fpage>1177</fpage>&#x02013;<lpage>1194</lpage>. <pub-id pub-id-type="doi">10.1002/qj.49711247414</pub-id></mixed-citation></ref><ref id="pone.0148134.ref025"><label>25</label><mixed-citation publication-type="book">
<name><surname>Kalnay</surname><given-names>E</given-names></name>. <source>Atmospheric modeling, data assimilation, and predictability</source>. <publisher-name>Cambridge university press</publisher-name>; <year>2003</year>.</mixed-citation></ref><ref id="pone.0148134.ref026"><label>26</label><mixed-citation publication-type="journal">
<name><surname>Danforth</surname><given-names>CM</given-names></name>, <name><surname>Kalnay</surname><given-names>E</given-names></name>, <name><surname>Miyoshi</surname><given-names>T</given-names></name>. <article-title>Estimating and correcting global weather model error</article-title>. <source>Monthly weather review</source>. <year>2007</year>;<volume>135</volume>(<issue>2</issue>):<fpage>281</fpage>&#x02013;<lpage>299</lpage>. <pub-id pub-id-type="doi">10.1175/MWR3289.1</pub-id></mixed-citation></ref><ref id="pone.0148134.ref027"><label>27</label><mixed-citation publication-type="journal">
<name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Kalnay</surname><given-names>E</given-names></name>, <name><surname>Miyoshi</surname><given-names>T</given-names></name>, <name><surname>Danforth</surname><given-names>CM</given-names></name>. <article-title>Accounting for model errors in ensemble data assimilation</article-title>. <source>Monthly Weather Review</source>. <year>2009</year>;<volume>137</volume>(<issue>10</issue>):<fpage>3407</fpage>&#x02013;<lpage>3419</lpage>. <pub-id pub-id-type="doi">10.1175/2009MWR2766.1</pub-id></mixed-citation></ref><ref id="pone.0148134.ref028"><label>28</label><mixed-citation publication-type="journal">
<name><surname>Danforth</surname><given-names>CM</given-names></name>, <name><surname>Kalnay</surname><given-names>E</given-names></name>. <article-title>Using singular value decomposition to parameterize state-dependent model errors</article-title>. <source>Journal of the Atmospheric Sciences</source>. <year>2008</year>;<volume>65</volume>(<issue>4</issue>):<fpage>1467</fpage>&#x02013;<lpage>1478</lpage>. <pub-id pub-id-type="doi">10.1175/2007JAS2419.1</pub-id></mixed-citation></ref><ref id="pone.0148134.ref029"><label>29</label><mixed-citation publication-type="journal">
<name><surname>Bishop</surname><given-names>CH</given-names></name>, <name><surname>Etherton</surname><given-names>BJ</given-names></name>, <name><surname>Majumdar</surname><given-names>SJ</given-names></name>. <article-title>Adaptive sampling with the ensemble transform Kalman filter. Part I: Theoretical aspects</article-title>. <source>Monthly weather review</source>. <year>2001</year>;<volume>129</volume>(<issue>3</issue>):<fpage>420</fpage>&#x02013;<lpage>436</lpage>. <pub-id pub-id-type="doi">10.1175/1520-0493(2001)129&#x0003c;0420:ASWTET&#x0003e;2.0.CO;2</pub-id></mixed-citation></ref><ref id="pone.0148134.ref030"><label>30</label><mixed-citation publication-type="journal">
<name><surname>Kalnay</surname><given-names>E</given-names></name>, <name><surname>Li</surname><given-names>H</given-names></name>, <name><surname>Miyoshi</surname><given-names>T</given-names></name>, <name><surname>Yang</surname><given-names>SC</given-names></name>, <name><surname>Ballabrera-Poy</surname><given-names>J</given-names></name>. <article-title>4-D-Var or ensemble Kalman filter?</article-title>
<source>Tellus A</source>. <year>2007</year>;<volume>59</volume>(<issue>5</issue>):<fpage>758</fpage>&#x02013;<lpage>773</lpage>. <pub-id pub-id-type="doi">10.1111/j.1600-0870.2007.00261.x</pub-id></mixed-citation></ref><ref id="pone.0148134.ref031"><label>31</label><mixed-citation publication-type="journal">
<name><surname>Ott</surname><given-names>E</given-names></name>, <name><surname>Hunt</surname><given-names>BR</given-names></name>, <name><surname>Szunyogh</surname><given-names>I</given-names></name>, <name><surname>Zimin</surname><given-names>AV</given-names></name>, <name><surname>Kostelich</surname><given-names>EJ</given-names></name>, <name><surname>Corazza</surname><given-names>M</given-names></name>, <etal>et al</etal>
<article-title>A local ensemble Kalman filter for atmospheric data assimilation</article-title>. <source>Tellus A</source>. <year>2004</year>;<volume>56</volume>(<issue>5</issue>):<fpage>415</fpage>&#x02013;<lpage>428</lpage>. <pub-id pub-id-type="doi">10.1111/j.1600-0870.2004.00076.x</pub-id></mixed-citation></ref><ref id="pone.0148134.ref032"><label>32</label><mixed-citation publication-type="journal">
<name><surname>Hunt</surname><given-names>BR</given-names></name>, <name><surname>Kostelich</surname><given-names>EJ</given-names></name>, <name><surname>Szunyogh</surname><given-names>I</given-names></name>. <article-title>Efficient data assimilation for spatiotemporal chaos: A local ensemble transform Kalman filter</article-title>. <source>Physica D: Nonlinear Phenomena</source>. <year>2007</year>;<volume>230</volume>(<issue>1</issue>):<fpage>112</fpage>&#x02013;<lpage>126</lpage>. <pub-id pub-id-type="doi">10.1016/j.physd.2006.11.008</pub-id></mixed-citation></ref><ref id="pone.0148134.ref033"><label>33</label><mixed-citation publication-type="other">Tu JH, Rowley CW, Luchtenburg DM, Brunton SL, Kutz JN. On dynamic mode decomposition: theory and applications. arXiv preprint arXiv:13120041. 2013;.</mixed-citation></ref><ref id="pone.0148134.ref034"><label>34</label><mixed-citation publication-type="journal">
<name><surname>Bishop</surname><given-names>CH</given-names></name>, <name><surname>Hodyss</surname><given-names>D</given-names></name>. <article-title>Adaptive Ensemble Covariance Localization in Ensemble 4D-VAR State Estimation</article-title>. <source>Monthly Weather Review</source>. <year>2011</year>
<month>4</month>;<volume>139</volume>(<issue>4</issue>):<fpage>7</fpage>
<pub-id pub-id-type="doi">10.1175/2010MWR3403.1</pub-id></mixed-citation></ref></ref-list></back></article>