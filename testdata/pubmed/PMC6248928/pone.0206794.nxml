<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">30462665</article-id><article-id pub-id-type="pmc">6248928</article-id><article-id pub-id-type="publisher-id">PONE-D-17-37313</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0206794</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Operator Theory</subject><subj-group><subject>Kernel Functions</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Signal Processing</subject><subj-group><subject>Signal Bandwidth</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Kernel Methods</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Kernel Methods</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Cell Biology</subject><subj-group><subject>Cellular Types</subject><subj-group><subject>Animal Cells</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cellular Neuroscience</subject><subj-group><subject>Neurons</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane Potential</subject><subj-group><subject>Action Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Membrane Potential</subject><subj-group><subject>Action Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Physiology</subject><subj-group><subject>Electrophysiology</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action Potentials</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neurophysiology</subject><subj-group><subject>Action Potentials</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Neuronal Tuning</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Algebra</subject><subj-group><subject>Polynomials</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Probability Theory</subject><subj-group><subject>Probability Density</subject></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Estimation of neuronal firing rate using Bayesian Adaptive Kernel Smoother (BAKS)</article-title><alt-title alt-title-type="running-head">Estimation of neuronal firing rate using BAKS</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9902-9051</contrib-id><name><surname>Ahmadi</surname><given-names>Nur</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Data curation</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Investigation</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Software</role><role content-type="http://credit.casrai.org/">Validation</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; original draft</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="aff" rid="aff002"><sup>2</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Constandinou</surname><given-names>Timothy G.</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="aff" rid="aff002"><sup>2</sup></xref></contrib><contrib contrib-type="author" equal-contrib="yes"><name><surname>Bouganis</surname><given-names>Christos-Savvas</given-names></name><role content-type="http://credit.casrai.org/">Conceptualization</role><role content-type="http://credit.casrai.org/">Formal analysis</role><role content-type="http://credit.casrai.org/">Methodology</role><role content-type="http://credit.casrai.org/">Supervision</role><role content-type="http://credit.casrai.org/">Visualization</role><role content-type="http://credit.casrai.org/">Writing &#x02013; review &#x00026; editing</role><xref ref-type="aff" rid="aff002"><sup>2</sup></xref></contrib></contrib-group><aff id="aff001">
<label>1</label>
<addr-line>Centre for Bio-Inspired Technology, Institute of Biomedical Engineering, Imperial College London, London, United Kingdom</addr-line>
</aff><aff id="aff002">
<label>2</label>
<addr-line>Department of Electrical and Electronic Engineering, Imperial College London, London, United Kingdom</addr-line>
</aff><contrib-group><contrib contrib-type="editor"><name><surname>Harezlak</surname><given-names>Jaroslaw</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1">
<addr-line>Indiana University, UNITED STATES</addr-line>
</aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><corresp id="cor001">* E-mail: <email>n.ahmadi16@imperial.ac.uk</email></corresp></author-notes><pub-date pub-type="collection"><year>2018</year></pub-date><pub-date pub-type="epub"><day>21</day><month>11</month><year>2018</year></pub-date><volume>13</volume><issue>11</issue><elocation-id>e0206794</elocation-id><history><date date-type="received"><day>18</day><month>10</month><year>2017</year></date><date date-type="accepted"><day>21</day><month>10</month><year>2018</year></date></history><permissions><copyright-statement>&#x000a9; 2018 Ahmadi et al</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Ahmadi et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0206794.pdf"/><abstract><p>Neurons use sequences of action potentials (spikes) to convey information across neuronal networks. In neurophysiology experiments, information about external stimuli or behavioral tasks has been frequently characterized in term of neuronal firing rate. The firing rate is conventionally estimated by averaging spiking responses across multiple similar experiments (or trials). However, there exist a number of applications in neuroscience research that require firing rate to be estimated on a single trial basis. Estimating firing rate from a single trial is a challenging problem and current state-of-the-art methods do not perform well. To address this issue, we develop a new method for estimating firing rate based on a kernel smoothing technique that considers the bandwidth as a random variable with prior distribution that is adaptively updated under an empirical Bayesian framework. By carefully selecting the prior distribution together with Gaussian kernel function, an analytical expression can be achieved for the kernel bandwidth. We refer to the proposed method as Bayesian Adaptive Kernel Smoother (BAKS). We evaluate the performance of BAKS using synthetic spike train data generated by biologically plausible models: inhomogeneous Gamma (IG) and inhomogeneous inverse Gaussian (IIG). We also apply BAKS to real spike train data from non-human primate (NHP) motor and visual cortex. We benchmark the proposed method against established and previously reported methods. These include: optimized kernel smoother (OKS), variable kernel smoother (VKS), local polynomial fit (Locfit), and Bayesian adaptive regression splines (BARS). Results using both synthetic and real data demonstrate that the proposed method achieves better performance compared to competing methods. This suggests that the proposed method could be useful for understanding the encoding mechanism of neurons in cognitive-related tasks. The proposed method could also potentially improve the performance of brain-machine interface (BMI) decoder that relies on estimated firing rate as the input.</p></abstract><funding-group><award-group id="award001"><funding-source><institution>Indonesia Endowment Fund for Education (LPDP)</institution></funding-source><award-id>PRJ-123/LPDP/2016</award-id><principal-award-recipient><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0002-9902-9051</contrib-id><name><surname>Ahmadi</surname><given-names>Nur</given-names></name></principal-award-recipient></award-group><funding-statement>This study was funded by the Indonesia Endowment Fund for Education (LPDP), Republic of Indonesia (award reference: PRJ-123/LPDP/2016). The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. No additional external funding received for this study.</funding-statement></funding-group><counts><fig-count count="12"/><table-count count="3"/><page-count count="31"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>Synthetic datasets are available via GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/nurahmadi/BAKS">https://github.com/nurahmadi/BAKS</ext-link>). Real datasets are available via the CRCNS website (<ext-link ext-link-type="uri" xlink:href="https://crcns.org/">https://crcns.org/</ext-link>) and the NSA website (<ext-link ext-link-type="uri" xlink:href="http://www.neuralsignal.org/">http://www.neuralsignal.org/</ext-link>).</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>Synthetic datasets are available via GitHub (<ext-link ext-link-type="uri" xlink:href="https://github.com/nurahmadi/BAKS">https://github.com/nurahmadi/BAKS</ext-link>). Real datasets are available via the CRCNS website (<ext-link ext-link-type="uri" xlink:href="https://crcns.org/">https://crcns.org/</ext-link>) and the NSA website (<ext-link ext-link-type="uri" xlink:href="http://www.neuralsignal.org/">http://www.neuralsignal.org/</ext-link>).</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>In neural systems, signaling and interneuronal communication can be observed through the characteristic of action potentials (or &#x02018;spikes&#x02019;). A sequence of spikes, known as a spike train, may encode information based on different schemes. Currently, there are two main hypotheses of neural coding schemes: <italic>temporal</italic> coding and <italic>rate</italic> coding. The temporal coding represents the information by the precise timing or occurrence of spikes. On the other hand, the rate coding represents the information by the rate or frequency at which a neuron &#x0201c;fires&#x0201d; spikes, also known as &#x0201c;firing rate&#x0201d;, and has been the most commonly used scheme to characterize the neuronal or network responses to external stimuli or behavioral tasks [<xref rid="pone.0206794.ref001" ref-type="bibr">1</xref>, <xref rid="pone.0206794.ref002" ref-type="bibr">2</xref>]. The firing rate is typically estimated in offline analysis by averaging spiking responses across multiple repeated experiments known as trials. In practice, however, spiking responses may differ considerably even though the trial setting remains approximately the same. This is partly due to the inherent stochastic nature of neurons and the difference of cognitive states during the trials [<xref rid="pone.0206794.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0206794.ref004" ref-type="bibr">4</xref>]. Averaging out many variably similar trials can obscure the temporal dynamics, which may contain useful information, on each single trial. Furthermore, many research of interests require the firing rate to be estimated on single trial basis. For example, quantifying trial-to-trial variability of neuronal responses [<xref rid="pone.0206794.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0206794.ref006" ref-type="bibr">6</xref>], decoding task parameters in brain-machine interface (BMI) applications [<xref rid="pone.0206794.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0206794.ref005" ref-type="bibr">5</xref>], and measuring neuronal responses in cognitive-related tasks such as decision making, motor planning, learning and memory [<xref rid="pone.0206794.ref007" ref-type="bibr">7</xref>&#x02013;<xref rid="pone.0206794.ref009" ref-type="bibr">9</xref>]. Therefore, it is essential to be able to accurately estimate firing rate based on single trials.</p><p>Estimating firing rate as a continuous-time function from a single trial is a challenging task since the underlying process provides only a sparse representation of the spiking data. A widely used method known as peri-stimulus time histogram (PSTH) results in a coarse estimate [<xref rid="pone.0206794.ref010" ref-type="bibr">10</xref>, <xref rid="pone.0206794.ref011" ref-type="bibr">11</xref>]. To produce smooth estimate of firing rate, several methods have been proposed such as optimized kernel smoother (OKS) [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>], variable kernel smoother (VKS) [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>], local polynomial fit (Locfit) [<xref rid="pone.0206794.ref013" ref-type="bibr">13</xref>], and Bayesian adaptive regression splines (BARS) [<xref rid="pone.0206794.ref014" ref-type="bibr">14</xref>]. OKS and VKS employ kernel density estimation technique in which the accuracy of estimation is heavily impacted by the choice of the kernel bandwidth. Both methods automatically compute the bandwidth based on mean integrated squared error (MISE) minimization principle. However, in computing the bandwidth, these methods make assumption that spikes are generated by a Poisson process. Even though superimposed spike trains across many trials approximate a Poisson process, in the case of single trial, a spike train has been shown to depart from this assumption [<xref rid="pone.0206794.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0206794.ref016" ref-type="bibr">16</xref>]. Single trial spike train exhibits history-dependent properties such as refractory period and bursting, which cannot be modeled by Poisson process [<xref rid="pone.0206794.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0206794.ref016" ref-type="bibr">16</xref>]. The deviation from Poisson assumption can lead both OKS and VKS to exhibit poor performance under single trial cases. Locfit employs a generalized nonparametric regression technique where the firing rate is approximated by polynomial. The estimation accuracy of Locfit depends mostly on a smoothing parameter (bandwidth). How this bandwidth is selected along with the Poisson assumption of the spike train are the main caveats of this method. Like Locfit, BARS also employs a generalized regression technique, except that it estimates the firing rate using splines (several polynomials connected at some points or knots). The challenge of using a spline-based method is determining the number and location of the knots since these will significantly impact the estimation. To determine the optimal knot configurations (number and location), BARS utilizes a reversible-jump Markov chain Monte Carlo (MCMC) engine with Bayesian information criterion (BIC). The flexibility and powerfulness of BARS comes at a price of relatively high computational complexity [<xref rid="pone.0206794.ref014" ref-type="bibr">14</xref>, <xref rid="pone.0206794.ref017" ref-type="bibr">17</xref>]. In addition, similarly to above-mentioned methods, BARS also assumes that spikes are generated from a Poisson process. It is intended to be used for firing rate estimation after pooling spikes across multiple trials [<xref rid="pone.0206794.ref017" ref-type="bibr">17</xref>].</p><p>Within this context, it is highly desirable to have a method for estimating neuronal firing rate from a single trial spike train, which features an adaptive capability and low computational complexity. An adaptive capability is crucial as spiking activity may change rapidly within single trial. The proposed method should be data-driven and able to accurately estimate the underlying spike dynamics. Low computational complexity is needed to perform the computation within a short time, and is necessary for real-time BMI applications. In addition, it is important to have a spike train model that mimics the spiking behavior encountered in real neural recording. Using certain assumption on the underlying rate function (i.e. the &#x0201c;ground truth&#x0201d; is known), single spike trains can be stochastically generated which can then be used to evaluate the performance of the firing rate estimation method.</p><p>In this paper, we propose a new method for estimation of firing rate that addresses the issues listed above. This method employs a kernel smoothing technique due to its simplicity. The key parameter, bandwidth, is considered as a random variable with a prior distribution and is adaptively determined under an empirical Bayesian framework. With the appropriate selection of kernel and prior distribution functions, an analytical expression of posterior distribution can be attained which reduces the computational complexity. We refer to this method as Bayesian Adaptive Kernel Smoother (BAKS). We evaluate BAKS with synthetic data generated from two biologically plausible models: inhomogeneous Gamma (IG) and inhomogeneous inverse Gaussian (IIG). BAKS is then tested with real neural data recorded from motor and visual cortex of non-human primate (NHP).</p></sec><sec sec-type="materials|methods" id="sec002"><title>Methods</title><p>In this section, we first introduce a kernel smoothing technique for estimating firing rate. We then describe our proposed method, BAKS, a new variant of kernel-based firing rate estimation method that incorporates an adaptive bandwidth. Lastly, we explain two models that we used to generate synthetic spike train data for evaluating the performance of the proposed method. The BAKS code and all the datasets that we synthesized (in Matlab) have been made publicly available through <ext-link ext-link-type="uri" xlink:href="https://github.com/nurahmadi/BAKS">https://github.com/nurahmadi/BAKS</ext-link>.</p><sec id="sec003"><title>Kernel-based firing rate estimation</title><p>Let <italic>t</italic><sub>1</sub>, <italic>t</italic><sub>2</sub>, &#x022ef;, <italic>t</italic><sub><italic>n</italic></sub> be a sequence of spike times (i.e. a spike train) which can be expressed mathematically as
<disp-formula id="pone.0206794.e001"><alternatives><graphic xlink:href="pone.0206794.e001.jpg" id="pone.0206794.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>&#x003b4;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(1)</label></disp-formula>
where <italic>&#x003b4;</italic>(<italic>t</italic>) is Dirac function and <italic>n</italic> is the total number of spikes. The underlying rate function also known as firing rate, &#x003bb;(<italic>t</italic>), can be estimated by using kernel smoothing, a method which convolves the spike train with a kernel function <italic>K</italic>(<italic>t</italic>) as follows,
<disp-formula id="pone.0206794.e002"><alternatives><graphic xlink:href="pone.0206794.e002.jpg" id="pone.0206794.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003bb;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mo>-</mml:mo><mml:mi>&#x0221e;</mml:mi></mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:msubsup><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c4;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:mi>&#x003c4;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(2)</label></disp-formula>
<xref ref-type="disp-formula" rid="pone.0206794.e002">Eq (2)</xref> can also be represented as the sum over kernel functions centered at spike times <italic>t</italic><sub><italic>i</italic></sub>,
<disp-formula id="pone.0206794.e003"><alternatives><graphic xlink:href="pone.0206794.e003.jpg" id="pone.0206794.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003bb;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(3)</label></disp-formula>
The effectiveness of kernel smoothing technique depends on the choice of a kernel function and the selection of a smoothing parameter (i.e. bandwidth). A kernel function is required to be a non-negative, normalized to a unit area, having a zero first moment and a finite variance [<xref rid="pone.0206794.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>]. Examples of kernel functions that have been widely used are Gaussian and Epanechnikov [<xref rid="pone.0206794.ref018" ref-type="bibr">18</xref>, <xref rid="pone.0206794.ref019" ref-type="bibr">19</xref>]. In many occasions, the kernel bandwidth is set fixed over the whole observation interval. A significant amount of literature has been reported in the field of statistics on selecting the proper value for this fixed bandwidth [<xref rid="pone.0206794.ref020" ref-type="bibr">20</xref>&#x02013;<xref rid="pone.0206794.ref024" ref-type="bibr">24</xref>]. Even though a near-optimal fixed bandwidth selection (e.g. [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0206794.ref025" ref-type="bibr">25</xref>, <xref rid="pone.0206794.ref026" ref-type="bibr">26</xref>]) may yield a better estimate compared to an arbitrary choice, it may still suffer from simultaneously under- and over-smoothing depending on the underlying spike dynamics. A rapid change in spiking activity is sometimes encountered in neural responses and is of interest to neuroscientists. Thus, it is highly desirable to find optimal adaptive bandwidth selection method that can adaptively grasp the slow and rapid changes of firing rate.</p></sec><sec id="sec004"><title>Bayesian Adaptive Kernel Smoother (BAKS)</title><p>BAKS employs a kernel smoothing technique and incorporates an adaptive bandwidth at the estimation points, meaning the bandwidth at which firing rate is being estimated can adapt to the dynamics of the underlying process. In so doing, BAKS considers the bandwidth as a random variable with prior distribution and adaptively updates the posterior bandwidth given spiking data using an empirical Bayesian framework.</p><sec id="sec005"><title>Selection of kernel function</title><p>There are several choices of kernel functions that can be utilized for firing rate estimation. Gaussian and Epanechnikov are among the popular kernel functions in statistical research [<xref rid="pone.0206794.ref018" ref-type="bibr">18</xref>, <xref rid="pone.0206794.ref019" ref-type="bibr">19</xref>]. In term of minimizing asymptotic mean integrated squared error (AMISE), Gaussian kernel is slightly less efficient than Epanechnikov kernel [<xref rid="pone.0206794.ref018" ref-type="bibr">18</xref>]. However, Gaussian offers more interesting properties, e.g. the availability of several types of conjugate prior distributions. This conjugate property enables an analytical expression of posterior distribution which simplifies the computation and avoids using a numerical approximation technique. Due to this mathematical convenience, in our proposed method, we select a Gaussian kernel with adaptive bandwidth which can be expressed as,
<disp-formula id="pone.0206794.e004"><alternatives><graphic xlink:href="pone.0206794.e004.jpg" id="pone.0206794.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>K</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:msqrt><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:msup><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(4)</label></disp-formula>
where <italic>h</italic>(<italic>t</italic>) is the adaptive bandwidth. The bandwidth should be small (large) at the region of high (low) spike density.</p></sec><sec id="sec006"><title>Selection of prior distribution</title><p>We select a prior distribution of bandwidth that incorporates prior belief about spiking data (i.e. informative prior) and also leads to an analytical expression of posterior distribution. The informative prior is especially useful when the number of spiking data is relatively small as this prior can give more weight than the likelihood function, while the analytical expression is crucial to simplifying the computation and avoiding a numerical approximation technique (e.g. Markov chain Monte Carlo). In <xref ref-type="disp-formula" rid="pone.0206794.e004">Eq (4)</xref>, the Gaussian kernel uses parameter bandwidth (i.e. standard deviation in statistical literature) that describes how spread the observed data are around the mean. We can also represent the parameter in term of precision (inverse of square bandwidth) that describes how concentrated the observed data are around the mean. In computing firing rate estimation, the means of Gaussian kernel are set to the spike times. These spike times can be represented as sum of the interspike intervals (ISIs) that can be conveniently modeled by Gamma distribution [<xref rid="pone.0206794.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0206794.ref027" ref-type="bibr">27</xref>&#x02013;<xref rid="pone.0206794.ref030" ref-type="bibr">30</xref>]. Since sum of independent Gamma random variables follows Gamma distribution [<xref rid="pone.0206794.ref031" ref-type="bibr">31</xref>], the spike times can also be represented as Gamma distribution. Hence, we propose a Gamma prior distribution on the precision parameter <italic>&#x003c3;</italic>(<italic>t</italic>), where <italic>&#x003c3;</italic>(<italic>t</italic>) = 1/<italic>h</italic>(<italic>t</italic>)<sup>2</sup>. As Gamma distribution is a conjugate prior for Gaussian distribution with precision parameter [<xref rid="pone.0206794.ref032" ref-type="bibr">32</xref>], the choice of Gamma prior distribution results in an analytical expression of the posterior distribution. This Gamma prior distribution is given by
<disp-formula id="pone.0206794.e005"><alternatives><graphic xlink:href="pone.0206794.e005.jpg" id="pone.0206794.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>&#x003b2;</mml:mi><mml:mi>&#x003b1;</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>}</mml:mo><mml:mo>,</mml:mo><mml:mspace width="1.em"/><mml:mi>&#x003c3;</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(5)</label></disp-formula>
where <italic>&#x003b1;</italic> &#x0003e; 0 is the shape parameter, <italic>&#x003b2;</italic> &#x0003e; 0 is the scale parameter, and &#x00393;(<italic>&#x003b1;</italic>) is Gamma function. By the change-of-variable formula and transformation technique, we can express the prior distribution <italic>&#x003c0;</italic>(<italic>&#x003c3;</italic>(<italic>t</italic>)) as a function of <italic>h</italic>(<italic>t</italic>):
<disp-formula id="pone.0206794.e006"><alternatives><graphic xlink:href="pone.0206794.e006.jpg" id="pone.0206794.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow/><mml:mo>=</mml:mo><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000d7;</mml:mo><mml:mo>|</mml:mo><mml:mfrac><mml:mrow><mml:mi>d</mml:mi><mml:mi>&#x003c3;</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>|</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>&#x003b2;</mml:mi><mml:mi>&#x003b1;</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>&#x003b2;</mml:mi><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(6)</label></disp-formula></p></sec><sec id="sec007"><title>BAKS modeling and inference</title><p>Under Bayesian framework, the statistical inference depends on both likelihood function and prior distribution. The likelihood function is the probability density function of the observed spike train <italic>&#x003c1;</italic>(<italic>t</italic>) viewed as a function of the unknown bandwidth parameter <italic>h</italic>(<italic>t</italic>), which can be approximated by
<disp-formula id="pone.0206794.e007"><alternatives><graphic xlink:href="pone.0206794.e007.jpg" id="pone.0206794.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow/><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow/><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:msqrt><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>}</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(7)</label></disp-formula>
where <italic>K</italic><sub><italic>h</italic>(<italic>t</italic>)</sub>(<italic>t</italic> &#x02212; <italic>t</italic><sub><italic>i</italic></sub>) is Gaussian kernel as defined in <xref ref-type="disp-formula" rid="pone.0206794.e004">Eq (4)</xref> with adaptive bandwidth and centered at spike event time <italic>t</italic><sub><italic>i</italic></sub>.</p><p>Using Bayes&#x02019; theorem, the posterior distribution of kernel bandwidth, <italic>&#x003c0;</italic>(<italic>h</italic>(<italic>t</italic>)|<italic>&#x003c1;</italic>(<italic>t</italic>)), can be computed by
<disp-formula id="pone.0206794.e008"><alternatives><graphic xlink:href="pone.0206794.e008.jpg" id="pone.0206794.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mfrac></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(8)</label></disp-formula>
Computing the denominator of <xref ref-type="disp-formula" rid="pone.0206794.e008">Eq (8)</xref>, also called marginal density, can be problematic if there is no analytical solution of its integral expression since an approximation method will be required instead. The choice of prior distribution in <xref ref-type="disp-formula" rid="pone.0206794.e006">Eq (6)</xref> coupled with Gaussian kernel in <xref ref-type="disp-formula" rid="pone.0206794.e007">Eq (7)</xref> leads to an analytical expression for the denominator in <xref ref-type="disp-formula" rid="pone.0206794.e008">Eq (8)</xref> as follows,
<disp-formula id="pone.0206794.e009"><alternatives><graphic xlink:href="pone.0206794.e009.jpg" id="pone.0206794.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>-</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(9)</label></disp-formula>
The adaptive bandwidth can then be estimated under squared error loss function by using the posterior mean formulated as
<disp-formula id="pone.0206794.e010"><alternatives><graphic xlink:href="pone.0206794.e010.jpg" id="pone.0206794.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>&#x0222b;</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(10)</label></disp-formula>
The closed-form expression of <xref ref-type="disp-formula" rid="pone.0206794.e010">Eq (10)</xref> is given by
<disp-formula id="pone.0206794.e011"><alternatives><graphic xlink:href="pone.0206794.e011.jpg" id="pone.0206794.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(11)</label></disp-formula>
Eqs <xref ref-type="disp-formula" rid="pone.0206794.e009">(9)</xref>&#x02013;<xref ref-type="disp-formula" rid="pone.0206794.e011">(11)</xref> define what is called a mixture of <italic>t</italic>-distributions in statistical literature. By substituting the adaptive bandwidth in <xref ref-type="disp-formula" rid="pone.0206794.e011">Eq (11)</xref> into <xref ref-type="disp-formula" rid="pone.0206794.e003">Eq (3)</xref>, we can compute firing rate estimation using the following formula:
<disp-formula id="pone.0206794.e012"><alternatives><graphic xlink:href="pone.0206794.e012.jpg" id="pone.0206794.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003bb;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:msqrt><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi></mml:mrow></mml:msqrt><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(12)</label></disp-formula>
BAKS is graphically illustrated in <xref ref-type="fig" rid="pone.0206794.g001">Fig 1</xref>. The derivation of the closed-form expressions of bandwidth posterior distribution and the adaptive bandwidth estimate are given in Appendix 1 and Appendix 2, respectively.</p><fig id="pone.0206794.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g001</object-id><label>Fig 1</label><caption><title>Graphical representation of BAKS.</title><p>The various blocks describe the different components as follows: Circular blocks denote continuous variables, and rectangle blocks denote discrete variables. Shaded blocks represent observed variables, whereas white blocks represent hidden variables. Solid and dashed arrow indicate Bayesian modeling and inference phase, respectively.</p></caption><graphic xlink:href="pone.0206794.g001"/></fig></sec><sec id="sec008"><title>Parameter setting of prior distribution</title><p>The effectiveness of firing rate estimation using BAKS depends on the adaptive bandwidth estimate, which is influenced by the setting of parameter shape (<italic>&#x003b1;</italic>) and scale (<italic>&#x003b2;</italic>) of the prior distribution. According to prior distribution of bandwidth in <xref ref-type="disp-formula" rid="pone.0206794.e006">Eq (6)</xref>, we can calculate its mean and variance as follows,
<disp-formula id="pone.0206794.e013"><alternatives><graphic xlink:href="pone.0206794.e013.jpg" id="pone.0206794.e013g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M13"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo>[</mml:mo><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>]</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow/><mml:mo>=</mml:mo><mml:mo>&#x0222b;</mml:mo><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mi>&#x003c0;</mml:mi><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>&#x003b2;</mml:mi><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(13)</label></disp-formula>
<disp-formula id="pone.0206794.e014"><alternatives><graphic xlink:href="pone.0206794.e014.jpg" id="pone.0206794.e014g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M14"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mo>[</mml:mo><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>]</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow/><mml:mo>=</mml:mo><mml:mo>&#x0222b;</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mi>&#x003bc;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="1.em"/><mml:mi>&#x003bc;</mml:mi><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:mrow><mml:mo>[</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mrow><mml:mrow/><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mo>&#x00393;</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi>&#x003b2;</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(14)</label></disp-formula>
where <inline-formula id="pone.0206794.e015"><alternatives><graphic xlink:href="pone.0206794.e015.jpg" id="pone.0206794.e015g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M15"><mml:mrow><mml:mi mathvariant="double-struck">E</mml:mi><mml:mo>[</mml:mo><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mspace width="4pt"/><mml:mtext>and</mml:mtext><mml:mspace width="4pt"/></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">V</mml:mi><mml:mo>[</mml:mo><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo><mml:mo>]</mml:mo></mml:mrow></mml:math></alternatives></inline-formula> are the mean and variance of <italic>&#x003c0;</italic>(<italic>h</italic>(<italic>t</italic>)), respectively. It can be observed from both Eqs <xref ref-type="disp-formula" rid="pone.0206794.e013">(13)</xref> and <xref ref-type="disp-formula" rid="pone.0206794.e014">(14)</xref> that the mean and variance are inversely proportional to the value of parameter <italic>&#x003b2;</italic>. As the number of spike events (<italic>n</italic>) increases, the bandwidth decreases. Hence, to obtain consistency of the estimation, the value of <italic>&#x003b2;</italic> is set to be a function proportional to the number of spike events (<italic>n</italic>). Here, we propose <italic>&#x003b2;</italic> = <italic>n</italic><sup>4/5</sup> in accordance with MISE convergence rate of Gaussian kernel [<xref rid="pone.0206794.ref033" ref-type="bibr">33</xref>].</p><p>To yield accurate estimate of firing rate, we tune parameter <italic>&#x003b1;</italic> by minimizing mean integrated squared error (MISE). Since <italic>h</italic>(<italic>t</italic>) &#x0003e; 0, the numerator of Eqs <xref ref-type="disp-formula" rid="pone.0206794.e013">(13)</xref> and <xref ref-type="disp-formula" rid="pone.0206794.e014">(14)</xref> must be greater than zero, which in turn requires <italic>&#x003b1;</italic> &#x0003e; 1. The value of parameter <italic>&#x003b1;</italic> is tuned such that it minimizes MISE function given fixed value of <italic>&#x003b2;</italic> = <italic>n</italic><sup>4/5</sup>. This tuning process is mathematically expressed as follows,
<disp-formula id="pone.0206794.e016"><alternatives><graphic xlink:href="pone.0206794.e016.jpg" id="pone.0206794.e016g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M16"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>&#x003b1;</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mo form="prefix">arg</mml:mo><mml:munder><mml:mo form="prefix" movablelimits="true">min</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:munder><mml:mrow><mml:mo>{</mml:mo><mml:mtext>MISE</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(15)</label></disp-formula>
MISE is a common metric used in evaluating goodness-of-fit of a density estimation and has been used in previous studies of firing rate estimation [<xref rid="pone.0206794.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0206794.ref034" ref-type="bibr">34</xref>]. It is computed between the estimated firing rate (<inline-formula id="pone.0206794.e017"><alternatives><graphic xlink:href="pone.0206794.e017.jpg" id="pone.0206794.e017g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M17"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003bb;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>) and the true underlying rate function (&#x003bb;(<italic>t</italic>)) with the following formula,
<disp-formula id="pone.0206794.e018"><alternatives><graphic xlink:href="pone.0206794.e018.jpg" id="pone.0206794.e018g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M18"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mtext>MISE</mml:mtext></mml:mtd><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow/><mml:mo>=</mml:mo><mml:mo>&#x0222b;</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mover accent="true"><mml:mo>&#x003bb;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mo>&#x003bb;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mi>d</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow/><mml:mo>&#x02248;</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi><mml:mo>&#x02211;</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mover accent="true"><mml:mo>&#x003bb;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mo>&#x003bb;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(16)</label></disp-formula>
where <inline-formula id="pone.0206794.e019"><alternatives><graphic xlink:href="pone.0206794.e019.jpg" id="pone.0206794.e019g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M19"><mml:mi mathvariant="double-struck">E</mml:mi></mml:math></alternatives></inline-formula> denotes the expectation with respect to stochastic process of spike generation model and the integration/summation is performed over observation interval.</p><p>The tuning of parameter <italic>&#x003b1;</italic> was performed using synthetic spike train data generated by biologically plausible models &#x02013;inhomogeneous Gamma (IG) model and inhomogeneous inverse Gaussian (IIG) model&#x02013; which are described in the subsequent section. Parameter <italic>&#x003b1;</italic> value that gives the smallest MISE during this tuning process was then fixed and used for firing rate estimation during performance evaluation (testing) phase of our proposed method. The testing phase was performed using distinct synthetic datasets (i.e. different than that of during tuning phase) and real neural datasets.</p></sec></sec><sec id="sec009"><title>Spike train generation model</title><p>It is essential to have a model for generating spike trains in order to tune the parameter of BAKS and to evaluate its performance. A spike train can be modeled by using a point process; a stochastic process that describes localized events or points in real (e.g. time, space) domain. The most commonly used class of point processes to model a spike train is inhomogeneous Poisson (IP) process. [<xref rid="pone.0206794.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0206794.ref005" ref-type="bibr">5</xref>, <xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0206794.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0206794.ref025" ref-type="bibr">25</xref>]. In this class, spike counts (increments) within any intervals vary across time (i.e. nonstationary). The spike counts depend on integral value of the firing intensity function over interval in question but do not depend on the past spike times (i.e. remain independent). As a consequence, IP process still possesses memoryless property; a spike occurring at a particular time does not depend on the past spiking activities [<xref rid="pone.0206794.ref035" ref-type="bibr">35</xref>]. It has been shown that IP process can be used to approximate the behavior of neural spikes when the spikes are superimposed across trials [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0206794.ref016" ref-type="bibr">16</xref>]. However, a Poisson process cannot model the history-dependent properties (e.g. refractory period and bursting) of neural spike trains in the case of single trial. Hence, another class of point process is required to model single trial spike train.</p><p><italic>Renewal process</italic> is an alternative class of point process that can describe the history-dependent property of spike times by assuming that a spike fired at any point in time depending only on the last spike, not the spikes before it. In the renewal process, spike times are no longer independent, but it is their inter-spike intervals (ISIs) that remain independent. Spike trains can be conveniently represented by their ISIs drawn from a certain distribution. Two classes of distribution which have often been used to model non-Poisson spike train are Gamma and inverse Gaussian distributions [<xref rid="pone.0206794.ref006" ref-type="bibr">6</xref>, <xref rid="pone.0206794.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0206794.ref027" ref-type="bibr">27</xref>&#x02013;<xref rid="pone.0206794.ref030" ref-type="bibr">30</xref>, <xref rid="pone.0206794.ref036" ref-type="bibr">36</xref>]. The former is then called inhomogeneous Gamma (IG) model while the latter is called inhomogeneous inverse Gaussian (IIG) model.</p><sec id="sec010"><title>Inhomogeneous Gamma (IG) model</title><p>The Inhomogeneous Gamma (IG) model generalizes a Poisson model by allowing more flexible ISI distribution that is controlled by shape parameter (<italic>&#x003b3;</italic>) [<xref rid="pone.0206794.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0206794.ref027" ref-type="bibr">27</xref>&#x02013;<xref rid="pone.0206794.ref030" ref-type="bibr">30</xref>]. The gamma probability density of the ISI is defined as
<disp-formula id="pone.0206794.e020"><alternatives><graphic xlink:href="pone.0206794.e020.jpg" id="pone.0206794.e020g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M20"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>&#x003c4;</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c4;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>&#x003b8;</mml:mi><mml:mi>&#x003b3;</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:msup><mml:mi>&#x003c4;</mml:mi><mml:mrow><mml:mi>&#x003b3;</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mi>&#x003c4;</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:mfrac><mml:mo>}</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(17)</label></disp-formula>
where <italic>&#x003c4;</italic> &#x0003e; 0 denotes the ISI, <italic>&#x003b3;</italic> &#x0003e; 0 represents the shape parameter, <italic>&#x003b8;</italic> is the scale parameter, and &#x00393;(<italic>&#x003b3;</italic>) is the Gamma function. As shown in <xref ref-type="disp-formula" rid="pone.0206794.e020">Eq (17)</xref>, when <italic>&#x003b3;</italic> = 1, the ISI follows an exponential distribution as in a Poisson process. If <italic>&#x003b3;</italic> &#x0003c; 1, the probability density value declines faster than exponential, which means the ISI tends to become smaller. This can be used to describe neuron&#x02019;s rapid firing (bursting) phenomena. If <italic>&#x003b3;</italic> &#x0003e; 1, the probability density value will increase from zero up to a certain peak value and then decrease again to zero. This indicates the refractory period property where a neuron is less likely to fire again immediately after it fires a spike.</p><p>To generate a spike train from such a model, we employ time-rescaling theorem which transforms the original spike times into new rescaled spike times where the ISIs are independently and identically drawn from fixed distribution (e.g. Gamma) [<xref rid="pone.0206794.ref029" ref-type="bibr">29</xref>]. In the IG model, this transformation is defined as integration of underlying rate function, &#x003bb;(<italic>t</italic>), on the interval (0, <italic>t</italic>] and multiplied by the shape parameter (<italic>&#x003b3;</italic>). This transformation is formulated as
<disp-formula id="pone.0206794.e021"><alternatives><graphic xlink:href="pone.0206794.e021.jpg" id="pone.0206794.e021g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M21"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>&#x0039b;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:msubsup><mml:mo>&#x003bb;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(18)</label></disp-formula></p><p>Since &#x003bb;(<italic>t</italic>) is a non-negative function, &#x0039b;(<italic>t</italic>) is a monotonically increasing and one-to-one function and usually called integrated intensity function. Thus, we can obtain the original spike times from <italic>i.i.d</italic>. ISI samples (<italic>&#x003c4;</italic>) by performing the inverse of time-rescaling transform as follows,
<disp-formula id="pone.0206794.e022"><alternatives><graphic xlink:href="pone.0206794.e022.jpg" id="pone.0206794.e022g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M22"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02261;</mml:mo><mml:msub><mml:mo>&#x0039b;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>&#x0039b;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>-</mml:mo><mml:mo>&#x0039b;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003b3;</mml:mi><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:msubsup><mml:mo>&#x003bb;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(19)</label></disp-formula>
<disp-formula id="pone.0206794.e023"><alternatives><graphic xlink:href="pone.0206794.e023.jpg" id="pone.0206794.e023g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M23"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#x0039b;</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>&#x003c4;</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(20)</label></disp-formula>
where 0 &#x0003c; <italic>t</italic><sub>1</sub> &#x0003c; <italic>t</italic><sub>2</sub> &#x0003c;, &#x022ef;, &#x0003c; <italic>t</italic><sub><italic>n</italic></sub> &#x02264; <italic>T</italic> represent the spike times within interval (0, <italic>T</italic>] and <inline-formula id="pone.0206794.e024"><alternatives><graphic xlink:href="pone.0206794.e024.jpg" id="pone.0206794.e024g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M24"><mml:mrow><mml:msubsup><mml:mo>&#x0039b;</mml:mo><mml:mrow><mml:msub><mml:mi>t</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> is the inverse of time-rescaling transform.</p></sec><sec id="sec011"><title>Inhomogeneous inverse Gaussian (IIG) model</title><p>It has been suggested that inhomogeneous inverse Gaussian (IIG) model is more biologically plausible to describe the characteristic of neural spike train than IG model [<xref rid="pone.0206794.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0206794.ref037" ref-type="bibr">37</xref>]. The IIG model uses inverse Gaussian distribution for the ISI and has been applied in multiple studies [<xref rid="pone.0206794.ref038" ref-type="bibr">38</xref>, <xref rid="pone.0206794.ref039" ref-type="bibr">39</xref>]. The inverse Gaussian ISI distribution used in this model is given by
<disp-formula id="pone.0206794.e025"><alternatives><graphic xlink:href="pone.0206794.e025.jpg" id="pone.0206794.e025g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M25"><mml:mrow><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>&#x003c4;</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c4;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mi>&#x003b3;</mml:mi><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:msup><mml:mi>&#x003c4;</mml:mi><mml:mn>3</mml:mn></mml:msup></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>/</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mtext>exp</mml:mtext><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003b3;</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003c4;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003bc;</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>&#x003bc;</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mi>&#x003c4;</mml:mi></mml:mrow></mml:mfrac></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(21)</label></disp-formula>
where <italic>&#x003c4;</italic> &#x0003e; 0 denotes the ISI, <italic>&#x003b3;</italic> is the shape parameter, and <italic>&#x003bc;</italic> is the location parameter. In the IIG model, the value of ISI density is zero at the origin, then increases to certain peak value, and decreases again to zero. How quick the density value rises or falls is controlled by the shape parameter (<italic>&#x003b3;</italic>), which demonstrates the flexibility of IIG model in describing different neural spike characteristics such as rapid bursting and refractory period. The smaller (larger) value of <italic>&#x003b3;</italic>, neuron tends to fire more bursty (regularly).</p><p>To generate a spike train using the IIG model, we employ a similar procedure as that of IG model, with the exception that the time-rescaling transform here is expressed as
<disp-formula id="pone.0206794.e026"><alternatives><graphic xlink:href="pone.0206794.e026.jpg" id="pone.0206794.e026g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M26"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mo>&#x0039b;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msubsup><mml:mo>&#x0222b;</mml:mo><mml:mrow><mml:mn>0</mml:mn></mml:mrow><mml:mi>t</mml:mi></mml:msubsup><mml:mo>&#x003bb;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>u</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>u</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(22)</label></disp-formula>
where the interval between subsequent spike times (ISIs) in the rescaled domain are drawn from <italic>i.i.d</italic>. inverse Gaussian distribution. The spike times in the original domain can be computed by using the inverse of time-rescaling transform as shown in <xref ref-type="disp-formula" rid="pone.0206794.e023">Eq (20)</xref>.</p></sec></sec></sec><sec sec-type="results" id="sec012"><title>Results</title><sec id="sec013"><title>Synthetic datasets</title><p>In our synthetic data, the spike trains were generated from IG and IIG models with different underlying rate functions that represent non-stationary processes usually encountered in empirical datasets. These rate functions include (1) a continuous process with changing (heterogeneous) frequency, (2) a continuous process with oscillatory (homogeneous) frequency, and (3) a discontinuous process with sudden rate changes. In this study, the first, second, and third rate functions are referred to as &#x02018;chirp&#x02019;, &#x02018;sine&#x02019;, and &#x02018;sawtooth&#x02019; rate functions, and are mathematically expressed as,
<disp-formula id="pone.0206794.e027"><alternatives><graphic xlink:href="pone.0206794.e027.jpg" id="pone.0206794.e027g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M27"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mo>&#x003bb;</mml:mo><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mo form="prefix">sin</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:mi>f</mml:mi><mml:msup><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(23)</label></disp-formula>
<disp-formula id="pone.0206794.e028"><alternatives><graphic xlink:href="pone.0206794.e028.jpg" id="pone.0206794.e028g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M28"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mo>&#x003bb;</mml:mo><mml:mi>s</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo>+</mml:mo><mml:mi>A</mml:mi><mml:mo form="prefix">sin</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(24)</label></disp-formula>
<disp-formula id="pone.0206794.e029"><alternatives><graphic xlink:href="pone.0206794.e029.jpg" id="pone.0206794.e029g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M29"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mo>&#x003bb;</mml:mo><mml:mrow><mml:mi>s</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>A</mml:mi></mml:mrow><mml:mi>&#x003c0;</mml:mi></mml:mfrac><mml:mo form="prefix">arctan</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mo form="prefix">cot</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c0;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(25)</label></disp-formula>
where <italic>&#x003b7;</italic> indicates the base or average number of spikes per second and <italic>A</italic> denotes the intensity (or amplitude) which controls the dynamic range of the rate function. Parameter <italic>f</italic> is frequency whereas <italic>&#x003d5;</italic> is phase. The chirp, sine and sawtooth rate functions are represented by &#x003bb;<sub><italic>c</italic></sub>(<italic>t</italic>), &#x003bb;<sub><italic>s</italic></sub>(<italic>t</italic>) and &#x003bb;<sub><italic>st</italic></sub>(<italic>t</italic>), respectively.</p><p>The chirp rate function used in this study is similar to that of Rao and Teh [<xref rid="pone.0206794.ref040" ref-type="bibr">40</xref>], whereas the sine and sawtooth processes are similar to that of Shimazaki and Shinomoto [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>] but with different intensity, frequency, and spike train model. Examples of chirp, sine, and sawtooth rate functions with certain parameter settings are illustrated in <xref ref-type="fig" rid="pone.0206794.g002">Fig 2a, 2b and 2c</xref>, respectively.</p><fig id="pone.0206794.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g002</object-id><label>Fig 2</label><caption><title>Illustration of the underlying rate functions used in this study.</title><p>(a) Chirp rate function with <italic>&#x003b7;</italic> = 50, <italic>A</italic> = 25, <italic>f</italic><sub><italic>c</italic></sub> = 0.5, and <italic>&#x003d5;</italic> = 0. (b) Sine rate function with <italic>&#x003b7;</italic> = 50, <italic>A</italic> = 25, <italic>f</italic><sub><italic>s</italic></sub> = 1, and <italic>&#x003d5;</italic> = &#x02212;<italic>&#x003c0;</italic>/2. (c) Sawtooth rate function with <italic>&#x003b7;</italic> = 50, <italic>A</italic> = 25, <italic>f</italic><sub><italic>st</italic></sub> = 1, and <italic>&#x003d5;</italic> = &#x02212;<italic>&#x003c0;</italic>/4. (d) Gaussian-damped sinusoidal rate function with <italic>&#x003b7;</italic> = 50, <italic>A</italic> = 1, <italic>t</italic><sub>0</sub> = 0.2, <italic>&#x003c3;</italic> = 1, <italic>f</italic><sub><italic>gds</italic></sub> = 0.5, and <italic>&#x003d5;</italic> = &#x02212;<italic>&#x003c0;</italic>/2.</p></caption><graphic xlink:href="pone.0206794.g002"/></fig><p>During parameter tuning of BAKS (tuning phase), we set <italic>&#x003b7;</italic> to 50 spikes/s and <italic>A</italic> to 25 spikes/s (corresponds to dynamic intensity range between 25 and 75 spikes/s) as in [<xref rid="pone.0206794.ref028" ref-type="bibr">28</xref>]. These intensity values are referred to as medium intensity. This setting is reasonable as in practice cortical neurons do not often fire more than 100 spikes/s [<xref rid="pone.0206794.ref041" ref-type="bibr">41</xref>]. The frequency of chirp (<italic>f</italic><sub><italic>c</italic></sub>), sine (<italic>f</italic><sub><italic>s</italic></sub>) and sawtooth (<italic>f</italic><sub><italic>st</italic></sub>) rate functions were set to 0.5, 1 and 1, respectively. These frequency values are referred to as medium frequency. We generated randomly 100 single spike trains (duration of 2s) from two models (IG and IIG) and three rate functions (chirp, sine, and sawtooth). In IG model, the shape parameter (<italic>&#x003b3;</italic>) that determines the regularity of firing rate was set to 4, while the scale parameter (<italic>&#x003b8;</italic>) was set to 1. This setting is comparable to real neural spiking data and also used in [<xref rid="pone.0206794.ref027" ref-type="bibr">27</xref>, <xref rid="pone.0206794.ref036" ref-type="bibr">36</xref>]. Analogously, the shape (<italic>&#x003b3;</italic>) and location (<italic>&#x003bc;</italic>) parameters in IIG model were respectively set to 4 and 1. The parameter value (<italic>&#x003b1;</italic>) of prior distribution in BAKS was tuned by minimizing the average MISE from two models and three rate functions mentioned above. The same procedure was performed to tune the smoothing parameter value of Locfit.</p><p>For evaluating the performance of BAKS (testing phase), we generated 5 datasets each containing 100 repetitions from both IG and IIG models with the same and different setting from that of parameter tuning phase. Dataset testing 1 was generated using the same setting as in the tuning phase. Dataset testing 1 was used to evaluate BAKS when the underlying rate functions are the same but their stochastic spiking data realizations are different. Dataset testing 2 was used to evaluate BAKS when the frequency and intensity of the underlying rate functions are different. The frequency of chirp, sine and sawtooth rate functions were respectively set to low (0.25, 0.5 and 0.5) and high (0.75, 1.5 and 1.5) while keeping the intensity same as that of tuning phase. Then, the dynamic intensity range of these three rate functions were set to low (2&#x02013;20) and high (25&#x02013;175) while keeping the frequency same as that of tuning phase. In dataset testing 3, the model setting was equal to during the tuning phase except that the parameter shape (<italic>&#x003b3;</italic>) was varied between 1 and 10 with an increment of 1. Dataset testing 4 was used to assess the performance of BAKS under multiple trials (<italic>tr</italic> = {5, 10, 20, 30}). These multi trial spike trains were obtained by superimposing spike trains from a number of trial (5, 10, 20 or 30) into single spike trains with the same setting as of tuning phase. In dataset testing 5, spike trains were generated using Gaussian-damped sinusoidal rate function with variable intensity and frequency. The idea of using this rate is taken from Mazurek&#x02019;s work [<xref rid="pone.0206794.ref041" ref-type="bibr">41</xref>]. Mathematically, the Gaussian damped sinusoidal rate function is given by
<disp-formula id="pone.0206794.e030"><alternatives><graphic xlink:href="pone.0206794.e030.jpg" id="pone.0206794.e030g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M30"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mo>&#x003bb;</mml:mo><mml:mrow><mml:mi>g</mml:mi><mml:mi>d</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003b7;</mml:mi><mml:mi>A</mml:mi><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:mn>2</mml:mn><mml:msup><mml:mi>&#x003c3;</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>}</mml:mo><mml:mo form="prefix">sin</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>2</mml:mn><mml:mi>&#x003c0;</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003d5;</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(26)</label></disp-formula></p><p>During the generation of dataset testing 5, the frequency (<italic>f</italic><sub><italic>gds</italic></sub>) was set to low (0.5), medium (1.5) and high (2) while keeping the dynamic intensity range to medium (0 to 100) which corresponds to <italic>&#x003b7;</italic> = 50 and <italic>A</italic> = 1; the dynamic intensity range was varied between low (0 to 20), medium (0 to 100) and high (0 to 200) while setting <italic>f</italic><sub><italic>gds</italic></sub> = 1. An example of Gaussian-damped sinusoidal rate function is illustrated in <xref ref-type="fig" rid="pone.0206794.g002">Fig 2d</xref>. The summary of model settings for generating the synthetic datasets used in tuning and testing phase is shown in <xref rid="pone.0206794.t001" ref-type="table">Table 1</xref>.</p><table-wrap id="pone.0206794.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.t001</object-id><label>Table 1</label><caption><title>Model setting for synthetic dataset generation.</title></caption><alternatives><graphic id="pone.0206794.t001g" xlink:href="pone.0206794.t001"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Phase</th><th align="center" rowspan="1" colspan="1">Rate function</th><th align="center" rowspan="1" colspan="1">Intensity</th><th align="center" rowspan="1" colspan="1">Frequency</th><th align="center" rowspan="1" colspan="1">Parameter shape (<italic>&#x003b3;</italic>)</th><th align="center" rowspan="1" colspan="1">Number of trial (<italic>tr</italic>)</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Tuning</td><td align="center" rowspan="1" colspan="1">{Chirp, sine, sawtooth}</td><td align="center" rowspan="1" colspan="1">Medium</td><td align="center" rowspan="1" colspan="1">Medium</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">1</td></tr><tr><td align="left" rowspan="1" colspan="1">Testing 1</td><td align="center" rowspan="1" colspan="1">{Chirp, sine, sawtooth}</td><td align="center" rowspan="1" colspan="1">Medium</td><td align="center" rowspan="1" colspan="1">Medium</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">1</td></tr><tr><td align="left" rowspan="1" colspan="1">Testing 2</td><td align="center" rowspan="1" colspan="1">{Chirp, sine, sawtooth}</td><td align="center" rowspan="1" colspan="1">{Low, high}</td><td align="center" rowspan="1" colspan="1">{Low, high}</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">1</td></tr><tr><td align="left" rowspan="1" colspan="1">Testing 3</td><td align="center" rowspan="1" colspan="1">{Chirp, sine, sawtooth}</td><td align="center" rowspan="1" colspan="1">Medium</td><td align="center" rowspan="1" colspan="1">Medium</td><td align="center" rowspan="1" colspan="1">{1, 2, &#x022ef;, 10}</td><td align="center" rowspan="1" colspan="1">1</td></tr><tr><td align="left" rowspan="1" colspan="1">Testing 4</td><td align="center" rowspan="1" colspan="1">{Chirp, sine, sawtooth}</td><td align="center" rowspan="1" colspan="1">Medium</td><td align="center" rowspan="1" colspan="1">Medium</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">{5, 10, 20, 30}</td></tr><tr><td align="left" rowspan="1" colspan="1">Testing 5</td><td align="center" rowspan="1" colspan="1">{Gaussian-damped sine}</td><td align="center" rowspan="1" colspan="1">{Low, medium, high}</td><td align="center" rowspan="1" colspan="1">{Low, medium, high}</td><td align="center" rowspan="1" colspan="1">4</td><td align="center" rowspan="1" colspan="1">1</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t001fn001"><p>Tuning: medium intensity (<italic>&#x003b7;</italic> = 50, <italic>A</italic> = 25), medium frequency (<italic>f</italic><sub><italic>c</italic></sub> = 0.5, <italic>f</italic><sub><italic>s</italic></sub> = 1, <italic>f</italic><sub><italic>st</italic></sub> = 1)</p></fn><fn id="t001fn002"><p>Testing 1: medium intensity (<italic>&#x003b7;</italic> = 50, <italic>A</italic> = 25), medium frequency (<italic>f</italic><sub><italic>c</italic></sub> = 0.5, <italic>f</italic><sub><italic>s</italic></sub> = 1, <italic>f</italic><sub><italic>st</italic></sub> = 1)</p></fn><fn id="t001fn003"><p>Testing 2: low intensity (<italic>&#x003b7;</italic> = 11, <italic>A</italic> = 9), high intensity (<italic>&#x003b7;</italic> = 100, <italic>A</italic> = 75), low frequency (<italic>f</italic><sub><italic>c</italic></sub> = 0.25, <italic>f</italic><sub><italic>s</italic></sub> = 0.5, <italic>f</italic><sub><italic>s</italic></sub><italic>t</italic> = 0.5), high frequency (<italic>f</italic><sub><italic>c</italic></sub> = 0.75, <italic>f</italic><sub><italic>s</italic></sub> = 1.5, <italic>f</italic><sub><italic>st</italic></sub> = 1.5)</p></fn><fn id="t001fn004"><p>Testing 3: medium intensity (<italic>&#x003b7;</italic> = 50, <italic>A</italic> = 25), medium frequency (<italic>f</italic><sub><italic>c</italic></sub> = 0.5, <italic>f</italic><sub><italic>s</italic></sub> = 1, <italic>f</italic><sub><italic>st</italic></sub> = 1)</p></fn><fn id="t001fn005"><p>Testing 4: medium intensity (<italic>&#x003b7;</italic> = 50, <italic>A</italic> = 25), medium frequency (<italic>f</italic><sub><italic>c</italic></sub> = 0.5, <italic>f</italic><sub><italic>s</italic></sub> = 1, <italic>f</italic><sub><italic>st</italic></sub> = 1)</p></fn><fn id="t001fn006"><p>Testing 5: low intensity (<italic>&#x003b7;</italic> = 10, <italic>A</italic> = 1), medium intensity (<italic>&#x003b7;</italic> = 50, <italic>A</italic> = 1), high intensity (<italic>&#x003b7;</italic> = 100, <italic>A</italic> = 1), low frequency (<italic>f</italic><sub><italic>gds</italic></sub> = 0.5), medium frequency (<italic>f</italic><sub><italic>gds</italic></sub> = 1.5), high frequency (<italic>f</italic><sub><italic>gds</italic></sub> = 2)</p></fn></table-wrap-foot></table-wrap></sec><sec id="sec014"><title>Tuning the shape parameter (<italic>&#x003b1;</italic>) of prior distribution</title><p>We investigated the choice of parameter value that yielded the most accurate firing rate estimates measured by MISE metric. The tuned parameter (<italic>&#x003b1;</italic><sub><italic>t</italic></sub>) obtained from the tuning phase was then used as parameter value for our proposed method during testing phase. Spike trains used during tuning phase were stochastically generated from two models (IG and IIG) and three different underlying rate functions (chirp, sine, sawtooth) as described in previous section. We performed firing rate estimation over tuning dataset using parameter <italic>&#x003b1;</italic> varying from 1 to 10 with an increment of 0.5. This estimation was carried out while keeping parameter <italic>&#x003b2;</italic> fixed to <italic>n</italic><sup>4/5</sup>, where <italic>n</italic> represents total number of spikes within observed duration.</p><p>The performance of estimation was quantified in term of MISE, mean of integrated squared error between the underlying and estimated firing rates over the observed duration (2s). From 100 repetitions and 19 variation of parameter values (<italic>&#x003b1;</italic> = {1, 1.5, 2, &#x022ef;, 10}), we computed the MISE values along with their 95% confidence intervals from these 6 scenarios (2 models and 3 rate functions). The MISE values and their confidence intervals for IG and IIG models are shown in <xref ref-type="fig" rid="pone.0206794.g003">Fig 3a and 3b</xref>. In IG model, <italic>&#x003b1;</italic> values that resulted in smallest MISE for chirp, sine and sawtooth rate functions are 4, 3 and 6, respectively. In IIG model, <italic>&#x003b1;</italic> values associated with the smallest MISE for chirp, sine and sawtooth rate functions are 4.5, 3 and 5.5, respectively. We tuned parameter <italic>&#x003b1;</italic> by computing the average MISE values across 6 scenarios. The value of <italic>&#x003b1;</italic> that corresponds to the smallest average MISE is referred to as the tuned parameter (<italic>&#x003b1;</italic><sub><italic>t</italic></sub>). According to the results as shown in <xref ref-type="fig" rid="pone.0206794.g003">Fig 3c</xref>, we set <italic>&#x003b1;</italic><sub><italic>t</italic></sub> = 4 and used this value during the testing phase.</p><fig id="pone.0206794.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g003</object-id><label>Fig 3</label><caption><title>MISE comparison under different values of prior parameter (<italic>&#x003b1;</italic>).</title><p>(a) MISE values (star marks) and their 95% confidence intervals (vertical bars) for IG model. (b) MISE values (star marks) and their 95% confidence intervals (vertical bars) for IIG model. (c) Average MISE values across 2 models and 3 rate functions. We set <italic>&#x003b1;</italic><sub><italic>t</italic></sub> = 4 as it yields the smallest average MISE.</p></caption><graphic xlink:href="pone.0206794.g003"/></fig></sec><sec id="sec015"><title>Comparison with established methods</title><p>We evaluated and compared the performance of the proposed method (BAKS) with established methods which include optimized kernel smoother (OKS) [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>], variable kernel smoother (VKS) [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>], local polynomial fit (Locfit) [<xref rid="pone.0206794.ref013" ref-type="bibr">13</xref>] and Bayesian adaptive regression splines (BARS) [<xref rid="pone.0206794.ref014" ref-type="bibr">14</xref>]. The performances were quantified using MISE as expressed in <xref ref-type="disp-formula" rid="pone.0206794.e018">Eq (16)</xref>. We did not include the the histogram (PSTH) method in the comparison as this cannot produce a smooth estimate under single-trial case. Shimazaki and Shinomoto demonstrated that even if the number of trials is increased, the performance of PSTH is far outperformed by OKS, VKS, Locfit, and BARS [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>].</p><p>The two kernel smoothing methods used in the presented work, OKS and VKS, were developed by Shimazaki and Shinomoto [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>]. In OKS, the bandwidth is fixed for the whole duration and automatically selected based on global MISE minimization principle. Unlike OKS, VKS employs a variable bandwidth and this bandwidth is automatically determined by minimizing local MISE function. Thus, both OKS and VKS do not require manual user intervention in selecting optimal bandwidth parameter. The Matlab codes for OKS and VKS can be obtained from the author&#x02019;s website (<ext-link ext-link-type="uri" xlink:href="http://www.neuralengine.org/res/kernel.html">http://www.neuralengine.org/res/kernel.html</ext-link>).</p><p>Locfit is part of Chronux analysis software that at the time of this study can be downloaded from <ext-link ext-link-type="uri" xlink:href="http://chronux.org/">http://chronux.org/</ext-link>. This method estimates the firing rate by maximizing local log-likelihood where the log-density function is approximated by a local polynomial. Locfit has some parameters such as degree of polynomial, weight function, and bandwidth. However, it is the bandwidth that is considered as the most crucial parameter affecting the accuracy of estimation [<xref rid="pone.0206794.ref013" ref-type="bibr">13</xref>]. We used nearest neighbor bandwidth so that the local neighborhood always contains sufficient data (spikes). This can reduce data sparsity problem that may arise in real neural data. The nearest neighbor bandwidth parameter was determined by a tuning process similar to that of BAKS, while the parameter of degree of polynomial and weight function were set to the default values which are two and tricube (&#x02018;tcub&#x02019;), respectively. We performed MISE comparison from three underlying rate processes (chirp, sine, and sawtooth) for nearest neighbor bandwidth between 0.2 to 0.8 with increment 0.1. We set the bandwidth parameter value to 0.4 since the average MISE associated with this value was the smallest among others. The value 0.4 means that Locfit uses 40% of the total data in each estimation point.</p><p>BARS estimates the firing rate by using a cubic spline basis function with free parameters on the number and location of knots [<xref rid="pone.0206794.ref014" ref-type="bibr">14</xref>]. The optimal knot configuration is determined by a fully Bayesian approach with a reversible-jump Markov chain Monte Carlo (MCMC) engine and locality heuristic procedure. BARS takes spike counts within bin intervals (histogram) centered on estimation times of interest. In our study, we used Matlab implementation of BARS which is available at <ext-link ext-link-type="uri" xlink:href="http://lib.stat.cmu.edu/~kass/bars/bars.html">http://lib.stat.cmu.edu/~kass/bars/bars.html</ext-link>. We used a Poisson prior distribution on the number of knots and set the sample iterations to 5000 and burn-in samples to 500. We used spike counts within 10ms bin intervals as the input and mean of fitted function as the output estimate.</p><p>We performed 100 repetitions of single-trial firing rate estimation using dataset testing 1. MISE comparison of all the methods for three underlying rate functions and two models is plotted as a boxplot (<xref ref-type="fig" rid="pone.0206794.g004">Fig 4</xref>). In all 6 scenarios, the medians, means, and interquartile ranges of MISE computed by BAKS are smallest among other competing methods. As shown in <xref ref-type="fig" rid="pone.0206794.g004">Fig 4a</xref> for IG model and <xref ref-type="fig" rid="pone.0206794.g004">Fig 4b</xref> for IIG model, BAKS (blue boxplot) yields significantly lower MISE compared to the other methods. This demonstrates the effectiveness of BAKS which features an adaptive bandwidth in estimating the underlying rate from single trial spike train.</p><fig id="pone.0206794.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g004</object-id><label>Fig 4</label><caption><title>MISE comparison of BAKS with other methods.</title><p>(a) MISE comparison for three rate functions (chirp, sine, and sawtooth) from IG model. (b) MISE comparison for three rate functions (chirp, sine, and sawtooth) from IIG model. In each boxplot, black lines show the medians; black circles indicate the means; colored solid boxes represent interquartile ranges; whiskers extend 1.5&#x000d7; from upper and lower quartiles; gray crosses represent outliers.</p></caption><graphic xlink:href="pone.0206794.g004"/></fig><p>Examples of the underlying rate functions and the estimated firing rates from all methods are given in <xref ref-type="fig" rid="pone.0206794.g005">Fig 5</xref>. In this figure, BAKS (blue line) shows qualitatively good firing rate estimates across 6 scenarios.</p><fig id="pone.0206794.g005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g005</object-id><label>Fig 5</label><caption><title>Comparison of firing rate estimates across all methods.</title><p>(a)-(c) Firing rate estimates from IG model with chirp, sine, and sawtooth rate functions, respectively. (d)-(f) Firing rate estimates from IIG model with chirp, sine, and sawtooth rate functions, respectively. Black lines with gray-shaded regions indicate the underlying rate functions. Black raster in the bottom of each plot represents the spike train generated from the associated model and underlying rate function.</p></caption><graphic xlink:href="pone.0206794.g005"/></fig></sec><sec id="sec016"><title>Comparison under different values of intensity and frequency</title><p>We studied the effect of different intensity and frequency values of the underlying rate functions to the performance of BAKS. In real neural data, the number of spikes (intensity) and the temporal fluctuation of spikes (frequency) may change slowly and rapidly. Therefore, we varied the values of intensity and frequency parameters as described in <xref rid="pone.0206794.t001" ref-type="table">Table 1</xref> (Testing 2). Using dataset testing 2, we performed 100 repetitions of single trial firing rate estimation from all methods. The statistical summaries of MISE comparison across all methods for the cases of IG and IIG models are shown in <xref ref-type="fig" rid="pone.0206794.g006">Fig 6</xref> and <xref ref-type="supplementary-material" rid="pone.0206794.s001">S1 Fig</xref>, respectively. From a total of 24 cases (2 models, 3 rate functions and 4 variations of intensity and frequency), BAKS outperforms other competing methods in 16 cases (66.67%) as shown in <xref ref-type="fig" rid="pone.0206794.g006">Fig 6</xref> and <xref ref-type="supplementary-material" rid="pone.0206794.s001">S1 Fig</xref>. On average, BAKS performs better than other methods. Large performance improvements by BAKS are achieved in the cases of chirp and sawtooth rate functions with high frequency. This suggests that BAKS is more effective at estimating a continuous or discontinuous rate function with rapidly changing spike dynamic. On the other hand, BAKS exhibits poor performance in the case of sine rate function with low frequency. This suggests that BAKS is not suitable for estimating a continuous rate function with slowly changing spike dynamic.</p><fig id="pone.0206794.g006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g006</object-id><label>Fig 6</label><caption><title>MISE comparison under different values of intensity and frequency for IG model.</title><p>(a) MISE comparison for the case of low intensity. (b) MISE comparison for the case of high intensity. (c) MISE comparison for the case of low frequency. (d) MISE comparison for the case of high frequency. In each boxplot, black lines show the medians; black circles indicate the means; colored solid boxes represent interquartile ranges; whiskers extend 1.5&#x000d7; from upper and lower quartiles; gray crosses represent outliers.</p></caption><graphic xlink:href="pone.0206794.g006"/></fig></sec><sec id="sec017"><title>Comparison under different values of shape parameter (<italic>&#x003b3;</italic>)</title><p>The flexibility of BAKS when the assumption of ISI shape deviates from that of used during the tuning phase is addressed in this section. Using dataset testing 3 (<italic>&#x003b3;</italic> = {1, 2, &#x022ef; 10}), we performed 100 repetitions of single trial firing rate estimation. From a total of 60 cases (2 models, 3 rate functions and 10 variations of <italic>&#x003b3;</italic> values), BAKS shows superior performance over the other methods in 55 cases (91.67%) as shown in <xref ref-type="fig" rid="pone.0206794.g007">Fig 7</xref>. In the remaining cases, BAKS results in comparable performance to OKS and VKS which perform good under inhomogeneous Poisson model (corresponds to <italic>&#x003b3;</italic> = 1). We also investigated the performance of BAKS when <italic>&#x003b3;</italic> &#x0003c; 1 which corresponds to bursting activity. We performed firing rate estimations using synthetic data generated with <italic>&#x003b3;</italic> = {0.25, 0.5, 0.75}. The results show the superiority of BAKS to other methods in all 18 scenarios (2 models, 3 rate functions, 3 variations of <italic>&#x003b3;</italic> values) as depicted in <xref ref-type="supplementary-material" rid="pone.0206794.s002">S2 Fig</xref>. These results demonstrate the flexibility of BAKS in estimating the underlying rates under various ISI characteristics of spike train models.</p><fig id="pone.0206794.g007" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g007</object-id><label>Fig 7</label><caption><title>MISE comparison under various values of shape parameter (<italic>&#x003b3;</italic>).</title><p>(a)-(c) MISE comparison for chirp, sine, and sawtooth rate functions, respectively, from IG model. (d)-(f) MISE comparison for chirp, sine, and sawtooth rate functions, respectively, from IIG model. Vertical bars represent the 95% confidence intervals.</p></caption><graphic xlink:href="pone.0206794.g007"/></fig></sec><sec id="sec018"><title>Comparison under different numbers of trials</title><p>In offline analyses, the firing rate is typically estimated using spike trains from many similar trials aggregated into a single, compact, spike train. To study the effect of increasing number of trials, we assessed the performance of BAKS under different numbers of trials (<italic>tr</italic> = {5, 10, 20, 30}) using dataset testing 4. We performed firing rate estimation using all methods, each for 100 times. MISE comparison for these multi-trial cases is depicted in <xref ref-type="fig" rid="pone.0206794.g008">Fig 8</xref>. The increasing number of trials improves the performance of all methods as indicated by the decreasing MISE values. However, with the increasing number of trials, the rate of improvement declines as the MISE values reach their convergences. BAKS on average performs better than other methods except BARS. Compared to Locfit, BAKS always shows significantly better performance in all multi-trial cases. In comparison to OKS and VKS, BAKS shows worse performance only in the cases of sine rate functions for <italic>tr</italic> &#x02265; 10 (<xref ref-type="fig" rid="pone.0206794.g008">Fig 8b and 8e</xref>). However, compared to BARS, BAKS shows inferior performance in most multi-trial cases with the exception of sawtooth rate cases (<italic>tr</italic> &#x0003c; 30) as can be seen in <xref ref-type="fig" rid="pone.0206794.g008">Fig 8c and 8f</xref>. These overall results suggest that BAKS perform well on multi-trial cases with moderate number of spikes. Nevertheless, when it comes to multi-trial cases with large number of spikes, BARS always performs the best among others.</p><fig id="pone.0206794.g008" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g008</object-id><label>Fig 8</label><caption><title>MISE comparison under different numbers of trials.</title><p>(a)-(c) MISE comparison for chirp, sine and sawtooth rate functions, respectively, for IG model. (d)-(f) MISE comparison for chirp, sine and sawtooth rate functions, respectively, for IG model. Vertical bars (not clearly seen for <italic>tr</italic> &#x02265; 5) represent the 95% confidence intervals.</p></caption><graphic xlink:href="pone.0206794.g008"/></fig></sec><sec id="sec019"><title>Comparison under different underlying rate functions</title><p>In practice, the true underlying rate function that generates the spiking data is unknown. There is infinite spaces of rate function that underlie the spiking generation. During the tuning phase, we used 3 underlying rate functions (chirp, sine and sawtooth) to tune the parameter of BAKS that minimizes the MISE. Next, we studied the impact of different underlying rate function along with its intensity and frequency variations to the performance of BAKS. We performed 100 repetitions of firing rate estimation using dataset testing 5 which corresponds to single trial spike trains generated from Gaussian-damped sinusoidal rate function as in <xref ref-type="disp-formula" rid="pone.0206794.e030">Eq (26)</xref>. This rate function is chosen as another representation of continuous rate functions with changing spike dynamic. The performance comparisons across all methods using this dataset for IG and IIG models are plotted in <xref ref-type="fig" rid="pone.0206794.g009">Fig 9</xref> and <xref ref-type="supplementary-material" rid="pone.0206794.s003">S3 Fig</xref>, respectively. From a total of 12 cases, BAKS outperforms all other methods in 8 cases (66.67%).</p><fig id="pone.0206794.g009" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g009</object-id><label>Fig 9</label><caption><title>MISE comparison under different underlying rate functions for IG model.</title><p>In each boxplot, black lines show the medians; black circles indicate the means; colored solid boxes represent interquartile ranges; whiskers extend 1.5&#x000d7; from upper and lower quartiles; gray crosses represent outliers.</p></caption><graphic xlink:href="pone.0206794.g009"/></fig><p>We also evaluated the performance of BAKS using synthetic data generated from square rate function which represents discontinuous rate functions with changing spike dynamic. The choice of square rate function is inspired by other studies [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0206794.ref042" ref-type="bibr">42</xref>]. We performed firing rate estimations using synthetic data generated from IG model with square rate function. We varied the values of frequency and intensity of the square rate function. From a total of 5 cases, BAKS always shows superior performance than other methods as depicted in <xref ref-type="supplementary-material" rid="pone.0206794.s005">S5 Fig</xref>. These overall results demonstrate the reliability of BAKS even when the underlying rate functions depart from that of used during the tuning phase.</p><p>Examples of estimated firing rates from all methods for IG and IIG models with Gaussian-damped sinusoidal rate function are shown in <xref ref-type="fig" rid="pone.0206794.g010">Fig 10</xref> and <xref ref-type="supplementary-material" rid="pone.0206794.s004">S4 Fig</xref>, respectively, whereas examples of estimated firing rates for IG model with square rate function are depicted in <xref ref-type="supplementary-material" rid="pone.0206794.s006">S6 Fig</xref>.</p><fig id="pone.0206794.g010" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g010</object-id><label>Fig 10</label><caption><title>Firing rate estimate comparison for IG model with Gaussian-damped sinusoidal rate function.</title><p>(a)-(c) Firing rate estimates for the cases of low, medium and high frequency, respectively. (d)-(f) Firing rate estimates for the cases of low, medium and high intensity, respectively. Black lines with gray-shaded regions indicate the underlying rate functions. Black raster in the bottom of each plot represents a spike train generated from the associated underlying rate function.</p></caption><graphic xlink:href="pone.0206794.g010"/></fig></sec><sec id="sec020"><title>Comparison of computational complexity</title><p>Computational complexity affects how fast the computation of each method is completed. A computationally fast method allows significant reduction in data analysis process when working with large number of iterations. Furthermore, fast computation of firing rate is necessary in online spike-based BMI experiments to generate real-time feedback to the subject. This section describes and compares the computational complexity of each method.</p><p>Kernel smoothing technique has the advantage of being relatively simple and computationally fast. This is especially the case when the bandwidth is fixed throughout the observation interval such as in OKS. OKS uses binned spike counts within certain bin intervals (centered at estimation times) and kernel function with fixed bandwidth to estimate firing rate. The firing rate computation is performed by convolving the binned spike counts with the kernel function. OKS incorporates a Fast Fourier Transform (FFT) for computing the convolution to further reduce the computation time. In OKS, the bandwidth is selected by minimizing mean integrated squared error (MISE) function over the whole duration [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>]. An extension to OKS is VKS, which incorporates a variable bandwidth. This variable bandwidth is computed by minimizing local MISE which requires large number of iterations with varying local interval. This iterative process makes VKS significantly more complex than OKS. Unlike OKS and VKS, Locfit uses a polynomial to fit log-rate function by maximizing a local likelihood function. Locfit has relatively low complexity because it uses a fixed bandwidth selected in manual fashion; it does not employ an automatic selection of bandwidth. In this study, the bandwidth (in term of nearest neighbor) of Locfit was set to 0.4, meaning that the computation involves 40% of the total data within the whole duration.</p><p>Our proposed method, BAKS, even though incorporating an automatic selection of adaptive bandwidth, it still offers relatively low computational complexity. This advantage arises from the simple kernel smoothing technique with proper choice of prior distribution and kernel function which leads to closed-form expression of posterior bandwidth. This in turn simplifies the computation process of determining the adaptive bandwidth. This type of convenient closed-form expression cannot be obtained in the case of BARS; thus, a numerical approximation technique is required. BARS uses an iterative procedure involving computationally expensive Markov chain Monte Carlo (MCMC) technique and Bayes information criterion (BIC) to find the optimal smoothing parameters (i.e. number and location of knots). This process takes relatively long computation to yield &#x0201c;converged&#x0201d; results.</p><p>The computational complexity among these methods can be indicated by the time required for completing the firing rate estimation in computer simulation (i.e. computational runtime). Since this runtime comparison is impacted by the code implementation of each method, this should be viewed as an estimation of the real computational complexity of each method. The code for BAKS can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://github.com/nurahmadi/BAKS">https://github.com/nurahmadi/BAKS</ext-link>. The OKS and VKS codes can be downloaded from <ext-link ext-link-type="uri" xlink:href="http://www.neuralengine.org/res/kernel.html">http://www.neuralengine.org/res/kernel.html</ext-link>. The Locfit code is available through <ext-link ext-link-type="uri" xlink:href="http://chronux.org/">http://chronux.org/</ext-link>; while the BARS code is available through <ext-link ext-link-type="uri" xlink:href="http://lib.stat.cmu.edu/~kass/bars/bars.html">http://lib.stat.cmu.edu/~kass/bars/bars.html</ext-link>. All the program codes were written and run in Matlab R2016b software (The Mathworks Inc., Natick, MA) installed on Windows 7 64-bit PC with 8 Intel cores i7-4790 @3.6 GHz and RAM 16 GB. This comparison uses 100 repetitions of single trial synthetic spike train data (2s duration) generated by IG model with chirp rate function.</p><p>As shown in <xref rid="pone.0206794.t002" ref-type="table">Table 2</xref>, Locfit and OKS are the two fastest methods; both methods complete the computation within the order of few milliseconds. VKS requires around 2 order of magnitude longer time than both Locfit and OKS, whereas BARS requires the longest time (in the order of seconds). In BARS parameter setting, we set burn-in iterations to 500 and sample iterations to 5000. The BARS runtime can be reduced by setting the burn-in and sample iterations to smaller values. However, this may result in decreasing accuracy as the trade-off. Therefore, these parameters should be carefully set to find good trade-off between accuracy and runtime. Wallstrom et al. suggested that the default values for burn-in and sample iterations are 500 and 2000, respectively [<xref rid="pone.0206794.ref043" ref-type="bibr">43</xref>].</p><table-wrap id="pone.0206794.t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.t002</object-id><label>Table 2</label><caption><title>Average runtime comparison of BAKS with other methods (in second).</title></caption><alternatives><graphic id="pone.0206794.t002g" xlink:href="pone.0206794.t002"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Single trial case</th><th align="center" rowspan="1" colspan="1">BAKS</th><th align="center" rowspan="1" colspan="1">OKS</th><th align="center" rowspan="1" colspan="1">VKS</th><th align="center" rowspan="1" colspan="1">Locfit</th><th align="center" rowspan="1" colspan="1">BARS</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Low intensity</td><td align="char" char="." rowspan="1" colspan="1">0.0016</td><td align="char" char="." rowspan="1" colspan="1">0.0017</td><td align="char" char="." rowspan="1" colspan="1">0.2340</td><td align="char" char="." rowspan="1" colspan="1">0.0012</td><td align="char" char="." rowspan="1" colspan="1">4.8438</td></tr><tr><td align="left" rowspan="1" colspan="1">Medium intensity</td><td align="char" char="." rowspan="1" colspan="1">0.0062</td><td align="char" char="." rowspan="1" colspan="1">0.0018</td><td align="char" char="." rowspan="1" colspan="1">0.3306</td><td align="char" char="." rowspan="1" colspan="1">0.0012</td><td align="char" char="." rowspan="1" colspan="1">4.6563</td></tr><tr><td align="left" rowspan="1" colspan="1">High intentisy</td><td align="char" char="." rowspan="1" colspan="1">0.0126</td><td align="char" char="." rowspan="1" colspan="1">0.0017</td><td align="char" char="." rowspan="1" colspan="1">0.3306</td><td align="char" char="." rowspan="1" colspan="1">0.0014</td><td align="char" char="." rowspan="1" colspan="1">4.5527</td></tr></tbody></table></alternatives></table-wrap><p>The runtime performance of BAKS is significantly better than that of both VKS and BARS, but worse than that of Locfit and OKS. <xref rid="pone.0206794.t002" ref-type="table">Table 2</xref> shows that BAKS runtime is influenced by the intensity of the underlying rate function (i.e. number of spikes), whereas other methods&#x02019; runtime is relatively consistent. This is because other methods incorporate binning procedure for the spiking data prior to their core computation. This makes the number of input data fed to the core computation always uniform regardless of the number spikes within the observation interval. This is not the case for BAKS. Our current BAKS code is a straightforward implementation of the formula described in section. In this study, we have not considered the efficient implementation of BAKS. It is important to note, as neurons have a property of refractory period, the number of spikes within observation interval is limited. This guarantees that under single trial cases, even with current implementation code, the runtime performance of BAKS will only decrease up to certain bound.</p></sec><sec id="sec021"><title>Application to real neural data</title><p>In this section, we apply our proposed method for estimating the neuronal firing rate from real data obtained from two public neural databases, which are database for reaching experiments and models (DREAM) and neural signal archive (NSA). The DREAM and NSA databases can be accessed from <ext-link ext-link-type="uri" xlink:href="http://crcns.org/">http://crcns.org/</ext-link> and <ext-link ext-link-type="uri" xlink:href="http://www.neuralsignal.org/">http://www.neuralsignal.org/</ext-link>, respectively. In the DREAM database, we used Flint_2012 dataset that were recorded from primary motor cortex area (M1) of monkey&#x02019;s brain when the subject was performing center-out reaching task. Single unit spikes were obtained by using thresholding and offline sorting technique. More detailed information on the recording tools and experimental setup can be found in [<xref rid="pone.0206794.ref044" ref-type="bibr">44</xref>]. In the NSA database, we used nsa2004.1 dataset recorded from visual cortex (MT/V5) area when random dot stimuli was being presented to a monkey [<xref rid="pone.0206794.ref045" ref-type="bibr">45</xref>]. The detailed electrophysiological recording is given in [<xref rid="pone.0206794.ref046" ref-type="bibr">46</xref>].</p><p>Unlike the synthetic data in which the true underlying rate function is known (i.e. ground truth), in the case of real neural data, we do not have access to the ground truth. Therefore, the ground truth underlying rate in real neural data was estimated by averaging and smoothing the spike counts across many similar trials. This procedure is similar to the work of Cunningham et al. [<xref rid="pone.0206794.ref027" ref-type="bibr">27</xref>]. We assume that neurons respond similarly upon given same tasks/stimuli, e.g. moving hand to the same target direction or observing the same visual stimuli. These similar trials were selected such that each trial contains greater or equal to 50 spikes/s within observation interval (1s for the Flint_2012 dataset, 2s for the nsa2004.1 dataset). This limited number of spikes was taken on the assumption that neurons likely fire more spikes when performing tasks or receiving stimuli. In this work, we considered only neurons that satisfy this criterion in more than 30 trials in order to obtain sufficiently small error as we observed in multi-trial synthetic data (<xref ref-type="fig" rid="pone.0206794.g008">Fig 8</xref>). To this end, we obtained 47 (4) subdatasets with total trial of 1791 (134) for the Flint_2012 (nsa2004.1) dataset. In the Flint_2012 dataset, we aligned the spiking responses over same-direction reaching tasks to the time when the monkey started the actual hand movement (indicated by cursor movement). To make the observation interval the same from inherently different trial duration for each trial, we used on average 200ms before and 800ms after the movement (total duration of 1s). In the nsa2004.1 dataset, the spiking responses were aligned to the time when random moving dot stimuli was firstly presented to the monkey. In this type of experiment, the trial duration was fixed to 2s.</p><p>To estimate the ground truth underlying rate, we employed trial averaging and smoothing processes. Trial averaging process was done by superimposing the spike trains from single neuron and averaging the spike counts within predefined bin interval (10ms) across all similar trials. This trial averaging process still results in a coarse or jagged estimate. Therefore, to get a smooth estimate of the underlying rate, a smoothing process is required. The smoothing process was performed by using BARS. BARS was selected because, based on the synthetic data, it demonstrates the most superior performance in multi-trial cases with a large number of trials (see <xref ref-type="fig" rid="pone.0206794.g008">Fig 8</xref>). In these multi-trial cases where there exists spike train variability across trials, we increased the sample iteration to 30,000 and burn-in samples to 5,000 to ensure the convergence of BARS results. One of the advantages of BARS is that it provides the output estimate along with its credible interval. In this work, we used 95% credible interval. When computing MISE, we took into account this uncertainty. Before squaring and integrating across observation interval, we normalized the error between ground truth underlying rate obtained from multi-trials (act as a reference) and single-trial estimated firing rate from method of interest by dividing it with upper or lower credible interval. The upper (lower) interval was used when the estimated firing rate is larger (smaller) than the reference. By doing so, we impose more (less) weight when the credible interval is smaller (larger) to adjust the uncertainty brought by the BARS estimation. We call this normalized MISE as a weighted MISE (WMISE) and formulate it as follows,
<disp-formula id="pone.0206794.e031"><alternatives><graphic xlink:href="pone.0206794.e031.jpg" id="pone.0206794.e031g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M31"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mtext>WMISE</mml:mtext><mml:mo>&#x02248;</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mi>t</mml:mi><mml:mo>&#x02211;</mml:mo><mml:mi mathvariant="double-struck">E</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mo>&#x003bb;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mo>&#x003bb;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(27)</label></disp-formula>
where <italic>C</italic>(<italic>t</italic>) is set to the upper credible interval when <inline-formula id="pone.0206794.e032"><alternatives><graphic xlink:href="pone.0206794.e032.jpg" id="pone.0206794.e032g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M32"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003bb;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02265;</mml:mo><mml:mo>&#x003bb;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula> and the lower credible interval when <inline-formula id="pone.0206794.e033"><alternatives><graphic xlink:href="pone.0206794.e033.jpg" id="pone.0206794.e033g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M33"><mml:mrow><mml:mover accent="true"><mml:mo>&#x003bb;</mml:mo><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003c;</mml:mo><mml:mo>&#x003bb;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></inline-formula>. These upper and lower credible intervals calculated by BARS are not uniform.</p><p>We examined the performance comparison across methods under WMISE function. Based on WMISE function, we derived three different metrics for performing the comparison. First, we investigated the WMISE performance across total number of trials. Based on 1791 single-trial firing rate estimation from 47 subdatasets in the Flint_2012 dataset, BAKS produces the smallest WMISE mean (10.34) and median (6.85) as shown in <xref ref-type="fig" rid="pone.0206794.g011">Fig 11a</xref>. BAKS also produces the best performance (mean = 19.77 and median = 13.56) in the case of nsa2004.1 dataset with a total of 134 trials from 4 subdatasets (<xref ref-type="fig" rid="pone.0206794.g011">Fig 11d</xref>). Second, we measured the number of times (in %) one method outperforms all the other methods. In both Flint_2012 and nsa2004.1 datasets, BAKS more frequently (41.99% and 42.54% respectively) outperforms the other methods as depicted in <xref ref-type="fig" rid="pone.0206794.g011">Fig 11b and 11e</xref>. In these cases, OKS comes as the second best method with 30.65% and 17.16%. Third, we assessed the improvement (WMISE decrease in %) per trial made by BAKS against other methods. <xref ref-type="fig" rid="pone.0206794.g011">Fig 11c and 11f</xref> describe the statistical summary of BAKS performance compared to competing methods for the Flint_2012 and nsa2004.1 datasets, respectively. A positive (negative) value means that the BAKS method outperforms (is outperformed by) the others. As described in <xref ref-type="fig" rid="pone.0206794.g011">Fig 11c</xref>, the performance of BAKS is better than other methods except OKS (see magenta boxplot; mean = -2.58% and median = 3.20%). This seems to contradict the results when using the first and second metrics, in which BAKS outperforms all other methods. To investigate this contradictory, we analyzed the performance of BAKS against OKS across 1791 trials. It turns out that although BAKS more frequently outperforms OKS, in a few trials, the magnitude of improvement made by OKS against BAKS is significantly large. However, in the nsa2004.1 dataset, BAKS is able to outperform all other methods (<xref ref-type="fig" rid="pone.0206794.g011">Fig 11f</xref>). These results are in agreement with the two other metrics and the results obtained from the synthetic datasets. As a summary, BAKS on average performs good compared to other methods in both real and synthetic datasets.</p><fig id="pone.0206794.g011" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g011</object-id><label>Fig 11</label><caption><title>WMISE comparison across all firing rate estimation methods using real neural data.</title><p>(a) Average WMISE comparison across all trials in Flint_2012 dataset. (b) Number of times (in %) BAKS outperforms other methods in Flint_2012 datasets. (c) Single trial performance improvement made by BAKS over competing methods in Flint_2012 datasets. (d)-(f) Similar to that of (a)-(c) but with nsa2004.1 dataset. In each boxplot, black lines show the medians; black circles indicate the means; colored solid boxes represent interquartile ranges; whiskers extend 1.5&#x000d7; from upper and lower quartiles; gray crosses represent outliers.</p></caption><graphic xlink:href="pone.0206794.g011"/></fig><p>Some examples of single-trial firing rate estimations from all methods for both datasets are shown in <xref ref-type="fig" rid="pone.0206794.g012">Fig 12</xref>. <xref ref-type="fig" rid="pone.0206794.g012">Fig 12a and 12b</xref> show the firing rate estimates from &#x02018;N184&#x02019; and &#x02018;E164&#x02019; cases in the Flint_2012 dataset. <xref ref-type="fig" rid="pone.0206794.g012">Fig 12c and 12d</xref> show the firing rate estimates from &#x02018;j032_25.6&#x02019; and &#x02018;j032_51.2&#x02019; cases in the nsa2004.1 dataset.</p><fig id="pone.0206794.g012" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.g012</object-id><label>Fig 12</label><caption><title>Firing rate estimates comparison for real neural data.</title><p>(a) Firing rate estimates from &#x02018;N184&#x02019; of Flint_2012 dataset (b) Firing rate estimates from &#x02018;E164&#x02019; of Flint_2012 dataset (c) Firing rate estimates from &#x02018;j032_25.6&#x02019; of nsa2004.1 dataset. (d) Firing rate estimates from &#x02018;j032_51.2&#x02019; of nsa2004.1 dataset. Black lines and gray-shaded regions indicate the &#x02018;true&#x02019; underlying rates and their 95% credible intervals, respectively. Black raster in the bottom of each plot represents a single spike train generated from the associated underlying rate.</p></caption><graphic xlink:href="pone.0206794.g012"/></fig></sec></sec><sec sec-type="conclusions" id="sec022"><title>Discussion</title><p>In this study, we propose a new method, referred to as BAKS, for estimating single-trial neuronal firing rate. BAKS employs a kernel smoothing technique with adaptive bandwidth. This differs from other kernel-based firing rate estimation methods in that its bandwidth parameter is adaptively determined by an empirical Bayesian approach. BAKS has been developed with the motivation to estimate firing rate from single spike train generated from underlying rate function that dynamically changes over observed duration (i.e. non-stationary).</p><p>We tune the parameter of BAKS using synthetic spike train data stochastically sampled from 3 rate functions (as representation of non-stationary underlying processes). These rate functions are chirp, sine, and sawtooth expressed in Eqs <xref ref-type="disp-formula" rid="pone.0206794.e027">(23)</xref>, <xref ref-type="disp-formula" rid="pone.0206794.e028">(24)</xref> and <xref ref-type="disp-formula" rid="pone.0206794.e029">(25)</xref>, respectively. Using this tuned parameter, we evaluate the performance of BAKS using 5 synthetic datasets. These datasets represent various setting and combination of underlying rate functions along with their intensity and frequency variations, ISI shape (parameter <italic>&#x003b3;</italic>), and number of trials. The performance comparison is measured under MISE function. By extensive simulations, we demonstrate good performance of BAKS compared to two other kernel-based methods (OKS and VKS) and two generalized nonparametric regression methods (Locfit and BARS). On average, BAKS outperforms the other methods in single-trial estimation (smallest MISE) across various settings. The adaptive bandwidth featured in the BAKS can adjust the different spike densities within the observation interval. The results suggest that BAKS is suitable to be used for single-trial analysis of neural data. The flexibility of BAKS has also been tested by using spike train generated from same models with different values of shape parameter (<italic>&#x003b3;</italic> = {0.25, 0.5, 0.75, 1, 2, 3, &#x022ef; 10}). These various values represent diverse neuronal activities which include bursting, irregular, and regular spiking. Furthermore, BAKS is also evaluated using synthetic datasets generated from two other underlying rate functions, namely Gaussian-damped sinusoidal rate and square rate functions. Consistent results are obtained despite using these different characteristics of spike trains. BAKS does not assume specific distribution on the spike train, rather it uses appropriately chosen prior distribution on the bandwidth parameter. The prior distribution of the bandwidth is derived from Gamma prior distribution on the precision parameter (inverse of square bandwidth). The precision parameter describes how concentrated observed data are around the means of Gaussian kernel which are set to the spike times. Since these spike times (i.e. sum of ISI) are conveniently modeled with Gamma distribution [<xref rid="pone.0206794.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0206794.ref027" ref-type="bibr">27</xref>&#x02013;<xref rid="pone.0206794.ref030" ref-type="bibr">30</xref>], the precision parameter is also assumed to be Gamma distribution. This choice has been shown to yield good performance. On the other hand, all other competing methods (OKS, VKS, Locfit, and BARS) use a Poisson assumption [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>&#x02013;<xref rid="pone.0206794.ref014" ref-type="bibr">14</xref>], which is less likely for the case of single-trial spike train; neurons have certain properties (e.g. refractory and bursting) that cannot be described by the Poisson model [<xref rid="pone.0206794.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0206794.ref016" ref-type="bibr">16</xref>]. Numerous works have shown the inadequacy of the Poisson model and proposed other more biophysically plausible models (e.g. IG and IIG) [<xref rid="pone.0206794.ref006" ref-type="bibr">6</xref>, <xref rid="pone.0206794.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0206794.ref027" ref-type="bibr">27</xref>&#x02013;<xref rid="pone.0206794.ref030" ref-type="bibr">30</xref>, <xref rid="pone.0206794.ref036" ref-type="bibr">36</xref>]. The deviation from Poisson assumption under single-trial cases may lead OKS, VKS, Locfit and BARS to poor performance [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0206794.ref017" ref-type="bibr">17</xref>].</p><p>We also compare the performance of BAKS method under multi-trial cases to study the implication of increasing number of spikes within the same duration. Some topics of interest in neuroscience use multi-trial spike train to obtain the firing rate. The results show that all methods produce similar trend; the increasing number of trials up to a certain value (threshold) improves the performance. However, as the number of trial increases, the rate of improvement of each method and the threshold value differ from each other. BARS produces the most significant performance improvement with the increasing number of trials. This significant improvement of BARS is driven by two factors. First, BARS is built on the assumption that spike counts within the bin intervals follow a Poisson distribution. This assumption is suitable for multi-trial cases since superimposed spike train across trials approximate a Poison process [<xref rid="pone.0206794.ref012" ref-type="bibr">12</xref>, <xref rid="pone.0206794.ref016" ref-type="bibr">16</xref>]. Second, BARS employs a fully Bayesian approach and locality heuristic procedure to update prior distribution of parameter (knots configuration) [<xref rid="pone.0206794.ref014" ref-type="bibr">14</xref>]. With the increasing number of trials (i.e. number of spikes), BARS at the cost of high computational complexity can effectively find the optimal knots configuration regardless of the prior. Nevertheless, in comparison to OKS, VKS, and Locfit methods, BAKS still yields good performance. The overall results suggest that BAKS is good at estimating firing rate from a low to moderate number of spikes (represented by single or few trials) from non-stationary underlying rate functions. BAKS performs even significantly better in the cases of sawtooth and square rate functions which indicates its suitability for estimating firing rate from discontinuous underlying rate functions.</p><p>After validation using synthetic data, BAKS is also tested using real neural data recorded from motor and visual cortex of non-human primate (NHP). The motor neural data (Flint_2012) is associated with center-out reaching tasks, whereas the visual neural data (nsa2004.1) is associated with moving random-dot visual stimuli. Measuring the performance in real neural data is a challenging due to unknown underlying rate. Hence, the underlying rate is estimated by using multi-trial cases on the assumption that neurons respond similarly upon given same tasks/stimuli. This procedure is similar to Cunningham&#x02019;s work [<xref rid="pone.0206794.ref027" ref-type="bibr">27</xref>]. However, our procedure differs from [<xref rid="pone.0206794.ref027" ref-type="bibr">27</xref>] in that we use BARS instead of PSTH for smoothing process. In practice, neuronal response may considerably differ across similar trials. To minimize large variation in the spike trains, subsets from two datasets (Flint_2012 and nsa2004.1) are selected with constraints explained in previous section. BARS is chosen to obtain a smooth estimate of the ground truth underlying rate as it provides the smallest MISE in multi-trial cases of synthetic data. To account for the estimation uncertainty produced by BARS, weighted MISE (WMISE) is used for comparison. From a total of 6 cases (3 metrics and 2 real datasets), BAKS outperforms all other methods in 5 cases. The overall results show that, on average, BAKS yields good performance compared to all other competing methods. This is in good agreement with the results obtained from single-trial synthetic data, which further demonstrates the effectiveness of the proposed method in estimating single-trial neuronal firing rate.</p><p>In BAKS, the selection of prior parameter (<italic>&#x003b1;</italic>) value is crucial since it will impact the performance of the firing rate estimation. In this study, the value of <italic>&#x003b1;</italic> is tuned by minimizing MISE on synthetic dataset during training phase. This dataset is generated from three rate functions (chirp, sine, sawtooth) with medium intensity and frequency. During testing phase, we use datasets with various settings to evaluate the robustness of BAKS with this tuned parameter (<italic>&#x003b1;</italic><sub><italic>t</italic></sub> = 4). According to <xref ref-type="disp-formula" rid="pone.0206794.e013">Eq (13)</xref>, the mean of prior bandwidth is inversely proportional to the value of <italic>&#x003b1;</italic>. In the cases of low frequency rate functions with the same intensity as of during the tuning phase, the spike density tends to decrease, which in turn requires larger bandwidth. To adapt to this, the value of <italic>&#x003b1;</italic> that minimizes MISE tends to become smaller. Since we use a fixed <italic>&#x003b1;</italic><sub><italic>t</italic></sub>, this results in poor performance of BAKS. On the other hand, in the cases of high frequency, although there is performance degradation, BAKS still shows better performance compared to all other methods. This may be caused by relatively small performance degradation resulted from the use of <italic>&#x003b1;</italic><sub><italic>t</italic></sub> as opposed to larger value of <italic>&#x003b1;</italic> (for adapting to higher spike density). As can be seen in (<xref ref-type="fig" rid="pone.0206794.g003">Fig 3</xref>), the performance difference from the use of <italic>&#x003b1;</italic><sub><italic>t</italic></sub> = 4 to the right (larger value of <italic>&#x003b1;</italic>) is smaller than to the left (smaller value of <italic>&#x003b1;</italic>). In other cases related with different values of intensity (the frequency is kept same), the performance of BAKS is consistently better among other methods. The change of intensity (thus the associated bandwidth) can be partially compensated by the change in scale parameter (<italic>&#x003b2;</italic>) which is set to a function proportional to the number of spikes. This indicates that the performance of BAKS is less (more) sensitive to <italic>&#x003b1;</italic><sub><italic>t</italic></sub> value when there is low (high) variation of frequency (i.e. temporal fluctuation) of the underlying rate function.</p><p>In practice, the value of <italic>&#x003b1;</italic> parameter of BAKS can be tuned using synthetic datasets generated from spike train model whose parameters derived from statistical summary of real datasets of interest. By analyzing repeated trial spike trains on real neural datasets with the same tasks/stimuli, we can estimate important underlying parameters such as temporal fluctuation, mean and dynamic range of intensity, ISI characteristic, and shape of the rate function. These information can then be fed to the spike train model to generate synthetic datasets for tuning purpose. Using the same principle of minimizing MISE, we can tune <italic>&#x003b1;</italic> and use this tuned value for firing rate estimation during testing phase.</p><p>BAKS offers simplicity as standard kernel-based method does, yet is effective in grasping sudden and slow changes of firing rate in different regions within the observation interval. Unlike BARS which is computationally demanding, BAKS is relatively fast owing to an analytical expression of bandwidth posterior density. This analytical expression leads to the adaptive bandwidth determined in an exact way (not numerical approximation), which reduces the computational complexity. With good performance and relatively low complexity, BAKS is suitable to be used for research that require single-trial firing rate estimation. For example, understanding the encoding mechanism of neurons in cognitive-related tasks and decoding task parameter in brain-machine interface (BMI) applications. As a summary, the comparison of BAKS with other methods is given in <xref rid="pone.0206794.t003" ref-type="table">Table 3</xref>.</p><table-wrap id="pone.0206794.t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0206794.t003</object-id><label>Table 3</label><caption><title>Comparison summary of BAKS with other methods.</title></caption><alternatives><graphic id="pone.0206794.t003g" xlink:href="pone.0206794.t003"/><table frame="box" rules="all" border="0"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1"/><th align="center" rowspan="1" colspan="1">BAKS</th><th align="center" rowspan="1" colspan="1">OKS</th><th align="center" rowspan="1" colspan="1">VKS</th><th align="center" rowspan="1" colspan="1">Locfit</th><th align="center" rowspan="1" colspan="1">BARS</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Adaptability to underlying dynamics</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02212;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02212;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td></tr><tr><td align="left" rowspan="1" colspan="1">Bayesian/probabilistic approach</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02212;</td><td align="center" rowspan="1" colspan="1">&#x02212;</td><td align="center" rowspan="1" colspan="1">&#x02212;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td></tr><tr><td align="left" rowspan="1" colspan="1">Automatic selection of smoothing parameter</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td><td align="center" rowspan="1" colspan="1">&#x02212;</td><td align="center" rowspan="1" colspan="1">&#x02713;</td></tr><tr><td align="left" rowspan="1" colspan="1">Single trial (low to moderate number of spikes)</td><td align="center" rowspan="1" colspan="1">&#x025c7; &#x025c7; &#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7;&#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7;&#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7;&#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7;&#x025c7;</td></tr><tr><td align="left" rowspan="1" colspan="1">Multi trials (large number of spikes)</td><td align="center" rowspan="1" colspan="1">&#x025c7;&#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7;&#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7;&#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7; &#x025c7; &#x025c7;</td></tr><tr><td align="left" rowspan="1" colspan="1">Computational complexity (runtime)</td><td align="center" rowspan="1" colspan="1">&#x025c7; &#x025c7; &#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7; &#x025c7; &#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7;&#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7; &#x025c7; &#x025c7;</td><td align="center" rowspan="1" colspan="1">&#x025c7;</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="t003fn001"><p>More diamonds mark (&#x025c7;) indicates better (desirable) property.</p></fn></table-wrap-foot></table-wrap></sec><sec sec-type="conclusions" id="sec023"><title>Conclusion</title><p>We have presented a simple yet accurate method, referred to as BAKS, for estimating single-trial neuronal firing rate based on a kernel smoothing technique with adaptive bandwidth. The key idea of BAKS is to consider the bandwidth parameter as a random variable under an empirical Bayesian framework. By using Bayes&#x02019; theorem with proper choice of kernel and prior distribution functions, the bandwidth can be adaptively determined in an exact and quick way. Extensive evaluations on both synthetic and real neural data show that BAKS yields good performance compared to other competing methods. This suggests that BAKS has the potential to improve single-trial analysis in neuroscience studies and decoding performance of spike-based brain-machine interfaces (BMIs).</p></sec><sec id="sec024"><title>Appendix</title><sec id="sec025"><title>Appendix 1. Posterior distribution of bandwidth</title><p>In this appendix, we derive a closed-form expression of the posterior density of bandwidth as given in <xref ref-type="disp-formula" rid="pone.0206794.e009">Eq (9)</xref>. According to Bayes&#x02019; theorem, the posterior density is formulated as:
<disp-formula id="pone.0206794.e034"><alternatives><graphic xlink:href="pone.0206794.e034.jpg" id="pone.0206794.e034g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M34"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(28)</label></disp-formula>
Using likelihood function as in <xref ref-type="disp-formula" rid="pone.0206794.e007">Eq (7)</xref> and prior distribution of bandwidth as in <xref ref-type="disp-formula" rid="pone.0206794.e006">Eq (6)</xref>, we can obtain:
<disp-formula id="pone.0206794.e035"><alternatives><graphic xlink:href="pone.0206794.e035.jpg" id="pone.0206794.e035g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M35"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>&#x003b2;</mml:mi><mml:mi>&#x003b1;</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>&#x003b2;</mml:mi><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>}</mml:mo></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>n</mml:mi></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msub><mml:mi>K</mml:mi><mml:mrow><mml:mi>h</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msup><mml:mi>&#x003b2;</mml:mi><mml:mi>&#x003b1;</mml:mi></mml:msup></mml:mrow></mml:mfrac><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>&#x003b2;</mml:mi><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>}</mml:mo><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(29)</label></disp-formula>
By substituting a Gaussian kernel into the likelihood function and removing the same constants in both numerator and denominator, <xref ref-type="disp-formula" rid="pone.0206794.e035">Eq (29)</xref> then becomes:
<disp-formula id="pone.0206794.e036"><alternatives><graphic xlink:href="pone.0206794.e036.jpg" id="pone.0206794.e036g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M36"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo><mml:mo>}</mml:mo><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(30)</label></disp-formula>
Let now consider the denominator of Eqs <xref ref-type="disp-formula" rid="pone.0206794.e034">(28)</xref> and <xref ref-type="disp-formula" rid="pone.0206794.e036">(30)</xref>, which we can rewrite as:
<disp-formula id="pone.0206794.e037"><alternatives><graphic xlink:href="pone.0206794.e037.jpg" id="pone.0206794.e037g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M37"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>&#x0222b;</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo><mml:mo>}</mml:mo><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(31)</label></disp-formula>
To simplify the calculation, let us define variables as follows:
<disp-formula id="pone.0206794.e038"><alternatives><graphic xlink:href="pone.0206794.e038.jpg" id="pone.0206794.e038g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M38"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>,</mml:mo><mml:mspace width="1.em"/><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mspace width="1.em"/><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>&#x003c3;</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mfrac><mml:mn>3</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mi>d</mml:mi><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(32)</label></disp-formula>
<disp-formula id="pone.0206794.e039"><alternatives><graphic xlink:href="pone.0206794.e039.jpg" id="pone.0206794.e039g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M39"><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(33)</label></disp-formula>
By substituting Eqs <xref ref-type="disp-formula" rid="pone.0206794.e038">(32)</xref> and <xref ref-type="disp-formula" rid="pone.0206794.e039">(33)</xref> into <xref ref-type="disp-formula" rid="pone.0206794.e037">Eq (31)</xref>, the integral function can be represented as:
<disp-formula id="pone.0206794.e040"><alternatives><graphic xlink:href="pone.0206794.e040.jpg" id="pone.0206794.e040g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M40"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>}</mml:mo><mml:mi>d</mml:mi><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(34)</label></disp-formula>
<xref ref-type="disp-formula" rid="pone.0206794.e040">Eq (34)</xref> can be simplified so that the integral part forms Gamma probability density as follows:
<disp-formula id="pone.0206794.e041"><alternatives><graphic xlink:href="pone.0206794.e041.jpg" id="pone.0206794.e041g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M41"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mtable><mml:mtr><mml:mtd columnalign="right"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow/><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mtd></mml:mtr><mml:mtr><mml:mtd/><mml:mtd columnalign="left"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mrow/><mml:mspace width="1.em"/><mml:mo>&#x000d7;</mml:mo><mml:mo>&#x0222b;</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>}</mml:mo><mml:mi>d</mml:mi><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(35)</label></disp-formula>
Since the integration of Gamma probability density function is equal to 1,
<disp-formula id="pone.0206794.e042"><alternatives><graphic xlink:href="pone.0206794.e042.jpg" id="pone.0206794.e042g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M42"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>}</mml:mo><mml:mi>d</mml:mi><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mstyle></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(36)</label></disp-formula>
<xref ref-type="disp-formula" rid="pone.0206794.e041">Eq 35</xref> can then be analytically expressed as:
<disp-formula id="pone.0206794.e043"><alternatives><graphic xlink:href="pone.0206794.e043.jpg" id="pone.0206794.e043g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M43"><mml:mtable columnalign="left"><mml:mtr columnalign="right"><mml:mtd columnalign="right"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:mover accent="true"><mml:mi>f</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mstyle displaystyle="true"><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:mfrac><mml:mrow><mml:msup><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>t</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(37)</label></disp-formula>
Finally, by substituting <xref ref-type="disp-formula" rid="pone.0206794.e043">Eq (37)</xref> back to the original equation of posterior density of bandwidth in <xref ref-type="disp-formula" rid="pone.0206794.e034">Eq (28)</xref>, we can obtain the closed-form solution as in <xref ref-type="disp-formula" rid="pone.0206794.e009">Eq (9)</xref>:
<disp-formula id="pone.0206794.e044"><alternatives><graphic xlink:href="pone.0206794.e044.jpg" id="pone.0206794.e044g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M44"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:msup><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo><mml:mo>}</mml:mo></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>-</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(38)</label></disp-formula></p></sec><sec id="sec026"><title>Appendix 2. Adaptive bandwidth estimate</title><p>Under squared error loss function, the adaptive bandwidth can be estimated by using the posterior mean as given by:
<disp-formula id="pone.0206794.e045"><alternatives><graphic xlink:href="pone.0206794.e045.jpg" id="pone.0206794.e045g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M45"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>&#x0222b;</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>&#x003c0;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>|</mml:mo><mml:mi>&#x003c1;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(39)</label></disp-formula>
By substituting <xref ref-type="disp-formula" rid="pone.0206794.e044">Eq (38)</xref> into <xref ref-type="disp-formula" rid="pone.0206794.e045">Eq (39)</xref>, we can obtain:
<disp-formula id="pone.0206794.e046"><alternatives><graphic xlink:href="pone.0206794.e046.jpg" id="pone.0206794.e046g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M46"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x0222b;</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mn>2</mml:mn><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mrow><mml:mi>h</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfrac><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo><mml:mo>}</mml:mo><mml:mi>d</mml:mi><mml:mi>h</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>-</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(40)</label></disp-formula>
Similar to the derivation procedure for the posterior distribution of bandwidth (Appendix 1), by the change-of-variables rule using Eqs <xref ref-type="disp-formula" rid="pone.0206794.e038">(32)</xref>, <xref ref-type="disp-formula" rid="pone.0206794.e039">(33)</xref> and <xref ref-type="disp-formula" rid="pone.0206794.e046">(40)</xref> can be written as:
<disp-formula id="pone.0206794.e047"><alternatives><graphic xlink:href="pone.0206794.e047.jpg" id="pone.0206794.e047g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M47"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:mo>&#x0222b;</mml:mo><mml:mi>&#x003c3;</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo form="prefix">exp</mml:mo><mml:mo>{</mml:mo><mml:mo>-</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003c3;</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac><mml:mo>}</mml:mo><mml:mi>d</mml:mi><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mo>-</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(41)</label></disp-formula>
By modifying the integral part of numerator to be an integration of Gamma probability density function (which is equal to 1) as in <xref ref-type="disp-formula" rid="pone.0206794.e041">Eq (35)</xref>, we can obtain the final closed-form solution as in <xref ref-type="disp-formula" rid="pone.0206794.e011">Eq (11)</xref>:
<disp-formula id="pone.0206794.e048"><alternatives><graphic xlink:href="pone.0206794.e048.jpg" id="pone.0206794.e048g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M48"><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mover accent="true"><mml:mi>h</mml:mi><mml:mo>^</mml:mo></mml:mover><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:mstyle><mml:mstyle displaystyle="true" scriptlevel="0"><mml:mrow><mml:mo>&#x00393;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mo>)</mml:mo></mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>n</mml:mi></mml:munderover><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:mfrac><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>t</mml:mi><mml:mo>-</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mn>2</mml:mn></mml:mfrac><mml:mo>+</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mi>&#x003b2;</mml:mi></mml:mfrac><mml:mo>]</mml:mo></mml:mrow><mml:mrow><mml:mo>-</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>-</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac></mml:mrow></mml:msup></mml:mrow></mml:mstyle></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:math></alternatives><label>(42)</label></disp-formula></p></sec></sec><sec sec-type="supplementary-material" id="sec027"><title>Supporting information</title><supplementary-material content-type="local-data" id="pone.0206794.s001"><label>S1 Fig</label><caption><title>MISE comparison under different values of intensity and frequency for IIG model.</title><p>(a) MISE comparison for the case of low intensity. (b) MISE comparison for the case of high intensity. (c) MISE comparison for the case of low frequency. (d) MISE comparison for the case of high frequency. In each boxplot, black lines show the medians; black circles indicate the means; colored solid boxes represent interquartile ranges; whiskers extend 1.5&#x000d7; from upper and lower quartiles; gray crosses represent outliers.</p><p>(EPS)</p></caption><media xlink:href="pone.0206794.s001.eps"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0206794.s002"><label>S2 Fig</label><caption><title>MISE comparison under different values of shape parameter (<italic>&#x003b3;</italic> = {0.25, 0.5, 0.75}).</title><p>(a)-(c) MISE comparison for chirp, sine, and sawtooth rate functions, respectively, from IG model. (d)-(f) MISE comparison for chirp, sine, and sawtooth rate functions, respectively, from IIG model. Vertical bars represent the 95% confidence intervals.</p><p>(EPS)</p></caption><media xlink:href="pone.0206794.s002.eps"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0206794.s003"><label>S3 Fig</label><caption><title>MISE comparison for IIG model with Gaussian-damped sinusoidal rate function.</title><p>In each boxplot, black lines show the medians; black circles indicate the means; colored solid boxes represent interquartile ranges; whiskers extend 1.5&#x000d7; from upper and lower quartiles; gray crosses represent outliers.</p><p>(EPS)</p></caption><media xlink:href="pone.0206794.s003.eps"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0206794.s004"><label>S4 Fig</label><caption><title>Firing rate estimate comparison for IIG model with Gaussian-damped sinusoidal rate function.</title><p>(a)-(c) Firing rate estimates for the cases of low, medium and high frequency, respectively. (d)-(f) Firing rate estimates for the cases of low, medium and high intensity, respectively. Black lines with gray-shaded regions indicate the underlying rate functions. Black raster in the bottom of each plot represents a spike train generated from the associated underlying rate function.</p><p>(EPS)</p></caption><media xlink:href="pone.0206794.s004.eps"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0206794.s005"><label>S5 Fig</label><caption><title>MISE comparison for IG model with square rate function.</title><p>In each boxplot, black lines show the medians; black circles indicate the means; colored solid boxes represent interquartile ranges; whiskers extend 1.5&#x000d7; from upper and lower quartiles; gray crosses represent outliers.</p><p>(EPS)</p></caption><media xlink:href="pone.0206794.s005.eps"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material><supplementary-material content-type="local-data" id="pone.0206794.s006"><label>S6 Fig</label><caption><title>Firing rate estimate comparison for IG model with square rate function.</title><p>(a)-(b) Firing rate estimates for the cases of low and high frequency, respectively. (c)-(d) Firing rate estimates for the cases of low and high intensity, respectively. Black lines with gray-shaded regions indicate the underlying rate functions.</p><p>(EPS)</p></caption><media xlink:href="pone.0206794.s006.eps"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ack><p>We thank R.D. Flint, E.W. Lindberg, L.R. Jordan, L.E. Miller, and M.W. Slutzky for making their data available via the CRCNS database (<ext-link ext-link-type="uri" xlink:href="https://crcns.org/">https://crcns.org/</ext-link>). We also thank K.H. Britten, M.N. Shadlen, W.T. Newsome, and J.A. Movshon for making their data available via the NSA website (<ext-link ext-link-type="uri" xlink:href="http://www.neuralsignal.org/">http://www.neuralsignal.org/</ext-link>). Nur Ahmadi acknowledges the graduate scholarship granted by Indonesia Endowment Fund for Education (LPDP), Republic of Indonesia.</p></ack><ref-list><title>References</title><ref id="pone.0206794.ref001"><label>1</label><mixed-citation publication-type="journal">
<name><surname>Cherif</surname><given-names>S</given-names></name>, <name><surname>Cullen</surname><given-names>KE</given-names></name>, <name><surname>Galiana</surname><given-names>HL</given-names></name>. <article-title>An improved method for the estimation of firing rate dynamics using an optimal digital filter</article-title>. <source>Journal of neuroscience methods</source>. <year>2008</year>;<volume>173</volume>(<issue>1</issue>):<fpage>165</fpage>&#x02013;<lpage>181</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneumeth.2008.05.021">10.1016/j.jneumeth.2008.05.021</ext-link>
<pub-id pub-id-type="pmid">18577401</pub-id></mixed-citation></ref><ref id="pone.0206794.ref002"><label>2</label><mixed-citation publication-type="journal">
<name><surname>L&#x000e1;nsk&#x01ef3;</surname><given-names>P</given-names></name>, <name><surname>Rodriguez</surname><given-names>R</given-names></name>, <name><surname>Sacerdote</surname><given-names>L</given-names></name>. <article-title>Mean instantaneous firing frequency is always higher than the firing rate</article-title>. <source>Neural computation</source>. <year>2004</year>;<volume>16</volume>(<issue>3</issue>):<fpage>477</fpage>&#x02013;<lpage>489</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/089976604772744875">10.1162/089976604772744875</ext-link>
<pub-id pub-id-type="pmid">15022676</pub-id></mixed-citation></ref><ref id="pone.0206794.ref003"><label>3</label><mixed-citation publication-type="journal">
<name><surname>Cunningham</surname><given-names>JP</given-names></name>, <name><surname>Gilja</surname><given-names>V</given-names></name>, <name><surname>Ryu</surname><given-names>SI</given-names></name>, <name><surname>Shenoy</surname><given-names>KV</given-names></name>. <article-title>Methods for estimating neural firing rates, and their application to brain&#x02013;machine interfaces</article-title>. <source>Neural Networks</source>. <year>2009</year>;<volume>22</volume>(<issue>9</issue>):<fpage>1235</fpage>&#x02013;<lpage>1246</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neunet.2009.02.004">10.1016/j.neunet.2009.02.004</ext-link>
<pub-id pub-id-type="pmid">19349143</pub-id></mixed-citation></ref><ref id="pone.0206794.ref004"><label>4</label><mixed-citation publication-type="journal">
<name><surname>Yu</surname><given-names>BM</given-names></name>, <name><surname>Cunningham</surname><given-names>JP</given-names></name>, <name><surname>Santhanam</surname><given-names>G</given-names></name>, <name><surname>Ryu</surname><given-names>SI</given-names></name>, <name><surname>Shenoy</surname><given-names>KV</given-names></name>, <name><surname>Sahani</surname><given-names>M</given-names></name>. <article-title>Gaussian-Process Factor Analysis for Low-Dimensional Single-Trial Analysis of Neural Population Activity</article-title>. <source>Journal of Neurophysiology</source>. <year>2009</year>;<volume>102</volume>(<issue>1</issue>):<fpage>614</fpage>&#x02013;<lpage>635</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.90941.2008">10.1152/jn.90941.2008</ext-link>
<pub-id pub-id-type="pmid">19357332</pub-id></mixed-citation></ref><ref id="pone.0206794.ref005"><label>5</label><mixed-citation publication-type="journal">
<name><surname>Nawrot</surname><given-names>M</given-names></name>, <name><surname>Aertsen</surname><given-names>A</given-names></name>, <name><surname>Rotter</surname><given-names>S</given-names></name>. <article-title>Single-trial estimation of neuronal firing rates: from single-neuron spike trains to population activity</article-title>. <source>Journal of neuroscience methods</source>. <year>1999</year>;<volume>94</volume>(<issue>1</issue>):<fpage>81</fpage>&#x02013;<lpage>92</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0165-0270(99)00127-2">10.1016/S0165-0270(99)00127-2</ext-link>
<pub-id pub-id-type="pmid">10638817</pub-id></mixed-citation></ref><ref id="pone.0206794.ref006"><label>6</label><mixed-citation publication-type="journal">
<name><surname>Nawrot</surname><given-names>MP</given-names></name>, <name><surname>Boucsein</surname><given-names>C</given-names></name>, <name><surname>Molina</surname><given-names>VR</given-names></name>, <name><surname>Riehle</surname><given-names>A</given-names></name>, <name><surname>Aertsen</surname><given-names>A</given-names></name>, <name><surname>Rotter</surname><given-names>S</given-names></name>. <article-title>Measurement of variability dynamics in cortical spike trains</article-title>. <source>Journal of neuroscience methods</source>. <year>2008</year>;<volume>169</volume>(<issue>2</issue>):<fpage>374</fpage>&#x02013;<lpage>390</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jneumeth.2007.10.013">10.1016/j.jneumeth.2007.10.013</ext-link>
<pub-id pub-id-type="pmid">18155774</pub-id></mixed-citation></ref><ref id="pone.0206794.ref007"><label>7</label><mixed-citation publication-type="journal">
<name><surname>Latimer</surname><given-names>KW</given-names></name>, <name><surname>Yates</surname><given-names>JL</given-names></name>, <name><surname>Meister</surname><given-names>ML</given-names></name>, <name><surname>Huk</surname><given-names>AC</given-names></name>, <name><surname>Pillow</surname><given-names>JW</given-names></name>. <article-title>Single-trial spike trains in parietal cortex reveal discrete steps during decision-making</article-title>. <source>Science</source>. <year>2015</year>;<volume>349</volume>(<issue>6244</issue>):<fpage>184</fpage>&#x02013;<lpage>187</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1126/science.aaa4056">10.1126/science.aaa4056</ext-link>
<pub-id pub-id-type="pmid">26160947</pub-id></mixed-citation></ref><ref id="pone.0206794.ref008"><label>8</label><mixed-citation publication-type="journal">
<name><surname>Afshar</surname><given-names>A</given-names></name>, <name><surname>Santhanam</surname><given-names>G</given-names></name>, <name><surname>Byron</surname><given-names>MY</given-names></name>, <name><surname>Ryu</surname><given-names>SI</given-names></name>, <name><surname>Sahani</surname><given-names>M</given-names></name>, <name><surname>Shenoy</surname><given-names>KV</given-names></name>. <article-title>Single-trial neural correlates of arm movement preparation</article-title>. <source>Neuron</source>. <year>2011</year>;<volume>71</volume>(<issue>3</issue>):<fpage>555</fpage>&#x02013;<lpage>564</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.neuron.2011.05.047">10.1016/j.neuron.2011.05.047</ext-link>
<pub-id pub-id-type="pmid">21835350</pub-id></mixed-citation></ref><ref id="pone.0206794.ref009"><label>9</label><mixed-citation publication-type="journal">
<name><surname>Rey</surname><given-names>HG</given-names></name>, <name><surname>Ahmadi</surname><given-names>M</given-names></name>, <name><surname>Quiroga</surname><given-names>RQ</given-names></name>. <article-title>Single trial analysis of field potentials in perception, learning and memory</article-title>. <source>Current opinion in neurobiology</source>. <year>2015</year>;<volume>31</volume>:<fpage>148</fpage>&#x02013;<lpage>155</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.conb.2014.10.009">10.1016/j.conb.2014.10.009</ext-link>
<pub-id pub-id-type="pmid">25460071</pub-id></mixed-citation></ref><ref id="pone.0206794.ref010"><label>10</label><mixed-citation publication-type="book">
<name><surname>Shinomoto</surname><given-names>S</given-names></name>. <chapter-title>Estimating the firing rate</chapter-title> In: <source>Analysis of Parallel Spike Trains</source>. <publisher-name>Springer</publisher-name>; <year>2010</year> p. <fpage>21</fpage>&#x02013;<lpage>35</lpage>.</mixed-citation></ref><ref id="pone.0206794.ref011"><label>11</label><mixed-citation publication-type="journal">
<name><surname>Shinomoto</surname><given-names>S</given-names></name>. <article-title>Estimation of Neuronal Firing Rate</article-title>. <source>Encyclopedia of Computational Neuroscience</source>. <year>2015</year>; p. <fpage>1148</fpage>&#x02013;<lpage>1152</lpage>.</mixed-citation></ref><ref id="pone.0206794.ref012"><label>12</label><mixed-citation publication-type="journal">
<name><surname>Shimazaki</surname><given-names>H</given-names></name>, <name><surname>Shinomoto</surname><given-names>S</given-names></name>. <article-title>Kernel bandwidth optimization in spike rate estimation</article-title>. <source>Journal of computational neuroscience</source>. <year>2010</year>;<volume>29</volume>(<issue>1-2</issue>):<fpage>171</fpage>&#x02013;<lpage>182</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10827-009-0180-4">10.1007/s10827-009-0180-4</ext-link>
<pub-id pub-id-type="pmid">19655238</pub-id></mixed-citation></ref><ref id="pone.0206794.ref013"><label>13</label><mixed-citation publication-type="book">
<name><surname>Loader</surname><given-names>C</given-names></name>. <source>Local regression and likelihood</source>. <publisher-name>Springer</publisher-name>; <year>1999</year>.</mixed-citation></ref><ref id="pone.0206794.ref014"><label>14</label><mixed-citation publication-type="journal">
<name><surname>DiMatteo</surname><given-names>I</given-names></name>, <name><surname>Genovese</surname><given-names>CR</given-names></name>, <name><surname>Kass</surname><given-names>RE</given-names></name>. <article-title>Bayesian curve-fitting with free-knot splines</article-title>. <source>Biometrika</source>. <year>2001</year>; p. <fpage>1055</fpage>&#x02013;<lpage>1071</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/biomet/88.4.1055">10.1093/biomet/88.4.1055</ext-link></mixed-citation></ref><ref id="pone.0206794.ref015"><label>15</label><mixed-citation publication-type="journal">
<name><surname>Barbieri</surname><given-names>R</given-names></name>, <name><surname>Quirk</surname><given-names>MC</given-names></name>, <name><surname>Frank</surname><given-names>LM</given-names></name>, <name><surname>Wilson</surname><given-names>MA</given-names></name>, <name><surname>Brown</surname><given-names>EN</given-names></name>. <article-title>Construction and analysis of non-Poisson stimulus-response models of neural spiking activity</article-title>. <source>Journal of neuroscience methods</source>. <year>2001</year>;<volume>105</volume>(<issue>1</issue>):<fpage>25</fpage>&#x02013;<lpage>37</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0165-0270(00)00344-7">10.1016/S0165-0270(00)00344-7</ext-link>
<pub-id pub-id-type="pmid">11166363</pub-id></mixed-citation></ref><ref id="pone.0206794.ref016"><label>16</label><mixed-citation publication-type="journal">
<name><surname>Kass</surname><given-names>RE</given-names></name>, <name><surname>Ventura</surname><given-names>V</given-names></name>, <name><surname>Brown</surname><given-names>EN</given-names></name>. <article-title>Statistical issues in the analysis of neuronal data</article-title>. <source>Journal of neurophysiology</source>. <year>2005</year>;<volume>94</volume>(<issue>1</issue>):<fpage>8</fpage>&#x02013;<lpage>25</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00648.2004">10.1152/jn.00648.2004</ext-link>
<pub-id pub-id-type="pmid">15985692</pub-id></mixed-citation></ref><ref id="pone.0206794.ref017"><label>17</label><mixed-citation publication-type="book">
<name><surname>Kass</surname><given-names>RE</given-names></name>. <chapter-title>Adaptive Spline Smoothing of Neural Data</chapter-title> In: <name><surname>Mitra</surname><given-names>PP</given-names></name>, editor. <source>Neural Signal Processing: Quantitative Analysis of Neural Activity</source>. <publisher-name>Society for Neuroscience</publisher-name>; <year>2008</year> p. <fpage>35</fpage>&#x02013;<lpage>42</lpage>.</mixed-citation></ref><ref id="pone.0206794.ref018"><label>18</label><mixed-citation publication-type="other">Hansen BE. Lecture notes on nonparametrics; 2009.</mixed-citation></ref><ref id="pone.0206794.ref019"><label>19</label><mixed-citation publication-type="journal">
<name><surname>Cheng</surname><given-names>T</given-names></name>, <name><surname>Gao</surname><given-names>J</given-names></name>, <name><surname>Zhang</surname><given-names>X</given-names></name>. <article-title>Nonparametric localized bandwidth selection for Kernel density estimation</article-title>. <source>Econometric Reviews</source>. <year>2018</year>; p. <fpage>1</fpage>&#x02013;<lpage>30</lpage>.</mixed-citation></ref><ref id="pone.0206794.ref020"><label>20</label><mixed-citation publication-type="book">
<name><surname>Silverman</surname><given-names>BW</given-names></name>. <source>Density estimation for statistics and data analysis</source>. <volume>vol. 26</volume>
<publisher-name>CRC press</publisher-name>; <year>1986</year>.</mixed-citation></ref><ref id="pone.0206794.ref021"><label>21</label><mixed-citation publication-type="journal">
<name><surname>Sheather</surname><given-names>SJ</given-names></name>, <name><surname>Jones</surname><given-names>MC</given-names></name>. <article-title>A reliable data-based bandwidth selection method for kernel density estimation</article-title>. <source>Journal of the Royal Statistical Society Series B (Methodological)</source>. <year>1991</year>; p. <fpage>683</fpage>&#x02013;<lpage>690</lpage>.</mixed-citation></ref><ref id="pone.0206794.ref022"><label>22</label><mixed-citation publication-type="journal">
<name><surname>Rudemo</surname><given-names>M</given-names></name>. <article-title>Empirical choice of histograms and kernel density estimators</article-title>. <source>Scandinavian Journal of Statistics</source>. <year>1982</year>; p. <fpage>65</fpage>&#x02013;<lpage>78</lpage>.</mixed-citation></ref><ref id="pone.0206794.ref023"><label>23</label><mixed-citation publication-type="journal">
<name><surname>Bowman</surname><given-names>AW</given-names></name>. <article-title>An alternative method of cross-validation for the smoothing of density estimates</article-title>. <source>Biometrika</source>. <year>1984</year>;<volume>71</volume>(<issue>2</issue>):<fpage>353</fpage>&#x02013;<lpage>360</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/biomet/71.2.353">10.1093/biomet/71.2.353</ext-link></mixed-citation></ref><ref id="pone.0206794.ref024"><label>24</label><mixed-citation publication-type="journal">
<name><surname>Heidenreich</surname><given-names>NB</given-names></name>, <name><surname>Schindler</surname><given-names>A</given-names></name>, <name><surname>Sperlich</surname><given-names>S</given-names></name>. <article-title>Bandwidth selection for kernel density estimation: a review of fully automatic selectors</article-title>. <source>AStA Advances in Statistical Analysis</source>. <year>2013</year>;<volume>97</volume>(<issue>4</issue>):<fpage>403</fpage>&#x02013;<lpage>433</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10182-013-0216-y">10.1007/s10182-013-0216-y</ext-link></mixed-citation></ref><ref id="pone.0206794.ref025"><label>25</label><mixed-citation publication-type="journal">
<name><surname>Ventura</surname><given-names>V</given-names></name>, <name><surname>Carta</surname><given-names>R</given-names></name>, <name><surname>Kass</surname><given-names>RE</given-names></name>, <name><surname>Gettner</surname><given-names>SN</given-names></name>, <name><surname>Olson</surname><given-names>CR</given-names></name>. <article-title>Statistical analysis of temporal evolution in single-neuron firing rates</article-title>. <source>Biostatistics</source>. <year>2002</year>;<volume>3</volume>(<issue>1</issue>):<fpage>1</fpage>&#x02013;<lpage>20</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/biostatistics/3.1.1">10.1093/biostatistics/3.1.1</ext-link>
<pub-id pub-id-type="pmid">12933620</pub-id></mixed-citation></ref><ref id="pone.0206794.ref026"><label>26</label><mixed-citation publication-type="book">
<name><surname>Kornienko</surname><given-names>O</given-names></name>. <source>Neural Representations and Decoding with Optimized Kernel Density Estimates</source>. <publisher-name>University of Heidelberg</publisher-name>, <publisher-loc>Germany</publisher-loc>; <year>2015</year>.</mixed-citation></ref><ref id="pone.0206794.ref027"><label>27</label><mixed-citation publication-type="other">Cunningham JP, Yu BM, Shenoy KV, Sahani M. Inferring Neural Firing Rates from Spike Trains Using Gaussian Processes. In: Platt JC, Koller D, Singer Y, Roweis ST, editors. Advances in Neural Information Processing Systems 20. Curran Associates, Inc.; 2008. p. 329&#x02013;336.</mixed-citation></ref><ref id="pone.0206794.ref028"><label>28</label><mixed-citation publication-type="journal">
<name><surname>Shimokawa</surname><given-names>T</given-names></name>, <name><surname>Shinomoto</surname><given-names>S</given-names></name>. <article-title>Estimating instantaneous irregularity of neuronal firing</article-title>. <source>Neural computation</source>. <year>2009</year>;<volume>21</volume>(<issue>7</issue>):<fpage>1931</fpage>&#x02013;<lpage>1951</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/neco.2009.08-08-841">10.1162/neco.2009.08-08-841</ext-link>
<pub-id pub-id-type="pmid">19323639</pub-id></mixed-citation></ref><ref id="pone.0206794.ref029"><label>29</label><mixed-citation publication-type="journal">
<name><surname>Brown</surname><given-names>EN</given-names></name>, <name><surname>Barbieri</surname><given-names>R</given-names></name>, <name><surname>Ventura</surname><given-names>V</given-names></name>, <name><surname>Kass</surname><given-names>RE</given-names></name>, <name><surname>Frank</surname><given-names>LM</given-names></name>. <article-title>The time-rescaling theorem and its application to neural spike train data analysis</article-title>. <source>Neural computation</source>. <year>2002</year>;<volume>14</volume>(<issue>2</issue>):<fpage>325</fpage>&#x02013;<lpage>346</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/08997660252741149">10.1162/08997660252741149</ext-link>
<pub-id pub-id-type="pmid">11802915</pub-id></mixed-citation></ref><ref id="pone.0206794.ref030"><label>30</label><mixed-citation publication-type="journal">
<name><surname>Shimokawa</surname><given-names>T</given-names></name>, <name><surname>Koyama</surname><given-names>S</given-names></name>, <name><surname>Shinomoto</surname><given-names>S</given-names></name>. <article-title>A characterization of the time-rescaled gamma process as a model for spike trains</article-title>. <source>Journal of computational neuroscience</source>. <year>2010</year>;<volume>29</volume>(<issue>1-2</issue>):<fpage>183</fpage>&#x02013;<lpage>191</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s10827-009-0194-y">10.1007/s10827-009-0194-y</ext-link>
<pub-id pub-id-type="pmid">19844786</pub-id></mixed-citation></ref><ref id="pone.0206794.ref031"><label>31</label><mixed-citation publication-type="journal">
<name><surname>Moschopoulos</surname><given-names>PG</given-names></name>. <article-title>The distribution of the sum of independent gamma random variables</article-title>. <source>Annals of the Institute of Statistical Mathematics</source>. <year>1985</year>;<volume>37</volume>(<issue>1</issue>):<fpage>541</fpage>&#x02013;<lpage>544</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/BF02481123">10.1007/BF02481123</ext-link></mixed-citation></ref><ref id="pone.0206794.ref032"><label>32</label><mixed-citation publication-type="other">Fink D. A compendium of conjugate priors. 1997.</mixed-citation></ref><ref id="pone.0206794.ref033"><label>33</label><mixed-citation publication-type="other">Zambom AZ, Dias R. A review of kernel density estimation with applications to econometrics. arXiv preprint arXiv:12122812. 2012.</mixed-citation></ref><ref id="pone.0206794.ref034"><label>34</label><mixed-citation publication-type="journal">
<name><surname>Kass</surname><given-names>RE</given-names></name>, <name><surname>Ventura</surname><given-names>V</given-names></name>, <name><surname>Cai</surname><given-names>C</given-names></name>. <article-title>Statistical smoothing of neuronal data</article-title>. <source>Network-Computation in Neural Systems</source>. <year>2003</year>;<volume>14</volume>(<issue>1</issue>):<fpage>5</fpage>&#x02013;<lpage>16</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1088/0954-898X/14/1/301">10.1088/0954-898X/14/1/301</ext-link></mixed-citation></ref><ref id="pone.0206794.ref035"><label>35</label><mixed-citation publication-type="book">
<name><surname>Kass</surname><given-names>RE</given-names></name>, <name><surname>Eden</surname><given-names>UT</given-names></name>, <name><surname>Brown</surname><given-names>EN</given-names></name>. <source>Analysis of neural data</source>. <volume>vol. 491</volume>
<publisher-name>Springer</publisher-name>; <year>2014</year>.</mixed-citation></ref><ref id="pone.0206794.ref036"><label>36</label><mixed-citation publication-type="journal">
<name><surname>Soteropoulos</surname><given-names>DS</given-names></name>, <name><surname>Baker</surname><given-names>SN</given-names></name>. <article-title>Quantifying neural coding of event timing</article-title>. <source>Journal of neurophysiology</source>. <year>2009</year>;<volume>101</volume>(<issue>1</issue>):<fpage>402</fpage>&#x02013;<lpage>417</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.90767.2008">10.1152/jn.90767.2008</ext-link>
<pub-id pub-id-type="pmid">19019976</pub-id></mixed-citation></ref><ref id="pone.0206794.ref037"><label>37</label><mixed-citation publication-type="book">
<name><surname>Brown</surname><given-names>EN</given-names></name>, <name><surname>Barbieri</surname><given-names>R</given-names></name>, <name><surname>Eden</surname><given-names>UT</given-names></name>, <name><surname>Frank</surname><given-names>LM</given-names></name>. <chapter-title>Likelihood methods for neural spike train data analysis</chapter-title> In: <name><surname>Feng</surname><given-names>J</given-names></name>, editor. <source>Computational neuroscience: A comprehensive approach</source>. <publisher-name>CRC Press</publisher-name>
<publisher-loc>London</publisher-loc>; <year>2003</year> p. <fpage>253</fpage>&#x02013;<lpage>286</lpage>.</mixed-citation></ref><ref id="pone.0206794.ref038"><label>38</label><mixed-citation publication-type="journal">
<name><surname>Takiyama</surname><given-names>K</given-names></name>, <name><surname>Okada</surname><given-names>M</given-names></name>. <article-title>Detection of hidden structures in nonstationary spike trains</article-title>. <source>Neural computation</source>. <year>2011</year>;<volume>23</volume>(<issue>5</issue>):<fpage>1205</fpage>&#x02013;<lpage>1233</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1162/NECO_a_00109">10.1162/NECO_a_00109</ext-link>
<pub-id pub-id-type="pmid">21299427</pub-id></mixed-citation></ref><ref id="pone.0206794.ref039"><label>39</label><mixed-citation publication-type="journal">
<name><surname>Truccolo</surname><given-names>W</given-names></name>, <name><surname>Eden</surname><given-names>UT</given-names></name>, <name><surname>Fellows</surname><given-names>MR</given-names></name>, <name><surname>Donoghue</surname><given-names>JP</given-names></name>, <name><surname>Brown</surname><given-names>EN</given-names></name>. <article-title>A point process framework for relating neural spiking activity to spiking history, neural ensemble, and extrinsic covariate effects</article-title>. <source>Journal of neurophysiology</source>. <year>2005</year>;<volume>93</volume>(<issue>2</issue>):<fpage>1074</fpage>&#x02013;<lpage>1089</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1152/jn.00697.2004">10.1152/jn.00697.2004</ext-link>
<pub-id pub-id-type="pmid">15356183</pub-id></mixed-citation></ref><ref id="pone.0206794.ref040"><label>40</label><mixed-citation publication-type="other">Teh YW, Rao V. Gaussian process modulated renewal processes. In: Advances in Neural Information Processing Systems; 2011. p. 2474&#x02013;2482.</mixed-citation></ref><ref id="pone.0206794.ref041"><label>41</label><mixed-citation publication-type="journal">
<name><surname>Mazurek</surname><given-names>ME</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>. <article-title>Limits to the temporal fidelity of cortical spike rate signals</article-title>. <source>Nature neuroscience</source>. <year>2002</year>;<volume>5</volume>(<issue>5</issue>):<fpage>463</fpage>
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/nn836">10.1038/nn836</ext-link>
<pub-id pub-id-type="pmid">11976706</pub-id></mixed-citation></ref><ref id="pone.0206794.ref042"><label>42</label><mixed-citation publication-type="journal">
<name><surname>Mochizuki</surname><given-names>Y</given-names></name>, <name><surname>Shinomoto</surname><given-names>S</given-names></name>. <article-title>Analog and digital codes in the brain</article-title>. <source>Physical Review E</source>. <year>2014</year>;<volume>89</volume>(<issue>2</issue>):<fpage>022705</fpage>
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1103/PhysRevE.89.022705">10.1103/PhysRevE.89.022705</ext-link></mixed-citation></ref><ref id="pone.0206794.ref043"><label>43</label><mixed-citation publication-type="journal">
<name><surname>Wallstrom</surname><given-names>G</given-names></name>, <name><surname>Liebner</surname><given-names>J</given-names></name>, <name><surname>Kass</surname><given-names>RE</given-names></name>. <article-title>An implementation of Bayesian adaptive regression splines (BARS) in C with S and R wrappers</article-title>. <source>Journal of Statistical Software</source>. <year>2008</year>;<volume>26</volume>(<issue>1</issue>):<fpage>1</fpage>
<comment>doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.18637/jss.v026.i01">10.18637/jss.v026.i01</ext-link></comment>
<pub-id pub-id-type="pmid">19777145</pub-id></mixed-citation></ref><ref id="pone.0206794.ref044"><label>44</label><mixed-citation publication-type="journal">
<name><surname>Flint</surname><given-names>RD</given-names></name>, <name><surname>Lindberg</surname><given-names>EW</given-names></name>, <name><surname>Jordan</surname><given-names>LR</given-names></name>, <name><surname>Miller</surname><given-names>LE</given-names></name>, <name><surname>Slutzky</surname><given-names>MW</given-names></name>. <article-title>Accurate decoding of reaching movements from field potentials in the absence of spikes</article-title>. <source>Journal of neural engineering</source>. <year>2012</year>;<volume>9</volume>(<issue>4</issue>):<fpage>046006</fpage>
<ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1088/1741-2560/9/4/046006">10.1088/1741-2560/9/4/046006</ext-link>
<pub-id pub-id-type="pmid">22733013</pub-id></mixed-citation></ref><ref id="pone.0206794.ref045"><label>45</label><mixed-citation publication-type="other">Britten KH, Shadlen MN, Newsome WT, Movson JA. Responses of single neurons in macaque MT/V5 as a function of motion coherence in stochastic dot stimuli; 2004.</mixed-citation></ref><ref id="pone.0206794.ref046"><label>46</label><mixed-citation publication-type="journal">
<name><surname>Britten</surname><given-names>KH</given-names></name>, <name><surname>Shadlen</surname><given-names>MN</given-names></name>, <name><surname>Newsome</surname><given-names>WT</given-names></name>, <name><surname>Movshon</surname><given-names>JA</given-names></name>. <article-title>The analysis of visual motion: a comparison of neuronal and psychophysical performance</article-title>. <source>Journal of Neuroscience</source>. <year>1992</year>;<volume>12</volume>(<issue>12</issue>):<fpage>4745</fpage>&#x02013;<lpage>4765</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1523/JNEUROSCI.12-12-04745.1992">10.1523/JNEUROSCI.12-12-04745.1992</ext-link>
<pub-id pub-id-type="pmid">1464765</pub-id></mixed-citation></ref></ref-list></back></article>