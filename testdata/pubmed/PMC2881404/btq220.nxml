<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Bioinformatics</journal-id><journal-id journal-id-type="publisher-id">bioinformatics</journal-id><journal-id journal-id-type="hwp">bioinfo</journal-id><journal-title-group><journal-title>Bioinformatics</journal-title></journal-title-group><issn pub-type="ppub">1367-4803</issn><issn pub-type="epub">1367-4811</issn><publisher><publisher-name>Oxford University Press</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">20529939</article-id><article-id pub-id-type="pmc">2881404</article-id><article-id pub-id-type="doi">10.1093/bioinformatics/btq220</article-id><article-id pub-id-type="publisher-id">btq220</article-id><article-categories><subj-group subj-group-type="heading"><subject>Ismb 2010 Conference Proceedings July 11 to July 13, 2010, Boston, Ma, Usa</subject><subj-group><subject>Original Papers</subject><subj-group><subject>Bioimaging</subject></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Quantifying the distribution of probes between subcellular locations using unsupervised pattern unmixing</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Coelho</surname><given-names>Luis Pedro</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref><xref ref-type="aff" rid="AFF1"><sup>2</sup></xref><xref ref-type="aff" rid="AFF1"><sup>3</sup></xref><xref ref-type="author-notes" rid="FN1"><sup>&#x02020;</sup></xref></contrib><contrib contrib-type="author"><name><surname>Peng</surname><given-names>Tao</given-names></name><xref ref-type="aff" rid="AFF1"><sup>2</sup></xref><xref ref-type="aff" rid="AFF1"><sup>4</sup></xref><xref ref-type="author-notes" rid="FN1"><sup>&#x02020;</sup></xref></contrib><contrib contrib-type="author"><name><surname>Murphy</surname><given-names>Robert F.</given-names></name><xref ref-type="aff" rid="AFF1"><sup>1</sup></xref><xref ref-type="aff" rid="AFF1"><sup>2</sup></xref><xref ref-type="aff" rid="AFF1"><sup>3</sup></xref><xref ref-type="aff" rid="AFF1"><sup>4</sup></xref><xref ref-type="aff" rid="AFF1"><sup>5</sup></xref><xref ref-type="aff" rid="AFF1"><sup>6</sup></xref><xref ref-type="aff" rid="AFF1"><sup>7</sup></xref><xref ref-type="corresp" rid="COR1">*</xref></contrib></contrib-group><aff id="AFF1"><sup>1</sup> Lane Center for Computational Biology, <sup>2</sup> Center for Bioimage informatics, Carnegie Mellon University, Pittsburgh, PA 15213, <sup>3</sup> Joint Carnegie Mellon University&#x02013;University of Pittsburgh Ph.D. Program in Computational Biology, <sup>4</sup> Department of Biomedical Engineering, <sup>5</sup> Department of Biological Sciences, <sup>6</sup> Department of Machine Learning, Carnegie Mellon University, Pittsburgh, PA 15213, USA and <sup>7</sup> Freiburg Institute for Advanced Studies, Albert Ludwig University of Freiburg, 79104 Freiburg, Germany</aff><author-notes><corresp id="COR1">* To whom correspondence should be addressed.</corresp><fn id="FN1"><p><sup>&#x02020;</sup> The authors wish it to be known that, in their opinion, the first two authors should be regarded as joint First Authors.</p></fn></author-notes><pub-date pub-type="ppub"><day>15</day><month>6</month><year>2010</year></pub-date><pub-date pub-type="epub"><day>1</day><month>6</month><year>2010</year></pub-date><pub-date pub-type="pmc-release"><day>1</day><month>6</month><year>2010</year></pub-date><!-- PMC Release delay is 0 months and 0 days and was based on the
							<pub-date pub-type="epub"/>. --><volume>26</volume><issue>12</issue><fpage>i7</fpage><lpage>i12</lpage><permissions><copyright-statement>&#x000a9; The Author(s) 2010. Published by Oxford University Press.</copyright-statement><copyright-year>2010</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/2.0/uk/"><license-p><!--CREATIVE COMMONS-->This is an Open Access article distributed under the terms of the Creative Commons Attribution Non-Commercial License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/2.5">http://creativecommons.org/licenses/by-nc/2.5</ext-link>), which permits unrestricted non-commercial use, distribution, and reproduction in any medium, provided the original work is properly cited.</license-p></license></permissions><abstract><p><bold>Motivation:</bold> Proteins exhibit complex subcellular distributions, which may include localizing in more than one organelle and varying in location depending on the cell physiology. Estimating the amount of protein distributed in each subcellular location is essential for quantitative understanding and modeling of protein dynamics and how they affect cell behaviors. We have previously described automated methods using fluorescent microscope images to determine the fractions of protein fluorescence in various subcellular locations when the basic locations in which a protein can be present are known. As this set of basic locations may be unknown (especially for studies on a proteome-wide scale), we here describe unsupervised methods to identify the fundamental patterns from images of mixed patterns and estimate the fractional composition of them.</p><p><bold>Methods:</bold> We developed two approaches to the problem, both based on identifying types of objects present in images and representing patterns by frequencies of those object types. One is a basis pursuit method (which is based on a linear mixture model), and the other is based on latent Dirichlet allocation (LDA). For testing both approaches, we used images previously acquired for testing supervised unmixing methods. These images were of cells labeled with various combinations of two organelle-specific probes that had the same fluorescent properties to simulate mixed patterns of subcellular location.</p><p><bold>Results:</bold> We achieved 0.80 and 0.91 correlation between estimated and underlying fractions of the two probes (fundamental patterns) with basis pursuit and LDA approaches, respectively, indicating that our methods can unmix the complex subcellular distribution with reasonably high accuracy.</p><p><bold>Availability:</bold> <ext-link ext-link-type="uri" xlink:href="http://murphylab.web.cmu.edu/software">http://murphylab.web.cmu.edu/software</ext-link></p><p><bold>Contact:</bold> <email>murphy@cmu.edu</email></p></abstract></article-meta></front><body><sec sec-type="intro" id="SEC1"><title>1 INTRODUCTION</title><p>To investigate the subcellular localization of proteins at a proteome-wide scale, we need to be able to characterize all observed patterns. Identification of subcellular localization patterns from fluorescence images using supervised machine learning methods has become an established method, with excellent results in its field of application. However, this method is, by design, limited to hard assignments to classes predefined by the researcher. Some researchers have explored using unsupervised learning technologies (Garc&#x000ed;a Osuna <italic>et al.</italic>, <xref ref-type="bibr" rid="B5">2007</xref>; Hamilton <italic>et al.</italic>, <xref ref-type="bibr" rid="B6">2009</xref>), which do not require the researcher to specify classes. These methods still result in each protein being assigned a single label.</p><p>However, not all proteins can be thus characterized. In particular, there are many proteins that exhibit &#x02018;mixed patterns&#x02019;, i.e. patterns that are composed of more than one location. For example, while some proteins locate in the nucleus and others locate in the endoplasmic reticulum, there is a third group that locates in both of these locations. A simple class assignment does not adequately represent the relationship between these three possibilities. One alternative is to assign multiple labels to a single pattern. In one large-scale study of the yeast proteome, a third of proteins were annotated with multiple locations, which demonstrates that this is not a problem confined to &#x02018;special case&#x02019; proteins (Chen <italic>et al.</italic>, <xref ref-type="bibr" rid="B2">2007</xref>; Huh <italic>et al.</italic>, <xref ref-type="bibr" rid="B8">2003</xref>). However, this approach fails to quantify the contribution of each element and shows the need for a system that directly models the mixture phenomenon.</p><p>We have previously presented some methods that address this pattern unmixing problem in a supervised setting: given images of fundamental patterns (e.g. nuclear and endoplasmic reticulum in the above example) and mixed images, map mixed images into a set of coefficients, one for each fundamental pattern (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B11">2010</xref>; Zhao <italic>et al.</italic>, <xref ref-type="bibr" rid="B14">2005</xref>). These methods were observed to perform well on both synthetic and real data in recovering the underlying mixture coefficients (which had been kept hidden from the algorithm).</p><p>However, the supervised approach still requires the researcher to specify the fundamental patterns of which other patterns are composed. For example, for the quantitative analysis of translocation experiments as a function of time or drug concentration, the extreme points could be easily identified as the patterns of interest. However, they are still inapplicable to proteome-wide studies where it would be a difficult (and perhaps impossible) task to identify all fundamental patterns that are present. We note that the set of fundamental patterns that can be identified depends both on the specific cell type and the technology used for imaging, high-resolution confocal microscopes being able to distinguish patterns that lower resolution systems cannot.</p><p>Therefore, it is necessary to tackle the unsupervised pattern unmixing problem: given a large collection of images, where none has been tagged as being a representative of a fundamental pattern, map all images into a set of mixture coefficients automatically derived from the data.</p><p>In this article, we present and compare methods to address this problem using a test dataset previously created to test supervised unmixing methods (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B11">2010</xref>).</p></sec><sec sec-type="methods" id="SEC2"><title>2 METHODS</title><sec id="SEC2.1"><title>2.1 Object typing</title><sec id="SEC2.1.1"><title>2.1.1 Overview</title><p>All the methods developed for this problem so far are based on a bag of objects model, where an image is interpreted as a collection of regions of above-background fluorescence. Each object is then characterized by a small set of object features, and objects are clustered into groups (object types). Patterns are then defined as distributions over these groups. This is illustrated in <xref ref-type="fig" rid="F1">Figure 1</xref>.
<fig id="F1" position="float"><label>Fig. 1.</label><caption><p>Overview of unmixing methods. (<bold>a</bold>) The algorithms use a collection of images as input in which various concentrations of two probes are present (the concentrations of the Mitotracker and Lysotracker probes are shown by increasing intensity of red and green, respectively). Example images are shown from wells containing only Mitotracker (<bold>b</bold>), only Lysotracker (<bold>c</bold>) and a mixture of the two probes (<bold>d</bold>). (<bold>e</bold>) Objects with different size and shapes are extracted and object features are calculated. (<bold>f</bold>) Objects are clustered into groups in feature space, shown with different colors. (<bold>g</bold>) Fundamental patterns are identified and the fractions they contribute to each image are estimated.</p></caption><graphic xlink:href="btq220f1"/></fig></p><p>The intuition is to capture patterns such as the fact that lysosomes are small mostly circular objects, while mitochondria consist of stringy objects. The methods need to be robust to stochastic variation, however, as mitochondrial patterns are also observed to contain circular objects and agglomerations of lysosomes may appear as a single stringy object. In fact, the algorithms need to capture not only the fact that mitochondrial patterns are composed of stringy objects, but also that the proportions of different types of objects are present in statistically different proportions.</p></sec><sec id="SEC2.1.2"><title>2.1.2 Image preprocessing and segmentation</title><p>Images are first preprocessed to remove uneven illumination. The illumination bias is estimated by fitting a plane to the average pixel intensity at each location across the whole collection of images. Every image pixel is then divided by this illumination estimate to regularize across the whole image.</p><p>Images are segmented by using the model-based method of Lin <italic>et al.</italic> (<xref ref-type="bibr" rid="B10">2003</xref>) on the nuclear channel, which was previously found to give the best results for images in the unmixing test dataset (Coelho <italic>et al.</italic>, <xref ref-type="bibr" rid="B3">2009</xref>). The segmentation is extended to the whole field by using the watershed method with the segmented nuclei as seeds.</p></sec><sec id="SEC2.1.3"><title>2.1.3 Object detection</title><p>In our previous supervised unmixing work, objects were simply defined as contiguous pixel regions above a global threshold. In the work described here, we use both a global threshold, using the Ridler&#x02013;Calvard method (Ridler and Calvard, <xref ref-type="bibr" rid="B13">1978</xref>), and a local threshold, the mean pixel value of a 15 &#x000d7; 15 window centered at the pixel. We have found that the global threshold achieves a good separation of the general cell areas from the background, while, inside those regions, local thresholding is better at capturing detail.</p><p>Objects that are smaller than 5 pixels are filtered out.</p></sec><sec id="SEC2.1.4"><title>2.1.4 Object features</title><p>Each object is characterized by a set of features, previously defined as SOF1 (subcellular object features 1). This is a combination of morphological features for describing the shape and size of the object and features which capture the relationship to the nuclear marker (Zhao <italic>et al.</italic>, <xref ref-type="bibr" rid="B14">2005</xref>):
<list list-type="order"><list-item><p>Size (in pixels) of the object.</p></list-item><list-item><p>Distance of object center of fluorescence to DNA center of fluorescence.</p></list-item><list-item><p>Fraction of object that overlaps with DNA.</p></list-item><list-item><p>Eccentricity of object hull.</p></list-item><list-item><p>Euler number of object.</p></list-item><list-item><p>Shape factor of convex hull.</p></list-item><list-item><p>Size of object skeleton.</p></list-item><list-item><p>Fraction of overlap between object convex hull and object.</p></list-item><list-item><p>Fraction of binary object that is skeleton.</p></list-item><list-item><p>Fraction of fluorescence contained in skeleton.</p></list-item><list-item><p>Fraction of binary object that constitutes branch points in the skeleton.</p></list-item></list>
</p></sec><sec id="SEC2.1.5"><title>2.1.5 Object clustering</title><p>In order to be able to reason about object types, objects are clustered into groups using <italic>k</italic>-means on the <italic>z</italic>-scored feature space. Multiple values of <italic>k</italic> are tried and the one resulting in the lowest BIC (Bayesian information criterion) score is selected.</p><p>Based on this clustering, each object can be assigned a numerical identifier, its cluster index, which serves as its type.</p><p>After this step, the algorithms diverge in how they handle the cluster indices.</p></sec></sec><sec id="SEC2.2"><title>2.2 Basis pursuit</title><p>In this model, each image is represented by a vector <bold><italic>x</italic></bold><sup>(<italic>i</italic>)</sup> such that entry <bold><italic>x</italic></bold><sup>(<italic>i</italic>)</sup><sub>&#x02113;</sub> represents the fraction of objects in condition <italic>i</italic> that have type &#x02113; (if there are multiple images for the same condition, a common situation, they are counted together). We have one vector per input condition (i.e. <italic>i</italic> = 1,&#x02026;, <italic>C</italic>, where <italic>C</italic> is the number of conditions), and the size of this vector is the number of clusters that was automatically identified in the clustering step (i.e. &#x02113; = 1,&#x02026;, <italic>k</italic>).</p><p>Using fractions instead of the direct object counts normalizes for the different number of cells in each image and different cell sizes.</p><p>In this model, bases (fundamental patterns) are represented as a set of vectors in the same space and a mixture is defined by a set of coefficients &#x003b1;<sub><italic>j</italic></sub> for each <bold><italic>b</italic></bold><sup>(<italic>j</italic>)</sup> (<italic>j</italic> = 1,&#x02026;, <italic>B</italic>, where <italic>B</italic> is the number of basis vectors, and each <bold><italic>b</italic></bold><sup>(<italic>j</italic>)</sup> is of the same dimension as the <bold><italic>x</italic></bold><sup>(<italic>i</italic>)</sup><italic>s</italic>):
<disp-formula id="M1"><label>(1)</label><graphic xlink:href="btq220m1"/></disp-formula>
where <bold>&#x003b5;</bold><sup>(<italic>i</italic>)</sup> encapsulates both the stochastic nature of the mixing process and the measurement noise.</p><p>Given a set of observations, the task is to identify the bases <bold><italic>b</italic></bold><sup>(<italic>j</italic>)</sup> and coefficients <bold>&#x003b1;</bold><sup>(<italic>i</italic>)</sup>, which minimize the squared norm of the error terms &#x02211;<sub><italic>i</italic></sub>&#x02016;<bold>&#x003b5;</bold><sup>(<italic>i</italic>)</sup>&#x02016;<sup>2</sup>.</p><p>Without additional constraints, principal component analysis (PCA) is the simplest solution to this problem. However, this is unsatisfactory as it could result in negative mixtures, which are not meaningful. Independent component analysis (ICA) suffers from the same problem. Therefore, we add a non-negativity constraint on the vector <bold>&#x003b1;</bold> and use non-negative matrix factorization (NNMF) possibly with sparsity constraints to solve the problem (Hoyer <italic>et al.</italic>, <xref ref-type="bibr" rid="B7">2004</xref>; Lee and Seung, <xref ref-type="bibr" rid="B9">1999</xref>).</p><p>An additional constraint can be helpful to obtain more meaningful results: require the basis vectors to be members of the input dataset (i.e. for all <italic>j</italic>, there is some <italic>i</italic>, such that <bold><italic>b</italic></bold><sup>(<italic>j</italic>)</sup> = <bold><italic>x</italic></bold><sup>(<italic>i</italic>)</sup>). This condition, which encapsulates the expectation that the input dataset is large enough to contain both fundamental and mixed patterns, requires a search method.</p><p>Some preliminary results showed that this model was still too sensitive to the trend, i.e. to the average value of <italic>x</italic><sub><italic>i</italic>,<italic>j</italic></sub> across the dataset (data not shown). If one basis vector was allocated to handle this trend, good fits were obtained but poor interpretability. We found that removing the mean from the data led to more meaningful results. In this detrended dataset, <inline-formula><inline-graphic xlink:href="btq220i1.jpg"/></inline-formula> may take negative values, but the mixing coefficients &#x003b1;<sub><italic>i</italic>,<italic>j</italic></sub> are still constrained to be non-negative.</p><p>Thus, the final optimization problem is:
<disp-formula id="M2"><label>(2)</label><graphic xlink:href="btq220m2"/></disp-formula>
<disp-formula id="M3"><label>(3)</label><graphic xlink:href="btq220m3"/></disp-formula>
<disp-formula id="M4"><label>(4)</label><graphic xlink:href="btq220m4"/></disp-formula></p><p>Subject to the constraint, that for all <italic>j</italic>, there exists an <italic>i</italic>, such that <bold><italic>b</italic></bold><sup>(<italic>j</italic>)</sup> = <bold><italic>x</italic></bold><sup>(<italic>i</italic>)</sup>. In order to find the best basis, we resort to simulated annealing as an optimization method. In this class of methods, the number of fundamental patterns <italic>B</italic> must be prespecified by the user.</p><p>PCA and ICA were also performed on detrended data, but NNMF could not be (as the detrended data contains negative numbers, it cannot be the product of two positive matrices). Before applying NNMF, we therefore removed very frequent objects (those that appeared in more than 90% of the images). The intuition is that very frequent objects also correspond to the background.</p></sec><sec id="SEC2.3"><title>2.3 Latent Dirichlet allocation</title><p>Topic modeling in text using latent Dirichlet allocation (LDA) is a popular technique to solve an analogous class of problems (Blei <italic>et al.</italic>, <xref ref-type="bibr" rid="B1">2003</xref>). In this framework, documents are seen as simple &#x02018;bags of words&#x02019; and topics are distributions over words. Observed bags of words can be generated by choosing mixture coefficients for topics followed by a generation of words according to: pick a topic from which to generate, then pick a word from that topic.</p><p>In our setting, we view object classes as visual words over which to run LDA. This is similar to work by other researchers in computer vision which use keypoints to define visual words (Csurka <italic>et al.</italic>, <xref ref-type="bibr" rid="B4">2004</xref>; Philbin <italic>et al.</italic>, <xref ref-type="bibr" rid="B12">2008</xref>; Zhu <italic>et al.</italic>, <xref ref-type="bibr" rid="B15">2009</xref>).</p><p>The process of generating objects in images to represent mixtures of multiple fundamental patterns follows the Bayesian network in <xref ref-type="fig" rid="F2">Figure 2</xref>. The generative process is as follows: for each of <italic>M</italic> images, a mixture <bold>&#x003b8;</bold><sub><italic>i</italic></sub> is first sampled (conditioned on the hyper-parameter &#x003b1;). <bold>&#x003b8;</bold><sub><italic>i</italic></sub> is a vector of fractions of the fundamental pattern distributions <bold><italic>b</italic></bold>. <italic>N</italic><sub><italic>i</italic></sub> objects are sampled for each image in two steps: select a basis pattern according to <bold><italic>t</italic></bold>&#x003b8;<sub><italic>i</italic></sub> and then an object is sampled from the corresponding object type distribution.
<fig id="F2" position="float"><label>Fig. 2.</label><caption><p>LDA for unmixing. &#x003b1; represents the prior on the topics, &#x003b8; is the topic mixture parameter (one for each of <italic>M</italic> images), <italic>z</italic> represents the particular object topic which is combined with &#x003b2;, the topic distributions to generate an object of type <italic>w</italic>.</p></caption><graphic xlink:href="btq220f2"/></fig></p><p>To invert this generative process, we used the <italic>variational EM</italic> algorithm of Blei <italic>et al.</italic> (<xref ref-type="bibr" rid="B1">2003</xref>) to estimate the model parameters of fundamental patterns <bold>&#x003b2;</bold> and mixture fractions <bold>&#x003b8;</bold>. It should be noted that this is an approximation approach liable to getting trapped in local maxima and returning non-optimal results. Therefore, we ran the algorithm multiple times with different random initializations and chose the one with the highest log-likelihood.</p><p>We choose the number of fundamental patterns <italic>B</italic> to maximize the log likelihood on a held-out dataset (using cross-validation to obtain more accurate estimate).</p></sec></sec><sec sec-type="results" id="SEC3"><title>3 RESULTS</title><sec id="SEC3.1"><title>3.1 Dataset</title><p>In order to validate the algorithms, we used a test set that was built to evaluate pattern unmixing algorithms (Peng <italic>et al.</italic>, <xref ref-type="bibr" rid="B11">2010</xref>).</p><p>In this dataset, <sc>u2os</sc> cells were exposed to different concentrations of two fluorescent probes with differing localization profiles (mitochondrial and lysosomal) but similar fluorescence. The probes were image using the same fluorescence filter and therefore could not be distinguished. This simulates the situation in which a fluorophore is present in two different locations. For each probe, eight concentrations were used, for a total of 64 combinations.</p><p>In parallel to the marker image, a nuclear marker was imaged to serve as a reference point.</p></sec><sec id="SEC3.2"><title>3.2 Computation time</title><p>Most of the computation time is dominated by segmenting the images (&#x0223c;30 s per image in our implementation) and computing features (&#x0223c;10 s per image). However, this is an embarrassingly parallel problem and can be computed on multiple machines simultaneously. The clustering takes increasing time for different numbers of clusters, but we limited each clustering run to &#x0223c;1 h (while relying on multiple initialization as a guard against local minima). Again, we note that the runs for multiple <italic>k</italic> can easily be run in parallel. Both basis pursuit and LDA then take only on the order of minutes to run.</p></sec><sec id="SEC3.3"><title>3.3 Basis pursuit</title><p>We measured how well the identified coefficients &#x003b1;<sup>(<italic>i</italic>)</sup><sub><italic>j</italic></sub> correlated with the underlying fractions, which were estimated as linearly proportional to the ratio of the relative concentration of the mitochondrial probe to the sum of the relative concentration of the mitochondrial and lysosomal probes (relative concentration is defined as fraction of the maximum subsaturating concentration).</p><p>Using PCA, the correlation coefficient between predicted fractions and the underlying relative concentrations was 0.20. NNMF performed better on this metric, achieving a correlation coefficient of 0.65. Independent component analysis performed very poorly, returning correlations on the order of less than 0.10. This is not unexpected as the independence assumptions that underly ICA fail to hold even as an approximation.</p><p>However, we are also interested in having the basis vectors line up with the underlying fundamental patterns and, in this regard, NNMF performs poorly. One of the patterns corresponded roughly to the total concentration and they did not align well with the fundamental patterns in the data (data not shown).</p><p>The fully constrained basis pursuit algorithm performed better. It achieved a 0.80 correlation with the underlying relative concentration. It identified as a basis a vector that has the maximal concentration of the mitochondrial probe (and some lysosomal probe, at a relative concentration of 19%) and another that consists of the maximal concentration of the lysosomal probe and 20% mitochondrial probe. <xref ref-type="table" rid="T1">Table 1</xref> shows that the identified pattern 0 matches the mitochondrial probe, while pattern 1 matches the lysosomal probe.
<table-wrap id="T1" position="float"><label>Table 1.</label><caption><p>Unmixed coefficients for images of fundamental patterns and mixed samples using basis pursuit with <italic>B</italic> = 2</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">Mitochondrial (%)</th><th align="left" rowspan="1" colspan="1">Lysosomal (%)</th></tr></thead><tbody align="left"><tr><td align="left" rowspan="1" colspan="1">Pattern 0</td><td align="left" rowspan="1" colspan="1"><bold>99</bold></td><td align="left" rowspan="1" colspan="1">18</td></tr><tr><td align="left" rowspan="1" colspan="1">Pattern 1</td><td align="left" rowspan="1" colspan="1">1</td><td align="left" rowspan="1" colspan="1"><bold>82</bold></td></tr></tbody></table><table-wrap-foot><fn><p>For the two fundamental patterns, we display the average coefficient for the inferred fundamental patterns.</p></fn></table-wrap-foot></table-wrap>
</p><p>The results above were obtained by specifying <italic>B</italic> = 2 as an input to the algorithm. For different values of <italic>B</italic>, we obtain decreasing reconstruction error as plotted in <xref ref-type="fig" rid="F3">Figure 3</xref>. As it is clear in this figure, most of the contribution to the reconstruction comes from the first two or three vectors. Therefore, we can expect that a researcher would be able to estimate <italic>B</italic> = 2 or <italic>B</italic> = 3.
<fig id="F3" position="float"><label>Fig. 3.</label><caption><p>Average squared reconstruction error as a function of the number of patterns <italic>B</italic> for basis pursuit. This is the value of &#x02211;<sub><italic>i</italic></sub> &#x02016;<bold>&#x003b5;</bold>&#x02016;<sup>2</sup> in (<xref ref-type="disp-formula" rid="M2">2</xref>). For <italic>B</italic> = 0, we show the total variance, i.e. <inline-formula><inline-graphic xlink:href="btq220i2.jpg"/></inline-formula></p></caption><graphic xlink:href="btq220f3"/></fig></p></sec><sec id="SEC3.4"><title>3.4 LDA</title><p>To estimate the number of fundamental patterns using the LDA approach, we measured the log likelihood of the dataset for different numbers of bases using cross-validation. The results are shown in <xref ref-type="fig" rid="F4">Figure 4</xref>. We can see that the best result is obtained for <italic>B</italic> = 3, although the underlying dataset only has two fundamental patterns.
<fig id="F4" position="float"><label>Fig. 4.</label><caption><p>Log likelihood as a function of the number of fundamental patterns.</p></caption><graphic xlink:href="btq220f4"/></fig></p><p><xref ref-type="table" rid="T2">Table 2</xref> shows the average coefficients inferred for pure pattern inputs after the algorithm had been applied on the whole dataset. Pattern 1 obviously corresponds to the lysosomal component, while pattern 2 corresponds to the mitochondrial component. Pattern 0 appears to be a &#x02018;non-significant&#x02019; pattern capturing the new object types arising in the mixture patterns. The overall correlation coefficient is 0.95 with pattern 0 removed.
<table-wrap id="T2" position="float"><label>Table 2.</label><caption><p>Unmixed coefficients for fundamental patterns and mixed samples for the discovered patterns (using LDA method)</p></caption><table frame="hsides" rules="groups"><thead align="left"><tr><th rowspan="1" colspan="1"/><th align="left" rowspan="1" colspan="1">Mitochondrial (%)</th><th align="left" rowspan="1" colspan="1">Lysosomal (%)</th></tr></thead><tbody align="left"><tr><td align="left" rowspan="1" colspan="1">Pattern 0</td><td align="left" rowspan="1" colspan="1">0.0</td><td align="left" rowspan="1" colspan="1">0.0</td></tr><tr><td align="left" rowspan="1" colspan="1">Pattern 1</td><td align="left" rowspan="1" colspan="1">8.8</td><td align="left" rowspan="1" colspan="1"><bold>99.9</bold></td></tr><tr><td align="left" rowspan="1" colspan="1">Pattern 2</td><td align="left" rowspan="1" colspan="1"><bold>91.2</bold></td><td align="left" rowspan="1" colspan="1">0.1</td></tr></tbody></table><table-wrap-foot><fn><p>For the two fundamental patterns, we display the average coefficient for the three discovered fundamental patterns.</p></fn></table-wrap-foot></table-wrap>
</p><p>Using the LDA approach with <italic>B</italic> = 2, which is the ground truth, the overall correlation coefficient between estimated and actual pattern fractions was found to be 0.91.</p></sec><sec id="SEC3.5"><title>3.5 Comparisons</title><p><xref ref-type="fig" rid="F5">Figure 5</xref> shows the results of one inferred fraction as a function of the underlying concentrations (the plots for the other fraction, not shown, are, of course, symmetric as they sum to 1). <xref ref-type="fig" rid="F6">Figure 6</xref> plots all the estimates in a single plot as a function of the underlying concentration fractions.
<fig id="F5" position="float"><label>Fig. 5.</label><caption><p>Comparison of results for different unmixing methods. The inferred fraction of pattern 1 is displayed as different intensities of gray (black corresponding to pure pattern 1). The design matrix, which was kept hidden from the algorithms is shown on the top left, for comparison; the other three panels are results of computation.</p></caption><graphic xlink:href="btq220f5"/></fig>
<fig id="F6" position="float"><label>Fig. 6.</label><caption><p>Estimated concentration as a function of the underlying relative probe concentration. Perfect result would be along the dashed diagonal. In LDA unmixing with 3 fundamental patterns, fractions of the two major patterns are normalized and plotted over ground-truth.</p></caption><graphic xlink:href="btq220f6"/></fig></p></sec></sec><sec sec-type="discussion" id="SEC4"><title>4 DISCUSSION</title><p>We have described two approaches for performing unsupervised unmixing of subcellular location patterns, and demonstrated good performance with both on a test dataset acquired by high-throughput microscopy and previously used for testing supervised methods.</p><p>In our supervised work, we had presented two methods, one based on a linear mixture, whose adaptation to the unsupervised case results in the basis pursuit method described here, and another based on multinomial mixtures, which results in the LDA model.</p><p>The newer LDA model led to slightly better results than the basis pursuit method. This model has the apparent disadvantage that it does not return examples of the underlying patterns, which could potentially make interpretation harder. However, we observed that this was, empirically, not a major issue as the identified bases were indeed well aligned with the underlying (hidden) concentrations as opposed to forming a complex mixture with a difficult interpretation.</p><p>The methods are comparable in terms of computational cost as it is the image processing, feature computation and, particularly, the <italic>k</italic>-means clustering that has the highest cost (the clustering is done over objects and even this evaluation set of &#x0223c;12 K images resulted in &#x0223c;750 K objects). Once the clustering is done, both algorithms are very fast. Therefore, in their current forms, the LDA algorithm is superior.</p><p>It is notable that both unsupervised methods led to higher correlation with the underlying coefficients than the supervised methods. A possible cause of this is the appearance of new object types in the mixture patterns. Under the unsupervised framework, with massive clustering, these objects might be assigned labels different from the ones of the fundamental patterns, while in the supervised version they are forced to be one of the object types present in the fundamental patterns. To prove this conjecture, we assumed that such new types of objects really exist and applied the outlier removal technique of Peng <italic>et al.</italic> (<xref ref-type="bibr" rid="B11">2010</xref>) to perform supervised unmixing again, in the hope of removing the influence of these objects. The correlations increased to 0.91 and 0.88 with linear and multinomial unmixing approaches, respectively, which are comparable with the unsupervised results.</p><p>Based on the results presented here, we plan to apply the unsupervised unmixing methods to large-scale image collections with the goal of identifying both the set of all fundamental patterns and of quantitating for the first time the fraction of all proteins that are present in each.</p></sec></body><back><ack><title>ACKNOWLEDGMENTS</title><p>The authors thank Ghislain Bonami, Sumit Chanda and Daniel Rines for providing images as well as many helpful discussions.</p><p><italic>Funding</italic>: <funding-source>National Institutes of Health</funding-source> (grant <award-id>GM075205</award-id>); Funda&#x000e7;&#x000e3;o para a Ci&#x000ea;ncia e Tecnologia (grant SFRH/BD/37535/2007 to L.P.C., partially); fellowship from the Fulbright Program (to L.P.C.).</p><p><italic>Conflict of Interest</italic>: none declared.</p></ack><ref-list><title>REFERENCES</title><ref id="B1"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Blei</surname><given-names>DM</given-names></name><etal/></person-group><article-title>Latent Dirichlet allocation</article-title><source>J. Mach. Learn. Res.</source><year>2003</year><volume>3</volume><fpage>993</fpage><lpage>1022</lpage></element-citation></ref><ref id="B2"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>S.-C</given-names></name><etal/></person-group><article-title>Automated image analysis of protein localization in budding yeast</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><fpage>i66</fpage><lpage>i71</lpage><pub-id pub-id-type="pmid">17646347</pub-id></element-citation></ref><ref id="B3"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Coelho</surname><given-names>LP</given-names></name><etal/></person-group><article-title>Nuclear segmentation in microscope cell images: a hand-segmented dataset and comparison of algorithms</article-title><source>Proceedings of the 2009 IEEE International Symposium on Biomedical Imaging.</source><year>2009</year><publisher-loc>Piscataway, NJ, USA</publisher-loc><publisher-name>IEEE</publisher-name><fpage>518</fpage><lpage>521</lpage></element-citation></ref><ref id="B4"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Csurka</surname><given-names>G</given-names></name><etal/></person-group><article-title>Visual categorization with bags of keypoints</article-title><source>Workshop on Statistical Learning in Computer Vision</source><year>2004</year><publisher-loc>Prague, Czech Republic</publisher-loc><publisher-name>ECCV</publisher-name><fpage>1</fpage><lpage>22</lpage></element-citation></ref><ref id="B5"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garc&#x000ed;a Osuna</surname><given-names>E</given-names></name><etal/></person-group><article-title>Large-scale automated analysis of location patterns in randomly tagged 3T3 cells</article-title><source>Ann. Biomed. Eng.</source><year>2007</year><volume>35</volume><fpage>1081</fpage><lpage>1087</lpage><pub-id pub-id-type="pmid">17285363</pub-id></element-citation></ref><ref id="B6"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hamilton</surname><given-names>NA</given-names></name><etal/></person-group><article-title>Statistical and visual differentiation of subcellular imaging</article-title><source>BMC Bioinformatics</source><year>2009</year><volume>10</volume><fpage>94</fpage><pub-id pub-id-type="pmid">19302715</pub-id></element-citation></ref><ref id="B7"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hoyer</surname><given-names>PO</given-names></name></person-group><article-title>Non-negative matrix factorization with sparseness constraints</article-title><source>J. Mach. Learn. Res.</source><year>2004</year><volume>5</volume><fpage>1457</fpage><lpage>1469</lpage></element-citation></ref><ref id="B8"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huh</surname><given-names>W.-K</given-names></name><etal/></person-group><article-title>Global analysis of protein localization in budding yeast</article-title><source>Nature</source><year>2003</year><volume>425</volume><fpage>686</fpage><lpage>691</lpage><pub-id pub-id-type="pmid">14562095</pub-id></element-citation></ref><ref id="B9"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lee</surname><given-names>DD</given-names></name><name><surname>Seung</surname><given-names>HS</given-names></name></person-group><article-title>Learning the parts of objects by non-negative matrix factorization</article-title><source>Nature</source><year>1999</year><volume>401</volume><fpage>788</fpage><lpage>791</lpage><pub-id pub-id-type="pmid">10548103</pub-id></element-citation></ref><ref id="B10"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lin</surname><given-names>G</given-names></name><etal/></person-group><article-title>A hybrid 3D watershed algorithm incorporating gradient cues and object models for automatic segmentation of nuclei in confocal image stacks</article-title><source>Cytometry A</source><year>2003</year><volume>56A</volume><fpage>23</fpage><lpage>36</lpage><pub-id pub-id-type="pmid">14566936</pub-id></element-citation></ref><ref id="B11"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Peng</surname><given-names>T</given-names></name><etal/></person-group><article-title>Determining the distribution of probes between different subcellular locations through automated unmixing of subcellular patterns</article-title><source>Proc. Natl Acad. Sci. USA</source><year>2010</year><volume>107</volume><fpage>2944</fpage><lpage>2949</lpage><pub-id pub-id-type="pmid">20133616</pub-id></element-citation></ref><ref id="B12"><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Philbin</surname><given-names>J</given-names></name><etal/></person-group><article-title>Geometric LDA: a generative model for particular object discovery</article-title><source>Proceedings of the British Machine Vision Conference</source><year>2008</year><publisher-loc>Leeds, UK</publisher-loc></element-citation></ref><ref id="B13"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ridler</surname><given-names>T</given-names></name><name><surname>Calvard</surname><given-names>S</given-names></name></person-group><article-title>Picture thresholding using an iterative selection method</article-title><source>IEEE Trans. Syst. Man Cybernet.</source><year>1978</year><volume>8</volume><fpage>630</fpage><lpage>632</lpage></element-citation></ref><ref id="B14"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhao</surname><given-names>T</given-names></name><etal/></person-group><article-title>Object type recognition for automated analysis of protein subcellular location</article-title><source>IEEE Trans. Image Process.</source><year>2005</year><volume>14</volume><fpage>1351</fpage><lpage>1359</lpage><pub-id pub-id-type="pmid">16190470</pub-id></element-citation></ref><ref id="B15"><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhu</surname><given-names>L</given-names></name><etal/></person-group><article-title>Unsupervised learning of probabilistic grammar-Markov models for object categories</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2009</year><volume>31</volume><fpage>114</fpage><lpage>128</lpage><pub-id pub-id-type="pmid">19029550</pub-id></element-citation></ref></ref-list></back></article>