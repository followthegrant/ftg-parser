<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Neurosci</journal-id><journal-id journal-id-type="iso-abbrev">Front Neurosci</journal-id><journal-id journal-id-type="publisher-id">Front. Neurosci.</journal-id><journal-title-group><journal-title>Frontiers in Neuroscience</journal-title></journal-title-group><issn pub-type="ppub">1662-4548</issn><issn pub-type="epub">1662-453X</issn><publisher><publisher-name>Frontiers Media S.A.</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">23898236</article-id><article-id pub-id-type="pmc">3721006</article-id><article-id pub-id-type="doi">10.3389/fnins.2013.00129</article-id><article-categories><subj-group subj-group-type="heading"><subject>Neuroscience</subject><subj-group><subject>Original Research Article</subject></subj-group></subj-group></article-categories><title-group><article-title>Comparison of tactile, auditory, and visual modality for brain-computer interface use: a case study with a patient in the locked-in state</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kaufmann</surname><given-names>Tobias</given-names></name><xref ref-type="author-notes" rid="fn001"><sup>*</sup></xref></contrib><contrib contrib-type="author"><name><surname>Holz</surname><given-names>Elisa M.</given-names></name></contrib><contrib contrib-type="author"><name><surname>K&#x000fc;bler</surname><given-names>Andrea</given-names></name></contrib></contrib-group><aff><institution>Department for Psychology I, Institute for Psychology, University of W&#x000fc;rzburg</institution><country>W&#x000fc;rzburg, Germany</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Emanuel Donchin, University of South Florida, USA</p></fn><fn fn-type="edited-by"><p>Reviewed by: Eric W. Sellers, East Tennessee State University, USA; Yael Arbel, University of South Florida, USA; Dean Krusienski, Old Dominion University, USA</p></fn><corresp id="fn001">*Correspondence: Tobias Kaufmann, Department for Psychology I, Institute for Psychology, University of W&#x000fc;rzburg, Marcusstr. 9-11, 97070 W&#x000fc;rzburg, Germany e-mail: <email xlink:type="simple">tobias.kaufmann@uni-wuerzburg.de</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Frontiers in Neuroprosthetics, a specialty of Frontiers in Neuroscience.</p></fn></author-notes><pub-date pub-type="epub"><day>24</day><month>7</month><year>2013</year></pub-date><pub-date pub-type="collection"><year>2013</year></pub-date><volume>7</volume><elocation-id>129</elocation-id><history><date date-type="received"><day>26</day><month>3</month><year>2013</year></date><date date-type="accepted"><day>05</day><month>7</month><year>2013</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2013 Kaufmann, Holz and K&#x000fc;bler.</copyright-statement><copyright-year>2013</copyright-year><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This is an open-access article distributed under the terms of the Creative Commons Attribution License, which permits use, distribution and reproduction in other forums, provided the original authors and source are credited and subject to any copyright notices concerning any third-party graphics etc.</license-p></license></permissions><abstract><p>This paper describes a case study with a patient in the classic locked-in state, who currently has no means of independent communication. Following a user-centered approach, we investigated event-related potentials (ERP) elicited in different modalities for use in brain-computer interface (BCI) systems. Such systems could provide her with an alternative communication channel. To investigate the most viable modality for achieving BCI based communication, classic oddball paradigms (1 rare and 1 frequent stimulus, ratio 1:5) in the visual, auditory and tactile modality were conducted (2 runs per modality). Classifiers were built on one run and tested offline on another run (and vice versa). In these paradigms, the tactile modality was clearly superior to other modalities, displaying high offline accuracy even when classification was performed on single trials only. Consequently, we tested the tactile paradigm online and the patient successfully selected targets without any error. Furthermore, we investigated use of the visual or tactile modality for different BCI systems with more than two selection options. In the visual modality, several BCI paradigms were tested offline. Neither matrix-based nor so-called gaze-independent paradigms constituted a means of control. These results may thus question the gaze-independence of current gaze-independent approaches to BCI. A tactile four-choice BCI resulted in high offline classification accuracies. Yet, online use raised various issues. Although performance was clearly above chance, practical daily life use appeared unlikely when compared to other communication approaches (e.g., partner scanning). Our results emphasize the need for user-centered design in BCI development including identification of the best stimulus modality for a particular user. Finally, the paper discusses feasibility of EEG-based BCI systems for patients in classic locked-in state and compares BCI to other AT solutions that we also tested during the study.</p></abstract><kwd-group><kwd>brain-computer interface</kwd><kwd>tactile auditory and visual modality</kwd><kwd>locked-in syndrome</kwd><kwd>user-centered design</kwd><kwd>end-user testing</kwd><kwd>assistive technology</kwd></kwd-group><counts><fig-count count="7"/><table-count count="1"/><equation-count count="0"/><ref-count count="66"/><page-count count="12"/><word-count count="9325"/></counts></article-meta></front><body><sec id="s1"><title>Introduction</title><p>Damages to neuromuscular pathways, e.g., due to a stroke in the brainstem, or neurodegenerative diseases such as amyotrophic lateral sclerosis (ALS) or spinal muscular atrophy (SMA) can entail a severe loss of voluntary muscular control. These patients are summarized under the term locked-in syndrome (LIS; Plum and Posner, <xref ref-type="bibr" rid="B45">1966</xref>) as they are locked into their own body despite often intact cognitive functioning. Patients in classic LIS are in total paralysis except for retaining control of vertical eye movements (Bauer et al., <xref ref-type="bibr" rid="B6">1979</xref>). Consequently, communication is severely restricted for patients in this state. They usually rely on communication partners and utilize remaining eye muscle control (blinking or moving eye-brows) to answer questions in the closed format (yes/no) or to select suggested options.</p><p>Brain-computer interfaces (BCIs) were proposed as an alternative communication channel bypassing the requirement for retaining muscular control (for review, e.g., K&#x000fc;bler et al., <xref ref-type="bibr" rid="B39">2001</xref>; Birbaumer and Cohen, <xref ref-type="bibr" rid="B9">2007</xref>; Birbaumer et al., <xref ref-type="bibr" rid="B10">2008</xref>; Allison et al., <xref ref-type="bibr" rid="B3">2012</xref>; Wolpaw and Wolpaw, <xref ref-type="bibr" rid="B61">2012</xref>). BCIs based on classification of event-related potentials (ERP) in the electroencephalogram (EEG) of a patient are most frequently used for communication purpose (Farwell and Donchin, <xref ref-type="bibr" rid="B18">1988</xref>; for review, e.g., Kleih et al., <xref ref-type="bibr" rid="B35">2011</xref>; Mak et al., <xref ref-type="bibr" rid="B44">2011</xref>; Sellers et al., <xref ref-type="bibr" rid="B54">2012</xref>). Several options (e.g., characters for typing words) are iteratively presented and users focus their attention on presentation of the one option they intend to select. Such target stimuli will elicit more pronounced ERPs than all other, irrelevant non-target stimuli. The procedure is thus referred to as oddball paradigm, as the target stimulus is rare compared to the frequent occurrence of irrelevant, non-target stimuli. ERP&#x02013;BCIs usually rely highly on the P300 component (Sutton et al., <xref ref-type="bibr" rid="B57">1965</xref>), a positive potential deflection occurring in the period of 200&#x02013;500 ms post-stimulus (for review, Polich, <xref ref-type="bibr" rid="B46">2007</xref>). Importantly, the P300 can be elicited in different modalities, i.e., visually, auditory or tactually. Thus, ERP&#x02013;BCIs relying on any of the three modalities have been introduced (visual, Farwell and Donchin, <xref ref-type="bibr" rid="B18">1988</xref>; auditory, Hill et al., <xref ref-type="bibr" rid="B22">2005</xref>; Sellers and Donchin, <xref ref-type="bibr" rid="B55">2006</xref>; tactile, Aloise et al., <xref ref-type="bibr" rid="B5">2007</xref>; Brouwer and Van Erp, <xref ref-type="bibr" rid="B11">2010</xref>; for review, Riccio et al., <xref ref-type="bibr" rid="B47">2012</xref>).</p><p>Visual ERP&#x02013;BCIs present characters for typing (or other selection options) on a screen. Usually, they are arranged in a matrix so that groups of characters can be stimulated at once, e.g., row/column wise (Farwell and Donchin, <xref ref-type="bibr" rid="B18">1988</xref>; for review, e.g., Sellers et al., <xref ref-type="bibr" rid="B54">2012</xref>). Stimulation can be performed by highlighting characters (i.e., light-flashing; Farwell and Donchin, <xref ref-type="bibr" rid="B18">1988</xref>) or, as recently proposed, by overlaying them with faces (e.g., Kaufmann et al., <xref ref-type="bibr" rid="B33">2011</xref>, <xref ref-type="bibr" rid="B31">2013a</xref>; Zhang et al., <xref ref-type="bibr" rid="B62">2012</xref>; Jin et al., <xref ref-type="bibr" rid="B28">2012</xref>). However, matrix based ERP&#x02013;BCIs may require accurate gaze control, therefore limiting its feasibility for people with LIS (Brunner et al., <xref ref-type="bibr" rid="B13">2010</xref>; Treder and Blankertz, <xref ref-type="bibr" rid="B59">2010</xref>). Thus, so-called gaze-independent paradigms have been suggested that present characters in the center of the screen (e.g., Acqualagna et al., <xref ref-type="bibr" rid="B2">2010</xref>; Treder and Blankertz, <xref ref-type="bibr" rid="B59">2010</xref>; Liu et al., <xref ref-type="bibr" rid="B42">2011</xref>; Aloise et al., <xref ref-type="bibr" rid="B4">2012</xref>; Acqualagna and Blankertz, <xref ref-type="bibr" rid="B1">2013</xref>).</p><p>Auditory ERP&#x02013;BCIs present sound stimuli that may differ in terms of volume, pitch, direction or combinations of those (e.g., Hill et al., <xref ref-type="bibr" rid="B22">2005</xref>; Halder et al., <xref ref-type="bibr" rid="B20">2010</xref>; H&#x000f6;hne et al., <xref ref-type="bibr" rid="B23">2010</xref>, <xref ref-type="bibr" rid="B24">2011</xref>; Schreuder et al., <xref ref-type="bibr" rid="B50">2010</xref>, <xref ref-type="bibr" rid="B52">2011a</xref>, <xref ref-type="bibr" rid="B51">2013</xref>; K&#x000e4;thner et al., <xref ref-type="bibr" rid="B30">2013</xref>) or differ with regard to informational content (e.g., Sellers and Donchin, <xref ref-type="bibr" rid="B55">2006</xref>; Furdea et al., <xref ref-type="bibr" rid="B19">2009</xref>; Klobassa et al., <xref ref-type="bibr" rid="B36">2009</xref>; K&#x000fc;bler et al., <xref ref-type="bibr" rid="B38">2009</xref>). Furthermore, stimuli may be presented sequentially or as a continuous stream (e.g., Hill and Sch&#x000f6;lkopf, <xref ref-type="bibr" rid="B21">2012</xref>).</p><p>Tactile ERP&#x02013;BCIs utilize stimulation units (further referred to as tactors; e.g., vibration motors or piezo elements) placed at different body locations, e.g., on hands, around the waist or on the back of participants (e.g., Aloise et al., <xref ref-type="bibr" rid="B5">2007</xref>; Brouwer and Van Erp, <xref ref-type="bibr" rid="B11">2010</xref>; Brouwer et al., <xref ref-type="bibr" rid="B12">2010</xref>; Thurlings et al., <xref ref-type="bibr" rid="B58">2012</xref>; van der Waal et al., <xref ref-type="bibr" rid="B60">2012</xref>; Kaufmann et al., <xref ref-type="bibr" rid="B32">2013b</xref>). Users focus their attention on tactile stimulation of one location they intend to select (target stimulus) and ignore stimuli on all other locations.</p><p>Aloise et al. (<xref ref-type="bibr" rid="B5">2007</xref>) compared the modalities in terms of achieved classification accuracies of eight participants. Results yielded strong superiority of the visual modality in terms of higher ERP amplitudes and lower latencies, thus enhancing classification accuracy. Consequently, all participants achieved best accuracy with visual stimulation, except for one participant who achieved equal performance in tactile and visual modality. However, this study faces the limitation that all participants were healthy. As described above, patients in classic LIS have impaired vision and thus results may differ.</p><p>Herein we report a case study with a locked-in patient for who we aimed at developing a BCI for communication. To our knowledge, this is the first report on tactile ERP classification in a patient with classic LIS. We compared ERPs evoked in all three modalities, investigated reliability of classification and further explored issues involved in the use of visual paradigms. Finally, we emphasize the requirement for user-centered design in BCI development and discuss limitations of current EEG-based BCI systems compared to other assistive technology (AT).</p></sec><sec sec-type="materials|methods" id="s2"><title>Materials and methods</title><sec><title>The case</title><p>We visited a 46-year-old Italian woman twice for intensive testing on 7 days in total (first visit: 4 days; second visit: 3 days; with morning and afternoon testing sessions on most days). She had a brainstem stroke in the pons 7 years ago and since then has been in the classic locked-in state (for definition: Bauer et al., <xref ref-type="bibr" rid="B6">1979</xref>). As confirmed by computed tomography (CT), the lesion barely affected her cortical abilities and she was fully attentive during all testing sessions. During the last year, she has been regaining some (still unreliable) control of her right thumb. Still reliable communication is only possible with vertical eye movements (partner scanning). As she cannot well accommodate, her left eye was partially sutured to avoid double vision. With her right eye fixation was possible, but never for more than few seconds and thus, she had to re-focus constantly.</p><p>She currently has no means of independent communication, i.e., communication is only possible in a partner scanning approach. Her dialog partner suggests letters or statements in the closed format that she can either select/agree with (eyelift) or not select/disagree (looking down). To enhance communication speed the patient utilizes an interval approach, i.e., characters were sorted according to their importance in Italian daily language and grouped into four categories (Figure <xref ref-type="fig" rid="F1">1A</xref>). First, the dialog partner reads out the categories (&#x0201c;first, second, third, fourth&#x0201d;) and she selects one category. Next, the letters of the selected category are read out and again she makes a choice (&#x0201c;A, E, I, O, U&#x0201d; for the first category; &#x0201c;B, C, D, F, G&#x0201d; for the second; &#x0201c;H, L, M, N, P&#x0201d; for the third and &#x0201c;Q, R, S, T, V, Z&#x0201d; for the fourth category).</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>(A)</bold> Spelling system used by the patient in a partner scanning approach. Characters are grouped into four categories to increase spelling speed. <bold>(B)</bold> We developed a BCI system based on the partner scanning approach described in <bold>(A)</bold>. Four tactile stimulation units were placed on the patient's left arm. We individually adjusted the BCI paradigm to the partner scanning approach the patient is used to. Each tactor either represented one of the groups of characters, or represented a character of one prior selected group. Please note that we restricted the number of tactors to four, thus limiting the possible selections. Practical use of the system would require seven tactors (up to six tactors for selection of characters plus one tactor to undo a wrong selection).</p></caption><graphic xlink:href="fnins-07-00129-g0001"/></fig><p>The patient rated her quality of life as indexed by the <italic>ACSA</italic> [Anamnestic Comparative Self-Assessment Scale for Measuring the Subjective Quality of Life; scale from -5 (worst time in life) to 5 (best time in life); Bernheim and Buyse, <xref ref-type="bibr" rid="B8">1993</xref>] as the worst time in her life (ACSA = &#x02212;5). Asked for the reason, she answered &#x0201c;Desperate because I depend on others and I do not see a solution.&#x0201d; For 1 week prior to our first visit, caregivers daily assessed her mood and health as well as satisfaction with communication and nursing using questionnaires (linear scales from 0 [extremely bad] to 10 [excellent]). She rated mood low to medium (<italic>M</italic> = 5.0, range 3&#x02013;6) and health as slightly above medium (<italic>M</italic> = 5.6, range 5&#x02013;7). She had a cold prior to our first visit with fits of coughing leading to spasms. She was satisfied with nursing (<italic>M</italic> = 7.2, range 7&#x02013;8) but displayed greater variance with regard to satisfaction with communication (<italic>M</italic> = 5.8, range 2&#x02013;7). During our first stay, she reported one incidence where she had physical pain but was not able to call attention due to the absence of a communication partner. Establishing an independent communication ability is thus of utmost importance for her.</p><p>Prior to all testing sessions, we verbally informed the patient in detail about the procedure and obtained her consent to participate in the study through partner scanning. As no means of independent communication was possible, we asked her prior to every run if she agreed to proceed. The experiment was conducted in accordance with standard ethical guidelines as defined by the Declaration of Helsinki (World Medical Association) and the European Council's Convention for the Protection of Human Rights and Dignity of the Human Being with regard to the Application of Biology and Medicine (Convention on Human Rights and Biomedicine).</p><p>We approached the intended development of a BCI-based communication channel from a user-centered perspective targeting an individually tailored BCI solution for the patient. (1) We presented her with several classic oddball paradigms in three different modalities to identify the most promising modality for BCI use. (2) We tested different settings of BCI paradigms to explore emerging issues related to, e.g., system timing, gaze requirement, modality. Apart from BCI paradigms, we also tested other AT.</p></sec><sec><title>Experimental design</title><p>Figure <xref ref-type="fig" rid="F2">2</xref> illustrates the various different paradigms that were tested during the visits.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Illustration of paradigms and systems tested during the visits</bold>.</p></caption><graphic xlink:href="fnins-07-00129-g0002"/></fig><sec><title>Classic oddball paradigms</title><p>All tested oddball paradigms shared the same parameters except for the modality and stimulus duration (SD) (Figure <xref ref-type="fig" rid="F3">3</xref>). Two stimuli were presented with an inter-SD of 1000 ms and a rare to frequent ratio of 1:5. One run comprised 90 rare and 450 frequent stimuli. We conducted two runs per modality.</p><fig id="F3" position="float"><label>Figure 3</label><caption><p><bold>Classic oddball paradigms in three modalities.</bold> Stimuli where Einstein face vs. red square displayed in the center of a black screen (visual; the figure exemplarily displays another face due to printing license), high vs. low pitched tone (auditory) and tactile stimulation at one position vs. stimulation on a second position (tactile). Rare stimuli to frequent stimuli ratio was 1:5.</p></caption><graphic xlink:href="fnins-07-00129-g0003"/></fig><p><bold><italic>Offline classification</italic></bold>. To investigate reliability of each modality, we build weights of a stepwise linear discriminant analysis (SWLDA; e.g., Donchin, <xref ref-type="bibr" rid="B16">1969</xref>; Farwell and Donchin, <xref ref-type="bibr" rid="B18">1988</xref>; Krusienski et al., <xref ref-type="bibr" rid="B37">2006</xref>) based on one of two runs and tested the classifier on the other run (and vice versa). We used 1000 ms of data post-stimulus for classification. In ERP&#x02013;BCIs, higher reliability is usually achieved by considering several trials for classification. To align with this setting we grouped trials into several blocks for offline classification. This led to classification based on 15 trials, based on 5 trials, 3 trials, 2 trials and finally to classification of single trials respectively.</p><p><bold><italic>Online classification</italic></bold>. Apart from the above described offline classification we conducted one run with online classification in the tactile modality. A classifier was built from the two classic tactile oddball runs. The task was to select the target stimulus four times and online classification was performed each time after 20 rare and 100 frequent stimuli. Feedback was immediately presented to the patient in that we verbally communicated classification outcome.</p><p><bold><italic>Visual oddball</italic></bold>. A red square of size 100 &#x000d7; 100 pixels was displayed frequently in the center of a screen with black background. The odd stimuli were of same size and displayed the famous picture of Albert Einstein presenting his tongue. We modified the picture in that it only displayed the face on a black background. SD was 64.25 ms.</p><p><bold><italic>Auditory oddball</italic></bold>. Stimuli were presented with headphones to both ears with same volume for all stimuli. SD was 400 ms. Odd stimuli comprised a high-pitched tone whereas irrelevant stimuli comprised a low-pitched tone.</p><p><bold><italic>Tactile oddball</italic></bold>. Target and non-target stimuli did not vary in terms of SD (220 ms), vibration frequency or vibration gain, but only with respect to the location. The task was to focus attention on one location while ignoring stimuli on the other. To account for sensitivity differences on two forearm locations, we switched target and non-target location between the two runs. As such, we made sure that elicited ERPs following rare stimuli are not due to decreased sensory perception capabilities on the location of frequent stimuli.</p></sec><sec><title>Visual BCI</title><p>The patient reported to see the entire screen placed approximately 80&#x02013;90 cm distant to her. We pointed to different locations in a visually displayed character matrix, in particular to the corners, and asked if she could see these locations (closed question by means of partner scanning; &#x0201c;Can you see the character displayed at this location?&#x0201d;). The tested visual matrices were of different size (large matrix grid on full screen; smaller matrix grid in the center of the screen), contents (6 &#x000d7; 6 matrix; 4 &#x000d7; 4 matrix) and timing [short, medium and long inter-stimulus interval (ISI)]. We adjusted the latter settings based on the patient's report after each testing run. Stimuli in all matrix paradigms comprised the famous face of Albert Einstein as introduced earlier (Kaufmann et al., <xref ref-type="bibr" rid="B33">2011</xref>, <xref ref-type="bibr" rid="B31">2013a</xref>), i.e., the famous face overlaid characters (face flash) and the patient counted the number of face flashes on top of the intended character. We explicitly told the patient to focus attention continuously on face flashes on top of the target character even if she was not able to keep her gaze focused on the target.</p><p>Apart from matrix paradigms, we tested a so-called gaze-independent paradigm in which characters were presented consecutively in the center of the screen. We used only six characters (A&#x02013;F) to align with the properties of the visual oddball paradigm. The target character was the &#x0201c;D.&#x0201d; Furthermore, we tested one setting, to bridge between the oddball paradigm and the gaze-independent speller. Instead of the &#x0201c;D,&#x0201d; it displayed the Einstein face as for the visual oddball paradigm. Yet, in contrast to the visual oddball, frequent stimuli comprised characters instead of the red square (thus referred to as &#x0201c;leading to&#x0201d; gaze-independent speller).</p></sec><sec><title>Tactile BCI</title><p>We checked sensory sensitivity of the patient's left forearm and upper arm by stimulating different locations and inquiring her perception capabilities (two closed questions by means of partner scanning; &#x0201c;Do you feel the stimulus?&#x0201d;; &#x0201c;Do you feel the stimuli approximately equally well?&#x0201d;). Four tactors (see section Equipment, Data Acquisition and Analysis) were then placed with around 10&#x02013;15 cm distance on her left forearm and upper arm (see Figure <xref ref-type="fig" rid="F1">1B</xref>).</p><p>We investigated different timing parameters in several sessions to define the setting in which discrimination of four tactors would work best for the patient. Each setting comprised five runs, each run with every tactor being the target once. (1) SD was long (520 ms) and ISI was short (200 ms). Each tactor was stimulated 15 times per selection, resulting in 60 target and 180 non-target stimuli per run. (2) SD was long (520 ms) and ISI was medium (520 ms) with again every tactor being stimulated 15 times per target. (3) SD was short (220 ms) and ISI was long (800 ms). We increased the number of stimulations by factor 2 to gather more data, resulting in 120 target and 360 non-target stimuli. For direct comparison of the first and the second setting, we reduced the number of stimulations in the offline analysis.</p><p>For comparison of these settings, we trained SWLDA classifiers on every combination of four of five runs and tested classification outcome on the remaining run (see first three columns of Table <xref ref-type="table" rid="T1">1</xref> for illustration of all combinations). Furthermore, we assessed classification outcome for classifier weights trained on 800 ms of data, 1000 ms, 1200 ms, and 1400 ms respectively.</p><table-wrap id="T1" position="float"><label>Table 1</label><caption><p><bold>Classification accuracy based on different runs of tactile BCI use</bold>.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="left" rowspan="1" colspan="1"><bold>Data set</bold></th><th align="left" rowspan="1" colspan="1"><bold>Classifier trained on runs #</bold></th><th align="left" rowspan="1" colspan="1"><bold>Classifier tested on runs #</bold></th><th align="left" rowspan="1" colspan="1"><bold>800 ms post-stimulus</bold></th><th align="left" rowspan="1" colspan="1"><bold>1000 ms post-stimulus</bold></th><th align="left" rowspan="1" colspan="1"><bold>1200 ms post-stimulus</bold></th><th align="left" rowspan="1" colspan="1"><bold>1400 ms post-stimulus</bold></th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Long stimulus, short ISI</td><td align="left" rowspan="1" colspan="1">[1 2 3 4]</td><td align="left" rowspan="1" colspan="1">[5]</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 2 3 5]</td><td align="left" rowspan="1" colspan="1">[4]</td><td align="left" rowspan="1" colspan="1">25</td><td align="left" rowspan="1" colspan="1">25</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 2 4 5]</td><td align="left" rowspan="1" colspan="1">[3]</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">100</td><td align="left" rowspan="1" colspan="1">75</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 3 4 5]</td><td align="left" rowspan="1" colspan="1">[2]</td><td align="left" rowspan="1" colspan="1">100</td><td align="left" rowspan="1" colspan="1">100</td><td align="left" rowspan="1" colspan="1">100</td><td align="left" rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[2 3 4 5]</td><td align="left" rowspan="1" colspan="1">[1]</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">100</td><td align="left" rowspan="1" colspan="1">100</td><td align="left" rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" colspan="2" rowspan="1">Mean &#x000b1; STD</td><td align="left" rowspan="1" colspan="1">55.5 &#x000b1; 27.4</td><td align="left" rowspan="1" colspan="1">75.0 &#x000b1; 30.6</td><td align="left" rowspan="1" colspan="1">90.0 &#x000b1; 13.7</td><td align="left" rowspan="1" colspan="1">90.0 &#x000b1; 13.7</td></tr><tr><td align="left" rowspan="1" colspan="1">Long stimulus, medium ISI</td><td align="left" rowspan="1" colspan="1">[1 2 3 4]</td><td align="left" rowspan="1" colspan="1">[5]</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">100</td><td align="left" rowspan="1" colspan="1">100</td><td align="left" rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 2 3 5]</td><td align="left" rowspan="1" colspan="1">[4]</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">100</td><td align="left" rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 2 4 5]</td><td align="left" rowspan="1" colspan="1">[3]</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">50</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 3 4 5]</td><td align="left" rowspan="1" colspan="1">[2]</td><td align="left" rowspan="1" colspan="1">0</td><td align="left" rowspan="1" colspan="1">0</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">25</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[2 3 4 5]</td><td align="left" rowspan="1" colspan="1">[1]</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">50</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" colspan="2" rowspan="1">Mean &#x000b1; STD</td><td align="left" rowspan="1" colspan="1">50 &#x000b1; 30.6</td><td align="left" rowspan="1" colspan="1">50 &#x000b1; 35.4</td><td align="left" rowspan="1" colspan="1">80 &#x000b1; 20.9</td><td align="left" rowspan="1" colspan="1">65 &#x000b1; 33.5</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Short stimulus, long ISI. Number of stimulations reduced offline for direct comparison</td><td align="left" valign="top" rowspan="1" colspan="1">[1 2 3 4]</td><td align="left" valign="top" rowspan="1" colspan="1">[5]</td><td align="left" valign="top" rowspan="1" colspan="1">75</td><td align="left" valign="top" rowspan="1" colspan="1">75</td><td align="left" valign="top" rowspan="1" colspan="1">50</td><td align="left" valign="top" rowspan="1" colspan="1">75</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 2 3 5]</td><td align="left" rowspan="1" colspan="1">[4]</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 2 4 5]</td><td align="left" rowspan="1" colspan="1">[3]</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 3 4 5]</td><td align="left" rowspan="1" colspan="1">[2]</td><td align="left" rowspan="1" colspan="1">25</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">0</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[2 3 4 5]</td><td align="left" rowspan="1" colspan="1">[1]</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" colspan="2" rowspan="1">Mean &#x000b1; STD</td><td align="left" rowspan="1" colspan="1">65 &#x000b1; 22.4</td><td align="left" rowspan="1" colspan="1">70 &#x000b1; 11.2</td><td align="left" rowspan="1" colspan="1">65 &#x000b1; 13.4</td><td align="left" rowspan="1" colspan="1">65 &#x000b1; 37.9</td></tr><tr><td align="left" valign="top" rowspan="1" colspan="1">Short stimulus, long ISI. Full data set with twice as much stimuli.</td><td align="left" valign="top" rowspan="1" colspan="1">[1 2 3 4]</td><td align="left" valign="top" rowspan="1" colspan="1">[5]</td><td align="left" valign="top" rowspan="1" colspan="1">100</td><td align="left" valign="top" rowspan="1" colspan="1">75</td><td align="left" valign="top" rowspan="1" colspan="1">100</td><td align="left" valign="top" rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 2 3 5]</td><td align="left" rowspan="1" colspan="1">[4]</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 2 4 5]</td><td align="left" rowspan="1" colspan="1">[3]</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[1 3 4 5]</td><td align="left" rowspan="1" colspan="1">[2]</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">100</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" rowspan="1" colspan="1">[2 3 4 5]</td><td align="left" rowspan="1" colspan="1">[1]</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">75</td><td align="left" rowspan="1" colspan="1">50</td><td align="left" rowspan="1" colspan="1">50</td></tr><tr><td rowspan="1" colspan="1"/><td align="left" colspan="2" rowspan="1">Mean &#x000b1; STD</td><td align="left" rowspan="1" colspan="1">80.0 &#x000b1; 11.2</td><td align="left" rowspan="1" colspan="1">75.0 &#x000b1; 0.0</td><td align="left" rowspan="1" colspan="1">75.0 &#x000b1; 17.7</td><td align="left" rowspan="1" colspan="1">85.0 &#x000b1; 22.4</td></tr></tbody></table><table-wrap-foot><p>We trained SWLDA classifiers on every combination of four of five runs and tested them on the remaining run. The table furthermore presents classification outcome for classifier weights trained on 800 ms of data, 1000 ms, 1200 ms, and 1400 ms respectively.</p></table-wrap-foot></table-wrap><p>Finally, we conducted one run, in which the patient used the tactile BCI for communication. We implemented a BCI spelling system analog to her partner scanning approach (see Figure <xref ref-type="fig" rid="F1">1</xref>). First, one of four groups of characters was selected, followed by selection of an individual character. As our setup and calibration was restricted to a four-choice paradigm, we only enabled selection of the first four characters in each group for this online test (colored characters in Figure <xref ref-type="fig" rid="F1">1</xref>). The patient tested this system in one run aiming at copy spelling a four-letter word (8 selections, i.e., four times selection of group plus four times selection of character). SD was the same as ISI duration, both 520 ms long.</p></sec><sec><title>Other assistive technology</title><p>In this study, we investigated feasibility of a BCI system as a communication channel alternative to the partner scanning that she currently uses. Yet, during the visits, we also attempted to provide her with other AT as no reliable communication method other than partner scanning has ever been established within the past 7 years. During our first visit we tried two commercial AT devices, (1) an infrared blink detection sensor (<italic>SCATIR</italic>, Prentke Romich GmbH) and (2) a button (<italic>Lib Switch</italic>, Prentke Romich GmbH) on her thumb. We connected it to a communication device that allows for selecting characters or commands (<italic>XLTalker</italic>, Prentke Romich GmbH). During our second visit, we investigated use of an electrooculogram (EOG) for detection of eyelifts. We connected one EOG electrode placed below her right eye to our BCI software and classified eyelifts using SWLDA. The software read out characters in the same manner as the above-described partner scanning approach the patient is used to (see also section Tactile BCI and Figure <xref ref-type="fig" rid="F1">1A</xref>). When the software read out the intended group or the intended character respectively, the patient lifted her eyebrow thereby triggering a reliable deflection in the recorded muscle activity.</p></sec></sec><sec><title>Equipment, data acquisition, and analysis</title><p>Visual stimulation was performed on a 22&#x02033; screen (LG Flatron; 1680 &#x000d7; 1050 pixels), auditory stimulation through headphones fully covering both ears (Sennheiser, HD280 pro) and tactile stimulation with small vibrate transducers (C2 tactors; Engineering Acoustics Inc., USA). We implemented the stimulation paradigms for all modalities in Python 2.7 (<ext-link ext-link-type="uri" xlink:href="http://www.python.org">www.python.org</ext-link>) and connected them to the BCI2000 software (Schalk et al., <xref ref-type="bibr" rid="B49">2004</xref>; <ext-link ext-link-type="uri" xlink:href="http://www.bci2000.org">www.bci2000.org</ext-link>) via user datagram protocol.</p><p>EEG during oddball-paradigms was obtained from 11 passive Ag/AgCl electrodes with mastoid ground and reference placed at positions Fz, FC1, FC2, C3, Cz, C4, PO7, P3, Pz, P4 and PO8. For testing BCI paradigms, we extended the electrode setup by four electrodes (TP7, CP3, CP4 and TP8) to a 15 electrodes setting. EEG was amplified with a g.USBamp amplifier (g.Tec Medical GmbH, Austria) and recorded at 512 Hz using BCI2000. Data was analyzed in Matlab 2012 (The Mathworks Inc., USA) and classification of oddball paradigms as well as all BCI paradigms performed utilizing SWLDA (e.g., Donchin, <xref ref-type="bibr" rid="B16">1969</xref>; Farwell and Donchin, <xref ref-type="bibr" rid="B18">1988</xref>; Krusienski et al., <xref ref-type="bibr" rid="B37">2006</xref>).</p></sec></sec><sec sec-type="results" id="s3"><title>Results</title><sec><title>Classic oddball paradigms</title><p>Figure <xref ref-type="fig" rid="F4">4</xref> displays ERPs elicited in the oddball paradigms for two exemplary electrodes. Difference between rare and frequent stimuli was most pronounced for visual and tactile modalities displaying a distinct P300 around 500 ms post-stimulus. Peak amplitudes were of same size for the visual (5.96 &#x003bc;V, 530 ms, Pz) and the tactile modality (5.92 &#x003bc;V, 471 ms, FC2) and higher than for the auditory modality (3.95 &#x003bc;V, 493 ms, Fz).</p><fig id="F4" position="float"><label>Figure 4</label><caption><p><bold>Comparison of ERPs elicited in different modalities in the classic oddball paradigms.</bold> ERPs are exemplarily displayed for electrode Cz (upper row) and Pz (lower row). Visual and tactile stimulation elicited the most pronounced differences between target and non-target stimulations. Reliability across trials was highest for the tactile modality (see Figure <xref ref-type="fig" rid="F5">5</xref>).</p></caption><graphic xlink:href="fnins-07-00129-g0004"/></fig><p>To investigate the reliability of elicited ERPs offline, we trained classifiers for each modality based on one run and tested them on the other run (and vice versa). Figure <xref ref-type="fig" rid="F5">5</xref> depicts average offline classification accuracies. The tactile modality was clearly superior to the visual and auditory modality. Although classification of visual and auditory ERPs was possible when including many trials into classification (visual: <italic>M</italic> = 83.33%, auditory: <italic>M</italic> = 66.67% with 15 trials), performance severely decreased with reduced number of trials. This effect was more pronounced in the auditory modality. Classification accuracy based on few trials was insufficiently low (below <italic>M</italic> = 60% with 3 trials or less). In contrast, in the tactile modality five or more trials led to 100% classification accuracy. Importantly, accuracy was still high if based on two trials (<italic>M</italic> = 92.85%) and even if based on single trial (<italic>M</italic> = 78.33%).</p><fig id="F5" position="float"><label>Figure 5</label><caption><p><bold>Offline classification accuracy achieved in different modalities in the classic oddball paradigms.</bold> Classification accuracies are presented based on classification of single trials, two, three, five, or fifteen trials. Tactile modality outperformed other modalities in that high classification accuracy could be achieved even based on single trials.</p></caption><graphic xlink:href="fnins-07-00129-g0005"/></fig><p>We conducted an online test session with the tactile oddball paradigm. The patient correctly selected the target in all cases, i.e., online classification accuracy based on 10-trials of two tactile stimuli was 100%.</p></sec><sec><title>Transfer to BCI</title><p>As visual and tactile oddballs displayed pronounced ERPs post-stimulus, we tested these modalities with BCI paradigms.</p><sec><title>Visual BCI</title><p>Although the patient reported to perceive the entire screen (see section Experimental Design), matrix-based BCI paradigms were not viable. After initial testing with a 6 &#x000d7; 6 matrix, we reduced the number of matrix items to 4 &#x000d7; 4 and finally we reduced the size from full-screen to a small matrix in the center of the screen. Yet, none of these paradigms evoked pronounced and thus, reliably classifiable ERPs (Figures <xref ref-type="fig" rid="F6">6A&#x02013;C</xref>). No N170 was visible as would have been expected if recognizing the face presented on the target character (Bentin et al., <xref ref-type="bibr" rid="B7">1996</xref>; Eimer, <xref ref-type="bibr" rid="B17">2000</xref>). The patient reported difficulties in continuously focusing on a target, although possible for a short time.</p><fig id="F6" position="float"><label>Figure 6</label><caption><p><bold>Comparison of ERPs elicited in different visual BCI paradigms, exemplarily illustrated for electrode Cz (upper row) and Pz (lower row). (A)</bold> 6 &#x000d7; 6 matrix presented in fullscreen, <bold>(B)</bold> 4&#x000d7;4 matrix presented in fullscreen, <bold>(C)</bold> 4&#x000d7;4 matrix presented at smaller size in the center of the screen, <bold>(D)</bold> &#x0201c;Gaze independent&#x0201d; speller, characters were presented in the center of the screen <bold>(E)</bold> &#x0201c;Leading to&#x0201d; gaze independent speller, similar to the gaze independent speller except for the target stimulus that was replaced by a face stimulus. Neither matrix based paradigms <bold>(A-C)</bold>, nor a gaze-independent paradigm <bold>(D)</bold> led to reliable differences between target and non-target stimulations. To investigate potential sources why the gaze-independent paradigm did not work, we conducted one run in which the target character was replaced with a face <bold>(E)</bold>. This paradigm is similar to the visual oddball and differed only with regard to the non-target stimuli. As this paradigm elicited pronounced ERPs that compared to the visual oddball, we assume that identification of a character in a plethora of presented characters may be aggravated and sufficient gaze control may be required.</p></caption><graphic xlink:href="fnins-07-00129-g0006"/></fig><p>As she had trouble with focusing her gaze on targets, we tested a so-called gaze-independent BCI paradigm, randomly presenting six characters in the center of the screen. However, also this paradigm failed such that no reliable ERPs were elicited (Figure <xref ref-type="fig" rid="F6">6D</xref>). As the visual oddball elicited pronounced ERPs, we further investigated possible reasons for failure of the gaze-independent paradigm. In the visual oddball, the black and white Einstein face was easily distinguishable from the red squares. Thus, we combined the oddball with the gaze-independent speller such that five white characters were used as non-targets and the (black and white) Einstein face as target. As depicted in Figure <xref ref-type="fig" rid="F6">6E</xref>, the paradigm elicited pronounced ERPs including a strong N170. The P300 was even of higher amplitude compared to the visual oddball (7.78 &#x003bc;V, Fz), however, its latency was strongly increased (723 ms), indicating increased difficulty to discriminate between target and non-target stimuli (Figure <xref ref-type="fig" rid="F4">4</xref>).</p></sec><sec><title>Tactile BCI</title><p>As the visual modality appeared unreliable, we further focused on the tactile modality. We extended the setup to a four-choice BCI paradigm and conducted 15 runs in total where each of four tactors was the target once per run. Figure <xref ref-type="fig" rid="F7">7</xref> compares the ERPs elicited in different settings (long SD + short ISI; long SD + medium ISI; short SD + long ISI). The condition with long SD and short ISI elicited most pronounced ERPs, followed by the condition with short SD and long ISI. Importantly, ERPs of all conditions could be classified offline with high accuracies (see Table <xref ref-type="table" rid="T1">1</xref>). In general classification on 1200 ms and 1400 ms post-stimulus achieved highest accuracy yet variance was lowest for classification based on 1200 ms. All obtained classification results were clearly above the chance level of 25%.</p><fig id="F7" position="float"><label>Figure 7</label><caption><p><bold>Comparison of ERPs elicited in a four-choice tactile BCI with different stimulus parameters.</bold> Stimulus duration (SD) was either long (520 ms) or short (220 ms). Inter-stimulus interval (ISI) was short (200 ms), medium (520 ms) or long (800 ms). Three combinations of SD and ISI were tested exploratory, i.e., (1) SD<sub>long</sub> + ISI<sub>short</sub>, (2) SD<sub>long</sub> + ISI<sub>medium</sub>, and (3) SD<sub>short</sub> + ISI<sub>long</sub>. Please note that for the third combination, more data was available. For comparison, we thus reduced the amount of data to similar size for all conditions. Yet, the full data set is depicted in the plot on the right.</p></caption><graphic xlink:href="fnins-07-00129-g0007"/></fig><p>Finally, we tested a communication application online, utilizing the tactile four choice BCI described in section Tactile BCI. The patient completed one run with 50% online accuracy (four of eight selections correct).</p></sec></sec><sec><title>Other assistive technology</title><p>Communication by means of an infrared blink detection sensor failed due to the presence of involuntary muscle movements of her eyelids. Use of a simple button on her thumb appeared more promising. Although still unreliable, selections were clearly above chance.</p><p>The EOG based eye lift detection tested during our second visit appeared far most promising. After a short calibration of 8 min only, the patient could use the EOG for reliable communication and spelled several words without error. Classification was performed after every three trials of eye lifts. This system for the first time provided a reliable and fast means of independent communication.</p></sec></sec><sec sec-type="discussion" id="s4"><title>Discussion</title><p>This case study with a LIS patient revealed the potential of tactile stimulation for BCI use such that tactually evoked ERPs were clearly more reliable than those elicited in the visual or auditory modality. Although an average across 180 target trials per modality led to similar ERP amplitudes for the tactile and the visual domain, visual ERPs were much less reliable. With single-trial offline classification of tactile ERPs in the oddball paradigm, almost the same level of classification accuracy was obtained (<italic>M</italic> = 78.33) as with 15 trials of classification in the visual modality (<italic>M</italic> = 83.33). These promising offline results were replicated in an online run in which the patient correctly selected the target stimuli without any error (four times, each based on 20 rare and 100 frequent tactile ERP stimuli).</p><p>When extending the setting to four tactile stimulation units, ERPs of same amplitude were elicited. Classification accuracies as depicted in Table <xref ref-type="table" rid="T1">1</xref> were up to 100% and for all settings clearly above chance level. Performance achieved in runs based on long SD and short ISI was higher than in other settings (<italic>M</italic> = 90%). ERPs depicted in Figure <xref ref-type="fig" rid="F7">7</xref> render a short SD feasible for tactile ERP elicitation in our patient, yet classification accuracy was not as high. The larger SD may have increased the patient's stimulus perception ability. Brouwer and Van Erp (<xref ref-type="bibr" rid="B11">2010</xref>) reported significantly decreased classification accuracy for a condition with long SD (367 ms) and no ISI (0 ms). Our results complement these findings in that the decreased performance may not be due to the increased SD but due to the missing ISI. The authors further reported, that for a condition with sufficiently long SD (188 cms), performance could be further increased by decreasing the ISI (SD: 188 ms, ISI: 188 ms). This finding is in line with our results, where a shorter ISI entailed better accuracy than a longer ISI.</p><p>In the test of the tactile spelling system, the patient achieved an accuracy of 50% only. Although this result was above chance, it is insufficient for communication (K&#x000fc;bler et al., <xref ref-type="bibr" rid="B39">2001</xref>). Choice of 520 ms SD and 520 ms ISI might have been suboptimal when considering the results from the comprehensive offline analysis conducted afterwards (depicted in Table <xref ref-type="table" rid="T1">1</xref>). Consequently, we expect higher accuracies for future tests, when applying a shorter ISI. Also, the patient had a strong cough during the last character selection process, explaining the last miss-selection. As noted by a family member, these coughs particularly appear when she is excited and endeavored (see also section General Implications with EEG-Based BCIs and Comparison to Other Assistive Technology). To use the proposed spelling system in full functionality, an extension from four to seven tactors would be required. Brouwer and Van Erp (<xref ref-type="bibr" rid="B11">2010</xref>) reported similar classification accuracies when using two, four, or six tactors. Our results yielded decreased performance when extending the setup from two to four tactors. Although accuracies were still high, they were lower in the four-choice tactile BCI than expected from the classic oddball paradigm results. If an extension to seven tactors may be feasible for the patient remains to be investigated.</p><p>Notwithstanding these caveats, our results were a proof of concept for the feasibility of tactile stimulation for BCI control in a patient for who the visual modality did not work in any setting.</p><p>Apart from these promising results on tactually evoked ERPs, we reported on two other modalities. The auditory modality appears least promising in this patient. ERP amplitudes were lower as compared to other modalities and offline classification accuracy rapidly decreased when reducing the number of trials. Here we used stimuli that varied in pitch as a study by Halder et al. (<xref ref-type="bibr" rid="B20">2010</xref>) reported such stimuli superior to those that varied in volume or direction. Yet other differentiations between rare and frequent stimuli may yield better results, e.g., combinations of pitch and spatial information (Schreuder et al., <xref ref-type="bibr" rid="B50">2010</xref>; H&#x000f6;hne et al., <xref ref-type="bibr" rid="B24">2011</xref>; K&#x000e4;thner et al., <xref ref-type="bibr" rid="B30">2013</xref>). Recently, Halder et al. (<xref ref-type="bibr" rid="B20a">2013</xref>) illustrated that training may positively affect auditory BCI performance. Furthermore, as for tactile BCIs, SD may strongly affect classification outcome. No definite conclusion can thus be drawn for the auditory modality.</p><p>For the visual modality, we conducted many runs in different settings and were thus able to draw a more detailed picture than for the auditory modality. Matrix-based visual ERP&#x02013;BCIs failed in all of the tested configurations. Although able to see the entire screen, the patient had difficulties in focusing for a longer time on a peripheral location. However, it is notable that a so-called gaze-independent speller did not work either. Focusing attention on the target character seemed not sufficient for correct selection. A possible explanation is that these paradigms in fact do require gaze control for discrimination between characters. To investigate this hypotheses we compared ERPs elicited in the visual oddball (Einstein face vs. red squares) to ERPs elicited in a paradigm with the black and white Einstein face as target and white characters as non-targets. This paradigm elicited a strong P300, yet the peak was delayed as compared to the visual oddball. This delay may be due to an increased difficulty in discriminating targets from non-targets. Consequently, we assume that enhancing discriminability between characters may entail better results in her case. Acqualagna et al. (<xref ref-type="bibr" rid="B2">2010</xref>) compared a condition in which characters were presented in different colors to a condition with black characters only. Participants achieved better counting accuracy when characters were of different color, yet offline classification was lower compared to the black-character condition. In the follow-up online study classification accuracy was the same for both conditions (Acqualagna and Blankertz, <xref ref-type="bibr" rid="B1">2013</xref>). Thus, we would not expect a boost in performance from such modification. Other &#x0201c;gaze-independent&#x0201d; spellers could be tested, e.g., a speller that groups characters into categories (Treder and Blankertz, <xref ref-type="bibr" rid="B59">2010</xref>). However, from the classification accuracy achieved in the visual oddball we would not expect reliable communication based on the visual modality.</p><p>Our results manifest the importance of user-centered design in BCI development (Maguire, <xref ref-type="bibr" rid="B43">1998</xref>; Zickler et al., <xref ref-type="bibr" rid="B64">2011</xref>; Holz et al., <xref ref-type="bibr" rid="B27">2012</xref>). Based on data obtained from healthy participants, we expected the visual modality (gaze-independent) to be superior to the others (e.g., the direct comparison of modalities by Aloise et al., <xref ref-type="bibr" rid="B5">2007</xref>; accuracies reported from studies conducted in different modalities, for review, Riccio et al., <xref ref-type="bibr" rid="B47">2012</xref>). Clearly, this was not the case in our patient, which convincingly demonstrates that results achieved with healthy subjects do not necessarily transfer to locked-in patients. BCIs that yield lower results in healthy users may be the only possible setting for a particular end-user with motor impairment or in the locked-in state. Thus, when aiming at bringing BCIs to end-users, those have to be included in the developmental process for which the user-centered design provides a framework (Maguire, <xref ref-type="bibr" rid="B43">1998</xref>; Holz et al., <xref ref-type="bibr" rid="B27">2012</xref>). Only when specifically investigating the requirements of a targeted end-user a well-suited BCI can be implemented as their needs and requirements may well differ from that of healthy users (Zickler et al., <xref ref-type="bibr" rid="B64">2011</xref>). In addition, development of a BCI system that copies the communication approach a patient is used to may increase learnability of system control. The approach we implemented in this study (Figure <xref ref-type="fig" rid="F1">1</xref>) was similar to the patient's approach, which she highly appreciated.</p><p>In our case study, the patient rated her perceived quality of life as &#x0201c;the worst time in life&#x0201d; (see section The Case) and explained her low rating as being due to the strong dependence on others. In a survey among 65 LIS patients, Bruno et al. (<xref ref-type="bibr" rid="B14">2011</xref>) reported that only 28% of patients perceived unhappiness (<italic>ACSA</italic> scores below 0) and only 1/3 of them rated quality of life with an <italic>ACSA</italic> score of -5. Yet unhappiness was associated with non-recovery of speech production. These and our results manifest the importance of providing these patients with a means of independent communication.</p><sec><title>General implications with EEG-based BCIs and comparison to other assistive technology</title><p>Recent research demonstrated that independent BCI home-use by a locked-in patient is possible (Sellers et al., <xref ref-type="bibr" rid="B56">2010</xref>; Holz et al., <xref ref-type="bibr" rid="B26">2013</xref>) and that the software can be automatized such that na&#x000ef;ve users can handle it (Kaufmann et al., <xref ref-type="bibr" rid="B34">2012a</xref>). However, several issues remain, e.g., related to artifact contamination of EEG data or attention allocation capacity. Some of these issues may be:
<list list-type="order"><list-item><p>Spasm artifacts: During our first visit, the patient had several spasm attacks (due to cough, see section The Case) so that we had to cancel runs and start again. On the last day, the attacks were so intense, that the BCI session had to be terminated. Apart from health related attacks, the patient also had coughs due to an increased excitement and endeavor (as noted by a family member). Future research should thus investigate algorithms for identification of artifacts from the ongoing EEG. A practical BCI should automatically pause in the case of too noisy EEG and proceed once artifact induced electrode drifts diminished. In addition, the EEG could be cleaned prior to computing classifier weights to avoid building classifiers based on artifacts. Furthermore, classification based on a dynamically adjusting number of trials may compensate small artifact contamination such that more trials can be presented if artifacts lower classification certainty (e.g., Lenhardt et al., <xref ref-type="bibr" rid="B40">2008</xref>; H&#x000f6;hne et al., <xref ref-type="bibr" rid="B23">2010</xref>; Liu et al., <xref ref-type="bibr" rid="B41">2010</xref>; Jin et al., <xref ref-type="bibr" rid="B29">2011</xref>; Schreuder et al., <xref ref-type="bibr" rid="B52">2011a</xref>; for review, Schreuder et al., <xref ref-type="bibr" rid="B53">2011b</xref>, <xref ref-type="bibr" rid="B51">2013</xref>).</p></list-item><list-item><p>Single electrode drifts and cap displacement: Apart from spasm artifacts, that usually contaminate all electrodes, single electrode drifts or shift of cap placement should automatically be identified. During our stay, the patient had a strong spasm attack after which the whole electrode cap had shifted. Furthermore, single electrodes sometimes lost contact or even dropped out after such attacks. Dauce and Proix (<xref ref-type="bibr" rid="B15">2013</xref>) suggested a method for identification of performance drops during free spelling. The backspace key is used as an indicator of low performance. If used too frequently, the BCI is recalibrated.</p></list-item><list-item><p>Attention allocation and workload: In a home environment, background noise is present in daily life situations, e.g., phone rings, voice of others, etc. ERP&#x02013;BCIs (especially non-visual ERP&#x02013;BCIs) require high attention to stimuli (e.g., Kaufmann et al., <xref ref-type="bibr" rid="B34a">2012b</xref>) and such noise may badly affect performance. This clearly is a limitation compared to other assistive technologies. For example, the EOG based device that we provided to the patient (see section The Case) requires far less attention allocation and may thus prove more useful for her in daily life even if both systems would display equivalent bit rates.</p></list-item><list-item><p>Flexibility: In the partner scanning approach that the patient currently uses, the communication partner can easily repeat a scan if selection of a character was unclear or can even suggest another more likely character instead. Not only may these selections be based on the spelled characters but also be based on contextual knowledge of the patient's life. Furthermore, the partner will easily recognize if the patient was distracted. Consequently, the partner scanning approach is particularly flexible. First approaches to increase flexibility of BCI systems are available (e.g., the above described dynamic stopping, for review Schreuder et al., <xref ref-type="bibr" rid="B51">2013</xref>; text prediction, e.g., Ryan et al., <xref ref-type="bibr" rid="B48">2011</xref>; Kaufmann et al., <xref ref-type="bibr" rid="B34">2012a</xref>; or error correction procedures, e.g., Dauce and Proix, <xref ref-type="bibr" rid="B15">2013</xref>), yet compared to the partner scanning these systems still lack flexibility.</p></list-item><list-item><p>Evaluation: It is important to validate after each run if the patient could concentrate and if anything was disturbing or unclear. Although this is rather time consuming when considering that the patient can only communicate on a character-by-character basis in a partner scanning approach, it is a necessity. Otherwise, it is impossible to investigate if for example decreased performance results from a modification of the system or from decreased attention or distraction (Zickler et al., <xref ref-type="bibr" rid="B64">2011</xref>, <xref ref-type="bibr" rid="B63">in press</xref>; Holz et al., <xref ref-type="bibr" rid="B26">2013</xref>, <xref ref-type="bibr" rid="B25">in press</xref>).</p></list-item></list>
</p><p>Although we consider BCIs of particular interest for the patient described in this paper, the patient will not use a current BCI system for communication. As described in section The Case we tested an EOG based system that was far more reliable. However, the system requires muscular control which can be too fatiguing in frequent use. A tactile ERP&#x02013;BCI would be a muscle-independent alternative. Importantly, the patient reported tactile BCI use as not being tiring. Thus, although we identified multiple issues that prevent transfer of current BCI technology to her daily life, the method should still be further explored as an alternative communication channel. If future research identifies solutions to the issues described above, BCIs may well be a feasible communication tool for patients in (classic) LIS - at least as a valuable alternative among other systems.</p></sec></sec><sec sec-type="conclusion" id="s5"><title>Conclusion</title><p>This case study demonstrated successful classification of tactually evoked ERPs in a patient with classic LIS. The tactile modality was clearly superior to the visual and auditory modality. The patient achieved high accuracy even with a small number of trials in a two-class oddball and medium to high accuracy in a four-choice tactile BCI paradigm. Results from visual BCI paradigms may question gaze-independence of current gaze-independent spellers, as gaze-control may not only be required to focus peripheral targets but also for discrimination of characters presented in the center of the screen. Further, our results emphasize the need for user-centered design in BCI development and underline remaining issues when considering practical daily life use that are not as relevant with other assistive technologies.</p><sec><title>Conflict of interest statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></sec></body><back><ack><p>This work is supported by the European ICT Programme Project FP7-224631. This paper only reflects the authors' views and funding agencies are not liable for any use that may be made of the information contained herein. Open access publication was funded by the German Research Foundation (DFG) and the University of W&#x000fc;rzburg in the funding programme Open Access Publishing.</p></ack><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acqualagna</surname><given-names>L.</given-names></name><name><surname>Blankertz</surname><given-names>B.</given-names></name></person-group> (<year>2013</year>). <article-title>Gaze-independent BCI-spelling using rapid serial visual presentation (RSVP)</article-title>. <source>Clin. Neurophysiol</source>. <volume>124</volume>, <fpage>901</fpage>&#x02013;<lpage>908</lpage>
<pub-id pub-id-type="doi">10.1016/j.clinph.2012.12.050</pub-id><pub-id pub-id-type="pmid">23466266</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Acqualagna</surname><given-names>L.</given-names></name><name><surname>Treder</surname><given-names>M. S.</given-names></name><name><surname>Schreuder</surname><given-names>M.</given-names></name><name><surname>Blankertz</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>A novel brain-computer interface based on the rapid serial visual presentation paradigm</article-title>. <source>Conf. Proc. IEEE Eng. Med. Biol. Soc</source>. <volume>2010</volume>, <fpage>2686</fpage>&#x02013;<lpage>2689</lpage>
<pub-id pub-id-type="doi">10.1109/IEMBS.2010.5626548</pub-id><pub-id pub-id-type="pmid">21096199</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allison</surname><given-names>B. Z.</given-names></name><name><surname>Dunne</surname><given-names>S.</given-names></name><name><surname>Leeb</surname><given-names>R.</given-names></name><name><surname>Mill&#x000e1;n</surname><given-names>J. D. R.</given-names></name><name><surname>Nijholt</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>Towards practical brain-computer interfaces: bridging the gap from research to real-world applications</article-title>, in <source>Springer, Biological and Medical Physics, Biomedical Engineering</source>. <pub-id pub-id-type="doi">10.1007/978-3-642-29746-5</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aloise</surname><given-names>F.</given-names></name><name><surname>Aric&#x000f2;</surname><given-names>P.</given-names></name><name><surname>Schettini</surname><given-names>F.</given-names></name><name><surname>Riccio</surname><given-names>A.</given-names></name><name><surname>Salinari</surname><given-names>S.</given-names></name><name><surname>Mattia</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>A covert attention P300-based brain-computer interface: geospell</article-title>. <source>Ergonomics</source>
<volume>55</volume>, <fpage>538</fpage>&#x02013;<lpage>551</lpage>
<pub-id pub-id-type="doi">10.1080/00140139.2012.661084</pub-id><pub-id pub-id-type="pmid">22455372</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Aloise</surname><given-names>F.</given-names></name><name><surname>Lasorsa</surname><given-names>I.</given-names></name><name><surname>Brouwer</surname><given-names>A. M.</given-names></name><name><surname>Mattia</surname><given-names>D.</given-names></name><name><surname>Babiloni</surname><given-names>F.</given-names></name><name><surname>Salinari</surname><given-names>S.</given-names></name><etal/></person-group> (<year>2007</year>). <article-title>Multimodal stimulation for a P300-based BCI</article-title>. <source>Int. J. Bioelectromagn</source>. <volume>9</volume>, <fpage>128</fpage>&#x02013;<lpage>130</lpage></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bauer</surname><given-names>G.</given-names></name><name><surname>Gerstenbrand</surname><given-names>F.</given-names></name><name><surname>Rumpl</surname><given-names>E.</given-names></name></person-group> (<year>1979</year>). <article-title>Varieties of the locked-in syndrome</article-title>. <source>J. Neurol</source>. <volume>221</volume>, <fpage>77</fpage>&#x02013;<lpage>91</lpage>
<pub-id pub-id-type="doi">10.1007/BF00313105</pub-id><pub-id pub-id-type="pmid">92545</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bentin</surname><given-names>S.</given-names></name><name><surname>Allison</surname><given-names>T.</given-names></name><name><surname>Puce</surname><given-names>A.</given-names></name><name><surname>Perez</surname><given-names>E.</given-names></name><name><surname>McCarthy</surname><given-names>G.</given-names></name></person-group> (<year>1996</year>). <article-title>Electrophysiological studies of face perception in humans</article-title>. <source>J. Cogn. Neurosci</source>. <volume>8</volume>, <fpage>551</fpage>&#x02013;<lpage>565</lpage>
<pub-id pub-id-type="doi">10.1162/jocn.1996.8.6.551</pub-id><pub-id pub-id-type="pmid">20740065</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bernheim</surname><given-names>J. L.</given-names></name><name><surname>Buyse</surname><given-names>M.</given-names></name></person-group> (<year>1993</year>). <article-title>The anamnestic comparative self-assessment for measuring the subjective quality of life of cancer patients</article-title>. <source>J. Psychosoc. Oncol</source>. <volume>1</volume>, <fpage>25</fpage>&#x02013;<lpage>38</lpage>
<pub-id pub-id-type="doi">10.1300/J077v01n04_03</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Cohen</surname><given-names>L. G.</given-names></name></person-group> (<year>2007</year>). <article-title>Brain-computer interfaces: communication and restoration of movement in paralysis</article-title>. <source>J. Physiol</source>. <volume>579(Pt 3)</volume>, <fpage>621</fpage>&#x02013;<lpage>636</lpage>
<pub-id pub-id-type="doi">10.1113/jphysiol.2006.125633</pub-id><pub-id pub-id-type="pmid">17234696</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Murguialday</surname><given-names>A. R.</given-names></name><name><surname>Cohen</surname><given-names>L.</given-names></name></person-group> (<year>2008</year>). <article-title>Brain-computer interface in paralysis</article-title>. <source>Curr. Opin. Neurol</source>. <volume>21</volume>, <fpage>634</fpage>&#x02013;<lpage>638</lpage>
<pub-id pub-id-type="doi">10.1097/WCO.0b013e328315ee2d</pub-id><pub-id pub-id-type="pmid">18989104</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>A.-M.</given-names></name><name><surname>Van Erp</surname><given-names>J. B. F.</given-names></name></person-group> (<year>2010</year>). <article-title>A tactile P300 brain-computer interface</article-title>. <source>Front. Neurosci</source>. <volume>4</volume>:<issue>19</issue>
<pub-id pub-id-type="doi">10.3389/fnins.2010.00019</pub-id><pub-id pub-id-type="pmid">20582261</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brouwer</surname><given-names>A.-M.</given-names></name><name><surname>Van Erp</surname><given-names>J. B. F.</given-names></name><name><surname>Aloise</surname><given-names>F.</given-names></name><name><surname>Cincotti</surname><given-names>F.</given-names></name></person-group> (<year>2010</year>). <article-title>Tactile, visual, and bimodal p300s: could bimodal p300s boost bci performance? SRX</article-title>. <source>Neuroscience</source>
<volume>2010</volume>, <fpage>1</fpage>&#x02013;<lpage>9</lpage>
<pub-id pub-id-type="doi">10.3814/2010/967027</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brunner</surname><given-names>P.</given-names></name><name><surname>Joshi</surname><given-names>S.</given-names></name><name><surname>Briskin</surname><given-names>S.</given-names></name><name><surname>Wolpaw</surname><given-names>J. R.</given-names></name><name><surname>Bischof</surname><given-names>H.</given-names></name><name><surname>Schalk</surname><given-names>G.</given-names></name></person-group> (<year>2010</year>). <article-title>Does the &#x0201c;P300&#x0201d; speller depend on eye gaze?</article-title>
<source>J. Neural Eng</source>. <volume>7</volume>, <fpage>056013</fpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/7/5/056013</pub-id><pub-id pub-id-type="pmid">20858924</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bruno</surname><given-names>M.-A.</given-names></name><name><surname>Bernheim</surname><given-names>J. L.</given-names></name><name><surname>Ledoux</surname><given-names>D.</given-names></name><name><surname>Pellas</surname><given-names>F.</given-names></name><name><surname>Demertzi</surname><given-names>A.</given-names></name><name><surname>Laureys</surname><given-names>S.</given-names></name></person-group> (<year>2011</year>). <article-title>A survey on self-assessed well-being in a cohort of chronic locked-in syndrome patients: happy majority, miserable minority</article-title>. <source>BMJ Open</source>
<volume>1</volume>:<fpage>e000039</fpage>
<pub-id pub-id-type="doi">10.1136/bmjopen-2010-000039</pub-id><pub-id pub-id-type="pmid">22021735</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Dauce</surname><given-names>E.</given-names></name><name><surname>Proix</surname><given-names>T.</given-names></name></person-group> (<year>2013</year>). <article-title>P300-speller adaptivity to change with a backspace key</article-title>, in <source>Proceedings of the Fourth Workshop on Tools for Brain Computer Interaction (TOBI)</source> (<publisher-loc>Sion</publisher-loc>).</mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Donchin</surname><given-names>E.</given-names></name></person-group> (<year>1969</year>). <article-title>Discriminant analysis in average evoked response studies: the study of single trial data</article-title>. <source>Electroencephalogr. Clin. Neurophysiol</source>. <volume>27</volume>, <fpage>311</fpage>&#x02013;<lpage>314</lpage>
<pub-id pub-id-type="doi">10.1016/0013-4694(69)90061-3</pub-id><pub-id pub-id-type="pmid">4185662</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Eimer</surname><given-names>M.</given-names></name></person-group> (<year>2000</year>). <article-title>Event-related brain potentials distinguish processing stages involved in face perception and recognition</article-title>. <source>Clin. Neurophysiol</source>. <volume>111</volume>, <fpage>694</fpage>&#x02013;<lpage>705</lpage>
<pub-id pub-id-type="pmid">10727921</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farwell</surname><given-names>L. A.</given-names></name><name><surname>Donchin</surname><given-names>E.</given-names></name></person-group> (<year>1988</year>). <article-title>Talking off the top of your head: toward a mental prosthesis utilizing event-related brain potentials</article-title>. <source>Electroencephalogr. Clin. Neurophysiol</source>. <volume>70</volume>, <fpage>510</fpage>&#x02013;<lpage>523</lpage>
<pub-id pub-id-type="pmid">2461285</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Furdea</surname><given-names>A.</given-names></name><name><surname>Halder</surname><given-names>S.</given-names></name><name><surname>Krusienski</surname><given-names>D. J.</given-names></name><name><surname>Bross</surname><given-names>D.</given-names></name><name><surname>Nijboer</surname><given-names>F.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><etal/></person-group> (<year>2009</year>). <article-title>An auditory oddball (P300) spelling system for brain-computer interfaces</article-title>. <source>Psychophysiology</source>
<volume>46</volume>, <fpage>617</fpage>&#x02013;<lpage>625</lpage>
<pub-id pub-id-type="doi">10.1111/j.1469-8986.2008.00783.x</pub-id><pub-id pub-id-type="pmid">19170946</pub-id></mixed-citation></ref><ref id="B20a"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Halder</surname><given-names>S.</given-names></name><name><surname>Baykara</surname><given-names>E.</given-names></name><name><surname>Fioravanti</surname><given-names>C.</given-names></name><name><surname>Simon</surname><given-names>N.</given-names></name><name><surname>K&#x000e4;thner</surname><given-names>I.</given-names></name><name><surname>Pasqualotto</surname><given-names>E.</given-names></name><etal/></person-group> (<year>2013</year>). <article-title>Training effects of multiple auditory BCI sessions</article-title>, in <source>Fifth International Brain-Computer Interface Meeting 2013</source>, (<publisher-loc>Monterey</publisher-loc>). <pub-id pub-id-type="doi">10.3217/978-3-85125-260-6-80</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Halder</surname><given-names>S.</given-names></name><name><surname>Rea</surname><given-names>M.</given-names></name><name><surname>Andreoni</surname><given-names>R.</given-names></name><name><surname>Nijboer</surname><given-names>F.</given-names></name><name><surname>Hammer</surname><given-names>E. M.</given-names></name><name><surname>Kleih</surname><given-names>S. C.</given-names></name><etal/></person-group> (<year>2010</year>). <article-title>An auditory oddball brain-computer interface for binary choices</article-title>. <source>Clin. Neurophysiol</source>. <volume>121</volume>, <fpage>516</fpage>&#x02013;<lpage>523</lpage>
<pub-id pub-id-type="doi">10.1016/j.clinph.2009.11.087</pub-id><pub-id pub-id-type="pmid">20093075</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hill</surname><given-names>N. J.</given-names></name><name><surname>Sch&#x000f6;lkopf</surname><given-names>B.</given-names></name></person-group> (<year>2012</year>). <article-title>An online brain&#x02013;computer interface based on shifting attention to concurrent streams of auditory stimuli</article-title>. <source>J. Neural Eng</source>. <volume>9</volume>, <fpage>026011</fpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/9/2/026011</pub-id><pub-id pub-id-type="pmid">22333135</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Hill</surname><given-names>N. J.</given-names></name><name><surname>Lal</surname><given-names>T. N.</given-names></name><name><surname>Bierig</surname><given-names>K.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Sch&#x000f6;lkopf</surname><given-names>B.</given-names></name></person-group> (<year>2005</year>). <article-title>An Auditory Paradigm for Brain&#x02013;Computer Interfaces</article-title>, in <source>Advance in Neural Information Processing Systems</source>, <volume>Vol. 17</volume>, eds <person-group person-group-type="editor"><name><surname>Saul</surname><given-names>L. K.</given-names></name><name><surname>Weiss</surname><given-names>Y.</given-names></name><name><surname>Bottou</surname><given-names>L.</given-names></name></person-group> (<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>), <fpage>569</fpage>&#x02013;<lpage>576</lpage></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>H&#x000f6;hne</surname><given-names>J.</given-names></name><name><surname>Schreuder</surname><given-names>M.</given-names></name><name><surname>Blankertz</surname><given-names>B.</given-names></name><name><surname>Tangermann</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>Two-dimensional auditory p300 speller with predictive text system</article-title>. <source>Conf. Proc. IEEE Eng. Med. Biol. Soc</source>. <volume>2010</volume>, <fpage>4185</fpage>&#x02013;<lpage>4188</lpage>
<pub-id pub-id-type="doi">10.1109/IEMBS.2010.5627379</pub-id><pub-id pub-id-type="pmid">21096889</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>H&#x000f6;hne</surname><given-names>J.</given-names></name><name><surname>Schreuder</surname><given-names>M.</given-names></name><name><surname>Blankertz</surname><given-names>B.</given-names></name><name><surname>Tangermann</surname><given-names>M.</given-names></name></person-group> (<year>2011</year>). <article-title>A Novel 9-class auditory erp paradigm driving a predictive text entry system</article-title>. <source>Front. Neurosci</source>. <volume>5</volume>:<issue>99</issue>
<pub-id pub-id-type="doi">10.3389/fnins.2011.00099</pub-id><pub-id pub-id-type="pmid">21909321</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holz</surname><given-names>E.</given-names></name><name><surname>H&#x000f6;hne</surname><given-names>J.</given-names></name><name><surname>Staiger-S&#x000e4;lzer</surname><given-names>P.</given-names></name><name><surname>Tangermann</surname><given-names>M.</given-names></name><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name></person-group> (<year>in press</year>). <article-title>BCI-Controlled gaming: evaluation of usability by severely motor restricted end-users</article-title>. <source>Artif. Intell. Med</source>.</mixed-citation></ref><ref id="B26"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Holz</surname><given-names>E. M.</given-names></name><name><surname>Botrel</surname><given-names>L.</given-names></name><name><surname>Kaufmann</surname><given-names>T.</given-names></name><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name></person-group> (<year>2013</year>). <article-title>Long-term independent bci home-use by a locked-in end-user: an evaluation study</article-title>, in <source>Procedings of the Fifth International Brain Computer Interface Meeting</source> 2013 (<publisher-loc>Monterey, USA</publisher-loc>). <pub-id pub-id-type="doi">10.3217/978-3-85125-260-181</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Holz</surname><given-names>E. M.</given-names></name><name><surname>Kaufmann</surname><given-names>T.</given-names></name><name><surname>Desideri</surname><given-names>L.</given-names></name><name><surname>Malavasi</surname><given-names>M.</given-names></name><name><surname>Hoogerwerf</surname><given-names>E.-J.</given-names></name><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>User Centred Design in BCI Development</article-title>, in <source>Towards Practical Brain-Computer Interfaces</source>, eds <person-group person-group-type="editor"><name><surname>Allison</surname><given-names>B. Z.</given-names></name><name><surname>Dunne</surname><given-names>S.</given-names></name><name><surname>Leeb</surname><given-names>R.</given-names></name><name><surname>Mill&#x000e1;n</surname><given-names>J. D. R.</given-names></name><name><surname>Nijholt</surname><given-names>A.</given-names></name></person-group> (<publisher-loc>Berlin, Heidelberg</publisher-loc>: <publisher-name>Springer</publisher-name>), <fpage>155</fpage>&#x02013;<lpage>172</lpage> Available online at <ext-link ext-link-type="uri" xlink:href="http://link.springer.com/chapter/10.1007/978-3-642-29746-5_8">http://link.springer.com/chapter/10.1007/978-3-642-29746-5_8</ext-link></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>J.</given-names></name><name><surname>Allison</surname><given-names>B. Z.</given-names></name><name><surname>Kaufmann</surname><given-names>T.</given-names></name><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><etal/></person-group> (<year>2012</year>). <article-title>The changing face of P300 BCIs: a comparison of stimulus changes in a P300 BCI involving faces, emotion, and movement</article-title>. <source>PLoS ONE</source>
<volume>7</volume>:<fpage>e49688</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0049688</pub-id><pub-id pub-id-type="pmid">23189154</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jin</surname><given-names>J.</given-names></name><name><surname>Allison</surname><given-names>B. Z.</given-names></name><name><surname>Sellers</surname><given-names>E. W.</given-names></name><name><surname>Brunner</surname><given-names>C.</given-names></name><name><surname>Horki</surname><given-names>P.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>An adaptive P300-based control system</article-title>. <source>J. Neural Eng</source>. <volume>8</volume>, <fpage>036006</fpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/8/3/036006</pub-id><pub-id pub-id-type="pmid">21474877</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>K&#x000e4;thner</surname><given-names>I.</given-names></name><name><surname>Ruf</surname><given-names>C. A.</given-names></name><name><surname>Pasqualotto</surname><given-names>E.</given-names></name><name><surname>Braun</surname><given-names>C.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Halder</surname><given-names>S.</given-names></name></person-group> (<year>2013</year>). <article-title>A portable auditory P300 brain-computer interface with directional cues</article-title>. <source>Clin. Neurophysiol</source>. <volume>124</volume>, <fpage>327</fpage>&#x02013;<lpage>338</lpage>
<pub-id pub-id-type="doi">10.1016/j.clinph.2012.08.006</pub-id><pub-id pub-id-type="pmid">22959257</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufmann</surname><given-names>T.</given-names></name><name><surname>Schulz</surname><given-names>S. M.</given-names></name><name><surname>Gr&#x000fc;nzinger</surname><given-names>C.</given-names></name><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name></person-group> (<year>2011</year>). <article-title>Flashing characters with famous faces improves ERP-based brain-computer interface performance</article-title>. <source>J. Neural Eng</source>. <volume>8</volume>, <fpage>056016</fpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/8/5/056016</pub-id><pub-id pub-id-type="pmid">21934188</pub-id></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufmann</surname><given-names>T.</given-names></name><name><surname>Schulz</surname><given-names>S. M.</given-names></name><name><surname>K&#x000f6;blitz</surname><given-names>A.</given-names></name><name><surname>Renner</surname><given-names>G.</given-names></name><name><surname>Wessig</surname><given-names>C.</given-names></name><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name></person-group> (<year>2013a</year>). <article-title>Face stimuli effectively prevent brain&#x02013;computer interface inefficiency in patients with neurodegenerative disease</article-title>. <source>Clin. Neurophysiol</source>. <volume>124</volume>, <fpage>893</fpage>&#x02013;<lpage>900</lpage>
<pub-id pub-id-type="doi">10.1016/j.clinph.2012.11.006</pub-id><pub-id pub-id-type="pmid">23246415</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Kaufmann</surname><given-names>T.</given-names></name><name><surname>Herweg</surname><given-names>A.</given-names></name><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name></person-group> (<year>2013b</year>). <article-title>Tactually-evoked event-related potentials for bci-based wheelchair control in a virtual environment</article-title>, in <source>Proceedings of the Fifth International Brain Computer Interface Meeting</source> (<publisher-loc>Monterey, USA</publisher-loc>). <pub-id pub-id-type="doi">10.3217/978-4-83452-381-5/051</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufmann</surname><given-names>T.</given-names></name><name><surname>V&#x000f6;lker</surname><given-names>S.</given-names></name><name><surname>Gunesch</surname><given-names>L.</given-names></name><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name></person-group> (<year>2012a</year>). <article-title>Spelling is just a click away - a user-centered brain-computer interface including auto-calibration and predictive text entry</article-title>. <source>Front. Neurosci</source>. <volume>6</volume>:<issue>72</issue>
<pub-id pub-id-type="doi">10.3389/fnins.2012.00072</pub-id><pub-id pub-id-type="pmid">22833713</pub-id></mixed-citation></ref><ref id="B34a"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kaufmann</surname><given-names>T.</given-names></name><name><surname>V&#x000f6;gele</surname><given-names>C.</given-names></name><name><surname>S&#x000fc;tterlin</surname><given-names>S.</given-names></name><name><surname>Lukito</surname><given-names>S.</given-names></name><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name></person-group> (<year>2012b</year>) <article-title>Effects of resting heart rate variability on performance in the P300 brain-computer interface</article-title>. <source>Int. J. Psychophysiol.</source>
<volume>83</volume>, <fpage>336</fpage>&#x02013;<lpage>341</lpage>
<pub-id pub-id-type="doi">10.1016/j.ijpsycho.2011.11.018</pub-id><pub-id pub-id-type="pmid">22172335</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleih</surname><given-names>S. C.</given-names></name><name><surname>Kaufmann</surname><given-names>T.</given-names></name><name><surname>Zickler</surname><given-names>C.</given-names></name><name><surname>Halder</surname><given-names>S.</given-names></name><name><surname>Leotta</surname><given-names>F.</given-names></name><name><surname>Cincotti</surname><given-names>F.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Out of the frying pan into the fire&#x02014;the P300-based BCI faces real-world challenges</article-title>. <source>Prog. Brain Res</source>. <volume>194</volume>, <fpage>27</fpage>&#x02013;<lpage>46</lpage>
<pub-id pub-id-type="pmid">21867792</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Klobassa</surname><given-names>D. S.</given-names></name><name><surname>Vaughan</surname><given-names>T. M.</given-names></name><name><surname>Brunner</surname><given-names>P.</given-names></name><name><surname>Schwartz</surname><given-names>N. E.</given-names></name><name><surname>Wolpaw</surname><given-names>J. R.</given-names></name><name><surname>Neuper</surname><given-names>C.</given-names></name><etal/></person-group> (<year>2009</year>). <article-title>Toward a high-throughput auditory P300-based brain-computer interface</article-title>. <source>Clin. Neurophysiol</source>. <volume>120</volume>, <fpage>1252</fpage>&#x02013;<lpage>1261</lpage>
<pub-id pub-id-type="doi">10.1016/j.clinph.2009.04.019</pub-id><pub-id pub-id-type="pmid">19574091</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Krusienski</surname><given-names>D. J.</given-names></name><name><surname>Sellers</surname><given-names>E. W.</given-names></name><name><surname>Cabestaing</surname><given-names>F.</given-names></name><name><surname>Bayoudh</surname><given-names>S.</given-names></name><name><surname>McFarland</surname><given-names>D. J.</given-names></name><name><surname>Vaughan</surname><given-names>T. M.</given-names></name><etal/></person-group> (<year>2006</year>). <article-title>A comparison of classification techniques for the P300 Speller</article-title>. <source>J. Neural Eng</source>. <volume>3</volume>, <fpage>299</fpage>&#x02013;<lpage>305</lpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/3/4/007</pub-id><pub-id pub-id-type="pmid">17124334</pub-id></mixed-citation></ref><ref id="B38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name><name><surname>Furdea</surname><given-names>A.</given-names></name><name><surname>Halder</surname><given-names>S.</given-names></name><name><surname>Hammer</surname><given-names>E. M.</given-names></name><name><surname>Nijboer</surname><given-names>F.</given-names></name><name><surname>Kotchoubey</surname><given-names>B.</given-names></name></person-group> (<year>2009</year>). <article-title>A brain&#x02013;computer interface controlled auditory event-related potential (p300) spelling system for locked-in patients</article-title>. <source>Ann. N.Y. Acad. Sci</source>. <volume>1157</volume>, <fpage>90</fpage>&#x02013;<lpage>100</lpage>
<pub-id pub-id-type="doi">10.1111/j.1749-6632.2008.04122.x</pub-id><pub-id pub-id-type="pmid">19351359</pub-id></mixed-citation></ref><ref id="B39"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name><name><surname>Kotchoubey</surname><given-names>B.</given-names></name><name><surname>Kaiser</surname><given-names>J.</given-names></name><name><surname>Wolpaw</surname><given-names>J. R.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name></person-group> (<year>2001</year>). <article-title>Brain-computer communication: unlocking the locked in</article-title>. <source>Psychol. Bull</source>. <volume>127</volume>, <fpage>358</fpage>&#x02013;<lpage>375</lpage>
<pub-id pub-id-type="pmid">11393301</pub-id></mixed-citation></ref><ref id="B40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lenhardt</surname><given-names>A.</given-names></name><name><surname>Kaper</surname><given-names>M.</given-names></name><name><surname>Ritter</surname><given-names>H. J.</given-names></name></person-group> (<year>2008</year>). <article-title>An adaptive P300-based online brain-computer interface</article-title>. <source>IEEE transactions on neural systems and rehabilitation engineering: a publication of the IEEE Eng. Med. Biol. Soc</source>. <volume>16</volume>, <fpage>121</fpage>&#x02013;<lpage>130</lpage>
<pub-id pub-id-type="doi">10.1109/TNSRE.2007.912816</pub-id><pub-id pub-id-type="pmid">18403280</pub-id></mixed-citation></ref><ref id="B41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>T.</given-names></name><name><surname>Goldberg</surname><given-names>L.</given-names></name><name><surname>Gao</surname><given-names>S.</given-names></name><name><surname>Hong</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>An online brain&#x02013;computer interface using non-flashing visual evoked potentials</article-title>. <source>J. Neural Eng</source>. <volume>7</volume>, <fpage>036003</fpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/7/3/036003</pub-id><pub-id pub-id-type="pmid">20404396</pub-id></mixed-citation></ref><ref id="B42"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Zhou</surname><given-names>Z.</given-names></name><name><surname>Hu</surname><given-names>D.</given-names></name></person-group> (<year>2011</year>). <article-title>Gaze independent brain-computer speller with covert visual search tasks</article-title>. <source>Clin. Neurophysiol</source>. <volume>122</volume>, <fpage>1127</fpage>&#x02013;<lpage>1136</lpage>
<pub-id pub-id-type="doi">10.1016/j.clinph.2010.10.049</pub-id><pub-id pub-id-type="pmid">21163695</pub-id></mixed-citation></ref><ref id="B43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maguire</surname><given-names>M. C.</given-names></name></person-group> (<year>1998</year>). <source>User-Centred Requirements Handbook wp5 d5.3 of the Telematics Applications Project TE &#x02013; RESPECT: Requirements Engineering and Specification in Telematics</source>, The RESPECT Project Consortium 1998.</mixed-citation></ref><ref id="B44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Mak</surname><given-names>J. N.</given-names></name><name><surname>Arbel</surname><given-names>Y.</given-names></name><name><surname>Minett</surname><given-names>J. W.</given-names></name><name><surname>McCane</surname><given-names>L. M.</given-names></name><name><surname>Yuksel</surname><given-names>B.</given-names></name><name><surname>Ryan</surname><given-names>D.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Optimizing the P300-based brain-computer interface: current status, limitations and future directions</article-title>. <source>J. Neural Eng</source>. <volume>8</volume>, <fpage>025003</fpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/8/2/025003</pub-id><pub-id pub-id-type="pmid">21436525</pub-id></mixed-citation></ref><ref id="B45"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Plum</surname><given-names>F.</given-names></name><name><surname>Posner</surname><given-names>J. B.</given-names></name></person-group> (<year>1966</year>). <source>The Diagnosis of Stupor and Coma</source>. <publisher-loc>Philadelphia, PA</publisher-loc>: <publisher-name>FA Davis</publisher-name></mixed-citation></ref><ref id="B46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Polich</surname><given-names>J.</given-names></name></person-group> (<year>2007</year>). <article-title>Updating P300: an integrative theory of P3a and P3b</article-title>. <source>Clin. Neurophysiol</source>. <volume>118</volume>, <fpage>2128</fpage>&#x02013;<lpage>2148</lpage>
<pub-id pub-id-type="doi">10.1016/j.clinph.2007.04.019</pub-id><pub-id pub-id-type="pmid">17573239</pub-id></mixed-citation></ref><ref id="B47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Riccio</surname><given-names>A.</given-names></name><name><surname>Mattia</surname><given-names>D.</given-names></name><name><surname>Simione</surname><given-names>L.</given-names></name><name><surname>Olivetti</surname><given-names>M.</given-names></name><name><surname>Cincotti</surname><given-names>F.</given-names></name></person-group> (<year>2012</year>). <article-title>Eye-gaze independent EEG-based brain&#x02013;computer interfaces for communication</article-title>. <source>J. Neural Eng</source>. <volume>9</volume>, <fpage>045001</fpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/9/4/045001</pub-id><pub-id pub-id-type="pmid">22831893</pub-id></mixed-citation></ref><ref id="B48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ryan</surname><given-names>D. B.</given-names></name><name><surname>Frye</surname><given-names>G. E.</given-names></name><name><surname>Townsend</surname><given-names>G.</given-names></name><name><surname>Berry</surname><given-names>D. R.</given-names></name><name><surname>Mesa</surname><given-names>-G. S.</given-names></name><name><surname>Gates</surname><given-names>N. A.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>Predictive spelling with a P300-based brain-computer interface: increasing the rate of communication</article-title>. <source>Int. J. Hum. Comput. Interact</source>. <volume>27</volume>, <fpage>69</fpage>&#x02013;<lpage>84</lpage>
<pub-id pub-id-type="doi">10.1080/10447318.2011.535754</pub-id><pub-id pub-id-type="pmid">21278858</pub-id></mixed-citation></ref><ref id="B49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schalk</surname><given-names>G.</given-names></name><name><surname>McFarland</surname><given-names>D. J.</given-names></name><name><surname>Hinterberger</surname><given-names>T.</given-names></name><name><surname>Birbaumer</surname><given-names>N.</given-names></name><name><surname>Wolpaw</surname><given-names>J. R.</given-names></name></person-group> (<year>2004</year>). <article-title>BCI2000: a general-purpose brain-computer interface (BCI) system</article-title>. <source>IEEE Trans. Biomed. Eng</source>. <volume>51</volume>, <fpage>1034</fpage>&#x02013;<lpage>1043</lpage>
<pub-id pub-id-type="doi">10.1109/TBME.2004.827072</pub-id><pub-id pub-id-type="pmid">15188875</pub-id></mixed-citation></ref><ref id="B50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schreuder</surname><given-names>M.</given-names></name><name><surname>Blankertz</surname><given-names>B.</given-names></name><name><surname>Tangermann</surname><given-names>M.</given-names></name></person-group> (<year>2010</year>). <article-title>A new auditory multi-class brain-computer interface paradigm: spatial hearing as an informative cue</article-title>. <source>PLoS ONE</source>
<volume>5</volume>:<fpage>e9813</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0009813</pub-id><pub-id pub-id-type="pmid">20368976</pub-id></mixed-citation></ref><ref id="B51"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schreuder</surname><given-names>M.</given-names></name><name><surname>H&#x000f6;hne</surname><given-names>J.</given-names></name><name><surname>Blankertz</surname><given-names>B.</given-names></name><name><surname>Haufe</surname><given-names>S.</given-names></name><name><surname>Dickhaus</surname><given-names>T.</given-names></name><name><surname>Tangermann</surname><given-names>M.</given-names></name></person-group> (<year>2013</year>). <article-title>Optimizing event-related potential based brain&#x02013;computer interfaces: a systematic evaluation of dynamic stopping methods</article-title>. <source>J. Neural Eng</source>. <volume>10</volume>, <fpage>036025</fpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/10/3/036025</pub-id><pub-id pub-id-type="pmid">23685458</pub-id></mixed-citation></ref><ref id="B52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schreuder</surname><given-names>M.</given-names></name><name><surname>Rost</surname><given-names>T.</given-names></name><name><surname>Tangermann</surname><given-names>M.</given-names></name></person-group> (<year>2011a</year>). <article-title>Listen, You are Writing! Speeding up online spelling with a dynamic auditory BCI</article-title>. <source>Front. Neurosci</source>. <volume>5</volume>:<issue>112</issue>
<pub-id pub-id-type="doi">10.3389/fnins.2011.00112</pub-id><pub-id pub-id-type="pmid">22016719</pub-id></mixed-citation></ref><ref id="B53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schreuder</surname><given-names>M.</given-names></name><name><surname>H&#x000f6;hne</surname><given-names>J.</given-names></name><name><surname>Treder</surname><given-names>M.</given-names></name><name><surname>Blankertz</surname><given-names>B.</given-names></name><name><surname>Tangermann</surname><given-names>M.</given-names></name></person-group> (<year>2011b</year>). <article-title>Performance optimization of ERP-based BCIs using dynamic stopping</article-title>. <source>Conf. Proc. IEEE Eng. Med. Biol. Soc</source>. <volume>2011</volume>, <fpage>4580</fpage>&#x02013;<lpage>4583</lpage>
<pub-id pub-id-type="doi">10.1109/IEMBS.2011.6091134</pub-id><pub-id pub-id-type="pmid">22255357</pub-id></mixed-citation></ref><ref id="B54"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Sellers</surname><given-names>E. W.</given-names></name><name><surname>Arbel</surname><given-names>Y.</given-names></name><name><surname>Donchin</surname><given-names>E.</given-names></name></person-group> (<year>2012</year>). <article-title>BCIs that use P300 event-related potentials</article-title>, in <source>Brain-Computer Interfaces: Principles and Practice</source>, eds <person-group person-group-type="editor"><name><surname>Wolpaw</surname><given-names>J. R.</given-names></name><name><surname>Wolpaw</surname><given-names>E. W.</given-names></name></person-group> (<publisher-loc>New York, NY; Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>), <fpage>215</fpage>&#x02013;<lpage>226</lpage></mixed-citation></ref><ref id="B55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sellers</surname><given-names>E. W.</given-names></name><name><surname>Donchin</surname><given-names>E.</given-names></name></person-group> (<year>2006</year>). <article-title>A P300-based brain-computer interface: initial tests by ALS patients</article-title>. <source>Clin. Neurophysiol</source>. <volume>117</volume>, <fpage>538</fpage>&#x02013;<lpage>548</lpage>
<pub-id pub-id-type="doi">10.1016/j.clinph.2005.06.027</pub-id><pub-id pub-id-type="pmid">16461003</pub-id></mixed-citation></ref><ref id="B56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sellers</surname><given-names>E. W.</given-names></name><name><surname>Vaughan</surname><given-names>T. M.</given-names></name><name><surname>Wolpaw</surname><given-names>J. R.</given-names></name></person-group> (<year>2010</year>). <article-title>A brain-computer interface for long-term independent home use</article-title>. <source>Amyotroph. Lateral Scler</source>. <volume>11</volume>, <fpage>449</fpage>&#x02013;<lpage>455</lpage> 6/j.clinph.2005.06.027 <pub-id pub-id-type="doi">10.3109/17482961003777470</pub-id><pub-id pub-id-type="pmid">20583947</pub-id></mixed-citation></ref><ref id="B57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sutton</surname><given-names>S.</given-names></name><name><surname>Braren</surname><given-names>M.</given-names></name><name><surname>Zubin</surname><given-names>J.</given-names></name><name><surname>John</surname><given-names>E. R.</given-names></name></person-group> (<year>1965</year>). <article-title>Evoked-potential correlates of stimulus uncertainty</article-title>. <source>Science</source>
<volume>150</volume>, <fpage>1187</fpage>&#x02013;<lpage>1188</lpage>
<pub-id pub-id-type="doi">10.1126/science.150.3700.1187</pub-id><pub-id pub-id-type="pmid">5852977</pub-id></mixed-citation></ref><ref id="B58"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thurlings</surname><given-names>M. E.</given-names></name><name><surname>Van Erp</surname><given-names>J. B. F.</given-names></name><name><surname>Brouwer</surname><given-names>A.-M.</given-names></name><name><surname>Blankertz</surname><given-names>B.</given-names></name><name><surname>Werkhoven</surname><given-names>P.</given-names></name></person-group> (<year>2012</year>). <article-title>Control-display mapping in brain&#x02013;computer interfaces</article-title>. <source>Ergonomics</source>
<volume>55</volume>, <fpage>564</fpage>&#x02013;<lpage>580</lpage>
<pub-id pub-id-type="doi">10.1080/00140139.2012.661085</pub-id><pub-id pub-id-type="pmid">22506977</pub-id></mixed-citation></ref><ref id="B59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Treder</surname><given-names>M. S.</given-names></name><name><surname>Blankertz</surname><given-names>B.</given-names></name></person-group> (<year>2010</year>). <article-title>(C)overt attention and visual speller design in an ERP-based brain-computer interface.</article-title>
<source>Behav. Brain Funct</source>. <volume>6</volume>, <fpage>28</fpage>
<pub-id pub-id-type="doi">10.1186/1744-9081-6-28</pub-id><pub-id pub-id-type="pmid">20509913</pub-id></mixed-citation></ref><ref id="B60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>van der Waal</surname><given-names>M.</given-names></name><name><surname>Severens</surname><given-names>M.</given-names></name><name><surname>Geuze</surname><given-names>J.</given-names></name><name><surname>Desain</surname><given-names>P.</given-names></name></person-group> (<year>2012</year>). <article-title>Introducing the tactile speller: an ERP-based brain&#x02013;computer interface for communication</article-title>. <source>J. Neural Eng</source>. <volume>9</volume>, <fpage>045002</fpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/9/4/045002</pub-id><pub-id pub-id-type="pmid">22831906</pub-id></mixed-citation></ref><ref id="B61"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wolpaw</surname><given-names>J. R.</given-names></name><name><surname>Wolpaw</surname><given-names>E. W.</given-names></name></person-group> (<year>2012</year>). <source>Brain-Computer Interfaces: Principles and Practice</source>. <publisher-loc>New York, NY; Oxford</publisher-loc>: <publisher-name>Oxford University Press</publisher-name></mixed-citation></ref><ref id="B62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Y.</given-names></name><name><surname>Zhao</surname><given-names>Q.</given-names></name><name><surname>Jin</surname><given-names>J.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name><name><surname>Cichocki</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>A novel BCI based on ERP components sensitive to configural processing of human faces</article-title>. <source>J. Neural Eng</source>. <volume>9</volume>, <fpage>026018</fpage>
<pub-id pub-id-type="doi">10.1088/1741-2560/9/2/026018</pub-id><pub-id pub-id-type="pmid">22414683</pub-id></mixed-citation></ref><ref id="B63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zickler</surname><given-names>C.</given-names></name><name><surname>Halder</surname><given-names>S.</given-names></name><name><surname>Kleih</surname><given-names>S. C.</given-names></name><name><surname>Herbert</surname><given-names>C.</given-names></name><name><surname>K&#x000fc;bler</surname><given-names>A.</given-names></name></person-group> (<year>in press</year>). <article-title>Brain painting: usability testing according to the user-centered design in end users with severe disabilities</article-title>. <source>Artif. Intell. Med</source>.</mixed-citation></ref><ref id="B64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zickler</surname><given-names>C.</given-names></name><name><surname>Riccio</surname><given-names>A.</given-names></name><name><surname>Leotta</surname><given-names>F.</given-names></name><name><surname>Hillian-Tress</surname><given-names>S.</given-names></name><name><surname>Halder</surname><given-names>S.</given-names></name><name><surname>Holz</surname><given-names>E.</given-names></name><etal/></person-group> (<year>2011</year>). <article-title>A brain-computer interface as input channel for a standard assistive technology software</article-title>. <source>Clin. EEG Neurosci</source>. <volume>42</volume>, <fpage>236</fpage>&#x02013;<lpage>244</lpage>
<pub-id pub-id-type="doi">10.1177/15500594110420040</pub-id><pub-id pub-id-type="pmid">22208121</pub-id></mixed-citation></ref></ref-list></back></article>