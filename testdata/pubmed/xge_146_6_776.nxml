<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">J Exp Psychol Gen</journal-id><journal-id journal-id-type="iso-abbrev">J Exp Psychol Gen</journal-id><journal-title-group><journal-title>Journal of Experimental Psychology. General</journal-title></journal-title-group><issn pub-type="ppub">0096-3445</issn><issn pub-type="epub">1939-2222</issn><publisher><publisher-name>American Psychological Association</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28406682</article-id><article-id pub-id-type="pmc">5459222</article-id><article-id pub-id-type="publisher-id">xge_146_6_776</article-id><article-id pub-id-type="doi">10.1037/xge0000286</article-id><article-id pub-id-type="publisher-id">2017-16730-001</article-id><article-categories><subj-group subj-group-type="heading"><subject>Articles</subject></subj-group></article-categories><title-group><article-title>Overcoming Indecision by Changing the Decision Boundary</article-title></title-group><contrib-group><contrib contrib-type="editor" corresp="no"><name><surname>Gauthier</surname><given-names>Isabel</given-names></name><role>Editor</role></contrib><contrib contrib-type="editor" corresp="no"><name><surname>Cowan</surname><given-names>Nelson</given-names></name><role>Incoming Editor</role></contrib></contrib-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Malhotra</surname><given-names>Gaurav</given-names></name><xref rid="aff1" ref-type="aff">1</xref><xref rid="corr1" ref-type="corresp">*</xref></contrib><contrib contrib-type="author" corresp="no"><name><surname>Leslie</surname><given-names>David S.</given-names></name><xref rid="aff2" ref-type="aff">2</xref></contrib><contrib contrib-type="author" corresp="no"><name><surname>Ludwig</surname><given-names>Casimir J. H.</given-names></name><xref rid="aff3" ref-type="aff">3</xref></contrib><contrib contrib-type="author" corresp="no"><name><surname>Bogacz</surname><given-names>Rafal</given-names></name><xref rid="aff4" ref-type="aff">4</xref></contrib><aff id="aff1"><label>1</label>School of Experimental Psychology, University of Bristol</aff><aff id="aff2"><label>2</label>Department of Mathematics and Statistics, Lancaster University</aff><aff id="aff3"><label>3</label>School of Experimental Psychology, University of Bristol</aff><aff id="aff4"><label>4</label>MRC Brain Network Dynamics Unit, University of Oxford</aff></contrib-group><author-notes><p>This research was carried out as part of the project &#x02018;Decision making in an unstable world,&#x02019; supported by the Engineering and Physical Sciences Research Council (EPSRC), Grant Reference EP/1032622/1. Additionally, RB was supported by Medical Research Council Grant MC UU 12024/5. The funding sources had no other role other than financial support.</p><p>All authors contributed to the design of the experiment, the analysis of the results and the writing of the manuscript. All authors have read and approved the final manuscript.</p><p>We thank E. J. Wagenmakers, Daniel Wolpert, Andreas Jarvstad and Iain Gilchrist for their insightful comments during the development of this research. We also thank Caitlin Molloy for help with data collection in some of the experiments presented in this study.</p><p>Some of the experiments reported in this study were previously presented at the 46th Annual Meeting of the Society of Mathematical Psychology, August 4th&#x02013;7th, 2013, Potsdam, Germany and at Decision-Making Bristol, September 9th&#x02013;12th, 2014.</p><corresp id="corr1"><label>*</label>Correspondence concerning this article should be addressed to Gaurav Malhotra, School of Experimental Psychology, University of Bristol, 12a Priory Road, Bristol BS8 1TU, United Kingdom <email>gaurav.malhotra@bristol.ac.uk</email></corresp></author-notes><pub-date pub-type="epub"><day>13</day><month>4</month><year>2017</year></pub-date><pub-date pub-type="ppub"><month>6</month><year>2017</year></pub-date><volume>146</volume><issue>6</issue><fpage>776</fpage><lpage>805</lpage><history><date date-type="received"><day>25</day><month>8</month><year>2016</year></date><date date-type="rev-recd"><day>10</day><month>1</month><year>2017</year></date><date date-type="accepted"><day>16</day><month>1</month><year>2017</year></date></history><permissions><copyright-statement>&#x000a9; 2017 The Author(s)</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>The Author(s)</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/3.0/"><license-p>This article has been published under the terms of the Creative Commons Attribution License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/3.0/" specific-use="live">http://creativecommons.org/licenses/by/3.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited. Copyright for this article is retained by the author(s). Author(s) grant(s) the American Psychological Association the exclusive right to publish the article and identify itself as the original publisher.</license-p></license></permissions><abstract><p>The dominant theoretical framework for decision making asserts that people make decisions by integrating noisy evidence to a threshold. It has recently been shown that in many ecologically realistic situations, decreasing the decision boundary maximizes the reward available from decisions. However, empirical support for decreasing boundaries in humans is scant. To investigate this problem, we used an ideal observer model to identify the conditions under which participants should change their decision boundaries with time to maximize reward rate. We conducted 6 expanded-judgment experiments that precisely matched the assumptions of this theoretical model. In this paradigm, participants could sample noisy, binary evidence presented sequentially. Blocks of trials were fixed in duration, and each trial was an independent reward opportunity. Participants therefore had to trade off speed (getting as many rewards as possible) against accuracy (sampling more evidence). Having access to the actual evidence samples experienced by participants enabled us to infer the slope of the decision boundary. We found that participants indeed modulated the slope of the decision boundary in the direction predicted by the ideal observer model, although we also observed systematic deviations from optimality. Participants using suboptimal boundaries do so in a robust manner, so that any error in their boundary setting is relatively inexpensive. The use of a normative model provides insight into what variable(s) human decision makers are trying to optimize. Furthermore, this normative model allowed us to choose diagnostic experiments and in doing so we present clear evidence for time-varying boundaries.</p></abstract><kwd-group><kwd>decision making</kwd><kwd>decision threshold</kwd><kwd>decreasing bounds</kwd><kwd>optimal decisions</kwd><kwd>reward rate</kwd></kwd-group></article-meta></front><body><p>In an early theory of decision making, <xref rid="c14" ref-type="bibr" id="cr14-1">Cartwright and Festinger (1943)</xref> modeled decision making as a struggle between fluctuating forces. At each instant, the decision maker drew a sample from the (Gaussian) distribution for each force and computed the difference between these samples. This difference was the resultant force and no decision was made while the opposing forces were balanced and the resultant force was zero. Cartwright and Festinger realized that if a decision was made as soon as there was the slightest imbalance in forces, there would be no advantage to making decisions more slowly. This was inconsistent with the observation that the speed of making decisions traded-off with their accuracy, a property of decision making that had already been recorded (<xref rid="c21" ref-type="bibr" id="cr21-1">Festinger, 1943</xref>; <xref rid="c22" ref-type="bibr" id="cr22-1">Garrett, 1922</xref>; <xref rid="c36" ref-type="bibr" id="cr36-1">Johnson, 1939</xref>) and has been repeatedly observed since (e.g., <xref rid="c7" ref-type="bibr" id="cr7-1">Bogacz, Wagenmakers, Forstmann, &#x00026; Nieuwenhuis, 2010</xref>; <xref rid="c32" ref-type="bibr" id="cr32-1">Howell &#x00026; Kreidler, 1963</xref>; <xref rid="c51" ref-type="bibr" id="cr51-1">Pachella, 1974</xref>; <xref rid="c97" ref-type="bibr" id="cr97-1">Wickelgren, 1977</xref>; <xref rid="c42" ref-type="bibr" id="cr42-1">Luce, 1986</xref>). Cartwright and Festinger addressed the speed&#x02013;accuracy trade-off by introducing an internal <italic>restraining force&#x02014;</italic>also normally distributed and in the opposite direction to the resultant force&#x02014;which would prevent the decision maker from going off &#x0201c;half-cocked&#x0201d; (<xref rid="c14" ref-type="bibr" id="cr14-2">Cartwright &#x00026; Festinger, 1943</xref>, p. 598). The decision maker drew samples from this restraining force and did not make a decision until the resultant force was larger than these samples. The restraining force was adaptable and could be adjusted on the basis of whether the decision maker wanted to emphasize speed or accuracy in the task.</p><p>In the ensuing decades, Cartwright and Festinger&#x02019;s theory fell out of favor because several shortcomings (see <xref rid="c35" ref-type="bibr" id="cr35-1">Irwin, Smith, &#x00026; Mayfield, 1956</xref>; <xref rid="c86" ref-type="bibr" id="cr86-1">Vickers, Nettelbeck, &#x00026; Willson, 1972</xref>) and was superseded by the signal detection theory (<xref rid="c78" ref-type="bibr" id="cr78-1">Tanner &#x00026; Swets, 1954</xref>) and sequential sampling models (<xref rid="c38" ref-type="bibr" id="cr38-1">LaBerge, 1962</xref>; <xref rid="c39" ref-type="bibr" id="cr39-1">Laming, 1968</xref>; <xref rid="c41" ref-type="bibr" id="cr41-1">Link &#x00026; Heath, 1975</xref>; <xref rid="c59" ref-type="bibr" id="cr59-1">Ratcliff, 1978</xref>; <xref rid="c77" ref-type="bibr" id="cr77-1">Stone, 1960</xref>; <xref rid="c83" ref-type="bibr" id="cr83-1">Vickers, 1970</xref>). These models do not mention a restraining force explicitly, but this concept is implicit in a threshold, which must be crossed before the decision maker indicates their choice. Just as the restraining force could be adjusted based on the emphasis on speed or accuracy, these models proposed that the threshold could be lowered or raised to emphasize speed or accuracy. This adaptability of thresholds has been a key strength of these models, a feature that has been used to explain how distribution of response latencies changes when subjects are instructed to emphasize speed or accuracy in a decision (for a review, see <xref rid="c5" ref-type="bibr" id="cr5-1">Bogacz, Brown, Moehlis, Holmes, &#x00026; Cohen, 2006</xref>; <xref rid="c65" ref-type="bibr" id="cr65-1">Ratcliff &#x00026; Smith, 2004</xref>; <xref rid="c66" ref-type="bibr" id="cr66-1">Ratcliff, Smith, Brown, &#x00026; McKoon, 2016</xref>).</p><p>Introducing a restraining force or a threshold to explain the speed&#x02013;accuracy trade-off answers one question but raises another: How should a decision maker select the restraining force (threshold) for a decision-making problem? Should this restraining force remain constant during a decision? This problem was examined by <xref rid="c91" ref-type="bibr" id="cr91-1">Wald (1947)</xref> who proposed that, for an isolated decision, an optimal decision maker can distinguish between two hypotheses by choosing the desired ratio of Type I and Type II errors and then using a statistical procedure called the sequential-probability-ratio-test (SPRT). In the SPRT, the decision maker sequentially computes the ratio of the likelihoods of all observations given the hypotheses and the decision process terminates only once the ratio exceeds a threshold (corresponding to accepting the first hypothesis) or decreases below another threshold (corresponding to accepting the second hypothesis). The values of these thresholds do not change as more samples are accumulated and they determine the accuracy of decisions. <xref rid="c92" ref-type="bibr" id="cr92-1">Wald and Wolfowitz (1948)</xref> showed that the SPRT requires a smaller or equal number of observations, on average, than any other statistical procedure for a given accuracy of decisions.</p><p>The SPRT gives a statistically optimal procedure to set the threshold for an isolated decision. However, in many real-world decision problems&#x02014;a bird foraging for food, a market trader deciding whether to keep or sell stocks, a professor going through a pile of job applications or, indeed, a psychology undergraduate doing an experiment for course credits&#x02014;decisions are not made in isolation; rather, individuals have to make a sequence of decisions. How should one set the threshold in this situation? Is the optimal threshold still given by SPRT? If decision makers accrue a reward from each decision, an ecologically sensible goal for the decision maker may be to maximize the expected reward from these decisions, rather than to minimize the number of samples required to make a decision with a given accuracy (as SPRT does). And for sequences that involve a large number of decisions or sequence of decisions that do not have a clearly defined end point, it would make sense for the decision maker to maximize the <italic>reward rate</italic> (i.e., the expected amount of rewards per unit time). In fact, under certain assumptions, including the assumption that every decision in a sequence has the same difficulty, it can be shown that the two optimization criteria&#x02014;SPRT and reward rate&#x02014;result in the same threshold (<xref rid="c5" ref-type="bibr" id="cr5-2">Bogacz et al., 2006</xref>). That is, the decision maker can maximize reward rate by using the SPRT and maintaining an appropriately chosen threshold that remains constant within and across trials. Experimental data suggest that people do indeed adapt their speed and accuracy to improve their reward rate (<xref rid="c6" ref-type="bibr" id="cr6-1">Bogacz, Hu, Holmes, &#x00026; Cohen, 2010</xref>; <xref rid="c72" ref-type="bibr" id="cr72-1">Simen et al., 2009</xref>). This adaptability seems to be larger for younger than older adults (<xref rid="c75" ref-type="bibr" id="cr75-1">Starns &#x00026; Ratcliff, 2010</xref>, <xref rid="c76" ref-type="bibr" id="cr76-1">2012</xref>) and seems to become stronger with practice (<xref rid="c2" ref-type="bibr" id="cr2-1">Balci et al., 2011</xref>) and guidance (<xref rid="c20" ref-type="bibr" id="cr20-1">Evans &#x00026; Brown, 2016</xref>).</p><p>However, maintaining a fixed and time-invariant threshold across a sequence of trials cannot be the optimal solution in many ecologically realistic situations where the difficulty of decisions fluctuates from trial-to-trial. Consider, for example, a situation in which there is very little information or evidence in favor of the different decision alternatives. Accumulating little evidence to a fixed threshold might take a very long time. The decision maker risks being stuck in such an impoverished trial because they are unable to choose between two equally uninformative options, like Buridan&#x02019;s donkey (see <xref rid="c40" ref-type="bibr" id="cr40-1">Lamport, 2012</xref>), who risks being starved because it is unable to choose between two equally palatable options. <xref rid="c14" ref-type="bibr" id="cr14-3">Cartwright and Festinger (1943)</xref> foresaw this problem and noted that &#x0201c;there is good reason to suppose that the longer the individual stays in the decision region, the weaker are the restraining forces against leaving it&#x0201d; (p. 600). So they speculated that the mean restraining force should be expressed as a decreasing function of time but they were not prepared to make specific assumptions as to the exact nature of this function.</p><p>In cases where the restraining force may change with time, the concept of a fixed threshold may be replaced by a time-dependent decision boundary between making more observations and choosing an alternative. A number of recent studies have mathematically computed the shape of decision boundaries that maximize reward rate when decisions in a sequence vary in difficulty and shown that the decision maker can maximize the reward rate by decreasing this decision boundary with time (<xref rid="c18" ref-type="bibr" id="cr18-1">Drugowitsch, Moreno-Bote, Churchland, Shadlen, &#x00026; Pouget, 2012</xref>; <xref rid="c33" ref-type="bibr" id="cr33-1">Huang &#x00026; Rao, 2013</xref>; <xref rid="c48" ref-type="bibr" id="cr48-1">Moran, 2015</xref>). It can also be shown that the shape of the boundary that maximizes reward rate depends on the mixture of decision difficulties. Indeed, on the basis of the difficulties of decisions in a sequence, optimal boundaries may decrease, remain constant or increase (<xref rid="c46" ref-type="bibr" id="cr46-1">Malhotra, Leslie, Ludwig, &#x00026; Bogacz, 2017</xref>; also see subsequent text).<xref ref-type="fn" rid="fn1"><sup>1</sup></xref></p><p>The goal of this study was to test whether, and under what circumstances, humans vary their decision boundaries with time during a decision. More generally, we assessed the relationship between the bounds used by people and the optimal bounds&#x02014;that is, the boundary that maximizes reward rate. Importantly, we adopt an experimental approach that is firmly rooted in a mathematical optimality analysis (<xref rid="c46" ref-type="bibr" id="cr46-2">Malhotra et al., 2017</xref>) and that allows us to infer the decision boundary relatively directly based on the sequences of evidence samples actually experienced by decision makers.</p><p>Previous evidence on whether people change decision boundaries at all during a trial, much less adapt it to be optimal, is inconclusive. Some evidence of time-dependent boundaries was found early on in studies that compared participant behavior with Wald&#x02019;s optimal procedure. These studies used an expanded-judgment paradigm in which the participant makes their decision based on a sequence of discrete samples or observations presented at discrete times&#x02014;for example, deciding between two deck of cards with different means based on cards sampled sequentially from the two decks (see, e.g., <xref rid="c3" ref-type="bibr" id="cr3-1">Becker, 1958</xref>; <xref rid="c12" ref-type="bibr" id="cr12-1">Busemeyer, 1985</xref>; <xref rid="c34" ref-type="bibr" id="cr34-1">Irwin et al., 1956</xref>; <xref rid="c47" ref-type="bibr" id="cr47-1">Manz, 1970</xref>; <xref rid="c57" ref-type="bibr" id="cr57-1">Pleskac &#x00026; Busemeyer, 2010</xref>; <xref rid="c73" ref-type="bibr" id="cr73-1">Smith &#x00026; Vickers, 1989</xref>; <xref rid="c84" ref-type="bibr" id="cr84-1">Vickers, 1995</xref>). The advantage of this paradigm is that the experimenter can record not only the response time and accuracy of the participant, but also the exact sequence of samples on which they base their decisions. In an expanded-judgment paradigm <xref rid="c56" ref-type="bibr" id="cr56-1">Pitz, Reinhold, and Geller (1969)</xref> found that participants made decisions at lower posterior odds when the number of samples increased. Similar results were reported by <xref rid="c69" ref-type="bibr" id="cr69-1">Sanders and Linden (1967)</xref> and <xref rid="c93" ref-type="bibr" id="cr93-1">Wallsten (1968)</xref>. Curiously, participants seemed to be disregarding the optimal strategy in these studies, which was to keep decision boundaries constant. We discuss in the following text why this behavior may be ecologically rational when the participant has uncertainty about task parameters.</p><p>The shape of decision boundaries has been also analyzed in a number of experiments using a paradigm where the samples drawn by the participant are implicit, that is, hidden from the experimenter. In these paradigms, the data recorded is limited to the response time and accuracy, so one can distinguish between constant or variable decision boundaries only indirectly, by fitting the two models to the data and comparing them. These tasks generally involve detecting a signal in the presence of noise. Therefore, to distinguish these experiments from the expanded-judgment tasks, we call them <italic>signal detection tasks</italic>. Examples of this paradigm include lexical decisions (<xref rid="c90" ref-type="bibr" id="cr90-1">Wagenmakers, Ratcliff, Gomez, &#x00026; McKoon, 2008</xref>), basic perceptual discrimination (e.g., brightness; <xref rid="c64" ref-type="bibr" id="cr64-1">Ratcliff &#x00026; Rouder, 1998</xref>; <xref rid="c44" ref-type="bibr" id="cr44-1">Ludwig, Gilchrist, McSorley, &#x00026; Baddeley, 2005</xref>), and numerosity judgments (<xref rid="c76" ref-type="bibr" id="cr76-2">Starns &#x00026; Ratcliff, 2012</xref>). <xref rid="c55" ref-type="bibr" id="cr55-1">Pike (1968)</xref> analyzed data from a number of psychophysical discrimination studies and found that this data is best explained by the accumulator model (<xref rid="c1" ref-type="bibr" id="cr1-1">Audley &#x00026; Pike, 1965</xref>) if subjects either vary decision bounds between trials or decrease bounds during a trial. Additional support for decreasing boundaries was found by <xref rid="c18" ref-type="bibr" id="cr18-2">Drugowitsch et al. (2012)</xref>, who analyzed data collected by <xref rid="c52" ref-type="bibr" id="cr52-1">Palmer, Huk, and Shadlen (2005)</xref>. Finally, data from nonhuman primates performing a random dot motion discrimination task (<xref rid="c67" ref-type="bibr" id="cr67-1">Roitman &#x00026; Shadlen, 2002</xref>) were best fit by a diffusion model with decreasing boundaries (<xref rid="c17" ref-type="bibr" id="cr17-1">Ditterich, 2006</xref>).</p><p>In contrast to these studies that found evidence favoring decreasing boundaries, <xref rid="c30" ref-type="bibr" id="cr30-1">Hawkins, Forstmann, Wagenmakers, Ratcliff, and Brown (2015)</xref> analyzed data from experiments on human and nonhuman primates spanning a range of experiments using signal detection paradigms and found equivocal support for constant and decreasing boundaries. They found that overall evidence, especially in humans, favored constant boundaries and that, crucially, experimental procedures such as the extent of task practice seemed to play a role in which option was favored. Therefore, what seems to be missing is a more systematic analysis of the conditions under which people decrease the decision boundary within a trial and understanding why they would do so.</p><p>In this study, we took a different approach: Rather than inferring the decision boundaries indirectly by fitting different boundaries to explain RTs and error rates, we used the expanded-judgment paradigm, where the experimenter can observe the exact sequence of samples used by the participant and record the exact evidence and time used to make a decision. This evidence and time should lie on the boundary. This allowed us to make a more direct estimate of the decision boundary used by the participants and compare this boundary with the optimal boundary. We found that, in general, participants modulated their decision boundaries during a trial in a manner predicted by the maximization of reward rate. This effect was robust across paradigms and for decisions that play out over time scales that range from several hundreds of ms to several s. However, there were also systematic deviations from optimal behavior. Much like the expanded-judgment tasks discussed in preceding text, in a number of our experiments participants seemed to decrease their decision boundary even when it was optimal to keep them constant. We mapped these strategies on to the <italic>reward landscape</italic>, predicted by the theoretical model&#x02014;that is, the variation in reward rate with different settings of the decision boundary. These analyses suggest that participants&#x02019; choice of decision boundary may be guided not only by maximizing the reward rate, but also by robustness considerations. That is, they appear to allow for some &#x0201c;error&#x0201d; in their boundary setting due to uncertainty in task parameters and deviate from optimality in a manner that reduces the impact of such error.</p><p>Although it has been argued that the results from an expanded-judgment task can be generalized to signal detection paradigms, where sampling is implicit (<xref rid="c19" ref-type="bibr" id="cr19-1">Edwards, 1965</xref>; <xref rid="c34" ref-type="bibr" id="cr34-2">Irwin &#x00026; Smith, 1956</xref>; <xref rid="c69" ref-type="bibr" id="cr69-2">Sanders &#x00026; Linden, 1967</xref>; <xref rid="c57" ref-type="bibr" id="cr57-2">Pleskac &#x00026; Busemeyer, 2010</xref>; <xref rid="c85" ref-type="bibr" id="cr85-1">Vickers, Burt, Smith, &#x00026; Brown, 1985</xref>), these tasks usually use a slow presentation rate and elicit longer response latencies than those expected for perceptual decisions. It is possible that attention and memory play a different role in decision making at this speed than at faster speeds at which perceptual decisions occur. To address this possibility, we adapted the expanded-judgment task to allow fast presentation rates and consequently elicit rapid decisions.</p><p>The rest of the article is split into five sections. First, we summarize the theoretical basis for the relationship between a boundary and reward rate. In the next three sections, we describe a series of expanded-judgment tasks, each of which compares the boundaries used by participants with the theoretically optimal boundaries. In the final section, we consider the implications of our findings as well as the potential mechanisms by which time-varying boundaries may be instantiated. Data from all experiments reported in this article is available online (<ext-link ext-link-type="uri" xlink:href="https://osf.io/f3vhr/" specific-use="live">https://osf.io/f3vhr/</ext-link>).</p><sec id="s2"><title>Optimal Shape of Decision Boundaries</title><p>We now outline how an expanded-judgment task can be mathematically modeled and how this model can be used to establish the relationship between the task&#x02019;s parameters and decision boundaries that maximize reward rate. We summarize the key results from a theoretical study of <xref rid="c46" ref-type="bibr" id="cr46-3">Malhotra et al. (2017)</xref>, provide intuition for them, and state predictions that we tested experimentally.</p><p>Consider an expanded-judgment task that consists of making a sequence of decisions, each of which yields a unit reward if the decision is correct. Each decision (or trial) consists of estimating the true state of the world on the basis of a sequence of noisy observations. We consider the simplest possible case in which the world can be in one of two different states, call these <italic>up</italic> or <italic>down</italic>, and each observation of the world can be one of two different outcomes. Each outcome provides a fixed amount of evidence, &#x003b4;<italic>X</italic>, to the decision maker about the true state of the world:
<disp-formula id="eqn1"><alternatives><graphic xlink:href="xge_146_6_776_eqn1a.jpg" id="eqn1a"/><mml:math id="M1"><mml:mrow><mml:mi>&#x003b4;</mml:mi><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mtext>with&#x02009;probability</mml:mtext></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mi>u</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mtext>with&#x02009;probability</mml:mtext></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>u</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives><label>1</label></disp-formula>
where <italic>u</italic> is the up-probability that governs how quickly evidence is accumulated and depends on the true state of the world. We assume throughout that <italic>u</italic> &#x02265; 0.5 when the true state is up and <italic>u</italic> &#x02264; 0.5 when the true state is down. Note that the parameter <italic>u</italic> will determine the difficulty of a decision&#x02014;when <italic>u</italic> is close to 0.5 the decision will be hard while when <italic>u</italic> is close to 0 or 1 the decision will be easy.</p><p><xref ref-type="fig" id="fgc1-1" rid="fig1">Figure 1</xref> illustrates the process of making a decision in this expanded-judgment task. As assumed in sequential sampling models, decision making involves the accumulation of the probabilistic evidence, so let <italic>x</italic> be the cumulative evidence, that is, the sum of all &#x003b4;<italic>X</italic> outcomes. The accumulation continues till <italic>x</italic> crosses one of two boundaries &#x003b8; corresponding to the options, so that the decision maker responds up when <italic>x</italic> &#x0003e; &#x003b8;, and down when <italic>x</italic> &#x0003c; &#x02212;&#x003b8;. During the expanded-judgment task described above, the state of the decision maker, at any point of time, is defined by the pair (<italic>t</italic>, <italic>x</italic>), where <italic>t</italic> is the number of observations made. In any given state, the decision maker can take one of two actions: (a) make another observation&#x02014;we call this action <italic>wait</italic>, or (b) signal their estimate of the true state of the world&#x02014;we call this the action <italic>go</italic>. As shown in <xref ref-type="fig" id="fgc1-2" rid="fig1">Figure 1</xref>, taking an action wait can lead to one of two transitions: the next observed outcome is +1; in this case, make a transition to state (<italic>t</italic> + 1, <italic>x</italic> + 1), or the next observed outcome is &#x02212;1; in this case, make a transition to state (<italic>t</italic> + 1, <italic>x</italic> &#x02212; 1). Similarly, taking the action go can also lead to one of two transitions: (a) The estimated state is the true state of the world; in this case, collect a reward and make a transition to the correct state, or (b) the estimated state is not the true state of the world; in this case, make a transition to the incorrect state. After making a transition to a correct or incorrect state, the decision maker starts a new decision, that is, returns to the state (<italic>t</italic>, <italic>x</italic>) = (0, 0) after an intertrial delay <italic>D</italic><sub><italic>C</italic></sub> following a correct choice and <italic>D</italic><sub><italic>I</italic></sub> following the incorrect choice.<xref ref-type="fig-anchor" rid="fig1"/></p><p>These set of state-action pairs and transitions between these states defines a Markov decision process (MDP) shown schematically in <xref ref-type="fig" id="fgc1-3" rid="fig1">Figure 1</xref>. In this framework, any decision boundary that is a function of time, &#x003b8; = <italic>f</italic>(<italic>t</italic>), can be mapped to a set of actions, such that action wait is selected for any state within the boundaries, and action go is selected for any state on or beyond the boundaries. The mapping that assigns actions to all possible states is called a <italic>policy</italic> for the MDP.</p><p>We assume that a decision maker wishes to maximize the reward rate (i.e., the expected number of rewards per unit time). The reward rate depends on the decision boundary: If the boundary is too low, the decision maker will make errors and miss possible rewards, but if it is too high, each decision will take a long period, and the number of reward per unit of time will also be low.</p><p>The policy that maximizes average reward can be obtained by using a dynamic programming procedure known as <italic>policy iteration</italic> (<xref rid="c31" ref-type="bibr" id="cr31-1">Howard, 1960</xref>; <xref rid="c58" ref-type="bibr" id="cr58-1">Puterman, 2005</xref>; <xref rid="c68" ref-type="bibr" id="cr68-1">Ross, 1983</xref>). Several recent studies have shown how dynamic programming can be applied to decision-making tasks to get a policy that maximizes reward rate (see, e.g., <xref rid="c18" ref-type="bibr" id="cr18-3">Drugowitsch et al., 2012</xref>; <xref rid="c33" ref-type="bibr" id="cr33-2">Huang &#x00026; Rao, 2013</xref>; <xref rid="c46" ref-type="bibr" id="cr46-4">Malhotra et al., 2017</xref>). We now summarize how the optimal shape of decision boundary depends on task&#x02019;s parameters on the basis of the analysis given in <xref rid="c46" ref-type="bibr" id="cr46-5">Malhotra et al. (2017)</xref>. Let us first consider a class of tasks in which the difficulty of the decisions is fixed. That is, evidence can point either toward up or down, but the quality of the evidence remains fixed across decisions: <mml:math id="math1"><mml:mrow><mml:mi>u</mml:mi><mml:mspace width=".33em"/><mml:mo>&#x02208;</mml:mo><mml:mspace width=".33em"/><mml:mo>{</mml:mo><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003f5;</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mo>+</mml:mo><mml:mi>&#x003f5;</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math>, with &#x003f5; corresponding to the drift. The drift can take values in range <mml:math id="math2"><mml:mrow><mml:mi>&#x003f5;</mml:mi><mml:mspace width=".33em"/><mml:mo>&#x02208;</mml:mo><mml:mo stretchy="false">[</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mo stretchy="false">]</mml:mo></mml:mrow></mml:math> and it determines the difficulty of each trial with higher drift corresponding to easier trials. For single-difficulty tasks, &#x003f5; remains fixed across trials.</p><p>In the single-difficulty tasks, reward rate can be optimized by choosing a policy such that the decision boundary remains constant during each decision. Intuitively, this is because the decision maker&#x02019;s estimate of the probability that the world is in a particular state depends only on integrated evidence <italic>x</italic>, but not on time elapsed within the trial <italic>t</italic>. Therefore, the optimal action to take in each state only depends on <italic>x</italic> but not <italic>t</italic>, so go actions are only taken if <italic>x</italic> exceeds a particular value, leading to constant boundaries.</p><p>The optimal height of the decision boundary in the single-difficulty tasks depends on task difficulty in a nonmonotonic way. For very easy tasks (&#x003f5; close to <mml:math id="math3"><mml:mrow><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow></mml:math>), each outcome is a very reliable predictor of the state of the world, so very few outcomes need to be seen to obtain an accurate estimate of the state of the world (<xref ref-type="fig" id="fgc2-1" rid="fig2">Figure 2a</xref>). As the difficulty increases, more outcomes are required, and the optimal boundary increases (compare <xref ref-type="fig" id="fgc2-2" rid="fig2">Figures 2a</xref> and <xref ref-type="fig" id="fgc2-3" rid="fig2">2b</xref>). However, when the task becomes very difficult (&#x003f5; close 0), there is little benefit in observing the stimulus at all, and for &#x003f5; = 0 the optimal strategy is not to integrate evidence at all, but guess immediately, that is, &#x003b8; = 0 (compare <xref ref-type="fig" id="fgc2-4" rid="fig2">Figures 2d</xref> and <xref ref-type="fig" id="fgc2-5" rid="fig2">2e</xref>).<xref ref-type="fig-anchor" rid="fig2"/></p><p>Let us now consider a mixed-difficulty task, in which half of the trials are easy with drift &#x003f5;<sub><italic>e</italic></sub> and the other half of the trials are difficult with drift &#x003f5;<sub><italic>d</italic></sub>, where &#x003f5;<sub><italic>e</italic></sub> &#x0003e; &#x003f5;<sub><italic>d</italic></sub>. We assume that during mixed-difficulty tasks, the decision maker knows that there are two levels of difficulty (either through experience or instruction), but does not know if a particular trial is easy or difficult. Indeed, a key assumption of the underlying theory is that the difficulty level is something the decision maker has to infer during the accumulation of evidence.</p><p>In mixed-difficulty tasks, reward rate is optimized by using boundaries that may decrease, increase or remain constant based on the mixture of difficulties. Intuitively, this is because the decision maker&#x02019;s estimate of the probability that the world is in a particular state, given the existing evidence, depends on their inference about the difficulty of the trial. Time becomes informative in mixed-difficulty tasks because it helps the decision maker infer whether a given trial is easy or difficult and hence the estimate of the true state of the world depends not only on the evidence, <italic>x</italic>, but also on the time, <italic>t</italic>. The optimal decision maker should begin each decision trial assuming the decision could be easy or difficult. Therefore, &#x003b8; at the beginning of the trial should be in between the optimal boundaries for the two difficulties. As they make observations, they will update their estimate of the task difficulty. In particular, as time within a trial progresses, and the decision boundary has not been reached, the estimated probability of the trial being difficult increases and the decision boundary moves toward the optimal boundary for the difficult trials.</p><p>The above principle is illustrated in <xref ref-type="fig" id="fgc2-6" rid="fig2">Figures 2c</xref> and <xref ref-type="fig" id="fgc2-7" rid="fig2">2f</xref> showing optimal boundaries for two sample mixed-difficulty tasks. <xref ref-type="fig" id="fgc2-8" rid="fig2">Figure 2f</xref> shows the optimal boundary for a task in which half of the trials have moderate difficulty and half are very difficult (the optimal bounds for single-difficultly tasks with corresponding values of drift are shown in <xref ref-type="fig" id="fgc2-9" rid="fig2">Figures 2d</xref> and <xref ref-type="fig" id="fgc2-10" rid="fig2">2e</xref>). As the time progresses the optimal decision maker infers that a trial is likely to be very difficult, so an optimal strategy involves moving on to the next trial (which may be easier), that is, decreasing the decision boundary with time in the trial.</p><p>In contrast, when the boundary for the difficult task is higher than the easy task (the difficult task is not extremely hard; <xref ref-type="fig" id="fgc2-11" rid="fig2">Figures 2a</xref> and <xref ref-type="fig" id="fgc2-12" rid="fig2">2b</xref>), the optimal boundary in the mixed-difficulty task will again start at a value in-between the boundaries for the easy and difficult tasks and approach the boundary for the difficult task (<xref ref-type="fig" id="fgc2-13" rid="fig2">Figure 2c</xref>). In this case, the boundary for the difficult task will be higher than the easy task meaning that the optimal boundary will increase with time.</p><p>In summary, the mathematical model makes three key predictions about the normative behavior: (a) optimal decision boundaries should stay constant if all decisions in a sequence are of the same difficulty, (b) it is optimal to decrease decision boundaries if decisions are of mixed difficulty and some decisions are extremely difficult (or impossible), and (c) it may be optimal to keep decision boundaries constant or even increase them in mixed-difficulty tasks where the difficult decision is not too difficult. In the next three sections, we compare human behavior with these normative results.</p></sec><sec id="s3"><title>Experiment 1</title><p>To compare human behavior with the normative behavior described previously, we designed an experiment that involved an evidence-foraging game which parallels the expanded-judgment task described in the previous section. We modeled this evidence-foraging game on previous expanded-judgment tasks, such as <xref rid="c34" ref-type="bibr" id="cr34-3">Irwin et al. (1956)</xref> and <xref rid="c85" ref-type="bibr" id="cr85-2">Vickers, Burt, et al. (1985)</xref>, where participants are shown a sequence of discrete observations and required to judge the distribution from which these observations were drawn. We modified these expanded-judgment paradigms so that (a) the observations could have only one of two values (i.e., drawn from the Bernoulli distribution), (b) the reward-structure of the task was based on performance, and (c) the task had an intrinsic speed&#x02013;accuracy trade-off. We introduced a speed&#x02013;accuracy trade-off by using a fixed-time blocks paradigm: the experiment was divided into a number of games, the total duration for each game was fixed, and participants could attempt as many decisions as they like during this period. Therefore, if a participant takes a very long time for each decision they are likely to be accurate, but will not be able to complete many decisions during a game. If a participant decides very quickly, they are likely to perform worse in terms of accuracy, but will have more reward &#x0201c;opportunities&#x0201d; during the game. The goal of the participants was to collect as much reward as possible during each game, so they need to find a balance between these two strategies.</p><p>In this expanded judgment task, we are able to record the exact sequence of stimuli presented to the participants and the position in state-space (<italic>t</italic>, <italic>x</italic>) at which participants made their decisions. Based on the location of these decisions, we inferred how the decision boundary for a participant depended on time. According to the above theory, the optimal decision boundary should be independent of time in single-difficultly tasks, but could vary with time during mixed-difficulty tasks. By comparing the inferred decision boundary with optimal boundaries in each type of task, we assessed whether participants adjusted their decision boundaries to maximize reward rate.</p><sec id="s4"><title>Method</title><sec id="s5"><title>Description of task</title><p>Twenty-four participants from the university community were asked to play a set of games on a computer. The number of participants was chosen to give a sample size that is comparable to previous human decision-making studies and kept constant during all of our experiments.<xref ref-type="fn" rid="fn2"><sup>2</sup></xref> Each game lasted a fixed duration and participants made a series of decisions during this time. Correct decisions led to a reward and participants were asked to maximize the cumulative reward. The game was programmed using Matlab&#x000ae; and Psychtoolbox (<xref rid="c9" ref-type="bibr" id="cr9-1">Brainard, 1997</xref>; <xref rid="c37" ref-type="bibr" id="cr37-1">Kleiner et al., 2007</xref>; <xref rid="c54" ref-type="bibr" id="cr54-1">Pelli, 1997</xref>) and was played using a computer keyboard. The study lasted approximately 50 min, including the instruction phase and training.</p><p>During each game, participants were shown an animated creature (Pacman) moving along a path (see <xref ref-type="fig" id="fgc3-1" rid="fig3">Figure 3</xref>). A trial started with Pacman stationary at a fork in the path. At this point Pacman could jump either up or down and the participant made this choice using the <italic>up</italic> or <italic>down</italic> arrow keys on the keyboard. One of these paths contained a reward, but the participant could not see this before making the decision. Participants were shown a sequence of cues and they could wait and watch as many cues as they wanted before making their choice. The display also showed the total reward they accumulated in the experiment and a progress bar showing how much time was left in the current game.<xref ref-type="fig-anchor" rid="fig3"/></p><p>Once the participant indicated their choice, an animation showed Pacman moving along the chosen path. If this path was the rewarded one, a bag with a $ sign appeared along the path (right panel in <xref ref-type="fig" id="fgc3-2" rid="fig3">Figure 3</xref>). When Pacman reached this bag, the reward was added to the total and Pacman navigated to the next fork and this started the next trial. If the participant chose the unrewarded path, the money bag appeared along the other path.</p><p>The intertrial interval (ITI) started as soon as the participant indicated their choice. We manipulated the ITI for correct and incorrect decisions by varying Pacman&#x02019;s speed. Participants were told that Pacman received a &#x0201c;speed-boost&#x0201d; when it ate the money bag so that ITI for correct decisions was smaller than that for incorrect decisions. Values for all parameters used during the game are shown in <xref ref-type="table" id="tbc1-1" rid="tbl1">Table 1</xref>.<xref ref-type="table-anchor" rid="tbl1"/></p></sec><sec id="s6"><title>Cue stimuli</title><p>When Pacman reached a fork, cues were displayed at a fixed rate, with a new cue every 200 ms. We call this delay the interstimulus interval (ISI). During these 200 ms, the cue was displayed for 66 ms, followed by 134 ms of no cue. Each cue was the outcome of a Bernoulli trial and consisted of either an upward or a downward pointing arrow. This arrow indicated the rewarded path with a particular probability.</p><p>Next to the cues, participants were shown a picture of either an elephant or a penguin. This animal indicated the type of game they were playing. One of the two animals provided cues with a probability 0.70 of being correct, while the other animal provided cues with a probability 0.50 of being correct. Thus, the two animals mapped to the two single-difficultly conditions&#x02014;easy (with &#x003f5; = 0.20) or difficult (with &#x003f5; = 0)&#x02014;shown in <xref ref-type="fig" id="fgc2-14" rid="fig2">Figure 2d</xref> and <xref ref-type="fig" id="fgc2-15" rid="fig2">2e</xref>. The mapping between difficulties and animals was counterbalanced across participants.</p><p>We chose the values of up-probability so that the optimal decision boundaries in the mixed-difficulty case have the steepest slope, making it easier to detect if participants decrease decision boundaries. The theory in the previous section shows that decision boundaries decrease only when the difficult decisions are extremely difficult. In the experiment we set the up-probability for difficult condition to the extreme value of 0.5, that is, &#x003f5;<sub><italic>d</italic></sub> = 0; therefore, the cues do not give any information on the true state of the world. Using this value has two advantages: (a) it leads to optimal decision boundaries in mixed-difficulty games with the steepest decrease in slope, and (b) it makes it easier for participants to realize that the optimal boundary in the difficult condition is very low (in fact, the optimal strategy for difficult games is to guess immediately). Optimal boundaries should also decrease (although with a smaller slope) when decisions are marginally easier (e.g., &#x003f5;<sub><italic>d</italic></sub> = 0.03). But we found that participants frequently overweight evidence given by these low probability cues (perhaps analogous to the overweighting of small probabilities in other risky choice situations, e.g., <xref rid="c82" ref-type="bibr" id="cr82-1">Tversky &#x00026; Kahneman, 1992</xref>; <xref rid="c25" ref-type="bibr" id="cr25-1">Gonzalez &#x00026; Wu, 1999</xref>) and need a large amount of training to establish the optimal behavior in such extremely difficult (but not impossible) games. In contrast, when &#x003f5;<sub><italic>d</italic></sub> = 0, participants could learn the optimal strategy difficult games with a small amount of training.</p><p>The experiment consisted of three types of games: <italic>easy games</italic>, where only the animal giving 70% correct cues appeared at each fork; <italic>difficult games</italic>, where only the animal giving the 50% cues appeared at the fork; and <italic>mixed games</italic>, where the animal could change from one fork to the next. Participants were given these probabilities at the start of each game and also received training on each type of game (see Structure of Experiment section). Importantly, during mixed games participants were shown a picture of a wall instead of either animal and told that the animal was hidden behind this wall. That is, other than the cues themselves, they received no information indicating whether a particular trial during a mixed game was easy or difficult so that they had to infer the type of trial solely on the basis of these cues. This corresponds to the mixed-difficulty task shown in <xref ref-type="fig" id="fgc2-16" rid="fig2">Figure 2f</xref>.</p></sec><sec id="s7"><title>Reward structure</title><p>Participant reimbursement was broken down into three components. The first component was fixed and every participant received (approx $7.5) for taking part in the study. The second component was the money bags accumulated during the experiment. Each money bag was worth (approx 2 cents) and participants were told that they could accumulate up to (approx $6) during the experiment. The third component was a bonus prize of (approx $25) available to the participant who accumulated the highest reward during the study. Participants were not told how much other participants had won until after they took part in the study.</p></sec><sec id="s8"><title>Structure of experiment</title><p>The experiment was divided into a training phase and a testing phase. Participants were given training on each type of game. The duration of each training game was 150 s. This phase allowed participants to familiarize themselves with the games and probability of cues as well as understand the speed&#x02013;accuracy trade-off for each type of games. The reward accumulated during the training phase did not count toward their reimbursement.</p><p>The testing phase consisted of six games, two of each type. Participants were again reminded of the probabilities of cues at the start of each game. The order of these games was counterbalanced across participants so that each type of game was equally likely to occur in each position in the sequence of games. The duration of the easy games was 240 s, whereas the difficult and mixed games lasted 300 s each. The reason for different durations for different types of games was that we wanted to collect around the same amount of data for each condition. Pilot studies showed that participants generally have faster reaction time (RT) during the easy games (see following Results section). Therefore, we increased the length of the difficult and mixed blocks. By using these durations, participants made approximately 70 to 90 choices during both easy and mixed conditions. In the middle of each game, participants received a 35 s break.</p></sec><sec id="s9"><title>Eliminating nondecision time</title><p>We preprocessed the recorded data to eliminate nondecision time&#x02014;the delay between making a decision and executing a response. As a result of this nondecision time, the data contained irrelevant stimuli that were presented after the participant had made their decision. To eliminate these irrelevant stimuli, we estimated the nondecision time for each participant on the basis of their responses during the easy games. <xref ref-type="app" id="apcA-1" rid="A">Appendix A</xref> illustrates the method in detail; the key points are summarized briefly in the following text.</p><p>For each participant, we reversed the sequence of stimuli and aligned them on the response time. Let us call these ordered sequence (<italic>s</italic><sub>1</sub><sup><italic>i</italic></sup>, <italic>s</italic><sub>2</sub><sup><italic>i</italic></sup>, . . . , <italic>s<sub>T</sub><sup>i</sup></italic>), where <italic>i</italic> is the trial number and (1, 2, . . . , <italic>T</italic>) are the stimulus indices before the response. Each stimulus can be either up or down, that is, <italic>s<sub>t</sub><sup>i</sup></italic> &#x02208; {up, down}. At each time step, we estimated the correlation (across trials) between the observing a stimulus in a particular direction and making a decision to go in that direction. That is, we computed <italic>p</italic><sub><italic>t</italic></sub> at each stimulus index, <italic>t</italic> &#x02208; {1, 2, . . . , <italic>T</italic>}, as the fraction of trials where the response <italic>r<sup>i</sup></italic> &#x02208; {up, down} is the same as <italic>s<sub>t</sub><sup>i</sup></italic>. So, for each participant, the values (<italic>p</italic><sub>1</sub>, <italic>p</italic><sub>2</sub>, . . . , <italic>p</italic><sub><italic>T</italic></sub>) serve as an estimate of the correlation between the stimulus at that index and the response.</p><p>If stimuli at a particular index, <italic>t</italic>, occurred after the decision, that is, during the nondecision time, we expected them to have a low correlation with response and consequently <italic>p</italic><sub><italic>t</italic></sub> to be below the drift rate, 0.70. We determined the first index in the sequence with <italic>p</italic><sub><italic>t</italic></sub> larger than 0.75; that is, the first index with more than 75% of stimuli in the same direction as the response. This gave us an estimate of the number of stimuli, <italic>ND</italic>, that fall in the nondecision period. We used this estimate to eliminate the stimuli, <italic>s</italic><sub>1</sub>, . . . , <italic>s</italic><sub><italic>ND</italic></sub> from each recorded sequence for the participant. See <xref ref-type="fig" id="fgc12-1" rid="fig12">Figure A1</xref> in <xref ref-type="app" id="apcA-2" rid="A">Appendix A</xref>.</p><p>For 21 out of 24 participants, we estimated <italic>ND</italic> = 1, that is, a nondecision delay of approximately 200 ms. For two subjects the nondecision delay was two stimuli and for one participant no stimuli were excluded.</p></sec><sec id="s10"><title>Exclusion of participants</title><p>To ensure that each participant understood the task, we conducted a binomial test on responses in the easy and mixed-difficulty games. This test checked whether the number of correct responses during a game were significantly different from chance. Two participants failed this test during mixed-difficulty games and were excluded from further analysis.</p></sec><sec id="s11"><title>Analysis method</title><p>We now describe how we estimated the decision boundary underlying each participant&#x02019;s decisions. In signal-detection paradigms, the experimenter cannot observe the exact sequence of samples based on which the participant made their decision. Therefore, parameters like boundary are obtained by fitting a sequential sampling or accumulator model to the RT and error distributions. In contrast, the expanded-judgment paradigm allows us to observe the entire sequence of samples used to make each decision. Therefore, our analysis method takes into account not only the evidence and time at which the decision (&#x02018;up&#x02019;/&#x02018;down&#x02019;) was made, but also the exact sequence of actions (<italic>wait&#x02013;go</italic>) in response to the sequence of cues seen by the participant. It also takes into account the trial-to-trial variability in the behavior of participants: even when participants saw the exact same sequence of cues, they could vary their actions from one trial to next.</p><p>If a participant makes a decision as soon as evidence crosses the boundary, the value of time and evidence, (<italic>t</italic>, <italic>x</italic>) during each decision should lie along this boundary. Therefore, one way to recover this boundary is by simply fitting a curve through the values of (<italic>t</italic>, <italic>x</italic>) for all decisions in a block. However, note that participants show a trial-to-trial variability in their decision making. Sequential sampling models account for this trial-to-trial variability by assuming noisy integration of sensory signals as well as variability in either drift, starting point or in threshold (see <xref rid="c59" ref-type="bibr" id="cr59-2">Ratcliff, 1978</xref>; <xref rid="c65" ref-type="bibr" id="cr65-2">Ratcliff &#x00026; Smith, 2004</xref>). We chose to model this variability by assuming there is stochasticity in each <italic>wait&#x02013;go</italic> decision. That is, instead of waiting when evidence was below the boundary and going as soon as evidence crossed the boundary, we assumed that a participant&#x02019;s decision depended on the outcome of a random variable, with the probability of the outcome depending on the accumulated evidence and time.</p><p>Specifically, we define two predictor variables&#x02014;the evidence accumulated, <italic>X</italic> = <italic>x</italic>, and the time spent in the trial, <italic>T</italic> = <italic>t</italic> &#x02013; and a binary response variable, <italic>A</italic> &#x02208; <italic>wait, go</italic>. The probability of an action can be related to the predictor variables using the following logistic regression model:
<disp-formula id="eqn2"><alternatives><graphic xlink:href="xge_146_6_776_eqn2a.jpg" id="eqn2a"/><mml:math id="M2"><mml:mrow><mml:mi>log</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x02119;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mi>T</mml:mi></mml:msub><mml:mo>&#x02217;</mml:mo><mml:mi>T</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mo>&#x02217;</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:math></alternatives><label>2</label></disp-formula>
where &#x003b2;<sub><italic>T</italic></sub> and &#x003b2;<sub><italic>X</italic></sub> are the regression coefficients for time and evidence, respectively, and &#x003b2;<sub>0</sub> is the intercept. Given the triplet (<italic>X</italic>, <italic>T</italic>, <italic>A</italic>) for each stimulus in each trial, we estimated for each type of game and each participant the <mml:math id="math4"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> and <mml:math id="math5"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> that maximized the likelihood of the observed triplets.</p><p><xref ref-type="fig" id="fgc4-1" rid="fig4">Figure 4</xref> shows the results of applying the above analysis to one participant. The data are split according to condition &#x02013; easy, difficult or mixed. Each circle shows the end of a random walk (sequence of stimuli) in the time-evidence plane. These random walks were used to determine the (maximum likelihood) regression coefficients, <mml:math id="math6"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> and <mml:math id="math7"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math>, as outlined above. These estimated coefficients are then used (<xref ref-type="disp-formula" id="eqnc2-1" rid="eqn2">Equation 2</xref>) to determine the probability of <italic>go</italic>ing at each <italic>x</italic> and <italic>t</italic>, which is shown as the heat-map in <xref ref-type="fig" id="fgc4-2" rid="fig4">Figure 4</xref>.<xref ref-type="fig-anchor" rid="fig4"/></p><p>This heat-map shows that, under the easy condition, this participant&#x02019;s probability of <italic>go</italic>ing strongly depended on the evidence and weakly on the number of samples. In contrast, under the difficult condition, the participant&#x02019;s probability of <italic>go</italic>ing depends almost exclusively on the number of samples&#x02014;most of their decisions are made within a couple of samples and irrespective of the evidence. Under the mixed condition, the probability of <italic>go</italic>ing is a function of both evidence and number of samples.</p><p>Since we were interested in comparing the slopes of boundaries during easy and mixed conditions, we determined a <italic>line of indifference</italic> under each condition, where <mml:math id="math8"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>, that is, the participant was equally likely to choose actions <italic>wait</italic> and <italic>go</italic>. Substituting in <xref ref-type="disp-formula" id="eqnc2-2" rid="eqn2">Equation 2</xref> gives the line:
<disp-formula id="eqn3"><alternatives><graphic xlink:href="xge_146_6_776_eqn3a.jpg" id="eqn3a"/><mml:math id="M3"><mml:mrow><mml:mi>X</mml:mi><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mo>&#x02217;</mml:mo><mml:mi>T</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow></mml:math></alternatives><label>3</label></disp-formula>
with slope <mml:math id="math9"><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>T</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow></mml:math> and intercept as <mml:math id="math10"><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mstyle><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mn>0</mml:mn></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>X</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow></mml:math>. We used the slope of this line as an estimate for the slope of the boundary. <xref ref-type="app" id="apcB-1" rid="B">Appendix B</xref> reports a set of simulations that tested the validity of this assumption and found that there is a systematic relationship between this inferred slope and the true slope generating decisions. Importantly, these simulations also demonstrate that even if the variability in data is due to noisy integration of sensory signals (rather than trial-to-trial variability in decision boundary), this inferential method still allows us to make valid comparisons of slopes of boundaries in easy and mixed games.</p><p>Each panel in <xref ref-type="fig" id="fgc4-3" rid="fig4">Figure 4</xref> also shows the line of indifference for the condition. The slope of the line of indifference is steepest under the difficult condition followed by the mixed condition and most flat for the easy condition. Note that for the mixed condition, we only considered the &#x0201c;easy&#x0201d; trials&#x02014;that is, trials showing cues with correct probability = 0.70. This ensured that we made a like-for-like comparison between easy and mixed conditions.</p><p>A quantitative comparison of slopes between conditions can be made by taking the difference between slopes. However, a linear difference is inappropriate as large increasing slopes are qualitatively quite similar to large decreasing slopes&#x02014;both indicate a temporal, rather than evidence-based boundary (e.g., the difficult condition in <xref ref-type="fig" id="fgc4-4" rid="fig4">Figure 4</xref>). Therefore, we compared slopes in the mixed and easy conditions by converting these slopes from gradients to degrees and finding the circular difference between slopes:
<disp-formula id="eqn4"><alternatives><graphic xlink:href="xge_146_6_776_eqn4a.jpg" id="eqn4a"/><mml:math id="M4"><mml:mrow><mml:mi>&#x00394;</mml:mi><mml:mi>m</mml:mi><mml:mo>=</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mi>e</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>m</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mn>90</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mspace width=".33em"/><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi><mml:mspace width=".33em"/><mml:mn>180</mml:mn><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>90</mml:mn></mml:mrow></mml:math></alternatives><label>4</label></disp-formula>
where <italic>m</italic><sub><italic>e</italic></sub> and <italic>m</italic><sub><italic>m</italic></sub> are the slopes in easy and mixed conditions, respectively; &#x00394;<italic>m</italic> is the difference in slopes and <italic>mod</italic> is the modulo operation. <xref ref-type="disp-formula" id="eqnc4-1" rid="eqn4">Equation 4</xref> ensures that the difference between slopes is confined to the interval [&#x02212;90, +90] degrees and large increasing slopes have a small difference to large decreasing slopes.</p><p>The above analysis assumes that evidence accumulated by a participant mirrors the evidence presented by the experimenter&#x02014;so there is no loss of evidence during accumulation and the internal rate of evidence accumulation remains the same from one trial to next. In <xref ref-type="app" id="apcC-1" rid="C">Appendix C</xref> we performed simulations to verify that inferences using the above analysis remain valid even when there is loss in information accumulated and when the drift rate varied from one trial to next.</p></sec></sec><sec id="s12"><title>Results</title><p>The mean RTs during easy, difficult and mixed games were 1444 ms (<italic>SEM</italic> = 23 ms), 1024 ms (<italic>SEM</italic> = 47ms) and 1412 ms (<italic>SEM</italic> = 22ms), respectively, where <italic>SEM</italic> is the within-subject standard error of the means. Note that &#x02018;RT&#x02019; here refers to &#x02018;decision time,&#x02019; that is, the raw response time minus the estimated nondecision time. As noted above, the nondecision time for most participants was approximately 200 ms. <xref ref-type="fig" id="fgc5-1" rid="fig5">Figure 5</xref> compares the slopes for the lines of indifference in the easy and mixed games (black circles). Error bars indicate the 0.95 percentile confidence interval.<xref ref-type="fn" rid="fn3"><sup>3</sup></xref> Like the participant shown in <xref ref-type="fig" id="fgc4-5" rid="fig4">Figure 4</xref> the estimated slope for most participants was more negative during the mixed games than during easy games, falling below the identity line. A paired <italic>t</italic> test on the difference in slopes in the two conditions (using <xref ref-type="disp-formula" id="eqnc4-2" rid="eqn4">Equation 4</xref>) confirmed that there was a significant difference in the slopes (<italic>t</italic>(21) = 5.24, <italic>p</italic> &#x0003c; 0.001, <italic>m</italic> = 15.94, <italic>d</italic> = 1.20), indicating that the type of game modulated how participants set their decision boundary.<xref ref-type="fig-anchor" rid="fig5"/></p><p><xref ref-type="fig" id="fgc5-2" rid="fig5">Figure 5</xref> also shows the relationship between the slopes of easy and mixed games for 24 simulated participants (red crosses) who optimize the reward rate. Each of these participants had slopes of boundary calculated using dynamic programming (<xref rid="c46" ref-type="bibr" id="cr46-6">Malhotra et al., 2017</xref>) and made decisions based on a noisy integration of evidence to this optimal boundary. The slopes in each condition were then inferred using the same procedure as for our real participants. These optimal participants, like the majority of participants in our study, had a larger (negative) slope in the mixed condition than the easy condition. However, in contrast to the optimal participants, the majority of participants also exhibited a negative slope during the <italic>easy</italic> games, indicating that they lowered their decision boundary with time during this condition. A <italic>t</italic> test confirmed that the slope during easy condition was less than zero (<italic>t</italic>(21) = &#x02212;5.51, <italic>p</italic> &#x0003c; 0.001, <italic>m</italic> = &#x02212;11.47). Participants also showed substantial variability in the decision boundary in the easy condition, with slopes varying between 0 and 45 degrees.</p><p>An alternative possibility is that participants change their decision boundary during the experiment, adopting a higher (but constant) boundary toward the beginning and lowering it to different (constant) boundary during the experiment. In order to check for this possibility, we split the data from each condition into two halves and checked whether the mean number of samples required to make a decision changed from the first half to second half of the experiment. During easy games, we found that participants observed 7.5 and 6.8 samples, on average, during the first and second half of the experiment, respectively. During mixed games, these mean observations changed to 6.8 and 6.2 samples, on average, during the first and second half of the experiment. A two-sided paired <italic>t</italic> test which examined whether the mean number of samples were different in the two halves of the experiment found no significant difference in either the easy games (<italic>t</italic>(21) = 1.76, <italic>p</italic> = 0.09, <italic>m</italic> = 0.73) or in the mixed games (<italic>t</italic>(21) = 1.40, <italic>p</italic> = 0.18, <italic>m</italic> = 0.64).<xref ref-type="fn" rid="fn4"><sup>4</sup></xref></p><p>We checked the robustness of these results by performing a model comparison exercise, pitting a time-varying decision boundary against a fixed boundary model. The latter simply involves a logistic regression in which the decisions to <italic>wait</italic> or <italic>go</italic> were based on evidence only. The full details of this model comparison procedure and results are described in <xref ref-type="app" id="apcD-1" rid="D">Appendix D</xref>. Based on a comparison of Bayesian Information Criteria (<xref rid="c70" ref-type="bibr" id="cr70-1">Schwarz, 1978</xref>; <xref rid="c89" ref-type="bibr" id="cr89-1">Wagenmakers, 2007</xref>), the time-varying model provided a better account of the behavior of 15 out of 22 participants in mixed-difficulty games. For 3 participants, the evidence was ambiguous and for the remaining 4 participants the simpler, fixed boundary model won. In easy games, the model using time as a predictor was better at accounting for data from 13 participants while the simpler model performed better to data for 8 participants.</p><p>In order to understand why participants decrease the decision boundary in easy games and why different participants show a large variation in their choice of boundary, we computed the reward rate accrued by each participant&#x02019;s choice of boundary and compared it to the reward rate for the optimal policy. This gave us the cost of setting any nonoptimal decision boundary. <xref ref-type="fig" id="fgc6-1" rid="fig6">Figure 6</xref> shows the landscape (heat-map) of the reward rate for each type of game for a host of different boundaries, defined by different combinations of intercepts and slopes. The circles indicate the intercepts and slopes of the inferred line of indifference of each participant.<xref ref-type="fig-anchor" rid="fig6"/></p><p>Notice, in particular, the landscape for the easy games. Even though the peak of this landscape lies at the policy with zero slope (flat bounds), there is a &#x0201c;ridge&#x0201d; of policies on the landscape where the reward rate is close to optimal. The policies chosen by most participants in Experiment 1 seem to lie along this ridge&#x02014;even though participants do not necessarily choose the optimal policy, they seem to be choosing policies that are close to optimal. A similar pattern holds in the mixed games. In contrast, during difficult games, the average reward is low, irrespective of the policy. Correspondingly, there is a large variability in the policies chosen by participants. We examine the effect of reward landscape on the policies chosen by participants in more detail at the end of Experiment 2.</p></sec></sec><sec id="s13"><title>Experiment 2</title><p>Experiment 1 established that people modulate their decision boundary based on task difficulty and variations in the reward landscape. However, our experimental paradigm&#x02014;effectively an expanded-judgment task&#x02014;is clearly very different from the dominant, typically signal-detection paradigms used to test rise-to-threshold models and time-varying boundaries (e.g., <xref rid="c10" ref-type="bibr" id="cr10-1">Britten, Shadlen, Newsome, &#x00026; Movshon, 1992</xref>; <xref rid="c52" ref-type="bibr" id="cr52-2">Palmer et al., 2005</xref>; <xref rid="c43" ref-type="bibr" id="cr43-1">Ludwig, 2009</xref>; <xref rid="c76" ref-type="bibr" id="cr76-3">Starns &#x00026; Ratcliff, 2012</xref>). In our paradigm, response times in mixed games were generally between 1 and 2 s, whereas in the perceptual decision-making literature, RTs are typically between 0.5-1 s (<xref rid="c52" ref-type="bibr" id="cr52-3">Palmer et al., 2005</xref>). It is possible that at this speed participants do not, or cannot, modulate their decision boundaries and instead adopt suboptimal fixed thresholds.</p><p>Our aim in Experiment 2 then was to replicate and extend our findings to a more rapid task, where RTs were similar to a signal-detection paradigm. More generally, we tested the robustness and generality of the results from the expanded-judgment task of Experiment 1 by introducing different (i) stimulus materials, (ii) ISIs and (iii) ITIs. The variation in ISI was designed to induce more rapid decision making (with RTs typically &#x0003c; 1<italic>s</italic>). Since the optimal policies are computed on a relative time scale (based on a unit ISI), we can scale both the interstimulus and ITI without affecting the optimal policy, but reducing the RT. The variation in ITI (specifically: for correct decisions, <italic>D</italic><sub><italic>C</italic></sub>) was introduced to manipulate the reward landscape, without affecting the <italic>optimal policy</italic>. <xref rid="c5" ref-type="bibr" id="cr5-3">Bogacz et al. (2006)</xref> have previously shown that the optimal policy is invariant to change in <italic>D</italic><sub><italic>C</italic></sub> for single-difficultly games. <xref rid="c46" ref-type="bibr" id="cr46-7">Malhotra et al. (2017)</xref> showed that this result generalizes to the mixed-difficulty scenario: optimal policy for mixed-difficulty games depends only on the ITI for incorrect decisions, <italic>D</italic><sub><italic>I</italic></sub>, but is independent of the ITI for correct decisions, <italic>D</italic><sub><italic>C</italic></sub>, as long as <italic>D</italic><sub><italic>C</italic></sub> &#x0003c; <italic>D</italic><sub><italic>I</italic></sub>. If participants were optimizing the reward rate, they should not change their decision boundary with a change in <italic>D</italic><sub><italic>C</italic></sub>. However, as we will see below, changing <italic>D</italic><sub><italic>C</italic></sub> does affect the wider reward landscape around the optimal policy and we explored to what extent participants were sensitive to this change.</p><p>Permutations of varying these two parameters leads to four experiments, which we have labeled Experiments 2a&#x02013;2d. The values of parameters for each experiment are shown in <xref ref-type="table" id="tbc2-1" rid="tbl2">Table 2</xref>. Experiment 2a was a replication of Experiment 1 with exactly the same parameters, but using the new paradigm (described below). In Experiment 2b, we scaled the ISI and ITI to elicit rapid decisions but kept all other parameters the same as Experiment 2a. In Experiment 2c, we increased the inter-trial-interval for correct responses to match that for incorrect responses. All other parameters were kept same as Experiment 2a. Finally, in Experiment 2d, we scaled ISI and ITI to elicit rapid decisions and also matched ITIs for correct and incorrect decisions.<xref ref-type="table-anchor" rid="tbl2"/></p><p>Like Experiment 1, 24 healthy adults between the age of 18 and 35 from the university community participated in each of these experiments, with no overlapping participants between experiments.</p><sec id="s14"><title>Method</title><p>Decreasing the ISI increases two sources of noise in the experiment: (i) noise due to variation in attention to cues (i.e., there is a greater likelihood of participants &#x0201c;missing&#x0201d; samples when they are coming in faster; ii) noise due to visual interference between consecutive cues in the same location. The second source of noise is particularly challenging for our purposes. That is, the analysis presented here assumes that each evidence sample is processed independently. However, if we were to present a sequence of cues in rapid succession, it is clear that, due to the temporal response properties of the human visual system, successive cues could &#x0201c;blend in&#x0201d; with each other (<xref rid="c24" ref-type="bibr" id="cr24-1">Georgeson, 1987</xref>). As a result, we could not simply speed-up the presentation of the arrow cues in the Pacman task. We adapted the original task from Experiment 1 to another evidence-foraging game that retained the structure of the paradigm and that allowed for systematic variation of the various parameters of interest (i.e., interstimulus and ITIs).</p><p>Participants were again asked to maximize their cumulative reward by making correct decisions in a game. But now, during each trial participants focused on a fixation cross in the middle of the screen with gray background<xref ref-type="fn" rid="fn5"><sup>5</sup></xref> and were told that a reward was either on the left or the right of the fixation cross. In order to make their choice, participants were shown cues that could appear either to the left or right of the fixation cross. In order to minimize interference (see below) cues could appear in two alternative locations on each side &#x02013; &#x02018;left-up&#x02019; or &#x02018;left-down&#x02019; on the left and &#x02018;right-up&#x02019; or &#x02018;right-down&#x02019; on the right. A cue appeared on the same side as the reward with a given probability. Participants were given this probability at the beginning of the game. For single-difficultly games, they were told that this probability was the same <mml:math id="math11"><mml:mrow><mml:mo>(</mml:mo><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mo>&#x000b1;</mml:mo><mml:mn>0.22</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math> for all trials within this game. For the mixed-difficulty games, they were told that a particular trial during the game could give cues with one of two different probabilities <mml:math id="math12"><mml:mrow><mml:mo>(</mml:mo><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mo>&#x000b1;</mml:mo><mml:mn>0.22</mml:mn></mml:mrow></mml:math> or <mml:math id="math13"><mml:mrow><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mo>&#x000b1;</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:math> and they were given these possible probabilities at the start of each game (i.e., block). Participants were again told that they could see as many cues as they wanted during a trial before making a decision, but the total duration of the game was fixed. <xref ref-type="fig" id="fgc7-1" rid="fig7">Figure 7</xref> shows an example trial in which the participant makes the decision to go left after observing a series of cues.<xref ref-type="fig-anchor" rid="fig7"/></p><p>Each cue was a Gabor pattern (sinusoidal luminance grating modulated by a 2D Gaussian window). We designed these cue patterns to minimize interference between consecutive patterns. The integration period of early visual mechanisms depends strongly on the spatiotemporal parameters of the visual patterns. But for coarse (i.e., low spatial frequency) and transient patterns it should be less than 100 ms (<xref rid="c24" ref-type="bibr" id="cr24-2">Georgeson, 1987</xref>; <xref rid="c95" ref-type="bibr" id="cr95-1">Watson, Ahumada, &#x00026; Farrell, 1986</xref>). To ensure the low spatial frequency we fixed the nominal spatial frequency of the Gabor to 0.4 cycles/deg (we did not precisely control the viewing distance, so the actual spatial frequency varied somewhat between participants) and the size of the Gaussian window to 1.2 deg (2D standard deviation). The patterns had a vertical orientation. In the &#x0201c;fast&#x0201d; experiments (Experiments 2b and 2d), each cue was displayed for 10 ms and the delay between onset of two consecutive cues (the ISI) was 50 ms. To ensure that consecutive cues were processed independently by the visual system we (i) alternated the location on one side of the screen (e.g., &#x02018;left-up&#x02019; and &#x02018;left-down&#x02019;) so that the smallest ISI at any one retinal location was 90 ms and (ii) alternated the phase of the patterns (90&#x000b0; and 270&#x000b0;).</p><p>Participants indicated their choice by pressing the left or right arrow keys on a keyboard. When the decision was correct, a money bag appeared on the chosen side. During the ITI, an animation displayed this money bag moving toward the bottom of the screen. When the decision was incorrect, no money bag appeared. All money bags collected by the participant remained at the bottom of the screen, so participants could track the amount of reward they had gathered during the current game.</p><p>The structure of the experiment was the same as Experiment 1, with the experiment consisting of a set of games of fixed durations and given difficulties. Each game consisted of a sequence of trials where participants could win a small reward if they made the correct decision or no reward if they made an incorrect decision. Games were again of three different types: (i) Type I, corresponding to easy games from Experiment 1, (ii) Type II corresponding to difficult games and (iii) Type 3 corresponding to mixed games. The type of the game was indicated by the color of the fixation cross &#x02013; Type I: Green, Type II: Red and Type 3: Blue. The order of games was counterbalanced across participants.</p><p>In all four experiments the <italic>up-probability</italic> for easy and difficult games was 0.50 &#x000b1; 0.22 and 0.50 &#x000b1; 0, respectively. During mixed games, easy and difficult trials were equally likely. The reward rate-optimal policy for easy games was again to maintain constant threshold (<xref ref-type="fig" id="fgc2-17" rid="fig2">Figure 2d</xref>) while for difficult it was to guess immediately (<xref ref-type="fig" id="fgc2-18" rid="fig2">Figure 2e</xref>). Similarly, the optimal policy for the mixed condition was to start with a high boundary (similar to the boundary at the start of easy games) and steadily decrease it, eventually making a decision at <italic>x</italic> = 0 (<xref ref-type="fig" id="fgc2-19" rid="fig2">Figure 2f</xref>). Just like in Experiment 1, participants were given training on each type of game and the reward structure was divided into three components: (approx $8.50) for participating, (approx 2 cents) for each correct response and (approx $25) for the participant accumulating the largest number of money bags.</p></sec><sec id="s15"><title>Results</title><p>We analyzed data using the same method as Experiment 1 after removing the nondecision time. <italic>Wait</italic> and <italic>go</italic> actions were used to determine the probability of <italic>go</italic>ing at all combinations of evidence and time, which were then used to determine a line of indifference, where the probability of wait matched the probability of go. We compared the slopes of this line of indifference for easy and mixed games for each of the four experiments.</p><sec id="s16"><title>Experiment 2a</title><p>This experiment used the same parameters as Experiment 1, but replaced the Pacman game, with the evidence-foraging game described in <xref ref-type="fig" id="fgc7-2" rid="fig7">Figure 7</xref>. Two participants failed the binomial test in the mixed games and were excluded from analysis. The mean RTs during easy, difficult and mixed games were 1155 ms (5.8 samples, <italic>SEM</italic> = 17 ms), 618 ms (3.1 samples, <italic>SEM</italic> = 27 ms) and 1142 ms (5.7 samples, <italic>SEM</italic> = 19 ms), respectively. We estimated the average number of stimuli that fell in the nondecision period (<italic>ND</italic>) to be 0.96, that is, a average nondecision delay of approximately 192 ms. For 21 out of the 22 participants, we estimated <italic>ND</italic> = 1 and for one participant no stimuli were excluded. <xref ref-type="fig" id="fgc8-1" rid="fig8">Figure 8</xref> (top-left panel) shows a comparison of the estimated slopes of lines of indifference in easy and mixed games. We observed that slopes were negative in both easy and mixed games for almost all participants and more negative during mixed games than easy games (<italic>t</italic>(21) = 3.92, <italic>p</italic> &#x0003c; 0.001, <italic>m</italic> = 15.76, <italic>d</italic> = 0.84). Again, circles show the slopes for estimated lines of indifference for each subjects. The 0.95 percentile confidence intervals on these slopes are obtained using the same bootstrap procedure described in Experiment 1.<xref ref-type="fn" rid="fn6"><sup>6</sup></xref> Note that the mean difference in slopes is virtually identical to Experiment 1, although the effect size (Cohen&#x02019;s <italic>d</italic>) was larger during Experiment 1. Thus, Experiment 2a replicated the results of Experiment 1 showing that the findings were robust to different formulations of the evidence-foraging game. A model comparison exercise concurred with these results, showing that the majority of participants in mixed (<italic>N</italic> = 18) as well as easy games (<italic>N</italic> = 17) were better accounted by a logistic regression model using both evidence and time as a predictor than by a simpler model that used only evidence as the predictor (see <xref ref-type="app" id="apcD-2" rid="D">Appendix D</xref> for details).<xref ref-type="fig-anchor" rid="fig8"/></p></sec><sec id="s17"><title>Experiment 2b</title><p>In the next experiment, we decreased the ISI to 50 ms and scaled the ITIs accordingly. All other parameters were the same as Experiment 2a. All participants passed the binomial test in the easy and mixed games. The mean RT during easy, difficult and mixed games were 337 ms (6.7 samples, <italic>SEM</italic> = 4.2 ms) 418 ms (8.4 samples, <italic>SEM</italic> = 9.8 ms) and 419 ms (8.4 samples, <italic>SEM</italic> = 5.3 ms), respectively, showing that this paradigm successfully elicited subsecond RTs typically found in signal detection paradigms. We estimated the average number of stimuli that fell in the nondecision period to be 3.7, that is, an average nondecision delay of approximately 183 ms. We estimated <italic>ND</italic> = 4 for 15 participants, <italic>ND</italic> = 3 for six participants, <italic>ND</italic> = 5 for two participants and <italic>ND</italic> = 1 for one participant. The bottom-left panel of <xref ref-type="fig" id="fgc8-2" rid="fig8">Figure 8</xref> shows the estimated slopes in easy versus mixed games. Like Experiment 2a, the slopes were negative for most participants in both easy and mixed games. Similarly, we also observed that the slopes were more negative in the mixed games than in the easy games, although the result was a little weaker than in Experiment 2a (<italic>t</italic>(23) = 2.12, <italic>p</italic> = 0.044, <italic>m</italic> = 11.80, <italic>d</italic> = 0.47). There are three possible reasons for this weaker result. First, the distribution for difference in slopes is more diffuse due the outlier at the right of the plot. Excluding this participant gave a clearer difference in slopes (<italic>t</italic>(22) = 3.31, <italic>p</italic> = .003, <italic>m</italic> = 15.19, <italic>d</italic> = 0.72) that was numerically highly similar to the slope difference observed in Experiments 1 and 2a. Second, for reasons discussed below, our estimates of nondecision time are likely to be less accurate in the &#x0201c;faster&#x0201d; paradigm. In turn, this error introduces variability in the accuracy of the actual evidence paths on a trial-by-trial basis that were used to derive our slope estimates. Lastly, it is possible that the process decreasing the boundary needs time to estimate the drift and adjust the boundary accordingly. With shorter ISI, this process may have less time to affect the decision process before the response is made, resulting in smaller difference in slopes between conditions.</p></sec><sec id="s18"><title>Experiment 2c</title><p>Next, we changed the ISI back to 200 ms (same as Experiment 2a) but increased <italic>D</italic><sub><italic>C</italic></sub>, the ITI for correct decisions, to the same value as <italic>D</italic><sub><italic>I</italic></sub>, the ITI for incorrect decisions (10s for both). Increasing the ITI decreased the reward per unit time and meant that participants had to wait longer between trials. Participants found this task difficult, we suspect because the ITI is so much longer than the typical RT. That is, participants spend most of their time waiting for a new trial, but then those trials are over rather quickly. Perhaps as a result, the games lacked in engagement and six out of 24 participants failed the binomial test in mixed games. For the 18 remaining participants, the mean RTs in easy, difficult and mixed games were 807 ms (4.0 samples, <italic>SEM</italic> = 27 ms), 858 ms (4.3 samples, <italic>SEM</italic> = 49 ms) and 954 ms (4.8 samples, <italic>SEM</italic> = 32 ms), respectively. We estimated the average number of stimuli that fell in the nondecision period to be 0.9, that is, an average nondecision delay of approximately 176 ms (<italic>ND</italic> = 2 for 21 participants and <italic>ND</italic> = 0 for the remaining three participants). The estimated slopes are shown in the top-right panel of <xref ref-type="fig" id="fgc8-3" rid="fig8">Figure 8</xref>. We observed much greater variability in the estimated decision boundaries, though slopes were generally negative in mixed as well as easy games.<xref ref-type="fn" rid="fn7"><sup>7</sup></xref> The mean estimated slopes decreased more rapidly in mixed games as compared to easy games. However, given the large variability of responses and the number of participants that had to be excluded, this effect was comparatively weaker (<italic>t</italic>(17) = 2.41, <italic>p</italic> = .028, <italic>m</italic> = 17.97, <italic>d</italic> = 0.60). Nevertheless, the mean slope difference is very similar to that observed in all previous three experiments.</p></sec><sec id="s19"><title>Experiment 2d</title><p>In this experiment we tested the final permutation of ISIs and ITIs&#x02014;we decreased the ISI to 50 ms and matched the ITIs for correct and incorrect decisions (both 2.5s). Two participants failed the binomial test in mixed games and were excluded from further analysis. The mean RTs during easy, difficult and mixed games were 240 ms (4.8 samples, <italic>SEM</italic> = 4 ms), 308 ms (6.2 samples, <italic>SEM</italic> = 9 ms) and 294 ms (5.9 samples, <italic>SEM</italic> = 5 ms), respectively. We estimated the average number of stimuli that fell in the nondecision period to be 4.3, that is, an average nondecision delay of approximately 216 ms (<italic>ND</italic> = 4 for 18 participants, <italic>ND</italic> = 5 for five participants and <italic>ND</italic> = 7 for one participant). The bottom-right panel in <xref ref-type="fig" id="fgc8-4" rid="fig8">Figure 8</xref> compares the estimated slopes in easy and mixed games. The mean slope in either kind of game was negative (<italic>t</italic>(21) = &#x02212;3.10, <italic>p</italic> = .005, <italic>m</italic> = &#x02212;11.66 for easy games and <italic>t</italic>(21) = &#x02212;3.42, <italic>p</italic> = .003, <italic>m</italic> = &#x02212;18.82 for mixed games). However, in contrast to Experiment 2b, there was no significant difference in mean estimated slopes during easy and mixed games (<italic>t</italic>(21) = 1.71, <italic>p</italic> = 0.10, <italic>m</italic> = 7.15, <italic>d</italic> = 0.32).</p></sec></sec><sec id="s20"><title>Discussion</title><p>Experiments 2a-d revealed three key behavioral patterns: (i) participants generally decreased their decision boundaries with time, not only in the mixed games, but also in the easy games, (ii) this pattern held for the rapid task (Experiment 2b) but the variability of parameter estimates increased at faster RTs, (iii) decreasing the difference between <italic>D</italic><sub><italic>C</italic></sub> and <italic>D</italic><sub><italic>I</italic></sub> decreased the difference in slopes between easy and mixed games.</p><p>Clearly, it is not optimal to decrease the decision boundary during fixed difficulty (easy) games, but most participants seemed to do this. As noted in Experiment 1, a possible reason is that the reward rate for suboptimal policies is asymmetrical around the optimal boundary. <xref ref-type="fig" id="fgc9-1" rid="fig9">Figure 9(a)</xref> shows the reward rate landscape for all possible decision boundaries during easy games in Experiment 2a, and maps the estimated boundaries for each participant onto this landscape.<xref ref-type="fig-anchor" rid="fig9"/></p><p>Reward rate is maximum at (0, 3). When slope increases above zero the reward rate drops rapidly. In contrast, when slope decreases below zero, reward rate decreases gradually. This asymmetry means that participants pay a large penalty for a suboptimal boundary with a positive slope, but a small penalty for a suboptimal boundary with a negative slope. If participants are uncertain about the evidence gathered during a trial, or about the optimal policy, it is rational for them to decrease their decision boundary, as an error in estimation will lead to a relatively small penalty. <xref ref-type="fig" id="fgc9-2" rid="fig9">Figure 9</xref> suggests that most participants err on the side of caution and adopt policies with high (though not maximum) rewards and decreasing boundaries.</p><p>The shape of the reward landscape also sheds light on why participants behave differently when the ITI <italic>D</italic><sub><italic>C</italic></sub> is changed, even though changing this parameter does not affect the optimal policy. The first column in <xref ref-type="fig" id="fgc9-3" rid="fig9">Figure 9</xref> shows the reward rate in experiments where <mml:math id="math14"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math>, while the second column shows the reward rate in experiments where <italic>D</italic><sub><italic>C</italic></sub> = <italic>D</italic><sub><italic>I</italic></sub>. The top two rows show the reward-rate landscapes in easy games at all combinations of slopes and intercepts, while the bottom row compares the reward rate in easy and mixed games at a particular intercept of decision boundary but different values of slope (i.e., a horizontal slice through the heat-maps above). Even though the optimal policy in all four experiments is the same, there are several ways in which the reward-rate landscape in the left-hand column (Experiments 2a and 2b) differ from the landscape in the right-hand column (Experiments 2c and 2d).</p><p>First, the reward-rate landscape in easy games is more sharply peaked when <mml:math id="math15"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> (Experiments 2a and 2b). This is most clearly discernible in panels in the bottom row which shows the profile of the (normalized) reward-rate landscape at a particular intercept. If the participant adopts a boundary with large negative slope, the difference between the reward rate for such a policy and the optimal reward rate is larger when <mml:math id="math16"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> (left panel) than when <italic>D</italic><sub><italic>C</italic></sub> = <italic>D</italic><sub><italic>I</italic></sub> (right panel). So in Experiments 2a and 2b adopting a suboptimal policy carries a larger &#x02018;regret&#x02019; than in Experiments 2c and 2d. This means that the reward landscape constrains the choice of boundaries more in Experiments 2a and 2b than it does in Experiments 2c and 2d, even though the optimal policy for all experiments is the same.</p><p>The panels in the bottom row also compare the reward-rate profiles during easy (shaded) and mixed (hatched) games at a particular intercept. It can be seen that for both types of experiments the normalized reward rate is larger in mixed games than easy games when slopes are more negative. Thus it is better (more rewarding) to have decreasing boundaries in mixed games than in easy games. However, the difference in easy and mixed games is larger when <mml:math id="math17"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> (left panel) than when <italic>D</italic><sub><italic>C</italic></sub> = <italic>D</italic><sub><italic>I</italic></sub> (right panel). Correspondingly, we found a more robust difference in slopes during Experiments 2a and 2b than we did in Experiments 2c and 2d.</p><p>The third behavioral pattern was an increase in variability of slopes when the decisions were made more rapidly. There are two possible sources of this variability: internal noise and error in estimation of the nondecision time. Recall that we excluded stimuli that arrive during the nondecision time based on a single estimate of this time for each participant. It is likely that the nondecision time varies from trial-to-trial; indeed, this is a common assumption in models of decision making (see <xref rid="c65" ref-type="bibr" id="cr65-3">Ratcliff &#x00026; Smith, 2004</xref>). Any such variability means that on some trials we are including irrelevant samples (estimating a nondecision time too short) or excluding relevant samples (estimating a nondecision time too long). As a result, there is a discrepancy between the evidence paths that actually led to the participant&#x02019;s decision and the one entered into the logistic regression model used to estimate the decision boundary. Importantly, this discrepancy will be much smaller in the experiments with a long ISI, because even an error in nondecision time of, say, 100 ms will at most introduce only one additional or excluded evidence sample. However, in the experiments with a much shorter ISIs, the same numerical error will result in several additional or missed evidence samples. Therefore, trial-to-trial variability in the nondecision times introduces more noise in the slope estimates for the faster experiments.</p></sec></sec><sec id="s21"><title>Experiment 3</title><p>In the above experiments, the optimal policy was to decrease decision boundaries in mixed games but keep them constant in single-difficultly games. Correspondingly, data suggested that participants adopted more strongly decreasing boundaries in mixed-difficulty games than in single-difficultly games, particularly when errors are costly (in terms of reward rate). In Experiment 3 we changed the parameters so that the optimal policy during mixed-difficulty games was, in fact, to increase the decision boundary. Recall from the theory on optimal shapes of decision boundaries that the optimal policy in mixed games is to decrease decision boundaries only when one of the decision types is extremely difficult. In contrast, when both types of decisions are easy or moderately difficult, the policy that optimizes reward rate is to increase decision boundaries or leave them constant (<xref ref-type="fig" id="fgc2-20" rid="fig2">Figure 2c</xref>). Therefore, if participants were optimizing their average reward, we expected estimated slopes in mixed-difficulty games of this type to be either the same or larger than slopes in single-difficultly games.</p><p>Experiment 3 used the same experimental paradigm as Experiment 2. The parameters for Experiment 3 are shown in <xref ref-type="table" id="tbc3-1" rid="tbl3">Table 3</xref>. During this experiment, easy games showed cues with <italic>up-probability</italic>
<mml:math id="math18"><mml:mrow><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mo>&#x000b1;</mml:mo><mml:mn>0.40</mml:mn></mml:mrow></mml:math> &#x02013; so participants could make really rapid decisions in these games. And unlike Experiments 1 and 2, difficult games showed cues with <italic>up-probability</italic>
<mml:math id="math19"><mml:mrow><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:mo>&#x000b1;</mml:mo><mml:mn>0.10</mml:mn></mml:mrow></mml:math>. The optimal boundaries in this case are higher for difficult games than easy games (<xref ref-type="fig" id="fgc2-21" rid="fig2">Figures 2a</xref> and <xref ref-type="fig" id="fgc2-22" rid="fig2">2b</xref>) and the optimal boundary for mixed games show a slight increase in evidence with time (<xref ref-type="fig" id="fgc2-23" rid="fig2">Figure 2c</xref>).<xref ref-type="table-anchor" rid="tbl3"/></p><p>Twenty-four participants played blocks of easy, difficult and mixed games with the objective of maximizing their reward. Each correct decision was worth 2p and there was no reward or penalty for incorrect decisions. The participant who collected the largest number of money bags received a bonus reward of (approx $25). The ISI was 50 ms and ITI was 3.5 s.</p><p>We used the same procedure as the above experiments to analyze the data. All participants passed the binomial test in mixed games so no data was rejected. <xref ref-type="fig" id="fgc10-1" rid="fig10">Figure 10</xref> shows the estimated slopes for lines of indifference in easy, difficult and mixed games. Unlike the previous experiments, we compared the slopes in mixed games not only to easy games, but also to difficult games, since the difficult games in this case required participants to accumulate evidence before making a decision.<xref ref-type="fig-anchor" rid="fig10"/></p><p>During easy games, participants made really rapid (and accurate) decisions, with mean RTs 107 ms (<italic>SEM</italic> = 4 ms), that is, based on two to three sample cues (after excluding nondecision time). Such fast responses are of course consistent with the model prediction of narrow decision boundaries in this condition. As discussed above, on this rapid time scale noise in the responses due to nondecision time or due to variability of the perceptual system has a large impact on the variability of estimated slopes. Indeed, we can see from <xref ref-type="fig" id="fgc10-2" rid="fig10">Figure 10</xref> (left panel), that the confidence intervals around estimated slopes are large and there was substantial (between-participants) variability in the mean estimated slopes.</p><p>A more accurate comparison between single- and mixed-difficulty games is obtained by comparing the slopes in difficult games with the slopes on difficult trials in mixed games. The panel on the right in <xref ref-type="fig" id="fgc10-3" rid="fig10">Figure 10</xref> shows this comparison. The mean RTs in difficult games was 397 ms (8 samples, <italic>SEM</italic> = 9 ms), while that in the mixed games was 234 ms (4.7 samples, <italic>SEM</italic> = 6 ms). We estimated the nondecision time to be approximately 4.5 samples, that is, 227 ms (<italic>ND</italic> = 5 for 13 participants and <italic>ND</italic> = 4 for the remaining 11 participants). Like previous experiments, the mean slope in single-difficultly (here, difficult) games was less than zero (<italic>t</italic>(23) = &#x02212;3.15, <italic>p</italic> &#x0003c; 0.001, <italic>m</italic> = &#x02212;19.5).</p><p>Crucially, in contrast to Experiment 1 and 2, but in agreement with the reward-rate optimizing policy, we found that the estimated slopes in mixed games were slightly <italic>larger</italic> (less negative) than in the difficult games (<italic>t</italic>(23) = &#x02212;2.25, <italic>p</italic> = .034, <italic>m</italic> = &#x02212;9.86, <italic>d</italic> = &#x02212;0.39). Indeed, model comparison suggested that, again in contrast to Experiment 1 and 2, the simpler logistic regression model using only evidence as the predictor provided a better account of data in mixed games than the model using both evidence and time as predictors (see <xref ref-type="app" id="apcD-3" rid="D">Appendix D</xref>). However, for the difficult games, the evidence was more mixed in that for just over half the participants, a model that included time as a predictor performed better. These results are consistent with the slope comparisons in that boundaries varied with time (slightly) in difficult games, but were approximately constant in the mixed games. Although we do not actually observe <italic>increasing</italic> boundaries, the shift from decreasing to approximately constant boundaries is a shift in the right direction.</p><p>In <xref ref-type="fig" id="fgc11-1" rid="fig11">Figure 11</xref>, we have again plotted the estimated policies of all participants on the reward landscape. The key difference in behavior between mixed and difficult games was that most participants were concentrated around the zero slope during mixed games while the slope of boundaries chosen by participants in the difficult games were spread over a large range with a number of participants choosing policies with large negative slopes. In the right-most panel, we have compared the profile of the landscape, slicing it at intercept = 3 (optimal policy in mixed games had slope slightly above 0 and intercept between 3 and 4). This profile shows that, like Experiment 2, reward rate is an asymmetric function of slope in both the difficult and mixed games. However, in contrast to Experiment 2, the amount of asymmetry is now lesser during mixed games than difficult games. So during mixed games, participants can choose policies in the neighborhood of constant boundary with a lower regret, even in the presence of uncertainty about the evidence or the optimal boundary. This could explain why the majority of participants in the mixed games are concentrated around policies with zero slope. In contrast, the larger asymmetry during difficult games seems to push a number of participants into adopting boundaries with large negative slopes&#x02014;a lower risk strategy that nevertheless leads to a small loss in average reward.<xref ref-type="fig-anchor" rid="fig11"/></p></sec><sec id="s22"><title>General Discussion</title><sec id="s23"><title>Constant or Decreasing Boundaries</title><p>Sequential sampling models have had a very successful history of fitting data in a variety of decision-making experiments (<xref rid="c5" ref-type="bibr" id="cr5-4">Bogacz et al., 2006</xref>; <xref rid="c59" ref-type="bibr" id="cr59-3">Ratcliff, 1978</xref>; <xref rid="c65" ref-type="bibr" id="cr65-4">Ratcliff &#x00026; Smith, 2004</xref>; <xref rid="c66" ref-type="bibr" id="cr66-2">Ratcliff et al., 2016</xref>; <xref rid="c73" ref-type="bibr" id="cr73-2">Smith &#x00026; Vickers, 1989</xref>). These models typically assume that decision boundaries remain constant during a trial, so introducing the possibility of changing boundaries adds further complexity to these models. The question is whether this complexity is warranted given existing data.</p><p>Recently, <xref rid="c30" ref-type="bibr" id="cr30-2">Hawkins et al. (2015)</xref> and <xref rid="c88" ref-type="bibr" id="cr88-1">Voskuilen, Ratcliff, and Smith (2016)</xref> conducted a model comparison based on data from a number of decision-making studies and found that introducing decreasing bounds did not generally improve the model fit. In this study, we took a different approach&#x02014;instead of working out whether decreasing boundaries improves model fit, we used a mathematical model (<xref rid="c46" ref-type="bibr" id="cr46-8">Malhotra et al., 2017</xref>) to establish the circumstances for changing decision boundary if the decision maker wanted to maximize reward rate. The key insight from this approach is that optimal decision boundaries decrease only in very specific scenarios&#x02014;when one of the difficulty in a mixed-difficulty task is extremely difficult, or even impossible. In other conditions, optimal boundaries for mixed-difficulty tasks may increase or stay constant based on the difficulty of constituent decisions. An advantage of the model presented in this study is that it can be used for inferring the reward rate of any given boundary, which can then be used to compare with the optimal boundary. Using this approach, we found that suboptimal policies were &#x0201c;asymmetrically distributed&#x0201d; near the optimal boundary in policy space. A judicious decision maker should consider this asymmetry in reward landscape to make decisions that are robust to uncertainty in task parameters and to their own estimate of the optimal policy. Six expanded-judgment experiments indicate that people may not only be modulating how decision boundaries change with time, but may also be using such robustness considerations to choose the value and shape of these boundaries.</p><p>So why do <xref rid="c30" ref-type="bibr" id="cr30-3">Hawkins et al. (2015)</xref> and <xref rid="c88" ref-type="bibr" id="cr88-2">Voskuilen et al. (2016)</xref> find no strong evidence for changing decision boundaries and, indeed, why are models with constant decision thresholds so successful at fitting data from a variety of experiments? There could be three possible reasons. First, the data sets analyzed by <xref rid="c30" ref-type="bibr" id="cr30-4">Hawkins et al. (2015)</xref> and <xref rid="c88" ref-type="bibr" id="cr88-3">Voskuilen et al. (2016)</xref> consist of mixed-difficulty experiments with a variety of different difficulty levels. For example, Experiment 1 conducted by <xref rid="c30" ref-type="bibr" id="cr30-5">Hawkins et al. (2015)</xref> was a motion-discrimination task with six different difficulty levels (0%, 2.5%, 5%, 10%, 20% and 40%) while Experiment 1 from <xref rid="c62" ref-type="bibr" id="cr62-1">Ratcliff, Hasegawa, Hasegawa, Smith, and Segraves (2007)</xref> was a brightness-discrimination task with three levels of difficulty (55%, 65% and 98%). It is not clear in any of these experiments what the shape of boundaries that optimize reward rate should be. As we have discussed above, optimal boundaries do not necessarily decrease in mixed-difficulty trials and when they do decrease, the rate of decrease varies over a broad range based on the levels of difficulty. So even if participants were optimizing reward rate in the experiments considered by <xref rid="c30" ref-type="bibr" id="cr30-6">Hawkins et al. (2015)</xref> and <xref rid="c88" ref-type="bibr" id="cr88-4">Voskuilen et al. (2016)</xref>, this may not necessarily entail observing decreasing boundaries.</p><p>Second, each of our experiments carefully controls the cost/reward of each decision and links performance to reward. This allows us to compute the optimal behavior in the task (in terms of reward rate) and compare participant performance with this optimal behavior. In contrast, most studies considered by <xref rid="c30" ref-type="bibr" id="cr30-7">Hawkins et al. (2015)</xref> do not have a performance-based reward structure. Participants are asked to emphasize speed, accuracy or both and there is no explicit scale on which a participant can measure the expected return of a policy. Exceptions to these are studies involving nonhuman primates, such as <xref rid="c67" ref-type="bibr" id="cr67-2">Roitman and Shadlen (2002)</xref>; <xref rid="c61" ref-type="bibr" id="cr61-1">Ratcliff, Cherian, and Segraves (2003)</xref>; <xref rid="c17" ref-type="bibr" id="cr17-2">Ditterich (2006)</xref>, where performance was explicitly linked to reward and interestingly, Hawkins et al. find evidence for decreasing boundaries in these studies.</p><p>Decisions in ecologically realistic situations are typically accompanied by costs and rewards and the structure of incentives can profoundly affect performance, as shown by a series of studies in experimental economics (<xref rid="c13" ref-type="bibr" id="cr13-1">Camerer &#x00026; Hogarth, 1999</xref>; <xref rid="c16" ref-type="bibr" id="cr16-1">Cubitt, Starmer, &#x00026; Sugden, 1998</xref>). Therefore, if we want to establish whether participants decrease decision boundaries within a trial, we must determine what it is they stand to gain by changing their decision boundaries during the experiment.</p><p>Last, note that the expanded-judgment paradigm used by us is different from the signal detection paradigms used in studies analyzed by <xref rid="c30" ref-type="bibr" id="cr30-8">Hawkins et al. (2015)</xref> and <xref rid="c88" ref-type="bibr" id="cr88-5">Voskuilen et al. (2016)</xref>. This is a key strength of our study as we are able to observe the exact sequence of stimuli observed by the decision maker and infer their decision boundaries based on these observations. It has been demonstrated recently that constraining sequential sampling models by the exact sequence of stimuli provides a closer description of RTs than that obtained from models in which the drift parameter is assumed constant within a trial (<xref rid="c53" ref-type="bibr" id="cr53-1">Park, Lueckmann, Kriegstein, von Bitzer, &#x00026; Kiebel, 2016</xref>). However, using this paradigm leaves open the possibility that the decision boundary is set differently when the decision processes draw samples from an internal representation (e.g., in color/brightness/numerosity judgment tasks) and when samples drawn cannot be recorded by the experimenter. Previous evidence suggests that results from expanded-judgment tasks can be generalized to situations where sampling is internal (<xref rid="c85" ref-type="bibr" id="cr85-3">Vickers, Burt, et al., 1985</xref>; <xref rid="c87" ref-type="bibr" id="cr87-1">Vickers, Smith, Burt, &#x00026; Brown, 1985</xref>). However, these studies did not examine a signal-detection task where RTs are typically &#x0003c;500 ms. Thus, an important outstanding question is whether people use different decision processes for internally and externally sampled observations and whether this affects how they set their decision boundaries.</p><p>Data from several expanded-judgment tasks involving choice between multiple alternatives have been successfully analyzed using sequential sampling models with fixed boundaries, which have been shown to capture the key interesting aspects of these data (<xref rid="c11" ref-type="bibr" id="cr11-1">Brown, Steyvers, &#x00026; Wagenmakers, 2009</xref>; <xref rid="c28" ref-type="bibr" id="cr28-1">Hawkins, Brown, Steyvers, &#x00026; Wagenmakers, 2012</xref>). It would be interesting to extend the model fitting methodology presented in this paper to the case of choice between multiple alternatives, and investigate if these data are better described by a model with flat or decreasing boundaries.</p></sec><sec id="s24"><title>Individual Differences</title><p>In all of the preceding experiments, we observed variability in behavior both between individuals and between trials within a participant. We have already discussed two reasons for the variability between trials: (a) nondecision time, which is estimated per individual but may vary from trial-to-trial and (b) internal noise, which could lead to a trial-to-trial variability in drift rate. As mentioned previously, a trial-to-trial variability in drift rate, starting point or threshold has been shown to be essential for fitting RT distributions&#x02014;in particular, different patterns of error RTs&#x02014;using sequential sampling models (see <xref rid="c59" ref-type="bibr" id="cr59-4">Ratcliff, 1978</xref>; <xref rid="c65" ref-type="bibr" id="cr65-5">Ratcliff &#x00026; Smith, 2004</xref>). In addition to these, our study highlights another source of variability between individuals&#x02014;the shape of the reward landscape with its broad region in which acceptably high reward rates could be achieved. Reward rate was asymmetrically distributed around the optimal policy in all the above experiments, with a bias toward suboptimal policies that yielded a reward rate that was close to maximum.</p><p>A number of previous studies have compared individuals with optimal behavior in decision-making tasks and found that participants often use boundaries that are suboptimal (<xref rid="c6" ref-type="bibr" id="cr6-2">Bogacz, Hu, et al., 2010</xref>; <xref rid="c56" ref-type="bibr" id="cr56-2">Pitz et al., 1969</xref>; <xref rid="c69" ref-type="bibr" id="cr69-3">Sanders &#x00026; Linden, 1967</xref>; <xref rid="c72" ref-type="bibr" id="cr72-2">Simen et al., 2009</xref>; <xref rid="c75" ref-type="bibr" id="cr75-2">Starns &#x00026; Ratcliff, 2010</xref>; <xref rid="c93" ref-type="bibr" id="cr93-2">Wallsten, 1968</xref>; <xref rid="c98" ref-type="bibr" id="cr98-1">Zacksenhouse, Bogacz, &#x00026; Holmes, 2010</xref>). It has also been observed that participants have a tendency to overvalue accuracy, setting boundaries that are wider than those suggested by maximization of reward rate (<xref rid="c2" ref-type="bibr" id="cr2-2">Balci et al., 2011</xref>; <xref rid="c8" ref-type="bibr" id="cr8-1">Bohil &#x00026; Maddox, 2003</xref>; <xref rid="c45" ref-type="bibr" id="cr45-1">Maddox &#x00026; Bohil, 1998</xref>; <xref rid="c49" ref-type="bibr" id="cr49-1">Myung &#x00026; Busemeyer, 1989</xref>; <xref rid="c76" ref-type="bibr" id="cr76-4">Starns &#x00026; Ratcliff, 2012</xref>). To explain this behavior, a set of studies have investigated alternative objective functions (<xref rid="c5" ref-type="bibr" id="cr5-5">Bogacz et al., 2006</xref>; <xref rid="c8" ref-type="bibr" id="cr8-2">Bohil &#x00026; Maddox, 2003</xref>; <xref rid="c98" ref-type="bibr" id="cr98-2">Zacksenhouse et al., 2010</xref>). For example, <xref rid="c98" ref-type="bibr" id="cr98-3">Zacksenhouse et al. (2010)</xref> found that only about 30% of participants achieve (reward rate) optimality and the behavior of the other 70% is better explained by a robust strategy that maximizes performance under presumed level of uncertainty (the maximin strategy).</p><p>The behavior of participants in our experiments is in line with such a robust strategy: a small proportion of participants adopt policies that are close to optimal (<xref ref-type="fig" id="fgc5-3" rid="fig5">Figures 5</xref>, <xref ref-type="fig" id="fgc8-5" rid="fig8">8</xref>, and <xref ref-type="fig" id="fgc10-4" rid="fig10">10</xref>) but most participants adopt strategies that yield high, but not maximum, reward rate (<xref ref-type="fig" id="fgc6-2" rid="fig6">Figures 6</xref>, <xref ref-type="fig" id="fgc9-4" rid="fig9">9</xref> and <xref ref-type="fig" id="fgc11-2" rid="fig11">11</xref>). Because the gradient of reward rate was larger above constant boundary than below it, this meant choosing a policy with a decreasing boundary.</p><p>In the preceding experiments, there can be several sources of uncertainty, leading to adoption of a robust strategy: uncertainty in estimation of task parameters such as ISI/ITI, uncertainty in the signal due to noise in the sensory system, and uncertainty in the estimate of reward rate for the task. If participants use a hill-climbing learning mechanism (<xref rid="c49" ref-type="bibr" id="cr49-2">Myung &#x00026; Busemeyer, 1989</xref>; <xref rid="c71" ref-type="bibr" id="cr71-1">Simen, Cohen, &#x00026; Holmes, 2006</xref>), these uncertainties introduce noise in the learning process and make it harder for participants to search for the optimal policy, especially when the reward landscape has a low gradient, leading to the observed differences in the choice of boundaries. With training, participants should be able to reduce these uncertainties and approach optimal boundaries, as shown by previous research (<xref rid="c49" ref-type="bibr" id="cr49-3">Myung &#x00026; Busemeyer, 1989</xref>; <xref rid="c2" ref-type="bibr" id="cr2-3">Balci et al., 2011</xref>).</p><p>Conversely, when internal noise in the sensory system increases or when the estimate of the task parameters becomes more uncertain, participants should find it more difficult to locate the optimal policy in policy space. For example, it has been shown that the duration estimates of older adults are more variable than younger adults (<xref rid="c4" ref-type="bibr" id="cr4-1">Block, Zakay, &#x00026; Hancock, 1998</xref>) and visual perception declines with aging (<xref rid="c27" ref-type="bibr" id="cr27-1">Habak &#x00026; Faubert, 2000</xref>; <xref rid="c50" ref-type="bibr" id="cr50-1">Owsley, 2011</xref>; <xref rid="c74" ref-type="bibr" id="cr74-1">Spear, 1993</xref>; <xref rid="c96" ref-type="bibr" id="cr96-1">Weale, 1963</xref>). These processes will increase the level of uncertainty in the (temporal) task parameters as well as the visual stimuli and could explain why older adults adopt boundaries that are farther from optimal (<xref rid="c75" ref-type="bibr" id="cr75-3">Starns &#x00026; Ratcliff, 2010</xref>, <xref rid="c76" ref-type="bibr" id="cr76-5">2012</xref>). Of course, it is also possible that the deviation from optimality is a consequence of not only an increase in visual and temporal noise but also a decline in the ability to flexibly set the boundary and more empirical studies would be required to tease apart the relative contribution of these two factors.</p></sec><sec id="s25"><title>Mechanistic Considerations</title><p>The behavior of participants in the experiments above suggests that they adapt their decision-making mechanism to achieve near-maximal reward rates. We claim neither that participants are optimal&#x02014;they clearly are not&#x02014;nor that the mathematical model we have used to derive the optimal policy is a psychological theory. The focus of our study was not on establishing the mechanism by which people achieve this behavior but on comparing the normative behavior with the empirical behavior. In a manner similar to &#x0201c;ideal observer models&#x0201d; in the study of sensory systems (<xref rid="c23" ref-type="bibr" id="cr23-1">Geisler, 2003</xref>), specifying the optimal policy has helped us (a) identify experimental conditions that are best suited to empirically test time-varying decision boundaries, and (b) identify sources for suboptimal behavior (or inefficiencies) through analysis of the reward landscape. Nevertheless, we finish with some considerations of the underlying mechanisms that may be responsible for the time varying boundaries observed in our study.</p><p>First of all, the reader may wonder whether the decreasing bounds we identify in our experiments may be accounted for by existing mechanisms in models that assume constant boundaries. In <xref ref-type="app" id="apcC-2" rid="C">Appendix C</xref>, we explore two such mechanisms&#x02014;between-trial noise in the drift rate and imperfect integration of information. We simulated decisions using a rise-to-threshold model both with and without between-trial noise in drift rate and with and without loss in integration of evidence. We then estimated the slopes of boundaries using the method discussed above and found that the estimated difference in slopes between single- and mixed-difficulty conditions reflected the true difference, irrespective of the noise in drift rate or loss in integration of evidence. Thus, our inferences about difference in slopes remain valid even when these mechanisms are considered.</p><p>Next, the pattern of decision making we observed in the expanded-judgment tasks is compatible with a number of different mechanistic accounts. For example, it is possible that participants did not weigh each cue equally and cues later in the decision carried a larger weight. This mechanism has been recently suggested by the urgency-gating model (<xref rid="c15" ref-type="bibr" id="cr15-1">Cisek, Puskas, &#x00026; El-Murr, 2009</xref>; <xref rid="c79" ref-type="bibr" id="cr79-1">Thura, Beauregard-Racine, Fradet, &#x00026; Cisek, 2012</xref>). Similarly, it is also possible that participants maintained a constant threshold but also used a stochastic deadline. That is, they maintain an internal clock and make a decision if evidence crosses a constant threshold before a deadline or choose the most-likely alternative if the threshold is not crossed but a deadline is reached. This mechanism is similar to the response signal paradigm (e.g., <xref rid="c60" ref-type="bibr" id="cr60-1">Ratcliff, 2006</xref>), with an internal instead of an external deadline. Both these mechanisms will lead to decision boundaries that appear to decrease with time. However, the urgency gating model does not assume integration of sensory input over whole duration of trial, but rather rapid forgetting of previously integrated input. It would be interesting to formally compare in a future study whether the urgency gating model or an integration to boundary model better describes data from the current study, which is freely available, as mentioned earlier.</p><p>However, note that the normative model does not always predict that decision boundaries should decrease with time. In agreement with this, we found that many participants in Experiment 3 did not appear to decrease their decision boundaries in mixed-difficulty condition (also see <xref ref-type="fig" id="fgc16-1" rid="fig16">Figure D1</xref>). These findings are not straightforward to reconcile in mechanistic accounts such as urgency-gating and stochastic deadline and provide a good test for teasing apart these models.</p><p>The logistic regression model used to infer the boundary from data (<xref ref-type="disp-formula" id="eqnc2-3" rid="eqn2">Equations 2</xref> and <xref ref-type="disp-formula" id="eqnc3-1" rid="eqn3">3</xref>) assumes that people integrate evidence to a constant boundary but that the slope of the boundary is allowed to vary. Under this assumption, participants appear to decrease their decision boundaries when decreasing boundaries increases reward rate. So the thrust of our argument is that people seem sensitive to the normative behavior and when the normative behavior changes (single-difficulty vs. mixed-difficulty conditions) participants seem to adapt their decision mechanism in line with the normative standard. A separate and important question is how people make this adaptation. Decreasing the decision boundary, increasing the gain of observations or maintaining a stochastic deadline are all possible mechanisms to achieve this goal and future research should examine what mechanisms are used by people.</p></sec></sec></body><back><fn-group content-type="footnotes"><fn id="fn1"><label>1</label><p>Article available at <ext-link ext-link-type="uri" xlink:href="https://osf.io/9t76q/" specific-use="live">https://osf.io/9t76q/</ext-link></p></fn><fn id="fn2"><label>2</label><p>See, for example, <xref rid="c52" ref-type="bibr" id="cr52-4">Palmer et al. (2005)</xref> who tested 6 participants with &#x0223c;560 trials for each participant and <xref rid="c63" ref-type="bibr" id="cr63-1">Ratcliff and McKoon (2008)</xref> who tested 15 participants with &#x0223c;960 trials per participant. We used a performance-based reward paradigm (outlined subsequently), which means that the number of trials varied between participants and experiments but were between &#x0223c;150 and &#x0223c;650 trials per participant for each of the experiments reported subsequently.</p></fn><fn id="fn3"><label>3</label><p>Each confidence interval is based on percentiles of the bootstrap distribution of the lines of indifference. Each bootstrap distribution is obtained by generating 1,000 independent bootstrapped data sets (per condition) and computing the slope for the line of indifference on the data set. Each data set consists of <italic>N</italic> sampled trials, where <italic>N</italic> is the number of trials (for that condition) seen by the participant.</p></fn><fn id="fn4"><label>4</label><p>Analogous analysis was also done for Experiments 2a through 2d as well and no significant differences were found.</p></fn><fn id="fn5"><label>5</label><p>The luminance of the monitor was gamma-corrected so that luminance was a linear function of grayscale RGB value. The background luminance was fixed to 0.5 on a scale of [0, 1].</p></fn><fn id="fn6"><label>6</label><p>When the estimated slope for a participant is really steep, a large negative slope is qualitatively similar to a large positive slope. For this reason, the confidence intervals for some participants with large slopes seem extremely wide. We compare the slopes using a circular difference (<xref ref-type="disp-formula" id="eqnc4-3" rid="eqn4">Equation 4</xref>), which corrects for this problem.</p></fn><fn id="fn7"><label>7</label><p>There is an outlier who seems to have a large positive slope in mixed games. This may seem unintuitive, but, as noted above, there is little difference between a large positive and a large negative slope&#x02014;in both cases the probability of going depends strongly on time (a temporal deadline) and weakly on evidence. The circular difference (<xref ref-type="disp-formula" id="eqnc4-4" rid="eqn4">Equation 4</xref>) accounts for cases like this.</p></fn><fn id="fn8"><label>8</label><p>Note that we used both <mml:math id="math20"><mml:mrow><mml:msup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math> and <mml:math id="math21"><mml:mrow><mml:msup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math> to obtain maximum-likelihood estimates. If we use only <mml:math id="math22"><mml:mrow><mml:msup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math>, which is what is available if the paradigm does not involve an expanded-judgment task, we get a more noisy estimate of the slope. In that case we also obtain a poor correlation between true and estimated differences when data was simulated using the stochastic boundary model (bottom-right) graph.</p></fn></fn-group><ref-list><title>References</title><ref id="c1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Audley</surname><given-names>R.</given-names></name>, &#x00026; <name><surname>Pike</surname><given-names>A.</given-names></name></person-group> (<year>1965</year>). <article-title>Some alternative stochastic models of choice</article-title>. <source>British Journal of Mathematical and Statistical Psychology</source>, <volume>18</volume>, <fpage>207</fpage>&#x02013;<lpage>225</lpage>.</mixed-citation></ref><ref id="c2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Balci</surname><given-names>F.</given-names></name>, <name><surname>Simen</surname><given-names>P.</given-names></name>, <name><surname>Niyogi</surname><given-names>R.</given-names></name>, <name><surname>Saxe</surname><given-names>A.</given-names></name>, <name><surname>Hughes</surname><given-names>J. A.</given-names></name>, <name><surname>Holmes</surname><given-names>P.</given-names></name>, &#x00026; <name><surname>Cohen</surname><given-names>J. D.</given-names></name></person-group> (<year>2011</year>). <article-title>Acquisition of decision making criteria: Reward rate ultimately beats accuracy</article-title>. <source>Attention, Perception, &#x00026; Psychophysics</source>, <volume>73</volume>, <fpage>640</fpage>&#x02013;<lpage>657</lpage>.</mixed-citation></ref><ref id="c3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Becker</surname><given-names>G. M.</given-names></name></person-group> (<year>1958</year>). <article-title>Sequential decision making: Wald&#x02019;s model and estimates of parameters</article-title>. <source>Journal of Experimental Psychology</source>, <volume>55</volume>, <fpage>628</fpage>&#x02013;<lpage>636</lpage>.<pub-id pub-id-type="pmid">13563781</pub-id></mixed-citation></ref><ref id="c4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Block</surname><given-names>R. A.</given-names></name>, <name><surname>Zakay</surname><given-names>D.</given-names></name>, &#x00026; <name><surname>Hancock</surname><given-names>P. A.</given-names></name></person-group> (<year>1998</year>). <article-title>Human aging and duration judgments: A meta-analytic review</article-title>. <source>Psychology and Aging</source>, <volume>13</volume>, <fpage>584</fpage>.<pub-id pub-id-type="pmid">9883459</pub-id></mixed-citation></ref><ref id="c5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R.</given-names></name>, <name><surname>Brown</surname><given-names>E.</given-names></name>, <name><surname>Moehlis</surname><given-names>J.</given-names></name>, <name><surname>Holmes</surname><given-names>P.</given-names></name>, &#x00026; <name><surname>Cohen</surname><given-names>J. D.</given-names></name></person-group> (<year>2006</year>). <article-title>The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced choice tasks</article-title>. <source>Psychological Review</source>, <volume>113</volume>, <fpage>700</fpage>&#x02013;<lpage>765</lpage>.<pub-id pub-id-type="pmid">17014301</pub-id></mixed-citation></ref><ref id="c6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R.</given-names></name>, <name><surname>Hu</surname><given-names>P. T.</given-names></name>, <name><surname>Holmes</surname><given-names>P. J.</given-names></name>, &#x00026; <name><surname>Cohen</surname><given-names>J. D.</given-names></name></person-group> (<year>2010</year>). <article-title>Do humans produce the speed&#x02013;accuracy trade-off that maximizes reward rate?</article-title>
<source>The Quarterly Journal of Experimental Psychology</source>, <volume>63</volume>, <fpage>863</fpage>&#x02013;<lpage>891</lpage>.<pub-id pub-id-type="pmid">19746300</pub-id></mixed-citation></ref><ref id="c7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bogacz</surname><given-names>R.</given-names></name>, <name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name>, <name><surname>Forstmann</surname><given-names>B. U.</given-names></name>, &#x00026; <name><surname>Nieuwenhuis</surname><given-names>S.</given-names></name></person-group> (<year>2010</year>). <article-title>The neural basis of the speed&#x02013;accuracy tradeoff</article-title>. <source>Trends in Neurosciences</source>, <volume>33</volume>, <fpage>10</fpage>&#x02013;<lpage>16</lpage>.<pub-id pub-id-type="pmid">19819033</pub-id></mixed-citation></ref><ref id="c8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bohil</surname><given-names>C. J.</given-names></name>, &#x00026; <name><surname>Maddox</surname><given-names>W. T.</given-names></name></person-group> (<year>2003</year>). <article-title>On the generality of optimal versus objective classifier feedback effects on decision criterion learning in perceptual categorization</article-title>. <source>Memory &#x00026; Cognition</source>, <volume>31</volume>, <fpage>181</fpage>&#x02013;<lpage>198</lpage>.<pub-id pub-id-type="pmid">12749461</pub-id></mixed-citation></ref><ref id="c9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brainard</surname><given-names>D. H.</given-names></name></person-group> (<year>1997</year>). <article-title>The psychophysics toolbox</article-title>. <source>Spatial Vision</source>, <volume>10</volume>, <fpage>433</fpage>&#x02013;<lpage>436</lpage>.<pub-id pub-id-type="pmid">9176952</pub-id></mixed-citation></ref><ref id="c10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Britten</surname><given-names>K. H.</given-names></name>, <name><surname>Shadlen</surname><given-names>M. N.</given-names></name>, <name><surname>Newsome</surname><given-names>W. T.</given-names></name>, &#x00026; <name><surname>Movshon</surname><given-names>J. A.</given-names></name></person-group> (<year>1992</year>). <article-title>The analysis of visual motion: A comparison of neuronal and psychophysical performance</article-title>. <source>The Journal of Neuroscience</source>, <volume>12</volume>, <fpage>4745</fpage>&#x02013;<lpage>4765</lpage>.<pub-id pub-id-type="pmid">1464765</pub-id></mixed-citation></ref><ref id="c11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Brown</surname><given-names>S.</given-names></name>, <name><surname>Steyvers</surname><given-names>M.</given-names></name>, &#x00026; <name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name></person-group> (<year>2009</year>). <article-title>Observing evidence accumulation during multi-alternative decisions</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>53</volume>, <fpage>453</fpage>&#x02013;<lpage>462</lpage>.</mixed-citation></ref><ref id="c12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Busemeyer</surname><given-names>J. R.</given-names></name></person-group> (<year>1985</year>). <article-title>Decision making under uncertainty: A comparison of simple scalability, fixed-sample, and sequential-sampling models</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>11</volume>, <fpage>538</fpage>&#x02013;<lpage>564</lpage>.</mixed-citation></ref><ref id="c13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Camerer</surname><given-names>C. F.</given-names></name>, &#x00026; <name><surname>Hogarth</surname><given-names>R. M.</given-names></name></person-group> (<year>1999</year>). <article-title>The effects of financial incentives in experiments: A review and capital-labor-production framework</article-title>. <source>Journal of Risk and Uncertainty</source>, <volume>19</volume>, <fpage>7</fpage>&#x02013;<lpage>42</lpage>.</mixed-citation></ref><ref id="c14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cartwright</surname><given-names>D.</given-names></name>, &#x00026; <name><surname>Festinger</surname><given-names>L.</given-names></name></person-group> (<year>1943</year>). <article-title>A quantitative theory of decision</article-title>. <source>Psychological Review</source>, <volume>50</volume>, <fpage>595</fpage>&#x02013;<lpage>621</lpage>.</mixed-citation></ref><ref id="c15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cisek</surname><given-names>P.</given-names></name>, <name><surname>Puskas</surname><given-names>G. A.</given-names></name>, &#x00026; <name><surname>El-Murr</surname><given-names>S.</given-names></name></person-group> (<year>2009</year>). <article-title>Decisions in changing conditions: The urgency-gating model</article-title>. <source>The Journal of Neuroscience</source>, <volume>29</volume>, <fpage>11560</fpage>&#x02013;<lpage>11571</lpage>.<pub-id pub-id-type="pmid">19759303</pub-id></mixed-citation></ref><ref id="c16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cubitt</surname><given-names>R. P.</given-names></name>, <name><surname>Starmer</surname><given-names>C.</given-names></name>, &#x00026; <name><surname>Sugden</surname><given-names>R.</given-names></name></person-group> (<year>1998</year>). <article-title>On the validity of the random lottery incentive system</article-title>. <source>Experimental Economics</source>, <volume>1</volume>, <fpage>115</fpage>&#x02013;<lpage>131</lpage>.</mixed-citation></ref><ref id="c17"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ditterich</surname><given-names>J.</given-names></name></person-group> (<year>2006</year>). <article-title>Stochastic models of decisions about motion direction: Behavior and physiology</article-title>. <source>Neural Networks</source>, <volume>19</volume>, <fpage>981</fpage>&#x02013;<lpage>1012</lpage>.<pub-id pub-id-type="pmid">16952441</pub-id></mixed-citation></ref><ref id="c18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Drugowitsch</surname><given-names>J.</given-names></name>, <name><surname>Moreno-Bote</surname><given-names>R.</given-names></name>, <name><surname>Churchland</surname><given-names>A. K.</given-names></name>, <name><surname>Shadlen</surname><given-names>M. N.</given-names></name>, &#x00026; <name><surname>Pouget</surname><given-names>A.</given-names></name></person-group> (<year>2012</year>). <article-title>The cost of accumulating evidence in perceptual decision making</article-title>. <source>Journal of Neuroscience</source>, <volume>32</volume>, <fpage>3612</fpage>&#x02013;<lpage>3628</lpage>.<pub-id pub-id-type="pmid">22423085</pub-id></mixed-citation></ref><ref id="c19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Edwards</surname><given-names>W.</given-names></name></person-group> (<year>1965</year>). <article-title>Optimal strategies for seeking information: Models for statistics, choice reaction times, and human information processing</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>2</volume>, <fpage>312</fpage>&#x02013;<lpage>329</lpage>.</mixed-citation></ref><ref id="c20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Evans</surname><given-names>N. J.</given-names></name>, &#x00026; <name><surname>Brown</surname><given-names>S. D.</given-names></name></person-group> (<year>2016</year>). <article-title>People adopt optimal policies in simple decision-making, after practice and guidance</article-title>. <source>Psychonomic Bulletin &#x00026; Review</source>. <comment>Advance online publication</comment>
<pub-id pub-id-type="doi">10.3758/s13423-016-1135-1</pub-id></mixed-citation></ref><ref id="c21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Festinger</surname><given-names>L.</given-names></name></person-group> (<year>1943</year>). <article-title>Studies in decision. ii. An empirical test of a quantitative theory of decision</article-title>. <source>Journal of Experimental Psychology</source>, <volume>32</volume>, <fpage>411</fpage>.</mixed-citation></ref><ref id="c22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garrett</surname><given-names>H. E.</given-names></name></person-group> (<year>1922</year>). <article-title>A study of the relation of accuracy to speed</article-title>. <source>Archives of Psychology</source>, <volume>56</volume>, <fpage>1</fpage>&#x02013;<lpage>104</lpage>.</mixed-citation></ref><ref id="c23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Geisler</surname><given-names>W. S.</given-names></name></person-group> (<year>2003</year>). <article-title>Ideal observer analysis</article-title>. <source>The Visual Neurosciences</source>, <volume>10</volume>, <fpage>12</fpage>&#x02013;<lpage>12</lpage>.</mixed-citation></ref><ref id="c24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Georgeson</surname><given-names>M. A.</given-names></name></person-group> (<year>1987</year>). <article-title>Temporal properties of spatial contrast vision</article-title>. <source>Vision Research</source>, <volume>27</volume>, <fpage>765</fpage>&#x02013;<lpage>780</lpage>.<pub-id pub-id-type="pmid">3660638</pub-id></mixed-citation></ref><ref id="c25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gonzalez</surname><given-names>R.</given-names></name>, &#x00026; <name><surname>Wu</surname><given-names>G.</given-names></name></person-group> (<year>1999</year>). <article-title>On the shape of the probability weighting function</article-title>. <source>Cognitive Psychology</source>, <volume>38</volume>, <fpage>129</fpage>&#x02013;<lpage>166</lpage>.<pub-id pub-id-type="pmid">10090801</pub-id></mixed-citation></ref><ref id="c26"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Green</surname><given-names>D. M.</given-names></name>, &#x00026; <name><surname>Swets</surname><given-names>J. A.</given-names></name></person-group> (<year>1966</year>). <source>Signal detection theory and psychophysics</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley &#x00026; Sons</publisher-name>.</mixed-citation></ref><ref id="c27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Habak</surname><given-names>C.</given-names></name>, &#x00026; <name><surname>Faubert</surname><given-names>J.</given-names></name></person-group> (<year>2000</year>). <article-title>Larger effect of aging on the perception of higher order stimuli</article-title>. <source>Vision Research</source>, <volume>40</volume>, <fpage>943</fpage>&#x02013;<lpage>950</lpage>.<pub-id pub-id-type="pmid">10720665</pub-id></mixed-citation></ref><ref id="c28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hawkins</surname><given-names>G.</given-names></name>, <name><surname>Brown</surname><given-names>S. D.</given-names></name>, <name><surname>Steyvers</surname><given-names>M.</given-names></name>, &#x00026; <name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name></person-group> (<year>2012</year>). <article-title>Decision speed induces context effects in choice</article-title>. <source>Experimental Psychology</source>, <volume>59</volume>, <fpage>206</fpage>&#x02013;<lpage>215</lpage>.<pub-id pub-id-type="pmid">22411178</pub-id></mixed-citation></ref><ref id="c29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hawkins</surname><given-names>G. E.</given-names></name>, <name><surname>Brown</surname><given-names>S. D.</given-names></name>, <name><surname>Steyvers</surname><given-names>M.</given-names></name>, &#x00026; <name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name></person-group> (<year>2012</year>). <article-title>An optimal adjustment procedure to minimize experiment time in decisions with multiple alternatives</article-title>. <source>Psychonomic Bulletin &#x00026; Review</source>, <volume>19</volume>, <fpage>339</fpage>&#x02013;<lpage>348</lpage>.<pub-id pub-id-type="pmid">22302644</pub-id></mixed-citation></ref><ref id="c30"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hawkins</surname><given-names>G. E.</given-names></name>, <name><surname>Forstmann</surname><given-names>B. U.</given-names></name>, <name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name>, <name><surname>Ratcliff</surname><given-names>R.</given-names></name>, &#x00026; <name><surname>Brown</surname><given-names>S. D.</given-names></name></person-group> (<year>2015</year>). <article-title>Revisiting the evidence for collapsing boundaries and urgency signals in perceptual decision-making</article-title>. <source>The Journal of Neuroscience</source>, <volume>35</volume>, <fpage>2476</fpage>&#x02013;<lpage>2484</lpage>.<pub-id pub-id-type="pmid">25673842</pub-id></mixed-citation></ref><ref id="c31"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Howard</surname><given-names>R. A.</given-names></name></person-group> (<year>1960</year>). <source>Dynamic programming and Markov processes</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</mixed-citation></ref><ref id="c32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Howell</surname><given-names>W. C.</given-names></name>, &#x00026; <name><surname>Kreidler</surname><given-names>D. L.</given-names></name></person-group> (<year>1963</year>). <article-title>Information processing under contradictory instructional sets</article-title>. <source>Journal of Experimental Psychology</source>, <volume>65</volume>, <fpage>39</fpage>&#x02013;<lpage>46</lpage>.<pub-id pub-id-type="pmid">13955169</pub-id></mixed-citation></ref><ref id="c33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Huang</surname><given-names>Y.</given-names></name>, &#x00026; <name><surname>Rao</surname><given-names>R. P.</given-names></name></person-group> (<year>2013</year>). <article-title>Reward optimization in the primate brain: A probabilistic model of decision making under uncertainty</article-title>. <source>PloS ONE</source>, <volume>8</volume>(<issue>1</issue>), <elocation-id>e53344</elocation-id>.<pub-id pub-id-type="pmid">23349707</pub-id></mixed-citation></ref><ref id="c34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Irwin</surname><given-names>F. W.</given-names></name>, &#x00026; <name><surname>Smith</surname><given-names>W. A. S.</given-names></name></person-group> (<year>1956</year>). <article-title>Further tests of theories of decision in an &#x0201c;expanded judgment&#x0201d; situation</article-title>. <source>Journal of Experimental Psychology</source>, <volume>52</volume>, <fpage>345</fpage>.<pub-id pub-id-type="pmid">13385410</pub-id></mixed-citation></ref><ref id="c35"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Irwin</surname><given-names>F. W.</given-names></name>, <name><surname>Smith</surname><given-names>W. A. S.</given-names></name>, &#x00026; <name><surname>Mayfield</surname><given-names>J. F.</given-names></name></person-group> (<year>1956</year>). <article-title>Tests of theories of decision in an &#x0201c;expanded judgement&#x0201d; situation</article-title>. <source>Journal of Experimental Psychology</source>, <volume>51</volume>, <fpage>261</fpage>&#x02013;<lpage>268</lpage>.<pub-id pub-id-type="pmid">13306875</pub-id></mixed-citation></ref><ref id="c36"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Johnson</surname><given-names>D. M.</given-names></name></person-group> (<year>1939</year>). <article-title>Confidence and speed in the two-category judgement</article-title>. <source>Archives of Psychology</source>, <volume>241</volume>, <fpage>1</fpage>&#x02013;<lpage>52</lpage>.</mixed-citation></ref><ref id="c37"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kleiner</surname><given-names>M.</given-names></name>, <name><surname>Brainard</surname><given-names>D.</given-names></name>, <name><surname>Pelli</surname><given-names>D.</given-names></name>, <name><surname>Ingling</surname><given-names>A.</given-names></name>, <name><surname>Murray</surname><given-names>R.</given-names></name>, &#x00026; <name><surname>Broussard</surname><given-names>C.</given-names></name></person-group> (<year>2007</year>). <article-title>What&#x02019;s new in psychtoolbox-3</article-title>. <source>Perception</source>, <volume>36</volume>, <fpage>1</fpage>&#x02013;<lpage>1</lpage>.</mixed-citation></ref><ref id="c38"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>LaBerge</surname><given-names>D.</given-names></name></person-group> (<year>1962</year>). <article-title>A recruitment theory of simple behavior</article-title>. <source>Psychometrika</source>, <volume>27</volume>, <fpage>375</fpage>&#x02013;<lpage>396</lpage>.</mixed-citation></ref><ref id="c39"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Laming</surname><given-names>D. R. J.</given-names></name></person-group> (<year>1968</year>). <source>Information theory of choice-reaction times</source>. <publisher-loc>London, England</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</mixed-citation></ref><ref id="c40"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Lamport</surname><given-names>L.</given-names></name></person-group> (<year>2012</year>). <article-title>Buridan&#x02019;s principle</article-title>. <source>Foundations of Physics</source>, <volume>42</volume>, <fpage>1056</fpage>&#x02013;<lpage>1066</lpage>.</mixed-citation></ref><ref id="c41"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Link</surname><given-names>S.</given-names></name>, &#x00026; <name><surname>Heath</surname><given-names>R.</given-names></name></person-group> (<year>1975</year>). <article-title>A sequential theory of psychological discrimination</article-title>. <source>Psychometrika</source>, <volume>40</volume>, <fpage>77</fpage>&#x02013;<lpage>105</lpage>.</mixed-citation></ref><ref id="c42"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Luce</surname><given-names>R. D.</given-names></name></person-group> (<year>1986</year>). <source>Response times</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>.</mixed-citation></ref><ref id="c43"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ludwig</surname><given-names>C. J.</given-names></name></person-group> (<year>2009</year>). <article-title>Temporal integration of sensory evidence for saccade target selection</article-title>. <source>Vision Research</source>, <volume>49</volume>, <fpage>2764</fpage>&#x02013;<lpage>2773</lpage>.<pub-id pub-id-type="pmid">19686771</pub-id></mixed-citation></ref><ref id="c44"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ludwig</surname><given-names>C. J.</given-names></name>, <name><surname>Gilchrist</surname><given-names>I. D.</given-names></name>, <name><surname>McSorley</surname><given-names>E.</given-names></name>, &#x00026; <name><surname>Baddeley</surname><given-names>R. J.</given-names></name></person-group> (<year>2005</year>). <article-title>The temporal impulse response underlying saccadic decisions</article-title>. <source>The Journal of Neuroscience</source>, <volume>25</volume>, <fpage>9907</fpage>&#x02013;<lpage>9912</lpage>.<pub-id pub-id-type="pmid">16251438</pub-id></mixed-citation></ref><ref id="c45"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Maddox</surname><given-names>W. T.</given-names></name>, &#x00026; <name><surname>Bohil</surname><given-names>C. J.</given-names></name></person-group> (<year>1998</year>). <article-title>Base-rate and payoff effects in multidimensional perceptual categorization</article-title>. <source>Journal of Experimental Psychology: Learning, Memory, and Cognition</source>, <volume>24</volume>, <fpage>1459</fpage>.</mixed-citation></ref><ref id="c46"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Malhotra</surname><given-names>G.</given-names></name>, <name><surname>Leslie</surname><given-names>D.</given-names></name>, <name><surname>Ludwig</surname><given-names>C.</given-names></name>, &#x00026; <name><surname>Bogacz</surname><given-names>R.</given-names></name></person-group> (<year>2017</year>). <article-title>A simple optimality model for time-varying decision boundaries</article-title>. <source>Psychonomic Bulletin &#x00026; Review</source>. <comment>Manuscript submitted for publication</comment>.</mixed-citation></ref><ref id="c47"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Manz</surname><given-names>W.</given-names></name></person-group> (<year>1970</year>). <article-title>Experiments on probabilistic information processing</article-title>. <source>Acta Psychologica</source>, <volume>34</volume>, <fpage>184</fpage>&#x02013;<lpage>200</lpage>.</mixed-citation></ref><ref id="c48"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Moran</surname><given-names>R.</given-names></name></person-group> (<year>2015</year>). <article-title>Optimal decision making in heterogeneous and biased environments</article-title>. <source>Psychonomic Bulletin &#x00026; Review</source>, <volume>22</volume>, <fpage>38</fpage>&#x02013;<lpage>53</lpage>.<pub-id pub-id-type="pmid">24928091</pub-id></mixed-citation></ref><ref id="c49"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Myung</surname><given-names>I. J.</given-names></name>, &#x00026; <name><surname>Busemeyer</surname><given-names>J. R.</given-names></name></person-group> (<year>1989</year>). <article-title>Criterion learning in a deferred decision-making task</article-title>. <source>The American Journal of Psychology</source>, <volume>102</volume>, <fpage>1</fpage>&#x02013;<lpage>16</lpage>.</mixed-citation></ref><ref id="c50"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Owsley</surname><given-names>C.</given-names></name></person-group> (<year>2011</year>). <article-title>Aging and vision</article-title>. <source>Vision Research</source>, <volume>51</volume>, <fpage>1610</fpage>&#x02013;<lpage>1622</lpage>.<pub-id pub-id-type="pmid">20974168</pub-id></mixed-citation></ref><ref id="c51"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Pachella</surname><given-names>R. G.</given-names></name></person-group> (<year>1974</year>). <chapter-title>The interpretation of reaction time in information processing research</chapter-title> In <person-group person-group-type="editor"><name><surname>Kantowitz</surname><given-names>B.</given-names></name></person-group> (<role>Ed.</role>), <source>Human information processing: Tutorials in performance and cognition</source> (pp. <fpage>41</fpage>&#x02013;<lpage>82</lpage>). <publisher-loc>Hillsdale, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum</publisher-name>.</mixed-citation></ref><ref id="c52"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Palmer</surname><given-names>J.</given-names></name>, <name><surname>Huk</surname><given-names>A. C.</given-names></name>, &#x00026; <name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>2005</year>). <article-title>The effect of stimulus strength on the speed and accuracy of a perceptual decision</article-title>. <source>Journal of Vision</source>, <volume>5</volume>, <fpage>376</fpage>&#x02013;<lpage>404</lpage>.<pub-id pub-id-type="pmid">16097871</pub-id></mixed-citation></ref><ref id="c53"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Park</surname><given-names>H.</given-names></name>, <name><surname>Lueckmann</surname><given-names>J.-M.</given-names></name>, <name><surname>Kriegstein</surname><given-names>K.</given-names></name>, <name><surname>von Bitzer</surname><given-names>S.</given-names></name>, &#x00026; <name><surname>Kiebel</surname><given-names>S. J.</given-names></name></person-group> (<year>2016</year>). <article-title>Spatiotemporal dynamics of random stimuli account for trial-to-trial variability in perceptual decision making</article-title>. <source>Scientific Reports</source>, <volume>6</volume>, <fpage>1</fpage>&#x02013;<lpage>17</lpage>.</mixed-citation></ref><ref id="c54"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pelli</surname><given-names>D. G.</given-names></name></person-group> (<year>1997</year>). <article-title>The video toolbox software for visual psychophysics: Transforming numbers into movies</article-title>. <source>Spatial Vision</source>, <volume>10</volume>, <fpage>437</fpage>&#x02013;<lpage>442</lpage>.<pub-id pub-id-type="pmid">9176953</pub-id></mixed-citation></ref><ref id="c55"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pike</surname><given-names>A.</given-names></name></person-group> (<year>1968</year>). <article-title>Latency and relative frequency of response in psychophysical discrimination</article-title>. <source>British Journal of Mathematical and Statistical Psychology</source>, <volume>21</volume>, <fpage>161</fpage>&#x02013;<lpage>182</lpage>.<pub-id pub-id-type="pmid">5717927</pub-id></mixed-citation></ref><ref id="c56"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pitz</surname><given-names>G. F.</given-names></name>, <name><surname>Reinhold</surname><given-names>H.</given-names></name>, &#x00026; <name><surname>Geller</surname><given-names>E. S.</given-names></name></person-group> (<year>1969</year>). <article-title>Strategies of information seeking in deferred decision making</article-title>. <source>Organizational Behavior and Human Performance</source>, <volume>4</volume>, <fpage>1</fpage>&#x02013;<lpage>19</lpage>.</mixed-citation></ref><ref id="c57"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pleskac</surname><given-names>T. J.</given-names></name>, &#x00026; <name><surname>Busemeyer</surname><given-names>J. R.</given-names></name></person-group> (<year>2010</year>). <article-title>Two-stage dynamic signal detection: A theory of choice, decision time, and confidence</article-title>. <source>Psychological Review</source>, <volume>117</volume>, <fpage>864</fpage>&#x02013;<lpage>901</lpage>.<pub-id pub-id-type="pmid">20658856</pub-id></mixed-citation></ref><ref id="c58"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Puterman</surname><given-names>M. L.</given-names></name></person-group> (<year>2005</year>). <source>Markov decision processes: Discrete stochastic dynamic programming</source>. <publisher-loc>Trenton, NJ</publisher-loc>: <publisher-name>Wiley</publisher-name>.</mixed-citation></ref><ref id="c59"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R.</given-names></name></person-group> (<year>1978</year>). <article-title>A theory of memory retrieval</article-title>. <source>Psychological Review</source>, <volume>83</volume>, <fpage>59</fpage>&#x02013;<lpage>108</lpage>.</mixed-citation></ref><ref id="c60"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R.</given-names></name></person-group> (<year>2006</year>). <article-title>Modeling response signal and response time data</article-title>. <source>Cognitive Psychology</source>, <volume>53</volume>, <fpage>195</fpage>&#x02013;<lpage>237</lpage>.<pub-id pub-id-type="pmid">16890214</pub-id></mixed-citation></ref><ref id="c61"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R.</given-names></name>, <name><surname>Cherian</surname><given-names>A.</given-names></name>, &#x00026; <name><surname>Segraves</surname><given-names>M.</given-names></name></person-group> (<year>2003</year>). <article-title>A comparison of macaque behavior and superior colliculus neuronal activity to predictions from models of two-choice decisions</article-title>. <source>Journal of Neurophysiology</source>, <volume>90</volume>, <fpage>1392</fpage>&#x02013;<lpage>1407</lpage>.<pub-id pub-id-type="pmid">12761282</pub-id></mixed-citation></ref><ref id="c62"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R.</given-names></name>, <name><surname>Hasegawa</surname><given-names>Y. T.</given-names></name>, <name><surname>Hasegawa</surname><given-names>R. P.</given-names></name>, <name><surname>Smith</surname><given-names>P. L.</given-names></name>, &#x00026; <name><surname>Segraves</surname><given-names>M. A.</given-names></name></person-group> (<year>2007</year>). <article-title>Dual diffusion model for single-cell recording data from the superior colliculus in a brightness-discrimination task</article-title>. <source>Journal of Neurophysiology</source>, <volume>97</volume>, <fpage>1756</fpage>&#x02013;<lpage>1774</lpage>.<pub-id pub-id-type="pmid">17122324</pub-id></mixed-citation></ref><ref id="c63"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R.</given-names></name>, &#x00026; <name><surname>McKoon</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>The diffusion decision model: Theory and data for two-choice decision tasks</article-title>. <source>Neural Computation</source>, <volume>20</volume>, <fpage>873</fpage>&#x02013;<lpage>922</lpage>.<pub-id pub-id-type="pmid">18085991</pub-id></mixed-citation></ref><ref id="c64"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R.</given-names></name>, &#x00026; <name><surname>Rouder</surname><given-names>J. N.</given-names></name></person-group> (<year>1998</year>). <article-title>Modeling response times for two-choice decisions</article-title>. <source>Psychological Science</source>, <volume>9</volume>, <fpage>347</fpage>&#x02013;<lpage>356</lpage>.</mixed-citation></ref><ref id="c65"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R.</given-names></name>, &#x00026; <name><surname>Smith</surname><given-names>P. L.</given-names></name></person-group> (<year>2004</year>). <article-title>A comparison of sequential sampling models for two-choice reaction time</article-title>. <source>Psychological Review</source>, <volume>111</volume>, <fpage>333</fpage>.<pub-id pub-id-type="pmid">15065913</pub-id></mixed-citation></ref><ref id="c66"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ratcliff</surname><given-names>R.</given-names></name>, <name><surname>Smith</surname><given-names>P. L.</given-names></name>, <name><surname>Brown</surname><given-names>S. D.</given-names></name>, &#x00026; <name><surname>McKoon</surname><given-names>G.</given-names></name></person-group> (<year>2016</year>). <article-title>Diffusion decision model: Current issues and history</article-title>. <source>Trends in Cognitive Sciences</source>, <volume>20</volume>, <fpage>260</fpage>&#x02013;<lpage>281</lpage>.<pub-id pub-id-type="pmid">26952739</pub-id></mixed-citation></ref><ref id="c67"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Roitman</surname><given-names>J. D.</given-names></name>, &#x00026; <name><surname>Shadlen</surname><given-names>M. N.</given-names></name></person-group> (<year>2002</year>). <article-title>Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title>. <source>Journal of Neuroscience</source>, <volume>22</volume>, <fpage>9475</fpage>&#x02013;<lpage>9489</lpage>.<pub-id pub-id-type="pmid">12417672</pub-id></mixed-citation></ref><ref id="c68"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Ross</surname><given-names>S.</given-names></name></person-group> (<year>1983</year>). <source>Introduction to stochastic dynamic programming</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Academic Press</publisher-name>.</mixed-citation></ref><ref id="c69"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sanders</surname><given-names>A.</given-names></name>, &#x00026; <name><surname>Linden</surname><given-names>W. T.</given-names></name></person-group> (<year>1967</year>). <article-title>Decision making during paced arrival of probabilistic information</article-title>. <source>Acta Psychologica</source>, <volume>27</volume>, <fpage>170</fpage>&#x02013;<lpage>177</lpage>.<pub-id pub-id-type="pmid">6062208</pub-id></mixed-citation></ref><ref id="c70"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Schwarz</surname><given-names>G.</given-names></name></person-group> (<year>1978</year>). <article-title>Estimating the dimension of a model</article-title>. <source>The annals of Statistics</source>, <volume>6</volume>, <fpage>461</fpage>&#x02013;<lpage>464</lpage>.</mixed-citation></ref><ref id="c71"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simen</surname><given-names>P.</given-names></name>, <name><surname>Cohen</surname><given-names>J. D.</given-names></name>, &#x00026; <name><surname>Holmes</surname><given-names>P.</given-names></name></person-group> (<year>2006</year>). <article-title>Rapid decision threshold modulation by reward rate in a neural network</article-title>. <source>Neural Networks</source>, <volume>19</volume>, <fpage>1013</fpage>&#x02013;<lpage>1026</lpage>.<pub-id pub-id-type="pmid">16987636</pub-id></mixed-citation></ref><ref id="c72"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Simen</surname><given-names>P.</given-names></name>, <name><surname>Contreras</surname><given-names>D.</given-names></name>, <name><surname>Buck</surname><given-names>C.</given-names></name>, <name><surname>Hu</surname><given-names>P.</given-names></name>, <name><surname>Holmes</surname><given-names>P.</given-names></name>, &#x00026; <name><surname>Cohen</surname><given-names>J. D.</given-names></name></person-group> (<year>2009</year>). <article-title>Reward rate optimization in two-alternative decision making: Empirical tests of theoretical predictions</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>35</volume>, <fpage>1865</fpage>&#x02013;<lpage>1897</lpage>.<pub-id pub-id-type="pmid">19968441</pub-id></mixed-citation></ref><ref id="c73"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Smith</surname><given-names>P. L.</given-names></name>, &#x00026; <name><surname>Vickers</surname><given-names>D.</given-names></name></person-group> (<year>1989</year>). <article-title>Modeling evidence accumulation with partial loss in expanded judgment</article-title>. <source>Journal of Experimental Psychology: Human Perception and Performance</source>, <volume>15</volume>, <fpage>797</fpage>&#x02013;<lpage>815</lpage>.</mixed-citation></ref><ref id="c74"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Spear</surname><given-names>P. D.</given-names></name></person-group> (<year>1993</year>). <article-title>Neural bases of visual deficits during aging</article-title>. <source>Vision Research</source>, <volume>33</volume>, <fpage>2589</fpage>&#x02013;<lpage>2609</lpage>.<pub-id pub-id-type="pmid">8296455</pub-id></mixed-citation></ref><ref id="c75"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Starns</surname><given-names>J. J.</given-names></name>, &#x00026; <name><surname>Ratcliff</surname><given-names>R.</given-names></name></person-group> (<year>2010</year>). <article-title>The effects of aging on the speed&#x02013;accuracy compromise: Boundary optimality in the diffusion model</article-title>. <source>Psychology and Aging</source>, <volume>25</volume>, <fpage>377</fpage>.<pub-id pub-id-type="pmid">20545422</pub-id></mixed-citation></ref><ref id="c76"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Starns</surname><given-names>J. J.</given-names></name>, &#x00026; <name><surname>Ratcliff</surname><given-names>R.</given-names></name></person-group> (<year>2012</year>). <article-title>Age-related differences in diffusion model boundary optimality with both trial-limited and time-limited tasks</article-title>. <source>Psychonomic Bulletin &#x00026; Review</source>, <volume>19</volume>, <fpage>139</fpage>&#x02013;<lpage>145</lpage>.<pub-id pub-id-type="pmid">22144142</pub-id></mixed-citation></ref><ref id="c77"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stone</surname><given-names>M.</given-names></name></person-group> (<year>1960</year>). <article-title>Models for choice-reaction time</article-title>. <source>Psychometrika</source>, <volume>25</volume>, <fpage>251</fpage>&#x02013;<lpage>260</lpage>.</mixed-citation></ref><ref id="c78"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tanner</surname><given-names>W. P.</given-names></name>, &#x00026; <name><surname>Swets</surname><given-names>J. A.</given-names></name></person-group> (<year>1954</year>). <article-title>A decision-making theory of visual detection</article-title>. <source>Psychological Review</source>, <volume>61</volume>, <fpage>401</fpage>.<pub-id pub-id-type="pmid">13215690</pub-id></mixed-citation></ref><ref id="c79"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thura</surname><given-names>D.</given-names></name>, <name><surname>Beauregard-Racine</surname><given-names>J.</given-names></name>, <name><surname>Fradet</surname><given-names>C.-W.</given-names></name>, &#x00026; <name><surname>Cisek</surname><given-names>P.</given-names></name></person-group> (<year>2012</year>). <article-title>Decision making by urgency gating: Theory and experimental support</article-title>. <source>Journal of Neurophysiology</source>, <volume>108</volume>, <fpage>2912</fpage>&#x02013;<lpage>2930</lpage>.<pub-id pub-id-type="pmid">22993260</pub-id></mixed-citation></ref><ref id="c80"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thurstone</surname><given-names>L. L.</given-names></name></person-group> (<year>1927a</year>). <article-title>A law of comparative judgment</article-title>. <source>Psychological Review</source>, <volume>34</volume>, <fpage>273</fpage>.</mixed-citation></ref><ref id="c81"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thurstone</surname><given-names>L. L.</given-names></name></person-group> (<year>1927b</year>). <article-title>Psychophysical analysis</article-title>. <source>The American Journal of Psychology</source>, <volume>38</volume>, <fpage>368</fpage>&#x02013;<lpage>389</lpage>.</mixed-citation></ref><ref id="c82"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tversky</surname><given-names>A.</given-names></name>, &#x00026; <name><surname>Kahneman</surname><given-names>D.</given-names></name></person-group> (<year>1992</year>). <article-title>Advances in prospect theory: Cumulative representation of uncertainty</article-title>. <source>Journal of Risk and Uncertainty</source>, <volume>5</volume>, <fpage>297</fpage>&#x02013;<lpage>323</lpage>.</mixed-citation></ref><ref id="c83"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vickers</surname><given-names>D.</given-names></name></person-group> (<year>1970</year>). <article-title>Evidence for an accumulator model of psychophysical discrimination</article-title>. <source>Ergonomics</source>, <volume>13</volume>, <fpage>37</fpage>&#x02013;<lpage>58</lpage>.<pub-id pub-id-type="pmid">5416868</pub-id></mixed-citation></ref><ref id="c84"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vickers</surname><given-names>D.</given-names></name></person-group> (<year>1995</year>). <article-title>The frequency accrual speed test (fast): A new measure of &#x02018;mental speed&#x02019;?</article-title>
<source>Personality and Individual Differences</source>, <volume>19</volume>, <fpage>863</fpage>&#x02013;<lpage>879</lpage>.</mixed-citation></ref><ref id="c85"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vickers</surname><given-names>D.</given-names></name>, <name><surname>Burt</surname><given-names>J.</given-names></name>, <name><surname>Smith</surname><given-names>P.</given-names></name>, &#x00026; <name><surname>Brown</surname><given-names>M.</given-names></name></person-group> (<year>1985</year>). <article-title>Experimental paradigms emphasising state or process limitations: I effects on speed&#x02013;accuracy tradeoffs</article-title>. <source>Acta Psychologica</source>, <volume>59</volume>, <fpage>129</fpage>&#x02013;<lpage>161</lpage>.</mixed-citation></ref><ref id="c86"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vickers</surname><given-names>D.</given-names></name>, <name><surname>Nettelbeck</surname><given-names>T.</given-names></name>, &#x00026; <name><surname>Willson</surname><given-names>R.</given-names></name></person-group> (<year>1972</year>). <article-title>Perceptual indices of performance: The measurement of &#x02018;inspection time&#x02019; and &#x02018;noise&#x02019; in the visual system</article-title>. <source>Perception</source>, <volume>1</volume>, <fpage>263</fpage>&#x02013;<lpage>295</lpage>.<pub-id pub-id-type="pmid">4680931</pub-id></mixed-citation></ref><ref id="c87"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vickers</surname><given-names>D.</given-names></name>, <name><surname>Smith</surname><given-names>P.</given-names></name>, <name><surname>Burt</surname><given-names>J.</given-names></name>, &#x00026; <name><surname>Brown</surname><given-names>M.</given-names></name></person-group> (<year>1985</year>). <article-title>Experimental paradigms emphasising state or process limitations: Ii effects on confidence</article-title>. <source>Acta Psychologica</source>, <volume>59</volume>, <fpage>163</fpage>&#x02013;<lpage>193</lpage>.</mixed-citation></ref><ref id="c88"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Voskuilen</surname><given-names>C.</given-names></name>, <name><surname>Ratcliff</surname><given-names>R.</given-names></name>, &#x00026; <name><surname>Smith</surname><given-names>P. L.</given-names></name></person-group> (<year>2016</year>). <article-title>Comparing fixed and collapsing boundary versions of the diffusion model</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>73</volume>, <fpage>59</fpage>&#x02013;<lpage>79</lpage>.</mixed-citation></ref><ref id="c89"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name></person-group> (<year>2007</year>). <article-title>A practical solution to the pervasive problems of p values</article-title>. <source>Psychonomic Bulletin &#x00026; Review</source>, <volume>14</volume>, <fpage>779</fpage>&#x02013;<lpage>804</lpage>.<pub-id pub-id-type="pmid">18087943</pub-id></mixed-citation></ref><ref id="c90"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wagenmakers</surname><given-names>E.-J.</given-names></name>, <name><surname>Ratcliff</surname><given-names>R.</given-names></name>, <name><surname>Gomez</surname><given-names>P.</given-names></name>, &#x00026; <name><surname>McKoon</surname><given-names>G.</given-names></name></person-group> (<year>2008</year>). <article-title>A diffusion model account of criterion shifts in the lexical decision task</article-title>. <source>Journal of Memory and Language</source>, <volume>58</volume>, <fpage>140</fpage>&#x02013;<lpage>159</lpage>.<pub-id pub-id-type="pmid">19122740</pub-id></mixed-citation></ref><ref id="c91"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wald</surname><given-names>A.</given-names></name></person-group> (<year>1947</year>). <source>Sequential analysis</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Wiley</publisher-name>.</mixed-citation></ref><ref id="c92"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wald</surname><given-names>A.</given-names></name>, &#x00026; <name><surname>Wolfowitz</surname><given-names>J.</given-names></name></person-group> (<year>1948</year>). <article-title>Optimum character of the sequential probability ratio test</article-title>. <source>The Annals of Mathematical Statistics</source>, <volume>19</volume>, <fpage>326</fpage>&#x02013;<lpage>339</lpage>.</mixed-citation></ref><ref id="c93"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wallsten</surname><given-names>T. S.</given-names></name></person-group> (<year>1968</year>). <article-title>Failure of predictions from subjectively expected utility theory in a Bayesian decision task</article-title>. <source>Organizational Behavior and Human Performance</source>, <volume>3</volume>, <fpage>239</fpage>&#x02013;<lpage>252</lpage>.</mixed-citation></ref><ref id="c94"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wasserman</surname><given-names>L.</given-names></name></person-group> (<year>2000</year>). <article-title>Bayesian model selection and model averaging</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>44</volume>, <fpage>92</fpage>&#x02013;<lpage>107</lpage>.<pub-id pub-id-type="pmid">10733859</pub-id></mixed-citation></ref><ref id="c95"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Watson</surname><given-names>A. B.</given-names></name>, <name><surname>Ahumada</surname><given-names>A. J.</given-names></name>, &#x00026; <name><surname>Farrell</surname><given-names>J. E.</given-names></name></person-group> (<year>1986</year>). <article-title>Window of visibility: A psychophysical theory of fidelity in time-sampled visual motion displays</article-title>. <source>JOSA A</source>, <volume>3</volume>, <fpage>300</fpage>&#x02013;<lpage>307</lpage>.</mixed-citation></ref><ref id="c96"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Weale</surname><given-names>R. A.</given-names></name></person-group> (<year>1963</year>). <source>The aging eye</source>. <publisher-loc>New York, NY</publisher-loc>: <publisher-name>Hoeber Medical Division, Harper &#x00026; Row</publisher-name>.</mixed-citation></ref><ref id="c97"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wickelgren</surname><given-names>W. A.</given-names></name></person-group> (<year>1977</year>). <article-title>Speed&#x02013;accuracy tradeoff and information processing dynamics</article-title>. <source>Acta Psychologica</source>, <volume>41</volume>, <fpage>67</fpage>&#x02013;<lpage>85</lpage>.</mixed-citation></ref><ref id="c98"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zacksenhouse</surname><given-names>M.</given-names></name>, <name><surname>Bogacz</surname><given-names>R.</given-names></name>, &#x00026; <name><surname>Holmes</surname><given-names>P.</given-names></name></person-group> (<year>2010</year>). <article-title>Robust versus optimal strategies for two-alternative forced choice tasks</article-title>. <source>Journal of Mathematical Psychology</source>, <volume>54</volume>, <fpage>230</fpage>&#x02013;<lpage>246</lpage>.<pub-id pub-id-type="pmid">23180885</pub-id></mixed-citation></ref></ref-list><app-group><app id="A"><label>A</label><title>Nondecision Time</title><sec id="s26"><p><xref ref-type="fig" id="fgc12-2" rid="fig12">Figure A1</xref> illustrates the reverse correlation procedure used to compute nondecision time across the experiments. For this example participant, the proportion of easy-difficulty trials where the samples at time steps (1, 2, 3, 4, 5, 6, . . .) before the response were in the same direction as the responses were (0.62, 0.65, 0.63, 0.68, 0.85, 0.91, . . .). The first time-step where this proportion was larger than 0.75 was 5, and we estimated the nondecision time to be 4. Note that the correlation during the nondecision time is not 0.50 because of drift in the stimuli&#x02014;the responses made by participants are generally correlated to the stimulus (provided their response rates were better than chance, which we check for in our exclusion criterion). Hence it is important to pick a threshold that is larger than the drift. We experimented with a number of different threshold values. Results remained similar for a range of threshold values that were above the drift rate but below the highest correlated stimuli for the participant. The threshold value chosen in this manner was kept constant across participants and experiments.<xref ref-type="fig-anchor" rid="fig12"/></p><p>Note that this analysis method assumes a fixed nondecision time across trials. Because nondecision time would, presumably, vary from trial to trial, we carried out simulations to test how trial-by-trial variability in nondecision time affects our estimates of the slopes of the decision boundaries. We found that the analysis method outlined in the main text was robust under trial-to-trial variability in nondecision time: Adding a trial-by-trial variability added a small amount of noise in our estimates but estimated slopes were still highly correlated with true slopes and inferences about difference in slopes between conditions remained the same irrespective of the variability of nondecision time.</p></sec></app><app id="B"><label>B</label><title>Parameter Recovery</title><sec id="s27"><p>In this study, we estimated decision boundaries based on a line of indifference computed using a logistic regression model. We now show that this estimation method allows us to make valid comparisons about slopes of single- and mixed-difficulty games and that our inferences about difference in slopes are valid irrespective of whether the noise in decisions originates from stochasticity in <italic>wait&#x02013;go</italic> actions (as we assume) or from a noisy integration of sensory signals.</p><p>We evaluated estimated slopes by simulating decisions from known boundaries and comparing estimated values with known values. Decisions were simulated using two alternative models: (a) a rise-to-threshold model, with noisy accumulation of evidence but no noise in the boundary and (b) a rise-to-threshold model with no noise in the accumulated signal but noisy <italic>wait&#x02013;go</italic> decisions. Once decisions had been generated, slopes were estimated using two alternative fitting methods: the logistic regression method described in <xref ref-type="disp-formula" id="eqnc2-4" rid="eqn2">Equations 2</xref> and <xref ref-type="disp-formula" id="eqnc3-2" rid="eqn3">3</xref> and a maximum likelihood fit to rise-to-threshold model described below. In <xref ref-type="fig" id="fgc13-1" rid="fig13">Figure B1</xref>, we show a 2 &#x000d7; 2 comparison between the two estimation methods and the two models used to generate the decisions. Before discussing these results, we describe how simulated data was generated and how the slopes of boundary were estimated.<xref ref-type="fig-anchor" rid="fig13"/></p></sec><sec id="s28"><title>Simulating Decisions</title><p>In the noisy accumulation model, each sample (cue) was generated using a Bernoulli process (<xref ref-type="disp-formula" id="eqnc1-1" rid="eqn1">Equation 1</xref>), with drift parameters (<italic>u</italic><sub><italic>e</italic></sub> = 0.72, <italic>u</italic><sub><italic>d</italic></sub> = 0.50). These samples were then integrated in a noisy decision variable, <italic>V</italic>:
<disp-formula id="eqn5"><alternatives><graphic xlink:href="xge_146_6_776_eqn5a.jpg" id="eqn5a"/><mml:math id="M5"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mi>X</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003be;</mml:mi></mml:mrow></mml:math></alternatives><label>5</label></disp-formula>
where <mml:math id="math23"><mml:mrow><mml:mi>&#x003be;</mml:mi><mml:mo>&#x0223c;</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> is a zero-mean Gaussian noise with variance &#x003c3;<sub><italic>V</italic></sub><sup>2</sup>. This integration process generates a random walk, (<italic>X</italic><sub>1</sub>, . . . , <italic>X</italic><sub><italic>t</italic></sub>) and terminates when the decision-variable, <italic>V</italic><sub><italic>t</italic></sub>, crosses a known boundary. We simulated random walks using 200 different values of boundary (standing for 200 simulated participants), with varying slopes and intercepts, generating 1,000 random walks for each boundary (in both easy and mixed conditions).</p><p>For the stochastic boundary model, decisions were generated stochastically based on the distance from boundary. For each given boundary, &#x003b8;, we determined the probability of going at any point (<italic>t</italic>, <italic>x</italic>) of the random walk, based on the distance, <italic>f</italic><sub>&#x003b8;</sub>(<italic>t</italic>, <italic>x</italic>), of the point from the boundary:
<disp-formula id="eqn6"><alternatives><graphic xlink:href="xge_146_6_776_eqn6a.jpg" id="eqn6a"/><mml:math id="M6"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow><mml:mrow><mml:mn>1</mml:mn><mml:mo>+</mml:mo><mml:msup><mml:mi>e</mml:mi><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>6</label></disp-formula></p><p>The key difference between data simulated using this model and the rise-to-threshold model is that this model does not assume any accumulation of noise&#x02014;each <italic>wait&#x02013;go</italic> action is independent and solely based on <mml:math id="math24"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> at that point.</p></sec><sec id="s29"><title>Estimating Slopes</title><p>The logistic regression method of estimating slopes has been described in the main text (<xref ref-type="disp-formula" id="eqnc2-5" rid="eqn2">Equations 2</xref> and <xref ref-type="disp-formula" id="eqnc3-3" rid="eqn3">3</xref>). We now describe how we generated maximum-likelihood estimates of slopes for the rise-to-threshold model with noisy accumulation of evidence.</p><p>According to this model, the value of the decision variable after accumulating <italic>t</italic> samples and evidence <italic>x</italic> is obtained by integrating <xref ref-type="disp-formula" id="eqnc5-1" rid="eqn5">Equation 5</xref> and is given by the Gaussian distribution, <mml:math id="math25"><mml:mrow><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mo>&#x000b7;</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>d</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math>, with mean <italic>x</italic> and variance &#x003c3;<sub><italic>d</italic></sub><sup>2</sup><italic>t</italic>, where &#x003c3;<sub><italic>d</italic></sub> is a free parameter that needs to be estimated. The probability of observing a <italic>go</italic> at (<italic>t</italic>, <italic>x</italic>) will be given by the probability that the decision variable is greater than or equal to the boundary, &#x003b8;, i.e.
<disp-formula id="eqn7"><alternatives><graphic xlink:href="xge_146_6_776_eqn7a.jpg" id="eqn7a"/><mml:math id="M7"><mml:mrow><mml:mtable columnspacing="0.4em" width="auto" columnalign="left"><mml:mtr columnalign="left"><mml:mtd columnalign="right"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msup><mml:mrow><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msup><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mspace width=".33em"/><mml:mstyle displaystyle="true"><mml:mrow><mml:msubsup><mml:mrow><mml:mo>&#x0222b;</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi>&#x0221e;</mml:mi></mml:mrow></mml:msubsup><mml:mi mathvariant="script">N</mml:mi></mml:mrow></mml:mstyle><mml:mo stretchy="false">(</mml:mo><mml:mi>&#x003ba;</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mi>d</mml:mi><mml:mi>&#x003ba;</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr columnalign="left"><mml:mtd columnalign="left"><mml:mrow/></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>=</mml:mo><mml:mspace width=".33em"/><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003a6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>7</label></disp-formula>
where <italic>f</italic><sub>&#x003b8;</sub>(<italic>t</italic>, <italic>x</italic>) is the distance to the current evidence, <italic>x</italic>, from the boundary and &#x003a6;(&#x000b7;|<italic>x</italic>, &#x003c3;<sub><italic>d</italic></sub><sup>2</sup><italic>t</italic>) is the cumulative Gaussian with mean <italic>x</italic> and variance &#x003c3;<sub><italic>d</italic></sub><sup>2</sup><italic>t</italic>. The boundary &#x003b8; is parameterised by it&#x02019;s slope, <italic>m</italic>, and intercept, <italic>c</italic>. Both of these are free parameters of the model. Similarly, the probability of <italic>wait</italic>ing at (<italic>t</italic>,<italic>x</italic>) is given by &#x003a6;(<italic>f</italic><sub>&#x003b8;(<italic>t</italic>, <italic>x</italic>)</sub>|<italic>x</italic>, &#x003c3;<sub><italic>d</italic></sub><sup>2</sup><italic>t</italic>). If <mml:math id="math26"><mml:mrow><mml:msup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math> is the set of all wait observations, {(<italic>t</italic><sub>1</sub><sup><italic>wait</italic></sup>, <italic>x</italic><sub>1</sub><sup><italic>wait</italic></sup>), . . . , (<italic>t<sub>n</sub><sup>wait</sup></italic>, <italic>x<sub>n</sub><sup>wait</sup></italic>)}, and <mml:math id="math27"><mml:mrow><mml:msup><mml:mi mathvariant="script">D</mml:mi><mml:mrow><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math> is the set of all go observations, {(<italic>t</italic><sub>1</sub><sup><italic>go</italic></sup>, <italic>x</italic><sub>1</sub><sup><italic>go</italic></sup>), . . . , (<italic>t<sub>m</sub><sup>go</sup></italic>, <italic>x<sub>m</sub><sup>go</sup></italic>)}, then the likelihood of all observations is given by
<disp-formula id="eqn8"><alternatives><graphic xlink:href="xge_146_6_776_eqn8a.jpg" id="eqn8a"/><mml:math id="M8"><mml:mrow><mml:mi>L</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi mathvariant="script">D</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:mi>c</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msub><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:munder><mml:mrow><mml:mo>&#x0220f;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003a6;</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mrow></mml:mstyle><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x000d7;</mml:mo><mml:mstyle displaystyle="true"><mml:mrow><mml:munder><mml:mrow><mml:mo>&#x0220f;</mml:mo></mml:mrow><mml:mrow><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x02208;</mml:mo><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:munder><mml:mi>&#x003a6;</mml:mi></mml:mrow></mml:mstyle><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>f</mml:mi></mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:mi>t</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo stretchy="false">|</mml:mo><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msubsup><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:msubsup><mml:mi>t</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:math></alternatives><label>8</label></disp-formula>
where <mml:math id="math28"><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow></mml:math> includes both <mml:math id="math29"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mrow><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math> and <mml:math id="math30"><mml:mrow><mml:msup><mml:mrow><mml:mi mathvariant="script">D</mml:mi></mml:mrow><mml:mrow><mml:mi>g</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msup></mml:mrow></mml:math> decisions. We obtained estimates, <italic>&#x0006d;&#x00302;</italic>, <italic>&#x00109;</italic> and <mml:math id="math31"><mml:mrow><mml:msub><mml:mrow><mml:mover><mml:mrow><mml:mi>&#x003c3;</mml:mi></mml:mrow><mml:mrow><mml:mo>^</mml:mo></mml:mrow></mml:mover></mml:mrow><mml:mrow><mml:mi>d</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math> that maximized the likelihood function given in <xref ref-type="disp-formula" id="eqnc8-1" rid="eqn8">Equation 8</xref>.<xref ref-type="fn" rid="fn8"><sup>8</sup></xref></p></sec><sec id="s30"><title>Evaluation of Estimation Methods</title><p>The panel on the top-left of <xref ref-type="fig" id="fgc13-2" rid="fig13">Figure B1</xref> compares the true and estimated difference in slopes when decisions were generated using the noisy accumulation model (<xref ref-type="disp-formula" id="eqnc5-2" rid="eqn5">Equation 5</xref>) and estimated using the logistic regression model (<xref ref-type="disp-formula" id="eqnc2-6" rid="eqn2">Equations 2</xref> and <xref ref-type="disp-formula" id="eqnc3-4" rid="eqn3">3</xref>). The estimated difference in slopes is not equal to the true difference and the deviation from truth does depend on the noise in the accumulation process, &#x003c3;<sub><italic>V</italic></sub>; simulations showed that the difference approaches zero as &#x003c3;<sub><italic>V</italic></sub> approaches zero. Moreover, the estimated difference is approximately proportional to the true difference, so that if statistical test, such as the t-test, is valid on the true difference it will also be valid on the estimated difference.</p><p>The top-right panel in <xref ref-type="fig" id="fgc13-3" rid="fig13">Figure B1</xref> compares the true and estimated differences in slopes, when decision were again generated using the noisy accumulation model (<xref ref-type="disp-formula" id="eqnc5-3" rid="eqn5">Equation 5</xref>) and also estimated assuming a noisy accumulation to boundary (<xref ref-type="disp-formula" id="eqnc8-2" rid="eqn8">Equation 8</xref>). It can be seen that the difference in slopes estimated using this method is fairly similar to that estimated using the logistic regression model. The estimated difference is approximately proportional to the true difference and, like the estimates in top-left panel, these estimates also contains a deviation that depends on the diffusion parameter used to generate the data, &#x003c3;<sub><italic>V</italic></sub>. Simulations also showed (not shown in <xref ref-type="fig" id="fgc13-4" rid="fig13">Figure B1</xref>) that, while the difference in slopes using this method was similar to that using the logistic regression method, this method overestimated the slopes when true slope was zero&#x02014;that is, when bounds are in fact flat, it estimates them to be increasing, which is not the case with the logistic regression method used in this study.</p><p>The bottom-left panel shows that the difference in slopes estimated using the logistic regression model (<xref ref-type="disp-formula" id="eqnc2-7" rid="eqn2">Equations 2</xref> and <xref ref-type="disp-formula" id="eqnc3-5" rid="eqn3">3</xref>) are highly correlated with the true differences when data is simulated using the stochastic boundary model (<xref ref-type="disp-formula" id="eqnc6-1" rid="eqn6">Equation 6</xref>). This is not surprising since this method of generating the data inverts the logistic regression model. In contrast, the bottom-right panel shows that when slopes are estimated using the noisy accumulation process (<xref ref-type="disp-formula" id="eqnc8-3" rid="eqn8">Equation 8</xref>), the correlation between the true and estimated difference in slopes decreases and there is a bias in the estimated difference albeit, again, multiplicative.</p><p>To sum up, difference in slopes estimated using the logistic regression model, were at least as good as estimates using the maximum likelihood method and the logistic regression model was, in fact, robust to misspecification of the model that generates the data. Furthermore, estimated differences were linearly related to true differences, which meant that it was valid to use the t-test on the estimated differences for inferring whether there was a difference in the true slopes of single- and mixed-difficulty games.</p></sec></app><app id="C"><label>C</label><title>Variable Drift Rate and Information Loss</title><sec id="s31"><p>We have analyzed the data based on the evidence and time of each wait and go decision, assuming that participants accumulated every cue provided to them and the internal drift rate was the same in every trial. In this appendix, we verified whether our inferences about difference in slopes would be valid if some evidence was lost during accumulation and the drift rate varied from trial-to-trial.</p><p>Consider a variable drift rate first. Even though our experiments use the expanded-judgement paradigm where the drift of the stimulus is controlled by the experimenter, it is possible that the internal drift rate varies from trial-to-trial due to fluctuations in attention and cognitive resources. Fluctuations in the effect of stimulation have been modeled as a random variable since Thurstone&#x02019;s comparative and categorical judgement models (<xref rid="c80" ref-type="bibr" id="cr80-1">Thurstone, 1927a</xref>, <xref rid="c81" ref-type="bibr" id="cr81-1">1927b</xref>) and form an integral part of signal detection theory (<xref rid="c78" ref-type="bibr" id="cr78-2">Tanner &#x00026; Swets, 1954</xref>; <xref rid="c26" ref-type="bibr" id="cr26-1">Green &#x00026; Swets, 1966</xref>) and sequential sampling models (<xref rid="c59" ref-type="bibr" id="cr59-5">Ratcliff, 1978</xref>; <xref rid="c65" ref-type="bibr" id="cr65-6">Ratcliff &#x00026; Smith, 2004</xref>).</p><p>To check how variability in drift rate affected our results, we simulated decisions using a rise-to-threshold model both with and without variability in drift and estimated the slopes in each case using the logistic regression method (<xref ref-type="disp-formula" id="eqnc3-6" rid="eqn3">Equation 3</xref>). A comparison between the estimated slopes showed us how a variability in drift affects our estimate.</p><p>Decisions were simulated using the following method. Stimuli were generated using a Bernoulli process (<xref ref-type="disp-formula" id="eqnc1-2" rid="eqn1">Equation 1</xref>), with drift &#x003f5; = &#x003f5;<sub>0</sub> + &#x003bd;, where &#x003f5;<sub>0</sub> was a constant drift parameter based on the type of game (e.g., &#x003f5;<sub>0</sub> = 0.22 for easy games) and <mml:math id="math32"><mml:mrow><mml:mi>&#x003bd;</mml:mi><mml:mo>&#x0223c;</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mrow><mml:mi>d</mml:mi><mml:mi>r</mml:mi><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> was a random variable drawn independently for every trial. The overall drift, &#x003f5;, was bound between 0 and <mml:math id="math33"><mml:mrow><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>2</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle></mml:mrow></mml:math>. These stimuli were then integrated in a noisy decision-variable, <italic>V</italic>:
<disp-formula id="eqn9"><alternatives><graphic xlink:href="xge_146_6_776_eqn9a.jpg" id="eqn9a"/><mml:math id="M9"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mi>X</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003be;</mml:mi></mml:mrow></mml:math></alternatives><label>9</label></disp-formula>
where <mml:math id="math34"><mml:mrow><mml:mi>&#x003be;</mml:mi><mml:mo>&#x0223c;</mml:mo><mml:mi mathvariant="script">N</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width=".33em"/><mml:msubsup><mml:mi>&#x003c3;</mml:mi><mml:mi>V</mml:mi><mml:mn>2</mml:mn></mml:msubsup><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> is a zero-mean Gaussian noise with variance &#x003c3;<sub><italic>V</italic></sub><sup>2</sup>. This integration process generated a random walk, (<italic>X</italic><sub>1</sub>, . . . , <italic>X</italic><sub>t</sub>) and terminated when the decision variable, <italic>V</italic><sub><italic>t</italic></sub>, crossed a known boundary. We simulated random walks using 200 different values of boundary (standing for 200 simulated participants), with varying slopes and intercepts, generating 1,000 random walks for each boundary (in both easy and mixed conditions).</p><p><xref ref-type="fig" id="fgc14-1" rid="fig14">Figure C1</xref> (Panel a) shows a comparison between true and estimated slopes in easy games when &#x003c3;<sub><italic>drift</italic></sub> = 0, i.e. there was no trial-to-trial variability in drift, as well as when &#x003c3;<sub><italic>drift</italic></sub> = 0.35, that is, there was a large trial-to-trial drift variability. When there was no trial-to-trial variability in drift, the estimated slopes were close to true slopes. In the presence of drift variability, the magnitude of slopes was systematically overestimated. However, constant slopes were still estimated as constant and increasing or decreasing slopes were also estimated as increasing or decreasing, respectively. Thus, irrespective of trial-to-trial variability in drift rates, a negative estimate of slope indicated that the true slope was also negative.<xref ref-type="fig-anchor" rid="fig14"/></p><p><xref ref-type="fig" id="fgc14-2" rid="fig14">Figure C1(b)</xref> shows a comparison between true and estimated difference in slopes for &#x003c3;<sub><italic>drift</italic></sub> = 0 and &#x003c3;<sub><italic>drift</italic></sub> = 0.35. In the presence of drift variability, the bias in estimation of slopes results in a bias in estimation of difference in slopes, with the magnitude of estimated difference being larger than true difference. The estimated difference in slopes is approximately proportional to the true difference for both &#x003c3;<sub><italic>drift</italic></sub> = 0 and &#x003c3;<sub><italic>drift</italic></sub> = 0.35. Therefore, when there was no difference in true slopes, there was also no difference in estimated slopes. Similarly, when true difference in slopes was positive (negative), the estimated difference in slopes was also positive (negative). Therefore, even when there was trial-to-trial variability in drift, the estimated difference in slopes indicated a difference in true slopes.</p><p>We also checked whether our inferences were robust to loss of information in the integrative decision process. To do this, we simulated data from the binomial loss model (<xref rid="c73" ref-type="bibr" id="cr73-3">Smith &#x00026; Vickers, 1989</xref>), where observations &#x003b4;<italic>X</italic> available to the decision maker are only accumulated with some fixed probability <italic>p</italic><sub><italic>a</italic></sub>, otherwise they are lost:
<disp-formula id="eqn10"><alternatives><graphic xlink:href="xge_146_6_776_eqn10a.jpg" id="eqn10a"/><mml:math id="M10"><mml:mrow><mml:msub><mml:mi>V</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b4;</mml:mi><mml:mi>X</mml:mi><mml:mo>+</mml:mo><mml:mi>&#x003be;</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mtext>with&#x02009;probability</mml:mtext></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:msub><mml:mi>V</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003be;</mml:mi></mml:mtd><mml:mtd columnalign="left"><mml:mtext>with&#x02009;probability</mml:mtext></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>a</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:mrow></mml:math></alternatives><label>10</label></disp-formula>
where <italic>V<sub>t</sub></italic> and &#x003be; are defined in the same way as <xref ref-type="disp-formula" id="eqnc9-1" rid="eqn9">Equation 9</xref>. Figure C2(a) compares the estimates of slopes during easy games for 200 simulated participants from the information loss model (<xref ref-type="disp-formula" id="eqnc10-1" rid="eqn10">Equation 10</xref>, <italic>p<sub>a</sub></italic> = 0.7) with 200 simulated participants from the rise-to-threshold model without any information loss (<xref ref-type="disp-formula" id="eqnc9-2" rid="eqn9">Equation 9</xref>). Introducing information loss resulted in some systematic biases: estimated slopes were, in general, larger and shifted in the positive direction so that constant slopes were estimated to have a small positive value and slightly negative slopes were estimated to be constant, whereas large negative and positive slopes were estimated to have a larger value than the true slopes. Note the direction of this bias&#x02014;when slopes were estimated to be negative (as in the majority of experiments in this study), the true slopes were also negative while when they were estimated to be positive, they could in fact be constant. This makes sense: the total information loss will increase over time and since the drift is positive, decisions made at later points of time will seem to be at higher levels of evidence than internally integrated.</p><p><xref ref-type="fig" id="fgc15-1" rid="fig15">Figure C2(b)</xref> compares the true and estimated difference in slopes between easy and mixed games. When information was lost, the estimate of slopes in each type of game was biased, therefore, the estimate for difference in slopes was also biased. However, the estimated difference in slopes was still approximately proportional to true difference in slopes, passing through the origin so that the estimated difference in slopes was proportional to the true difference in slopes even when data were simulated from the binomial loss model.<xref ref-type="fig-anchor" rid="fig15"/></p></sec></app><app id="D"><label>D</label><title>Model Selection and Recovery</title><sec id="s32"><p>A key finding of Experiments 1 and 2 is that participants seem to decrease their decision boundaries with time, especially in the mixed-difficulty condition. To check the robustness of this result, we compared the logistic regression model presented in the main text (<xref ref-type="disp-formula" id="eqnc2-8" rid="eqn2">Equation 2</xref>), which uses both evidence and time to predict the probability of <italic>go</italic>, with a simpler model that uses only evidence to predict this probability:
<disp-formula id="eqn11"><alternatives><graphic xlink:href="xge_146_6_776_eqn11a.jpg" id="eqn11a"/><mml:math id="M11"><mml:mrow><mml:mi>log</mml:mi><mml:mo>&#x02061;</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi>g</mml:mi><mml:mi>o</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:mi>w</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:mfrac><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mn>0</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003b2;</mml:mi><mml:mi>X</mml:mi></mml:msub><mml:mo>&#x02217;</mml:mo><mml:mi>X</mml:mi></mml:mrow></mml:math></alternatives><label>11</label></disp-formula>
where &#x003b2;<sub><italic>X</italic></sub> is the regression coefficient for evidence and &#x003b2;<sub>0</sub> is the intercept. Note that this simpler model is equivalent to assuming that decision boundaries do not change with time as only evidence predicts whether a participant chooses the action wait or go during a trial. We inferred the preferred model for each participant and condition by computing the Bayesian information criterion (BIC) for each model (<xref rid="c70" ref-type="bibr" id="cr70-2">Schwarz, 1978</xref>; <xref rid="c89" ref-type="bibr" id="cr89-2">Wagenmakers, 2007</xref>). Following <xref rid="c94" ref-type="bibr" id="cr94-1">Wasserman (2000)</xref> and <xref rid="c30" ref-type="bibr" id="cr30-9">Hawkins et al. (2015)</xref>, we approximated the posterior probability for a participant using each model under the assumption that both models are a priori equally likely,
<disp-formula id="eqn12"><alternatives><graphic xlink:href="xge_146_6_776_eqn12a.jpg" id="eqn12a"/><mml:math id="M12"><mml:mrow><mml:msub><mml:mi>P</mml:mi><mml:mrow><mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">|</mml:mo><mml:mi>D</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>a</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mstyle displaystyle="true"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>m</mml:mi></mml:msubsup><mml:mrow><mml:mi>e</mml:mi><mml:mi>x</mml:mi><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:mi>B</mml:mi><mml:mi>I</mml:mi><mml:mi>C</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:msub><mml:mi>M</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo stretchy="false">)</mml:mo><mml:mo>)</mml:mo></mml:mrow></mml:mstyle></mml:mrow></mml:mfrac></mml:mrow></mml:math></alternatives><label>12</label></disp-formula></p><p><xref ref-type="fig" id="fgc16-2" rid="fig16">Figure D1</xref> plots these posterior probabilities for data from both single-difficulty (left column) and mixed-difficulty conditions (right column) for each participant. Shaded (red) bars show the posterior model probability for the more complex model (using both evidence and time), while the while hatched bars show the complementary posterior probability for the simpler model (only on evidence).<xref ref-type="fig-anchor" rid="fig16"/></p><p>In agreement with the slopes estimated using the line of indifference (<xref ref-type="fig" id="fgc5-4" rid="fig5">Figures 5</xref> and <xref ref-type="fig" id="fgc8-6" rid="fig8">8</xref>), we found that the model using both evidence and time provided the best account of the data in Experiments 1, 2a, and 2b. This was especially true for the mixed-difficulty games. Note that, in spite of the fact that the BIC rewards lower model complexity, the simpler model of <xref ref-type="disp-formula" id="eqnc11-1" rid="eqn11">Equation 11</xref> provided the best account for only 5 participants during the mixed-difficulty trials during these experiments. Data from most other participants was better accounted for by the model using time as an additional predictor variable.</p><p>In contrast, during Experiments 2c and 2d, where the inter-trial intervals were same for correct and incorrect decisions and reward landscapes were flatter (<xref ref-type="fig" id="fgc9-5" rid="fig9">Figure 9</xref>), support for the two models was much more mixed. Finally, during Experiment 3, where the reward landscape favored constant (or slightly increasing) decision boundaries with time (<xref ref-type="fig" id="fgc10-5" rid="fig10">Figures 10</xref> and <xref ref-type="fig" id="fgc11-3" rid="fig11">11</xref>), the simpler model, using only evidence to predict probability of going, provided the best account of the data, especially in the mixed-difficulty condition.</p><p>We checked the validity of this model selection procedure using a model recovery analysis. We simulated decisions using two noisy accumulation-to-threshold models (see <xref ref-type="disp-formula" id="eqnc5-4" rid="eqn5">Equation 5</xref> in <xref ref-type="app" id="apcB-2" rid="B">Appendix B</xref>). The first model used a constant threshold, while the second one used a threshold that decreased linearly with time. For each simulated participant, we generated 100 random walks with drifts drawn, with uniform probability, from the set &#x003f5; &#x02208; {0.22, 0}. Thus, these simulated random walks approximately matched the data collected and conditions for mixed-difficulty trials in Experiment 2.</p><p>We then fit the two logistic regression models discussed above, one using only evidence as a predictor (<xref ref-type="disp-formula" id="eqnc11-2" rid="eqn11">Equation 11</xref>) and the other using evidence as well as time (<xref ref-type="disp-formula" id="eqnc2-9" rid="eqn2">Equation 2</xref>), to each of these simulated participants and computed the BIC values for each fit. Each plot in <xref ref-type="fig" id="fgc17-1" rid="fig17">Figure D2</xref> shows the distribution of difference in BIC values for 400 simulated participants, 200 of which are simulated using the fixed boundary model (hatched distribution), whereas the remaining 200 are simulated using the decreasing boundary model (shaded distribution). It can be seen from these plots that the decisions generated using a fixed boundary model are better fit (lower BIC<sub><italic>fix</italic></sub>) by the logistic regression model using only evidence as the predictor, while the decisions generated using a decreasing boundary model are better fit (lower BIC<sub><italic>var</italic></sub>) by the logistic regression model using both evidence as time as predictors. Furthermore, when the slope of the decision boundaries is increased for the simulated decisions, the difference in BIC values increases (compare the shaded region in the three plots), showing that the BIC of the time-varying bounds model decreases with increase in the slope used to generate the decisions.<xref ref-type="fig-anchor" rid="fig17"/></p></sec></app></app-group></back><floats-group><table-wrap id="tbl1" position="float" orientation="portrait"><label>Table 1</label><caption><title>Values of Parameters Used During the Game</title></caption><alternatives><graphic id="tbl1a" xlink:href="xge_146_6_776_tbl1a"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/></colgroup><thead><tr valign="bottom"><th rowspan="1" colspan="1">Parameter name</th><th rowspan="1" colspan="1">Value</th></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">Interstimulus interval (ISI)</td><td rowspan="1" colspan="1">200 ms</td></tr><tr valign="top"><td rowspan="1" colspan="1">Intertrial interval (ITI), correct (<italic>ISI</italic> &#x000d7; <italic>D<sub>C</sub></italic>)</td><td rowspan="1" colspan="1">3 s</td></tr><tr valign="top"><td rowspan="1" colspan="1">ITI, incorrect (<italic>ISI</italic> &#x000d7; <italic>D<sub>I</sub></italic>)</td><td rowspan="1" colspan="1">10 s</td></tr><tr valign="top"><td rowspan="1" colspan="1">Reward</td><td rowspan="1" colspan="1">(approx 2 cents)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Drift for easy condition (&#x003f5;<sub><italic>e</italic></sub>)</td><td rowspan="1" colspan="1">.20</td></tr><tr valign="top"><td rowspan="1" colspan="1">Drift for difficult condition (&#x003f5;<sub><italic>d</italic></sub>)</td><td rowspan="1" colspan="1">0</td></tr><tr valign="top"><td rowspan="1" colspan="1">Block duration, training</td><td rowspan="1" colspan="1">150 s</td></tr><tr valign="top"><td rowspan="1" colspan="1">Block duration, testing, easy</td><td rowspan="1" colspan="1">240 s</td></tr><tr valign="top"><td rowspan="1" colspan="1">Block duration, testing, difficult</td><td rowspan="1" colspan="1">300 s</td></tr><tr valign="top"><td rowspan="1" colspan="1">Block duration, testing, mixed</td><td rowspan="1" colspan="1">300 s</td></tr></tbody></table></alternatives></table-wrap><table-wrap id="tbl2" position="float" orientation="portrait"><label>Table 2</label><caption><title>Values of Parameters for Experiment 2</title></caption><alternatives><graphic id="tbl2a" xlink:href="xge_146_6_776_tbl2a"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/><col span="1"/></colgroup><thead><tr valign="bottom"><th colspan="2" rowspan="1">Parameter name</th><th rowspan="1" colspan="1">Value</th></tr></thead><tfoot valign="top"><tr><td colspan="3" rowspan="1"><italic>Note</italic>.&#x02003;The parameters that are common to all four subexperiments are listed at the top. Each of the four subexperiments has a different combination of interstimulus and intertrial intervals, the values of which are listed at the bottom. ISI = interstimulus interval.</td></tr></tfoot><tbody><tr valign="top"><td colspan="2" rowspan="1">Drift for easy condition (&#x003f5;<sub><italic>e</italic></sub>)</td><td rowspan="1" colspan="1">.22</td></tr><tr valign="top"><td colspan="2" rowspan="1">Drift for difficult condition (&#x003f5;<sub><italic>d</italic></sub>)</td><td rowspan="1" colspan="1">0</td></tr><tr valign="top"><td colspan="2" rowspan="1">Reward</td><td rowspan="1" colspan="1">(approx 2 cents)</td></tr><tr valign="top"><td rowspan="1" colspan="1"/><td colspan="2" rowspan="1"><italic>D<sub>I</sub></italic> = <italic>ISI</italic>&#x000d7;50</td></tr><tr valign="top"><td rowspan="1" colspan="1">ISI</td><td rowspan="1" colspan="1"><mml:math id="math35"><mml:mrow><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>C</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mstyle scriptlevel="1"><mml:mrow><mml:mfrac><mml:mrow><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>3</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mstyle><mml:msub><mml:mrow><mml:mi>D</mml:mi></mml:mrow><mml:mrow><mml:mi>I</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></td><td rowspan="1" colspan="1"><italic>D</italic><sub><italic>C</italic></sub> = <italic>D</italic><sub><italic>I</italic></sub></td></tr><tr valign="top"><td rowspan="1" colspan="1">200 msec</td><td rowspan="1" colspan="1">Experiment 2a</td><td rowspan="1" colspan="1">Experiment 2c</td></tr><tr valign="top"><td rowspan="1" colspan="1">50 msec</td><td rowspan="1" colspan="1">Experiment 2b</td><td rowspan="1" colspan="1">Experiment 2d</td></tr></tbody></table></alternatives></table-wrap><table-wrap id="tbl3" position="float" orientation="portrait"><label>Table 3</label><caption><title>Values of Parameters Used During Experiment 3</title></caption><alternatives><graphic id="tbl3a" xlink:href="xge_146_6_776_tbl3a"/><table frame="hsides" rules="groups"><colgroup span="1"><col span="1"/><col span="1"/></colgroup><thead><tr valign="bottom"><th rowspan="1" colspan="1">Parameter name</th><th rowspan="1" colspan="1">Value</th></tr></thead><tbody><tr valign="top"><td rowspan="1" colspan="1">Drift for easy condition (&#x003f5;<sub><italic>e</italic></sub>)</td><td rowspan="1" colspan="1">.40</td></tr><tr valign="top"><td rowspan="1" colspan="1">Drift for difficult condition (&#x003f5;<sub><italic>d</italic></sub>)</td><td rowspan="1" colspan="1">.10</td></tr><tr valign="top"><td rowspan="1" colspan="1">Reward</td><td rowspan="1" colspan="1">(approx 2 cents)</td></tr><tr valign="top"><td rowspan="1" colspan="1">Intertrial interval, correct</td><td rowspan="1" colspan="1">3.5 s</td></tr><tr valign="top"><td rowspan="1" colspan="1">Intertrial interval, incorrect</td><td rowspan="1" colspan="1">3.5 s</td></tr><tr valign="top"><td rowspan="1" colspan="1">Interstimulus interval</td><td rowspan="1" colspan="1">50 ms</td></tr></tbody></table></alternatives></table-wrap><fig id="fig1" position="float"><label>Figure 1</label><caption><p>Evidence accumulation and decision making as a Markov decision process: States are shown by circles, transitions are shown by arrows, and actions are shown by color of the circles. The solid (blue) line labeled &#x003b8; indicates a hypothetical decision boundary. The policy that corresponds to the boundary is indicated by the color of the states. Black circles indicate the action go, whereas gray circles indicate wait. Dashed lines with arrows indicate transitions on go, whereas solid lines with arrows indicate transitions on wait. The rewarded and unrewarded states are shown as <bold>C</bold> and <bold>I</bold>, respectively (for <italic>correct</italic> and <italic>incorrect</italic>). See the online article for the color version of this figure.</p></caption><graphic id="fig1a" xlink:href="xge_146_6_776_fig1a"/></fig><fig id="fig2" position="float"><label>Figure 2</label><caption><p>Optimal policies for single and mixed-difficulty tasks. Black squares indicate states of the MDP where the optimal action is to go&#x02014;that is, choose an alternative&#x02014;whereas gray squares indicate states where the optimal action is to wait&#x02014;that is, collect more evidence. In each row, the two panels on the left show optimal policies for single-difficulty tasks with two different levels of difficulty and the right-most panel shows optimal policy for mixed-difficulty task obtained by mixing the difficulties is the two left-hand panels. The intertrial intervals (ITIs) were <italic>D</italic><sub><italic>C</italic></sub> = <italic>D</italic><sub><italic>I</italic></sub> = 70 for the top row (Panels a through c) and <italic>D</italic><sub><italic>C</italic></sub> = <italic>D</italic><sub><italic>I</italic></sub> = 50 for the bottom row (Panels d through f).</p></caption><graphic id="fig2a" xlink:href="xge_146_6_776_fig2a"/></fig><fig id="fig3" position="float"><label>Figure 3</label><caption><p>Two screenshots of the display during the experiment. The left panel shows the display during the evidence-accumulation phase of a trial. Participants chose whether Pacman goes up or down after seeing a sequence of cues (arrows) pointing up or down. The elephant next to the arrow indicates that this is an easy game, so the arrow points to the reward-holding path with probability 0.70. The right panel shows a screenshot during the intertrial interval (ITI). The participant has chosen the lower path and can now see that this was the correct (rewarded) decision. See the online article for the color version of this figure.</p></caption><graphic id="fig3a" xlink:href="xge_146_6_776_fig3a"/></fig><fig id="fig4" position="float"><label>Figure 4</label><caption><p>The decisions made by a subject during Experiment 1 and the inferred boundaries based on these decisions. Each scatter-plot shows the values of evidence and time where the subject made decisions during a particular game (only easy trials considered during mixed game). These values have been slightly jittered for visualization. The heat-map shows the <mml:math id="math36"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> for each <italic>x</italic> and <italic>t</italic> inferred using logistic regression. The solid line shows a &#x0201c;line of indifference&#x0201d; where <mml:math id="math37"><mml:mrow><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>G</mml:mi><mml:mi>o</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="double-struck">P</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>W</mml:mi><mml:mi>a</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mo stretchy="false">|</mml:mo><mml:msub><mml:mi>X</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mo stretchy="false">)</mml:mo></mml:mrow></mml:math> and serves as a proxy for the subject&#x02019;s boundary (see <xref ref-type="app" id="apcB-3" rid="B">Appendix B</xref>). See the online article for the color version of this figure.</p></caption><graphic id="fig4a" xlink:href="xge_146_6_776_fig4a"/></fig><fig id="fig5" position="float"><label>Figure 5</label><caption><p>Each circle (black) compares the estimated slope in easy and mixed games for 1 participant. Circles below the dashed line were participants who had a larger gradient of the inferred boundary during the mixed games as compared to the easy games. Error bars indicate the 0.95 percentile bootstrapped confidence intervals for the estimated slopes. Crosses (red) show 24 simulated participants&#x02014;decisions were simulated using a rise-to-threshold model with optimal boundaries shown in <xref ref-type="fig" id="fgc2-24" rid="fig2">Figures 2d</xref> and <xref ref-type="fig" id="fgc2-25" rid="fig2">2f</xref>. See the online article for the color version of this figure.</p></caption><graphic id="fig5a" xlink:href="xge_146_6_776_fig5a"/></fig><fig id="fig6" position="float"><label>Figure 6</label><caption><p>The reward rates for different decision boundaries. In each panel, the slope and intercept determine a linear boundary. The actions of all states below the boundary are set to wait and all states above are set to go. The heat-map in each panel shows the reward rate for each threshold. The circles show the inferred boundaries used by the participants in Experiment 1.</p></caption><graphic id="fig6a" xlink:href="xge_146_6_776_fig6a"/></fig><fig id="fig7" position="float"><label>Figure 7</label><caption><p>An illustration of the paradigm for Experiments 2a through 2d. During each trial, participants chose left or right based on a sequence of cues. Each cue was a Gabor pattern displayed (for a fifth of interstimulus interval [ISI]) in one of four possible locations, equidistant from the fixation cross. If the decision was correct (as in this example), a money bag was displayed on the chosen side of the fixation cross and the participant waited for the duration <italic>D</italic><sub><italic>C</italic></sub> before starting the next trial. If the decision was incorrect, no money bag was displayed and the participant waited for the duration <italic>D</italic><sub><italic>I</italic></sub> before starting the next trial. RT = Reaction time. See the online article for the color version of this figure.</p></caption><graphic id="fig7a" xlink:href="xge_146_6_776_fig7a"/></fig><fig id="fig8" position="float"><label>Figure 8</label><caption><p>Slopes (in degrees) of estimated lines of indifference in easy versus mixed games in four experiments. The dashed line shows the curve for equal slope in easy and mixed games. Each circle (black) shows the estimated slopes for one participant. Error bars show 0.95 percentile bootstrapped confidence intervals. Crosses (red) show the estimated slopes for 24 simulated participants&#x02014;decisions were simulated using a rise-to-threshold model with boundaries given by the optimal policies computed as described by (<xref rid="c46" ref-type="bibr" id="cr46-9">Malhotra et al., 2017</xref>). See the online article for the color version of this figure.</p></caption><graphic id="fig8a" xlink:href="xge_146_6_776_fig8a"/></fig><fig id="fig9" position="float"><label>Figure 9</label><caption><p>Reward rate for Experiments 2a through 2d. Each heat-map in the first two rows shows the &#x0201c;landscape&#x0201d; of reward rate in policy space and dots show estimated policies adopted by participants in easy games. The bottom row show profiles sliced through the (normalized) reward-rate landscape at a particular intercept. Shaded regions show profiles for easy games, whereas hatched regions show profiles for mixed games.</p></caption><graphic id="fig9a" xlink:href="xge_146_6_776_fig9a"/></fig><fig id="fig10" position="float"><label>Figure 10</label><caption><p>Slopes of estimated lines of indifference in Experiment 3. The panel on the left compares slopes for the easy trials during mixed games with slopes for all trials during easy games, whereas the panel on the right compares slopes for the difficult trials in mixed games with slopes for all trials during difficult games. In each panel, the solid vertical and horizontal lines show lines of zero slope (flat threshold), and the dashed line shows the curve for equal slopes in the two types of games. Each circle shows the estimated slopes for one participant and crosses show estimated slopes from simulated optimal participants. See the online article for the color version of this figure.</p></caption><graphic id="fig10a" xlink:href="xge_146_6_776_fig10a"/></fig><fig id="fig11" position="float"><label>Figure 11</label><caption><p>Reward rate during difficult and mixed games during Experiment 3. Each heat-map shows the &#x0201c;landscape&#x0201d; of reward per unit time in policy space. Lighter colors show higher reward. Each circle shows the slope and intercept of the estimated line of indifference for a participant. The right-most panel compares the reward landscape in difficult and mixed games at a particular intercept.</p></caption><graphic id="fig11a" xlink:href="xge_146_6_776_fig11a"/></fig><fig id="fig12" position="float"><label>Figure A1</label><caption><p>The plot shows the proportion of trials at each time step before the response (for a particular participant and condition) that are in the same direction as the response. The dashed horizontal line represents a threshold on this proportion used to compute the nondecision time. The dashed vertical line shows the last time-step where this proportion was below the threshold.</p></caption><graphic id="fig12a" xlink:href="xge_146_6_776_fig12a"/></fig><fig id="fig13" position="float"><label>Figure B1</label><caption><p>True versus estimated difference in slopes for 200 simulations. Each circle represents one participant simulated using either a rise-to-threshold model (first row) or a probabilistic boundary model (second row). The figures in the left column compare true difference with the difference estimated using logistic regression (as described in Section &#x02018;Experiment 1&#x02019;), whereas the panels in the right column make the same comparison but slopes are estimated by fitting a rise-to-threshold model.</p></caption><graphic id="fig13a" xlink:href="xge_146_6_776_fig13a"/></fig><fig id="fig14" position="float"><label>Figure C1</label><caption><p>The effect of trial-to-trial variability in drift on estimation of slopes of decision boundary. Panel (a) shows a comparison of true and estimated slopes in a single-difficulty task (&#x003f5; = 0.22). Panel (b) shows a comparison of true and estimated difference in slope during an easy (&#x003f5; = 0.22) and mixed (&#x003f5; = 0.22/0) task. In both panels, each dot represents a participant simulated using a rise-to-threshold model with no trial-to-trial drift and crosses represent participants simulated using a rise-to-threshold model with a large trial-to-trial variability in drift (&#x003c3;<sub><italic>drift</italic></sub> = 0.35). See the online article for the color version of this figure.</p></caption><graphic id="fig14a" xlink:href="xge_146_6_776_fig14a"/></fig><fig id="fig15" position="float"><label>Figure C2</label><caption><p>The effect of information loss on estimation of slopes of decision boundary. Panel (a) shows a comparison of true and estimated slopes in a Single-difficulty task (&#x003f5; = 0.22). Panel (b) shows a comparison of true and estimated difference in slope during an Easy (&#x003f5; = 0.22) and Mixed (&#x003f5; = 0.22/0) task. In both panels, each dot represents a participant simulated using a rise-to-threshold model without any information loss and crosses represent a participant simulated using a binomial loss model (<italic>p<sub>a</sub></italic> = 0.7). See the online article for the color version of this figure.</p></caption><graphic id="fig15a" xlink:href="xge_146_6_776_fig15a"/></fig><fig id="fig16" position="float"><label>Figure D1</label><caption><p>Each row shows the posterior model probability for the logistic regression models using only evidence as the predictor (hatched) and using both time and evidence as predictors (shaded) for all participants in an experiment. The left and right-hand columns show these posterior probabilities during the single- and mixed-difficulty conditions, respectively. See the online article for the color version of this figure.</p></caption><graphic id="fig16a" xlink:href="xge_146_6_776_fig16a"/></fig><fig id="fig17" position="float"><label>Figure D2</label><caption><p>Each plot shows the distribution of difference in Bayesian information criterion (BIC) values for fixed boundary model (only evidence used as predictor) and variable boundary model (both evidence and time used as predictors). Hatched distributions show this difference in BIC values when decisions are simulated using integration of evidence to a fixed boundary (inset, dashed line) and shaded distributions show the difference in BIC values when decisions are simulated from integration to a decreasing boundary (inset, solid line). Three different slopes are used for decreasing boundaries (a) 15 degrees, (b) 30 degrees, and (c) 60 degrees. See the online article for the color version of this figure.</p></caption><graphic id="fig17a" xlink:href="xge_146_6_776_fig17a"/></fig></floats-group></article>