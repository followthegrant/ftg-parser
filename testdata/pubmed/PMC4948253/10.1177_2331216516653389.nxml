<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Trends Hear</journal-id><journal-id journal-id-type="iso-abbrev">Trends Hear</journal-id><journal-id journal-id-type="publisher-id">TIA</journal-id><journal-id journal-id-type="hwp">sptia</journal-id><journal-title-group><journal-title>Trends in Hearing</journal-title></journal-title-group><issn pub-type="epub">2331-2165</issn><publisher><publisher-name>SAGE Publications</publisher-name><publisher-loc>Sage CA: Los Angeles, CA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">27317668</article-id><article-id pub-id-type="pmc">4948253</article-id><article-id pub-id-type="doi">10.1177/2331216516653389</article-id><article-id pub-id-type="publisher-id">10.1177_2331216516653389</article-id><article-categories><subj-group subj-group-type="heading"><subject>Original Articles</subject></subj-group></article-categories><title-group><article-title>Reducing Channel Interaction Through Cochlear Implant Programming May Improve Speech Perception</article-title><subtitle>Current Focusing and Channel Deactivation</subtitle></title-group><contrib-group><contrib contrib-type="author" corresp="yes"><name><surname>Bierer</surname><given-names>Julie A.</given-names></name><xref ref-type="aff" rid="aff1-2331216516653389">1</xref><xref ref-type="corresp" rid="corresp1-2331216516653389"/></contrib><contrib contrib-type="author"><name><surname>Litvak</surname><given-names>Leonid</given-names></name><xref ref-type="aff" rid="aff2-2331216516653389">2</xref></contrib></contrib-group><aff id="aff1-2331216516653389"><label>1</label>University of Washington, Seattle, WA, USA</aff><aff id="aff2-2331216516653389"><label>2</label>Advanced Bionics Corporation, Valencia, CA, USA</aff><author-notes><corresp id="corresp1-2331216516653389">Julie A. Bierer, Department of Speech and Hearing Sciences, University of Washington, Seattle, WA, USA. Email: <email>jbierer@u.washington.edu</email></corresp></author-notes><pub-date pub-type="epub"><day>17</day><month>6</month><year>2016</year></pub-date><pub-date pub-type="collection"><season>Jan-Dec</season><year>2016</year></pub-date><volume>20</volume><elocation-id>2331216516653389</elocation-id><history><date date-type="received"><day>18</day><month>3</month><year>2016</year></date><date date-type="rev-recd"><day>6</day><month>5</month><year>2016</year></date><date date-type="accepted"><day>6</day><month>5</month><year>2016</year></date></history><permissions><copyright-statement>&#x000a9; The Author(s) 2016</copyright-statement><copyright-year>2016</copyright-year><copyright-holder content-type="sage">SAGE Publications</copyright-holder><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/3.0/"><license-p>This article is distributed under the terms of the Creative Commons Attribution-NonCommercial 3.0 License (<ext-link ext-link-type="uri" xlink:href="http://www.creativecommons.org/licenses/by-nc/3.0/">http://www.creativecommons.org/licenses/by-nc/3.0/</ext-link>) which permits non-commercial use, reproduction and distribution of the work without further permission provided the original work is attributed as specified on the SAGE and Open Access page (<ext-link ext-link-type="uri" xlink:href="https://us.sagepub.com/en-us/nam/open-access-at-sage">https://us.sagepub.com/en-us/nam/open-access-at-sage</ext-link>).</license-p></license></permissions><abstract><p>Speech perception among cochlear implant (CI) listeners is highly variable. High degrees of channel interaction are associated with poorer speech understanding. Two methods for reducing channel interaction, focusing electrical fields, and deactivating subsets of channels were assessed by the change in vowel and consonant identification scores with different program settings. The main hypotheses were that (a) focused stimulation will improve phoneme recognition and (b) speech perception will improve when channels with high thresholds are deactivated. To select high-threshold channels for deactivation, subjects&#x02019; threshold profiles were processed to enhance the peaks and troughs, and then an exclusion or inclusion criterion based on the mean and standard deviation was used. Low-threshold channels were selected manually and matched in number and apex-to-base distribution. Nine ears in eight adult CI listeners with Advanced Bionics HiRes90k devices were tested with six experimental programs. Two, all-channel programs, (a) 14-channel partial tripolar (pTP) and (b) 14-channel monopolar (MP), and four variable-channel programs, derived from these two base programs, (c) pTP with high- and (d) low-threshold channels deactivated, and (e) MP with high- and (f) low-threshold channels deactivated, were created. Across subjects, performance was similar with pTP and MP programs. However, poorer performing subjects (scoring&#x02009;&#x0003c;&#x02009;62% correct on vowel identification) tended to perform better with the all-channel pTP than with the MP program (1&#x02009;&#x0003e;&#x02009;2). These same subjects showed slightly more benefit with the reduced channel MP programs (5 and 6). Subjective ratings were consistent with performance. These finding suggest that reducing channel interaction may benefit poorer performing CI listeners.</p></abstract><kwd-group><kwd>cochlear implant</kwd><kwd>electrode configuration</kwd><kwd>channel selection</kwd><kwd>phoneme perception</kwd><kwd>speech perception</kwd></kwd-group><custom-meta-group><custom-meta><meta-name>cover-date</meta-name><meta-value>January-December 2016</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec sec-type="intro" id="sec1-2331216516653389"><title>Introduction</title><p>Although cochlear implants (CIs) are highly successful neural prostheses, the speech perception outcomes are variable and can be unpredictable from listener to listener (e.g., <xref rid="bibr14-2331216516653389" ref-type="bibr">Holden et&#x000a0;al., 2013</xref>). A likely contributor to the variability in outcomes is the quality of the interface between each CI electrode and the neurons that make up the auditory nerve that are the intended targets of stimulation (<xref rid="bibr4-2331216516653389" ref-type="bibr">Bierer, 2010</xref>; <xref rid="bibr13-2331216516653389" ref-type="bibr">Goldwyn, Bierer, &#x00026; Bierer, 2010</xref>; <xref rid="bibr17-2331216516653389" ref-type="bibr">Long et&#x000a0;al., 2014</xref>). We refer to this as the <italic>electrode-neuron interface</italic>. The two main factors determining the quality of the electrode-neuron interface are the relative location of the electrodes within the cochlea and the health of auditory nerve cells.</p><p>The position of the electrodes has been shown to influence performance in several ways. Studies have found an association between greater insertion angles and poorer speech perception scores (e.g., <xref rid="bibr10-2331216516653389" ref-type="bibr">Finley et&#x000a0;al., 2008</xref>; <xref rid="bibr14-2331216516653389" ref-type="bibr">Holden et&#x000a0;al., 2013</xref>). One possible explanation is that those deeper insertions were more traumatic to the cochlea and more likely to traverse through the basilar membrane. In addition, position away from the modiolus (characterized by a low wrapping factor) was associated with poorer performance (<xref rid="bibr10-2331216516653389" ref-type="bibr">Finley et&#x000a0;al, 2008</xref>).</p><p><xref rid="bibr17-2331216516653389" ref-type="bibr">Long et&#x000a0;al. (2014)</xref> have demonstrated that electrodes distant from the inner wall of the cochlea have relatively high thresholds, especially when measured using a focused electrode configuration. In that study, increased variability in the thresholds that were not accounted for by the position corresponded with poorer speech perception scores. This finding suggests that other factors, such as neural health, might also play an important role in speech perception.</p><p>The electrode-neuron interface may also be directly assessed through psychophysical and neuro-physiological techniques. One particularly promising measure is the current required to reach threshold with focused, tripolar stimulation. Channels with a poor interface as assessed by high thresholds tend to have broader tuning and therefore greater channel interaction (<xref rid="bibr4-2331216516653389" ref-type="bibr">Bierer &#x00026; Faulkner, 2010</xref>). Other studies have shown that channels with high thresholds also have small dynamic ranges (<xref rid="bibr7-2331216516653389" ref-type="bibr">Bierer &#x00026; Nye, 2014</xref>) and abnormally steep amplitude growth functions in the electrically evoked auditory brainstem responses (<xref rid="bibr6-2331216516653389" ref-type="bibr">Bierer, Faulkner, &#x00026; Tremblay, 2011</xref>). More recently, a relationship between electrode position, spread of excitation, and focused behavioral thresholds was observed using the electrically evoked compound action potential and computed tomography (<xref rid="bibr9-2331216516653389" ref-type="bibr">DeVries, Scheperle, &#x00026; Bierer, 2016</xref>). Channels with smaller evoked compound action potential peak amplitudes had higher behavioral thresholds, suggesting sparse neural survival or poor neural synchrony in those regions. Finally, CI listeners with high degrees of channel interaction tend to have poorer spectral resolution (e.g., <xref rid="bibr15-2331216516653389" ref-type="bibr">Jones, Drennan, &#x00026; Rubinstein, 2013</xref>).</p><p>Hypothetically, speech perception could be improved by manipulations that affect the quality of the electrode-neuron interface. One proposed method to improve speech perception is to disable channels with &#x0201c;poor&#x0201d; electrode-neuron interfaces. Recent studies have shown improvements in speech perception scores when a subset of electrodes were deactivated with the intent of improving a psychophysical percept (<xref rid="bibr12-2331216516653389" ref-type="bibr">Garadat, Zwolan, &#x00026; Pfingst, 2012</xref>; <xref rid="bibr22-2331216516653389" ref-type="bibr">Saleh, Saeed, Meerton, Moore, &#x00026; Vickers, 2013</xref>) or reducing channel interaction (<xref rid="bibr19-2331216516653389" ref-type="bibr">Noble, Gifford, Hedley-Williams, Dawant, &#x00026; Labadie, 2014</xref>; <xref rid="bibr20-2331216516653389" ref-type="bibr">Noble, Labadie, Gifford, &#x00026; Dawant, 2013</xref>; Zhou &#x00026; Pfingst, 2012). In the study by Garadat et&#x000a0;al. (2012), channels with poor (high) amplitude modulation detection thresholds were deactivated from listeners&#x02019; programs and within-subject performance improved compared with when channels with good (low) thresholds were deactivated. Noble et&#x000a0;al. developed a computational model of CT data to select channels for deactivation. Channels were deactivated when the model suggested a high degree of overlapping stimulation patterns with neighboring channels. In the <xref rid="bibr20-2331216516653389" ref-type="bibr">Noble (2013</xref>, <xref rid="bibr19-2331216516653389" ref-type="bibr">2014</xref>) studies, performance was also improved with a subset of channels deactivated. In contrast, some studies have not found a positive result from deactivating electrodes that were indiscriminable from neighboring electrodes (Vickers et&#x000a0;al., 2016) or those producing nontonotopic percepts (Henshall &#x00026; McKay, 2001). Another approach to improving the electrode-neuron interface involves focusing stimulation on all available channels with partial-tripolar stimulation (<xref rid="bibr2-2331216516653389" ref-type="bibr">Berenstein, Mens, Mulder, &#x00026; Vanpoucke, 2008</xref>; <xref rid="bibr26-2331216516653389" ref-type="bibr">Srinivasan, Padilla, Shannon, &#x00026; Landsberger, 2013</xref>).</p><p>In the present study, we examine two methods for improving the transmission of spectral information by optimizing the electrode-neuron interfaces. We assess the effect of manipulation of the electrode-neuron interface on listeners&#x02019; abilities to identify medial vowels and consonants. The aim of these strategies is to determine (a) if acute performance using focused stimulation is better than with monopolar (MP) stimulation and (b) if focused thresholds are sensitive to both factors of the electrode-neuron interface (neural health and electrode position) and can they be effectively used to make programming decisions. In this experiment, three general types of programs were created: (a) a program in which all channels are programmed with focused configurations, (b) a program in which channels with high focused thresholds were deactivated (i.e., those estimated to have a poor electrode-neuron interface), and (c) a program in which channels with low-focused thresholds were deactivated (i.e., those estimated to have a good interface). The first experiment compares performance with all channels active between partial tripolar (pTP) and MP programs. The second experiment assesses channel deactivation when applied to both focused and MP strategies. In this experiment, the effects of deactivation in general across stimulus configurations and the effects of deactivating specific channels according to local variations in thresholds is evaluated. Note that focused thresholds are used to select channels for both the MP- and pTP-based programs to allow for direct comparisons of performance with those programs.</p></sec><sec sec-type="methods" id="sec2-2331216516653389"><title>Methods</title><sec id="sec3-2331216516653389" sec-type="subjects"><title>Subjects</title><p>Seven (eight ears) postlingually deafened adults along with and one peri-lingually deafened (S40) adult, all of whom wore the Advanced Bionics HiRes90K CI, participated. Their details are shown in <xref ref-type="table" rid="table1-2331216516653389">Table 1</xref>. One postlingually deaf subject, who was bilaterally implanted, was tested in each ear and is identified as S23-L and S36-R. This subject&#x02019;s two ears are treated separately, and therefore, for the purposes of analysis, nine subjects are considered. The Human Subjects Review Board at the University of Washington approved all procedures.
<table-wrap id="table1-2331216516653389" orientation="portrait" position="float"><label>Table 1.</label><caption><p>Subject Demographics.</p></caption><alternatives><graphic specific-use="table1-2331216516653389" xlink:href="10.1177_2331216516653389-table1"/><table frame="hsides" rules="groups"><thead align="left" valign="top"><tr><th rowspan="1" colspan="1">Subject ID</th><th rowspan="1" colspan="1">Age (years)</th><th rowspan="1" colspan="1">Duration of deafness (years)</th><th rowspan="1" colspan="1">Duration of CI use (years)</th><th rowspan="1" colspan="1">Etiology</th><th rowspan="1" colspan="1">Average performance with everyday strategy (% correct)</th><th rowspan="1" colspan="1">Electrode array type</th></tr></thead><tbody align="left" valign="top"><tr><td rowspan="1" colspan="1">S22</td><td rowspan="1" colspan="1">75</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">9</td><td rowspan="1" colspan="1">Unknown (genetic)</td><td rowspan="1" colspan="1">72</td><td rowspan="1" colspan="1">Helix</td></tr><tr><td rowspan="1" colspan="1">S23 (L)</td><td rowspan="1" colspan="1">71</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">8</td><td rowspan="1" colspan="1">Unknown</td><td rowspan="1" colspan="1">84</td><td rowspan="1" colspan="1">HiFocus 1J</td></tr><tr><td rowspan="1" colspan="1">S28</td><td rowspan="1" colspan="1">76</td><td rowspan="1" colspan="1">43</td><td rowspan="1" colspan="1">7</td><td rowspan="1" colspan="1">Autoimmune</td><td rowspan="1" colspan="1">45</td><td rowspan="1" colspan="1">HiFocus 1J</td></tr><tr><td rowspan="1" colspan="1">S30</td><td rowspan="1" colspan="1">52</td><td rowspan="1" colspan="1">22</td><td rowspan="1" colspan="1">11</td><td rowspan="1" colspan="1">Genetic</td><td rowspan="1" colspan="1">97</td><td rowspan="1" colspan="1">HiFocus 1J</td></tr><tr><td rowspan="1" colspan="1">S36 (R)</td><td rowspan="1" colspan="1">71</td><td rowspan="1" colspan="1">17</td><td rowspan="1" colspan="1">6</td><td rowspan="1" colspan="1">Unknown</td><td rowspan="1" colspan="1">74</td><td rowspan="1" colspan="1">HiFocus 1J</td></tr><tr><td rowspan="1" colspan="1">S38</td><td rowspan="1" colspan="1">51</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">5</td><td rowspan="1" colspan="1">Otosclerosis</td><td rowspan="1" colspan="1">44</td><td rowspan="1" colspan="1">HiFocus 1J</td></tr><tr><td rowspan="1" colspan="1">S40</td><td rowspan="1" colspan="1">53</td><td rowspan="1" colspan="1">49</td><td rowspan="1" colspan="1">3</td><td rowspan="1" colspan="1">Enlarged vestibular aqueduct</td><td rowspan="1" colspan="1">31</td><td rowspan="1" colspan="1">HiFocus 1J</td></tr><tr><td rowspan="1" colspan="1">S42</td><td rowspan="1" colspan="1">65</td><td rowspan="1" colspan="1">33</td><td rowspan="1" colspan="1">14</td><td rowspan="1" colspan="1">Unknown</td><td rowspan="1" colspan="1">96</td><td rowspan="1" colspan="1">HiFocus 1J with positioner</td></tr><tr><td rowspan="1" colspan="1">S43</td><td rowspan="1" colspan="1">70</td><td rowspan="1" colspan="1">18</td><td rowspan="1" colspan="1">2</td><td rowspan="1" colspan="1">Unknown</td><td rowspan="1" colspan="1">56</td><td rowspan="1" colspan="1">Mid-scala</td></tr></tbody></table></alternatives><table-wrap-foot><fn id="table-fn1-2331216516653389"><p><italic>Note.</italic> CI: cochlear implant.</p></fn></table-wrap-foot></table-wrap></p></sec><sec id="sec4-2331216516653389"><title>Stimuli for Detection Threshold</title><p>All threshold estimations were conducted with the pTP electrode configuration. Biphasic, charge-balanced, cathodic phase first pulse trains were used. Phase durations were 97&#x02009;&#x000b5;s and the pulse rate was 997 pulses per second. Pulse trains were 200&#x02009;ms in duration. These pulse settings are consistent with what have been used previously (e.g., <xref rid="bibr3-2331216516653389" ref-type="bibr">Bierer, 2007</xref>; Bierer et&#x000a0;al., 2015). Stimuli were presented in the pTP configuration with a return current fraction (&#x003c3;) of 0.9, which allowed for focused stimulation while remaining within the voltage compliance limits of the device. All stimuli were presented and controlled using research hardware and software (&#x0201c;BEDCS&#x0201d;) provided by Advanced Bionics (version BEDCS 18, 1.18.315, Valencia, CA, USA). Programs were written using the Matlab programming environment, which controlled low-level BEDCS routines. Prior to subject testing, all stimuli were checked using a test implant and digital storage oscilloscope.</p><p>Signal detection thresholds were measured using an adaptive three-down, one-up, two-interval forced-choice procedure that converged on 79% correct (<xref rid="bibr16-2331216516653389" ref-type="bibr">Levitt, 1971</xref>). Step size was 1 dB for the first two reversals and 0.25 dB thereafter. The mean of the last four of six turnpoints was used to estimate threshold. Subjects were asked, &#x0201c;Which interval contained the sound?&#x0201d; and responded using a computer mouse. Four or five repetitions were performed and averaged for each measurement. Thresholds were measured for all available channels (usually 2 through 15).</p></sec><sec id="sec5-2331216516653389"><title>Channel Selection</title><p>Channel selection for deactivation was based on the behavioral thresholds obtained with the pTP, &#x003c3;&#x02009;=&#x02009;0.9 electrode configuration. The following procedure was followed in the order described. A contrast enhancement filter (space constant of four electrodes, and gain of four) was applied to the threshold data to enhance the differences between peaks and troughs. We first applied a symmetric high-pass filter to the threshold profiles (with normalized coefficients of &#x02212;.14, &#x02212;.18,1, &#x02212;.18, &#x02212;.14, modified to account for electrodes at the ends of the array) to accentuate differences in threshold between each electrode and its apical and basal neighbors. The mean and standard deviation were calculated and a criterion was established such that more channels were selected for deactivation if the mean and standard deviation were high. Channels were dropped progressively until the standard deviation of the enhanced threshold data for the remaining channels was less than a subject-specific criterion or such that the total number of the remaining channels was at least eight. For each subject, the criterion was set based on the average threshold. Specifically, the criterion equaled 3 dB if the average threshold was 42 or below, and 1.5 dB if the average level was 48 or above. The distribution of thresholds for all of the subjects tested with these stimuli had a mean of approximately 45 dB re 1 uA +/&#x02212; 5 dB. One-half of the standard deviation was used above and below the mean to set these criteria. For subjects with average thresholds between 48 dB and 42 dB, the criterion was set as &#x02212;(A&#x02212;42)/(48&#x02212;42)&#x02009;&#x000d7;&#x02009;1.5&#x02009;+&#x02009;3. The subject-specific criterion was added so that more channels were dropped for subjects in whom the tripolar thresholds were higher.</p><p>Channels with high thresholds were selected in the following manner. The number of channels selected ranged from 1 to 6. If the algorithm selected two channels in a row, both channels were deactivated. If three channels in a row were identified, however, then the middle channel was not selected to maintain stimulation in that cochlear region. An equal number of relatively low-threshold channels were selected manually from the same region(s) (apical 2&#x02013;6, middle 7&#x02013;10, basal 11&#x02013;15) as the high-threshold channels when possible, to serve as a control condition.</p></sec><sec id="sec6-2331216516653389"><title>Experimental Mapping Procedure</title><p>Six different experimental programs were created for each subject using BEPS&#x02009;+&#x02009;software (version 1.10.19.27375, Advanced Bionics Corp., Valencia, CA, USA). All experimental programs were created on a Harmony research processor dedicated for use in the laboratory. The first two strategies were 14-channel programs including electrodes 2 through 15. Electrodes 1 and 16 were excluded because they could not serve as active electrodes with focused stimulation. Programs were created either in the pTP or MP configurations and are referred to as &#x0201c;pTP-all&#x0201d; and &#x0201c;MP-all,&#x0201d; respectively. The pTP-all program was created first because higher current levels are required for focused strategies and the software was set to automatically adjust the pulse duration and rate to reduce the power requirements (i.e., pulses that are longer in duration but smaller in amplitude have equal charge to short duration and larger amplitude but require less power). The goal was to create a pTP program with the highest degree of focusing possible for most subjects and channels; therefore, a &#x003c3;&#x02009;=&#x02009;0.875 was targeted for each electrode, for each subject. For some subjects and channels, the most comfortable listening level could not be achieved with that degree of focusing and sigma was reduced to either 0.75 or 0.625. <xref ref-type="table" rid="table2-2331216516653389">Table 2</xref> shows how often the sigma was changed for some channels in each subject. The final pulse duration and stimulation rate are also listed in <xref ref-type="table" rid="table2-2331216516653389">Table 2</xref>. Once the pulse duration and stimulation rate was set for the pTP-all program, the same pulse duration was used for the remaining five programs. This relatively slow rate could have reduced the performance with all of the experimental programs but was kept consistent to eliminate rate as a confounding factor for performance.
<table-wrap id="table2-2331216516653389" orientation="portrait" position="float"><label>Table 2.</label><caption><p>Experimental Program Details.</p></caption><alternatives><graphic specific-use="table2-2331216516653389" xlink:href="10.1177_2331216516653389-table2"/><table frame="hsides" rules="groups"><thead align="left" valign="top"><tr><th rowspan="1" colspan="1">Subject ID</th><th rowspan="1" colspan="1">Number of channels with a &#x003c3;&#x02009;&#x0003c;&#x02009;0.875</th><th rowspan="1" colspan="1">Pulse width (&#x000b5;sec/phase)</th><th rowspan="1" colspan="1">Pulse rate (pulses/ second)</th></tr></thead><tbody align="left" valign="top"><tr><td rowspan="1" colspan="1">S22</td><td rowspan="1" colspan="1">5; &#x003c3;&#x02009;=&#x02009;0.75</td><td rowspan="1" colspan="1">50.3</td><td rowspan="1" colspan="1">710</td></tr><tr><td rowspan="1" colspan="1">S23 (L)</td><td rowspan="1" colspan="1">5; 4 with &#x003c3;&#x02009;=&#x02009;0.7 and 1 &#x003c3;&#x02009;=&#x02009;0.625</td><td rowspan="1" colspan="1">192.2</td><td rowspan="1" colspan="1">200</td></tr><tr><td rowspan="1" colspan="1">S28</td><td rowspan="1" colspan="1">1; &#x003c3;&#x02009;=&#x02009;0.75</td><td rowspan="1" colspan="1">65.6</td><td rowspan="1" colspan="1">545</td></tr><tr><td rowspan="1" colspan="1">S30</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">141</td><td rowspan="1" colspan="1">253</td></tr><tr><td rowspan="1" colspan="1">S36 (R)</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">88.9</td><td rowspan="1" colspan="1">402</td></tr><tr><td rowspan="1" colspan="1">S38</td><td rowspan="1" colspan="1">7; &#x003c3;&#x02009;=&#x02009;0.75</td><td rowspan="1" colspan="1">88</td><td rowspan="1" colspan="1">406</td></tr><tr><td rowspan="1" colspan="1">S40</td><td rowspan="1" colspan="1">10; &#x003c3;&#x02009;=&#x02009;0.75</td><td rowspan="1" colspan="1">49.4</td><td rowspan="1" colspan="1">723</td></tr><tr><td rowspan="1" colspan="1">S42</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">36.8</td><td rowspan="1" colspan="1">970</td></tr><tr><td rowspan="1" colspan="1">S43</td><td rowspan="1" colspan="1">0</td><td rowspan="1" colspan="1">68.2</td><td rowspan="1" colspan="1">523</td></tr></tbody></table></alternatives></table-wrap></p><p>The all-channel programs were used as baseline strategies for the reduced-channel programs. Channels were selected for deactivation based on pTP threshold. The reduced-channel program using focused stimulation with the relatively high-threshold channels deactivated is referred to as &#x0201c;pTP high-off.&#x0201d; The other focused program with relatively low-threshold channels deactivated is referred to as &#x0201c;pTP low-off.&#x0201d; The &#x0201c;MP high-off&#x0201d; and &#x0201c;MP low-off&#x0201d; reduced-channel programs were created in the same manner using the MP-all as a baseline program. When channels were deactivated, both the overall pulse rate and per channel pulse durations were held constant to match the all-channel strategies across stimulation type. As a result, the inter-pulse interval was increased when the number of active channels was reduced.</p><p>To create each experimental program, threshold was estimated manually for each channel to the level in which the subject first heard the signal. Then, most comfortable level was estimated using a subjective loudness rating scale provided by Advanced Bionics that goes from 0 to 10. Stimulation level was increased until the subject indicated a rating of 7 described by <italic>Loud but comfortable</italic> and then the level was decreased until the subject indicated it was back to a 6 described as <italic>Most comfortable</italic>. Stimulus levels were loudness balanced at most comfortable level MCL in sets of four electrodes beginning with Electrode 2. The subject was instructed to inform the audiologist if the sounds were equally loud. Adjustments were made accordingly until those channels were perceived as not equally loud. The next set of electrodes was then loudness balanced with one electrode overlapping from the previous set until all 14 channels were balanced (2 through 5, 5 through 8, 8 through 11, and 11 through 14).</p><p>The following procedures were performed for each processor program. Once all channels were equally loud, the volume was reduced on the processor, and the microphone was activated. The volume was gradually increased until it was at 0 gain or 12 o&#x02019;clock on the dial. The subject was then asked to describe the overall volume of speech and the M-levels were globally adjusted until the subject indicated it was comfortable. Fine-tuning was conducted to optimize the stimulation levels for speech sounds. For instance, if the subject indicated the sound of their own voice was loud then the M levels were decreased for Electrode 2. Likewise, if the program had too much high frequency sound the M-level was reduced for Electrode 15. The Ling sounds (&#x0201c;ah,&#x0201d; &#x0201c;ee,&#x0201d; &#x0201c;oo,&#x0201d; &#x0201c;mm,&#x0201d; &#x0201c;sh,&#x0201d; &#x0201c;ss&#x0201d;) were presented through a screen to ensure audibility across the speech frequencies. If the Ling sounds were confused, minor adjustments in M-levels were made with the goal of correct identification of the sounds with each program.</p><p>Prior to speech discrimination testing, subjects were given approximately 20&#x02009;min of real-world listening experience with each program. This consisted of going outside for a walk or going to a nearby coffee shop with the audiologist. Each listener made six or seven visits to the laboratory, each visit lasting 3 to 4&#x02009;h. The order of testing with the experimental programs was randomized for each listener.</p></sec><sec id="sec7-2331216516653389"><title>Speech Discrimination</title><p>Two speech discrimination tests were administered; 16 medial consonants were presented in the &#x0201c;ah&#x0201d; context using a 16-choice closed-set task (/p/, &#x0201c;aPa&#x0201d;; /t/, &#x0201c;aTa&#x0201d;; /k/, &#x0201c;aKa&#x0201d;; /b/, &#x0201c;aBa&#x0201d;; /d/, &#x0201c;aDa&#x0201d;; /&#x00261;/, &#x0201c;aGa&#x0201d;; /f/, &#x0201c;aFa&#x0201d;; /&#x003b8;/, &#x0201c;aTHa&#x0201d;; /s/, &#x0201c;aSa&#x0201d;; /&#x00283;/, &#x0201c;aSHa&#x0201d;; /v/, &#x0201c;aVa&#x0201d;; /z/, &#x0201c;aZa&#x0201d;; /d&#x00292;/, &#x0201c;aJa&#x0201d;; /m/, &#x0201c;aMa&#x0201d;; /n/, &#x0201c;aNa&#x0201d;; /l/, &#x0201c;aLa&#x0201d;) (<xref rid="bibr24-2331216516653389" ref-type="bibr">Shannon, Jensvold, Padilla, Robert, &#x00026; Wang, 1999</xref>; <xref rid="bibr28-2331216516653389" ref-type="bibr">Tyler, Preece, &#x00026; Tye-Murray, 1986</xref>). Medial vowels were in the &#x0201c;hVd&#x0201d; context in a 10-choice closed-set task (/i/, &#x0201c;heed&#x0201d;; /&#x0026a;/, &#x0201c;hid&#x0201d;; /e&#x0026a;/, &#x0201c;hayed&#x0201d;; /&#x0025b;/, &#x0201c;head&#x0201d;; /&#x000e6;/, &#x0201c;had&#x0201d;; /&#x00251;/, &#x0201c;hod&#x0201d;; /u/, &#x0201c;who&#x02019;d&#x0201d;; /&#x0028a;/, &#x0201c;hood&#x0201d;; /o/, &#x0201c;hoed&#x0201d;; /&#x0028c;/, &#x0201c;hud&#x0201d;). Vowel stimuli were recorded for these experiments with one male and one female Pacific Northwest talker, as regional dialect has been found to influence recognition of vowel sounds (Wright &#x00026; Souza, 2012). A head-mounted close talking microphone was used to record vowel sounds in a double-walled sound-treated booth. Recordings were digitized at 44.1&#x02009;kHz using 16-bit quantization and were resampled to 22.5&#x02009;kHz. Listeners were given one practice set, where each token was presented three times; listeners could repeat the token and were given feedback. Following the practice set, two more sets of three repetitions were completed. If the average score of the two sets differed by more than 10%, a third set was run and all three were averaged to determine the percent correct. If listeners performed better than 70% correct on vowel or consonant identification in quiet, testing was performed with four-talker babble noise (Auditek) at a&#x02009;+&#x02009;10 signal-to-noise ratio. Speech scores were then converted to rational arcsine units (rau; <xref rid="bibr27-2331216516653389" ref-type="bibr">Studebaker, 1985</xref>).</p><p>Stimuli were presented through an external A/D device (SIIG USB SoundWave 7.1), amplified by a Crown Amplifier (D75) and presented at 60 dB sound pressure level&#x02009;(SPL) in the sound field inside a double-walled sound attenuating both. The sound files were presented from a desktop PC using custom software (ListPlayer2 version 2.2.11.52, Advanced Bionics). The stimuli were calibrated to a 1&#x02009;kHz tone with a sound level meter (Bruel and Kjaer, Hand-held Analyzer Type 2250 and ZC 0032 microphone) and presented through a loudspeaker (Bose 161) placed at ear level height, at 0&#x000b0; azimuth and 1&#x02009;m from the subjects&#x02019; head.</p></sec><sec id="sec8-2331216516653389"><title>Performance Questionnaire</title><p>Following the testing with each experimental strategy, subjects were asked to complete a questionnaire that involved rating the sound quality and clarity on a scale from 1 to 10 in comparison to their everyday listening strategy. A rating of &#x0201c;1&#x0201d; was considered worse than their everyday strategy, a rating of &#x0201c;10&#x0201d; was considered better, and &#x0201c;5&#x0201d; was considered equivalent. Subjects were blinded to the specific programs that were tested and did not see their scores following testing with each program.</p></sec></sec><sec sec-type="results" id="sec9-2331216516653389"><title>Results</title><p>Detection thresholds using focused stimulation are plotted for all subjects in <xref ref-type="fig" rid="fig1-2331216516653389">Figure 1</xref>. Each panel shows threshold data for one subject as a function of CI electrode number from apex to base (x-axis). The solid, horizontal line is the mean of thresholds for each subject and the dashed lines show one standard deviation. The symbols filled with red and gray indicate the &#x0201c;high-&#x0201d; and &#x0201c;low&#x0201d;-threshold channels, respectively that were deactivated in Experiment 2. Panels are arranged by performance on medial vowel identification for each subject using the pTP-all settings and the scores are listed in each panel. Data from the poorest performer appears in the top left and the best in the bottom right. Consistent with previous studies, the threshold profiles are variable across subjects (<xref rid="bibr3-2331216516653389" ref-type="bibr">Bierer, 2007</xref>, <xref rid="bibr4-2331216516653389" ref-type="bibr">2010</xref>; <xref rid="bibr4-2331216516653389" ref-type="bibr">Bierer &#x00026; Faulkner, 2010</xref>; <xref rid="bibr17-2331216516653389" ref-type="bibr">Long et&#x000a0;al., 2014</xref>; <xref rid="bibr21-2331216516653389" ref-type="bibr">Pfingst, Xu, &#x00026; Thompson, 2004</xref>). The data in <xref ref-type="fig" rid="fig1-2331216516653389">Figure 1</xref> represent the actual threshold profiles and not the results of the algorithm used for channel selection.
<fig id="fig1-2331216516653389" orientation="portrait" position="float"><label>Figure 1.</label><caption><p>Each panel shows the pTP detection threshold (dB re 1 mA) as a function of active electrode number (from apical to basal) for each subject. Subjects are organized by performance on medial vowel identification using their everyday listening program (indicated in the bottom left of each panel). Filled red and gray circles indicate channels selected for deactivation from high- and low-off programs, respectively. The solid black and blue dashed lines represent the mean and standard deviation of thresholds for each subject, respectively.</p></caption><graphic xlink:href="10.1177_2331216516653389-fig1"/></fig></p><p>In the first experiment, speech perception scores on medial consonants and medial vowels were obtained using experimental strategies programmed with the pTP and the MP configurations. <xref ref-type="fig" rid="fig2-2331216516653389">Figure 2</xref> shows the scores for each consonants (top), vowels (middle), and average (bottom) panels. Darker bars indicated scores when tested in quiet while the lighter bars indicated scores tested in a&#x02009;+&#x02009;10 dB signal to noise ratio of multitalker babble noise. As before, the subject order is sorted by performance. Performance both in quiet and in background noise was not significantly different for pTP and MP configurations (repeated-measures ANOVA with speech test as a between subjects factor, <italic>F</italic><sub>1,50</sub>&#x02009;=&#x02009;0.146, <italic>p</italic>&#x02009;=&#x02009;.52, no interaction with speech test <italic>F</italic><sub>3,50</sub>&#x02009;=&#x02009;1.66, <italic>p</italic>&#x02009;=&#x02009;.19).
<fig id="fig2-2331216516653389" orientation="portrait" position="float"><label>Figure 2.</label><caption><p>The bars represent performance (converted from percent correct) for medial consonant (top), medial vowel (middle), and the average of consonants and vowels (bottom). The color of the bars represent the electrode configuration used in these all channel programs. The lighter color bars indicated that the testing was performed in the presence of four-talker babble noise at a signal-to-noise ratio threshold of&#x02009;+&#x02009;10 dB. Error bars on the averaged data to the right in each panel represent 1 standard deviation of the mean.</p></caption><graphic xlink:href="10.1177_2331216516653389-fig2"/></fig></p><p><xref ref-type="fig" rid="fig3-2331216516653389">Figure 3</xref> shows the quality (top) and clarity (bottom) ratings for TP-all versus MP-all. As with speech discrimination scores, the subjective ratings by the subjects were higher for the pTP program for the poorer performers and higher for the MP program for the better performers; therefore, on average there is no difference between ratings across configurations. However, quality and clarity ratings were different from each other (repeated-measures ANOVA with strategy as a between subjects variable; <italic>F</italic><sub>1.3,12.6</sub>&#x02009;=&#x02009;4.86, <italic>p</italic>&#x02009;=&#x02009;.03, with no interaction with configuration, <italic>F</italic><sub>2,12.6</sub>&#x02009;=&#x02009;1.42, <italic>p</italic>&#x02009;=&#x02009;.24).
<fig id="fig3-2331216516653389" orientation="portrait" position="float"><label>Figure 3.</label><caption><p>Bars represent the subjective quality (top) and clarity (bottom) ratings on a scale from 1 to 10 for subjects listening to either pTP (red) or MP (blue) experimental programs. Conventions as in previous figure.</p></caption><graphic xlink:href="10.1177_2331216516653389-fig3"/></fig></p><p><xref ref-type="fig" rid="fig4-2331216516653389">Figure 4</xref> shows the difference in performance between pTP and MP configurations (y-axis) as a function of performance scores with the listener&#x02019;s everyday programs for medial consonants (left), vowels (middle), and average (right). The everyday program refers to the listener&#x02019;s clinical program. The medial vowel performance with everyday programs was used to divide listeners into poor (&#x0003c;62% correct) and good (&#x0003e;63% correct) performers based on the median performance of 62%. This classification was used for the statistical analyses. The poorer performing subjects were more likely to benefit from reduced channel interaction with focused programming than were the better performing subjects for vowels and not consonants (paired <italic>t</italic>-test with Bonferroni correction, consonants; <italic>t</italic><sub>6</sub>&#x02009;=&#x02009;0.67, <italic>p</italic>&#x02009;=&#x02009;.53, vowels; <italic>t</italic><sub>6</sub>&#x02009;=&#x02009;3.48, <italic>p</italic>&#x02009;=&#x02009;.026). The quality and clarity ratings showed a trend with higher ratings for strategies they performed better with (paired <italic>t</italic>-test with Bonferroni correction, quality; <italic>t</italic><sub>6</sub>&#x02009;=&#x02009;3.78, <italic>p</italic>&#x02009;=&#x02009;.026, clarity; <italic>t</italic><sub>6</sub>&#x02009;=&#x02009;2.48, <italic>p</italic>&#x02009;=&#x02009;.11).
<fig id="fig4-2331216516653389" orientation="portrait" position="float"><label>Figure 4.</label><caption><p>Circles represent data for each subject for the difference in performance between the all channel pTP and MP programs (y-axis) and with the subjects&#x02019; everyday listening program (x-axis) for medial consonants (left), vowels (middle), and the average of consonants and vowels (right). The stars represent the average data for poorer performers (filled) and better performers (open). Performance was categorized based on medial vowel performance, indicated by the vertical dashed line at 62%.</p></caption><graphic xlink:href="10.1177_2331216516653389-fig4"/></fig></p><p>In the second experiment, programs with disabled channels were evaluated. Channels were selected for deactivation based on focused thresholds, either relatively high, &#x0201c;high-off&#x0201d; (red-filled symbols in <xref ref-type="fig" rid="fig1-2331216516653389">Figure 1</xref>) or low, &#x0201c;low-off&#x0201d; (gray-filled symbols in <xref ref-type="fig" rid="fig1-2331216516653389">Figure 1</xref>). For S42, for example, channels were selected for the following reasons. Beyond the clearly high thresholds for Electrodes 3 and 4, when the threshold profile was enhanced, the threshold for Electrode 9 was a local peak and was therefore also selected as a high-threshold channel. For low-threshold channels, Electrode 2 was selected because it had the lowest threshold in the apical region that was nonneighboring with Electrode 6 (the lowest threshold channel for the middle region). In <xref ref-type="fig" rid="fig5-2331216516653389">Figure 5</xref>, performance relative to the pTP &#x0201c;all-channel&#x0201d; condition is shown for consonants (top), vowels (middle), and average scores (bottom) for the high- and low-off conditions. Note that bars going up indicate better performance with channels deactivated. In general, most subjects perform similarly when channels are deactivated from the pTP strategies whether the channels deactivated have relatively high or low thresholds (Repeated-measures ANOVA with speech test as a between subjects factor [<italic>F</italic><sub>1.9,94</sub>&#x02009;=&#x02009;1.67, <italic>p</italic>&#x02009;=&#x02009;.20]).
<fig id="fig5-2331216516653389" orientation="portrait" position="float"><label>Figure 5.</label><caption><p>Bars indicate the difference in performance between the pTP all channel program and the programs with either high (dark pink in quiet and gray in noise) or low (light pink in quiet and white in noise) channels deactivated. Upward going bars indicate that performance was better with channels deactivated.</p></caption><graphic xlink:href="10.1177_2331216516653389-fig5"/></fig></p><p>In contrast, when channels are deactivated in a MP program, performance tends to improve compared with the MP-all condition. <xref ref-type="fig" rid="fig6-2331216516653389">Figure 6</xref> shows that although performance is improved with channel deactivation on average, performance was enhanced, but not significantly, for high-off channels (Repeated-measures ANOVA with speech test as a covariate [<italic>F</italic><sub>1.1,57</sub>&#x02009;=&#x02009;3.07, <italic>p</italic>&#x02009;=&#x02009;.08]). Note that because of time constraints, S30 did not participate in the MP channel deactivation portion of the experiment and therefore the data are missing.
<fig id="fig6-2331216516653389" orientation="portrait" position="float"><label>Figure 6.</label><caption><p>Conventions as in <xref ref-type="fig" rid="fig5-2331216516653389">Figure 5</xref> except the data were obtained with the MP configuration. Color indicates programs with either high (dark blue in quiet and gray in noise) or low (light blue in quiet and white in noise) channels deactivated. Note that because of time constraints S30 did not participate in the MP channel deactivation portion of the experiment and therefore the data are missing from the figure.</p></caption><graphic xlink:href="10.1177_2331216516653389-fig6"/></fig></p><p><xref ref-type="fig" rid="fig7-2331216516653389">Figure 7</xref> shows the change in performance for deactivated channel conditions across stimulation types by averaging the scores of high- and low-off conditions (i.e., MP-reduced minus MP-all or pTP-reduced minus pTP-all) on the y-axis as a function of the scores the listener obtained with their <italic>everyday</italic> listening programs. Although the everyday programs all used the MP configuration, the program settings were quite different from the MP-all research programs. For the MP configuration, it is clear that the subjects who benefit from channel deactivation are the poorer performers while that trend does not exist for the pTP strategies (paired <italic>t</italic>-test with Bonferroni correction for MP; <italic>t</italic><sub>6</sub>&#x02009;=&#x02009;2.89, <italic>p</italic>&#x02009;=&#x02009;.05, for pTP; <italic>t</italic><sub>6</sub>&#x02009;=&#x02009;&#x02212;0.92, <italic>p</italic>&#x02009;=&#x02009;.78).
<fig id="fig7-2331216516653389" orientation="portrait" position="float"><label>Figure 7.</label><caption><p>Conventions as in <xref ref-type="fig" rid="fig4-2331216516653389">Figure 4</xref>. The top and bottom rows of panels represent the difference between the pTP and MP all channel programs and the average of the high- and low-channels deactivated programs (y-axis). Positive numbers indicate the subject performed better with channels deactivated compared with using all channels.</p></caption><graphic xlink:href="10.1177_2331216516653389-fig7"/></fig></p></sec><sec sec-type="discussion" id="sec10-2331216516653389"><title>Discussion</title><p>The present study was designed to assess improvements in speech perception by programming CIs to reduce channel interaction, using focused stimulation or deactivating a subset of channels. Results showed that speech perception scores did not improve for all subjects with any one of the channel reduction strategies. Interestingly, the poorer performing subjects appeared to benefit from either current focusing of all channels or channel deactivation in the MP configuration. However, the effects of the two manipulations were not additive. When channels were deactivated from the MP experimental programs, improvements were observed with both the high- or low-threshold channels deactivated. This suggests that channel selection based on focused threshold alone is not sufficient to optimize implant settings.</p><sec id="sec11-2331216516653389"><title>Focused Stimulation: Perceptual Measures</title><p>Consistent with previous studies, focused thresholds were high and variable across the CI array (<xref rid="bibr3-2331216516653389" ref-type="bibr">Bierer, 2007</xref>; <xref rid="bibr4-2331216516653389" ref-type="bibr">Bierer &#x00026; Faulkner, 2010</xref>; <xref rid="bibr17-2331216516653389" ref-type="bibr">Long et&#x000a0;al, 2014</xref>; <xref rid="bibr21-2331216516653389" ref-type="bibr">Pfingst et&#x000a0;al., 2004</xref>). Previous studies suggest that elevated thresholds are an indication of a poor electrode-neuron interface either because of a large distance between the stimulating electrodes and the target neurons or because of poor neural health (<xref rid="bibr4-2331216516653389" ref-type="bibr">Bierer &#x00026; Faulkner, 2010</xref>; <xref rid="bibr9-2331216516653389" ref-type="bibr">DeVries et&#x000a0;al., 2016</xref>; <xref rid="bibr13-2331216516653389" ref-type="bibr">Goldwyn et&#x000a0;al., 2010</xref>; <xref rid="bibr17-2331216516653389" ref-type="bibr">Long et&#x000a0;al., 2014</xref>). Focused thresholds are often correlated with distance between the electrodes and the inner wall of the cochlea; therefore, it is difficult to separate the contributions of neural health to focused thresholds (e.g., <xref rid="bibr17-2331216516653389" ref-type="bibr">Long et&#x000a0;al., 2014</xref>).</p><p>It is well established that CI listeners have significant channel interactions. Interactions have been quantified with broad tuning (<xref rid="bibr4-2331216516653389" ref-type="bibr">Bierer &#x00026; Faulkner, 2010</xref>; <xref rid="bibr8-2331216516653389" ref-type="bibr">Chatterjee, Galvin, Fu, &#x00026; Shannon, 2006</xref>; <xref rid="bibr18-2331216516653389" ref-type="bibr">Nelson, Donaldson, &#x00026; Kreft, 2008</xref>; <xref rid="bibr25-2331216516653389" ref-type="bibr">Shannon, Zeng, Kamath, Wygonski, &#x00026; Ekelid, 1995</xref>), indicating an inability of implant listeners to access independent spectral information as well as normal hearing listeners (for review, see <xref rid="bibr23-2331216516653389" ref-type="bibr">Shannon, Fu, &#x00026; Galvin, 2004</xref>). In addition, greater channel interaction and poor spectral resolution have also been correlated and vary across the array within individual listeners (<xref rid="bibr1-2331216516653389" ref-type="bibr">Anderson, Nelson, Kreft, Nelson, &#x00026; Oxenham, 2011</xref>; <xref rid="bibr15-2331216516653389" ref-type="bibr">Jones et&#x000a0;al., 2013</xref>).</p><sec id="sec12-2331216516653389"><title>Focused stimulation: Speech perception</title><p>In the present study in Experiment 1, focused stimulation was used in an effort to reduce channel interaction with mixed results. Notably, listeners who had relatively poor speech perception scores were the subjects who both benefited from focused stimulation and rated the quality and clarity higher than broad stimulation. Berenstein and colleagues (2008) showed that some listeners benefited from focused stimulation programs while others benefited from MP stimulation with current steering. <xref rid="bibr26-2331216516653389" ref-type="bibr">Srinivasan et&#x000a0;al. (2013)</xref>, on the other hand, observed an improvement for all listeners when tested on sentences in noise and a spectral resolution task.</p><p>A few methodological differences could account for the lack of consistent benefit observed in the present study compared with <xref rid="bibr26-2331216516653389" ref-type="bibr">Srinivasan et&#x000a0;al. (2013)</xref>. First, the speech perception stimuli used in the present study are more difficult than the sentences used previously. Single words or phonemes are generally more difficult because the listeners cannot rely on the context of the sentence or the coarticulation cues from the words coming before or after key words. It is unclear why then improvements were consistently observed using sentences and not phonemes given the added benefit of using sentence context even if spectral cues are lacking. Both studies have tested a small number of subjects which could contribute to the variability in results. Second, we programmed experimental strategies differently than in the Srinivasan study. Rather than loudness balancing across configurations and using a fixed dynamic range for each channel, we measured behavioral thresholds and most comfortable levels for all of the programs independently, and &#x0201c;fine-tuning&#x0201d; was performed for each strategy. To perform the fine-tuning, listeners were presented with the Ling sounds to ensure audibility across the speech frequencies and minor adjustments were made to optimize every program so that listeners could detect or identify as many of the Ling sounds as possible. The programming technique employed in the present study might have influenced performance across strategies.</p></sec></sec><sec id="sec13-2331216516653389"><title>Channel Deactivation</title><p>In Experiment 2, another method used to reduce channel interaction was to deactivate a subset of channels from listeners&#x02019; programs. This method of channel deactivation has shown some success for improved speech perception and spectral resolution in previous studies (<xref rid="bibr12-2331216516653389" ref-type="bibr">Garadat et&#x000a0;al., 2012</xref>; <xref rid="bibr20-2331216516653389" ref-type="bibr">Noble et&#x000a0;al., 2013</xref>, <xref rid="bibr19-2331216516653389" ref-type="bibr">2014</xref>; <xref rid="bibr22-2331216516653389" ref-type="bibr">Saleh et&#x000a0;al., 2013</xref>). However, <xref rid="bibr20-2331216516653389" ref-type="bibr">Noble et&#x000a0;al. (2013</xref>, <xref rid="bibr19-2331216516653389" ref-type="bibr">2014</xref>) did not provide either psychophysical or electrophysiological evidence to support that the channels selected for deactivation were those with high levels of channel interaction. Indeed, the results from the present study suggest that the choice of which channels should be deactivated may not be critical because both reduced-channel MP programs were beneficial for many listeners, especially those with poorer speech perception performance. The improvements observed by <xref rid="bibr12-2331216516653389" ref-type="bibr">Garadat et&#x000a0;al. (2012)</xref> may not have been observed in the present study because we did not require the selection of a single channel in each of the quadrants of the CI array. In the Garadat study, the channels were deactivated based on a temporal resolution measure and the relationship between modulation detection and focused thresholds is yet unknown.</p><p>In the second experiment of the present study, one hypothesis tested was if improvements beyond focusing could be achieved by channel deactivation in the tripolar strategies. In fact, rather than improved speech perception, the scores were generally unchanged or even reduced by channel deactivation. Because focused thresholds alone were used to select channels and the contributions of electrode position and neural health to the elevated thresholds have not been differentiated, it might be that deactivating channels with focused stimulation simply reduces the number of neurons activated. Consider the model shown in <xref ref-type="fig" rid="fig8-2331216516653389">Figure 8</xref>. In the top two panels with electrical fields created in the MP configuration, even with a reduced number of active channels, the number of neurons activated is still complete, whereas in the lower two panels with fields created in the pTP configuration, there are neurons available that might not ever be stimulated.
<fig id="fig8-2331216516653389" orientation="portrait" position="float"><label>Figure 8.</label><caption><p>Schematic showing electrical fields generated by the <xref rid="bibr13-2331216516653389" ref-type="bibr">Goldwyn et&#x000a0;al. (2010)</xref> cylinder model for MP (top) and pTP (bottom). Rectangles represent electrode contacts and pink ovals represent spiral ganglion neurons. The left panels show the full complement of active channels. The right panels show the distribution of voltage that would occur if the electrodes with x&#x02019;s were not activated in a program.</p></caption><graphic xlink:href="10.1177_2331216516653389-fig8"/></fig></p><p>The small improvements observed in speech perception tasks for listeners using programs designed to reduce channel interaction largely did not reach statistical significance. Part of the reason for this could be that a small sample of subjects participated in the experiments and only the poorer performing subjects seemed to benefit. In previous studies, the poorer performing listeners have typically shown a higher degree of channel interaction (e.g., <xref rid="bibr1-2331216516653389" ref-type="bibr">Anderson et&#x000a0;al., 2011</xref>; <xref rid="bibr15-2331216516653389" ref-type="bibr">Jones et&#x000a0;al., 2013</xref>), elevated thresholds (<xref rid="bibr17-2331216516653389" ref-type="bibr">Long et&#x000a0;al., 2014</xref>), or small evoked potential peak amplitudes (<xref rid="bibr9-2331216516653389" ref-type="bibr">DeVries et&#x000a0;al., 2016</xref>). This may be the reason those listeners, in particular, benefit from focusing and channel-deactivation. In addition, previous studies allowed listeners to acclimate to the reduced-channel programs for one month (<xref rid="bibr20-2331216516653389" ref-type="bibr">Noble et&#x000a0;al., 2013</xref>, <xref rid="bibr19-2331216516653389" ref-type="bibr">2014</xref>). When channels are deactivated, the frequencies are reallocated to the available channels and this change in the channels which carry certain sound frequencies can take some time for listeners to adapt (e.g., <xref rid="bibr11-2331216516653389" ref-type="bibr">Fu, Shannon, &#x00026; Galvin, 2002</xref>). It is possible that in the present study, experience with each strategy might have enhanced the effects of reducing channel interaction and led to better performance. Future studies will examine the effects of listening experience with strategies that reduce channel interaction.</p></sec></sec></body><back><ack><title>Acknowledgments</title><p>The authors would like to acknowledge Emily Ellis for assistance with data collection and our subjects for their constant dedication. Melanie Gilbert and Chen Chen from Advanced Bionics assisted with the setup of the study. We also want to thank Lynne A. Werner and the Communication Studies Participant Pool (P30 DC04661) for their support.</p></ack><sec id="sec14-2331216516653389"><title>Declaration of Conflicting Interests</title><p>The authors declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p></sec><sec id="sec15-2331216516653389"><title>Funding</title><p>The author(s) disclosed receipt of the following financial support for the research, authorship, and/or publication of this article: We would like to acknowledge funding from NIH, NIDCD (RO1 DC012142 ), JAB.</p></sec><ref-list><title>References</title><ref id="bibr1-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Anderson</surname><given-names>E. S.</given-names></name><name><surname>Nelson</surname><given-names>D. A.</given-names></name><name><surname>Kreft</surname><given-names>H.</given-names></name><name><surname>Nelson</surname><given-names>P. B.</given-names></name><name><surname>Oxenham</surname><given-names>A. J.</given-names></name></person-group> (<year>2011</year>) <article-title>Comparing spatial tuning curves, spectral ripple resolution and speech perception in cochlear implant users</article-title>. <source>Journal of the Acoustical Society of America</source>
<volume>130</volume>(<issue>1</issue>): <fpage>364</fpage>&#x02013;<lpage>375</lpage>. <comment>(PMID: 21786905)</comment>.<pub-id pub-id-type="pmid">21786905</pub-id></mixed-citation></ref><ref id="bibr2-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berenstein</surname><given-names>C. K.</given-names></name><name><surname>Mens</surname><given-names>L. H.</given-names></name><name><surname>Mulder</surname><given-names>J. J.</given-names></name><name><surname>Vanpoucke</surname><given-names>F. J.</given-names></name></person-group> (<year>2008</year>) <article-title>Current steering and current focusing in cochlear implants: Comparison of monopolar, tripolar, and virtual channel electrode configurations</article-title>. <source>Ear and Hearing</source>
<volume>29</volume>: <fpage>250</fpage>&#x02013;<lpage>260</lpage>. <comment>(PMID: 18595189)</comment>.<pub-id pub-id-type="pmid">18595189</pub-id></mixed-citation></ref><ref id="bibr3-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bierer</surname><given-names>J. A.</given-names></name></person-group> (<year>2007</year>) <article-title>Threshold and channel interaction in cochlear implant users: Evaluation of the tripolar electrode configuration</article-title>. <source>Journal of the Acoustical Society of America</source>
<volume>121</volume>(<issue>3</issue>): <fpage>1642</fpage>&#x02013;<lpage>1653</lpage>. <comment>(PMID: 17407901)</comment>.<pub-id pub-id-type="pmid">17407901</pub-id></mixed-citation></ref><ref id="bibr4-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bierer</surname><given-names>J. A.</given-names></name></person-group> (<year>2010</year>) <article-title>Probing the electrode-neuron interface with focused cochlear implant stimulation</article-title>. <source>Trends in Amplification</source>
<volume>14</volume>(<issue>2</issue>): <fpage>84</fpage>&#x02013;<lpage>95</lpage>. <comment>(PMID: 20724356)</comment>.<pub-id pub-id-type="pmid">20724356</pub-id></mixed-citation></ref><ref id="bibr5-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bierer</surname><given-names>J. A.</given-names></name><name><surname>Faulkner</surname><given-names>K. F.</given-names></name></person-group> (<year>2010</year>) <article-title>Identifying cochlear implant channels with poor electrode-neuron interface: Partial tripolar, single-channel thresholds, and psychophysical tuning curves</article-title>. <source>Ear and Hearing</source>
<volume>31</volume>(<issue>1</issue>): <fpage>247</fpage>&#x02013;<lpage>258</lpage>. <comment>(PMID: 20090533)</comment>.<pub-id pub-id-type="pmid">20090533</pub-id></mixed-citation></ref><ref id="bibr6-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bierer</surname><given-names>J. A.</given-names></name><name><surname>Faulkner</surname><given-names>K. F.</given-names></name><name><surname>Tremblay</surname><given-names>K. L.</given-names></name></person-group> (<year>2011</year>) <article-title>Identifying cochlear implant channels with poor electrode-neuron interfaces: Electrically evoked auditory brainstem responses measured with the partial tripolar configuration</article-title>. <source>Ear and Hearing</source>
<volume>32</volume>(<issue>4</issue>): <fpage>436</fpage>&#x02013;<lpage>444</lpage>. <comment>(PMID: 21178633)</comment>.<pub-id pub-id-type="pmid">21178633</pub-id></mixed-citation></ref><ref id="bibr7-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bierer</surname><given-names>J. A.</given-names></name><name><surname>Nye</surname><given-names>A. D.</given-names></name></person-group> (<year>2014</year>) <article-title>Comparisons between detection threshold and loudness perception for individual cochlear implant channels</article-title>. <source>Ear and Hearing</source>
<volume>35</volume>(<issue>6</issue>): <fpage>641</fpage>&#x02013;<lpage>651</lpage>. <comment>(PMID: 25036146)</comment>.<pub-id pub-id-type="pmid">25036146</pub-id></mixed-citation></ref><ref id="bibr101-1363460715620576"><mixed-citation publication-type="other">Bierer, J. A., Bierer, S. M., Kreft, H. A., &#x00026; Oxenham, A. J. (2015). A fast method for measuring psychophysical thresholds across the cochlear implant array. <italic>Trends Hear</italic>, <italic>4</italic>, 19.</mixed-citation></ref><ref id="bibr8-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Chatterjee</surname><given-names>M.</given-names></name><name><surname>Galvin</surname><given-names>J. J.</given-names><suffix>3rd</suffix></name><name><surname>Fu</surname><given-names>Q. J.</given-names></name><name><surname>Shannon</surname><given-names>R. V.</given-names></name></person-group> (<year>2006</year>) <article-title>Effects of stimulation mode, level and location on forward-masked excitation patterns in cochlear implant patients</article-title>. <source>Journal of the Association for Research in Otolaryngology: JARO</source>
<volume>7</volume>(<issue>1</issue>): <fpage>15</fpage>&#x02013;<lpage>25</lpage>. <comment>(PMID: 16270234)</comment>.<pub-id pub-id-type="pmid">16270234</pub-id></mixed-citation></ref><ref id="bibr9-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>DeVries</surname><given-names>L. A.</given-names></name><name><surname>Scheperle</surname><given-names>R. A.</given-names></name><name><surname>Bierer</surname><given-names>J. A.</given-names></name></person-group> (<year>2016</year>) <article-title>Assessing the electrode-neuron interface with the electrically evoked compound action potential, electrode position, and behavioral thresholds</article-title>. <source>Journal of the Association for Research in Otolaryngology: JARO</source>
<volume>17</volume>: <fpage>237</fpage>&#x02013;<lpage>252</lpage>.<pub-id pub-id-type="pmid">26926152</pub-id></mixed-citation></ref><ref id="bibr10-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Finley</surname><given-names>C. C.</given-names></name><name><surname>Holden</surname><given-names>T. A.</given-names></name><name><surname>Holden</surname><given-names>L. K.</given-names></name><name><surname>Whiting</surname><given-names>B. R.</given-names></name><name><surname>Chole</surname><given-names>R. A.</given-names></name><name><surname>Neely</surname><given-names>G. J.</given-names></name><name><surname>Skinner</surname><given-names>M. W.</given-names></name></person-group> (<year>2008</year>) <article-title>Role of electrode placement as a contributor to variability in cochlear implant outcomes</article-title>. <source>Otology Neurotology</source>
<volume>29</volume>: <fpage>920</fpage>&#x02013;<lpage>928</lpage>.<pub-id pub-id-type="pmid">18667935</pub-id></mixed-citation></ref><ref id="bibr11-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fu</surname><given-names>Q. J.</given-names></name><name><surname>Shannon</surname><given-names>R. V.</given-names></name><name><surname>Galvin</surname><given-names>J. J.</given-names><suffix>3rd.</suffix></name></person-group> (<year>2002</year>) <article-title>Perceptual learning following changes in the frequency-to-electrode assignment with the Nucleus-22 cochlear implant</article-title>. <source>Journal of the Acoustical Society of America</source>
<volume>112</volume>(<issue>4</issue>): <fpage>1664</fpage>&#x02013;<lpage>1674</lpage>. <comment>(PMID: 12398471)</comment>.<pub-id pub-id-type="pmid">12398471</pub-id></mixed-citation></ref><ref id="bibr12-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Garadat</surname><given-names>S. N.</given-names></name><name><surname>Zwolan</surname><given-names>T. A.</given-names></name><name><surname>Pfingst</surname><given-names>B. E.</given-names></name></person-group> (<year>2012</year>) <article-title>Across-site patterns of modulation detection: Relation to speech perception</article-title>. <source>Journal of the Acoustical Society of America</source>
<volume>131</volume>(<issue>5</issue>): <fpage>4030</fpage>&#x02013;<lpage>4041</lpage>. <comment>(PMID: 2255937)</comment>.<pub-id pub-id-type="pmid">22559376</pub-id></mixed-citation></ref><ref id="bibr13-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goldwyn</surname><given-names>J. H.</given-names></name><name><surname>Bierer</surname><given-names>S. M.</given-names></name><name><surname>Bierer</surname><given-names>J. A.</given-names></name></person-group> (<year>2010</year>) <article-title>Modeling the electrode-neuron interface of cochlear implants: Effects of neural survival, electrode placement, and the partial tripolar configuration</article-title>. <source>Hearing Research</source>
<volume>268</volume>(<issue>1&#x02013;2</issue>): <fpage>93</fpage>&#x02013;<lpage>104</lpage>. <comment>(PMID: 20580801)</comment>.<pub-id pub-id-type="pmid">20580801</pub-id></mixed-citation></ref><ref id="bibr102-1363460715620576"><mixed-citation publication-type="other">Henshall, K. R, &#x00026; McKay, C. M. (2001). Optimizing electrode and filter selection in cochlear implant speech processor maps <italic>J Am Acad Audiol</italic>, <italic>12</italic>(9), 478&#x02013;89.</mixed-citation></ref><ref id="bibr14-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Holden</surname><given-names>L. K.</given-names></name><name><surname>Finely</surname><given-names>C. C.</given-names></name><name><surname>Firszt</surname><given-names>J. B.</given-names></name><name><surname>Holden</surname><given-names>T. A.</given-names></name><name><surname>Brenner</surname><given-names>C.</given-names></name><name><surname>Potts</surname><given-names>L. G.</given-names></name><name><surname>Skinner</surname><given-names>M. W.</given-names></name></person-group> (<year>2013</year>) <article-title>Factors affecting open-set word recognition in adults with cochlear implants</article-title>. <source>Ear and Hearing</source>
<volume>34</volume>(<issue>3</issue>): <fpage>342</fpage>&#x02013;<lpage>360</lpage>. <comment>(PMID: 23348845)</comment>.<pub-id pub-id-type="pmid">23348845</pub-id></mixed-citation></ref><ref id="bibr15-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jones</surname><given-names>G. J.</given-names></name><name><surname>Drennan</surname><given-names>W. R.</given-names></name><name><surname>Rubinstein</surname><given-names>J. T.</given-names></name></person-group> (<year>2013</year>) <article-title>Relationship between channel interaction and spectral-ripple discrimination in cochlear implant users</article-title>. <source>Journal of the Acoustical Society of America</source>
<volume>133</volume>(<issue>1</issue>): <fpage>425</fpage>&#x02013;<lpage>433</lpage>. <comment>(PMID: 23297914)</comment>.<pub-id pub-id-type="pmid">23297914</pub-id></mixed-citation></ref><ref id="bibr16-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Levitt</surname><given-names>H.</given-names></name></person-group> (<year>1971</year>) <article-title>Transformed up-down methods in psychoacoustics</article-title>. <source>Journal of the Acoustical Society of America</source>
<volume>49</volume>: <fpage>467</fpage>&#x02013;<lpage>477</lpage>. <comment>(PMID: 5541744)</comment>.<pub-id pub-id-type="pmid">5541744</pub-id></mixed-citation></ref><ref id="bibr17-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Long</surname><given-names>C. J.</given-names></name><name><surname>Holden</surname><given-names>T. A.</given-names></name><name><surname>McClelland</surname><given-names>G. H.</given-names></name><name><surname>Parkinson</surname><given-names>W. S.</given-names></name><name><surname>Shelton</surname><given-names>C.</given-names></name><name><surname>Kelsall</surname><given-names>D. C.</given-names></name><name><surname>Smith</surname><given-names>Z. M.</given-names></name></person-group> (<year>2014</year>) <article-title>Examining the electro-neural interface of cochlear implant users using psychophysics, CT scans, and speech understanding</article-title>. <source>Journal of the Association for Research in Otolaryngology: JARO</source>
<volume>15</volume>(<issue>2</issue>): <fpage>293</fpage>&#x02013;<lpage>304</lpage>. <comment>(PMID: 24477546)</comment>.<pub-id pub-id-type="pmid">24477546</pub-id></mixed-citation></ref><ref id="bibr18-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nelson</surname><given-names>D. A.</given-names></name><name><surname>Donaldson</surname><given-names>G. S.</given-names></name><name><surname>Kreft</surname><given-names>H.</given-names></name></person-group> (<year>2008</year>) <article-title>Forward-masked spatial tuning curves in cochlear implant users</article-title>. <source>Journal of the Acoustical Society of America</source>
<volume>123</volume>: <fpage>1522</fpage>&#x02013;<lpage>1543</lpage>. <comment>(PMID: 18345841)</comment>.<pub-id pub-id-type="pmid">18345841</pub-id></mixed-citation></ref><ref id="bibr19-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noble</surname><given-names>J. H.</given-names></name><name><surname>Gifford</surname><given-names>R. H.</given-names></name><name><surname>Hedley-Williams</surname><given-names>A. J.</given-names></name><name><surname>Dawant</surname><given-names>B. M.</given-names></name><name><surname>Labadie</surname><given-names>R. F.</given-names></name></person-group> (<year>2014</year>) <article-title>Clinical evaluation of an imageguided cochlear implant programming strategy</article-title>. <source>Audiology and Neurotology</source>
<volume>19</volume>(<issue>6</issue>): <fpage>400</fpage>&#x02013;<lpage>411</lpage>. <comment>(PMID: 25402603)</comment>.<pub-id pub-id-type="pmid">25402603</pub-id></mixed-citation></ref><ref id="bibr20-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Noble</surname><given-names>J. H.</given-names></name><name><surname>Labadie</surname><given-names>R. F.</given-names></name><name><surname>Gifford</surname><given-names>R. H.</given-names></name><name><surname>Dawant</surname><given-names>B. M.</given-names></name></person-group> (<year>2013</year>) <article-title>Image-guidance enables new methods for customizing cochlear implant stimulation strategies</article-title>. <source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source>
<volume>21</volume>(<issue>5</issue>): <fpage>820</fpage>&#x02013;<lpage>829</lpage>. <comment>(PMID: 23529109)</comment>.<pub-id pub-id-type="pmid">23529109</pub-id></mixed-citation></ref><ref id="bibr21-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pfingst</surname><given-names>B. E.</given-names></name><name><surname>Xu</surname><given-names>L.</given-names></name><name><surname>Thompson</surname><given-names>C. S.</given-names></name></person-group> (<year>2004</year>) <article-title>Across-site threshold variation in cochlear implants: Relation to speech recognition</article-title>. <source>Audiology and Neuro-Otology</source>
<volume>9</volume>: <fpage>341</fpage>&#x02013;<lpage>352</lpage>.<pub-id pub-id-type="pmid">15467287</pub-id></mixed-citation></ref><ref id="bibr22-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Saleh</surname><given-names>S. M.</given-names></name><name><surname>Saeed</surname><given-names>S. R.</given-names></name><name><surname>Meerton</surname><given-names>L.</given-names></name><name><surname>Moore</surname><given-names>D. R.</given-names></name><name><surname>Vickers</surname><given-names>D. A.</given-names></name></person-group> (<year>2013</year>) <article-title>Clinical use of electrode differentiation to enhance programming of cochear implants</article-title>. <source>Cochlear Implants International</source>
<volume>14</volume>: <fpage>216</fpage>&#x02013;<lpage>218</lpage>. <comment>(PMID: PMID: 24533757)</comment>.</mixed-citation></ref><ref id="bibr23-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>R. V.</given-names></name><name><surname>Fu</surname><given-names>Q. J.</given-names></name><name><surname>Galvin</surname><given-names>J. J.</given-names><suffix>3rd.</suffix></name></person-group> (<year>2004</year>) <article-title>The number of spectral channels required for speech recognition depends on the difficulty of the listening situation</article-title>. <source>Acta oto-laryngologica</source>
<volume>552</volume>: <fpage>50</fpage>&#x02013;<lpage>54</lpage>. <comment>(PMID: 15219048)</comment>.</mixed-citation></ref><ref id="bibr24-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>R. V.</given-names></name><name><surname>Jensvold</surname><given-names>A.</given-names></name><name><surname>Padilla</surname><given-names>M.</given-names></name><name><surname>Robert</surname><given-names>M. E.</given-names></name><name><surname>Wang</surname><given-names>X.</given-names></name></person-group> (<year>1999</year>) <article-title>Consonant recordings for speech testing</article-title>. <source>Journal of the Acoustical Society of America</source>
<volume>106</volume>(<issue>6</issue>): <fpage>L71</fpage>&#x02013;<lpage>L74</lpage>.<pub-id pub-id-type="pmid">10615713</pub-id></mixed-citation></ref><ref id="bibr25-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shannon</surname><given-names>R. V.</given-names></name><name><surname>Zeng</surname><given-names>F. G.</given-names></name><name><surname>Kamath</surname><given-names>V.</given-names></name><name><surname>Wygonski</surname><given-names>J.</given-names></name><name><surname>Ekelid</surname><given-names>M.</given-names></name></person-group> (<year>1995</year>) <article-title>Speech recognition with primarily temporal cues</article-title>. <source>Science</source>
<volume>270</volume>(<issue>5234</issue>): <fpage>303</fpage>&#x02013;<lpage>304</lpage>. <comment>(PMID: 7569981)</comment>.<pub-id pub-id-type="pmid">7569981</pub-id></mixed-citation></ref><ref id="bibr26-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Srinivasan</surname><given-names>A. G.</given-names></name><name><surname>Padilla</surname><given-names>M.</given-names></name><name><surname>Shannon</surname><given-names>R. V.</given-names></name><name><surname>Landsberger</surname><given-names>D. M.</given-names></name></person-group> (<year>2013</year>) <article-title>Improving speech perception in noise with current focusing in cochlear implant users</article-title>. <source>Hearing Research</source>
<volume>299</volume>: <fpage>29</fpage>&#x02013;<lpage>36</lpage>. <comment>(PMID: 23467170)</comment>.<pub-id pub-id-type="pmid">23467170</pub-id></mixed-citation></ref><ref id="bibr27-2331216516653389"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Studebaker</surname><given-names>G. A.</given-names></name></person-group> (<year>1985</year>) <article-title>A &#x0201c;rationalized&#x0201d; arcsine transform</article-title>. <source>Journal of speech Hearing Research</source>
<volume>28</volume>(<issue>3</issue>): <fpage>455</fpage>&#x02013;<lpage>462</lpage>.<pub-id pub-id-type="pmid">4046587</pub-id></mixed-citation></ref><ref id="bibr103-1363460715620576"><mixed-citation publication-type="other">Zhou, N., &#x00026; Pfingst, B. E. (2012). Psychophysically-based site selection coupled with dichotic stimulation improves speech recognition in noise with bilateral cochlear implants. <italic>Journal of the Acoustical Society of America</italic>, <italic>132</italic>, 994&#x02013;1008.</mixed-citation></ref><ref id="bibr104-1363460715620576"><mixed-citation publication-type="other">Wright, R., &#x00026; Souza, P. (2012). Comparing identification of standardized and regionally valid vowels. <italic>J Speech Lang Hear Res</italic>, <italic>55</italic>(1), 182&#x02013;93.</mixed-citation></ref><ref id="bibr28-2331216516653389"><mixed-citation publication-type="other">Tyler, R., Preece, J., &#x00026; Tye-Murray, N. (1986). <italic>The Iowa audiovisual speech perception laser videodisc. Laser videodisc and Laboratory Report</italic>. Iowa City, IA: Department of Otolaryngology, Head and Neck Surgery, University of Iowa Hospital and Clinics.</mixed-citation></ref><ref id="bibr105-1363460715620576"><mixed-citation publication-type="other">Vickers, D. A., Degun, A., Canas, A., Stainsby, T., Vanpoucke, F. (2016). Deactivating Cochlear Implant Electrodes Based on Pitch Information for Users of the ACE Strategy. In: <italic>Advances in Experimental Medicine and Biology</italic>, Vol. 894, pp.115&#x02013;123. New York: Springer.</mixed-citation></ref></ref-list></back></article>