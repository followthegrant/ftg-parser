<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">eNeuro</journal-id><journal-id journal-id-type="iso-abbrev">eNeuro</journal-id><journal-id journal-id-type="hwp">eneuro</journal-id><journal-id journal-id-type="pmc">eneuro</journal-id><journal-id journal-id-type="publisher-id">eNeuro</journal-id><journal-title-group><journal-title>eNeuro</journal-title></journal-title-group><issn pub-type="epub">2373-2822</issn><publisher><publisher-name>Society for Neuroscience</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">29736410</article-id><article-id pub-id-type="pmc">5937112</article-id><article-id pub-id-type="doi">10.1523/ENEURO.0078-18.2018</article-id><article-id pub-id-type="publisher-id">eN-NWR-0078-18</article-id><article-categories><subj-group subj-group-type="hwp-journal-coll"><subject>8</subject><subject>8.1</subject></subj-group><subj-group subj-group-type="heading"><subject>New Research</subject><subj-group><subject>Sensory and Motor Systems</subject></subj-group></subj-group></article-categories><title-group><article-title>Sound Frequency Representation in the Auditory Cortex of the Common Marmoset Visualized Using Optical Intrinsic Signal Imaging</article-title><alt-title alt-title-type="left-running-head">Sound Frequency Map of Common Marmoset</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Tani</surname><given-names>Toshiki</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Abe</surname><given-names>Hiroshi</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref><xref ref-type="aff" rid="aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Hayami</surname><given-names>Taku</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff3"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Banno</surname><given-names>Taku</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff4"><sup>4</sup></xref></contrib><contrib contrib-type="author"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-5057-0333</contrib-id><name><surname>Miyakawa</surname><given-names>Naohisa</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff5"><sup>5</sup></xref></contrib><contrib contrib-type="author"><name><surname>Kitamura</surname><given-names>Naohito</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Mashiko</surname><given-names>Hiromi</given-names></name><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" corresp="yes"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-8323-4552</contrib-id><name><surname>Ichinohe</surname><given-names>Noritaka</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Suzuki</surname><given-names>Wataru</given-names></name><xref ref-type="aff" rid="aff2"><sup>2</sup></xref><xref ref-type="aff" rid="aff1"><sup>1</sup></xref></contrib><aff id="aff1"><label>1</label>Ichinohe Neural System Group, Laboratory for Molecular Analysis of Higher Brain Functions, <institution>RIKEN Brain Science Institute</institution>, Wako, Saitama 351-0198, <country>Japan</country>
</aff><aff id="aff2"><label>2</label>Department of Ultrastructural Research, National Institute of Neuroscience, <institution>National Center of Neurology and Psychiatry</institution>, Kodaira, Tokyo 187-8502, <country>Japan</country>
</aff><aff id="aff3"><label>3</label>Department of Biotechnology and Life Science, Graduate School of Engineering, <institution>Tokyo University of Agriculture and Technology</institution>, Koganei, Tokyo 184-8588, <country>Japan</country>
</aff><aff id="aff4"><label>4</label>Department of Otorhinolaryngology, <institution>University of Pennsylvania</institution>, Philadelphia, PA 19104</aff><aff id="aff5"><label>5</label>Department of Functional Brain Imaging Research, <institution>National Institutes of Quantum and Radiological Science and Technology</institution>, Chiba, Chiba 263-8555, <country>Japan</country>
</aff></contrib-group><author-notes><fn fn-type="other"><p>The authors declare no competing financial interests.</p></fn><fn fn-type="con"><p>Author contributions: T.T. and W.S. Designed research; W.S., T.T., H.A., T.H., T.B., and N.M. performed research; W.S., T.T., H.A., N.K., and H.M. analyzed data; W.S., T.T., and N.I. wrote the paper.</p></fn><fn fn-type="supported-by"><p>This work was supported by Grant-in-Aid for Scientific Research (C) (17K04512, 26430031), and the program for Brain Mapping by Integrated Neurotechnologies for Disease Studies (Brain/MINDS) from Japan Agency for Medical Research and Development (AMED), Japan.</p></fn><corresp id="cor1">Correspondence should be addressed to either of the following: Wataru Suzuki, Department of Ultrastructural Research, National Institute of Neuroscience, National Center of Neurology and Psychiatry, 4-1-1 Ogawa-Higashi, Kodaira, Tokyo, Japan, 187-8502, E-mail: <email>watarus@ncnp.go.jp</email>; or Noritaka Ichinohe, Department of Ultrastructural Research, National Institute of Neuroscience, National Center of Neurology and Psychiatry, 4-1-1 Ogawa-Higashi, Kodaira, Tokyo, Japan, 187-8502, E-mail: <email>nichino@ncnp.go.jp</email>.</corresp></author-notes><pub-date pub-type="epreprint"><day>25</day><month>4</month><year>2018</year></pub-date><pub-date pub-type="epub"><day>7</day><month>5</month><year>2018</year></pub-date><pub-date pub-type="collection"><season>Mar-Apr</season><year>2018</year></pub-date><volume>5</volume><issue>2</issue><elocation-id>ENEURO.0078-18.2018</elocation-id><history><date date-type="received"><day>20</day><month>2</month><year>2018</year></date><date date-type="rev-recd"><day>27</day><month>3</month><year>2018</year></date><date date-type="accepted"><day>29</day><month>3</month><year>2018</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2018 Tani et al.</copyright-statement><copyright-year>2018</copyright-year><copyright-holder>Tani et al.</copyright-holder><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open-access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International license</ext-link>, which permits unrestricted use, distribution and reproduction in any medium provided that the original work is properly attributed.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="ENEURO.0078-18.2018.pdf"/><self-uri xlink:role="icon" xlink:href="enu00218260500g1.jpg"/><abstract><title>Abstract</title><p>Natural sound is composed of various frequencies. Although the core region of the primate auditory cortex has functionally defined sound frequency preference maps, how the map is organized in the auditory areas of the belt and parabelt regions is not well known. In this study, we investigated the functional organizations of the core, belt, and parabelt regions encompassed by the lateral sulcus and the superior temporal sulcus in the common marmoset (<italic>Callithrix jacchus</italic>). Using optical intrinsic signal imaging, we obtained evoked responses to band-pass noise stimuli in a range of sound frequencies (0.5&#x02013;16 kHz) in anesthetized adult animals and visualized the preferred sound frequency map on the cortical surface. We characterized the functionally defined organization using histologically defined brain areas in the same animals. We found tonotopic representation of a set of sound frequencies (low to high) within the primary (A1), rostral (R), and rostrotemporal (RT) areas of the core region. In the belt region, the tonotopic representation existed only in the mediolateral (ML) area. This representation was symmetric with that found in A1 along the border between areas A1 and ML. The functional structure was not very clear in the anterolateral (AL) area. Low frequencies were mainly preferred in the rostrotemplatal (RTL) area, while high frequencies were preferred in the caudolateral (CL) area. There was a portion of the parabelt region that strongly responded to higher sound frequencies (&#x0003e;5.8 kHz) along the border between the rostral parabelt (RPB) and caudal parabelt (CPB) regions.</p></abstract><kwd-group><kwd>ECoG</kwd><kwd>histology</kwd><kwd>marmoset</kwd><kwd>optical imaging</kwd><kwd>sound frequency</kwd><kwd>tonotopy</kwd></kwd-group><funding-group><award-group><funding-source>Grant-in-Aid for Scientific Research (C)</funding-source><award-id>17K04512</award-id><award-id>26430031</award-id></award-group><award-group><funding-source>the program for Brain Mapping by Integrated Neurotechnologies for Disease Studies (Brain/MINDS) from Japan Agency for Medical Research and Development (AMED), Japan</funding-source></award-group></funding-group><counts><fig-count count="7"/><table-count count="2"/><equation-count count="5"/><ref-count count="37"/><page-count count="13"/><word-count count="7586"/></counts><custom-meta-group><custom-meta><meta-name>cover-date</meta-name><meta-value>March/April 2018</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="s1"><title>Significance Statement</title><p>In this study, we examined functional organizations for sound frequency representation in the core, belt, and parabelt regions in the marmoset using optical intrinsic signal imaging (OISI). In addition to the auditory areas in the core region, the mediolateral (ML) in the belt region continuously represented a range of frequencies from low to high, with tonotopic organization, which was symmetric to that in the primary (A1) area in the core region about the border between the A1 and ML. The posterior and anterior belt regions represented mainly high and low frequencies, respectively. The parabelt region contained a distinct region with preference for high frequencies. These results suggest that the functional organization unique to each auditory region would process sound information specific to this species.</p></sec><sec sec-type="intro" id="s2"><title>Introduction</title><p>Frequencies of sounds (voice, environmental sound, etc.) are represented in a systematic manner, e.g., tonotopic organization, in the auditory cortex. In areas with tonotopic organization, cells distribute over a cortical surface such that their preferred frequencies are continuously aligned from low to high. This organization has been found in the core region of the auditory cortex in humans and non-human primates (<xref rid="B15" ref-type="bibr">Formisano et al., 2003</xref>; <xref rid="B31" ref-type="bibr">Petkov et al., 2006</xref>; <xref rid="B16" ref-type="bibr">Humphries et al., 2010</xref>; <xref rid="B4" ref-type="bibr">Baumann et al., 2013</xref>). This area contains three smaller areas: the primary (A1), rostral (R), and rostrotemporal (RT) areas (<xref rid="B21" ref-type="bibr">Kaas and Hackett, 2000</xref>). The sound frequency preference gradient is reversed at the border between A1, R, and RT. This organization was revealed using sound frequency preference mapping, which is used to visualize the preferred frequency of cells on the cortical surface (<xref rid="B31" ref-type="bibr">Petkov et al., 2006</xref>; <xref rid="B6" ref-type="bibr">Bendor and Wang, 2008</xref>; <xref rid="B29" ref-type="bibr">Striem-Amit et al., 2011</xref>). Although previous studies have reported that the belt region also has a sound frequency preference gradient in macaque monkeys (<xref rid="B34" ref-type="bibr">Rauschecker and Tian, 2004</xref>; <xref rid="B31" ref-type="bibr">Petkov et al., 2006</xref>), the two-dimensional relationships between the individual areas in the belt regions are still unclear. The representation of sound frequency preference has not as yet been sufficiently studied in the parabelt regions. Because major parts of the auditory area are located in the lateral sulcus in humans and macaque monkeys, it is difficult to investigate the functional organization of the entire auditory area in detail. Furthermore, histologic areal demarcation in the auditory cortex is necessary to study the correspondence between functional organization and individual cortical areas. This has not been performed in most previous studies mapping the functional organization of this region.</p><p>The common marmoset (<italic>Callithrix jacchus</italic>) has well-developed vision and vocal communication and has been used in studies of the visual-related cortex (<xref rid="B24" ref-type="bibr">Mitchell et al., 2014</xref>; <xref rid="B17" ref-type="bibr">Hung et al., 2015</xref>; <xref rid="B35" ref-type="bibr">Suzuki et al., 2015a, 2015b</xref>; <xref rid="B25" ref-type="bibr">Miyakawa et al., 2017</xref>) and the auditory cortex (<xref rid="B13" ref-type="bibr">Eliades and Wang, 2008a, 2008b</xref>; <xref rid="B26" ref-type="bibr">Nelken et al., 2014</xref>; <xref rid="B2" ref-type="bibr">Agamaite et al., 2015</xref>; <xref rid="B23" ref-type="bibr">Miller et al., 2016</xref>; <xref rid="B1" ref-type="bibr">Abe et al., 2017</xref>). Because marmosets have lissencephalic and small brains, most areas of the auditory cortex in their brains are exposed on the cortical surface. This enables the relatively easy simultaneous imaging of these areas (<xref rid="B37" ref-type="bibr">Tokuno et al., 2009</xref>; <xref rid="B30" ref-type="bibr">Paxinos et al., 2012</xref>). Taking advantage of this fact, we investigated the cortical representation of sound frequency in a major portion of the auditory area of a small New World monkey, the common marmoset. <xref rid="B27" ref-type="bibr">Nishimura et al. (2017)</xref> have performed optical imaging using a voltage-sensitive dye in the common marmoset and obtained function signals in response to sound frequency. However, they did not perform histologic studies. It was thus difficult to conclusively demonstrate a rigorous relationship between the imaging data and the auditory area in that study. Here, we visualized the functional organization of the entire auditory cortex using optical intrinsic signal imaging (OISI), which is used to measure cortical responses with higher spatial resolution (20&#x02013;30 &#x000b5;m) than that of other functional techniques [e.g., functional magnetic resonance imaging (fMRI): &#x0223c;1 mm; <xref rid="B8" ref-type="bibr">Cohen, 1973</xref>, <xref rid="B7" ref-type="bibr">Bonhoeffer and Grinvald, 1996</xref>]. We were thus able to directly compare the functional signals to the histologic areal demarcation data. We obtained evoked responses to band-pass noise stimuli in a range of sound frequencies (0.5&#x02013;16 kHz) in anesthetized adult animals and revealed functional organizations by mapping the preferred frequency in each area in the core, belt, and parabelt regions of the auditory cortex.</p></sec><sec sec-type="materials|methods" id="s3"><title>Materials and Methods</title><p>Experiments were performed using three adult common marmosets (one male and two females; body weight: 300&#x02013;400 g). The surgical procedure, optical imaging, and electrocorticogram (ECoG) recording were approved by the Institutional Animal Research Committee at RIKEN (No. H13-B040) and the Experimental Animal Committee of the National Institute of Neurology and Psychiatry and were performed in accordance with the Guiding Principles for the Care and Use of Animals in the Field of Physiologic Science of the Japanese Physiologic Society.</p><sec id="s3A"><title>Surgery</title><p>The surgeries were conducted under anesthesia induced by an intramuscular injection of ketamine hydrochloride (Ketalar, 25 mg/kg) following an intramuscular injection of atropine sulfate (0.15 &#x003bc;g/kg). The animal was artificially ventilated with a mixture of 70&#x02013;50% N<sub>2</sub>O, 30&#x02013;50% O<sub>2</sub>, and 1.0&#x02013;2.0% isoflurane. Electrocardiograms, end-tidal CO<sub>2</sub>, and rectal temperature were monitored continuously.</p><p>A head holder and a recording chamber (inside diameter: 18 mm) were implanted on the skull, and a craniotomy and a durotomy were performed inside the recording chamber to expose the auditory cortex for the OISI and the ECoG recordings.</p></sec><sec id="s3B"><title>Acoustic stimuli</title><p>All of the acoustic stimuli were generated using MATLAB (MathWorks) and saved in uncompressed audio file format (100-kHz sampling frequency, 16 bits, mono). The sound delivery system was calibrated with 1/2-octave band-passed noises ranging from 0.5&#x02013;16 kHz (1/2-octave step; 80-dB sound pressure level) using a noise meter (Sound level meter NL-27, RION). The sound stimuli were presented by a speaker system (BSSP10, iBUFFALO) placed 57 cm in front of the animal&#x02019;s head.</p></sec><sec id="s3C"><title>OISI</title><p>Following the surgeries, OISI was conducted under anesthesia maintained with an intravenous infusion of remifentanil (Ultiva, 0.1 &#x003bc;g/kg/min). During the recordings, muscular paralysis was induced with rocuronium bromide (Eslax, 13 &#x003bc;g/kg/min, i.v.). The recording chamber was filled with 0.5% agarose gel and sealed with a glass coverslip to minimize the movement of the brain due to respiration and cardiovascular pulses. A charge-coupled device (CCD; GRAS-03K2M-C, forward-looking infrared, Integrated Imaging Solutions Inc.) with 640 &#x000d7; 480-pixel resolution and 14-bit depth was used to obtain images reflected from the cortical surface. The cortex was illuminated by a band-pass filtered (535 &#x000b1; 30 nm) halogen lamp through two fiber optic bundles. The CCD camera was focused on a plane 600 &#x000b5;m below the cortical surface (approximately layer 3) to avoid blood vessel artifacts, although the noise from the blood vessels at 535-nm wavelength was too high to completely remove the artifacts. The imaging data were acquired at a frame rate of 30 Hz during 10-s trials in which the 2-s auditory stimuli were presented from a loudspeaker starting 2 s after recording onset. The 2-s auditory stimulus was composed of the band-passed noises, with 100-ms on and 100-ms off. The stimulus duration of 100-ms is ordinary for electrophysiological experiments and was repeated 10 times in a trial to evoke strong responses.</p><p>The stimulus set consisted of &#x000bd;-octave band-passed noises centered at 11 frequencies (0.5, 0.7, 1, 1.4, 2, 2.8, 4, 5.7, 8, 11.3, and 16 kHz). Each stimulus was presented 20&#x02013;25 times in pseudorandom order with 20-s interstimulus intervals.</p></sec><sec id="s3D"><title>ECoG recordings</title><p>Using the OISI results as a guide, we placed a multi-contact ECoG electrode (E32-1000-30-200, NeuroNexus) on the auditory cortex. The distances between neighboring contacts were 1 mm. The neural signals were amplified, band-pass filtered between 0.3 and 3 kHz, and stored at a 25-kHz sampling resolution into a TDT signal processing system (RZ2; Tucker-Davis Technologies). The digital time-stamps of the acoustic stimulus presentations were also stored.</p></sec><sec id="s3E"><title>Data analysis</title><p>Intrinsic optical signals evoked by the stimuli were defined based on changes in the backscattered light following auditory stimulus presentation. The change at position <italic>(x, y)</italic> of an image at time t, <inline-formula id="IE1"><mml:math id="i1"><mml:mrow><mml:mfrac><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi mathvariant="italic">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="italic">R</mml:mi></mml:mrow></mml:mfrac></mml:mrow></mml:math></inline-formula>
<italic>(x, y, t)</italic>, was obtained using the following equation:<disp-formula id="E1"><mml:math id="m1"><mml:mfrac><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow></mml:mfrac><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">t</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x02013;</mml:mo><mml:mfenced open="&#x03008;" close="&#x03009;" separators="|"><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mfenced open="&#x03008;" close="&#x03009;" separators="|"><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:math></disp-formula>where <italic>R(x, y, t)</italic> is the backscattered light (pixel luminance value). The bracket indicates the mean of the backscattered light at position <italic>(x, y)</italic> for the 2-s period before the stimulus presentation. The changes were further averaged across the 20-25 presentation times for each stimulus. The wavelength of 535 nm used for illumination is an isosbestic point for absorption of oxy- and deoxyhemoglobin. Thus, following neural activation, the optical signal decreased due to the change in cerebral blood flow containing oxy- and deoxyhemoglobin.</p><p>To evaluate how the sound stimuli used in this study were effective for each auditory cortical area, the magnitude of the optical signals was calculated using the following equation:<disp-formula id="E2"><mml:math id="m2"><mml:mi>M</mml:mi><mml:mi>a</mml:mi><mml:mi>g</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:mrow><mml:munder><mml:mrow><mml:mi mathvariant="normal">max</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>11</mml:mn></mml:mrow></mml:munder></mml:mrow><mml:mo>&#x02061;</mml:mo><mml:mrow><mml:mfenced open="|" close="|" separators="|"><mml:mrow><mml:mfrac><mml:mrow><mml:msub><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x02013;</mml:mo><mml:mfenced open="&#x03008;" close="&#x03009;" separators="|"><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mfenced open="&#x03008;" close="&#x03009;" separators="|"><mml:mrow><mml:mi mathvariant="normal">R</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfenced></mml:mrow><mml:mrow><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>where <italic>R<sub>i</sub>(x, y)</italic> was the backscattered light to i-th sound frequency averaged 4 s after stimulus onset.</p><p>The frequency preference map was created by calculating the expected values of the 11 sound frequencies for each pixel:<disp-formula id="E3"><mml:math id="m3"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mfenced><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo stretchy="false">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:munderover><mml:mrow><mml:mfrac><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mfenced><mml:mo>&#x000d7;</mml:mo><mml:mfrac><mml:mrow><mml:mi mathvariant="normal">f</mml:mi><mml:mo>(</mml:mo><mml:mi mathvariant="normal">i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mn>11</mml:mn></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>where <inline-formula id="IE2"><mml:math id="i2"><mml:mfrac><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi mathvariant="normal">R</mml:mi></mml:mrow><mml:mrow><mml:mi>i</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac><mml:mfenced separators="|"><mml:mrow><mml:mi mathvariant="normal">x</mml:mi><mml:mo>,</mml:mo><mml:mi mathvariant="normal">y</mml:mi></mml:mrow></mml:mfenced></mml:math></inline-formula> is the optical signal to i-th sound frequency averaged 4 s after stimulus onset and <italic>f(i)</italic> is the i-th sound frequency (i = 1, &#x02026;, 11). Note that the preferred sound frequency was a continuous real number.</p><p>The significant biased number of pixels that responded to a specific sound frequency in each area was evaluated using a bootstrap method. The preferred sound frequency was quantized to 10 steps (0.5&#x02013;0.7, 0.7&#x02013;1, 1&#x02013;1.4, 1.4&#x02013;2, 2&#x02013;2.8, 2.8&#x02013;4, 4&#x02013;5.7, 5.7&#x02013;8, 8&#x02013;11.3, and 11.3&#x02013;16 kHz). The number of pixels with the preferred sound frequency that were randomly placed in the auditory cortex was counted for each auditory area and iterated 1000 times. When the ratio of the original number to the pixels in each auditory area for a specific preferred sound frequency was &#x0003e;95% of the distribution of the ratio for the sound frequency with random sampling, the area was considered to have significantly biased representation for the specific sound frequency. We conducted the same analysis in each auditory region.</p></sec><sec id="s3F"><title>Histology</title><p>After the end of the recording, an amount of sodium pentobarbital leading to an overdose (Somnopentyl; 75 mg/kg) was injected intraperitoneally, and the animals were intracardially perfused with saline followed by 4% paraformaldehyde (PFA). The brain was removed and post-fixed in 4% PFA overnight. The brain was then sequentially cryoprotected in 10%, 20%, and 30% sucrose in 0.1 M phosphate buffer.</p><p>The brains were coronally sectioned at a thickness of 50 &#x000b5;m using a freezing microtome (SM2010R, Leica). The processed sections were mounted on silan-coated slide glasses. For histologic processing, brain sections from one marmoset were divided into two series and mounted on glass slides. Odd-numbered sections underwent myelin staining, while even-numbered sections underwent Nissl staining. The staining was performed after we obtained fluorescent images from the sections. Brain sections from another marmoset were divided into three series. Two series of sections underwent myelin and Nissl staining, respectively. The third series of sections underwent fluorescent imaging after staining with DiI. Brain sections from third marmoset were divided into four series. Three series of sections underwent myelin, Nissl, and DiI staining. The fourth series of sections were left as reserve. All of the mounted sections were scanned using a digital slide scanner (NanoZoomer 2.0-HT, Hamamatsu Photonics K.K.; 20&#x000d7; objective, 455 nm/pixel). The tissues were silver-stained for myelin using an auto-metallographic technique described elsewhere (<xref rid="B33" ref-type="bibr">Pistorio et al., 2006</xref>). The sections stained for myelin were dehydrated in graded ethanol solutions, immersed in xylene, and cover-slipped in DPX (Sigma-Aldrich Co or Merck).</p><p>To delineate the areal borders in the auditory cortex based on the myeloarchitecture and cytoarchitecture in the coronal sections, we referred to previously published literature (<xref rid="B3" ref-type="bibr">Aitkin et al., 1986</xref>; <xref rid="B10" ref-type="bibr">de la Mothe et al., 2006b</xref>; <xref rid="B30" ref-type="bibr">Paxinos et al., 2012</xref>). For example, myelin was densest in the A1, and the borders between the A1 and neighboring areas could be easily defined in the coronal sections (<xref ref-type="fig" rid="F1">Fig. 1</xref>). The large blood vessels on the cortical surface in the coronal sections were used as landmarks and the positions of the areal borders were identified with reference to the blood vessels. Subsequently, the blood vessels in the coronal sections were superimposed on the image obtained by the CCD camera used in the OISI experiment. The areal borders were reconstructed on the image and the sound frequency preference maps. Regions of interest were delimited by the histologically determined areal border.</p><fig id="F1" fig-type="figure" orientation="portrait" position="float"><label>Figure 1.</label><caption><p>
Coronal sections from the left hemisphere of a marmoset stained for myelin and the areal demarcation of the auditory cortical areas. Auditory cortical areas are defined by the myelin structure. The white lines indicate the areal borders. The black filled circles represent positions of blood vessels. The filled and open white arrowheads indicate the lateral sulcus and the superior temporal sulcus, respectively.</p></caption><graphic xlink:href="enu0021826050001"/></fig></sec></sec><sec sec-type="results" id="s4"><title>Results</title><sec id="s4A"><title>Responsiveness to band-pass noise stimuli in each auditory area in the core, belt, and parabelt regions</title><p>Intrinsic optical signals evoked by band-pass noise stimuli were clearly observed in the core, belt, and parabelt regions in all three marmosets. The spatial locations of the optical signal distribution in response to the 11 sound frequencies with centers of 0.5, 0.7, 1, 1.4, 2, 2.9, 4, 5.8, 8, 11.6, and 16 kHz systematically changed on the cortical surface in different manners in the core, belt, and parabelt regions (<xref ref-type="fig" rid="F2">Fig. 2</xref>). In the core region, when the sound frequency gradually changed from low to high, the corresponding responsive region continuously moved on the cortical surface. The regions responsive to stimuli with low to high frequencies mapped on the cortical surface from the antero-ventral to postero-dorsal direction in A1 and RT, and from the postero-ventral to antero-dorsal direction in R. A complete set of sound frequencies (from low to high) seemed to be represented in each area (A1, R, and RT). These results are consistent with those of previous electrophysiological studies performed in marmosets, in which unit recordings performed to map the best sound frequency showed a similar direction of continuous changes and complete representation of sound frequencies in the core region (<xref rid="B3" ref-type="bibr">Aitkin et al., 1986</xref>; <xref rid="B6" ref-type="bibr">Bendor and Wang, 2008</xref>).</p><fig id="F2" fig-type="figure" orientation="portrait" position="float"><label>Figure 2.</label><caption><p>Optical responses to sound frequencies in the auditory cortex of the marmoset shown in Figure 1. A single condition map was reconstructed based on the optical signal changes in response to sound frequencies of 0.5, 0.7, 1, 1.4, 2, 2.9, 4, 5.8, 8, 11.6, and 16 kHz. The response magnitude is indicated by the gray scale shown at the left bottom. The black and white regions indicate the highest and lowest response magnitudes, respectively. The white lines represent the histologically defined areal borders of the auditory cortex.</p></caption><graphic xlink:href="enu0021826050002"/></fig><p>In the mediolateral (ML) area of the belt region, the regions responsive to sound stimuli increasing in frequency from low to high continuously mapped in the antero-dorsal to postero-ventral direction. The remaining areas of the belt region, however, had biases for low or high frequencies. The regions responsive to low<strike>er</strike> frequencies (1.4&#x02013;2.9 kHz) extended over the border between ML and A1. The regions responsive only to low frequencies were found in the anterolateral (AL) and rostrotemplatal (RTL) areas, and those responsive only to high frequencies were found in the caudolateral area (CL). In the parabelt region, there was no continuous mapping of the frequencies to the cortical surface. A region strongly responsive to high frequencies (&#x0003e;5.8 kHz) was present around the border between the rostral parabelt (RPB) and caudal parabelt (CPB) area. This is consistent with the findings of previous electrophysiological studies in macaque monkeys, in which multi-unit recordings suggested that cells in the parabelt region which preferred high frequency clustered in the superior temporal gyrus (<xref rid="B20" ref-type="bibr">Kajikawa et al., 2015</xref>).</p><p>Although the band-pass noise stimuli used in this study evoked intrinsic optical signals in each region, their response properties were different among the auditory cortical areas. <xref ref-type="fig" rid="F3">Figure 3<italic>A&#x02013;C</italic></xref> shows the response magnitude map (top) and the mean response magnitude in each area (bottom) for the three marmosets. Optical responses to the band-pass noise stimuli, which were estimated based on the magnitudes of the optical signals (Mag(x, y)) averaged over each area, were strong in the A1, R, ML, and AL regions, and weak in the RT, RTL, and CL regions in all marmosets (<xref ref-type="table" rid="T1">Table 1</xref>). In the parabelt region, the mean response magnitude was generally low in all marmosets (<xref ref-type="table" rid="T1">Table 1</xref>), although there were some regions with high response magnitudes, e.g., regions around the border between RPB and CPB. The time courses of the optical signals evoked in response to each sound frequency at the six positions on the response magnitude map are shown in <xref ref-type="fig" rid="F3">Figure 3<italic>D</italic></xref>. There was clear selectivity for sound frequency, even at positions with small amplitudes.</p><fig id="F3" fig-type="figure" orientation="portrait" position="float"><label>Figure 3.</label><caption><p>Response magnitude maps and the mean response magnitude in each auditory area for the three marmosets. <bold><italic>A&#x02013;C</italic></bold>, top, Response magnitude maps reconstructed based on maximum evoked optical signals for sound frequencies of 0.5, 0.7, 1, 1.4, 2, 2.9, 4, 5.8, 8, 11.6, and 16 kHz for each marmoset. The color indicates the maximum signal magnitude at each pixel according to scale bar shown in <bold><italic>A</italic></bold>. Blood vessel images for each map are shown in the inset. Bottom, The mean response magnitude and SD in each auditory area. LS and STS represent the lateral sulcus and superior temporal sulcus, respectively. <bold><italic>D</italic></bold>, Time course of optical signals in response to each stimulus frequency in the six regions indicated in <bold><italic>A</italic></bold>. The colors of the lines correspond to the optical signal evoked for each frequency. The vertical black lines and horizontal red lines represent stimulus onset and the stimulus presentation period, respectively.</p></caption><graphic xlink:href="enu0021826050003"/></fig><table-wrap id="T1" orientation="portrait" position="float"><label>Table 1.</label><caption><p>The magnitude of the optical signals % (mean &#x000b1; SD) in each auditory area</p></caption><table frame="hsides" rules="none"><colgroup span="1"><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Subject</th><th align="left" rowspan="1" colspan="1">A1</th><th align="left" rowspan="1" colspan="1">R</th><th align="left" rowspan="1" colspan="1">RT</th><th align="left" rowspan="1" colspan="1">CL</th><th align="left" rowspan="1" colspan="1">ML</th><th align="left" rowspan="1" colspan="1">AL</th><th align="left" rowspan="1" colspan="1">RTL</th><th align="left" rowspan="1" colspan="1">CPB</th><th align="left" rowspan="1" colspan="1">RPB</th></tr></thead><tbody valign="top"><tr><td rowspan="1" colspan="1">Marmoset 1</td><td rowspan="1" colspan="1">1.1 &#x000b1; 0.4</td><td rowspan="1" colspan="1">0.9 &#x000b1; 0.4</td><td rowspan="1" colspan="1">0.5 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.5 &#x000b1; 0.2</td><td rowspan="1" colspan="1">1.1 &#x000b1; 0.3</td><td rowspan="1" colspan="1">1.2 &#x000b1; 0.3</td><td rowspan="1" colspan="1">0.6 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.6 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.6 &#x000b1; 0.2</td></tr><tr><td rowspan="1" colspan="1">Marmoset 2</td><td rowspan="1" colspan="1">0.5 &#x000b1; 0.3</td><td rowspan="1" colspan="1">0.5 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.5 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.3 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.7 &#x000b1; 0.1</td><td rowspan="1" colspan="1">0.4 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.6 &#x000b1; 0.1</td><td rowspan="1" colspan="1">0.2 &#x000b1; 0.1</td><td rowspan="1" colspan="1">0.2 &#x000b1; 0.1</td></tr><tr><td rowspan="1" colspan="1">Marmoset 3</td><td rowspan="1" colspan="1">1.0 &#x000b1; 0.4</td><td rowspan="1" colspan="1">0.6 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.5 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.5 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.9 &#x000b1; 0.3</td><td rowspan="1" colspan="1">0.6 &#x000b1; 0.1</td><td rowspan="1" colspan="1">0.5 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.5 &#x000b1; 0.2</td><td rowspan="1" colspan="1">0.3 &#x000b1; 0.1</td></tr></tbody></table></table-wrap></sec><sec id="s4B"><title>Organization of sound frequency preference</title><p>A frequency preference map in which the optical signals were averaged across the 11 sound frequencies at each pixel (<italic>pref(x, y)</italic>, defined in the materials and methods section) was used to estimate the representation of sound frequency in the auditory cortical areas (<xref ref-type="fig" rid="F4">Fig. 4<italic>A&#x02013;C</italic></xref>). In the core region, a gradient of sound frequency preference was observed for all frequencies with the exception of those lower than 1.4 kHz. This gradient was reversed at A1/R and R/RT borders. No regions with preference for stimuli with frequencies higher than 8 kHz were observed at the R/RT border. This is likely because this region is within the lateral sulcus (<xref rid="B5" ref-type="bibr">Bendor and Wang, 2005, 2008</xref>). Therefore, with the exception mentioned above, the three complete sets of sound frequencies are thought to be represented in the A1, R, and RT regions.</p><fig id="F4" fig-type="figure" orientation="portrait" position="float"><label>Figure 4.</label><caption><p>Sound frequency preference maps for the three marmosets. <bold><italic>A&#x02013;C</italic></bold>, Sound frequency preference maps reconstructed from averaged responses for all sound frequencies for the three marmosets. The color indicates the preferred frequency at each pixel according to the color code. LS and STS represent the lateral sulcus and superior temporal sulcus, respectively.</p></caption><graphic xlink:href="enu0021826050004"/></fig><p>In the belt region, there was only one area (ML) with a representation of the complete set of frequencies, with the exception of frequencies lower than 1.4 kHz. The topographical organization in this region was symmetric to that in A1 about the border between A1 and ML. In AL, the distribution of the preferred frequencies varied among three of the animals. There was a region with preference for high frequencies that protruded from the parabelt in two animals (<xref ref-type="fig" rid="F4">Fig. 4<italic>B</italic>,<italic>C</italic></xref>). The RTL mainly contained areas with preference for low frequencies and the CL had preference for high frequencies in all animals. There was a region that strongly responded to higher sound frequencies (&#x0003e;5.8 kHz) located around the middle part of the parabelt region in the rostro-caudal direction. This region was located mainly in the CPB in marmoset 1 and 3 and in the RPB in marmoset 2. In marmoset 1 and 3, regions with preference for high frequencies also existed in the anterior part of the RPB, which was distinct from the regions preferring high frequencies at the border between RPB and CPB. These anterior regions of the RPB were not found in marmoset 2, probably because the recording area did not include the anterior part of the RPB in this animal. These results indicate that the organization of sound frequency preference had different spatial arrangements among the core, belt, and parabelt regions, with some variance between individual animals.</p><p>To quantify the sound frequency preference described above, we counted the number of the pixels for each preferred sound frequency in each auditory area and calculated the ratio of this number to that of all pixels in each area (<xref ref-type="fig" rid="F5">Fig. 5<italic>A</italic></xref>). The number of pixels used for each area in this analysis has been summarized in <xref ref-type="table" rid="T2">Table 2</xref>. If the ratio was widely and equally distributed along the preferred sound frequency range in an area, then the area was thought to represent a complete set of sound frequencies. As indicated in <xref ref-type="fig" rid="F2">Figure 2</xref>, wide ranges of preferred sound frequencies, with the exception of frequencies lower than 1.4 kHz, were observed in A1, R, RT, and ML. However, there was a slight preference for high sound frequencies in R and RT, as shown in <xref ref-type="fig" rid="F2">Figure 2</xref>. The distribution of the ratio was slightly biased toward low sound frequencies in RTL. The distribution was biased toward high<strike>er</strike> frequencies in CL, CPB, and RPB.</p><fig id="F5" fig-type="figure" orientation="portrait" position="float"><label>Figure 5.</label><caption><p>Distribution of preferred sound frequencies in each auditory cortical area. A: relative areas with preference for sound frequencies of 0.5&#x02013;0.7, 0.7&#x02013;1, 1&#x02013;1.4, 1.4&#x02013;2, 2&#x02013;2.9, 2.9&#x02013;4, 4&#x02013;5.8, 5.8&#x02013;8, 8&#x02013;11.6, and 11.6&#x02013;16 kHz. <bold><italic>B</italic></bold>, Relative areas with preference for different sound frequencies in the core, belt, and parabelt regions. The pale blue, orange, and gray lines represent the three individual marmosets, and the black line represents the mean value for the three marmosets. The number of asterisks represent the number of animals with significantly biased representation in response to the sound frequency.</p></caption><graphic xlink:href="enu0021826050005"/></fig><table-wrap id="T2" orientation="portrait" position="float"><label>Table 2.</label><caption><p>The number of pixels for each defined auditory area</p></caption><table frame="hsides" rules="none"><colgroup span="1"><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/><col align="left" valign="top" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Subject</th><th align="left" rowspan="1" colspan="1">A1</th><th align="left" rowspan="1" colspan="1">R</th><th align="left" rowspan="1" colspan="1">RT</th><th align="left" rowspan="1" colspan="1">CL</th><th align="left" rowspan="1" colspan="1">ML</th><th align="left" rowspan="1" colspan="1">AL</th><th align="left" rowspan="1" colspan="1">RTL</th><th align="left" rowspan="1" colspan="1">CPB</th><th align="left" rowspan="1" colspan="1">RPB</th></tr></thead><tbody valign="top"><tr><td rowspan="1" colspan="1">Marmoset 1</td><td rowspan="1" colspan="1">14169</td><td rowspan="1" colspan="1">6961</td><td rowspan="1" colspan="1">4539</td><td rowspan="1" colspan="1">6690</td><td rowspan="1" colspan="1">11398</td><td rowspan="1" colspan="1">6180</td><td rowspan="1" colspan="1">6153</td><td rowspan="1" colspan="1">18074</td><td rowspan="1" colspan="1">18897</td></tr><tr><td rowspan="1" colspan="1">Marmoset 2</td><td rowspan="1" colspan="1">9417</td><td rowspan="1" colspan="1">5290</td><td rowspan="1" colspan="1">2018</td><td rowspan="1" colspan="1">5092</td><td rowspan="1" colspan="1">9072</td><td rowspan="1" colspan="1">5320</td><td rowspan="1" colspan="1">2247</td><td rowspan="1" colspan="1">16184</td><td rowspan="1" colspan="1">8828</td></tr><tr><td rowspan="1" colspan="1">Marmoset 3</td><td rowspan="1" colspan="1">12616</td><td rowspan="1" colspan="1">6660</td><td rowspan="1" colspan="1">3496</td><td rowspan="1" colspan="1">6709</td><td rowspan="1" colspan="1">11482</td><td rowspan="1" colspan="1">4935</td><td rowspan="1" colspan="1">5172</td><td rowspan="1" colspan="1">21342</td><td rowspan="1" colspan="1">22588</td></tr></tbody></table></table-wrap><p>We compared the preferred sound frequencies among the core, belt, and parabelt regions (<xref ref-type="fig" rid="F5">Fig. 5<italic>B</italic></xref>). Complete sets of sound frequencies, with the exception of frequencies lower than 1.4 kHz, were observed in both the core and belt regions. In the core regions, the sound frequency preference tended to have a peak in the middle frequency range, probably due to less preference for high frequencies in R and RT. In the parabelt regions, the distribution of sound frequencies was biased toward high frequencies. These results suggest that the core and belt regions contain representations of a wide range of sound frequencies, while the parabelt region may have specialized areas to process mainly high sound frequencies.</p></sec><sec id="s4C"><title>Comparison between optical and electrical signals</title><p>Finally, to confirm that the optical responses to sound frequencies reflected the neuronal responses, we compared the optical signals and the electrical response to the same sound stimuli in one animal (marmoset 3). <xref ref-type="fig" rid="F6">Figure 6<italic>A</italic></xref> shows an example of a local field potential in marmoset 3 at four ECoG contacts evoked by the band-pass noise stimuli used in the optical recording experiments. The local field potentials at positions 1 and 4 showed large responses to low and high frequencies, respectively. We constructed sound frequency preference maps with maximum responses to the 11 sound frequencies at all ECoG contacts. The sound frequency preference map for the ECoG recording was consistent with that for OISI (<xref ref-type="fig" rid="F6">Fig. 6<italic>B</italic></xref>).</p><fig id="F6" fig-type="figure" orientation="portrait" position="float"><label>Figure 6.</label><caption><p>Electrical responses to band-pass noise stimuli. <bold><italic>A</italic></bold>, ECoG responses to sound frequencies of 1.4, 4, 8, and 16 kHz at four contacts. The horizontal red lines represent the stimulus presentation period. <bold><italic>B</italic></bold>, left, Electrode positions of the ECoG device on the sound frequency preference map made based on OISI in Figure 4<italic>C</italic>. Green circles represent the contact positions shown in <bold><italic>A</italic></bold>. The brown circles correspond to the remaining contacts. LS and STS represent the lateral sulcus and superior temporal sulcus, respectively. Right, Sound frequency preference map reconstructed based on the maximum ECoG responses to all sound frequencies. Color indicates the preferred sound frequency at each contact according to the color code.</p></caption><graphic xlink:href="enu0021826050006"/></fig></sec></sec><sec sec-type="discussion" id="s5"><title>Discussion</title><p>In this study, we investigated the functional organization of sound frequency representation in a large area encompassed by the lateral sulcus and the superior temporal sulcus, including the core, belt, and parabelt regions in a small New World monkey, the common marmoset. We used OISI with reference to histologic areal demarcation. The auditory cortical areas A1, R, and RT in the core region and ML in the belt region responded to a range of sound frequencies from low to high with tonotopic organization. In the belt region, the RTL responded mainly to low frequencies, while the CL responded to high frequencies. Thus, the core and belt regions overall represented a complete set of the sound frequencies from low to high. In the parabelt region, the sound frequency preference was biased toward high sound frequencies. We have summarized our results in a sound frequency preference map for common marmosets (<xref ref-type="fig" rid="F7">Fig. 7</xref>).</p><fig id="F7" fig-type="figure" orientation="portrait" position="float"><label>Figure 7.</label><caption><p>Sound frequency preference map for common marmosets. The circles surrounding H and L indicate regions with preference for high and low frequencies, respectively. The arrows indicate the direction of frequency preference change from low to high. The dotted region represents regions requiring further study. LS and STS represent the lateral sulcus and superior temporal sulcus, respectively. The color map in the simplified schematic of the marmoset cortex in the inset represents the sound frequency preference map.</p></caption><graphic xlink:href="enu0021826050007"/></fig><sec id="s5A"><title>Optical signals evoked by band-pass noise stimuli</title><p>We used band-pass noise stimuli with low to high sound frequency to evoke the cortical responses. Although the band-pass noise stimuli were simple sounds, optical signals to the stimuli were evoked not only in the core and belt regions, but also in the parabelt region. Electrophysiological studies have shown that neurons in the core region of the monkey auditory cortex respond to pure tones with various sound frequencies, as well as band-pass noise stimuli (<xref rid="B3" ref-type="bibr">Aitkin et al., 1986</xref>; <xref rid="B5" ref-type="bibr">Bendor and Wang, 2005, 2008</xref>; <xref rid="B18" ref-type="bibr">Kajikawa et al., 2005, 2011</xref>; <xref rid="B32" ref-type="bibr">Philibert et al., 2005</xref>). A fMRI study has also shown that these stimuli activate the core and belt regions of the auditory cortex in humans and monkeys (<xref rid="B31" ref-type="bibr">Petkov et al., 2006</xref>; <xref rid="B22" ref-type="bibr">Leaver and Rauschecker, 2016</xref>). The response magnitudes of intrinsic signals to band-pass noise stimuli were larger in the A1 and R areas of the core region and the ML and AL areas of the belt region than in the other auditory cortical areas. The A1 and R regions have focal topographic connections to the auditory thalamus with tonotopic organization. The A1 sends outputs to the ML and AL (<xref rid="B9" ref-type="bibr">de la Mothe et al., 2006a</xref>, <xref rid="B10" ref-type="bibr">2006b</xref>, <xref rid="B11" ref-type="bibr">2012a</xref>, <xref rid="B12" ref-type="bibr">2012b</xref>). Thus, spectral analysis of acoustic stimuli might be massively processed in the A1, R, ML, and AL.</p><p>Although sound frequencies lower than 1.4 kHz evoked optical signals in line with the tonotopic organization shown in <xref ref-type="fig" rid="F2">Figure 2</xref>, their contributions to the functional organization seemed to be small (<xref ref-type="fig" rid="F4">Fig. 4</xref>). The ECoG results indicated that even sound stimuli lower than 1.4 kHz clearly elicited neuronal activity, as shown in <xref ref-type="fig" rid="F6">Figure 6<italic>B</italic></xref>. Thus, the insensitivity of the optical signals to low sound frequencies would be reflected in OISI. This is a limitation of the methods used here. We used the wavelength of 535 nm for illumination to the cortex which was reported the effectiveness for auditory optical imaging (<xref rid="B28" ref-type="bibr">Ojima et al., 2005</xref>). Noise, however, from the blood vessels with this wavelength was quite larger than that with the other wavelength, e.g., 630 nm. Further studies are necessary to map complete preferred frequency distribution including the low sound frequency.</p><p>In the parabelt region, although the response magnitude was low in general, there were small regions with higher response magnitudes around the RPB/CPB border. There was a tendency toward preference for high frequencies in these regions (<xref ref-type="fig" rid="F3">Figs. 3</xref>, <xref ref-type="fig" rid="F4">4</xref>). Interestingly, relatively simple sound stimuli activated the parabelt region, which was thought to be a higher auditory area in macaque monkeys (<xref rid="B21" ref-type="bibr">Kaas and Hackett, 2000</xref>). This suggests that acoustic stimuli with high frequencies can be analyzed more precisely in this higher auditory area.</p><p>Using the simple band-passed noise stimuli, the sound frequency preference map was successfully reconstructed even for the auditory cortical areas with weak optical signals: the RT of the core region, the RTL and CL of the belt region, and the areas of the parabelt region. This was due to the high signal amplitude and signal-to-noise ratio, with the relatively high spatial resolution of OISI. Several studies using fMRI in macaque monkeys have mapped the preferred frequency in the core and belt regions, but not in the parabelt region with weak signals to the simple stimuli, which would be averaged in voxels with low spatial resolution. Voltage sensitive dye imaging with lower signal amplitude (1/10&#x02013;1/100 of that of OISI) detected signals in the core and belt regions but not in the parabelt region of common marmoset, although it had better temporal resolution than OISI (<xref rid="B27" ref-type="bibr">Nishimura et al., 2017</xref>).</p></sec><sec id="s5B"><title>Comparison of sound frequency representation among core, belt, and parabelt regions</title><p>The core region of the auditory cortex in primates contains tonotopic maps (<xref rid="B15" ref-type="bibr">Formisano et al., 2003</xref>; <xref rid="B31" ref-type="bibr">Petkov et al., 2006</xref>; <xref rid="B16" ref-type="bibr">Humphries et al., 2010</xref>; <xref rid="B4" ref-type="bibr">Baumann et al., 2013</xref>). This was shown in the marmoset using electrophysiological studies (<xref rid="B3" ref-type="bibr">Aitkin et al., 1986</xref>; <xref rid="B5" ref-type="bibr">Bendor and Wang, 2005, 2008</xref>). Our results obtained in the common marmoset were consistent with those reported for other primate species. Specifically, the preferred frequency gradually changed from low to high in the antero-ventral to postero-dorsal direction in the A1 and RT, and in the postero-ventral to antero-dorsal direction in R. Regions with preference for high<strike>er</strike> frequencies were not clearly observed in R or RT, probably because these regions extended into the lateral sulcus, as reported in previous studies (<xref rid="B5" ref-type="bibr">Bendor and Wang, 2005, 2008</xref>). The regions around the intersection of the A1, R ML, and AL areas had the lowest sound frequency preferences. It is thought that the gradual change in sound frequency preference from low to high starts at this intersection. <xref rid="B5" ref-type="bibr">Bendor and Wang (2005)</xref> suggested that the pitch center region in non-human primates where cells responsive to pitch exist is located around the regions with preference for the lowest frequencies.</p><p>It is as yet not well known whether tonotopic maps exist outside the core region in primates. Our results showed that there was tonotopic organization only in the ML area of the belt region. This organization was symmetric to that in A1 about the border between A1 and ML. The preferred frequency gradually changed from low to high in the antero-dorsal to postero-ventral direction. There was no tonotopic organization in the other areas of the belt region. The sound frequency preference was biased toward low<strike>er</strike> frequencies in the RTL and toward high<strike>er</strike> frequencies in the CL. We did not observe a region with preference for low frequencies, which is inconsistent with the previous findings of <xref rid="B31" ref-type="bibr">Petkov et al. (2006)</xref>. When compared to the results of fMRI studies reporting the gradual change in frequency preference in the belt region in macaque monkeys (<xref rid="B31" ref-type="bibr">Petkov et al., 2006</xref>), our results further clarify the fine functional structure of the belt region with sub-areal scale. We were unable to investigate the medial part of the belt region in the lateral sulcus using OISI in this study. The use of fMRI with high spatial resolution, ECoG with high density electrodes, or new functional imaging techniques would be necessary to elucidate the sound frequency representation in the caudomedial, rostromedial, and rostrotempmedial areas in the medial belt region.</p><p>No tonotopic organization was found in the parabelt region, which contained the island-like region with preference for high frequencies (&#x0003e;5.8 kHz) around the border between the RPB and CPB. The spatial positions of the regions responsive to high frequencies varied among the different animals. We found regions with preference for high frequencies in the anterior part of the RPB. These regions had response magnitudes lower than that found in the RPB/CPB border. Regions with preference for high frequencies also exist at the border between RPB and CPB in macaque monkeys (<xref rid="B20" ref-type="bibr">Kajikawa et al., 2015</xref>). However, in contrast to the findings of this study, there is the gradient of sound frequency preference from the border to the anterior RPB and to the posterior CPB (<xref rid="B20" ref-type="bibr">Kajikawa et al., 2015</xref>). The difference in functional organization between the two species might be attributable to their vocal frequency ranges and their living environments.</p><p>The sound frequency preference map in the core region is a common functional structure among the primate species (<xref rid="B3" ref-type="bibr">Aitkin et al., 1986</xref>; <xref rid="B15" ref-type="bibr">Formisano et al., 2003</xref>; <xref rid="B34" ref-type="bibr">Rauschecker and Tian, 2004</xref>; <xref rid="B5" ref-type="bibr">Bendor and Wang, 2005</xref>; <xref rid="B31" ref-type="bibr">Petkov et al., 2006</xref>; <xref rid="B16" ref-type="bibr">Humphries et al., 2010</xref>; <xref rid="B4" ref-type="bibr">Baumann et al., 2013</xref>; <xref rid="B27" ref-type="bibr">Nishimura et al., 2017</xref>). This presence of this auditory cortical structure in primates might be reflected by their abundant vocal communication compared to other mammals. On the other hand, the spectral features of vocal sounds among different primate species (e.g., the main frequency contained in vocal sounds of marmosets is &#x0223c;8 kHz) might cause the structural differences in sound frequency representation in the belt and parabelt regions, as discussed above.</p></sec></sec></body><back><ack><p>Acknowledgements: We thank Dr. Kazuhisa Sakai, Ms. Hiromi Nito, Ms. Noriko Murayama, Dr. Misako Komatsu, and Dr. Toru Kurotani for their assistance with the experiments.</p></ack><ref-list content-type="nameDate"><title>References</title><ref id="B1"><mixed-citation publication-type="journal">
<string-name><surname>Abe</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Tani</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Mashiko</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Kitamura</surname>
<given-names>N</given-names></string-name>, <string-name><surname>Miyakawa</surname>
<given-names>N</given-names></string-name>, <string-name><surname>Mimura</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Sakai</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Suzuki</surname>
<given-names>W</given-names></string-name>, <string-name><surname>Kurotani</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Mizukami</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Watakabe</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Yamamori</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Ichinohe</surname>
<given-names>N</given-names></string-name> (<year>2017</year>) <article-title>3D reconstruction of brain section images for creating axonal projection maps in marmosets</article-title>. <source>J Neurosci Methods</source>
<volume>286</volume>:<fpage>102</fpage>&#x02013;<lpage>113</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2017.04.016</pub-id>
<pub-id pub-id-type="pmid">28577985</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal">
<string-name><surname>Agamaite</surname>
<given-names>JA</given-names></string-name>, <string-name><surname>Chang</surname>
<given-names>C-J</given-names></string-name>, <string-name><surname>Osmanski</surname>
<given-names>MS</given-names></string-name>, <string-name><surname>Wang</surname>
<given-names>X</given-names></string-name> (<year>2015</year>) <article-title>A quantitative acoustic analysis of the vocal repertoire of the common marmoset (<italic>Callithrix jacchus</italic>)</article-title>. <source>J Acoust Soc Am</source>
<volume>138</volume>:<fpage>2906</fpage>&#x02013;<lpage>2928</lpage>. <pub-id pub-id-type="doi">10.1121/1.4934268</pub-id>
<pub-id pub-id-type="pmid">26627765</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal">
<string-name><surname>Aitkin</surname>
<given-names>LM</given-names></string-name>, <string-name><surname>Merzenich</surname>
<given-names>MM</given-names></string-name>, <string-name><surname>Irvine</surname>
<given-names>DR</given-names></string-name>, <string-name><surname>Clarey</surname>
<given-names>JC</given-names></string-name>, <string-name><surname>Nelson</surname>
<given-names>JE</given-names></string-name> (<year>1986</year>) <article-title>Frequency representation in auditory cortex of the common marmoset (<italic>Callithrix jacchus jacchus</italic>)</article-title>. <source>J Comp Neur</source>
<volume>252</volume>:<fpage>175</fpage>&#x02013;<lpage>185</lpage>. <pub-id pub-id-type="doi">10.1002/cne.902520204</pub-id>
<pub-id pub-id-type="pmid">3782506</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal">
<string-name><surname>Baumann</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Petkov</surname>
<given-names>CI</given-names></string-name>, <string-name><surname>Griffiths</surname>
<given-names>TD</given-names></string-name> (<year>2013</year>) <article-title>A unified framework for the organization of the primate auditory cortex</article-title>. <source>Front Syst Neurosci</source>
<volume>7</volume>:<fpage>11.</fpage>
<pub-id pub-id-type="doi">10.3389/fnsys.2013.00011</pub-id><pub-id pub-id-type="pmid">23641203</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal">
<string-name><surname>Bendor</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Wang</surname>
<given-names>X</given-names></string-name> (<year>2005</year>) <article-title>The neuronal representation of pitch in primate auditory cortex</article-title>. <source>Nature</source>
<volume>436</volume>:<fpage>1161</fpage>&#x02013;<lpage>1165</lpage>. <pub-id pub-id-type="doi">10.1038/nature03867</pub-id>
<pub-id pub-id-type="pmid">16121182</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal">
<string-name><surname>Bendor</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Wang</surname>
<given-names>X</given-names></string-name> (<year>2008</year>) <article-title>Neural response properties of primary, rostral, and rostrotemporal core fields in the auditory cortex of marmoset monkeys</article-title>. <source>J Neurophysiol</source>
<volume>100</volume>:<fpage>888</fpage>&#x02013;<lpage>906</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00884.2007</pub-id>
<pub-id pub-id-type="pmid">18525020</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="book">
<string-name><surname>Bonhoeffer</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Grinvald</surname>
<given-names>A</given-names></string-name> (<year>1996</year>) <chapter-title>Optical imaging based on intrinsic signals: the methodology</chapter-title> In: <source>Brain mapping: the methods</source> (<person-group person-group-type="editor"><name name-style="western"><surname>Toga</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Mazziotta</surname><given-names>JC</given-names></name></person-group>, eds), pp <fpage>55</fpage>&#x02013;<lpage>97</lpage>. <publisher-loc>San Diego, CA</publisher-loc>: <publisher-name>Academic</publisher-name>.</mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal">
<string-name><surname>Cohen</surname>
<given-names>LB</given-names></string-name> (<year>1973</year>) <article-title>Changes in neuron structure during action potential propagation and synaptic transmission</article-title>. <source>Physiol Rev</source>
<volume>53</volume>:<fpage>373</fpage>&#x02013;<lpage>418</lpage>. <pub-id pub-id-type="doi">10.1152/physrev.1973.53.2.373</pub-id><pub-id pub-id-type="pmid">4349816</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal">
<string-name><surname>de la Mothe</surname>
<given-names>LA</given-names></string-name>, <string-name><surname>Blumell</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Kajikawa</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Hackett</surname>
<given-names>TA</given-names></string-name> (<year>2006a</year>) <article-title>Thalamic connections of the auditory cortex in marmoset monkeys: core and medial belt regions</article-title>. <source>J Comp Neur</source>
<volume>496</volume>:<fpage>72</fpage>&#x02013;<lpage>96</lpage>. <pub-id pub-id-type="doi">10.1002/cne.20924</pub-id><pub-id pub-id-type="pmid">16528728</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal">
<string-name><surname>de la Mothe</surname>
<given-names>LA</given-names></string-name>, <string-name><surname>Blumell</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Kajikawa</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Hackett</surname>
<given-names>TA</given-names></string-name> (<year>2006b</year>) <article-title>Cortical connections of the auditory cortex in marmoset monkeys: core and medial belt regions</article-title>. <source>J Comp Neur</source>
<volume>496</volume>:<fpage>27</fpage>&#x02013;<lpage>71</lpage>. <pub-id pub-id-type="doi">10.1002/cne.20923</pub-id><pub-id pub-id-type="pmid">16528722</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal">
<string-name><surname>de la Mothe</surname>
<given-names>LA</given-names></string-name>, <string-name><surname>Blumell</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Kajikawa</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Hackett</surname>
<given-names>TA</given-names></string-name> (<year>2012a</year>) <article-title>Thalamic connections of auditory cortex in marmoset monkeys: lateral belt and parabelt regions</article-title>. <source>Anat Rec (Hoboken)</source>
<volume>295</volume>:<fpage>822</fpage>&#x02013;<lpage>836</lpage>. <pub-id pub-id-type="doi">10.1002/ar.22454</pub-id><pub-id pub-id-type="pmid">22467603</pub-id></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal">
<string-name><surname>de la Mothe</surname>
<given-names>LA</given-names></string-name>, <string-name><surname>Blumell</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Kajikawa</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Hackett</surname>
<given-names>TA</given-names></string-name> (<year>2012b</year>) <article-title>Cortical connections of auditory cortex in marmoset monkeys: lateral belt and parabelt regions</article-title>. <source>Anat Rec (Hoboken)</source>
<volume>295</volume>:<fpage>800</fpage>&#x02013;<lpage>821</lpage>. <pub-id pub-id-type="doi">10.1002/ar.22451</pub-id><pub-id pub-id-type="pmid">22461313</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal">
<string-name><surname>Eliades</surname>
<given-names>SJ</given-names></string-name>, <string-name><surname>Wang</surname>
<given-names>X</given-names></string-name> (<year>2008a</year>) <article-title>Chronic multi-electrode neural recording in free-roaming monkeys</article-title>. <source>J Neurosci Methods</source>
<volume>172</volume>:<fpage>201</fpage>&#x02013;<lpage>214</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2008.04.029</pub-id><pub-id pub-id-type="pmid">18572250</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal">
<string-name><surname>Eliades</surname>
<given-names>SJ</given-names></string-name>, <string-name><surname>Wang</surname>
<given-names>X</given-names></string-name> (<year>2008b</year>) <article-title>Neural substrates of vocalization feedback monitoring in primate auditory cortex</article-title>. <source>Nature</source>
<volume>453</volume>:<fpage>1102</fpage>&#x02013;<lpage>1106</lpage>. <pub-id pub-id-type="doi">10.1038/nature06910</pub-id><pub-id pub-id-type="pmid">18454135</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal">
<string-name><surname>Formisano</surname>
<given-names>E</given-names></string-name>, <string-name><surname>Kim</surname>
<given-names>DS</given-names></string-name>, <string-name><surname>Di Salle</surname>
<given-names>F</given-names></string-name>, <string-name><surname>van de Moortele</surname>
<given-names>PF</given-names></string-name>, <string-name><surname>Ugurbil</surname>
<given-names>K</given-names></string-name>, <string-name><surname>Goebel</surname>
<given-names>R</given-names></string-name> (<year>2003</year>) <article-title>Mirror-symmetric tonotopic maps in human primary auditory cortex</article-title>. <source>Neuron</source>
<volume>40</volume>:<fpage>859</fpage>&#x02013;<lpage>869</lpage>. <pub-id pub-id-type="pmid">14622588</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal">
<string-name><surname>Humphries</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Liebenthal</surname>
<given-names>E</given-names></string-name>, <string-name><surname>Binder</surname>
<given-names>JR</given-names></string-name> (<year>2010</year>) <article-title>Tonotopic organization of human auditory cortex</article-title>. <source>Neuroimage</source>
<volume>50</volume>:<fpage>1202</fpage>&#x02013;<lpage>1211</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2010.01.046</pub-id>
<pub-id pub-id-type="pmid">20096790</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="journal">
<string-name><surname>Hung</surname>
<given-names>CC</given-names></string-name>, <string-name><surname>Yen</surname>
<given-names>CC</given-names></string-name>, <string-name><surname>Ciuchta</surname>
<given-names>JL</given-names></string-name>, <string-name><surname>Papoti</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Bock</surname>
<given-names>NA</given-names></string-name>, <string-name><surname>Leopold</surname>
<given-names>DA</given-names></string-name>, <string-name><surname>Silva</surname>
<given-names>AC</given-names></string-name> (<year>2015</year>) <article-title>Functional MRI of visual responses in the awake, behaving marmoset</article-title>. <source>Neuroimage</source>
<volume>120</volume>:<fpage>1</fpage>&#x02013;<lpage>11</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuroimage.2015.06.090</pub-id>
<pub-id pub-id-type="pmid">26149609</pub-id></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal">
<string-name><surname>Kajikawa</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>de la Mothe</surname>
<given-names>L</given-names></string-name>, <string-name><surname>Blumell</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Hackett</surname>
<given-names>TA</given-names></string-name> (<year>2005</year>) <article-title>A comparison of neuron response properties in areas A1 and CM of the marmoset monkey auditory cortex: tones and broadband noise</article-title>. <source>J Neurophysiol</source>
<volume>93</volume>:<fpage>22</fpage>&#x02013;<lpage>34</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00248.2004</pub-id>
<pub-id pub-id-type="pmid">15342713</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal">
<string-name><surname>Kajikawa</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Camalier</surname>
<given-names>CR</given-names></string-name>, <string-name><surname>de la Mothe</surname>
<given-names>LA</given-names></string-name>, <string-name><surname>D&#x02019;Angelo</surname>
<given-names>WR</given-names></string-name>, <string-name><surname>Sterbing-D&#x02019;Angelo</surname>
<given-names>SJ</given-names></string-name>, <string-name><surname>Hackett</surname>
<given-names>TA</given-names></string-name> (<year>2011</year>) <article-title>Auditory cortical tuning to band-pass noise in primate A1 and CM: a comparison to pure tones</article-title>. <source>Neurosci Res</source>
<volume>70</volume>:<fpage>401</fpage>&#x02013;<lpage>407</lpage>. <pub-id pub-id-type="doi">10.1016/j.neures.2011.04.003</pub-id><pub-id pub-id-type="pmid">21540062</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal">
<string-name><surname>Kajikawa</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Frey</surname>
<given-names>S</given-names></string-name>, <string-name><surname>Ross</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Falchier</surname>
<given-names>A</given-names></string-name>, <string-name><surname>Hackett</surname>
<given-names>TA</given-names></string-name>, <string-name><surname>Schroeder</surname>
<given-names>CE</given-names></string-name> (<year>2015</year>) <article-title>Auditory properties in the parabelt regions of the superior temporal gyrus in the awake macaque monkey: an initial survey</article-title>. <source>J Neurosci</source>
<volume>35</volume>:<fpage>4140</fpage>&#x02013;<lpage>4150</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3556-14.2015</pub-id>
<pub-id pub-id-type="pmid">25762661</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal">
<string-name><surname>Kaas</surname>
<given-names>JH</given-names></string-name>, <string-name><surname>Hackett</surname>
<given-names>TA</given-names></string-name> (<year>2000</year>) <article-title>Subdivisions of auditory cortex and processing streams in primates</article-title>. <source>Proc Natl Acad Sci USA</source>
<volume>97</volume>:<fpage>11793</fpage>&#x02013;<lpage>11799</lpage>. <pub-id pub-id-type="doi">10.1073/pnas.97.22.11793</pub-id>
<pub-id pub-id-type="pmid">11050211</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal">
<string-name><surname>Leaver</surname>
<given-names>AM</given-names></string-name>, <string-name><surname>Rauschecker</surname>
<given-names>JP</given-names></string-name> (<year>2016</year>) <article-title>Functional topography of human auditory cortex</article-title>. <source>J Neurosci</source>
<volume>36</volume>:<fpage>1416</fpage>&#x02013;<lpage>1428</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0226-15.2016</pub-id>
<pub-id pub-id-type="pmid">26818527</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal">
<string-name><surname>Miller</surname>
<given-names>CT</given-names></string-name>, <string-name><surname>Freiwald</surname>
<given-names>WA</given-names></string-name>, <string-name><surname>Leopold</surname>
<given-names>DA</given-names></string-name>, <string-name><surname>Mitchell</surname>
<given-names>JF</given-names></string-name>, <string-name><surname>Silva</surname>
<given-names>AC</given-names></string-name>, <string-name><surname>Wang</surname>
<given-names>X</given-names></string-name> (<year>2016</year>) <article-title>Marmosets: a neuroscientific model of human social behavior</article-title>. <source>Neuron</source>
<volume>90</volume>:<fpage>219</fpage>&#x02013;<lpage>233</lpage>. <pub-id pub-id-type="doi">10.1016/j.neuron.2016.03.018</pub-id>
<pub-id pub-id-type="pmid">27100195</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal">
<string-name><surname>Mitchell</surname>
<given-names>JF</given-names></string-name>, <string-name><surname>Reynolds</surname>
<given-names>JH</given-names></string-name>, <string-name><surname>Miller</surname>
<given-names>CT</given-names></string-name> (<year>2014</year>) <article-title>Active vision in marmosets: a model system for visual neuroscience</article-title>. <source>J Neurosci</source>
<volume>34</volume>:<fpage>1183</fpage>&#x02013;<lpage>1194</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.3899-13.2014</pub-id>
<pub-id pub-id-type="pmid">24453311</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal">
<string-name><surname>Miyakawa</surname>
<given-names>N</given-names></string-name>, <string-name><surname>Banno</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Abe</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Tani</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Suzuki</surname>
<given-names>W</given-names></string-name>, <string-name><surname>Ichinohe</surname>
<given-names>N</given-names></string-name> (<year>2017</year>) <article-title>Representation of glossy material surface in ventral superior temporal sulcal area of common marmosets</article-title>. <source>Front Neural Circuits</source>
<volume>11</volume>:<fpage>17.</fpage>
<pub-id pub-id-type="doi">10.3389/fncir.2017.00017</pub-id>
<pub-id pub-id-type="pmid">28367117</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal">
<string-name><surname>Nelken</surname>
<given-names>I</given-names></string-name>, <string-name><surname>Bizley</surname>
<given-names>J</given-names></string-name>, <string-name><surname>Shamma</surname>
<given-names>SA</given-names></string-name>, <string-name><surname>Wang</surname>
<given-names>X</given-names></string-name> (<year>2014</year>) <article-title>Auditory cortical processing in real-world listening: the auditory system going real</article-title>. <source>J Neurosci</source>
<volume>34</volume>:<fpage>15135</fpage>&#x02013;<lpage>15138</lpage>. <pub-id pub-id-type="doi">10.1523/JNEUROSCI.2989-14.2014</pub-id>
<pub-id pub-id-type="pmid">25392481</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal">
<string-name><surname>Nishimura</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Takemoto</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Song</surname>
<given-names>W-J</given-names></string-name> (<year>2017</year>) <article-title>Organization of auditory areas in the superior temporal gyrus of marmoset monkeys revealed by real-time optical imaging</article-title>. <source>Brain Struct Funct</source>
<volume>223</volume>:<fpage>1599</fpage>&#x02013;<lpage>1614</lpage>.
<pub-id pub-id-type="pmid">29185107</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal">
<string-name><surname>Ojima</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Takayanagi</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Potapov</surname>
<given-names>D</given-names></string-name>, <string-name><surname>Homma</surname>
<given-names>R</given-names></string-name> (<year>2005</year>) <article-title>Isofrequency band-like zones of activation revealed by optical imaging of intrinsic signals in the cat primary auditory cortex</article-title>. <source>Cereb Cortex</source>
<volume>15</volume>:<fpage>1497</fpage>&#x02013;<lpage>1509</lpage>. <pub-id pub-id-type="doi">10.1093/cercor/bhi028</pub-id>
<pub-id pub-id-type="pmid">15659656</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal">
<string-name><surname>Striem-Amit</surname>
<given-names>E</given-names></string-name>, <string-name><surname>Hertz</surname>
<given-names>U</given-names></string-name>, <string-name><surname>Amedi</surname>
<given-names>A</given-names></string-name> (<year>2011</year>) <article-title>Extensive cochleotopic mapping of human auditory cortical fields obtained with phase-encoding fMRI</article-title>. <source>PLoS ONE</source>
<volume>6</volume>:<fpage>e17832.</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pone.0017832</pub-id>
<pub-id pub-id-type="pmid">21448274</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="book">
<string-name><surname>Paxinos</surname>
<given-names>G</given-names></string-name>, <string-name><surname>Watson</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Petrides</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Rosa</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Tokuno</surname>
<given-names>H</given-names></string-name> (<year>2012</year>) <source>The marmoset brain in stereotaxic coordinates</source>. <publisher-loc>San Diego</publisher-loc>: <publisher-name>Academic Press Inc</publisher-name>.</mixed-citation></ref><ref id="B31"><mixed-citation publication-type="journal">
<string-name><surname>Petkov</surname>
<given-names>CI</given-names></string-name>, <string-name><surname>Kayser</surname>
<given-names>C</given-names></string-name>, <string-name><surname>Augath</surname>
<given-names>M</given-names></string-name>, <string-name><surname>Logothetis</surname>
<given-names>NK</given-names></string-name> (<year>2006</year>) <article-title>Functional imaging reveals numerous fields in the monkey auditory cortex</article-title>. <source>PLoS Biol</source>
<volume>4</volume>:<fpage>e215.</fpage>
<pub-id pub-id-type="doi">10.1371/journal.pbio.0040215</pub-id>
<pub-id pub-id-type="pmid">16774452</pub-id></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal">
<string-name><surname>Philibert</surname>
<given-names>B</given-names></string-name>, <string-name><surname>Beitel</surname>
<given-names>RE</given-names></string-name>, <string-name><surname>Nagarajan</surname>
<given-names>SS</given-names></string-name>, <string-name><surname>Bonham</surname>
<given-names>BH</given-names></string-name>, <string-name><surname>Schreiner</surname>
<given-names>CE</given-names></string-name>, <string-name><surname>Cheung</surname>
<given-names>SW</given-names></string-name> (<year>2005</year>) <article-title>Functional organization and hemispheric comparison of primary auditory cortex in the common marmoset (<italic>Callithrix jacchus</italic>)</article-title>. <source>J Comp Neur</source>
<volume>487</volume>:<fpage>391</fpage>&#x02013;<lpage>406</lpage>. <pub-id pub-id-type="doi">10.1002/cne.20581</pub-id>
<pub-id pub-id-type="pmid">15906314</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal">
<string-name><surname>Pistorio</surname>
<given-names>AL</given-names></string-name>, <string-name><surname>Hendry</surname>
<given-names>SH</given-names></string-name>, <string-name><surname>Wang</surname>
<given-names>X</given-names></string-name> (<year>2006</year>) <article-title>A modified technique for high-resolution staining of myelin</article-title>. <source>J. Neurosci. Methods</source>
<volume>153</volume>:<fpage>135</fpage>&#x02013;<lpage>146</lpage>. <pub-id pub-id-type="doi">10.1016/j.jneumeth.2005.10.014</pub-id><pub-id pub-id-type="pmid">16310256</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal">
<string-name><surname>Rauschecker</surname>
<given-names>JP</given-names></string-name>, <string-name><surname>Tian</surname>
<given-names>B</given-names></string-name> (<year>2004</year>) <article-title>Processing of band-passed noise in the lateral auditory belt cortex of the rhesus monkey</article-title>. <source>J Neurophysiol</source>
<volume>91</volume>:<fpage>2578</fpage>&#x02013;<lpage>2589</lpage>. <pub-id pub-id-type="doi">10.1152/jn.00834.2003</pub-id>
<pub-id pub-id-type="pmid">15136602</pub-id></mixed-citation></ref><ref id="B35"><mixed-citation publication-type="journal">
<string-name><surname>Suzuki</surname>
<given-names>W</given-names></string-name>, <string-name><surname>Banno</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Miyakawa</surname>
<given-names>N</given-names></string-name>, <string-name><surname>Abe</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Goda</surname>
<given-names>N</given-names></string-name>, <string-name><surname>Ichinohe</surname>
<given-names>N</given-names></string-name> (<year>2015a</year>) <article-title>Mirror neurons in a New World monkey, common marmoset</article-title>. <source>Front Neurosci</source>
<volume>9</volume>:<fpage>459.</fpage>
<pub-id pub-id-type="pmid">26696817</pub-id></mixed-citation></ref><ref id="B36"><mixed-citation publication-type="journal">
<string-name><surname>Suzuki</surname>
<given-names>W</given-names></string-name>, <string-name><surname>Tani</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Banno</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Miyakawa</surname>
<given-names>N</given-names></string-name>, <string-name><surname>Abe</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Ichinohe</surname>
<given-names>N</given-names></string-name> (<year>2015b</year>) <article-title>Functional columns in superior temporal sulcus areas of the common marmoset</article-title>. <source>Neuroreport</source>
<volume>26</volume>:<fpage>1133</fpage>&#x02013;<lpage>1139</lpage>.
<pub-id pub-id-type="pmid">26512934</pub-id></mixed-citation></ref><ref id="B37"><mixed-citation publication-type="journal">
<string-name><surname>Tokuno</surname>
<given-names>H</given-names></string-name>, <string-name><surname>Tanaka</surname>
<given-names>I</given-names></string-name>, <string-name><surname>Umitsu</surname>
<given-names>Y</given-names></string-name>, <string-name><surname>Akazawa</surname>
<given-names>T</given-names></string-name>, <string-name><surname>Nakamura</surname>
<given-names>Y</given-names></string-name> (<year>2009</year>) <article-title>Web-accessible digital brain atlas of the common marmoset (<italic>Callithrix jacchus</italic>)</article-title>. <source>Neurosci Res</source>
<volume>64</volume>:<fpage>128</fpage>&#x02013;<lpage>131</lpage>. <pub-id pub-id-type="doi">10.1016/j.neures.2009.02.003</pub-id>
<pub-id pub-id-type="pmid">19428691</pub-id></mixed-citation></ref></ref-list><sec sec-type="synthesis-author-response" id="s6"><title>Synthesis</title><boxed-text position="float" orientation="portrait"><p>Reviewing Editor: Tatyana Sharpee, The Salk Institute for Biological Studies</p><p>Decisions are customarily a result of the Reviewing Editor and the peer reviewers coming together and discussing their recommendations until a consensus is reached. When revisions are invited, a fact-based synthesis statement explaining their decision and outlining what is needed to prepare a revision will be listed below. The following reviewer(s) agreed to reveal their identity: Shuang Li, Andrew Dykstra</p></boxed-text><p>This study reports measurements of the tonotopic organization of auditory cortical fields in the common marmoset, an increasingly important animal model for auditory processing. The authors find, for the first time, the existence of tonotopic maps outside the core region in primates. </p><p>It would be helpful to discuss the relative advantages and limitations of the intrinsic signal imaging compared to other techniques. For example, intrinsic signal imaging provides higher resolution than fMRI and can survey broader regions of cortex than measurements made using voltage sensitive dyes. It would also be helpful to discuss why auditory processing should be similar across all of primates regardless of the folding patterns for the cortex, making the results obtained in the marmoset relevant to other primate species. </p><p>Reviewer 1: </p><p>1. Line 65: It will be helpful to justify OISI as high spatial resolution. For example, give the spatial resolution of the current approach and compare with previous approaches. </p><p>2. Line 107: Which cortical layer (depth) is imaged and why? From figure 3 A, C, blood vessel structure is readily visible from the imaged results. This is an indication of imaging from the superficial layer, which could further interfere with spatial resolution and conclusion. </p><p>3. Line 108 - 111: Protocol design should be based on the property of simulation sound and imaging signal dynamics. Justification will be necessary. </p><p>4. Line 140: The original sample size to perform bootstrapping from, i.e., the number of pixels for each defined area, is important to evaluate the method. </p><p>5. Line 146: The author should give detailed explanation how each histological measurement being used in the final results </p><p>6. Line 186: The results session is in general not specific enough. For example, in line 186, how are the results consistent with cited literature exactly? </p><p>7. Line 191: Please be consistent with the notation low frequency, lower frequencies </p><p>Reviewer 2: </p><p>-the 2nd sentence of the intro starts with &#x02018;therefore&#x02019;, causally linking spectral features of sound and how those features are represented. This is an unwarranted and teleological argument. </p><p>-no units in Figure 2. Also, it's not immediately apparent (at least for anyone who is unfamiliar with the details of OISI) why a lesser optical signal should be a higher response magnitude, as is stated in the legend for the figure. Please clarify, at least briefly. </p><p>-in the legend for Fig 7: &#x0201c;The dotted region and the arrow represent regions requiring further study.&#x0201d; I don't see the arrow that the authors refer to in the figure. </p><p>-the authors should consider using different color maps for responsiveness (e.g. fig 3) and frequency specificity (figs 4, 6, and 7). </p><p>-Lines 212-214: &#x0201c;A frequency preference map in which the optical signals were averaged across the 11 sound frequencies at each pixel was used to estimate the representation of sound frequency in the auditory cortical areas.&#x0201d; </p><p>I don't understand this sentence. How is a frequency preference map derived from signals averaged across frequencies? </p><p>-In all figures in which data from the three individuals are shown, it would help the reader if the respective panels were labeled to reflect this. In figure 5, a legend with color labels (I.e. marmoset 1, 2, and 3) would be helpful. </p><p>-Lines 254-255: &#x0201c;Finally, to confirm that the optical responses to sound frequencies reflected the neuronal responses, we compared the optical signals and the electrical response to the same sound stimuli in an animal.&#x0201d; </p><p>&#x02018;an&#x02019; &#x02192; &#x02018;one&#x02019;, and maybe include a parenthetical stating which animal (with reference to figures 3 and 4, i.e. the same animal as figure 4c). </p><p>-Lines 293-294: &#x0201c;The ECoG results indicated that even sound stimuli lower than 1.4 kHz clearly elicited neuronal activity, as shown in Figure 6A.&#x0201d;</p><p>Figure 6A shows no such thing, as the lowest frequency shown there is 1.4 kHz. Did the authors mean to refer to the ECoG map in the right-sided panel of Figure 6B instead?</p></sec></back></article>