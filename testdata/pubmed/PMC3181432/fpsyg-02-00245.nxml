<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Front Psychol</journal-id><journal-id journal-id-type="publisher-id">Front. Psychology</journal-id><journal-title-group><journal-title>Frontiers in Psychology</journal-title></journal-title-group><issn pub-type="epub">1664-1078</issn><publisher><publisher-name>Frontiers Research Foundation</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">21991259</article-id><article-id pub-id-type="pmc">3181432</article-id><article-id pub-id-type="doi">10.3389/fpsyg.2011.00245</article-id><article-categories><subj-group subj-group-type="heading"><subject>Psychology</subject><subj-group><subject>Original Research</subject></subj-group></subj-group></article-categories><title-group><article-title>How Many Objects are You Worth? Quantification of the Self-Motion Load on Multiple Object Tracking</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Thomas</surname><given-names>Laura E.</given-names></name><xref ref-type="author-notes" rid="fn001">*</xref></contrib><contrib contrib-type="author"><name><surname>Seiffert</surname><given-names>Adriane E.</given-names></name></contrib></contrib-group><aff id="aff1"><sup>1</sup><institution>Department of Psychology, Vanderbilt University</institution><country>Nashville, TN, USA</country></aff><author-notes><fn fn-type="edited-by"><p>Edited by: Anna M. Borghi, University of Bologna, Italy</p></fn><fn fn-type="edited-by"><p>Reviewed by: Costantini Marcello, University of Chieti, Italy; Jessica K. Witt, Purdue University, USA</p></fn><corresp id="fn001">*Correspondence: Laura E. Thomas, Department of Psychology, NDSU Dept. 2765, Fargo, ND 58108, USA. e-mail: <email>laura.e.thomas@ndsu.edu</email></corresp><fn fn-type="other" id="fn002"><p>This article was submitted to Frontiers in Cognition, a specialty of Frontiers in Psychology.</p></fn></author-notes><pub-date pub-type="epub"><day>28</day><month>9</month><year>2011</year></pub-date><pub-date pub-type="collection"><year>2011</year></pub-date><volume>2</volume><elocation-id>245</elocation-id><history><date date-type="received"><day>10</day><month>6</month><year>2011</year></date><date date-type="accepted"><day>06</day><month>9</month><year>2011</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2011 Thomas and Seiffert.</copyright-statement><copyright-year>2011</copyright-year><license license-type="open-access" xlink:href="http://www.frontiersin.org/licenseagreement"><license-p>This is an open-access article subject to a non-exclusive license between the authors and Frontiers Media SA, which permits use, distribution and reproduction in other forums, provided the original authors and source are credited and other Frontiers conditions are complied with.</license-p></license></permissions><abstract><p>Perhaps walking and chewing gum is effortless, but walking and tracking moving objects is not. Multiple object tracking is impaired by walking from one location to another, suggesting that updating location of the self puts demands on object tracking processes. Here, we quantified the cost of self-motion in terms of the tracking load. Participants in a virtual environment tracked a variable number of targets (1&#x02013;5) among distractors while either staying in one place or moving along a path that was similar to the objects&#x02019; motion. At the end of each trial, participants decided whether a probed dot was a target or distractor. As in our previous work, self-motion significantly impaired performance in tracking multiple targets. Quantifying tracking capacity for each individual under move versus stay conditions further revealed that self-motion during tracking produced a cost to capacity of about 0.8 (&#x000b1;0.2) objects. Tracking your own motion is worth about one object, suggesting that updating the location of the self is similar, but perhaps slightly easier, than updating locations of objects.</p></abstract><kwd-group><kwd>multiple object tracking</kwd><kwd>spatial updating</kwd><kwd>self-motion</kwd></kwd-group><counts><fig-count count="2"/><table-count count="0"/><equation-count count="1"/><ref-count count="34"/><page-count count="5"/><word-count count="4686"/></counts></article-meta></front><body><sec sec-type="introduction"><title>Introduction</title><p>We often find ourselves in environments where we need to keep track of objects moving around us while we ourselves are also in motion, such as when we drive in traffic, play team sports, or walk down a crowded sidewalk. These common situations can be challenging &#x02013; tracking moving objects and navigating through space are both demanding tasks. We use attention and memory to keep tabs on the changing locations of objects of interest as they move, a process known as object tracking (Cavanagh and Alvarez, <xref ref-type="bibr" rid="B7">2005</xref>; Allen et al., <xref ref-type="bibr" rid="B1">2006</xref>; Fougnie and Marois, <xref ref-type="bibr" rid="B12">2006</xref>; Tombu and Seiffert, <xref ref-type="bibr" rid="B28">2008</xref>). Object tracking has a limited capacity that can be measured as the number of targets that can be tracked in a given set of conditions (Pylyshyn and Storm, <xref ref-type="bibr" rid="B22">1988</xref>; Scholl et al., <xref ref-type="bibr" rid="B25">2001</xref>; Alvarez and Franconeri, <xref ref-type="bibr" rid="B3">2007</xref>; but see Ma and Huang, <xref ref-type="bibr" rid="B16">2009</xref>). As we move, we update a representation of our own changing location in space, a process known as spatial updating. Although spatial updating tends to occur obligatorily (Rieser, <xref ref-type="bibr" rid="B23">1989</xref>; Farrell and Robertson, <xref ref-type="bibr" rid="B10">1998</xref>; Farrell and Thomson, <xref ref-type="bibr" rid="B11">1998</xref>; May and Klatzky, <xref ref-type="bibr" rid="B18">2000</xref>), it requires cognitive resources (Amorim et al., <xref ref-type="bibr" rid="B4">1997</xref>) and also appears to be limited in capacity (Wang et al., <xref ref-type="bibr" rid="B32">2006</xref>; Wang, <xref ref-type="bibr" rid="B31">2007</xref>). Research describing the limitations of these processes provides a better understanding of how people function in complex environments.</p><p>Much previous research has investigated the properties of object tracking and spatial updating abilities, but there are few details about how these processes interact. Recently, we have found that these two processes tap common spatial resources (Thomas and Seiffert, <xref ref-type="bibr" rid="B26">2010</xref>). Our experiments demonstrated that when observers moved around an area in which they were tracking three targets moving amidst identical distractors, their object tracking performance suffered compared to when they remained in one location. Self-motion impaired object tracking both when observers walked around the tracking area and when they were pushed along the same path in a wheelchair. This impairment occurred both in an immersive virtual environment and a real-world analog and was robust even when observers did not receive visual feedback about their own movements. However, we also found that self-motion did not interfere when observers moved while performing a difficult feature-tracking task that did not involve changes to target locations. Taken together, these experiments strongly suggest that self-motion impairs object tracking performance because both rely on a process of updating spatial representations over time.</p><p>Our previous findings suggest spatial updating and object location tracking processes interfere with one another, indicating that they rely on common spatial resources. If object tracking and spatial updating require common resources, then perhaps we can understand one process in terms of the other &#x02013; how these resources are shared and allocated across the two tasks. As our first step in achieving this goal, we asked how spatial updating could be assessed in terms of object tracking capacity. Quantifying attributes of cognitive function provides insights into the underlying structure of information processing and the relationship between different functions. For example, working memory was originally quantified as containing about seven objects (Miller, <xref ref-type="bibr" rid="B19">1956</xref>), but this value was later revised to about four objects when the strategies and components of memory were better understood (see Baddeley, <xref ref-type="bibr" rid="B6">1992</xref>; Cowan, <xref ref-type="bibr" rid="B8">2001</xref>). Quantifying the capacity of working memory has benefited understanding of its nature in terms of representational structure of features, neural substrates, and development (Vogel et al., <xref ref-type="bibr" rid="B29">2001</xref>; Ross-Sheehy et al., <xref ref-type="bibr" rid="B24">2003</xref>; Alvarez and Cavanagh, <xref ref-type="bibr" rid="B2">2004</xref>; Todd and Marois, <xref ref-type="bibr" rid="B27">2004</xref>; Xu and Chun, <xref ref-type="bibr" rid="B33">2006</xref>; Jiang et al., <xref ref-type="bibr" rid="B14">2008</xref>; Oakes et al., <xref ref-type="bibr" rid="B20">2010</xref>). For the current study, the goal was to understand the relationship between self-motion and object tracking. Quantification of the effect of self-motion in terms of object tracking will allow us to determine whether it makes sense to interpret the interference between the two tasks in terms of a single process, such as a mechanism for tracking changes in spatial location. When an observer needs to move through her environment while simultaneously keeping track of the things moving around her, does a location tracking mechanism treat the self as just another moving item to track? Alternatively, is spatial updating of self-position calculated in a more efficient &#x02013; or even more costly &#x02013; manner?</p><p>In the current experiment, we set out to quantify the load of self-motion on tracking capacity. To measure the cost of self-motion on object tracking, we asked participants to keep track of a subset of identical moving balls while walking in an immersive virtual environment. Participants either walked around the area in which the balls moved or walked in place maintaining a constant location as in previous work (Thomas and Seiffert, <xref ref-type="bibr" rid="B26">2010</xref>). In the current study, we systematically varied the number of targets participants tracked in order to derive estimates of participants&#x02019; tracking capacity &#x02013; that is, how many moving objects they could successfully individuate and maintain over time. By measuring tracking capacity both while participants walked around and walked in place, we quantified the cost of self-motion in terms of the number of objects tracked.</p></sec><sec sec-type="materials|methods"><title>Materials and Methods</title><sec><title>Participants</title><p>Fourteen volunteers from Vanderbilt University participated for course credit. The research was approved by the Vanderbilt University Institutional Review Board and conformed to the ethical standards for conducting research established by the American Psychological Association. Informed consent was obtained from all participants.</p></sec><sec><title>Apparatus</title><p>Participants viewed the virtual environment on an nVisor SX head mounted display (HMD; NVIS, Reston, VA, USA), which presented stereoscopic images in a 60&#x000b0; diagonal field of view at a refresh rate of 60&#x02009;Hz using Vizard software (WorldViz, Santa Barbara, CA, USA) rendered graphics. A three-axis orientation sensor (InertiaCube2; Intersense, Bedford, MA, USA) tracked head orientation and an optical tracking system (PPTX4; WorldViz, Santa Barbara, CA, USA) tracked head position. The graphics displayed in the HMD were updated based on head position and orientation, leading participants&#x02019; physical movements to translate into visual movements within the virtual world.</p></sec><sec><title>Stimuli, procedure, and design</title><p>Participants saw a virtual world inside the HMD consisting of blue sky and a green ground plane. They stood approximately 4&#x02009;ft from the center of a rendered 2.7&#x02009;&#x000d7;&#x02009;2.7&#x02009;ft black outlined box on the ground plane. Inside this box were 10 red balls that subtended approximately 1.3&#x000b0; of visual angle when viewed in the center of the box. Participants performed a multiple object tracking task. At the start of each trial, each ball appeared stationary in a random starting location along its predefined path for 500&#x02009;ms. One, two, three, four, or five of these balls were designated as targets, changing color from red to blue for 1700&#x02009;ms before returning to red. All of the balls then moved in circular paths around the center of the box, with the radius of each path ranging randomly in 0.09&#x02009;ft steps from approximately 0.2 to 1.3&#x02009;ft, the speed of each dot ranging randomly in 1&#x02009;deg steps from approximately 2 to 25&#x02009;deg/s. At these radii and speeds, the slowest balls tended to move about a quarter of a full circle during a trial, while the fastest balls tended to move around their circular paths up to three times. Each ball had equal probability of moving clockwise or counterclockwise. Although the circles were often very close together, making it difficult to distinguish whether an individual ball was moving along a path with a radius greater or less than its neighbors, to prevent participants from encoding ball position based on radius without regard for the balls&#x02019; motion, the two innermost and two outermost balls were never designated as targets. After 4&#x02009;s of movement, the balls stopped moving and one ball changed color from red to blue. Participants verbally responded &#x0201c;yes&#x0201d; if they thought that the probed blue ball was the same as one of the targets and &#x0201c;no&#x0201d; otherwise. For half of trials, the cued ball was a target; for the other half of trials it was a distractor.</p><p>While engaged in the tracking task, participants could move in two different ways. In the <italic>move</italic> <italic>condition</italic>, participants walked an arc 90&#x000b0; around the box, moving a quarter circle from the center of one side of the box to an adjacent side. While walking, participants remained oriented so that their bodies faced the direction in which they moved and their heads remained turned toward the box. Participants initiated this walk at the same time that the tracking balls began to move and completed the walk when the balls stopped. To ensure that participants walked appropriately, an experimenter guided them by holding one end of a 4-ft stick while the participant held the other end. In the <italic>stay</italic> <italic>condition</italic>, on the other hand, participants simply walked in place, replacing their feet in the same location that they picked them up. While walking in place, participants were oriented identically to the move condition but maintaining a constant position. At the end of each trial in which participants changed location, they turned 180&#x000b0; so that they could move in the opposite direction along the same arc on the next move trial.</p><p>At the beginning of a session, participants spent a few minutes observing the testing area without the HMD as they provided consent and listened to instructions. Participants then had the opportunity to look around the virtual environment with the HMD before performing eight practice trials in which they tracked one or two targets. They then performed four blocks of 60 trials each in which number of targets (1&#x02013;5), movement condition (move or stay), and probe identity (target or distractor) were randomly intermixed. Before each trial began, an experimenter announced whether the trial was in the move or stay condition.</p></sec></sec><sec><title>Results</title><p>Participants made more tracking errors as tracking load increased from one to five balls and made more errors in the move condition than in the stay condition (Figure <xref ref-type="fig" rid="F1">1</xref>). A 5&#x02009;&#x000d7;&#x02009;2 ANOVA confirmed these effects, showing significant main effects of number of targets [<italic>F</italic>(4, 52)&#x02009;=&#x02009;39.37, MSE&#x02009;=&#x02009;56.04, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001] and self-motion [<italic>F</italic>(1,13)&#x02009;=&#x02009;46.14, MSE&#x02009;=&#x02009;22.76, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001]. The interaction between number of targets and self-motion approached significance [<italic>F</italic>(4,52)&#x02009;=&#x02009;2.43, MSE&#x02009;=&#x02009;45.43, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.06]. Planned pairwise comparisons showed that this marginal interaction was driven by a lack of difference between tracking performance in the move versus stay conditions under low tracking load [<italic>t</italic>(13)&#x02009;=&#x02009;0.99, <italic>p</italic>&#x02009;&#x0003e;&#x02009;0.3 for the one-target case and <italic>t</italic>(13)&#x02009;=&#x02009;1.39, <italic>p</italic>&#x02009;&#x0003e;&#x02009;0.1 for the two-target case] but significantly better tracking in the stay condition under higher tracking load [<italic>t</italic>(13)&#x02009;=&#x02009;3.43, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.01 for tracking three targets, <italic>t</italic>(13)&#x02009;=&#x02009;2.35, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.04 for tracking four targets, and <italic>t</italic>(13)&#x02009;=&#x02009;2.75, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.02 for tracking five targets]. This pattern of results replicates and extends our previous findings, showing that self-motion impairs object tracking when tracking load is sufficiently high (Thomas and Seiffert, <xref ref-type="bibr" rid="B26">2010</xref>).</p><fig id="F1" position="float"><label>Figure 1</label><caption><p><bold>Mean percentage correct in the tracking task</bold>.</p></caption><graphic xlink:href="fpsyg-02-00245-g001"/></fig><p>To determine whether results indicate differences in sensitivity or report bias, we conducted the same analyses as reported above on <italic>d</italic>&#x02032; and beta ratio values (Macmillan and Creelman, <xref ref-type="bibr" rid="B17">2005</xref>). A 5&#x02009;&#x000d7;&#x02009;2 ANOVA on <italic>d</italic>&#x02032; values showed significant effects of number of targets [<italic>F</italic>(4,52)&#x02009;=&#x02009;43.98, partial &#x003b7;<sup>2</sup>&#x02009;=&#x02009;0.772, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001] and self-motion [<italic>F</italic>(1,13)&#x02009;=&#x02009;43.71, partial &#x003b7;<sup>2</sup>&#x02009;=&#x02009;0.771, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.001]. The interaction between number of targets and self-motion approached significance [<italic>F</italic>(4,52)&#x02009;=&#x02009;2.43, partial &#x003b7;<sup>2</sup>&#x02009;=&#x02009;0.158, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.06]. Planned pairwise comparisons on <italic>d</italic>&#x02032; values showed that this marginal interaction was driven by a lack of difference between tracking performance in the move versus stay conditions under low tracking load [<italic>t</italic>(13)&#x02009;=&#x02009;1.05, <italic>p</italic>&#x02009;&#x0003e;&#x02009;0.30 for the one-target case and <italic>t</italic>(13)&#x02009;=&#x02009;1.41, <italic>p</italic>&#x02009;&#x0003e;&#x02009;0.10 for the two-target case] but significantly better tracking in the stay condition under higher tracking load [<italic>t</italic>(13)&#x02009;=&#x02009;3.39, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.005 for tracking three targets, and <italic>t</italic>(13)&#x02009;=&#x02009;2.92, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.02 for tracking five targets; for four targets results were marginal, <italic>t</italic>(13)&#x02009;=&#x02009;2.12, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.06]. A 5&#x02009;&#x000d7;&#x02009;2 ANOVA on beta ratio values showed a marginal main effect of number of targets [<italic>F</italic>(4,52)&#x02009;=&#x02009;2.24, partial &#x003b7;<sup>2</sup>&#x02009;=&#x02009;0.147, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.08] and no effect of self-motion [<italic>F</italic>(1,13)&#x02009;=&#x02009;2.14, partial &#x003b7;<sup>2</sup>&#x02009;=&#x02009;0.141, <italic>p</italic>&#x02009;&#x0003e;&#x02009;0.10] and no interaction [<italic>F</italic>(4,52)&#x02009;&#x0003c;&#x02009;1]. Taken together, this pattern of results replicates results reported as percent correct and shows that self-motion impairs tracking sensitivity and not bias (Thomas and Seiffert, <xref ref-type="bibr" rid="B26">2010</xref>).</p><p>At first glance, the averaged data are suggestive about the quantitative cost of self-motion in terms of number of objects tracked. When participants tracked three balls while moving, their performance was similar to when they tracked four balls while stationary [green dashed line in Figure <xref ref-type="fig" rid="F1">1</xref>; <italic>t</italic>(13)&#x02009;=&#x02009;0.32, <italic>p</italic>&#x02009;&#x0003e;&#x02009;0.75]. Similarly, performance tracking four balls while moving was equivalent to tracking five balls while stationary [blue dashed line in Figure <xref ref-type="fig" rid="F1">1</xref>; <italic>t</italic>(13)&#x02009;=&#x02009;0.54, <italic>p</italic>&#x02009;&#x0003e;&#x02009;0.59]. In other words, the cost of adding one more target appears similar to the cost of self-motion; the decrement in performance from adding one more target in the stay condition was similar to the decrement in performance associated with moving. Overall participants&#x02019; average percent correct suggests that the cost of self-motion is about one object.</p><p>To quantify the cost of self-motion on tracking in terms of the number of objects, we estimated tracking capacity for each individual participant in both stay and move conditions. We evaluated performance in terms of the effective number of targets tracked by calculating Cowan&#x02013;Pashler&#x02019;s <italic>K</italic> (Pashler, <xref ref-type="bibr" rid="B21">1988</xref>; Cowan, <xref ref-type="bibr" rid="B8">2001</xref>) with:</p><disp-formula id="E1"><mml:math id="M1"><mml:mi>K</mml:mi><mml:mspace width="0.3em" class="thinspace"/><mml:mstyle class="text"><mml:mtext>&#x000a0;=&#x000a0;</mml:mtext></mml:mstyle><mml:mspace width="0.3em" class="thinspace"/><mml:mfenced separators="" open="[" close="]"><mml:mrow><mml:mi>P</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mstyle class="text"><mml:mtext>H</mml:mtext></mml:mstyle></mml:mrow></mml:mfenced><mml:mspace width="0.3em" class="thinspace"/><mml:mo class="MathClass-bin">+</mml:mo><mml:mspace width="0.3em" class="thinspace"/><mml:mi>P</mml:mi><mml:mfenced separators="" open="(" close=")"><mml:mrow><mml:mstyle class="text"><mml:mtext>CR</mml:mtext></mml:mstyle></mml:mrow></mml:mfenced><mml:mspace width="0.3em" class="thinspace"/><mml:mo class="MathClass-bin">-</mml:mo><mml:mspace width="2.77695pt" class="tmspace"/><mml:mn>1</mml:mn></mml:mrow></mml:mfenced><mml:mo class="MathClass-bin">&#x000d7;</mml:mo><mml:mstyle class="text"><mml:mtext>N</mml:mtext></mml:mstyle></mml:math></disp-formula><p>where <italic>K</italic>&#x02009;=&#x02009;estimated number of balls tracked, H&#x02009;=&#x02009;proportion of accurate &#x0201c;yes&#x0201d; responses (hits), CR&#x02009;=&#x02009;proportion of accurate &#x0201c;no&#x0201d; responses (correct rejections), and N&#x02009;=&#x02009;number of target balls. <italic>K</italic> values are a performance measure similar to percent correct, but given in terms of the number of objects that are effectively tracked (as in Scholl et al., <xref ref-type="bibr" rid="B25">2001</xref>). For example, when there were three targets, if a participant had a hit rate of 0.8333 and a correct rejection rate of 0.8333, then the <italic>K</italic> value of 1.999 would indicate that participant was able to effectively track about two of the three targets on average. For each participant, we calculated <italic>K</italic> for each level of the factor that varied the number of targets, separately for the move and stay conditions. This allowed us to compare the asymptotes of the <italic>K</italic> curves as an estimate of the overall capacity costs of self-motion during tracking. Tracking capacity (C) for each individual was estimated by fitting the <italic>K</italic> values with an elbow curve that assumed perfect tracking performance for conditions with fewer targets than C and performance capped at C for conditions with more targets than C. The value of C that provided the least squared error from the data was taken as the estimated tracking capacity. This estimation of tracking capacity does not correct for guessing, nor consider the benefit to performance from known distractors (Hulleman, <xref ref-type="bibr" rid="B13">2005</xref>). However, we assume that any such correction would be the same for move and stay conditions because we manipulated self-motion independently of the tracking task. While the absolute values of capacity may be overestimated here, we assume the relationship between the capacity for move and stay conditions would not be affected by such analyses. As such, we use this analysis to quantify the cost of self-motion in terms of the effective number of targets tracked.</p><p>Capacity estimates under both the move and stay conditions for each participant agreed with the estimates from the overall average. All but one participant had a smaller capacity in the move condition than the stay condition (Figure <xref ref-type="fig" rid="F2">2</xref>, points relative to blue line), showing the reliability of the effect of self-motion on tracking performance across participants. Interestingly, 9 out of the 13 participants showing a cost had a difference between capacities for stay versus move conditions that was less than one (Figure <xref ref-type="fig" rid="F2">2</xref>, points relative to the red line). Calculating difference scores &#x02013; subtracting the tracking capacity for the move condition from the tracking capacity for the stay condition &#x02013; revealed a self-motion cost that, averaged across participants, was 0.8 objects (SE&#x02009;=&#x02009;0.2). This estimate for the cost of self-motion was reliably greater than zero [<italic>t</italic>(13)&#x02009;=&#x02009;4.6, <italic>p</italic>&#x02009;&#x0003c;&#x02009;0.0005], but not reliably different from one [<italic>t</italic>(13)&#x02009;&#x0003c;&#x02009;1, ns]. Taken together, these analyses suggest that most individual participants experienced a cost of self-motion of about one object.</p><fig id="F2" position="float"><label>Figure 2</label><caption><p><bold>Estimates of tracking capacity (C) for each participant in the move and stay conditions</bold>. The blue line shows the perfect one-to-one relationship that would occur if tracking capacity was unaffected by self-motion. The red line shows a perfect cost of one object due to self-motion.</p></caption><graphic xlink:href="fpsyg-02-00245-g002"/></fig></sec><sec sec-type="discussion"><title>Discussion</title><p>We often find ourselves in situations where we must move through the environment while simultaneously keeping track of other objects moving around us. The results of the current study show that self-motion hampers tracking performance at a cost that is about the same as adding one more target object. Replicating and extending our previous work (Thomas and Seiffert, <xref ref-type="bibr" rid="B26">2010</xref>), we found that when participants were only required to track one or two objects, self-motion did not substantially interfere with this task. However, when participants attempted to keep track of three, four, or five objects, there was a significant cost of self-motion on tracking performance. More specifically, we found that participants&#x02019; capacity data in move versus stay conditions were best described by fitting curves that differed in their asymptotes by 0.8. These results are in line with the idea that the spatial updating associated with self-motion draws upon resources that are also tapped in keeping track of multiple moving objects. We cannot help but update a representation of our own changing location in space as we move (e.g., Farrell and Robertson, <xref ref-type="bibr" rid="B10">1998</xref>; May and Klatzky, <xref ref-type="bibr" rid="B18">2000</xref>), but we do so at the expense of updating other objects&#x02019; changing locations as they move. Moreover, results from the majority of participants showed that keeping track of one&#x02019;s own location in space may be slightly less costly than tracking another object. In other words, when an observer moves while trying to keep track of other moving objects, self-motion imposes an additional load on the tracking mechanism of a bit less than one additional external object.</p><p>The results of the current study provide the first estimate of the actual cost of self-motion on object tracking. Quantification of the effect of self-motion in terms of object tracking allows us to interpret the interference between the two tasks in terms of a single process. The observation that self-motion produces a cost to tracking performance that is very similar to adding one more target object seems to suggest that people mentally update a representation of their own location in space with the same process they use to update representations of moving objects. A mechanism that tracks the location of the self and objects could use a single spatial representation, such as an allocentric map of the room, or affect multiple representations in a similar way, such as updating egocentric coordinates of objects and a representation of the self in the room. In our experiment, we attempted to match the speed and trajectories of both observers and the targets; participants walked along a curved path that was similar to the circular paths of the moving balls. Our results therefore speak to situations in which an observer&#x02019;s location changes in a very similar manner to tracking target locations. It is possible that in situations where an observer moves more quickly or along a more complicated trajectory, self-motion may reduce object tracking capacity to an even greater extent. In addition, our evidence does not allow for strong conclusions about the nature of the limitation in cognitive processing driving these effects. The concept of capacity as depicted here could be taken to suggest that the mind has slots for attending to and remembering a set number of objects (Miller, <xref ref-type="bibr" rid="B19">1956</xref>; Cowan, <xref ref-type="bibr" rid="B8">2001</xref>; Awh et al., <xref ref-type="bibr" rid="B5">2007</xref>; Zhang and Luck, <xref ref-type="bibr" rid="B34">2008</xref>). However, results are equally compatible with a more complex model of cognitive processing in which limits of performance are due to other factors, such as sampling rate, interference, or optimization of representation integrity (d&#x02019;Avossa et al., <xref ref-type="bibr" rid="B9">2006</xref>; Kazanovich and Borisyuk, <xref ref-type="bibr" rid="B15">2006</xref>; Ma and Huang, <xref ref-type="bibr" rid="B16">2009</xref>; Vul et al., <xref ref-type="bibr" rid="B30">2009</xref>). Whatever the model, the results demonstrate that the cost of self-motion is approximately the same as the cost of tracking another object, suggesting that similar processing may occur for updating the memory of the location of the self and the location of objects.</p><p>In conclusion, we find that adding self-motion to a multiple object tracking task costs a little less than adding one additional target, at least in cases where self-motion mirrors target motion such as driving in traffic, playing team sports, or walking down a crowded sidewalk. Both spatial updating and object tracking call upon a common mechanism that keeps track of the changing locations of items &#x02013; one&#x02019;s own position as well as those of objects in the environment. This mechanism may process information about self-location somewhat more efficiently than information about other objects. Such efficiency may not be surprising. After all, we have more experience keeping track of where we are than we do for any external objects and before we can act effectively on our environment, we must first have a representation of where we are within it.</p></sec><sec><title>Conflict of Interest Statement</title><p>The authors declare that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></sec></body><back><ack><p>Support for this work was provided by NSF MRI Grant 0821640 and NEI Core Grant P20-EY008126. We would like to thank Nicole Jardine for her assistance with testing participants in the experiment.</p></ack><ref-list><title>References</title><ref id="B1"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Allen</surname><given-names>R.</given-names></name><name><surname>McGeorge</surname><given-names>P.</given-names></name><name><surname>Pearson</surname><given-names>D.</given-names></name><name><surname>Milne</surname><given-names>A.</given-names></name></person-group> (<year>2006</year>). <article-title>Multiple-object tracking: a role for working memory?</article-title> <source>Q. J. Exp. Psychol.</source> <volume>59</volume>, <fpage>1101</fpage>&#x02013;<lpage>1116</lpage><pub-id pub-id-type="doi">10.1080/02724980543000097</pub-id></mixed-citation></ref><ref id="B2"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alvarez</surname><given-names>G. A.</given-names></name><name><surname>Cavanagh</surname><given-names>P.</given-names></name></person-group> (<year>2004</year>). <article-title>The capacity of visual short-term memory is set both by visual information load and by number of objects</article-title>. <source>Psychol. Sci.</source> <volume>15</volume>, <fpage>106</fpage>&#x02013;<lpage>111</lpage><pub-id pub-id-type="doi">10.1111/j.0963-7214.2004.01502006.x</pub-id><pub-id pub-id-type="pmid">14738517</pub-id></mixed-citation></ref><ref id="B3"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Alvarez</surname><given-names>G. A.</given-names></name><name><surname>Franconeri</surname><given-names>S. L.</given-names></name></person-group> (<year>2007</year>). <article-title>How many objects can you track? Evidence for a resource-limited attentive tracking mechanism</article-title>. <source>J. Vis.</source> <volume>7</volume>, <fpage>1</fpage>&#x02013;<lpage>10</lpage><pub-id pub-id-type="doi">10.1167/7.12.1</pub-id></mixed-citation></ref><ref id="B4"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Amorim</surname><given-names>M. A.</given-names></name><name><surname>Glasauer</surname><given-names>S.</given-names></name><name><surname>Corpinot</surname><given-names>K.</given-names></name><name><surname>andBerthoz</surname><given-names>A.</given-names></name></person-group> (<year>1997</year>). <article-title>Updating an object&#x02019;s orientation and location during nonvisual navigation: a comparison between two processing modes</article-title>. <source>Percept. Psychophys.</source> <volume>59</volume>, <fpage>404</fpage>&#x02013;<lpage>418</lpage><pub-id pub-id-type="doi">10.3758/BF03211907</pub-id><pub-id pub-id-type="pmid">9136270</pub-id></mixed-citation></ref><ref id="B5"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Awh</surname><given-names>E.</given-names></name><name><surname>Barton</surname><given-names>B.</given-names></name><name><surname>Vogel</surname><given-names>E. K.</given-names></name></person-group> (<year>2007</year>). <article-title>Visual working memory represents a fixed number of items regardless of complexity</article-title>. <source>Psychol. Sci.</source> <volume>18</volume>, <fpage>622</fpage>&#x02013;<lpage>628</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2007.01949.x</pub-id><pub-id pub-id-type="pmid">17614871</pub-id></mixed-citation></ref><ref id="B6"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Baddeley</surname><given-names>A.</given-names></name></person-group> (<year>1992</year>). <article-title>Working memory</article-title>. <source>Science</source> <volume>255</volume>, <fpage>556</fpage>&#x02013;<lpage>559</lpage><pub-id pub-id-type="doi">10.1126/science.1736359</pub-id><pub-id pub-id-type="pmid">1736359</pub-id></mixed-citation></ref><ref id="B7"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cavanagh</surname><given-names>P.</given-names></name><name><surname>Alvarez</surname><given-names>G.</given-names></name></person-group> (<year>2005</year>). <article-title>Tracking multiple objects with multifocal attention</article-title>. <source>Trends Cogn. Sci. (Regul. Ed.)</source> <volume>9</volume>, <fpage>349</fpage>&#x02013;<lpage>354</lpage><pub-id pub-id-type="doi">10.1016/j.tics.2005.05.009</pub-id><pub-id pub-id-type="pmid">15953754</pub-id></mixed-citation></ref><ref id="B8"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Cowan</surname><given-names>N.</given-names></name></person-group> (<year>2001</year>). <article-title>The magical number 4 in short-term memory: a reconsideration of mental storage capacity</article-title>. <source>Behav. Brain Sci.</source> <volume>24</volume>, <fpage>87</fpage>&#x02013;<lpage>114</lpage><pub-id pub-id-type="doi">10.1017/S0140525X0161392X</pub-id><pub-id pub-id-type="pmid">11515286</pub-id></mixed-citation></ref><ref id="B9"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>d&#x02019;Avossa</surname><given-names>G.</given-names></name><name><surname>Shulman</surname><given-names>G. L.</given-names></name><name><surname>Snyder</surname><given-names>A. Z.</given-names></name><name><surname>Corbetta</surname><given-names>M.</given-names></name></person-group> (<year>2006</year>). <article-title>Attentional selection of moving objects by a serial process</article-title>. <source>Vision Res.</source> <volume>46</volume>, <fpage>3403</fpage>&#x02013;<lpage>3412</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2006.04.018</pub-id><pub-id pub-id-type="pmid">16857234</pub-id></mixed-citation></ref><ref id="B10"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farrell</surname><given-names>M. J.</given-names></name><name><surname>Robertson</surname><given-names>I. H.</given-names></name></person-group> (<year>1998</year>). <article-title>Mental rotation and the automatic updating of body-centered spatial relationships</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source> <volume>24</volume>, <fpage>227</fpage>&#x02013;<lpage>233</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.24.1.227</pub-id></mixed-citation></ref><ref id="B11"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Farrell</surname><given-names>M. J.</given-names></name><name><surname>Thomson</surname><given-names>J. A.</given-names></name></person-group> (<year>1998</year>). <article-title>Automatic spatial updating during locomotion without vision</article-title>. <source>Q. J. Exp. Psychol.</source> <volume>51A</volume>, <fpage>637</fpage>&#x02013;<lpage>654</lpage></mixed-citation></ref><ref id="B12"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fougnie</surname><given-names>D.</given-names></name><name><surname>Marois</surname><given-names>R.</given-names></name></person-group> (<year>2006</year>). <article-title>Distinct capacity limits for attention and working memory</article-title>. <source>Psychol. Sci.</source> <volume>17</volume>, <fpage>526</fpage>&#x02013;<lpage>534</lpage><pub-id pub-id-type="doi">10.1111/j.1467-9280.2006.01739.x</pub-id><pub-id pub-id-type="pmid">16771804</pub-id></mixed-citation></ref><ref id="B13"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hulleman</surname><given-names>J.</given-names></name></person-group> (<year>2005</year>). <article-title>The mathematics of multiple object tracking: from proportions correct to number of objects tracked</article-title>. <source>Vision Res.</source> <volume>45</volume>, <fpage>2298</fpage>&#x02013;<lpage>2309</lpage><pub-id pub-id-type="doi">10.1016/j.visres.2005.02.016</pub-id><pub-id pub-id-type="pmid">15924943</pub-id></mixed-citation></ref><ref id="B14"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jiang</surname><given-names>Y. V.</given-names></name><name><surname>Shim</surname><given-names>W. M.</given-names></name><name><surname>Makovski</surname><given-names>T.</given-names></name></person-group> (<year>2008</year>). <article-title>Visual working memory for line orientations and face identities</article-title>. <source>Atten. Percept. Psychophys.</source> <volume>70</volume>, <fpage>1581</fpage>&#x02013;<lpage>1591</lpage><pub-id pub-id-type="doi">10.3758/PP.70.8.1581</pub-id></mixed-citation></ref><ref id="B15"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kazanovich</surname><given-names>Y.</given-names></name><name><surname>Borisyuk</surname><given-names>R.</given-names></name></person-group> (<year>2006</year>). <article-title>An oscillatory neural model of multiple object tracking</article-title>. <source>Neural Comput.</source> <volume>18</volume>, <fpage>1413</fpage>&#x02013;<lpage>1440</lpage><pub-id pub-id-type="doi">10.1162/neco.2006.18.6.1413</pub-id><pub-id pub-id-type="pmid">16764509</pub-id></mixed-citation></ref><ref id="B16"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>W. J.</given-names></name><name><surname>Huang</surname><given-names>W.</given-names></name></person-group> (<year>2009</year>). <article-title>No capacity limit in attentional tracking: evidence for probabilistic inference under a resource constraint</article-title>. <source>J. Vis.</source> <volume>9</volume>, <fpage>1</fpage>&#x02013;<lpage>30</lpage><pub-id pub-id-type="doi">10.1167/9.2.1</pub-id></mixed-citation></ref><ref id="B17"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Macmillan</surname><given-names>N. A.</given-names></name><name><surname>Creelman</surname><given-names>C. D.</given-names></name></person-group> (<year>2005</year>). <source>Detection Theory: A User&#x02019;s Guide</source>, <edition>2nd Edn</edition> <publisher-loc>Mahwah, NJ</publisher-loc>: <publisher-name>Lawrence Erlbaum Associates</publisher-name></mixed-citation></ref><ref id="B18"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>May</surname><given-names>M.</given-names></name><name><surname>Klatzky</surname><given-names>R. L.</given-names></name></person-group> (<year>2000</year>). <article-title>Path integration while ignoring irrelevant movement</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source> <volume>26</volume>, <fpage>169</fpage>&#x02013;<lpage>186</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.26.1.169</pub-id><pub-id pub-id-type="pmid">10682296</pub-id></mixed-citation></ref><ref id="B19"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Miller</surname><given-names>G. A.</given-names></name></person-group> (<year>1956</year>). <article-title>The magical number seven plus or minus two: some limits on our capacity for processing information</article-title>. <source>Psychol. Rev.</source> <volume>63</volume>, <fpage>81</fpage>&#x02013;<lpage>97</lpage><pub-id pub-id-type="doi">10.1037/h0043158</pub-id><pub-id pub-id-type="pmid">13310704</pub-id></mixed-citation></ref><ref id="B20"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Oakes</surname><given-names>L. M.</given-names></name><name><surname>Hurley</surname><given-names>K. B.</given-names></name><name><surname>Ross-Sheehy</surname><given-names>S.</given-names></name><name><surname>Luck</surname><given-names>S. J.</given-names></name></person-group> (<year>2010</year>). <article-title>Developmental changes in infants&#x02019; visual short-term memory for location</article-title>. <source>Cognition</source> <volume>118</volume>, <fpage>293</fpage>&#x02013;<lpage>305</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2010.11.007</pub-id></mixed-citation></ref><ref id="B21"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pashler</surname><given-names>H.</given-names></name></person-group> (<year>1988</year>). <article-title>Familiarity and visual change detection</article-title>. <source>Percept. Psychophys.</source> <volume>44</volume>, <fpage>369</fpage>&#x02013;<lpage>378</lpage><pub-id pub-id-type="doi">10.3758/BF03210419</pub-id><pub-id pub-id-type="pmid">3226885</pub-id></mixed-citation></ref><ref id="B22"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Pylyshyn</surname><given-names>Z.</given-names></name><name><surname>Storm</surname><given-names>R.</given-names></name></person-group> (<year>1988</year>). <article-title>Tracking multiple independent targets: evidence for a parallel tracking mechanism</article-title>. <source>Spat. Vis.</source> <volume>3</volume>, <fpage>179</fpage>&#x02013;<lpage>198</lpage><pub-id pub-id-type="doi">10.1163/156856888X00122</pub-id><pub-id pub-id-type="pmid">3153671</pub-id></mixed-citation></ref><ref id="B23"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rieser</surname><given-names>J. J.</given-names></name></person-group> (<year>1989</year>). <article-title>Access to knowledge of spatial structure at novel points of observation</article-title>. <source>J. Exp. Psychol. Learn. Mem. Cogn.</source> <volume>15</volume>, <fpage>1157</fpage>&#x02013;<lpage>1165</lpage><pub-id pub-id-type="doi">10.1037/0278-7393.15.6.1157</pub-id><pub-id pub-id-type="pmid">2530309</pub-id></mixed-citation></ref><ref id="B24"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ross-Sheehy</surname><given-names>S.</given-names></name><name><surname>Oakes</surname><given-names>L. M.</given-names></name><name><surname>Luck</surname><given-names>S. J.</given-names></name></person-group> (<year>2003</year>). <article-title>The development of visual short-term memory capacity in infants</article-title>. <source>Child Dev.</source> <volume>74</volume>, <fpage>1807</fpage>&#x02013;<lpage>1822</lpage><pub-id pub-id-type="doi">10.1046/j.1467-8624.2003.00639.x</pub-id><pub-id pub-id-type="pmid">14669897</pub-id></mixed-citation></ref><ref id="B25"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Scholl</surname><given-names>B. J.</given-names></name><name><surname>Pylyshyn</surname><given-names>Z. W.</given-names></name><name><surname>Feldman</surname><given-names>J.</given-names></name></person-group> (<year>2001</year>). <article-title>What is a visual object? Evidence from target merging in multiple object tracking</article-title>. <source>Cognition</source> <volume>80</volume>, <fpage>159</fpage>&#x02013;<lpage>177</lpage><pub-id pub-id-type="doi">10.1016/S0010-0277(00)00152-9</pub-id><pub-id pub-id-type="pmid">11245843</pub-id></mixed-citation></ref><ref id="B26"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Thomas</surname><given-names>L. E.</given-names></name><name><surname>Seiffert</surname><given-names>A. E.</given-names></name></person-group> (<year>2010</year>). <article-title>Self-motion impairs multiple-object tracking</article-title>. <source>Cognition</source> <volume>117</volume>, <fpage>80</fpage>&#x02013;<lpage>86</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2010.07.002</pub-id><pub-id pub-id-type="pmid">20659732</pub-id></mixed-citation></ref><ref id="B27"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Todd</surname><given-names>J. J.</given-names></name><name><surname>Marois</surname><given-names>R.</given-names></name></person-group> (<year>2004</year>). <article-title>Capacity limit of visual short-term memory in human posterior parietal cortex</article-title>. <source>Nature</source> <volume>428</volume>, <fpage>751</fpage>&#x02013;<lpage>754</lpage><pub-id pub-id-type="doi">10.1038/nature02466</pub-id><pub-id pub-id-type="pmid">15085133</pub-id></mixed-citation></ref><ref id="B28"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tombu</surname><given-names>M.</given-names></name><name><surname>Seiffert</surname><given-names>A. E.</given-names></name></person-group> (<year>2008</year>). <article-title>Attentional costs in multiple-object tracking</article-title>. <source>Cognition</source> <volume>108</volume>, <fpage>1</fpage>&#x02013;<lpage>25</lpage><pub-id pub-id-type="doi">10.1016/j.cognition.2007.12.014</pub-id><pub-id pub-id-type="pmid">18281028</pub-id></mixed-citation></ref><ref id="B29"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Vogel</surname><given-names>E. K.</given-names></name><name><surname>Woodman</surname><given-names>G. F.</given-names></name><name><surname>Luck</surname><given-names>S. J.</given-names></name></person-group> (<year>2001</year>). <article-title>Storage of features, conjunctions, and objects in visual working memory</article-title>. <source>J. Exp. Psychol. Hum. Percept. Perform.</source> <volume>27</volume>, <fpage>92</fpage>&#x02013;<lpage>114</lpage><pub-id pub-id-type="doi">10.1037/0096-1523.27.1.92</pub-id><pub-id pub-id-type="pmid">11248943</pub-id></mixed-citation></ref><ref id="B30"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Vul</surname><given-names>E.</given-names></name><name><surname>Frank</surname><given-names>M. C.</given-names></name><name><surname>Tenenbaum</surname><given-names>J. B.</given-names></name><name><surname>Alvarez</surname><given-names>G.</given-names></name></person-group> (<year>2009</year>). <article-title>&#x0201c;Explaining human multiple object tracking as resource-constrained approximate interference in a dynamic probabilistic model,&#x0201d;</article-title> in <source>Advances in Neural Information Processing Systems</source>, eds <person-group person-group-type="editor"><name><surname>Bengio</surname><given-names>Y.</given-names></name><name><surname>Schuurmans</surname><given-names>D.</given-names></name><name><surname>Lafferty</surname><given-names>J.</given-names></name><name><surname>Williams</surname><given-names>C. K. I.</given-names></name><name><surname>Culotta</surname><given-names>A.</given-names></name></person-group> (<publisher-loc>Cambridge, MA</publisher-loc>: <publisher-name>MIT Press</publisher-name>), <fpage>22</fpage></mixed-citation></ref><ref id="B31"><mixed-citation publication-type="book"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>R. F.</given-names></name></person-group> (<year>2007</year>). <article-title>&#x0201c;Spatial processing and view-dependent representations,&#x0201d;</article-title> in <source>Spatial Processing in Navigation, Imagery, and Perception</source>, eds <person-group person-group-type="editor"><name><surname>Mast</surname><given-names>F.</given-names></name><name><surname>Jancke</surname><given-names>L.</given-names></name></person-group> (<publisher-loc>New York, NY</publisher-loc>: <publisher-name>Springer Science+ Business Media Inc.</publisher-name>), <fpage>49</fpage>&#x02013;<lpage>65</lpage></mixed-citation></ref><ref id="B32"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Wang</surname><given-names>R. F.</given-names></name><name><surname>Crowell</surname><given-names>J. A.</given-names></name><name><surname>Simons</surname><given-names>D. J.</given-names></name><name><surname>Irwin</surname><given-names>D. E.</given-names></name><name><surname>Kramer</surname><given-names>A. F.</given-names></name><name><surname>Ambinder</surname><given-names>M. S.</given-names></name><name><surname>Thomas</surname><given-names>L. E.</given-names></name><name><surname>Gosney</surname><given-names>J. L.</given-names></name><name><surname>Levinthal</surname><given-names>B. R.</given-names></name><name><surname>Hsieh</surname><given-names>B. B.</given-names></name></person-group> (<year>2006</year>). <article-title>Spatial updating relies on an egocentric representation of space: effects of the number of objects</article-title>. <source>Psychon. Bull. Rev.</source> <volume>13</volume>, <fpage>281</fpage>&#x02013;<lpage>286</lpage><pub-id pub-id-type="doi">10.3758/BF03193844</pub-id><pub-id pub-id-type="pmid">16892995</pub-id></mixed-citation></ref><ref id="B33"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xu</surname><given-names>Y.</given-names></name><name><surname>Chun</surname><given-names>M. M.</given-names></name></person-group> (<year>2006</year>). <article-title>Dissociable neural mechanisms supporting visual short-term memory for objects</article-title>. <source>Nature</source> <volume>440</volume>, <fpage>91</fpage>&#x02013;<lpage>95</lpage><pub-id pub-id-type="doi">10.1038/440287a</pub-id><pub-id pub-id-type="pmid">16382240</pub-id></mixed-citation></ref><ref id="B34"><mixed-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>W.</given-names></name><name><surname>Luck</surname><given-names>S. J.</given-names></name></person-group> (<year>2008</year>). <article-title>Discrete fixed-resolution representations in visual working memory</article-title>. <source>Nature</source> <volume>453</volume>, <fpage>233</fpage>&#x02013;<lpage>235</lpage><pub-id pub-id-type="doi">10.1038/nature06860</pub-id><pub-id pub-id-type="pmid">18385672</pub-id></mixed-citation></ref></ref-list></back></article>