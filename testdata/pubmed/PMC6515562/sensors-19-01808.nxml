<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sensors (Basel)</journal-id><journal-id journal-id-type="iso-abbrev">Sensors (Basel)</journal-id><journal-id journal-id-type="publisher-id">sensors</journal-id><journal-title-group><journal-title>Sensors (Basel, Switzerland)</journal-title></journal-title-group><issn pub-type="epub">1424-8220</issn><publisher><publisher-name>MDPI</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">31014033</article-id><article-id pub-id-type="pmc">6515562</article-id><article-id pub-id-type="doi">10.3390/s19081808</article-id><article-id pub-id-type="publisher-id">sensors-19-01808</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>A Two-Stage Method for Online Signature Verification Using Shape Contexts and Function Features <xref ref-type="author-notes" rid="fn1-sensors-19-01808">&#x02020;</xref></article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Jia</surname><given-names>Yu</given-names></name></contrib><contrib contrib-type="author"><name><surname>Huang</surname><given-names>Linlin</given-names></name><xref rid="c1-sensors-19-01808" ref-type="corresp">*</xref></contrib><contrib contrib-type="author"><name><surname>Chen</surname><given-names>Houjin</given-names></name></contrib></contrib-group><aff id="af1-sensors-19-01808">School of Electronic and Information Engineering, Beijing Jiaotong University, No. 3 Shangyuancun Haidian District, Beijing 100044, China; <email>16120010@bjtu.edu.cn</email> (Y.J.); <email>hjchen@bjtu.edu.cn</email> (H.C.)</aff><author-notes><corresp id="c1-sensors-19-01808"><label>*</label>Correspondence: <email>huangll@bjtu.edu.cn</email>; Tel.: +86-010-5168-8206</corresp><fn id="fn1-sensors-19-01808"><label>&#x02020;</label><p>This paper is an extended version of our paper published in PRCV 2018: Chinese Conference on Pattern Recognition and Computer Vision, Guangzhou, China, 23&#x02013;26 November 2018.</p></fn></author-notes><pub-date pub-type="epub"><day>16</day><month>4</month><year>2019</year></pub-date><pub-date pub-type="collection"><month>4</month><year>2019</year></pub-date><volume>19</volume><issue>8</issue><elocation-id>1808</elocation-id><history><date date-type="received"><day>18</day><month>3</month><year>2019</year></date><date date-type="accepted"><day>13</day><month>4</month><year>2019</year></date></history><permissions><copyright-statement>&#x000a9; 2019 by the authors.</copyright-statement><copyright-year>2019</copyright-year><license license-type="open-access"><license-p>Licensee MDPI, Basel, Switzerland. This article is an open access article distributed under the terms and conditions of the Creative Commons Attribution (CC BY) license (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>).</license-p></license></permissions><abstract><p>As a behavioral biometric trait, an online signature is extensively used to verify a person&#x02019;s identity in many applications. In this paper, we present a method using shape contexts and function features as well as a two-stage strategy for accurate online signature verification. Specifically, in the first stage, features of shape contexts are extracted from the input and classification is made based on distance metric. Only the inputs passing by the first stage are represented by a set of function features and verified. To improve the matching accuracy and efficiency, we propose shape context-dynamic time warping (SC-DTW) to compare the test signature with the enrolled reference ones based on the extracted function features. Then, classification based on interval-valued symbolic representation is employed to decide if the test signature is a genuine one. The proposed method is evaluated on SVC2004 Task 2 achieving an Equal Error Rate of 2.39% which is competitive to the state-of-the-art approaches. The experiment results demonstrate the effectiveness of the proposed method.</p></abstract><kwd-group><kwd>online signature verification</kwd><kwd>shape contexts</kwd><kwd>function features</kwd><kwd>SC-DTW</kwd><kwd>symbolic representation</kwd><kwd>two-stage method</kwd></kwd-group></article-meta></front><body><sec sec-type="intro" id="sec1-sensors-19-01808"><title>1. Introduction</title><p>Biometric verification technology has aroused a lot of interest due to its reliability, effectiveness, and convenience in verifying personal identity [<xref rid="B1-sensors-19-01808" ref-type="bibr">1</xref>]. Verification techniques based on face [<xref rid="B2-sensors-19-01808" ref-type="bibr">2</xref>], fingerprint, and some such physiological biometric attributes have brought extra convenience and changed our lifestyle [<xref rid="B3-sensors-19-01808" ref-type="bibr">3</xref>]. Although behavioral biometric attributes are slightly inferior to physiological ones in stability and uniqueness, they are more accessible and less intrusive to users. Voice, signature, gait, etc. are all typical behavioral attributes. Among them, signature remains the most widespread and recognized socially and legally verification approach in our day-to-day life [<xref rid="B4-sensors-19-01808" ref-type="bibr">4</xref>]. Signing is a customary and fast movement driven by long-term nervous system and writing habit. Therefore, signature verification techniques can have more potential applications in the real world.</p><p>Depending on the different methods of signature acquisition, signature verification technique can be split into two categories: offline and online. In the system of offline signature verification [<xref rid="B5-sensors-19-01808" ref-type="bibr">5</xref>], images containing signatures are collected after finishing the signing process. For online signature verification, signatures are captured by sensor-based devices while the user is signing and represented by a set of temporal functions, from which both static and dynamic features are extracted and then used to make a decision on whether the signature belongs to its claimed user. Compared with offline signature verification, the dynamic information collection of online signature ensures its uniqueness and higher difficulty to forge, so online signature verification technique usually owns better performance in accuracy and security.</p><p>There are two parts of an online signature verification system: enrolment and verification. Several signatures are provided as reference signatures by the users during enrolment and their extracted features along with calculated thresholds would be stored in the knowledge base. In verification, the authenticity of a test signature is evaluated by matching its features with those from reference signatures of its claimed user [<xref rid="B6-sensors-19-01808" ref-type="bibr">6</xref>].</p><p>Online signatures are collected by electronic devices such as tablets, smart phones, and so on. Most of them use sensors to capture various real-time data such as coordinates, pressure, timestamp, etc. during signing. After collection, the signatures are represented as time series and then undergo preprocessing and feature extraction modules successively.</p><p>Online signature verification methods can be categorized based on the feature extraction process and matching strategy [<xref rid="B7-sensors-19-01808" ref-type="bibr">7</xref>]. According to the employed features, there are broadly two groups: parametric and function features-based approaches. In the framework of parametric features-based methods, a signature is characterized as a vector of elements and each one is a representative of the value of one feature [<xref rid="B8-sensors-19-01808" ref-type="bibr">8</xref>]. Examples of such attributes are width, height, average speed, etc. The dimensions of parametric features of signatures are all equal. In the function features-based method, a signature is represented by a multi-dimension feature set constituted by several time functions. Coordinate, timestamp, pressure, etc. are commonly used function features. Generally, the function features-based approaches perform better due to more dynamic information application, but these kinds of method consume more computational time and memory.</p><p>With regards to the matching methods, distance-based and model-based approaches are two main techniques [<xref rid="B9-sensors-19-01808" ref-type="bibr">9</xref>]. Dynamic time warping (DTW) has been often adopted in distance-based methods [<xref rid="B10-sensors-19-01808" ref-type="bibr">10</xref>]. DTW is a well-known approach for aligning vectors of different lengths. For application in signature verification, a set of features at each sample point is extracted and the similarity between the test signatures and enrolled reference signatures is then computed using dynamic programming. Point-based warping technique is a variant of DTW, wherein only selective points are warped. Extreme point [<xref rid="B11-sensors-19-01808" ref-type="bibr">11</xref>] and stroke point [<xref rid="B12-sensors-19-01808" ref-type="bibr">12</xref>] are often used. In addition, some works make a fusion of DTW with other methods. Sharma and Sundaram [<xref rid="B9-sensors-19-01808" ref-type="bibr">9</xref>] propose a method that uses the information from DTW cost matrix and warping paths alignments. The decision is made by the conjunction of warping path score and DTW score. Yanikoglu and Kholmatov [<xref rid="B13-sensors-19-01808" ref-type="bibr">13</xref>] fuse the Fast Fourier Transform with DTW and the fusion system lowers the error rate by up to about 25%. Chen and Xia [<xref rid="B14-sensors-19-01808" ref-type="bibr">14</xref>] extract a set of function features for comparing the dissimilarity-based DTW between the test signature and the template database. In addition, the nearest template and majority vote are proposed to classify. Model-based approaches employ either generative-based classifiers such as hidden Markov model (HMM) [<xref rid="B15-sensors-19-01808" ref-type="bibr">15</xref>,<xref rid="B16-sensors-19-01808" ref-type="bibr">16</xref>,<xref rid="B17-sensors-19-01808" ref-type="bibr">17</xref>] or discriminative ones such as neural network (NN) [<xref rid="B18-sensors-19-01808" ref-type="bibr">18</xref>,<xref rid="B19-sensors-19-01808" ref-type="bibr">19</xref>,<xref rid="B20-sensors-19-01808" ref-type="bibr">20</xref>] and support vector machine (SVM) [<xref rid="B21-sensors-19-01808" ref-type="bibr">21</xref>,<xref rid="B22-sensors-19-01808" ref-type="bibr">22</xref>]. Also, there are some hybrid methods that combine different methods mentioned above. Multi-stage cascade framework [<xref rid="B23-sensors-19-01808" ref-type="bibr">23</xref>], multi-stage decision-level score fusion [<xref rid="B24-sensors-19-01808" ref-type="bibr">24</xref>,<xref rid="B25-sensors-19-01808" ref-type="bibr">25</xref>] or a multi-expert system for signature verification [<xref rid="B26-sensors-19-01808" ref-type="bibr">26</xref>,<xref rid="B27-sensors-19-01808" ref-type="bibr">27</xref>] have been reported in the literature. Recently, inspired by the great success of recurrent neural networks (RNNs) in sequential modeling, several verification methods based on RNNs are proposed. Lai et al. [<xref rid="B28-sensors-19-01808" ref-type="bibr">28</xref>] propose a novel descriptor called the length-normalized path signature (LNPS) for feature representation and then features are fed into the GRU (Gated recurrent unit) network. Triplet loss and center loss were used to train the network with the BP algorithm. The method proposed in [<xref rid="B29-sensors-19-01808" ref-type="bibr">29</xref>] extracts 23 hand-crafted time function features and uses the bidirectional LSTM (Long short-term memory) and GRU networks with Siamese architecture to learn a dissimilarity metric from the pairs of signatures.</p><p>Although it is not that easy for a forger to fake a signature that is exactly the same as the genuine one, due to the large intra-class variations from one person and small inter-class variations between forgeries and genuine ones, accurate online signature verification still remains a challenging problem.</p><p>In real applications, the forgeries are usually classified to be two types, named skilled forgery and random one. A skilled forgery is signed by a person who had access to the genuine signatures and practiced for a while. A random forgery is signed without with any information about the signature, or even the name of the person whose signature is forged [<xref rid="B30-sensors-19-01808" ref-type="bibr">30</xref>]. Compared with skilled forgeries, the random forgeries are more common in our daily life. Obviously, the skilled forgeries are more difficult to verify. In addition, the loss brought by accepting forgeries is higher than that by rejecting genuine signatures, which means accepting a signature as genuine should be stricter. Considering these factors, we propose a two-stage method using shape contexts and function features for accurate online signature verification. Features of shape contexts are extracted from the input firstly and classification of this stage is based on shape distance metric. Only the inputs passing by the first stage are represented by a set of function features and verified. To improve the matching accuracy and efficiency, we employ a shape context-dynamic time warping (SC-DTW) to compare the test signature with the enrolled reference ones based on the extracted function features. An interval-valued symbolic representation-based classifier is proposed to decide if the test signature is a genuine one.</p><p>The contributions of this paper are as follows:<list list-type="bullet"><list-item><p>Based on the fact of unbalanced occurrence probability of skilled signature forgeries and random ones, a fast and accurate two-stage verification method is proposed.</p></list-item><list-item><p>Shape context feature extractor is designed to describe global shape characteristics of signature for fast classification of random forgeries.</p></list-item><list-item><p>SC-DTW is applied to fulfill comparison task and interval-valued-based representation classifier is proposed for final decision-making to achieve state-of-the-art verification performance.</p></list-item></list></p><p>This paper is an extended version of the one published in proceedings of PRCV2018 [<xref rid="B31-sensors-19-01808" ref-type="bibr">31</xref>]. In this paper, more details on feature extraction and matching methods are given. Moreover, to further improve the performance method in the paper of PRCV2018, more effective features are extracted. Instead of distance metric classification, an interval-valued symbolic representation-based classifier is employed to enhance classification ability. Besides, more detailed experimental results are reported.</p><p>The rest of this paper is organized as follows. <xref ref-type="sec" rid="sec2-sensors-19-01808">Section 2</xref> details the methodology we proposed. Signature preprocessing is presented in <xref ref-type="sec" rid="sec2dot1-sensors-19-01808">Section 2.1</xref>. <xref ref-type="sec" rid="sec2dot2-sensors-19-01808">Section 2.2</xref> presents the shape context descriptor and online signature verification method based on it. The function features extraction, feature alignment, and symbolic classifier are showed in <xref ref-type="sec" rid="sec2dot3-sensors-19-01808">Section 2.3</xref>. <xref ref-type="sec" rid="sec2dot4-sensors-19-01808">Section 2.4</xref> discusses the two-stage verification protocol. The database used in our experiment, experimental results, and performance analysis are provided in <xref ref-type="sec" rid="sec3-sensors-19-01808">Section 3</xref>. The conclusion is offered finally in <xref ref-type="sec" rid="sec4-sensors-19-01808">Section 4</xref>.</p></sec><sec sec-type="methods" id="sec2-sensors-19-01808"><title>2. Methodology</title><p>The diagram of the proposed method is shown in <xref ref-type="fig" rid="sensors-19-01808-f001">Figure 1</xref>. The input signature is first preprocessed for smoothing and normalization, and then it is fed into the shape context-based verification module, which does well in quickly distinguishing the random forgeries owing to their manifest differences in shape. Most obvious forgeries can be rule out in this stage. The signature passed through the first module is verified by function features-based verification module. This module achieves more accurate verification results due to the application of details in signature and decision fusion by interval-valued symbolic representation-based classifier.</p><sec id="sec2dot1-sensors-19-01808"><title>2.1. Preprocessing</title><p>Captured by electronic devices, the time series of a signature are mixed with noises and fluctuations unavoidably. In addition, the acquired signatures of one individual vary with time or places, with the result that there are differences in size and location between signatures. Therefore, we firstly let the acquired signatures pass the preprocessing module to address those issues. The preprocessing module includes smoothing and normalization. Gaussian smoothing is employed to filter the artifacts and smooth the data. Then we adopt moment normalization technique [<xref rid="B32-sensors-19-01808" ref-type="bibr">32</xref>] to standardize the size and location of acquired signatures.</p><p>Set the signature as <inline-formula><mml:math id="mm1"><mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm2"><mml:mrow><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>. N is the number of sample points, <inline-formula><mml:math id="mm3"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is x and y coordinates information.</p><p>In the moment normalization technique, the size of a signature is not the difference between maximum and minimum in horizontal and vertical directions, but the width and height of the window derived from its moment, as is show in <xref ref-type="fig" rid="sensors-19-01808-f002">Figure 2</xref>. Denote the width and height of window as W and H, given by
<disp-formula id="FD1-sensors-19-01808"><label>(1)</label><mml:math id="mm4"><mml:mrow><mml:mrow><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:msqrt><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mn>20</mml:mn></mml:msub></mml:msqrt><mml:mo>,</mml:mo><mml:mi>H</mml:mi><mml:mo>=</mml:mo><mml:mn>4</mml:mn><mml:msqrt><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mn>02</mml:mn></mml:msub></mml:msqrt></mml:mrow></mml:mrow></mml:math></disp-formula>
<inline-formula><mml:math id="mm5"><mml:mrow><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> denotes the center moment, and <inline-formula><mml:math id="mm6"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the signature&#x02019;s centroid.
<disp-formula id="FD2-sensors-19-01808"><label>(2)</label><mml:math id="mm7"><mml:mrow><mml:mrow><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>q</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>x</mml:mi></mml:munder><mml:munder><mml:mo>&#x02211;</mml:mo><mml:mi>y</mml:mi></mml:munder><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msup><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mi>q</mml:mi></mml:msup></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>After window calculation, the size normalization technique is implemented as follows. The heights of the signatures are normalized to a predetermined value that in this paper is 300. Moreover, the aspect ratio of before and after preprocessing remains consistent to keep the signature shape unchanged.
<disp-formula id="FD3-sensors-19-01808"><label>(3)</label><mml:math id="mm8"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:msub><mml:mrow/><mml:mi>c</mml:mi></mml:msub></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>x</mml:mi><mml:mi>c</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup><mml:mo>=</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>y</mml:mi><mml:mi>c</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msubsup></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
where <italic>x</italic> and <italic>y</italic> are smoothed originate coordinates. <inline-formula><mml:math id="mm9"><mml:mrow><mml:msup><mml:mi>x</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm10"><mml:mrow><mml:msup><mml:mi>y</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msup></mml:mrow></mml:math></inline-formula> are normalized coordinates. <inline-formula><mml:math id="mm11"><mml:mrow><mml:msubsup><mml:mi>x</mml:mi><mml:mi>c</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm12"><mml:mrow><mml:msubsup><mml:mi>y</mml:mi><mml:mi>c</mml:mi><mml:mo>&#x02032;</mml:mo></mml:msubsup></mml:mrow></mml:math></inline-formula> are the centroid of normalized signature. <inline-formula><mml:math id="mm13"><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm14"><mml:mrow><mml:mi>&#x003b2;</mml:mi></mml:mrow></mml:math></inline-formula> are the ratio of the normalized signature size to its original size, given by
<disp-formula id="FD4-sensors-19-01808"><label>(4)</label><mml:math id="mm15"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mi>W</mml:mi></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>&#x003b2;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:mi>H</mml:mi></mml:mfrac><mml:mo>,</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mfrac><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mfrac><mml:mo>=</mml:mo><mml:mfrac><mml:mi>W</mml:mi><mml:mi>H</mml:mi></mml:mfrac></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm16"><mml:mrow><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm17"><mml:mrow><mml:msub><mml:mi>H</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> denote the normalized width and height.</p><p>Signatures are centered at (0, 0) to normalize their locations. After preprocessing, the signatures have the same size and location. In this paper, we did not employ translation normalization since we believe signature&#x02019;s angle is an out-of-habit feature. <xref ref-type="fig" rid="sensors-19-01808-f002">Figure 2</xref> shows some examples of original signatures and corresponding preprocessed signatures.</p></sec><sec id="sec2dot2-sensors-19-01808"><title>2.2. Shape Context-Based Online Signature Verification</title><p>In the methods proposed for online signature verification, the dynamics properties of the signatures, for example, velocity, pressure, acceleration, etc. are widely applied. However, the shape of signature contains very useful details, which is critical for distinguish a signature between forgery and genuine one. The method proposed by Gupta and Joyce [<xref rid="B33-sensors-19-01808" ref-type="bibr">33</xref>] extracts the dynamics properties of position extreme points of signatures and achieved better performance. Features based on shape also have been successively applied in offline signature verification [<xref rid="B34-sensors-19-01808" ref-type="bibr">34</xref>].</p><p>In this paper, we propose a verification method based on shape context features. Specifically, shape context descriptor [<xref rid="B34-sensors-19-01808" ref-type="bibr">34</xref>,<xref rid="B35-sensors-19-01808" ref-type="bibr">35</xref>] is used to extract features of a signature and a cost matrix is computed. After finding the best one-to-one matching between two signatures&#x02019; shape and modeling transformation, the measurable shape distance is used for classification. To further improve the efficiency, only trend-transition-points (TTPs) that can represent the shape of a signature roughly are used for calculating distance.</p><sec id="sec2dot2dot1-sensors-19-01808"><title>2.2.1. Shape Context Feature Extraction</title><p>Shape context descriptor captures the distribution over relative positions of shape points and the connectivity properties between features points along curves. Therefore, shape context features not only provide global characterization of shape but also contain more contextual information within a certain range of a signature. Besides, shape context descriptor is designed in a way of describing shapes that allows for measuring shape similarity and the recovering of point correspondences. Traditionally, the first step is to randomly select a set of points that lie on the edges of two shapes separately. Here the shape of an online signature is represented by a set of sampled points which in this work is <inline-formula><mml:math id="mm18"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>, <inline-formula><mml:math id="mm19"><mml:mrow><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. <italic>N</italic> is the number of sampled points.</p><p><xref ref-type="fig" rid="sensors-19-01808-f003">Figure 3</xref> shows the shapes and shape context histograms of a reference signature, a genuine signature and a skilled forgery of one user. Because the writing speed is a kind of relatively fixed and unique information, the number and distribution of sample points between genuine signature and reference signature are more similar. Taking one point as the origin of polar coordinate, the shape contexts of this point can be represented using log-polar histogram. We set five bins for <inline-formula><mml:math id="mm20"><mml:mrow><mml:mrow><mml:mi>l</mml:mi><mml:mi>o</mml:mi><mml:mi>g</mml:mi><mml:mi>r</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and 12 bins for <inline-formula><mml:math id="mm21"><mml:mrow><mml:mi>&#x003b8;</mml:mi></mml:mrow></mml:math></inline-formula>. The number of neighboring points that fall into the very bin is just the histogram value. <xref ref-type="fig" rid="sensors-19-01808-f003">Figure 3</xref>d&#x02013;f present the corresponding histograms for certain points. We can see that the difference in shape context histograms between genuine signature and reference signature is relatively small, while the histogram of skilled forgeries is quite dissimilar to the reference ones.</p><p>Considering a point <inline-formula><mml:math id="mm22"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> on the first shape and a point <inline-formula><mml:math id="mm23"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> on the second shape, denote <inline-formula><mml:math id="mm24"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> as the matching cost of these two points, given by
<disp-formula id="FD5-sensors-19-01808"><label>(5)</label><mml:math id="mm25"><mml:mrow><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mn>1</mml:mn><mml:mn>2</mml:mn></mml:mfrac><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>k</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>K</mml:mi></mml:munderover><mml:mfrac><mml:msup><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>k</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>k</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>k</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>k</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm26"><mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>k</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm27"><mml:mrow><mml:mrow><mml:msub><mml:mi>h</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>k</mml:mi><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> denote the <inline-formula><mml:math id="mm28"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> bin histogram at <inline-formula><mml:math id="mm29"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm30"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> respectively.</p><p>For all pairs of points <inline-formula><mml:math id="mm31"><mml:mrow><mml:msub><mml:mi>p</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> on the first shape and <inline-formula><mml:math id="mm32"><mml:mrow><mml:msub><mml:mi>q</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> on the second shape, calculate the cost as Equation (<xref ref-type="disp-formula" rid="FD5-sensors-19-01808">5</xref>) and then we got a cost matrix. The next step is to find the optimal alignment between two shapes that minimizes total cost. This can be done by the Hungarian method with time complexity of <inline-formula><mml:math id="mm33"><mml:mrow><mml:mrow><mml:mi>O</mml:mi><mml:mo>(</mml:mo><mml:msup><mml:mi>N</mml:mi><mml:mn>3</mml:mn></mml:msup><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>. The cost between shape contexts is based on the chi-square test statistic that is not a suitable distance metric. Thin plate spline (TPS) model is adopted for modeling transformation [<xref rid="B35-sensors-19-01808" ref-type="bibr">35</xref>]. After that, we get the measurable distance of two shapes. The smaller the distance, the more similar these two shapes, or vice versa. So, if the average distance between test signature and reference signatures is lower than a threshold, it would be accepted as a genuine signature of its claimed user.</p></sec><sec id="sec2dot2dot2-sensors-19-01808"><title>2.2.2. Trend-Transition-Point Selection</title><p>The shape context representation of signature should not only capture specific shape features but also allow considerable variations. Besides, the computational load of distance calculation is closely related to the number of points. Therefore, with the hope of efficiency improvement and variances tolerance, a few representative points are selected. Only selected points can participate in shape distance calculation. In this paper, we propose the TTP selection method.</p><p>Trend-transition-points are the points where the curve trends before and after them are completely different while the trends between two successive TTPs do not have obvious change so that the curve shape of the segment approximates to a straight line. So, the signature could be re-constructed with these points. In our method, local extreme points and corner points are all defined as TTPs. The local extreme points are selected depending on its value greater or smaller than its neighborhood. The corner points selection we adopted is proposed in [<xref rid="B36-sensors-19-01808" ref-type="bibr">36</xref>,<xref rid="B37-sensors-19-01808" ref-type="bibr">37</xref>], which makes use of the smaller eigenvalues of covariance matrices of regions of support.</p><p>Let <inline-formula><mml:math id="mm34"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> denotes the region of support (ROS) of point <inline-formula><mml:math id="mm35"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>, a small curve segment containing itself and <italic>k</italic> points in its left and right neighborhoods. That is
<disp-formula><mml:math id="mm36"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mo>|</mml:mo><mml:mi>j</mml:mi><mml:mo>=</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>k</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>i</mml:mi><mml:mo>+</mml:mo><mml:mi>k</mml:mi></mml:mrow></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm37"><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>j</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> are the Cartesian coordinates of <inline-formula><mml:math id="mm38"><mml:mrow><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>.</p><p>Therefore, the <inline-formula><mml:math id="mm39"><mml:mrow><mml:mrow><mml:mn>2</mml:mn><mml:mo>&#x000d7;</mml:mo><mml:mn>2</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> covariance matrix for points in the segment <inline-formula><mml:math id="mm40"><mml:mrow><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>s</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> is calculated. <inline-formula><mml:math id="mm41"><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>L</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm42"><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> are two eigenvalues corresponding to the covariance matrix. The smaller eigenvalues <inline-formula><mml:math id="mm43"><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> can be used to measure prominence of corners over its ROS. In other words, sharper corner points have the large <inline-formula><mml:math id="mm44"><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and weaker corners have small one. When the points are on a straight line or on a flat curve, the <inline-formula><mml:math id="mm45"><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> will be very small, even approximate to zero. So, corners can be determined if its <inline-formula><mml:math id="mm46"><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> exceeds a predetermined threshold.</p><p>Shape contexts are calculated on every point, but only TTPs are used to distance calculation. For every sample point of signatures, the algorithm is implemented as follows.</p><list list-type="simple"><list-item><label>Step 1:</label><p>If the point is a start point, add it to TTP dataset. Else, go to Step 2;</p></list-item><list-item><label>Step 2:</label><p>If the point is an end point, add it to TTP dataset and go to Step 5. Else, go to Step 3;</p></list-item><list-item><label>Step 3:</label><p>If the point is an extreme point, add it to TTP dataset. Else, go to Step 4;</p></list-item><list-item><label>Step 4:</label><p>If the point is a corner point, add it to TTP dataset. Else, head to next sample point and return to Step 2;</p></list-item><list-item><label>Step 5:</label><p>For all points in TTP dataset, the point with smaller <inline-formula><mml:math id="mm47"><mml:mrow><mml:msub><mml:mi>&#x003bb;</mml:mi><mml:mi>S</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> would be deleted when the distance of two successive points is lower than a threshold. The process repeats several times until the distances between points are long enough.</p></list-item></list></sec></sec><sec id="sec2dot3-sensors-19-01808"><title>2.3. Function Features-Based Online Signature Verification</title><p>One of the advantages of online signature verification is that signature is captured by specialized sensors-based devices. So dynamic information can be recorded and used for verification, which makes verification more accurate and reliable. In function features-based methods, a set of function features, such as position, pressure, velocity, acceleration, etc., is firstly captured. Then matching between features of the test and the reference and decision-making are implemented.</p><sec id="sec2dot3dot1-sensors-19-01808"><title>2.3.1. Function Features Extraction</title><p>Usually, lots of features can be obtained directly from the specialized electronic devices. Horizontal and vertical position, pressure and timestamp of each sample point are the basic measurements. Let <inline-formula><mml:math id="mm48"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>,</mml:mo><mml:mi>y</mml:mi><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mo>,</mml:mo><mml:mi>t</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> be the mentioned basic measurements, <inline-formula><mml:math id="mm49"><mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mn>3</mml:mn><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> be the discrete time index of the temporal functions and <italic>N</italic> be the time duration of a signature in sampling units [<xref rid="B14-sensors-19-01808" ref-type="bibr">14</xref>]. Based on them, various features can be derived. Among them, 20 frequently used function features are selected. The features are grouped according to their properties, such as position-related, pressure-related, velocity-related, acceleration-related, and angle-related. The features are listed in <xref rid="sensors-19-01808-t001" ref-type="table">Table 1</xref>.</p></sec><sec id="sec2dot3dot2-sensors-19-01808"><title>2.3.2. Matching Based on Shape Context-Dynamic Time Warping (SC-DTW)</title><p>Feature matching is very critical for function features-based verification. In recent years, DTW has been widely applied as the matching technique in online signature verification. The DTW method compress or expand the time axis of two temporal functions locally to make them aligned.</p><p>Here are two time series <inline-formula><mml:math id="mm50"><mml:mrow><mml:mrow><mml:mi>T</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>N</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm51"><mml:mrow><mml:mrow><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mi>M</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> and their lengths are N and M respectively. The similarity between the <inline-formula><mml:math id="mm52"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> point of <italic>T</italic> and the <inline-formula><mml:math id="mm53"><mml:mrow><mml:msub><mml:mi>m</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> point of <italic>R</italic> are calculated according to defined similarity rule. All the similarity values constitute a DTW cost matrix denoted by <inline-formula><mml:math id="mm54"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> defined as:<disp-formula id="FD6-sensors-19-01808"><label>(6)</label><mml:math id="mm55"><mml:mrow><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mo>&#x02016;</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mi>m</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mrow><mml:mo>&#x02016;</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>The overall distance is calculated as following equation:<disp-formula id="FD7-sensors-19-01808"><label>(7)</label><mml:math id="mm56"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:mo movablelimits="true" form="prefix">min</mml:mo><mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>D</mml:mi><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>D</mml:mi><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>D</mml:mi><mml:mo>(</mml:mo><mml:mi>m</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>C</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm57"><mml:mrow><mml:mrow><mml:mi>D</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> is the cumulative distance up to the current element and C is gap cost. To alleviate the situation of signature at different length, the distance is normalized by Equation (<xref ref-type="disp-formula" rid="FD8-sensors-19-01808">8</xref>).
<disp-formula id="FD8-sensors-19-01808"><label>(8)</label><mml:math id="mm58"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mi>D</mml:mi><mml:msqrt><mml:mrow><mml:mi>M</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:mi>N</mml:mi></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>DTW has been an effective method of finding the alignment between two signatures with different length. However, a time series has both numerical nature and shape nature. DTW warps time series depending on the similarity of their numerical characteristics as Equation (<xref ref-type="disp-formula" rid="FD6-sensors-19-01808">6</xref>) but ignores the shape properties. It may lead to abnormal alignment sometimes. Zhang and Tang [<xref rid="B38-sensors-19-01808" ref-type="bibr">38</xref>] propose a novel variant of DTW, named SC-DTW. The SC-DTW employs shape context to replace the raw observed values used in conventional DTW, getting ahead in time series data mining. In this paper, we adopted the SC-DTW for function features-based verification to further improve the accuracy.</p><p>Specifically, the alignment of two point is decided by their shape matching cost of shape contexts, which means
<disp-formula id="FD9-sensors-19-01808"><label>(9)</label><mml:math id="mm59"><mml:mrow><mml:mrow><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>,</mml:mo><mml:mi>m</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm60"><mml:mrow><mml:msub><mml:mi>C</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>m</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> is defined in Equation (<xref ref-type="disp-formula" rid="FD5-sensors-19-01808">5</xref>).</p><p>Under this circumstance, a function feature is considered to be a 1-D array and a 2-D shape. The problem of measuring the similarity of two function features can be translate into how similar these two shapes. <xref ref-type="fig" rid="sensors-19-01808-f004">Figure 4</xref> shows the process of SC-DTW. <xref ref-type="fig" rid="sensors-19-01808-f004">Figure 4</xref>a,b are the time series of <inline-formula><mml:math id="mm61"><mml:mrow><mml:msub><mml:mn>11</mml:mn><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> function feature <italic>v</italic> listed in <xref rid="sensors-19-01808-t001" ref-type="table">Table 1</xref> of two signatures from the same user. <xref ref-type="fig" rid="sensors-19-01808-f004">Figure 4</xref>c,d are the corresponding shape context histograms. That the shape context is similar means the sample points in time series are well matched. Please note that the application of shape contexts is only used to find the alignment between two time series. The measurable cumulative distance of them is still obtained by the original cost matrix for the convenience of following classification.</p><p>Given a <inline-formula><mml:math id="mm62"><mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x000d7;</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> feature set <inline-formula><mml:math id="mm63"><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, extracted from a reference signature and a <inline-formula><mml:math id="mm64"><mml:mrow><mml:mrow><mml:msup><mml:mi>N</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup><mml:mo>&#x000d7;</mml:mo><mml:mi>D</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> feature set <inline-formula><mml:math id="mm65"><mml:mrow><mml:msup><mml:mi>X</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula>, extracted from a signature which is claimed to belong to the same user, a D-dimensional vector <inline-formula><mml:math id="mm66"><mml:mrow><mml:msup><mml:mi>z</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>k</mml:mi><mml:mo>,</mml:mo><mml:mi>q</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:msup></mml:mrow></mml:math></inline-formula> called &#x02019;similarity feature vector&#x02019; can be derived by calculating the similarity between each pair of corresponding function features using SC-DTW mentioned above.</p></sec><sec id="sec2dot3dot3-sensors-19-01808"><title>2.3.3. Classification Based on Interval-Valued Symbolic Representation</title><p>The concept of symbolic data analysis has been applied in the field of document image analysis and cluster analysis. Interval-valued and histogram-valued symbolic representation can represent the variability and distribution of feature values. Guru and Prakash [<xref rid="B39-sensors-19-01808" ref-type="bibr">39</xref>] extract global features of signature to form an interval-valued feature vectors and proposed a method for verification and recognition based on the symbolic representation. Pal and Alaei [<xref rid="B5-sensors-19-01808" ref-type="bibr">5</xref>] also propose an interval-valued symbolic representation-based method for offline verification. In this paper, we first use the interval-valued symbolic representation to model the similarity features derived from SC-DTW and then build a classifier for verification.</p><p>Let <inline-formula><mml:math id="mm67"><mml:mrow><mml:mrow><mml:mo>[</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> be a set of <italic>n</italic> enrolled reference signatures of user. In addition, denote <italic>D</italic> as the similarity feature vector of an user, where <inline-formula><mml:math id="mm68"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula> is the SC-DTW distance of feature <italic>r</italic> between signature <inline-formula><mml:math id="mm69"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm70"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>, as is showed in <xref rid="sensors-19-01808-t002" ref-type="table">Table 2</xref>. Each user has a feature vector like that. For the <inline-formula><mml:math id="mm71"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> feature, we compute the statistical mean <inline-formula><mml:math id="mm72"><mml:mrow><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and standard deviation <inline-formula><mml:math id="mm73"><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula> and the lower and upper bound of interval value can be computed as Equation (<xref ref-type="disp-formula" rid="FD10-sensors-19-01808">10</xref>).
<disp-formula id="FD10-sensors-19-01808"><label>(10)</label><mml:math id="mm74"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:mi>s</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>k</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>=</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>+</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>n</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mrow><mml:msub><mml:mi>&#x003c3;</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mi>d</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula>
where <inline-formula><mml:math id="mm75"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>k</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula> is the symbolic representation of <inline-formula><mml:math id="mm76"><mml:mrow><mml:msub><mml:mi>k</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:math></inline-formula> feature of a user and includes an interval value and two continuous values. <inline-formula><mml:math id="mm77"><mml:mrow><mml:mi>&#x003b1;</mml:mi></mml:mrow></mml:math></inline-formula> is a scalar to control the upper and lower limit of each feature. In addition, the symbolic feature vectors are computed for all users and stored in the template base for future verification.</p><p>For signature verification problem, the signature is compared with all the reference signatures belonging to the claimed ID. Let <inline-formula><mml:math id="mm78"><mml:mrow><mml:mrow><mml:msub><mml:mi>F</mml:mi><mml:mi>t</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mn>1</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mn>2</mml:mn></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>D</mml:mi></mml:mrow></mml:msub><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula> denote a D-dimensional feature vector representing the average SC-DTW distance with reference signatures. In addition, denote <inline-formula><mml:math id="mm79"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:mo>[</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mo>&#x022ef;</mml:mo><mml:mo>,</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>D</mml:mi></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>D</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula> as the reference signatures of the claimed identity described by an interval-valued symbolic feature vector. Each feature value of the test signature is compared with corresponding interval in <inline-formula><mml:math id="mm80"><mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>f</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> to examine whether it lies within the interval. The feature value represents the dissimilarity of two signatures. That is, the more similar the two signatures, the smaller the value and the closer to 0. The total value of features of a test signature which fall inside the interval value decides how this test signatures is similar to genuine ones, as is showed in Equations (<xref ref-type="disp-formula" rid="FD11-sensors-19-01808">11</xref>) and (<xref ref-type="disp-formula" rid="FD12-sensors-19-01808">12</xref>). Define <italic>A</italic> as the measure of measure of degree of authenticity: <disp-formula id="FD11-sensors-19-01808"><label>(11)</label><mml:math id="mm81"><mml:mrow><mml:mrow><mml:mi>A</mml:mi><mml:mo>=</mml:mo><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:munderover><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></disp-formula>
where
<disp-formula id="FD12-sensors-19-01808"><label>(12)</label><mml:math id="mm82"><mml:mrow><mml:mrow><mml:mi>C</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>,</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:msubsup><mml:mo>,</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup><mml:mo>]</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfenced separators="" open="{" close=""><mml:mtable><mml:mtr><mml:mtd columnalign="left"><mml:mn>2</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4.pt"/><mml:mi>if</mml:mi><mml:mspace width="4.pt"/><mml:mn>0</mml:mn><mml:mo>&#x02264;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn>1</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4.pt"/><mml:mi>if</mml:mi><mml:mspace width="4.pt"/><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mo>&#x02212;</mml:mo></mml:msubsup><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mrow><mml:mi>t</mml:mi><mml:mi>i</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02264;</mml:mo><mml:msubsup><mml:mi>f</mml:mi><mml:mrow><mml:mi>r</mml:mi><mml:mi>i</mml:mi></mml:mrow><mml:mo>+</mml:mo></mml:msubsup></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="left"><mml:mn>0</mml:mn></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mspace width="4.pt"/><mml:mi>else</mml:mi><mml:mspace width="4.pt"/></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mfenced></mml:mrow></mml:mrow></mml:math></disp-formula></p><p>If the acceptance count <italic>A</italic> is greater that a threshold <inline-formula><mml:math id="mm83"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>, the test signature will be classified as a genuine signature of its claimed user. In the user-dependent scenario, every person has its own <italic>A</italic> which is computed using those training samples. For each training signature, there is an <italic>A</italic> we got. For each person, we compute several <italic>A</italic> and then average them thus getting <inline-formula><mml:math id="mm84"><mml:mrow><mml:msub><mml:mi>A</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>. The threshold <inline-formula><mml:math id="mm85"><mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>h</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> equals to <inline-formula><mml:math id="mm86"><mml:mrow><mml:mrow><mml:mi>&#x003b2;</mml:mi><mml:mo>&#x000d7;</mml:mo><mml:msub><mml:mi>A</mml:mi><mml:mi>m</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>.</p></sec></sec><sec id="sec2dot4-sensors-19-01808"><title>2.4. Two-Stage Online Signature Verification</title><p>The forgery can be classified to be two types, named skilled forgery and random one. In real applications, random forgeries appear more frequently while skilled forgeries occur less. On the other hand, skilled forgeries are much more difficult to be verified correctly. In this paper, we propose a method using shape contexts and function features as well as a two-stage strategy for accurate online signature verification. The shape context-based verification module is firstly used to reject obvious random forgeries quickly while the function features-based verification module is applied to re-check the signatures survived from the previous module. In this way, the whole system can achieve higher accuracy and consume less computation cost at the mean time.</p><p>Two metrics named FRR (False Reject Rate) and FAR (False Accept Rate) have been widely used to evaluate signature verification system. For cascade structure applied in our method, the relationship of FRR and FAR between the sub-verification modules and the whole system are showed in <xref rid="sensors-19-01808-t003" ref-type="table">Table 3</xref>, where <italic>p</italic> denotes the reject percentage of first sub-verification module. Obviously, <italic>p</italic> takes the value smaller than 1.
<disp-formula id="FD13-sensors-19-01808"><label>(13)</label><mml:math id="mm87"><mml:mrow><mml:mtable displaystyle="true"><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x021d2;</mml:mo><mml:mi>p</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd columnalign="right"><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mtd><mml:mtd columnalign="left"><mml:mrow><mml:mo>&#x021d2;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>&#x0003c;</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></disp-formula></p><p>It can be seen that the performance of the cascade system depends on the thresholds of two sub-verification modules. If <inline-formula><mml:math id="mm88"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> and <inline-formula><mml:math id="mm89"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula> is set to be smaller than <inline-formula><mml:math id="mm90"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>, the cascade system can achieve better performance than the sub-verification modules in terms of false acceptance rate, which is illustrated in Equation (<xref ref-type="disp-formula" rid="FD13-sensors-19-01808">13</xref>).</p></sec></sec><sec id="sec3-sensors-19-01808"><title>3. Experimental Results</title><sec id="sec3dot1-sensors-19-01808"><title>3.1. Database and Evaluation Measurement</title><p>To evaluate the effectiveness of the proposed method, we run a set of experiments on public database SVC 2004 Task2. There are 40 users and each user has 20 genuine signatures and 20 skilled forgeries. These genuine signatures are collected in two sessions, spaced apart by at least one week. The skilled forgeries are contributed by who could replay the writing sequence of the signatures on the computer screen and practice the forgeries for a few times until they were confident to proceed to the actual data collection. The signatures are mostly in either English or Chinese [<xref rid="B40-sensors-19-01808" ref-type="bibr">40</xref>]. In our experiments, for each of the users, we randomly select five male/female genuine signatures for enrolment as reference signatures. The signatures are chosen from the first or second session. The remaining 15 genuine signatures (not selected for enrolment) and 20 skilled forgeries are considered for testing the performance of our proposal. As for the random-forgeries scenario, corresponding to any user, we randomly select 20 signatures from other users. The trial is conducted ten times for each user.</p><p>We evaluate the performance primarily using the Equal Error Rate (EER): which is the error when false acceptance rate is equal to false rejection rate. We considered two forms of calculating EER: EER-<inline-formula><mml:math id="mm91"><mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>T</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> and EER-<inline-formula><mml:math id="mm92"><mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>T</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula>. EER-<inline-formula><mml:math id="mm93"><mml:mrow><mml:mrow><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>m</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>T</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is calculated using a global decision threshold. In this case, all the feature values from all training signatures are used to find an optimal value based on minimum EER. The same threshold is shared by all users. EER-<inline-formula><mml:math id="mm94"><mml:mrow><mml:mrow><mml:mi>u</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>r</mml:mi><mml:mi>T</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>s</mml:mi><mml:mi>h</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:mrow></mml:math></inline-formula> is using user-specific decision threshold. It is derived from feature values of training samples of each user. For the respective user, the best threshold corresponds to his/her lowest EER. Since there are multiple users in the database SVC 2004, the average of EER across all users is applied as overall performance of the method when using user threshold in our experiments.</p></sec><sec id="sec3dot2-sensors-19-01808"><title>3.2. Experiment Results</title><p>Performance evaluations of shape context (SC)-based verification and function features (FF)-based verification method is firstly conducted. Here Skilled and Random denotes skilled forgeries and random forgeries. In the case of common threshold, the Receiver Operating Characteristic (ROC) curves are given to evaluate the performance. As for user-dependent threshold set-up, EER of every user are expressed as histograms.</p><p>The results of these two methods are shown in <xref ref-type="fig" rid="sensors-19-01808-f005">Figure 5</xref> and <xref ref-type="fig" rid="sensors-19-01808-f006">Figure 6</xref>. From the results, we can see that both the SC and FF method perform well, and the better results are achieved using user thresholds on random forgery verification. It is a general statement that the usage of user threshold usually can yield better performance than common threshold, as is proved by the results. For common threshold, it is difficult to use one value to cover the differences of different individuals. For user threshold, the value is user-specific, varying from one user to another.</p><p>As descried in the previous section, 20 frequently used features are categorized into 5 groups according to their properties. To achieve best performance and to investigate contributions of different features, we run a series of experiments. Since only single feature or single feature group cannot provide enough classification ability for online signature verification, we test several combinations of feature groups. For clear illustration, we use <inline-formula><mml:math id="mm95"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>G</mml:mi><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula> to represent the 5 groups: position-related, pressure-related, velocity-related, acceleration-related, and angle-related. The symbol &#x0222a; denotes combination of different groups. The experimental results are given in <xref rid="sensors-19-01808-t004" ref-type="table">Table 4</xref>. From the results, we can see that using all 20 features performs the best. It is also shown that when velocity-related FF are removed, verification performance deteriorates a lot.</p><p>To compare the performances of SC and FF method more clearly, the experimental results of two methods are shown together. <xref ref-type="fig" rid="sensors-19-01808-f007">Figure 7</xref> gives the results of SC and FF method on skilled forgery while <xref ref-type="fig" rid="sensors-19-01808-f008">Figure 8</xref> on random one. From the figures, it can be seen that for random forgery verification the performances of SC method and Feature Function method (FF) are similar while FF method outperforms SC method much more on skilled forgery verification. As described in the previous section, SC method is good at extracting global features from signatures with low computation cost, which are quite effective and sufficient for random forgery verification. FF method extracts more detailed features, thus achieving better performance than SC method on skilled forgery verification.</p><p>In real applications, random forgeries occur much more frequently that skilled ones. Based on the experimental results, a cascade verification method is designed and tested. The shape context-based verification method is firstly used to reject obvious random forgeries quickly while the function features-based verification method is applied to re-check the signatures survived from the previous module. As illustrated in <xref ref-type="sec" rid="sec2dot4-sensors-19-01808">Section 2.4</xref>, FRR of SC method should be smaller than function features-based verification to achieve higher accuracy with lower computation cost. In case of common threshold, FRR of the SC method is set to be 1% and 65% skilled forgeries and 25% random forgeries can be accepted by the second module for re-verification. <xref ref-type="fig" rid="sensors-19-01808-f009">Figure 9</xref> and <xref ref-type="fig" rid="sensors-19-01808-f010">Figure 10</xref> give the detailed results on SC method, function feature method, and the two-stage method. <xref rid="sensors-19-01808-t005" ref-type="table">Table 5</xref> shows the detailed results on EERs. From the results, it can be seen that the two-stage method achieves the best performance with tolerable computation cost.</p><p>Comparisons with the state of the art on database SVC2004 are given in <xref rid="sensors-19-01808-t006" ref-type="table">Table 6</xref>. It is not easy to make fair comparisons of online signature verification methods due to different databases, training, testing, etc. We select several recently published works which use the same database (SVC2004 ) with us. The method proposed by Lai et al. [<xref rid="B28-sensors-19-01808" ref-type="bibr">28</xref>] based on GRU network obtained slightly higher EER than our method. However, it needs more training samples and consumes more computation costs.</p></sec></sec><sec sec-type="conclusions" id="sec4-sensors-19-01808"><title>4. Conclusions</title><p>In this paper, we propose a two-stage method using SCs and FF for accurate online signature verification. Features of SCs are extracted from the input firstly and classification of this stage is based on shape distance metric. Only the inputs passing by the first stage are represented by a set of FF and verified. To improve the matching accuracy and efficiency, we propose a SC-DTW to compare the test signature with the enrolled reference ones based on the extracted FF. Then an interval-valued symbolic representation-based classifier is proposed to decide if the test signature is a genuine one. The proposed method is evaluated on SVC2004 Task 2 database achieving an EER of 2.39% which is competitive to the state-of-the-art approaches. The experiment results demonstrate the effectiveness of the proposed method.</p></sec></body><back><ack><title>Acknowledgments</title><p>The authors thank for the help of reviewers and editors.</p></ack><notes><title>Author Contributions</title><p>L.H., Y.J. and H.C. contributed to algorithm and system design; Y.J. conducted the experiments; L.H. and Y.J. contributed to experiment results analysis and manuscripts.</p></notes><notes><title>Funding</title><p>This research was funded by National Natural Science Foundation of China (NSFC) grant number 61271306.</p></notes><notes notes-type="COI-statement"><title>Conflicts of Interest</title><p>The authors declare no conflict of interest.</p></notes><ref-list><title>References</title><ref id="B1-sensors-19-01808"><label>1.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Plamondon</surname><given-names>R.</given-names></name><name><surname>Pirlo</surname><given-names>G.</given-names></name><name><surname>Impedovo</surname><given-names>D.</given-names></name></person-group><source>Online Signature Verification</source><publisher-name>Springer</publisher-name><publisher-loc>London, UK</publisher-loc><year>2014</year><fpage>156</fpage><lpage>161</lpage></element-citation></ref><ref id="B2-sensors-19-01808"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Seal</surname><given-names>A.</given-names></name><name><surname>Bhattacharjee</surname><given-names>D.</given-names></name><name><surname>Nasipuri</surname><given-names>M.</given-names></name><name><surname>Gonzalo-Martin</surname><given-names>C.</given-names></name><name><surname>Menasalvas</surname><given-names>E.</given-names></name></person-group><article-title>A-trous wavelet transform-based hybrid image fusion for face recognition using region classifiers</article-title><source>Expert Syst.</source><year>2018</year><volume>35</volume><fpage>12307</fpage><pub-id pub-id-type="doi">10.1111/exsy.12307</pub-id></element-citation></ref><ref id="B3-sensors-19-01808"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Jain</surname><given-names>A.K.</given-names></name><name><surname>Griess</surname><given-names>F.D.</given-names></name><name><surname>Connell</surname><given-names>S.D.</given-names></name></person-group><article-title>On-line signature verification</article-title><source>Pattern Recognit.</source><year>2007</year><volume>35</volume><fpage>2963</fpage><lpage>2972</lpage><pub-id pub-id-type="doi">10.1016/S0031-3203(01)00240-0</pub-id></element-citation></ref><ref id="B4-sensors-19-01808"><label>4.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Mohammed</surname><given-names>R.A.</given-names></name><name><surname>Nabi</surname><given-names>R.M.</given-names></name><name><surname>Mahmood</surname><given-names>M.R.</given-names></name><name><surname>Nabi</surname><given-names>R.M.</given-names></name></person-group><article-title>State-of-the-Art in Handwritten Signature Verification System</article-title><source>Proceedings of the International Conference on Computational Science and Computational Intelligence</source><conf-loc>Las Vegas, NV, USA</conf-loc><conf-date>7&#x02013;9 December 2015</conf-date><fpage>519</fpage><lpage>525</lpage></element-citation></ref><ref id="B5-sensors-19-01808"><label>5.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Pal</surname><given-names>S.</given-names></name><name><surname>Alaei</surname><given-names>A.</given-names></name><name><surname>Pal</surname><given-names>U.</given-names></name><name><surname>Blumenstein</surname><given-names>M.</given-names></name></person-group><article-title>Interval-valued symbolic representation based method for off-line signature verification</article-title><source>Proceedings of the International Joint Conference on Neural Networks</source><conf-loc>Killarney, Ireland</conf-loc><conf-date>12&#x02013;17 July 2015</conf-date><fpage>1</fpage><lpage>6</lpage></element-citation></ref><ref id="B6-sensors-19-01808"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Xia</surname><given-names>X.</given-names></name><name><surname>Song</surname><given-names>X.</given-names></name><name><surname>Luan</surname><given-names>F.</given-names></name><name><surname>Zheng</surname><given-names>J.</given-names></name><name><surname>Chen</surname><given-names>Z.</given-names></name><name><surname>Ma</surname><given-names>X.</given-names></name></person-group><article-title>Discriminative feature selection for on-line signature verification</article-title><source>Pattern Recognit.</source><year>2018</year><volume>74</volume><fpage>422</fpage><lpage>433</lpage><pub-id pub-id-type="doi">10.1016/j.patcog.2017.09.033</pub-id></element-citation></ref><ref id="B7-sensors-19-01808"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rua</surname><given-names>E.A.</given-names></name><name><surname>Castro</surname><given-names>J.L.A.</given-names></name></person-group><article-title>Online Signature Verification Based on Generative Models</article-title><source>IEEE Trans. Syst. Man Cybern.</source><year>2012</year><volume>42</volume><fpage>1231</fpage><lpage>1242</lpage></element-citation></ref><ref id="B8-sensors-19-01808"><label>8.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Impedovo</surname><given-names>D.</given-names></name><name><surname>Pirlo</surname><given-names>G.</given-names></name></person-group><article-title>Automatic Signature Verification: The State of the Art</article-title><source>IEEE Trans. Syst. Man Cybern.</source><year>2008</year><volume>38</volume><fpage>609</fpage><lpage>635</lpage><pub-id pub-id-type="doi">10.1109/TSMCC.2008.923866</pub-id></element-citation></ref><ref id="B9-sensors-19-01808"><label>9.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sharma</surname><given-names>A.</given-names></name><name><surname>Sundaram</surname><given-names>S.</given-names></name></person-group><article-title>On the Exploration of Information From the DTW Cost Matrix for Online Signature Verification</article-title><source>IEEE Trans. Cybern.</source><year>2018</year><volume>48</volume><fpage>611</fpage><lpage>624</lpage><pub-id pub-id-type="doi">10.1109/TCYB.2017.2647826</pub-id><pub-id pub-id-type="pmid">28103568</pub-id></element-citation></ref><ref id="B10-sensors-19-01808"><label>10.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Griechisch</surname><given-names>E.</given-names></name><name><surname>Malik</surname><given-names>M.I.</given-names></name><name><surname>Liwicki</surname><given-names>M.</given-names></name></person-group><article-title>Online Signature Verification Based on Kolmogorov-Smirnov Distribution Distance</article-title><source>Proceedings of the International Conference on Frontiers in Handwriting Recognition</source><conf-loc>Heraklion, Greece</conf-loc><conf-date>1&#x02013;4 September 2014</conf-date><fpage>738</fpage><lpage>742</lpage></element-citation></ref><ref id="B11-sensors-19-01808"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Feng</surname><given-names>H.</given-names></name><name><surname>Wah</surname><given-names>C.C.</given-names></name></person-group><article-title>Online signature verification using a new extreme points warping technique</article-title><source>Pattern Recognit. Lett.</source><year>2003</year><volume>24</volume><fpage>2943</fpage><lpage>2951</lpage><pub-id pub-id-type="doi">10.1016/S0167-8655(03)00155-7</pub-id></element-citation></ref><ref id="B12-sensors-19-01808"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kar</surname><given-names>B.</given-names></name><name><surname>Mukherjee</surname><given-names>A.</given-names></name><name><surname>Dutta</surname><given-names>P.K.</given-names></name></person-group><article-title>Stroke Point Warping-Based Reference Selection and Verification of Online Signature</article-title><source>IEEE Trans. Instrum. Meas.</source><year>2018</year><volume>67</volume><fpage>2</fpage><lpage>11</lpage><pub-id pub-id-type="doi">10.1109/TIM.2017.2755898</pub-id></element-citation></ref><ref id="B13-sensors-19-01808"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yanikoglu</surname><given-names>B.</given-names></name><name><surname>Kholmatov</surname><given-names>A.</given-names></name></person-group><article-title>Online Signature Verification Using Fourier Descriptors</article-title><source>Eurasip J. Adv. Signal Process.</source><year>2009</year><volume>2009</volume><fpage>260516</fpage><pub-id pub-id-type="doi">10.1155/2009/260516</pub-id></element-citation></ref><ref id="B14-sensors-19-01808"><label>14.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Chen</surname><given-names>Z.</given-names></name><name><surname>Xia</surname><given-names>X.</given-names></name><name><surname>Luan</surname><given-names>F.</given-names></name></person-group><article-title>Automatic online signature verification based on dynamic function features</article-title><source>Proceedings of the IEEE International Conference on Software Engineering and Service Science</source><conf-loc>Beijing, China</conf-loc><conf-date>26&#x02013;28 August 2016</conf-date><fpage>964</fpage><lpage>968</lpage></element-citation></ref><ref id="B15-sensors-19-01808"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bao</surname><given-names>L.V.</given-names></name><name><surname>Garcia-Salicetti</surname><given-names>S.</given-names></name><name><surname>Dorizzi</surname><given-names>B.</given-names></name></person-group><article-title>On Using the Viterbi Path along with HMM Likelihood Information for Online Signature Verification</article-title><source>IEEE Trans. Syst. Man Cybern.</source><year>2007</year><volume>37</volume><fpage>1237</fpage><lpage>1247</lpage></element-citation></ref><ref id="B16-sensors-19-01808"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Muramatsu</surname><given-names>D.</given-names></name><name><surname>Kondo</surname><given-names>M.</given-names></name><name><surname>Sasaki</surname><given-names>M.</given-names></name><name><surname>Tachibana</surname><given-names>S.</given-names></name><name><surname>Matsumoto</surname><given-names>T.</given-names></name></person-group><article-title>A Markov chain Monte Carlo algorithm for bayesian dynamic signature verification</article-title><source>IEEE Trans. Inform. Forensics Secur.</source><year>2006</year><volume>1</volume><fpage>22</fpage><lpage>34</lpage><pub-id pub-id-type="doi">10.1109/TIFS.2005.863507</pub-id></element-citation></ref><ref id="B17-sensors-19-01808"><label>17.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fierrez</surname><given-names>J.</given-names></name><name><surname>Ortega-Garcia</surname><given-names>J.</given-names></name><name><surname>Ramos</surname><given-names>D.</given-names></name><name><surname>Gonzalez-Rodriguez</surname><given-names>J.</given-names></name></person-group><article-title>HMM-based on-line signature verification: Feature extraction and signature modeling</article-title><source>Pattern Recognit. Lett.</source><year>2007</year><volume>28</volume><fpage>2325</fpage><lpage>2334</lpage><pub-id pub-id-type="doi">10.1016/j.patrec.2007.07.012</pub-id></element-citation></ref><ref id="B18-sensors-19-01808"><label>18.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Fuentes</surname><given-names>M.</given-names></name><name><surname>Garciasalicetti</surname><given-names>S.</given-names></name><name><surname>Dorizzi</surname><given-names>B.</given-names></name></person-group><article-title>On-Line Signature Verification: Fusion of a Hidden Markov Model and a Neural Network via a Support Vector Machine</article-title><source>Proceedings of the International Workshop on Frontiers in Handwriting Recognition</source><conf-loc>Niagara on the Lake, ON, Canada</conf-loc><conf-date>6&#x02013;8 August 2002</conf-date><fpage>253</fpage><lpage>258</lpage></element-citation></ref><ref id="B19-sensors-19-01808"><label>19.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lejtman</surname><given-names>D.Z.</given-names></name><name><surname>George</surname><given-names>S.E.</given-names></name></person-group><article-title>On-line Handwritten Signature Verification Using Wavelets and Back-propagation Neural Networks</article-title><source>Proceedings of the International Conference on Document Analysis and Recognition</source><conf-loc>Seattle, WA, USA</conf-loc><conf-date>10&#x02013;13 September 2001</conf-date><fpage>992</fpage><lpage>996</lpage></element-citation></ref><ref id="B20-sensors-19-01808"><label>20.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rashidi</surname><given-names>S.</given-names></name><name><surname>Fallah</surname><given-names>A.</given-names></name><name><surname>Towhidkhah</surname><given-names>F.</given-names></name></person-group><article-title>Feature extraction based DCT on dynamic signature verification</article-title><source>Sci. Iran.</source><year>2012</year><volume>19</volume><fpage>1810</fpage><lpage>1819</lpage><pub-id pub-id-type="doi">10.1016/j.scient.2012.05.007</pub-id></element-citation></ref><ref id="B21-sensors-19-01808"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gruber</surname><given-names>C.</given-names></name><name><surname>Gruber</surname><given-names>T.</given-names></name><name><surname>Krinninger</surname><given-names>S.</given-names></name><name><surname>Sick</surname><given-names>B.</given-names></name></person-group><article-title>Online Signature Verification with Support Vector Machines Based on LCSS Kernel Functions</article-title><source>IEEE Trans. Syst. Man Cybern.</source><year>2010</year><volume>40</volume><fpage>1088</fpage><lpage>1100</lpage><pub-id pub-id-type="doi">10.1109/TSMCB.2009.2034382</pub-id></element-citation></ref><ref id="B22-sensors-19-01808"><label>22.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Swanepoel</surname><given-names>J.</given-names></name><name><surname>Coetzer</surname><given-names>J.</given-names></name></person-group><article-title>Feature Weighted Support Vector Machines for Writer-Independent On-Line Signature Verification</article-title><source>Proceedings of the International Conference on Frontiers in Handwriting Recognition</source><conf-loc>Heraklion, Greece</conf-loc><conf-date>1&#x02013;4 September 2014</conf-date><fpage>434</fpage><lpage>439</lpage></element-citation></ref><ref id="B23-sensors-19-01808"><label>23.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>N.N.</given-names></name><name><surname>Wang</surname><given-names>Y.H.</given-names></name></person-group><article-title>Fusion of global and local information for an on-line Signature Verification system</article-title><source>Proceedings of the International Conference on Machine Learning and Cybernetics</source><conf-loc>Kunming, China</conf-loc><conf-date>12&#x02013;15 July 2008</conf-date><fpage>57</fpage><lpage>61</lpage></element-citation></ref><ref id="B24-sensors-19-01808"><label>24.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Fierrez-Aguilar</surname><given-names>J.</given-names></name><name><surname>Nanni</surname><given-names>L.</given-names></name><name><surname>Lopez-Pe&#x000f1;alba</surname><given-names>J.</given-names></name><name><surname>Ortega-Garcia</surname><given-names>J.</given-names></name><name><surname>Maltoni</surname><given-names>D.</given-names></name></person-group><source>An On-Line Signature Verification System Based on Fusion of Local and Global Information</source><publisher-name>Springer</publisher-name><publisher-loc>Berlin/Heidelberg, Germany</publisher-loc><year>2005</year><fpage>523</fpage><lpage>532</lpage></element-citation></ref><ref id="B25-sensors-19-01808"><label>25.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nanni</surname><given-names>L.</given-names></name><name><surname>Maiorana</surname><given-names>E.</given-names></name><name><surname>Lumini</surname><given-names>A.</given-names></name><name><surname>Campisi</surname><given-names>P.</given-names></name></person-group><article-title>Combining local, regional and global matchers for a template protected on-line signature verification system</article-title><source>Expert Syst. Appl.</source><year>2010</year><volume>37</volume><fpage>3676</fpage><lpage>3684</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2009.10.023</pub-id></element-citation></ref><ref id="B26-sensors-19-01808"><label>26.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Bovino</surname><given-names>L.</given-names></name><name><surname>Impedovo</surname><given-names>S.</given-names></name><name><surname>Pirlo</surname><given-names>G.</given-names></name><name><surname>Sarcinella</surname><given-names>L.</given-names></name></person-group><article-title>Multi-Expert Verification of Hand-Written Signatures</article-title><source>Proceedings of the Seventh International Conference on Document Analysis and Recognition</source><conf-loc>Edinburgh, UK</conf-loc><conf-date>6 August 2003</conf-date><fpage>932</fpage><lpage>936</lpage></element-citation></ref><ref id="B27-sensors-19-01808"><label>27.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Wan</surname><given-names>L.</given-names></name><name><surname>Wan</surname><given-names>B.</given-names></name><name><surname>Lin</surname><given-names>Z.C.</given-names></name></person-group><article-title>On-line signature verification with two-stage statistical models</article-title><source>Proceedings of the International Conference on Document Analysis and Recognition</source><conf-loc>Seoul, Korea</conf-loc><conf-date>31 August&#x02013;1 September 2005</conf-date><volume>Volume 1</volume><fpage>282</fpage><lpage>286</lpage></element-citation></ref><ref id="B28-sensors-19-01808"><label>28.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Lai</surname><given-names>S.</given-names></name><name><surname>Jin</surname><given-names>L.</given-names></name><name><surname>Yang</surname><given-names>W.</given-names></name></person-group><article-title>Online Signature Verification Using Recurrent Neural Network and Length-Normalized Path Signature Descriptor</article-title><source>Proceedings of the International Conference on Document Analysis and Recognition</source><conf-loc>Kyoto, Japan</conf-loc><conf-date>9&#x02013;15 November 2017</conf-date><fpage>400</fpage><lpage>405</lpage></element-citation></ref><ref id="B29-sensors-19-01808"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tolosana</surname><given-names>R.</given-names></name><name><surname>Verarodriguez</surname><given-names>R.</given-names></name><name><surname>Fierrez</surname><given-names>J.</given-names></name><name><surname>Ortegagarcia</surname><given-names>J.</given-names></name></person-group><article-title>Exploring Recurrent Neural Networks for On-Line Handwritten Signature Biometrics</article-title><source>IEEE Access</source><year>2018</year><volume>6</volume><fpage>5128</fpage><lpage>5138</lpage><pub-id pub-id-type="doi">10.1109/ACCESS.2018.2793966</pub-id></element-citation></ref><ref id="B30-sensors-19-01808"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kholmatov</surname><given-names>A.</given-names></name><name><surname>Yanikoglu</surname><given-names>B.</given-names></name></person-group><article-title>Identity authentication using improved online signature verification method</article-title><source>Pattern Recognit. Lett.</source><year>2005</year><volume>26</volume><fpage>2400</fpage><lpage>2408</lpage><pub-id pub-id-type="doi">10.1016/j.patrec.2005.04.017</pub-id></element-citation></ref><ref id="B31-sensors-19-01808"><label>31.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Jia</surname><given-names>Y.</given-names></name><name><surname>Huang</surname><given-names>L.</given-names></name></person-group><article-title>Online Signature Verification Based on Shape Context and Function Features</article-title><source>Proceedings of the Chinese Conference on Pattern Recognition and Computer Vision</source><conf-loc>Guangzhou, China</conf-loc><conf-date>23&#x02013;26 November 2018</conf-date><fpage>62</fpage><lpage>73</lpage></element-citation></ref><ref id="B32-sensors-19-01808"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>C.L.</given-names></name><name><surname>Nakashima</surname><given-names>K.</given-names></name><name><surname>Sako</surname><given-names>H.</given-names></name><name><surname>Fujisawa</surname><given-names>H.</given-names></name></person-group><article-title>Handwritten digit recognition: Investigation of normalization and feature extraction techniques</article-title><source>Pattern Recognit.</source><year>2004</year><volume>37</volume><fpage>265</fpage><lpage>279</lpage><pub-id pub-id-type="doi">10.1016/S0031-3203(03)00224-3</pub-id></element-citation></ref><ref id="B33-sensors-19-01808"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Gupta</surname><given-names>G.K.</given-names></name><name><surname>Joyce</surname><given-names>R.C.</given-names></name></person-group><article-title>Using position extrema points to capture shape in on-line handwritten signature verification</article-title><source>Pattern Recognit.</source><year>2007</year><volume>40</volume><fpage>2811</fpage><lpage>2817</lpage><pub-id pub-id-type="doi">10.1016/j.patcog.2007.01.014</pub-id></element-citation></ref><ref id="B34-sensors-19-01808"><label>34.</label><element-citation publication-type="confproc"><person-group person-group-type="author"><name><surname>Agam</surname><given-names>G.</given-names></name><name><surname>Suresh</surname><given-names>S.</given-names></name></person-group><article-title>Shape matching through particle dynamics warping</article-title><source>Proceedings of the IEEE Conference on Computer Vision And Pattern Recognition</source><conf-loc>Minneapolis, MN, USA</conf-loc><conf-date>17&#x02013;22 June 2007</conf-date><fpage>1</fpage><lpage>7</lpage></element-citation></ref><ref id="B35-sensors-19-01808"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belongie</surname><given-names>S.J.</given-names></name><name><surname>Malik</surname><given-names>J.</given-names></name><name><surname>Puzicha</surname><given-names>J.</given-names></name></person-group><article-title>Shape matching and object recognition using shape contexts</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2002</year><volume>24</volume><fpage>509</fpage><lpage>522</lpage><pub-id pub-id-type="doi">10.1109/34.993558</pub-id></element-citation></ref><ref id="B36-sensors-19-01808"><label>36.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Tsai</surname><given-names>D.M.</given-names></name><name><surname>Hou</surname><given-names>H.T.</given-names></name><name><surname>Su</surname><given-names>H.J.</given-names></name></person-group><source>Boundary-Based Corner Detection Using Eigenvalues of Covariance Matrices</source><publisher-name>Elsevier Science Inc.</publisher-name><publisher-loc>Amsterdam, The Netherlands</publisher-loc><year>1999</year><fpage>31</fpage><lpage>40</lpage></element-citation></ref><ref id="B37-sensors-19-01808"><label>37.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Horng</surname><given-names>W.B.</given-names></name><name><surname>Chen</surname><given-names>C.W.</given-names></name></person-group><article-title>Revision of Using Eigenvalues of Covariance Matrices in Boundary-Based Corner Detection</article-title><source>IEICE Trans. Inf. Syst.</source><year>2009</year><volume>92</volume><fpage>1692</fpage><lpage>1701</lpage><pub-id pub-id-type="doi">10.1587/transinf.E92.D.1692</pub-id></element-citation></ref><ref id="B38-sensors-19-01808"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhang</surname><given-names>Z.</given-names></name><name><surname>Tang</surname><given-names>P.</given-names></name><name><surname>Duan</surname><given-names>R.</given-names></name></person-group><article-title>Dynamic time warping under pointwise shape context</article-title><source>Inf. Sci.</source><year>2015</year><volume>315</volume><fpage>88</fpage><lpage>101</lpage><pub-id pub-id-type="doi">10.1016/j.ins.2015.04.007</pub-id></element-citation></ref><ref id="B39-sensors-19-01808"><label>39.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Guru</surname><given-names>D.S.</given-names></name><name><surname>Prakash</surname><given-names>H.N.</given-names></name></person-group><article-title>Online Signature Verification and Recognition: An Approach Based on Symbolic Representation</article-title><source>IEEE Trans. Pattern Anal. Mach. Intell.</source><year>2008</year><volume>31</volume><fpage>1059</fpage><lpage>1073</lpage><pub-id pub-id-type="doi">10.1109/TPAMI.2008.302</pub-id></element-citation></ref><ref id="B40-sensors-19-01808"><label>40.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Yeung</surname><given-names>D.Y.</given-names></name><name><surname>Chang</surname><given-names>H.</given-names></name><name><surname>Xiong</surname><given-names>Y.</given-names></name><name><surname>George</surname><given-names>S.E.</given-names></name><name><surname>Kashi</surname><given-names>R.S.</given-names></name><name><surname>Matsumoto</surname><given-names>T.</given-names></name><name><surname>Rigoll</surname><given-names>G.</given-names></name></person-group><article-title>SVC2004: First International Signature Verification Competition</article-title><source>Biometric Authentication</source><comment>Lecture Notes in Computer Science</comment><publisher-name>Springer</publisher-name><publisher-loc>Cham, Switzerland</publisher-loc><year>2004</year><fpage>16</fpage><lpage>22</lpage></element-citation></ref><ref id="B41-sensors-19-01808"><label>41.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Song</surname><given-names>X.</given-names></name><name><surname>Xia</surname><given-names>X.</given-names></name><name><surname>Luan</surname><given-names>F.</given-names></name></person-group><article-title>Online Signature Verification Based on Stable Features Extracted Dynamically</article-title><source>IEEE Trans. Syst. Man Cybern. Syst.</source><year>2017</year><volume>47</volume><fpage>2663</fpage><lpage>2676</lpage><pub-id pub-id-type="doi">10.1109/TSMC.2016.2597240</pub-id></element-citation></ref><ref id="B42-sensors-19-01808"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Liu</surname><given-names>Y.</given-names></name><name><surname>Yang</surname><given-names>Z.</given-names></name><name><surname>Yang</surname><given-names>L.</given-names></name></person-group><article-title>Online Signature Verification Based on DCT and Sparse Representation</article-title><source>IEEE Trans. Cybern.</source><year>2017</year><volume>45</volume><fpage>2498</fpage><lpage>2511</lpage><pub-id pub-id-type="doi">10.1109/TCYB.2014.2375959</pub-id></element-citation></ref></ref-list></back><floats-group><fig id="sensors-19-01808-f001" orientation="portrait" position="float"><label>Figure 1</label><caption><p>Diagram of proposed verification system.</p></caption><graphic xlink:href="sensors-19-01808-g001"/></fig><fig id="sensors-19-01808-f002" orientation="portrait" position="float"><label>Figure 2</label><caption><p>Examples of signature preprocessing. (<bold>a</bold>) Four English or Chinese examples of original signatures. (<bold>b</bold>) Window calculated by moment of signatures. (<bold>c</bold>) Preprocessed results of corresponding signatures.</p></caption><graphic xlink:href="sensors-19-01808-g002"/></fig><fig id="sensors-19-01808-f003" orientation="portrait" position="float"><label>Figure 3</label><caption><p>Examples of shape context feature extraction. (<bold>a</bold>) A reference signature of one user. (<bold>b</bold>) A corresponding genuine signature from the same user with reference one. (<bold>c</bold>) A skilled corresponding forgery from the same user with reference one. The green square points represent selected trend-transition-points. (<bold>d</bold>&#x02013;<bold>f</bold>) Shape context histograms for chosen trend-transition-point in the signatures of (<bold>a</bold>&#x02013;<bold>c</bold>), respectively.</p></caption><graphic xlink:href="sensors-19-01808-g003"/></fig><fig id="sensors-19-01808-f004" orientation="portrait" position="float"><label>Figure 4</label><caption><p>SC-DTW. (<bold>a</bold>,<bold>b</bold>) Time series of total velocity <italic>v</italic> from two signatures and a pair of corresponding points found by shape context. (<bold>c</bold>,<bold>d</bold>) show the shape context histograms of the points marked in (<bold>a</bold>,<bold>b</bold>), respectively.</p></caption><graphic xlink:href="sensors-19-01808-g004"/></fig><fig id="sensors-19-01808-f005" orientation="portrait" position="float"><label>Figure 5</label><caption><p>Results of shape context-based verification method (SC). (<bold>a</bold>) ROC curves under common threshold. (<bold>b</bold>) EER of each user under user threshold.</p></caption><graphic xlink:href="sensors-19-01808-g005"/></fig><fig id="sensors-19-01808-f006" orientation="portrait" position="float"><label>Figure 6</label><caption><p>Results of function features-based verification method (FF). (<bold>a</bold>) ROC curves under common threshold. (<bold>b</bold>) EER of each user under user threshold.</p></caption><graphic xlink:href="sensors-19-01808-g006"/></fig><fig id="sensors-19-01808-f007" orientation="portrait" position="float"><label>Figure 7</label><caption><p>Results of SC and FF method on skilled forgery. (<bold>a</bold>) ROC under common threshold. (<bold>b</bold>) EER of each user under user threshold. In addition, those dotted lines are the average levels of corresponding methods.</p></caption><graphic xlink:href="sensors-19-01808-g007"/></fig><fig id="sensors-19-01808-f008" orientation="portrait" position="float"><label>Figure 8</label><caption><p>Results of SC and FF method on random forgery. (<bold>a</bold>) ROC under common threshold. (<bold>b</bold>) EER of each user under user threshold. In addition, those dotted lines are the average levels of corresponding methods.</p></caption><graphic xlink:href="sensors-19-01808-g008"/></fig><fig id="sensors-19-01808-f009" orientation="portrait" position="float"><label>Figure 9</label><caption><p>Results of SC, FF, and two-stage method on skilled forgery. (<bold>a</bold>) ROC under common threshold. (<bold>b</bold>) EER of each user under user threshold. In addition, those dotted lines are the average levels of corresponding methods.</p></caption><graphic xlink:href="sensors-19-01808-g009"/></fig><fig id="sensors-19-01808-f010" orientation="portrait" position="float"><label>Figure 10</label><caption><p>Results of SC, FF, and two-stage method on random forgery. (<bold>a</bold>) ROC under common threshold. (<bold>b</bold>) EER of each user under user threshold. In addition, those dotted lines are the average levels of corresponding methods.</p></caption><graphic xlink:href="sensors-19-01808-g010"/></fig><table-wrap id="sensors-19-01808-t001" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-19-01808-t001_Table 1</object-id><label>Table 1</label><caption><p>Function features extracted for online signature verification.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Category</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Description</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Symbols</th></tr></thead><tbody><tr><td rowspan="6" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Position-related</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>x</italic> coordinate</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm96"><mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><italic>y</italic> coordinate</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm97"><mml:mrow><mml:mrow><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Displacement</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm98"><mml:mrow><mml:mrow><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:mi>x</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>y</mml:mi><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Change of <italic>x</italic> coordinate</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm99"><mml:mrow><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Change of <italic>y</italic> coordinate</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm100"><mml:mrow><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:msub><mml:mi>y</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Change of displacement</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm101"><mml:mrow><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:mi>S</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mo>&#x00394;</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td rowspan="2" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Pressure-related</td><td align="left" valign="middle" rowspan="1" colspan="1">Pressure</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm102"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Change of pressure</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm103"><mml:mrow><mml:mrow><mml:mo>&#x00394;</mml:mo><mml:msub><mml:mi>p</mml:mi><mml:mi>n</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>p</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td rowspan="3" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Velocity-related</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>x</italic> velocity</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm104"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><italic>y</italic> velocity</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm105"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Total velocity</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm106"><mml:mrow><mml:mrow><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>v</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td rowspan="4" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Acceleration-related</td><td align="left" valign="middle" rowspan="1" colspan="1"><italic>x</italic> acceleration</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm107"><mml:mrow><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1"><italic>y</italic> acceleration</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm108"><mml:mrow><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>[</mml:mo><mml:mi>n</mml:mi><mml:mo>]</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Total acceleration</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm109"><mml:mrow><mml:mrow><mml:mi>a</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msqrt><mml:mrow><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>x</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>+</mml:mo><mml:msubsup><mml:mi>a</mml:mi><mml:mrow><mml:mi>y</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:msqrt></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Centripetal acceleration</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm110"><mml:mrow><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mi>c</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>[</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>y</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x000b7;</mml:mo><mml:msub><mml:mi>a</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>]</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td rowspan="5" align="left" valign="middle" style="border-bottom:solid thin" colspan="1">Angle-related</td><td align="left" valign="middle" rowspan="1" colspan="1">Cosine of the angle<break/>between <italic>x</italic>-axis and signature curve</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm111"><mml:mrow><mml:mrow><mml:mo form="prefix">cos</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Sine of the angle<break/>between <italic>x</italic>-axis and signature curve</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm112"><mml:mrow><mml:mrow><mml:mo form="prefix">sin</mml:mo><mml:mi>&#x003b1;</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msqrt><mml:mrow><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mrow><mml:mo>(</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:msqrt></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Cosine of the angle<break/>between <italic>x</italic> velocity and total velocity</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm113"><mml:mrow><mml:mrow><mml:mo form="prefix">cos</mml:mo><mml:mi>&#x003b2;</mml:mi><mml:mo>=</mml:mo><mml:msub><mml:mi>v</mml:mi><mml:mi>x</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>/</mml:mo><mml:mi>v</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" rowspan="1" colspan="1">Angle between <italic>x</italic>-axis and signature curve</td><td align="left" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm114"><mml:mrow><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:msup><mml:mo form="prefix">tan</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mfrac><mml:mrow><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>y</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>x</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Angle velocity</td><td align="left" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm115"><mml:mrow><mml:mrow><mml:msub><mml:mi>v</mml:mi><mml:mi>&#x003b8;</mml:mi></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>&#x003b8;</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>&#x003b8;</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mi>t</mml:mi><mml:mo>(</mml:mo><mml:mi>n</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr></tbody></table></table-wrap><table-wrap id="sensors-19-01808-t002" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-19-01808-t002_Table 2</object-id><label>Table 2</label><caption><p>Similarity feature vector of each individual.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1"/><th align="center" valign="middle" style="border-top:solid thin" rowspan="1" colspan="1">Fea.</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" colspan="1">
<inline-formula><mml:math id="mm116"><mml:mrow><mml:mstyle mathvariant="bold"><mml:msub><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mstyle></mml:mrow></mml:math></inline-formula>
</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" colspan="1">
<inline-formula><mml:math id="mm117"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mn mathvariant="bold">2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>
</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" colspan="1">&#x022ef;</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" colspan="1">
<inline-formula><mml:math id="mm118"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mi mathvariant="bold-italic">r</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>
</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" colspan="1">&#x022ef;</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" colspan="1">
<inline-formula><mml:math id="mm119"><mml:mrow><mml:msub><mml:mi mathvariant="bold-italic">f</mml:mi><mml:mi mathvariant="bold-italic">D</mml:mi></mml:msub></mml:mrow></mml:math></inline-formula>
</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Ref.</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1"/></tr></thead><tbody><tr><td colspan="2" align="center" valign="middle" rowspan="1">
<inline-formula><mml:math id="mm120"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm121"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm122"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm123"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm124"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>12</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td colspan="2" align="center" valign="middle" rowspan="1">
<inline-formula><mml:math id="mm125"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm126"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>13</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm127"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>13</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm128"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>13</mml:mn></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm129"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>13</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td colspan="2" align="center" valign="middle" rowspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td></tr><tr><td colspan="2" align="center" valign="middle" rowspan="1">
<inline-formula><mml:math id="mm130"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>3</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm131"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm132"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm133"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm134"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>23</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td colspan="2" align="center" valign="middle" rowspan="1">
<inline-formula><mml:math id="mm135"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>/</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mn>4</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm136"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>24</mml:mn></mml:mrow><mml:mn>1</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm137"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>24</mml:mn></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm138"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>24</mml:mn></mml:mrow><mml:mi>r</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm139"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mn>24</mml:mn></mml:mrow><mml:mi>D</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td colspan="2" align="center" valign="middle" rowspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td></tr><tr><td colspan="2" align="center" valign="middle" rowspan="1">
<inline-formula><mml:math id="mm140"><mml:mrow><mml:mrow><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>/</mml:mo><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm141"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mn>1</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm142"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm143"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mn>2</mml:mn></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm144"><mml:mrow><mml:msubsup><mml:mi>D</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mi>D</mml:mi></mml:msubsup></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td colspan="2" align="center" valign="middle" style="border-bottom:solid thin" rowspan="1">&#x022ef;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x022ef;</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">&#x022ef;</td></tr></tbody></table></table-wrap><table-wrap id="sensors-19-01808-t003" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-19-01808-t003_Table 3</object-id><label>Table 3</label><caption><p>FRR and FAR of individual verification modules and cascade system.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">System Framework</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">FRR</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">FAR</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Shape Context Module</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm145"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm146"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>1</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Feature Function Module</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm147"><mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm148"><mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:math></inline-formula>
</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Cascade of two Modules</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm149"><mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:msub><mml:mi>r</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>+</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>r</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm150"><mml:mrow><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:msub><mml:mi>a</mml:mi><mml:mn>2</mml:mn></mml:msub></mml:mrow></mml:mrow></mml:math></inline-formula>
</td></tr></tbody></table></table-wrap><table-wrap id="sensors-19-01808-t004" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-19-01808-t004_Table 4</object-id><label>Table 4</label><caption><p>Comparisons between different group of function features.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Group</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Not Included Feature Group</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">EER(SF)</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">EER(RF)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm151"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mn>1</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>2</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>3</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>4</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">None</td><td align="center" valign="middle" rowspan="1" colspan="1">10.8</td><td align="center" valign="middle" rowspan="1" colspan="1">4.5</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm152"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mn>1</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>2</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>3</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>4</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Angle-related</td><td align="center" valign="middle" rowspan="1" colspan="1">11.5</td><td align="center" valign="middle" rowspan="1" colspan="1">4.8</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm153"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mn>1</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>2</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>3</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Acceleration-related</td><td align="center" valign="middle" rowspan="1" colspan="1">12.2</td><td align="center" valign="middle" rowspan="1" colspan="1">6.3</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm154"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mn>1</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>2</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>4</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Velocity-related</td><td align="center" valign="middle" rowspan="1" colspan="1">13.5</td><td align="center" valign="middle" rowspan="1" colspan="1">7.2</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm155"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mn>1</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>3</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>4</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" rowspan="1" colspan="1">Pressure-related</td><td align="center" valign="middle" rowspan="1" colspan="1">11.8</td><td align="center" valign="middle" rowspan="1" colspan="1">6.8</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">
<inline-formula><mml:math id="mm156"><mml:mrow><mml:mrow><mml:mi>G</mml:mi><mml:mn>2</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>3</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>4</mml:mn><mml:mo>&#x0222a;</mml:mo><mml:mi>G</mml:mi><mml:mn>5</mml:mn></mml:mrow></mml:mrow></mml:math></inline-formula>
</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Position-related</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">11.2</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">5.9</td></tr></tbody></table></table-wrap><table-wrap id="sensors-19-01808-t005" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-19-01808-t005_Table 5</object-id><label>Table 5</label><caption><p>Verification results (EER%) of different methods with common threshold and user threshold.</p></caption><table frame="hsides" rules="groups"><thead><tr><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" colspan="1">Method</th><th rowspan="2" align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" colspan="1">Time(s)</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">Common Threshold</th><th colspan="2" align="center" valign="middle" style="border-top:solid thin;border-bottom:solid thin" rowspan="1">User Threshold</th></tr><tr><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EER(SF)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EER(RF)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EER(SF)</th><th align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">EER(RF)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Shape context-based verification</td><td align="center" valign="middle" rowspan="1" colspan="1">0.47</td><td align="center" valign="middle" rowspan="1" colspan="1">17.4</td><td align="center" valign="middle" rowspan="1" colspan="1">4.5</td><td align="center" valign="middle" rowspan="1" colspan="1">10.45</td><td align="center" valign="middle" rowspan="1" colspan="1">0.5</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Function features-based verification</td><td align="center" valign="middle" rowspan="1" colspan="1">1.26</td><td align="center" valign="middle" rowspan="1" colspan="1">10.8</td><td align="center" valign="middle" rowspan="1" colspan="1">4.3</td><td align="center" valign="middle" rowspan="1" colspan="1">3.5</td><td align="center" valign="middle" rowspan="1" colspan="1">0.62</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Two-stage verification</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">1.04</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">6.92</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">3.8</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2.39</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">0.3</td></tr></tbody></table></table-wrap><table-wrap id="sensors-19-01808-t006" orientation="portrait" position="float"><object-id pub-id-type="pii">sensors-19-01808-t006_Table 6</object-id><label>Table 6</label><caption><p>Comparisons with the state-of-the-art works on database SVC2004.</p></caption><table frame="hsides" rules="groups"><thead><tr><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Works</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">Method</th><th align="center" valign="middle" style="border-bottom:solid thin;border-top:solid thin" rowspan="1" colspan="1">EER(%)</th></tr></thead><tbody><tr><td align="center" valign="middle" rowspan="1" colspan="1">Song et al., 2016, [<xref rid="B41-sensors-19-01808" ref-type="bibr">41</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">DTW with SCC</td><td align="center" valign="middle" rowspan="1" colspan="1">2.89</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Liu et al., 2017, [<xref rid="B42-sensors-19-01808" ref-type="bibr">42</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">Spare representation</td><td align="center" valign="middle" rowspan="1" colspan="1">2.98</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Xia et al., 2018, [<xref rid="B6-sensors-19-01808" ref-type="bibr">6</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">GMM+DTW with SCC</td><td align="center" valign="middle" rowspan="1" colspan="1">2.63</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Sharma et al., 2018, [<xref rid="B9-sensors-19-01808" ref-type="bibr">9</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">DTW+warping path alignment</td><td align="center" valign="middle" rowspan="1" colspan="1">2.53</td></tr><tr><td align="center" valign="middle" rowspan="1" colspan="1">Lai et.al., 2017, [<xref rid="B28-sensors-19-01808" ref-type="bibr">28</xref>]</td><td align="center" valign="middle" rowspan="1" colspan="1">LNPS+GRU</td><td align="center" valign="middle" rowspan="1" colspan="1">2.37</td></tr><tr><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Proposed method</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">Two-stage verification</td><td align="center" valign="middle" style="border-bottom:solid thin" rowspan="1" colspan="1">2.39</td></tr></tbody></table></table-wrap></floats-group></article>