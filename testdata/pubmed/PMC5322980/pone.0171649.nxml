<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">PLoS One</journal-id><journal-id journal-id-type="iso-abbrev">PLoS ONE</journal-id><journal-id journal-id-type="publisher-id">plos</journal-id><journal-id journal-id-type="pmc">plosone</journal-id><journal-title-group><journal-title>PLoS ONE</journal-title></journal-title-group><issn pub-type="epub">1932-6203</issn><publisher><publisher-name>Public Library of Science</publisher-name><publisher-loc>San Francisco, CA USA</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28231286</article-id><article-id pub-id-type="pmc">5322980</article-id><article-id pub-id-type="doi">10.1371/journal.pone.0171649</article-id><article-id pub-id-type="publisher-id">PONE-D-16-07418</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research Article</subject></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Engineering and Technology</subject><subj-group><subject>Signal Processing</subject><subj-group><subject>Noise Reduction</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Linguistics</subject><subj-group><subject>Lexicons</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Neck</subject><subj-group><subject>Throat</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Medicine and Health Sciences</subject><subj-group><subject>Anatomy</subject><subj-group><subject>Neck</subject><subj-group><subject>Throat</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Psychology</subject><subj-group><subject>Emotions</subject></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Data Acquisition</subject></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Sociology</subject><subj-group><subject>Communications</subject><subj-group><subject>Social Communication</subject><subj-group><subject>Social Media</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Network Analysis</subject><subj-group><subject>Social Networks</subject><subj-group><subject>Social Media</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Sociology</subject><subj-group><subject>Social Networks</subject><subj-group><subject>Social Media</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Physical Sciences</subject><subj-group><subject>Mathematics</subject><subj-group><subject>Applied Mathematics</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Research and Analysis Methods</subject><subj-group><subject>Simulation and Modeling</subject><subj-group><subject>Algorithms</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Biology and Life Sciences</subject><subj-group><subject>Neuroscience</subject><subj-group><subject>Cognitive Science</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Artificial Intelligence</subject><subj-group><subject>Machine Learning</subject><subj-group><subject>Machine Learning Algorithms</subject></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Sociology</subject><subj-group><subject>Communications</subject><subj-group><subject>Social Communication</subject><subj-group><subject>Social Media</subject><subj-group><subject>Twitter</subject></subj-group></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Computer and Information Sciences</subject><subj-group><subject>Network Analysis</subject><subj-group><subject>Social Networks</subject><subj-group><subject>Social Media</subject><subj-group><subject>Twitter</subject></subj-group></subj-group></subj-group></subj-group></subj-group><subj-group subj-group-type="Discipline-v3"><subject>Social Sciences</subject><subj-group><subject>Sociology</subject><subj-group><subject>Social Networks</subject><subj-group><subject>Social Media</subject><subj-group><subject>Twitter</subject></subj-group></subj-group></subj-group></subj-group></subj-group></article-categories><title-group><article-title>Lexicon-enhanced sentiment analysis framework using rule-based classification scheme</article-title><alt-title alt-title-type="running-head">LESAM</alt-title></title-group><contrib-group><contrib contrib-type="author"><contrib-id authenticated="true" contrib-id-type="orcid">http://orcid.org/0000-0003-3320-2074</contrib-id><name><surname>Asghar</surname><given-names>Muhammad Zubair</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref><xref ref-type="corresp" rid="cor001">*</xref></contrib><contrib contrib-type="author"><name><surname>Khan</surname><given-names>Aurangzeb</given-names></name><xref ref-type="aff" rid="aff002"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Ahmad</surname><given-names>Shakeel</given-names></name><xref ref-type="aff" rid="aff003"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Qasim</surname><given-names>Maria</given-names></name><xref ref-type="aff" rid="aff001"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Khan</surname><given-names>Imran Ali</given-names></name><xref ref-type="aff" rid="aff004"><sup>4</sup></xref></contrib></contrib-group><aff id="aff001"><label>1</label><addr-line>Institute of Computing and Information Technology (ICIT), Gomal University, Dera Ismail Khan, Pakistan</addr-line></aff><aff id="aff002"><label>2</label><addr-line>Department of Computer Science, University of Science and Technology, Bannu, Pakistan</addr-line></aff><aff id="aff003"><label>3</label><addr-line>Faculty of Computing and Information Technology in Rabigh (FCITR), King Abdul Aziz University (KAU) Saudi Arabia</addr-line></aff><aff id="aff004"><label>4</label><addr-line>COMSATS Institute of Information Technology, Abbottabad, Pakistan</addr-line></aff><contrib-group><contrib contrib-type="editor"><name><surname>Zou</surname><given-names>Quan</given-names></name><role>Editor</role><xref ref-type="aff" rid="edit1"/></contrib></contrib-group><aff id="edit1"><addr-line>Tianjin University, CHINA</addr-line></aff><author-notes><fn fn-type="COI-statement" id="coi001"><p><bold>Competing Interests: </bold>The authors have declared that no competing interests exist.</p></fn><fn fn-type="con"><p><list list-type="simple"><list-item><p><bold>Conceptualization:</bold> MZA AK.</p></list-item><list-item><p><bold>Data curation:</bold> MZA MQ SA.</p></list-item><list-item><p><bold>Formal analysis:</bold> MQ AK IAK.</p></list-item><list-item><p><bold>Investigation:</bold> MZA MQ IAK.</p></list-item><list-item><p><bold>Methodology:</bold> MZA MQ AK SA.</p></list-item><list-item><p><bold>Project administration:</bold> MZA.</p></list-item><list-item><p><bold>Resources:</bold> MQ IAK SA.</p></list-item><list-item><p><bold>Software:</bold> MZA AK MQ IAK.</p></list-item><list-item><p><bold>Supervision:</bold> SA.</p></list-item><list-item><p><bold>Validation:</bold> MQ MZA IAK.</p></list-item><list-item><p><bold>Visualization:</bold> MZA AK MQ.</p></list-item><list-item><p><bold>Writing &#x02013; original draft:</bold> MZA MQ.</p></list-item><list-item><p><bold>Writing &#x02013; review &#x00026; editing:</bold> MZA IAK.</p></list-item></list>
</p></fn><corresp id="cor001">* E-mail: <email>zubair@gu.edu.pk</email></corresp></author-notes><pub-date pub-type="epub"><day>23</day><month>2</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>12</volume><issue>2</issue><elocation-id>e0171649</elocation-id><history><date date-type="received"><day>20</day><month>2</month><year>2016</year></date><date date-type="accepted"><day>24</day><month>1</month><year>2017</year></date></history><permissions><copyright-statement>&#x000a9; 2017 Asghar et al</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>Asghar et al</copyright-holder><license xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution License</ext-link>, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.</license-p></license></permissions><self-uri content-type="pdf" xlink:href="pone.0171649.pdf"/><abstract><p>With the rapid increase in social networks and blogs, the social media services are increasingly being used by online communities to share their views and experiences about a particular product, policy and event. Due to economic importance of these reviews, there is growing trend of writing user reviews to promote a product. Nowadays, users prefer online blogs and review sites to purchase products. Therefore, user reviews are considered as an important source of information in Sentiment Analysis (SA) applications for decision making. In this work, we exploit the wealth of user reviews, available through the online forums, to analyze the semantic orientation of words by categorizing them into +ive and -ive classes to identify and classify emoticons, modifiers, general-purpose and domain-specific words expressed in the public&#x02019;s feedback about the products. However, the un-supervised learning approach employed in previous studies is becoming less efficient due to data sparseness, low accuracy due to non-consideration of emoticons, modifiers, and presence of domain specific words, as they may result in inaccurate classification of users&#x02019; reviews. Lexicon-enhanced sentiment analysis based on Rule-based classification scheme is an alternative approach for improving sentiment classification of users&#x02019; reviews in online communities. In addition to the sentiment terms used in general purpose sentiment analysis, we integrate emoticons, modifiers and domain specific terms to analyze the reviews posted in online communities. To test the effectiveness of the proposed method, we considered users reviews in three domains. The results obtained from different experiments demonstrate that the proposed method overcomes limitations of previous methods and the performance of the sentiment analysis is improved after considering emoticons, modifiers, negations, and domain specific terms when compared to baseline methods.</p></abstract><funding-group><funding-statement>The authors received no specific funding for this work.</funding-statement></funding-group><counts><fig-count count="4"/><table-count count="11"/><page-count count="22"/></counts><custom-meta-group><custom-meta id="data-availability"><meta-name>Data Availability</meta-name><meta-value>All relevant data are within the paper and its Supporting Information files.</meta-value></custom-meta></custom-meta-group></article-meta><notes><title>Data Availability</title><p>All relevant data are within the paper and its Supporting Information files.</p></notes></front><body><sec sec-type="intro" id="sec001"><title>Introduction</title><p>The Web is a huge repository of facts and opinions available for people around the world about a particular product, service, issue, policy and health-care [<xref rid="pone.0171649.ref001" ref-type="bibr">1</xref>]. With the rapid increase in social media sites, individuals are now relying on user review sites for exchanging their personal information, experiences and knowledge [<xref rid="pone.0171649.ref002" ref-type="bibr">2</xref>].The main focus of the studies in this area has been on issues, such as sentiment detection, sentiment classification at aspect, word, sentence and review levels, opinion spam detection, and context aware sentiment analysis [<xref rid="pone.0171649.ref003" ref-type="bibr">3</xref>]. However, due to the growing interest in computing the exact sentiment of terms within the SA applications, the sentiment classification at word, sentence and review level become an active area of research [<xref rid="pone.0171649.ref004" ref-type="bibr">4</xref>].</p><p>In most cases, such large number of information seems unstructured for average internet user. However, it attracted many sentiment analysis researchers towards developing such systems that could assist in analyzing user&#x02019;s reviews efficiently. User generated reviews poses different challenges due to the specialized nature of the online text. The main challenges faced in developing user centric sentiment analysis applications include: (i) emoticon handling, (ii) low accuracy of the classifier in the sentiment analysis of online content, and (iii) incorrect scoring and classification of domain specific words. Firstly, the emoticon handling issue arises due to insufficient coverage of emoticons expressed by users in their posts. The second challenge is to improve the accuracy of classifier by using unsupervised approach with emphasis on modifiers and negations. The third issue is the limited coverage of domain specific words in the existing general purpose lexicons, such as SentiWordNet (SWN), which assigns incorrect scores to most of the domain specific words and may often result in incorrect scoring and classification of sentiments. The sentiment score of a word is generally dependent on a particular domain and changes when a domain switch occurs.</p><p>The aforementioned issues often result in incorrect detection and classification of users&#x02019; sentiments expressed in users&#x02019; review sites. Therefore, it is an important task to develop a method to detect and analyze the users&#x02019; sentiments from online reviews by automatic classification of reviews as positive, negative or neutral.</p><p>In this work, we propose a lexicon-enhanced method for improving the sentiment analysis of user generated reviews based on rule-based classification scheme. The main focus is on reducing data sparsity and improving the accuracy of sentiment detection and classification in different domains, effectively reducing the reviews classified as neutral. The proposed method is inspired by the previous studies performed on sentiment analysis of user generated reviews [<xref rid="pone.0171649.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0171649.ref005" ref-type="bibr">5</xref>]. The previous studies have used un-supervised classification to detect and classify the users&#x02019; sentiments expressed by online users into +ive, -ive or neutral classes. However, we use the emoticon classifier, modifier &#x00026;negation classifier, SWN-based classifier (SWNC) in a sequential way to classify the reviews more accurately. Additionally, we input the text to and domain specific classifier (DSC) to assign accurate sentiment scores to domain specific words, which is one of our major contributions in this work. If the results of SWNC and DSC are identical, then the sentence and review is classified as +ive, -ive or neutral accordingly. However, if there is disagreement between the classifications results of SWNC and DSC, then we consider DSC-based results, because it gives more accurate results with respect to consideration of domain specific words. This assists in improving the performance of sentiment analysis system.</p><p>The main contribution of this work over the state of art methods [<xref rid="pone.0171649.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0171649.ref005" ref-type="bibr">5</xref>] is to handle emoticons, modifiers, negations and domain specific words in an integrated framework. The source code of different modules is available at: <ext-link ext-link-type="uri" xlink:href="https://datadryad.org/resource/doi:10.5061/dryad.p1j71/1">https://datadryad.org/resource/doi:10.5061/dryad.p1j71/1</ext-link></p><p>The paper is structured as follows. Section 2 presents literature review. In section3, we describe the proposed method. Experiment design is presented in section 4, which describes the metrics and discussion on obtained results. The final section outlines the work with a discussion on how it can be expanded in future.</p></sec><sec id="sec002"><title>Related work</title><p>There are several studies regarding analysis of users&#x02019; sentiments from online forums, with focus on classifying the reviews as positive, negative and neutral.</p><p>Ferrara and Yang et al. [<xref rid="pone.0171649.ref006" ref-type="bibr">6</xref>], in their work on quantifying the effect of sentiment on information diffusion invested different issues, such as identification of emotions having widespread usage in online text and, whether +ive sentiments are disseminated more than &#x02013;ive and vice-versa. It was reported that &#x02013;ive sentiments spread faster than +ive ones and +ive sentiments develops rapidly for highly anticipated events. They identified and classified additional linguistic rules, such as negations, amplifications and emoticons by adopting SentiStrength algorithm. Their approach didn&#x02019;t address the issue of domain dependent terms, which is one of a major issue in existing sentiment classification systems.</p><p>Poria et al. [<xref rid="pone.0171649.ref007" ref-type="bibr">7</xref>] presented a novel mechanism of extracting features from short multimedia-based heterogeneous data, such as textual, audio and visual clips by training the classifier using convolutional multiple kernel learning. For this purpose, they used Deep Convolutional Neural Network (DCNN) model by applying activation values in an inner layer of DCNN. They obtained a performance improvement of about 14% over the baseline methods.</p><p>Severyn and Moschitti [<xref rid="pone.0171649.ref008" ref-type="bibr">8</xref>] introduced a convolutional neural network model for performing sentiment analysis of microblogs using deep learning technique. It accurately trains the model without needing any support features. They used an unsupervised neural model for training the seed words which are further subjected to deep learning model. Finally, model is initialized by using pre-trained parameters. Furthermore, supervised learning technique is applied on the Twitter dataset. The system obtained promising results both at phrase level and message level.</p><p>In their work on extracting sentiment from text, Taboada et al. [<xref rid="pone.0171649.ref009" ref-type="bibr">9</xref>] developed a Semantic Orientation Calculator (SO-CAL) by using dictionaries of words associated with their sentiment class and score, and includes negation and intensification. The performance of SO-CAL was satisfactory across multiple domains. Moreover, they described the process of dictionary creation and annotation. However, their approach can be enriched by incorporating emoticons and domain specific words for more accurate sentiment classification.</p><p>Pensa et al. [<xref rid="pone.0171649.ref010" ref-type="bibr">10</xref>] proposed a concept-level knowledge graph in an integrated framework to represent user behavior on different social media. The active users are tracked by modeling their activities and concepts as well as the relationships with other users. Temporal relationships are also addressed to assist in carrying out temporal analysis. However, incorporation of event detection for automatic detection of hot topics in social networking sites can improve the performance of the system.</p><p>Cambria in his recent study [<xref rid="pone.0171649.ref011" ref-type="bibr">11</xref>] reported that emotion recognition and polarity detection are the two basic tasks of affective computing. The former aims at extracting emotion tags and the latter is focused on classifying text into positive and negative classes. The aforementioned tasks are highly co-related and mostly treated in a unified framework for detecting polarity of a sentence and then tagging the sentence with particular emotion category. In many applications, emotion recognition is performed as a subsequent task of sentiment classification.</p><p>While working on contextual sentiment analysis for social media genres, Muhammad et el. [<xref rid="pone.0171649.ref012" ref-type="bibr">12</xref>] introduced a lexicon-based sentiment classification method for capturing contextual polarity at local and global levels. The major limitation of lexicon-based approach is incorrect sentiment scoring of opinion words by the existing lexicons, such as SentiWordNet. To address this issue, domain specific vocabulary is introduced to improve the efficacy of sentiment classification.</p><p>L. Boratto et al. [<xref rid="pone.0171649.ref013" ref-type="bibr">13</xref>] proposed a technique to detect segments of users for modeling user behavior in advertising. Different data sources are exploited to detect such segments. Firstly, need for user segmentation system is presented to incorporate user preferences successfully, as most of the time is spent by the users on reformulating queries to fulfill their information requirement. Finally, a method is proposed to analyze item description on the basis of user evaluation and extract words in the form of vector notation. The proposed approach is validated by performing experiments on real-world datasets.</p><p>Kennedy and Inkpen [<xref rid="pone.0171649.ref014" ref-type="bibr">14</xref>] applied two phase method for measuring the effect of modifiers on classifying the reviews. In the first phase, <italic>General Inquirer</italic> is used to identify positive terms, negations, intensifiers and diminishers. They obtained improved classification results by extending the term-counting technique with context valence shifters. In second phase, machine learning approach, namely Support Vector Machine (SVM) is used by considering unigrams and valence shifter bigrams. They achieved high classification results by using bigram shifters.</p><p>The previous studies [<xref rid="pone.0171649.ref006" ref-type="bibr">6</xref>&#x02013;<xref rid="pone.0171649.ref010" ref-type="bibr">10</xref>] on sentiment analysis used different approaches for analysis, where the supervised learning algorithm [<xref rid="pone.0171649.ref015" ref-type="bibr">15</xref>, <xref rid="pone.0171649.ref016" ref-type="bibr">16</xref>, <xref rid="pone.0171649.ref017" ref-type="bibr">17</xref>] is mainly dependent on the availability labeled training dataset. Supervised learning systems are learnt over the labeled training instances to classify the users&#x02019; reviews as +ive, -ive or neutral using different features, such as n-grams, part of speech tags and emoticons. Moreover, most of the existing un-supervised approaches [<xref rid="pone.0171649.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0171649.ref005" ref-type="bibr">5</xref>] do not consider emoticons, modifiers, and domain specific words efficiently. Although such techniques offer satisfactory results for the classification of online content, they pose different challenges. The major challenges are: (i) limited coverage of emoticons, (ii) low accuracy of the classifier in the detection and classification users&#x02019; sentiments due to presence of modifiers and negations in online forums,(iii) and inaccurate sentiment classification of domain specific words, as the existing general-purpose lexicons, such as SWN may assign incorrect scores to most of the domain specific words.</p><p>The main motivation of this work is the lexicon-based approach suggested by [<xref rid="pone.0171649.ref005" ref-type="bibr">5</xref>], which classifies the reviews based on rule-based technique. They classified the reviews by passing them through different modules, namely, (i) filtering, (ii) subjectivity classification, and (iii) sentiment scoring, to classify the reviews accurately. In a recent work [<xref rid="pone.0171649.ref003" ref-type="bibr">3</xref>], the authors address the issues of sentiment analysis in user reviews, and proposed an effective method of the reviews classification into +ive, -ive, and neutral classes by incorporating slangs using different types of lexicons.</p><p>The proposed system is based on rule-based classification scheme supported by number of repositories, such as SentiWordNet (SWN), emoticon dictionary, modifiers lists and domain specific scoring modules. The major improvement of system over the state of the art methods [<xref rid="pone.0171649.ref003" ref-type="bibr">3</xref>, <xref rid="pone.0171649.ref005" ref-type="bibr">5</xref>] is in the way it handles emoticons, modifiers, negations and domain specific words in an integrated framework. Our system is capable of automatically detecting and classifying the modifiers, negations, emoticons and domain specific words expressed by users in reviews. That is, we automatically increase, decrease or invert the intensity strength of opinion words by incorporating hand-ranked percentage scale; classify the emoticons by proposing an enhanced rule-based emoticon repository; and finally, opinion words are classified using SWN-based classifier and an improved domain specific classifier. The proposed framework is presented in <xref ref-type="fig" rid="pone.0171649.g001">Fig 1</xref>.</p><fig id="pone.0171649.g001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.g001</object-id><label>Fig 1</label><caption><title>Proposed System.</title></caption><graphic xlink:href="pone.0171649.g001"/></fig></sec><sec sec-type="materials|methods" id="sec003"><title>Methods</title><p>The proposed method applies different techniques for analyzing and classifying users&#x02019; reviews. This involves data acquisition, noise reduction and a rule-based scheme of classification. Data acquisition involves dataset compilation from different resources. Noise reduction steps include: sentence splitting, tokenization, stop word removal, lemmatization, spell correction and co-reference resolution [<xref rid="pone.0171649.ref018" ref-type="bibr">18</xref>]. The proposed technique implements a rule-based scheme using an improved version of emoticon classification [<xref rid="pone.0171649.ref019" ref-type="bibr">19</xref>], enhanced modifier handling [<xref rid="pone.0171649.ref020" ref-type="bibr">20</xref>], sentiment scoring of opinion words using SentiWordNet [<xref rid="pone.0171649.ref021" ref-type="bibr">21</xref>] and an enhanced sentiment classifier using domain specific strategy [<xref rid="pone.0171649.ref022" ref-type="bibr">22</xref>].</p><p>The main aim of this work is to enhance the performance of sentiment analysis and resolve the issues of data sparseness and incorrect classification due to use of noisy text, emoticons, modifiers and domain specific words. The basic theme is to reduce noise from the review text by applying different pre-processing steps and process through variant of classifiers. The proposed method is able to test the text from different online forums. The reviews compiled from these sources are used as input items. The method is based on the three major steps: 1) firstly, we acquire the data from different online resources; 2) in next step, the noise reduction is performed by applying different preprocessing techniques to refine the text that can be used for subsequent processing, and 3) finally, different classification techniques are applied to classify the reviews into +ive, -ive or neutral.</p><sec id="sec004"><title>Data acquisition</title><p>The data acquisition module is used to compile datasets from user reviews, which serve as input to noise reduction module for filtering the noisy text. For this purpose, we used three user&#x02019;s reviews datasets, namely: (i)drug (ii) car, and (iii) hotel. Drug review dataset is publically available at: <ext-link ext-link-type="uri" xlink:href="http://ir.cs.georgetown.edu/data/adr/">http://ir.cs.georgetown.edu/data/adr/</ext-link>, whereas Car and Hotel reviews are obtained from: <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/OpinRank+Review+Dataset">https://archive.ics.uci.edu/ml/datasets/OpinRank+Review+Dataset</ext-link>. The reviews are stored in two separate MS-Excel files to compile the testing and training corpuses. This study did not involve any experimental research on humans or animals; hence an approval from an ethics committee was not applicable in this regard. The data collected from the online forums are publicly available data and no personally identifiable information of the forum users were collected or used for this study.</p><p>The detail of each dataset is shown in <xref ref-type="table" rid="pone.0171649.t001">Table 1</xref>.</p><table-wrap id="pone.0171649.t001" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t001</object-id><label>Table 1</label><caption><title>Sample Datasets.</title></caption><alternatives><graphic id="pone.0171649.t001g" xlink:href="pone.0171649.t001"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="justify" rowspan="1" colspan="1">Datasets</th><th align="justify" rowspan="1" colspan="1">Total # Reviews</th><th align="justify" rowspan="1" colspan="1">Dataset Description</th></tr></thead><tbody><tr><td align="justify" rowspan="1" colspan="1">Dataset#1</td><td align="justify" rowspan="1" colspan="1">350</td><td align="justify" rowspan="1" colspan="1">Drug</td></tr><tr><td align="justify" rowspan="1" colspan="1">Dataset#2</td><td align="justify" rowspan="1" colspan="1">273</td><td align="justify" rowspan="1" colspan="1">Car</td></tr><tr><td align="justify" rowspan="1" colspan="1">Dataset#3</td><td align="justify" rowspan="1" colspan="1">412</td><td align="justify" rowspan="1" colspan="1">Hotel</td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec005"><title>Noise reduction</title><p>In the noise reduction step, noisy text is filtered by applying different preprocessing techniques, including sentence splitting, tokenization, stop word removal, lemmatization, spell correction, case-conversion and anaphoric reference resolution [<xref rid="pone.0171649.ref023" ref-type="bibr">23</xref>]. Moreover, to provide better classification results, unrelated sentences were excluded. For example, in health review dataset, sentences reflecting sympathetic feelings and empathetic encouragements, such as &#x0201c;<italic>Thanks for your suggestion</italic>&#x0201d;, <italic>&#x0201c;wishing your recovery soon&#x0201d;</italic>, or <italic>&#x0201c;I will never leave you alone&#x0201d;</italic>. These comments contain no drug-related information and can be discarded. After noise reduction, the dataset consists of 8,500 reviews with 52% +ive, 42% -ive and 6% neutral reviews.</p></sec><sec id="sec006"><title>Sentiment classification</title><p>The rule based classification is used to classify the reviews using set of <italic>&#x0201c;if-then</italic>&#x0201d; rules. The rules are represented in disjunctive normal form (DNF), where <italic>if</italic> clause is called rule antecedent and <italic>then</italic> clause is called rule consequent. The proposed Sentiment Classification Algorithm (SCA) in rule-based framework classifies user reviews by using four classifiers, namely: (i) Emoticon Classifier (EC), (ii) Modifier and Negation Classifier (MNC), (iii) SentiWordNet Classifier (SWNC), and (iv) Domain Specific Classifier (DSC).</p><p>The EC is used to classify emoticons on the basis of +ive and &#x02013;ive emoticon sets. It detects presence or absence of emoticons in a given sentence to classify them as +ive, -ive or neutral. The MNC uses percentage scale based list of +ive and &#x02013;ive modifiers, stored in two database files; whereas the negation list is a separate text file that includes all possible negation terms. In order to perform sentiment classification of the user&#x02019;s reviews at word, sentence level and review level, we use SWNC, that uses SentiWordNet (SWN) lexicon to retrieve sentiment score of each word for the classification of reviews. The DSC module is used to perform sentiment classification of such domain specific words, which are, either not present or their sentiment score is not accurately available in SWN.</p><p>Algorithm 1 outlines the different steps required for the classification of reviews. Firstly, each review sentence is preprocessed using noise reduction steps, and then different classifiers are applied, as described in the classification module. Finally, the results are generated in the form of +ive, -ive or neutral sentiments at sentence and review level.</p><p>Let R denote the set of reviews and W denotes the set of words in each review as:
<disp-formula id="pone.0171649.e001"><alternatives><graphic xlink:href="pone.0171649.e001.jpg" id="pone.0171649.e001g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M1"><mml:mi>R</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>r</mml:mi><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>r</mml:mi><mml:mn>3</mml:mn><mml:mo>&#x02026;</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>.</mml:mo><mml:mi>r</mml:mi><mml:mi>n</mml:mi><mml:mo>}</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pone.0171649.e002"><alternatives><graphic xlink:href="pone.0171649.e002.jpg" id="pone.0171649.e002g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M2"><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi>w</mml:mi><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mn>2</mml:mn><mml:mo>,</mml:mo><mml:mi>w</mml:mi><mml:mn>3</mml:mn><mml:mo>&#x02026;</mml:mo><mml:mo>.</mml:mo><mml:mi>w</mml:mi><mml:mi>n</mml:mi><mml:mo>}</mml:mo></mml:math></alternatives></disp-formula></p><p>We use the following four sentiment classifiers for the final classification of the review sentence.</p><sec id="sec007"><title>Emoticon Classifier (EC)</title><p>Emoticon is a symbolic illustration of mind, mood, emotional state and feelings used by online community [<xref rid="pone.0171649.ref019" ref-type="bibr">19</xref>].Emoticons convey a message more effectively without having dependency on the language and specific domain. They have become vital part of social media chat and public reviews. Therefore, their detection, classification and evaluation have become necessary for the development of efficient sentiment analysis applications.</p><p>In this work, emoticon detection is carried out using if-then rules and their classification is based on the set of positive and negative emotions. The proposed module is an enhancement of the work proposed by F.H. Khan et al. [<xref rid="pone.0171649.ref019" ref-type="bibr">19</xref>]. F.H. Khan used a set of 145emoticons, whereas we have extended it to 230; 120 of which are labeled +ive and 110 are labeled as -ive. We hired the services of three human annotators to manually assign polarity class and score to emoticons in our emoticon dictionary. The annotators were informed to assign scores of -1.0 (-ive), 0 (neutral), and +1.0(+ive). The score nearest to the average of the annotators&#x02019; scores is computed for each emoticon. Overall inter-annotator agreement is 91.2% with a Kappa (K) score of 0.85, which is quite high.</p><p>The partial list of +ive and &#x02013;ive emoticons are given in <xref ref-type="table" rid="pone.0171649.t002">Table 2</xref> respectively. The emoticon is labeled as +ive, if it is found in +ive list. If the emoticon is found in the &#x02013;ive list, then it is labeled as &#x02013;ive. The emoticon is declared as neutral, if it does not exist in both lists.</p><table-wrap id="pone.0171649.t002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t002</object-id><label>Table 2</label><caption><title>Partial list of positive and negative emoticons.</title></caption><alternatives><graphic id="pone.0171649.t002g" xlink:href="pone.0171649.t002"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Emoticon</th><th align="center" rowspan="1" colspan="1">Meaning</th><th align="left" rowspan="1" colspan="1">Sentiment Class</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">:-D</td><td align="center" rowspan="1" colspan="1">Laughing</td><td align="center" rowspan="1" colspan="1">Positive</td></tr><tr><td align="center" rowspan="1" colspan="1">:-)</td><td align="center" rowspan="1" colspan="1">smile</td><td align="center" rowspan="1" colspan="1">Positive</td></tr><tr><td align="center" rowspan="1" colspan="1">o:)-</td><td align="center" rowspan="1" colspan="1">innocent</td><td align="center" rowspan="1" colspan="1">Positive</td></tr><tr><td align="center" rowspan="1" colspan="1">8-)</td><td align="center" rowspan="1" colspan="1">cool</td><td align="center" rowspan="1" colspan="1">Positive</td></tr><tr><td align="center" rowspan="1" colspan="1">:$</td><td align="center" rowspan="1" colspan="1">Happy blush</td><td align="center" rowspan="1" colspan="1">Positive</td></tr><tr><td align="center" rowspan="1" colspan="1">:(</td><td align="center" rowspan="1" colspan="1">defeated</td><td align="center" rowspan="1" colspan="1">Negative</td></tr><tr><td align="center" rowspan="1" colspan="1">:&#x02019;(</td><td align="center" rowspan="1" colspan="1">Crying</td><td align="center" rowspan="1" colspan="1">Negative</td></tr><tr><td align="center" rowspan="1" colspan="1">:o</td><td align="center" rowspan="1" colspan="1">shocked</td><td align="center" rowspan="1" colspan="1">Negative</td></tr><tr><td align="center" rowspan="1" colspan="1">&#x0003e;(</td><td align="center" rowspan="1" colspan="1">Grumpy</td><td align="center" rowspan="1" colspan="1">Negative</td></tr><tr><td align="center" rowspan="1" colspan="1">(@)</td><td align="center" rowspan="1" colspan="1">Angry red</td><td align="center" rowspan="1" colspan="1">Negative</td></tr><tr><td align="center" rowspan="1" colspan="1">X|</td><td align="center" rowspan="1" colspan="1">Dead</td><td align="center" rowspan="1" colspan="1">Negative</td></tr></tbody></table></alternatives></table-wrap><p>Let <italic>E</italic><sub><italic>pos</italic></sub>
<italic>be</italic> a list of positive emoticons and <italic>E</italic><sub><italic>neg</italic></sub> be a list of negative emoticons associated with each review represented as:
<disp-formula id="pone.0171649.e003"><alternatives><graphic xlink:href="pone.0171649.e003.jpg" id="pone.0171649.e003g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M3"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.25em"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:math></alternatives></disp-formula>
<disp-formula id="pone.0171649.e004"><alternatives><graphic xlink:href="pone.0171649.e004.jpg" id="pone.0171649.e004g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M4"><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mrow><mml:mi>l</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>t</mml:mi><mml:mspace width="0.25em"/><mml:mi>o</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mi>s</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:math></alternatives></disp-formula></p><p>The sentiment score of an emoticon &#x0201c;<italic>e</italic>&#x0201d; is computed as:
<disp-formula id="pone.0171649.e005"><alternatives><graphic xlink:href="pone.0171649.e005.jpg" id="pone.0171649.e005g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M5"><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mi>&#x003f5;</mml:mi><mml:mspace width="0.25em"/><mml:mi>R</mml:mi><mml:mspace width="0.25em"/><mml:mo>&#x022c0;</mml:mo><mml:mspace width="0.25em"/><mml:mi>e</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mi>&#x003f5;</mml:mi><mml:mspace width="0.25em"/><mml:mi>R</mml:mi><mml:mspace width="0.25em"/><mml:mo>&#x022c0;</mml:mo><mml:mi>e</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mi>&#x003f5;</mml:mi><mml:mspace width="0.25em"/><mml:mi>R</mml:mi><mml:mrow><mml:mo>&#x022c0;</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>&#x02209;</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x022c0;</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>&#x02209;</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mn>0</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mi>&#x003f5;</mml:mi><mml:mspace width="0.25em"/><mml:mi>R</mml:mi><mml:mrow><mml:mo>&#x022c0;</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow><mml:mrow><mml:mo>&#x022c0;</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>E</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(1)</label></disp-formula>
where, <italic>e</italic> denotes the emotion belongs to set of positive and negative emoticons respectively and r is a review from the set of reviews R. The sentiment score of an emoticon &#x0201c;<italic>e&#x0201d;</italic> is a value between 1 and -1, where 1 represents +ive, -1 means &#x02013;ive and 0 indicates neutral.</p></sec><sec id="sec008"><title>Modifier and Negation Classifier (MNC)</title><p>Modifiers and negations play an important role in the sentiment classification. Detail of the proposed module is described in the following sub-sections.</p><p><bold>Modifier Management:</bold> Modifiers are the words, which enhance or reduce the polarity strength of sentiment words in a sentence, such as: <italic>pretty</italic>, <italic>very</italic>, <italic>slightly</italic>, <italic>somewhat</italic>, <italic>even</italic>, <italic>few</italic>, <italic>too</italic>, <italic>really</italic>, <italic>extremely</italic>, <italic>quite</italic> etc. These words enhance or reduce the polarity strength of an opinion term.</p><p>Khan et al. [<xref rid="pone.0171649.ref020" ref-type="bibr">20</xref>], in their work on modifiers, used simple addition and subtraction of constant values. The main issue with this approach is that it does not cover full range of modifiers in particular category. The proposed modifier handling module is an improvement of the work proposed by [<xref rid="pone.0171649.ref020" ref-type="bibr">20</xref>], by using hand-ranked percentage scale to represent variety of modifiers as well as their sentiment scores. We use 75 English modifiers proposed by Benzinger (<ext-link ext-link-type="uri" xlink:href="https://archive.org/stream/intensifiersincu00benz/intensifiersincu00benz_djvu.txt">https://archive.org/stream/intensifiersincu00benz/intensifiersincu00benz_djvu.txt</ext-link>). We assigned a sentiment score to each modifier by using the numeric values proposed by [<xref rid="pone.0171649.ref009" ref-type="bibr">9</xref>, <xref rid="pone.0171649.ref014" ref-type="bibr">14</xref>]. We converted such numeric scores (e.g. 1, -1, 0.5, -0.5) to respective percentage scales (e.g. +100%, -100%, +50%, -50%) to build of +ive and &#x02013;ive modifiers lists. The enhancers are +ive, whereas reducers are &#x02013;ive, as shown in <xref ref-type="table" rid="pone.0171649.t003">Table 3</xref> and <xref ref-type="table" rid="pone.0171649.t004">Table 4</xref>.</p><table-wrap id="pone.0171649.t003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t003</object-id><label>Table 3</label><caption><title>Partial list of positive modifiers (enhancers).</title></caption><alternatives><graphic id="pone.0171649.t003g" xlink:href="pone.0171649.t003"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Modifier</th><th align="center" rowspan="1" colspan="1">Strength</th><th align="center" rowspan="1" colspan="1">Modifier</th><th align="center" rowspan="1" colspan="1">Strength</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">Completely</td><td align="center" rowspan="1" colspan="1">+100%</td><td align="center" rowspan="1" colspan="1">Pretty</td><td align="center" rowspan="1" colspan="1">+20%</td></tr><tr><td align="center" rowspan="1" colspan="1">Totally</td><td align="center" rowspan="1" colspan="1">+70%</td><td align="center" rowspan="1" colspan="1">Very</td><td align="center" rowspan="1" colspan="1">+50%</td></tr><tr><td align="center" rowspan="1" colspan="1">Really</td><td align="center" rowspan="1" colspan="1">+15%</td><td align="center" rowspan="1" colspan="1">Too</td><td align="center" rowspan="1" colspan="1">+45%</td></tr><tr><td align="center" rowspan="1" colspan="1">Most</td><td align="center" rowspan="1" colspan="1">+90%</td><td align="center" rowspan="1" colspan="1">Extremely</td><td align="center" rowspan="1" colspan="1">+80%</td></tr><tr><td align="center" rowspan="1" colspan="1">Extraordinarily</td><td align="center" rowspan="1" colspan="1">+75%</td><td align="center" rowspan="1" colspan="1"/><td align="center" rowspan="1" colspan="1"/></tr></tbody></table></alternatives></table-wrap><table-wrap id="pone.0171649.t004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t004</object-id><label>Table 4</label><caption><title>Partial list of negative modifiers (reducers).</title></caption><alternatives><graphic id="pone.0171649.t004g" xlink:href="pone.0171649.t004"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" rowspan="1" colspan="1">Modifier</th><th align="center" rowspan="1" colspan="1">Strength</th><th align="center" rowspan="1" colspan="1">Modifier</th><th align="center" rowspan="1" colspan="1">Strength</th></tr></thead><tbody><tr><td align="center" rowspan="1" colspan="1">hardly</td><td align="center" rowspan="1" colspan="1">-70%</td><td align="center" rowspan="1" colspan="1">a little</td><td align="center" rowspan="1" colspan="1">-40%</td></tr><tr><td align="center" rowspan="1" colspan="1">less</td><td align="center" rowspan="1" colspan="1">-50%</td><td align="center" rowspan="1" colspan="1">some</td><td align="center" rowspan="1" colspan="1">-25%</td></tr><tr><td align="center" rowspan="1" colspan="1">quite</td><td align="center" rowspan="1" colspan="1">-20%</td><td align="center" rowspan="1" colspan="1">a bit</td><td align="center" rowspan="1" colspan="1">-35%</td></tr><tr><td align="center" rowspan="1" colspan="1">minor</td><td align="center" rowspan="1" colspan="1">-30%</td><td align="center" rowspan="1" colspan="1">slight</td><td align="center" rowspan="1" colspan="1">-40%</td></tr><tr><td align="center" rowspan="1" colspan="1">a few</td><td align="center" rowspan="1" colspan="1">-25%</td><td align="center" rowspan="1" colspan="1">low</td><td align="center" rowspan="1" colspan="1">-20%</td></tr></tbody></table></alternatives></table-wrap><p>Let <italic>M</italic><sub><italic>pos</italic></sub> be a list of positive modifiers and <italic>M</italic><sub><italic>neg</italic></sub> be a list of negative modifiers represented as:
<disp-formula id="pone.0171649.e006"><alternatives><graphic xlink:href="pone.0171649.e006.jpg" id="pone.0171649.e006g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M6"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">p</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula>
<disp-formula id="pone.0171649.e007"><alternatives><graphic xlink:href="pone.0171649.e007.jpg" id="pone.0171649.e007g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M7"><mml:mrow><mml:msub><mml:mi>M</mml:mi><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mo>{</mml:mo><mml:mi mathvariant="normal">l</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">v</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">m</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mo>}</mml:mo></mml:mrow></mml:math></alternatives></disp-formula></p><p>If a word is found in a set of positive or negative modifiers, then the polarity of the neighboring opinion word is computed as follows:
<disp-formula id="pone.0171649.e008"><alternatives><graphic xlink:href="pone.0171649.e008.jpg" id="pone.0171649.e008g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M8"><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:mi>p</mml:mi><mml:mi>m</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="0.75em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mi>&#x003f5;</mml:mi><mml:mspace width="0.25em"/><mml:mi>R</mml:mi><mml:mo>&#x022c0;</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:mi>n</mml:mi><mml:mi>m</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="0.35em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mi>&#x003f5;</mml:mi><mml:mspace width="0.25em"/><mml:mi>R</mml:mi><mml:mo>&#x022c0;</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02208;</mml:mo><mml:msub><mml:mrow><mml:mi>M</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(2)</label></disp-formula>
where, <italic>w</italic><sub><italic>x</italic></sub> and <italic>w</italic><sub><italic>y</italic></sub> denote the words belonging to a set of +ive and &#x02013;ive modifiers respectively, w is an opinion word which belongs to a set of words <italic>W</italic>, <italic>r</italic> is a review from a set of reviews <italic>R</italic>, <italic>pm_score(w</italic><sub><italic>x</italic></sub><italic>)</italic> is the percentage score of +ive modifier and <italic>nm_score(w</italic><sub><italic>x</italic></sub><italic>)</italic> is the percentage score of -ive modifier retrieved from corresponding modifier dictionaries. The sentiment score of neighboring opinion word is obtained by multiplying the percentage score of modifier by the SWN-based sentiment score of opinion word and then adding it to the SWN-based sentiment score of an opinion word.</p><p>For example, in the sentence: <italic>&#x0201c;the medicine is so for very good&#x0201d;</italic>, the modifier <italic>&#x0201c;very&#x0201d;</italic> is enhancing the weight of the adjacent opinion word: <italic>&#x0201c;good&#x0201d;</italic>. Therefore, using <xref ref-type="disp-formula" rid="pone.0171649.e008">Eq 2</xref>, the enhanced sentiment score of an opinion word <italic>&#x0201c;good&#x0201d;</italic> is calculated as follows:</p><p><italic>pol</italic><sub><italic>score&#x02013;mod</italic></sub>("<italic>good</italic>") = <italic>pol</italic><sub><italic>score</italic></sub>(good")+(<italic>pol</italic><sub><italic>score</italic></sub>("good") * <italic>pm_score</italic>("very&#x0201d;) = 0.625+(0.625 x 50%) = 0.625+0.3125 = 0.9375, where, 0.625 is the sentiment score of opinion word, namely &#x0201c;good&#x0201d;, retrieved from SWN and 50% is the strength of positive modifier: &#x0201c;very&#x0201d;, obtained from <xref ref-type="table" rid="pone.0171649.t003">Table 3</xref>, and 0.9375 is modified score of opinion word &#x0201c;good&#x0201d; after the manipulation of modifier.</p><p><bold>Negation Management:</bold> Negation terms, such as: <italic>not</italic>, <italic>never</italic>, <italic>can&#x02019;t</italic>, <italic>couldn&#x02019;t</italic>, <italic>didn&#x02019;t</italic>, and <italic>don&#x02019;t</italic>, often reverse the polarity of the opinion words in a sentence. For example, the sentences: <italic>&#x0201c;the medicine is effective&#x0201d;</italic> and <italic>&#x0201c;the medicine is not effective&#x0201d;</italic> have different polarities. The first sentence carries positive sentiment, however, in second sentence, the negation term <italic>&#x0201c;not&#x0201d;</italic> reverses the polarity of opinion word <italic>&#x0201c;effective&#x0201d;</italic> from +ive to -ive. Therefore, the negation terms must be properly handled for accurate polarity computation. This work is an adaptation of the work performed by [<xref rid="pone.0171649.ref020" ref-type="bibr">20</xref>] for negation handling. We create a list of negation terms and presence of each word in a sentence is checked.</p><p>Let <italic>Neg</italic> be a list of negation words defined as:
<disp-formula id="pone.0171649.e009"><alternatives><graphic xlink:href="pone.0171649.e009.jpg" id="pone.0171649.e009g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M9"><mml:mrow><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">f</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">n</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">t</mml:mi><mml:mi mathvariant="normal">i</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">n</mml:mi><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">w</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">d</mml:mi><mml:mi mathvariant="normal">s</mml:mi></mml:mrow><mml:mo>}</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives></disp-formula></p><p>If a word is found in the negation list, then the polarity of the neighboring opinion word is flipped simply by multiplying the score of opinion word by -1 as follows:
<disp-formula id="pone.0171649.e010"><alternatives><graphic xlink:href="pone.0171649.e010.jpg" id="pone.0171649.e010g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M10"><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mspace width="0.25em"/><mml:mi>&#x003f5;</mml:mi><mml:mspace width="0.25em"/><mml:mi>R</mml:mi><mml:mo>&#x022c0;</mml:mo><mml:mo>(</mml:mo><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>x</mml:mi></mml:mrow></mml:msub><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn><mml:mo>)</mml:mo><mml:mo>&#x02208;</mml:mo></mml:mrow><mml:mi>N</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>)</mml:mo></mml:math></alternatives><label>(3)</label></disp-formula>
Where <italic>w</italic><sub>x</sub> denotes the neighboring opinion word and <italic>w</italic><sub>x</sub>-1 denotes the preceding word of an opinion word which belongs to a set of negation words <italic>Neg</italic> and <italic>r</italic> is a review from the set of reviews <italic>R</italic>. For example, using <xref ref-type="disp-formula" rid="pone.0171649.e010">Eq 3</xref>, the sentiment score of &#x0201c;<italic>not effective</italic>&#x0201d; is computed as follows:
<disp-formula id="pone.0171649.e011"><alternatives><graphic xlink:href="pone.0171649.e011.jpg" id="pone.0171649.e011g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M11"><mml:mo>=</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi><mml:mi>f</mml:mi><mml:mi>f</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mn>0.65</mml:mn><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">x</mml:mi><mml:mspace width="0.25em"/><mml:mtext>-</mml:mtext><mml:mn>1</mml:mn><mml:mo>=</mml:mo><mml:mtext>-</mml:mtext><mml:mn>0.65</mml:mn><mml:mo>.</mml:mo></mml:math></alternatives></disp-formula></p><p>In above computation, the polarity score of an opinion word &#x0201c;<italic>effective</italic>&#x0201d; is 0.65, which is obtained from SWN, and after applying negation (<xref ref-type="disp-formula" rid="pone.0171649.e010">Eq 3</xref>), it becomes -0.65.</p></sec><sec id="sec009"><title>SentiWordNet Classifier (SWNC)</title><p>This module is used to assign sentiment scores to opinion words using SentiWordNet [<xref rid="pone.0171649.ref024" ref-type="bibr">24</xref>]. Firstly, review document is passed through the NLTK-based (<ext-link ext-link-type="uri" xlink:href="http://www.nltk.org/book/ch05.html">http://www.nltk.org/book/ch05.html</ext-link>) python module which assigns a part of speech tag to each of the word (section 3.1 &#x0201c;noise reduction&#x0201d;). Part-Of-Speech (P.O.S) indicates the property and informativeness of a word [<xref rid="pone.0171649.ref025" ref-type="bibr">25</xref>], thus it is utilized to calculate sentiment scores." After P.O.S tagging, only those terms are considered and searched in SWN, which match the assigned part of speech tag. In this way, terms to be considered are reduced and all senses are not taken into account. If multiple senses belong to a specific term, then the arithmetic mean is computed as follows:
<disp-formula id="pone.0171649.e012"><alternatives><graphic xlink:href="pone.0171649.e012.jpg" id="pone.0171649.e012g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M12"><mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mfrac bevelled="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></alternatives><label>(4)</label></disp-formula>
<disp-formula id="pone.0171649.e013"><alternatives><graphic xlink:href="pone.0171649.e013.jpg" id="pone.0171649.e013g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M13"><mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mfrac bevelled="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></alternatives><label>(5)</label></disp-formula>
<disp-formula id="pone.0171649.e014"><alternatives><graphic xlink:href="pone.0171649.e014.jpg" id="pone.0171649.e014g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M14"><mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mfrac bevelled="true"><mml:mrow><mml:msub><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mrow><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mi>i</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:msub><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub></mml:mrow></mml:mfrac></mml:mrow></mml:mrow></mml:math></alternatives><label>(6)</label></disp-formula>
Where &#x0201c;<italic>p</italic>&#x0201d;, <italic>&#x0201c;n&#x0201d;</italic>, and <italic>&#x0201c;o&#x0201d;</italic> denote +ive, -ive and objective scores for particular word (<italic>w</italic>), <italic>n</italic><sub><italic>pos</italic></sub> represents total number of synsets of the word for corresponding part-of-speech. After computing the mean (average) for different synsets of a word under particular part of speech category, we obtain three scores: +ive, -ive and objective. The final score of the opinion word is calculated as follows:
<disp-formula id="pone.0171649.e015"><alternatives><graphic xlink:href="pone.0171649.e015.jpg" id="pone.0171649.e015g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M15"><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mi>l</mml:mi><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>o</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mspace width="1em"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mi>m</mml:mi><mml:mi>a</mml:mi><mml:mi>x</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>p</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="1em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mtext>max</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>n</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mi>o</mml:mi></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>n</mml:mi></mml:msub></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="4em"/><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>l</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow><mml:mi>o</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="2em"/><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></alternatives><label>(7)</label></disp-formula></p><p>In a given input text, the word &#x0201c;scream&#x0201d; has 6 entries (synsets) in SWN: 3 times as noun and 3 times as verb. If the word &#x0201c;scream&#x0201d; in the input text is noun, then its 3 scores with respect to 3-nouns are represented as:</p><list list-type="bullet"><list-item><p>scream#3(noun), PosScore = 0.25, NegScore = 0.375, ObjScore = 0.375</p></list-item><list-item><p>scream#1(noun), PosScore = 0.125, NegScore = 0.0, ObjScore = 0.875</p></list-item><list-item><p>scream#2(noun), PosScore = 0.0, NegScore = 0.0, ObjScore = 1.0</p></list-item></list><p>The aggregated positive, negative and objective scores for the word &#x0201c;scream&#x0201d; are computed using Eq (<xref ref-type="disp-formula" rid="pone.0171649.e012">4</xref>), Eq (<xref ref-type="disp-formula" rid="pone.0171649.e013">5</xref>) and Eq (<xref ref-type="disp-formula" rid="pone.0171649.e014">6</xref>) as follows:
<disp-formula id="pone.0171649.e016"><alternatives><graphic xlink:href="pone.0171649.e016.jpg" id="pone.0171649.e016g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M16"><mml:mrow><mml:mi mathvariant="normal">P</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">s</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mo>=</mml:mo><mml:mn>0.125</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">N</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mi mathvariant="normal">g</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mo>=</mml:mo><mml:mn>0.125</mml:mn><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi mathvariant="normal">O</mml:mi><mml:mi mathvariant="normal">b</mml:mi><mml:mi mathvariant="normal">j</mml:mi><mml:mi mathvariant="normal">S</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">o</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">e</mml:mi><mml:mspace width="0.25em"/><mml:mo>=</mml:mo><mml:mn mathvariant="bold">0.75</mml:mn></mml:mrow></mml:math></alternatives></disp-formula></p><p>We select maximum value among the aforementioned three scores, i.e. 0.75, which represents the objective score.</p></sec><sec id="sec010"><title>Domain Specific Classifier (DSC)</title><p>The domain specific words, such as most of words in the health-related domain, have one sentiment class in SWN, whereas, their semantics indicate strong inclination with the other polarity class. If a word&#x02019;s SWN-based aggregated sentiment score is positive, but its semantics indicate inclination towards negative class as compared to positive ones, we predict the new sentiment class of a word and update the sentiment score accordingly.</p><p>The DSC module is used to assign accurate sentiment class and scores to domain specific words. The proposed classifier is inspired from our recent work on domain dependent lexicon generation [<xref rid="pone.0171649.ref026" ref-type="bibr">26</xref>]. In DSC, we adopt their work to predict sentiment class of domain specific words using mutual information concepts and improved feature weighting scheme. However, to assign correct sentiment scores to domain specific words, we propose an alternative strategy based on revised SWN scoring and the manual annotation. The proposed DSC module yields improved results (see results and discussion section) than the comparing methods. It is comprised of two sub-modules, namely (i) Predicting Sentiment Class of a Word and (ii) Modifying Word Sentiment Score.</p><p><bold>Predicting Sentiment Class of a Word:</bold> To predict new sentiment class of a word w with positive or negative class, we adopt Mutual Information (MI) based strategy presented in our previous work [<xref rid="pone.0171649.ref026" ref-type="bibr">26</xref>]. In this strategy, we take two class tags, the positive tag cp and negative tag cn. The sentiment score on SentMI(w, cp) of a word w on class tag cp is computed as:</p><p><italic>Sent</italic><sub><italic>MI</italic></sub>(<italic>w</italic>, <italic>c</italic><sub><italic>p</italic></sub>) of word <italic>w</italic> on class tag <italic>c</italic><sub><italic>p</italic></sub> is computed as:
<disp-formula id="pone.0171649.e017"><alternatives><graphic xlink:href="pone.0171649.e017.jpg" id="pone.0171649.e017g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M17"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives><label>(8)</label></disp-formula></p><p>Similarly, we compute sentiment score <italic>Sent</italic><sub><italic>MI</italic></sub> (<italic>w</italic>, <italic>c</italic><sub><italic>n</italic></sub>) as:
<disp-formula id="pone.0171649.e018"><alternatives><graphic xlink:href="pone.0171649.e018.jpg" id="pone.0171649.e018g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M18"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mn>1</mml:mn><mml:mo>&#x02212;</mml:mo><mml:mi mathvariant="normal">&#x003b1;</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:math></alternatives><label>(9)</label></disp-formula>
Where &#x003b1; is the threshold representing the contributions of <italic>MI</italic>(<italic>w</italic>, <italic>c</italic><sub><italic>p</italic></sub>) and <italic>MI</italic>(<italic>w</italic>, <italic>c</italic><sub><italic>n</italic></sub>), and it ranges from 0 to 1. It is selected after the manual inspection of test sentences for different inputs of unigrams and bigrams. The sentiment score of word <italic>w</italic> for class tag <italic>c</italic> is the linear combination of <italic>MI</italic> with a positive class tag <italic>c</italic><sub><italic>p</italic></sub> and a negative positive class tag <italic>c</italic><sub><italic>n</italic></sub>. Different values (in the range of 0 to 1) of threshold &#x0201c;alpha&#x0201d; are experimented both for unigrams (e.g., Acute) and bigrams (e.g., Heart-burn). Finally, we come up with conclusion that ideal values of &#x003b1; ranges between {0.3 to 1}. For the unigram, the value of &#x003b1; ranges between {0.3 to 0.7}, and for bigram, it ranges from {0.8 to 1}.</p><p>In the next step, we combine <italic>Sent</italic><sub><italic>MI</italic></sub>(<italic>w</italic>,<italic>c</italic><sub><italic>p</italic></sub>) and <italic>Sent</italic><sub><italic>MI</italic></sub>(<italic>w</italic>,<italic>c</italic><sub><italic>n</italic></sub>) as:
<disp-formula id="pone.0171649.e019"><alternatives><graphic xlink:href="pone.0171649.e019.jpg" id="pone.0171649.e019g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M19"><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mspace width="0.75em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>&#x0003e;</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mspace width="0.75em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>&#x0003e;</mml:mo><mml:msub><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi></mml:mrow><mml:mrow><mml:mi>M</mml:mi><mml:mi>I</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>,</mml:mo><mml:msub><mml:mrow><mml:mi>c</mml:mi></mml:mrow><mml:mrow><mml:mi>p</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mspace width="7em"/><mml:mrow><mml:mn>0</mml:mn><mml:mspace width="4em"/><mml:mi>e</mml:mi><mml:mi>l</mml:mi><mml:mi>s</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(10)</label></disp-formula></p><p>If <italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w</italic>, <italic>cp)&#x0003e;Sent</italic><sub><italic>MI</italic></sub>
<italic>(w</italic>, <italic>cn)</italic>, then the sentiment class of the word <italic>w</italic> is positive, and the accumulative <italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w)</italic> sentiment score is +ive. However, if the sentiment of word <italic>w</italic> is negative, then the <italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w)</italic> score will be negative. For example, if <italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w</italic>, <italic>cn)</italic> = 4 and <italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w</italic>, <italic>cp)</italic> = 2.3, then the word <italic>w</italic> tends to be negative and <italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w)</italic> = 3. If the value of <italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w</italic>, <italic>cp)</italic> is greater than that of the <italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w</italic>, <italic>cn)</italic> then the word <italic>w</italic> shows a positive sentiment. Finally, if the aforementioned cases do not stand true, then the sentiment of the word <italic>w</italic> is considered as neutral.</p><p>A partial list of unigrams and bigrams along with predicted sentiment class is presented in <xref ref-type="table" rid="pone.0171649.t005">Table 5</xref>.</p><table-wrap id="pone.0171649.t005" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t005</object-id><label>Table 5</label><caption><title>Partial list of domain specific terms with predicted sentiment class.</title></caption><alternatives><graphic id="pone.0171649.t005g" xlink:href="pone.0171649.t005"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="justify" colspan="2" rowspan="1">Unigram</th><th align="justify" colspan="2" rowspan="1">Bigram</th></tr><tr><th align="justify" rowspan="1" colspan="1">Term</th><th align="left" rowspan="1" colspan="1">Predicted Sentiment Class<break/>Using Eq (<xref ref-type="disp-formula" rid="pone.0171649.e019">10</xref>)</th><th align="justify" rowspan="1" colspan="1">Term</th><th align="justify" rowspan="1" colspan="1">Predicted Sentiment Class Using Eq (<xref ref-type="disp-formula" rid="pone.0171649.e019">10</xref>)</th></tr></thead><tbody><tr><td align="justify" rowspan="1" colspan="1">Acute</td><td align="justify" rowspan="1" colspan="1">+ive</td><td align="justify" rowspan="1" colspan="1">Fast acting</td><td align="justify" rowspan="1" colspan="1">+ive</td></tr><tr><td align="justify" rowspan="1" colspan="1">Abrasion</td><td align="justify" rowspan="1" colspan="1">-ive</td><td align="justify" rowspan="1" colspan="1">Heart-burn</td><td align="justify" rowspan="1" colspan="1">- ive</td></tr><tr><td align="justify" rowspan="1" colspan="1">Nausea</td><td align="justify" rowspan="1" colspan="1">-ive</td><td align="justify" rowspan="1" colspan="1">Covering up</td><td align="justify" rowspan="1" colspan="1">+ive</td></tr><tr><td align="justify" rowspan="1" colspan="1">Chronic</td><td align="justify" rowspan="1" colspan="1">-ive</td><td align="justify" rowspan="1" colspan="1">abdominal distension</td><td align="justify" rowspan="1" colspan="1">-ive</td></tr><tr><td align="justify" rowspan="1" colspan="1">Exhaust</td><td align="justify" rowspan="1" colspan="1">-ive</td><td align="justify" rowspan="1" colspan="1">Nervous breakdown</td><td align="justify" rowspan="1" colspan="1">-ive</td></tr><tr><td align="justify" rowspan="1" colspan="1">Deaden</td><td align="justify" rowspan="1" colspan="1">+ive</td><td align="justify" rowspan="1" colspan="1">Heart beat</td><td align="justify" rowspan="1" colspan="1">neu</td></tr><tr><td align="justify" rowspan="1" colspan="1">Relieve</td><td align="justify" rowspan="1" colspan="1">+ive</td><td align="justify" rowspan="1" colspan="1">Bring down</td><td align="justify" rowspan="1" colspan="1">+ive</td></tr><tr><td align="justify" rowspan="1" colspan="1">Able</td><td align="justify" rowspan="1" colspan="1">+ive</td><td align="justify" rowspan="1" colspan="1">Cough up</td><td align="justify" rowspan="1" colspan="1">-ive</td></tr><tr><td align="justify" rowspan="1" colspan="1">Psychotic</td><td align="justify" rowspan="1" colspan="1">-ive</td><td align="justify" rowspan="1" colspan="1">Pulse rate</td><td align="justify" rowspan="1" colspan="1">neu</td></tr><tr><td align="justify" rowspan="1" colspan="1">Insight</td><td align="justify" rowspan="1" colspan="1">+ive</td><td align="justify" rowspan="1" colspan="1">Color blindness</td><td align="justify" rowspan="1" colspan="1">-ive</td></tr></tbody></table></alternatives></table-wrap><p><bold>Modifying Word Sentiment Score:</bold> When the SWN-based average scores (<xref ref-type="disp-formula" rid="pone.0171649.e012">Eq 4</xref>, <xref ref-type="disp-formula" rid="pone.0171649.e013">Eq 5</xref>, and <xref ref-type="disp-formula" rid="pone.0171649.e014">Eq 6</xref>) represent one sentiment class (positive, negative or neutral) and the <italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w)</italic> score of a word (<xref ref-type="disp-formula" rid="pone.0171649.e019">Eq 10</xref>) shows another sentiment class of a given word, we modify the sentiment score of such opinion words. Moreover, if a word is not available in SWN then sentiment classification and scoring of such words becomes difficult. This problem can be solved by using a manually crafted scale of +1 to -1 for sentiment scoring of each of the domain specific word.</p><p>The proposed method for updating the sentiment score of domain specific sentiment words is an enhancement of the work proposed by [<xref rid="pone.0171649.ref027" ref-type="bibr">27</xref>] and [<xref rid="pone.0171649.ref028" ref-type="bibr">28</xref>]. They used polarity shift method to change the polarity of word from +ive to &#x02013;ive and vice versa, whereas we have enhanced it for scoring of such words which are not available in SWN by using Manual Scoring Annotation Scheme(<xref ref-type="disp-formula" rid="pone.0171649.e021">Eq 12</xref>). This enhancement contributes significantly in the accurate scoring of domain specific words.</p><p>The proposed method is formulated using <xref ref-type="disp-formula" rid="pone.0171649.e020">Eq 11</xref> and <xref ref-type="disp-formula" rid="pone.0171649.e021">Eq 12</xref> as follows:
<disp-formula id="pone.0171649.e020"><alternatives><graphic xlink:href="pone.0171649.e020.jpg" id="pone.0171649.e020g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M20"><mml:mrow><mml:msub><mml:mrow><mml:mtext>pol</mml:mtext></mml:mrow><mml:mrow><mml:mtext>score</mml:mtext><mml:mo>&#x02212;</mml:mo><mml:mtext>ds</mml:mtext></mml:mrow></mml:msub><mml:mrow><mml:mo>(</mml:mo><mml:mtext>w</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mspace width="0.75em"/><mml:mtext>pos</mml:mtext><mml:mo>_</mml:mo><mml:mtext>score</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>w</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>*</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>pos</mml:mtext><mml:mo>_</mml:mo><mml:mtext>score</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>w</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003e;</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mrow><mml:mo>(</mml:mo><mml:mi>w</mml:mi><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x002c4;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>pos</mml:mtext><mml:mo>_</mml:mo><mml:mtext>score</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>w</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003e;</mml:mo><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x002c4;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>SentMI</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>w</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mtext>is</mml:mtext><mml:mo>&#x02212;</mml:mo><mml:mtext>ive</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mtext>neg</mml:mtext><mml:mo>_</mml:mo><mml:mtext>score</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>w</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>*</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>,</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>neg</mml:mtext><mml:mo>_</mml:mo><mml:mtext>score</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>w</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003e;</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x002c4;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>neg</mml:mtext><mml:mo>_</mml:mo><mml:mtext>score</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>w</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mo>&#x0003e;</mml:mo><mml:mi>o</mml:mi><mml:mi>b</mml:mi><mml:mi>j</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo stretchy="false">(</mml:mo><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo stretchy="false">)</mml:mo><mml:mo>&#x002c4;</mml:mo><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mtext>SentMI</mml:mtext><mml:mrow><mml:mo>(</mml:mo><mml:mtext>w</mml:mtext><mml:mo>)</mml:mo></mml:mrow><mml:mspace width="0.25em"/><mml:mtext>is</mml:mtext><mml:mo>+</mml:mo><mml:mtext>ive</mml:mtext></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:mrow></mml:math></alternatives><label>(11)</label></disp-formula>
where <italic>pos_score(w)</italic>, <italic>neg_score(w)</italic>, and <italic>obj_score(w)</italic> are the positive, negative and neutral scores of word <italic>w</italic> in SWN using Eq (<xref ref-type="disp-formula" rid="pone.0171649.e012">4</xref>), Eq (<xref ref-type="disp-formula" rid="pone.0171649.e013">5</xref>) and Eq (<xref ref-type="disp-formula" rid="pone.0171649.e014">6</xref>) respectively; &#x0201c;<italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w)</italic> is +ive&#x0201d; shows that the word <italic>w</italic> is labeled +ive using Eq (<xref ref-type="disp-formula" rid="pone.0171649.e020">11</xref>) and &#x0201c;<italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w)</italic> is -ive&#x0201d; shows that the word <italic>w</italic> is labeled as -ive using Eq (<xref ref-type="disp-formula" rid="pone.0171649.e019">10</xref>).</p><p>The Eq (<xref ref-type="disp-formula" rid="pone.0171649.e020">11</xref>) depicts two possible cases for scoring domain specific words: (i) if a term&#x02019;s SWN-based sentiment score (Eqs <xref ref-type="disp-formula" rid="pone.0171649.e012">4</xref>, <xref ref-type="disp-formula" rid="pone.0171649.e013">5</xref>, <xref ref-type="disp-formula" rid="pone.0171649.e014">6</xref>) is +ive but its SentMI (w) class is -ive then we invert its +ive sentiment score to &#x02013;ive, and (ii) if a term&#x02019;s SWN-based sentiment score (Eqs <xref ref-type="disp-formula" rid="pone.0171649.e012">4</xref>, <xref ref-type="disp-formula" rid="pone.0171649.e013">5</xref>, <xref ref-type="disp-formula" rid="pone.0171649.e014">6</xref>) is -ive but its SentMI (w) class is +ive then we invert its -ive sentiment score to +ive.</p><p><bold>Manual Scoring Annotation Scheme:</bold> The Manual Scoring Annotation Scheme aims at assigning polarity scores to those words which are not available in SWN. Our proposed scheme works as follows: We hired the services of five human annotators who are subject specialists in English language. We provided a list of words generated from our datasets, which are not available in SentiWordNet (SWN). We asked each expert to label the words on a scale of -+0.1 to -+ 1. After performing the manual annotation of entire list, we received five scores for each word. We take average of the five sentiment scores assigned by annotators to each and assign that average score to its corresponding sentiment word. It assists in increasing the scalability of manual evaluation of words not available in SWN.</p><p>The Manual Scoring Annotation Scheme is formulated as follows:
<disp-formula id="pone.0171649.e021"><alternatives><graphic xlink:href="pone.0171649.e021.jpg" id="pone.0171649.e021g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M21"><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable columnalign="left"><mml:mtr><mml:mtd><mml:mspace width="0.75em"/><mml:mrow><mml:mrow><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>+</mml:mo><mml:mn>0.1</mml:mn><mml:mspace width="0.25em"/><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mspace width="0.25em"/><mml:mo>+</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>}</mml:mo><mml:mo>/</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>&#x02209;</mml:mo><mml:mi>S</mml:mi><mml:mi>W</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>&#x002c4;</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>+</mml:mo><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mrow><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mn>5</mml:mn></mml:mrow></mml:msubsup><mml:mrow><mml:mo>{</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>0.1</mml:mn><mml:mspace width="0.25em"/><mml:mi>t</mml:mi><mml:mi>o</mml:mi><mml:mspace width="0.25em"/><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mo>}</mml:mo><mml:mo>/</mml:mo><mml:mn>5</mml:mn></mml:mrow></mml:mrow><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi><mml:mo>&#x02209;</mml:mo><mml:mi>S</mml:mi><mml:mi>W</mml:mi><mml:mi>N</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>&#x002c4;</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi>S</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mi>M</mml:mi><mml:mi>I</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(12)</label></disp-formula></p><p>The <xref ref-type="disp-formula" rid="pone.0171649.e021">Eq 12</xref> demonstrates that if a word is not available in SWN (<italic>w</italic> &#x02209; <italic>SWN</italic>) and its SentMI (w) class is +ive, then the score ranges between the average of the five scores of {+0.1 and +1}. If the word is not available in SWN (<italic>w</italic> &#x02209; <italic>SWN</italic>) and its SentMI (w) class is -ive, then the score ranges between the average of the five scores of {-0.1 and -1} using the aforementioned Manual Scoring Annotation Scheme. For example the word&#x0201c; <italic>heart-burn&#x0201d;</italic> is not available in SWN and its <italic>Sent</italic><sub><italic>MI</italic></sub>
<italic>(w)</italic>class is &#x02013;ive. Therefore, the word <italic>&#x0201c;heart-burn&#x0201d;</italic> receives a score of -0.5 using <xref ref-type="disp-formula" rid="pone.0171649.e021">Eq 12</xref>. In <xref ref-type="table" rid="pone.0171649.t006">Table 6</xref>, we can observe that the two words, namely &#x0201c;<italic>heart burn</italic>&#x0201d; and &#x0201c;<italic>sore throat</italic>&#x0201d; are not available in SWN, and therefore, their scores are manually crafted by a group of manual annotators in the aforementioned process of Manual Scoring Annotation Scheme.</p><table-wrap id="pone.0171649.t006" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t006</object-id><label>Table 6</label><caption><title>Words and their Sentiment coverage.</title></caption><alternatives><graphic id="pone.0171649.t006g" xlink:href="pone.0171649.t006"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="justify" rowspan="1" colspan="1">Term</th><th align="justify" rowspan="1" colspan="1">SentiWordNet Polarity</th><th align="justify" rowspan="1" colspan="1">Modified polarity and score using <xref ref-type="disp-formula" rid="pone.0171649.e020">Eq 11</xref> and <xref ref-type="disp-formula" rid="pone.0171649.e021">Eq 12</xref></th><th align="justify" rowspan="1" colspan="1">Example Sentence</th></tr></thead><tbody><tr><td align="justify" rowspan="1" colspan="1">heart-burn</td><td align="justify" rowspan="1" colspan="1">not found</td><td align="justify" rowspan="1" colspan="1">negative(-0.5) (using <xref ref-type="disp-formula" rid="pone.0171649.e021">Eq 12</xref>)</td><td align="justify" rowspan="1" colspan="1">I do not like this medicine. It caused <bold>heart-burn.</bold></td></tr><tr><td align="justify" rowspan="1" colspan="1">sore throat</td><td align="left" rowspan="1" colspan="1">not found</td><td align="justify" rowspan="1" colspan="1">negative(-0.4) (using <xref ref-type="disp-formula" rid="pone.0171649.e021">Eq 12</xref>)</td><td align="justify" rowspan="1" colspan="1">It caused <bold>sore-throat</bold> and blisters on my tongue.</td></tr><tr><td align="justify" rowspan="1" colspan="1">Growth</td><td align="left" rowspan="1" colspan="1">neutral (1)</td><td align="justify" rowspan="1" colspan="1">negative (-1) (using <xref ref-type="disp-formula" rid="pone.0171649.e020">Eq 11</xref>)</td><td align="justify" rowspan="1" colspan="1">The abnormal <bold>growth</bold> on the left shoulder is getting worst.</td></tr><tr><td align="justify" rowspan="1" colspan="1">Relax</td><td align="justify" rowspan="1" colspan="1">Neutral(0.625)</td><td align="justify" rowspan="1" colspan="1">positive(+0.625) (using <xref ref-type="disp-formula" rid="pone.0171649.e020">Eq 11</xref>)</td><td align="left" rowspan="1" colspan="1">It really works well and relaxes my anxiety.</td></tr><tr><td align="justify" rowspan="1" colspan="1">Hospital</td><td align="justify" rowspan="1" colspan="1">Neutral(0.8125)</td><td align="justify" rowspan="1" colspan="1">Negative(-0.8125) (using <xref ref-type="disp-formula" rid="pone.0171649.e020">Eq 11</xref>)</td><td align="justify" rowspan="1" colspan="1">I am in <bold>hospital</bold> with server stomach problem.</td></tr><tr><td align="justify" rowspan="1" colspan="1">Clot</td><td align="justify" rowspan="1" colspan="1">neutral (1)</td><td align="justify" rowspan="1" colspan="1">negative (-1) (using <xref ref-type="disp-formula" rid="pone.0171649.e020">Eq 11</xref>)</td><td align="left" rowspan="1" colspan="1">The doctor diagnosed a blood <bold>clot</bold> in the brain.</td></tr><tr><td align="justify" rowspan="1" colspan="1">Dressing</td><td align="justify" rowspan="1" colspan="1">neutral (1)</td><td align="justify" rowspan="1" colspan="1">Positive(+1) (using <xref ref-type="disp-formula" rid="pone.0171649.e020">Eq 11</xref>)</td><td align="left" rowspan="1" colspan="1">The patient&#x02019;s dressings need to be changed regularly.</td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec011"><title>Sentence and review-level sentiment classification</title><p>For each of the sentence in a given review, we compute sentiment score by adding all of the scores of emoticons, modifiers and opinion words present in a sentence. The proposed sentence and review-level sentiment classification is an enhancement of the work proposed by khan et al. [<xref rid="pone.0171649.ref020" ref-type="bibr">20</xref>]. They used limited model of modifiers, whereas we have enhanced it with hand-ranked percentage scale for representing variety of modifiers as well as their sentiment score. Moreover, we have included emoticon and domain specific modules for improving the accuracy of sentiment classification, which we demonstrated in the results and evaluation section.</p><p><bold>SWNC-based sentence level sentiment classification:</bold> Firstly, we classify a sentence using SWNC-based classifier as:
<disp-formula id="pone.0171649.e022"><alternatives><graphic xlink:href="pone.0171649.e022.jpg" id="pone.0171649.e022g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M22"><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>o</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(13)</label></disp-formula></p><p>Using SWNC scores, we classify the review as:
<disp-formula id="pone.0171649.e023"><alternatives><graphic xlink:href="pone.0171649.e023.jpg" id="pone.0171649.e023g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M23"><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mo>_</mml:mo><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>w</mml:mi><mml:mi>n</mml:mi><mml:mi>c</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(14)</label></disp-formula></p><p>The review is classified as +ive, if sum of all scores of sentences is &#x0003e;0 and review is classified as &#x02013;ive, if sum of all scores of sentences is &#x0003c; 0; otherwise the review is classified as neutral</p><p>For example a sentence in health domain is written as: <italic>&#x0201c;It caused</italic>
<bold><italic>slight sore-throat</italic></bold>&#x1f610;<italic>&#x0201d;</italic>. To perform sentiment classification of this sentence, firstly we classify it using SWNC classifier. For this purpose, we express the polarity scores of opinion words, modifiers, negations and emoticons expressed in the input sentence as follows:</p><p><bold>Emoticon scoring:</bold> There is one emoticon in example sentence, therefore, using <xref ref-type="disp-formula" rid="pone.0171649.e005">Eq 1</xref>, polarity score of emoticon = <italic>pol</italic><sub><italic>score&#x02013;emo</italic></sub>(<italic>e</italic>) = = <italic>pol</italic><sub><italic>score&#x02013;emo</italic></sub>("&#x1f610;") = 0, because, according to <xref ref-type="disp-formula" rid="pone.0171649.e005">Eq 1</xref>, straight face emoticon is neutral, with score=0.</p><p><bold>Modifier scoring:</bold> Using <xref ref-type="disp-formula" rid="pone.0171649.e008">Eq 2</xref>, polarity score of modifier and its associated opinion term is computed as: <italic>pol</italic><sub><italic>score&#x02013;mod</italic></sub>(<italic>w</italic>) = <italic>pol</italic><sub><italic>score&#x02013;mod</italic></sub> ("<italic>slight sore throat</italic>") = <italic>pol</italic><sub><italic>score</italic></sub>(<italic>w</italic>) +(<italic>pol</italic><sub><italic>score</italic></sub>(<italic>w</italic>) * <italic>nm_score</italic>(<italic>w</italic><sub><italic>y</italic></sub>) = 0+[0*(-40%)] = 0. Here, the opinion word &#x0201c;<italic>sore throat</italic>&#x0201d; is not available in SWN, therefore its score is taken as 0, and according to <xref ref-type="table" rid="pone.0171649.t004">Table 4</xref>, the reducer modifier &#x0201c;<italic>slight</italic>&#x0201d; has weightage of -40%. As computed above using <xref ref-type="disp-formula" rid="pone.0171649.e008">Eq 2</xref>, we received a score of 0.</p><p><bold>Negation scoring:</bold> using <xref ref-type="disp-formula" rid="pone.0171649.e010">Eq 3</xref>, the polarity score of negation term is evaluated as: <italic>pol</italic><sub><italic>score&#x02013;neg</italic></sub>(<italic>w</italic>) = 0, the 0 shows that there is no negation term, and therefore, negation scoring is not applicable.</p><p><bold>Opinion word scoring:</bold> The scores of the opinion word, namely: &#x0201c;<italic>sore-throat</italic>&#x0201d; is not found in SWN lexicon, and SWNC-based <xref ref-type="disp-formula" rid="pone.0171649.e015">Eq 7</xref> does not assist us in assigning polarity score to such opinion word. Therefore, we assigned 0 to its opinion score as follows: <italic>pol</italic><sub><italic>score&#x02013;op</italic></sub>(<italic>w</italic>) = 0</p><p>Using <xref ref-type="disp-formula" rid="pone.0171649.e021">Eq 12</xref>, we compute sentence level score of the given input sentence by combining the aforementioned polarity scores as follows:
<disp-formula id="pone.0171649.e024"><alternatives><graphic xlink:href="pone.0171649.e024.jpg" id="pone.0171649.e024g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M24"><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>o</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo>=</mml:mo><mml:mn mathvariant="bold">0</mml:mn></mml:math></alternatives></disp-formula></p><p>The overall sentiment of sentence is neutral, with score = 0.</p><p>The major issue with SWNC classifier is that it may result in inaccurate scoring of domain specific words, which may lead to incorrect classification of sentence in multiple domains. For example, &#x0201c;<italic>sore throat</italic>&#x0201d; is a domain specific word, which is not found in SWN. Resultantly, overall score at sentence level for the previous input sentence is neutral (0), which is incorrect.</p><p><bold>DSC-based classification:</bold> To classify such domain specific words more accurately, we further classify a sentence using domain specific classifier (DSC) as:
<disp-formula id="pone.0171649.e025"><alternatives><graphic xlink:href="pone.0171649.e025.jpg" id="pone.0171649.e025g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M25"><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>_</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:math></alternatives><label>(15)</label></disp-formula></p><p>Finally, using DSC scores, we classify the review as:
<disp-formula id="pone.0171649.e026"><alternatives><graphic xlink:href="pone.0171649.e026.jpg" id="pone.0171649.e026g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M26"><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>v</mml:mi><mml:mi>i</mml:mi><mml:mi>e</mml:mi><mml:mi>w</mml:mi><mml:mo>_</mml:mo><mml:mi>c</mml:mi><mml:mi>l</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>s</mml:mi><mml:mo>_</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mo>=</mml:mo><mml:mrow><mml:mo>{</mml:mo><mml:mtable><mml:mtr><mml:mtd><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>t</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>_</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mo>&#x0003e;</mml:mo><mml:mn>0</mml:mn><mml:mo>)</mml:mo></mml:mrow></mml:mrow></mml:mrow></mml:mtd></mml:mtr><mml:mtr><mml:mtd><mml:mrow><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mi>i</mml:mi><mml:mi>v</mml:mi><mml:mi>e</mml:mi><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:mi>i</mml:mi><mml:mi>f</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mrow><mml:mstyle displaystyle="false"><mml:msubsup><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:msubsup></mml:mstyle><mml:mrow><mml:mi>s</mml:mi><mml:mi>e</mml:mi><mml:mi>n</mml:mi><mml:mi>t</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>_</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mo>&#x0003c;</mml:mo><mml:mn>0</mml:mn></mml:mrow></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mtd></mml:mtr></mml:mtable></mml:mrow></mml:math></alternatives><label>(16)</label></disp-formula></p><p>The sentence level score computed in the previous example using SWNC classifier is neutral with sentence level score=<bold>0</bold>, which is incorrect due to incorrect scoring domain specific term: &#x0201c;<italic>sore throat</italic>&#x0201d;. Therefore, we update the polarity scores of such domain specific word(s) using <xref ref-type="disp-formula" rid="pone.0171649.e021">Eq 12</xref>, and classify the sentence as:</p><p><italic>pol</italic><sub><italic>score&#x02013;ds</italic></sub>(<italic>w</italic>) = <italic>pol</italic><sub><italic>score&#x02013;ds</italic></sub>("<italic>sore throat</italic>") = -0. 4, and using <xref ref-type="disp-formula" rid="pone.0171649.e008">Eq 2</xref>, reducer modifier &#x0201c;<italic>slight</italic>&#x0201d; operates on opinion word &#x0201c;<italic>sore throat&#x0201d;</italic> as follows:
<disp-formula id="pone.0171649.e027"><alternatives><graphic xlink:href="pone.0171649.e027.jpg" id="pone.0171649.e027g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M27"><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mo>"</mml:mo><mml:mi mathvariant="bold-italic">s</mml:mi><mml:mi mathvariant="bold-italic">l</mml:mi><mml:mi mathvariant="bold-italic">i</mml:mi><mml:mi mathvariant="bold-italic">g</mml:mi><mml:mi mathvariant="bold-italic">h</mml:mi><mml:mi mathvariant="bold-italic">t</mml:mi><mml:mspace width="0.25em"/><mml:mi>s</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mspace width="0.25em"/><mml:mi>t</mml:mi><mml:mi>h</mml:mi><mml:mi>r</mml:mi><mml:mi>o</mml:mi><mml:mi>a</mml:mi><mml:mi>t</mml:mi><mml:mo>"</mml:mo></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>*</mml:mo><mml:mi>n</mml:mi><mml:mi>m</mml:mi><mml:mo>_</mml:mo><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>(</mml:mo><mml:mrow><mml:msub><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mrow><mml:mi>y</mml:mi></mml:mrow></mml:msub></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mtext>-</mml:mtext><mml:mn>0.4</mml:mn><mml:mo>+</mml:mo><mml:mo>[</mml:mo><mml:mtext>-</mml:mtext><mml:mn>0.4</mml:mn><mml:mi>*</mml:mi><mml:mo>(</mml:mo><mml:mtext>-</mml:mtext><mml:mn>40</mml:mn><mml:mi mathvariant="normal">%</mml:mi><mml:mo>)</mml:mo><mml:mo>]</mml:mo><mml:mo>=</mml:mo><mml:mtext>-</mml:mtext><mml:mn>0.24</mml:mn><mml:mo>.</mml:mo></mml:math></alternatives></disp-formula></p><p>Now applying <xref ref-type="disp-formula" rid="pone.0171649.e023">Eq 14</xref>, we get:
<disp-formula id="pone.0171649.e028"><alternatives><graphic xlink:href="pone.0171649.e028.jpg" id="pone.0171649.e028g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M28"><mml:mo>=</mml:mo><mml:mrow><mml:munderover><mml:mo>&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>=</mml:mo><mml:mn>1</mml:mn></mml:mrow><mml:mrow><mml:mi>n</mml:mi></mml:mrow></mml:munderover><mml:mrow><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>e</mml:mi><mml:mi>m</mml:mi><mml:mi>o</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>e</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>n</mml:mi><mml:mi>e</mml:mi><mml:mi>g</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>n</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>o</mml:mi><mml:mi>d</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mi>p</mml:mi><mml:mi>o</mml:mi><mml:msub><mml:mrow><mml:mi>l</mml:mi></mml:mrow><mml:mrow><mml:mi>s</mml:mi><mml:mi>c</mml:mi><mml:mi>o</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>d</mml:mi><mml:mi>s</mml:mi></mml:mrow></mml:msub><mml:mo>(</mml:mo><mml:mrow><mml:mi>w</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mo>)</mml:mo></mml:mrow></mml:mrow><mml:mo>=</mml:mo><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:mn>0</mml:mn><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn>0.24</mml:mn><mml:mo>)</mml:mo><mml:mo>+</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>0.4</mml:mn></mml:mrow><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mo>&#x02212;</mml:mo><mml:mn mathvariant="bold">0.64</mml:mn></mml:math></alternatives></disp-formula></p><p>When we compare sentence level score of SWNC classifier (0) with DSC classifier (-0.64), it is observed that the identification and correct scoring of domain specific terms have produced more accurate classification and scoring of entire sentence and helped in reducing the classification anomalies.</p><p>If the results of SWNC and DSC are identical, then the review is classified as +ive, -ive or neutral on the basis of SWNC scoring. However, if there is disagreement between the classifications results of SWNC and DSC then we consider DSC-based results, because it gives more accurate results with respect to consideration of domain specific words. This assists in maximizing the efficiency of sentiment classification which was the major limitation in previous studies. As reported in the results and discussion section, the proposed framework performs better than the baseline methods.</p></sec><sec id="sec012"><title>Proposed Algorithm</title><p>An abstract of the steps of the proposed rule-based classification method for implementing the enhanced sentiment analysis are shown as follows:</p><boxed-text id="pone.0171649.box001" position="float" orientation="portrait"><p specific-use="line"><bold>Algorithm 1.</bold> Lexicon-Enhanced Sentiment Analysis using rule-based Classification Scheme</p><p specific-use="line"><bold>Input:</bold> Users&#x02019; reviews</p><p specific-use="line"><bold>Output: S</bold>entiment class, sentiment Score</p><p specific-use="line"><bold>Beg</bold><bold>in</bold></p><p specific-use="line">## Read all entries in the corpus</p><p specific-use="line">1. <bold>While</bold> (there is sentence in review) <bold>Do</bold></p><p specific-use="line">1. &#x000a0;&#x000a0;&#x000a0;&#x000a0;Perform Preprocessing</p><p specific-use="line">2. <bold>if</bold> (a sentence contains opinion word/emoticon))</p><p specific-use="line">3. &#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;Subjective Tweet</p><p specific-use="line">4. &#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;Call sentiment_scoring(subjective sentence)</p><p specific-use="line">5. &#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;Go to step#1 to scan next sentence</p><p specific-use="line">6.<bold>else</bold></p><p specific-use="line">7.Objective sentence</p><p specific-use="line">8.Go to step#1 to scan next sentence</p><p specific-use="line">9.<bold>endif</bold></p><p specific-use="line">10.<bold>If</bold> word found in Emoticon Dictionary</p><p specific-use="line">11. &#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;&#x000a0;Perform classification using Emoticon Classifier (<styled-content><xref ref-type="disp-formula" rid="pone.0171649.e005">Eq 1</xref></styled-content>)</p><p specific-use="line">12. <bold>If</bold> word found in (Modifier or Negation)Dictionary</p><p specific-use="line">13.Perform classification using Modifier and Negation Classifier (<styled-content><xref ref-type="disp-formula" rid="pone.0171649.e008">Eq 2</xref></styled-content> and <styled-content><xref ref-type="disp-formula" rid="pone.0171649.e010">Eq 3</xref></styled-content>)</p><p specific-use="line">14. Perform classification using SentiWordNet Classifier (<styled-content><xref ref-type="disp-formula" rid="pone.0171649.e015">Eq 7</xref></styled-content>)</p><p specific-use="line">15. Perform classification using Domain Specific Classifier (<styled-content><xref ref-type="disp-formula" rid="pone.0171649.e020">Eq 11</xref></styled-content> and <styled-content><xref ref-type="disp-formula" rid="pone.0171649.e021">Eq 12</xref></styled-content>)</p><p specific-use="line">16. Perform sentiment classification at sentence level (<styled-content><xref ref-type="disp-formula" rid="pone.0171649.e022">Eq 13</xref></styled-content> and <styled-content><xref ref-type="disp-formula" rid="pone.0171649.e025">Eq 15</xref></styled-content>)</p><p specific-use="line">17. <bold>End While</bold></p><p specific-use="line">18. Perform SWNC-based classification at review-level using (<styled-content><xref ref-type="disp-formula" rid="pone.0171649.e023">Eq 14</xref></styled-content>)</p><p specific-use="line">19. Perform DSC-based classification at review-level using (<styled-content><xref ref-type="disp-formula" rid="pone.0171649.e026">Eq 16</xref></styled-content>)</p><p specific-use="line">20.</p><p specific-use="line">20. Write classification result to file</p><p specific-use="line"><bold>En</bold><bold>d</bold></p></boxed-text></sec></sec></sec><sec id="sec013"><title>Experiments</title><p>We used python and Natural Language Toolkit (NLTK) [<xref rid="pone.0171649.ref029" ref-type="bibr">29</xref>] to implement all of the algorithms presented in Section 3. As described in the data acquisition section, we used multiple datasets to conduct the experiments.</p><sec id="sec014" sec-type="conclusions"><title>Results and discussion</title><p>In this section, we present and analyze results obtained from the experiments to evaluate the effectiveness of the proposed method by using various evaluation metrics, namely (i) precision, (ii) recall, (iii) F-score, and (iv) accuracy to measure the performance of the proposed technique as follows:
<disp-formula id="pone.0171649.e029"><alternatives><graphic xlink:href="pone.0171649.e029.jpg" id="pone.0171649.e029g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M29"><mml:mi>P</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>i</mml:mi><mml:mi>s</mml:mi><mml:mi>i</mml:mi><mml:mi>o</mml:mi><mml:mi>n</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mi>p</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives><label>(17)</label></disp-formula>
<disp-formula id="pone.0171649.e030"><alternatives><graphic xlink:href="pone.0171649.e030.jpg" id="pone.0171649.e030g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M30"><mml:mi>R</mml:mi><mml:mi>e</mml:mi><mml:mi>c</mml:mi><mml:mi>a</mml:mi><mml:mi>l</mml:mi><mml:mi>l</mml:mi><mml:mspace width="0.25em"/><mml:mo>(</mml:mo><mml:mi>r</mml:mi><mml:mo>)</mml:mo><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mi>p</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mi>p</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives><label>(18)</label></disp-formula>
<disp-formula id="pone.0171649.e031"><alternatives><graphic xlink:href="pone.0171649.e031.jpg" id="pone.0171649.e031g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M31"><mml:mi>F</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>m</mml:mi><mml:mi>e</mml:mi><mml:mi>a</mml:mi><mml:mi>s</mml:mi><mml:mi>u</mml:mi><mml:mi>r</mml:mi><mml:mi>e</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mn>2</mml:mn><mml:mo>(</mml:mo><mml:mrow><mml:mi>p</mml:mi></mml:mrow><mml:mo>)</mml:mo><mml:mo>(</mml:mo><mml:mrow><mml:mi>r</mml:mi></mml:mrow><mml:mo>)</mml:mo></mml:mrow><mml:mrow><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>r</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives><label>(19)</label></disp-formula>
<disp-formula id="pone.0171649.e032"><alternatives><graphic xlink:href="pone.0171649.e032.jpg" id="pone.0171649.e032g" mimetype="image" position="anchor" orientation="portrait"/><mml:math id="M32"><mml:mi mathvariant="normal">A</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">u</mml:mi><mml:mi mathvariant="normal">r</mml:mi><mml:mi mathvariant="normal">a</mml:mi><mml:mi mathvariant="normal">c</mml:mi><mml:mi mathvariant="normal">y</mml:mi><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mi>n</mml:mi></mml:mrow><mml:mrow><mml:mi>t</mml:mi><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mi>p</mml:mi><mml:mo>+</mml:mo><mml:mi>t</mml:mi><mml:mi>n</mml:mi><mml:mo>+</mml:mo><mml:mi>f</mml:mi><mml:mi>n</mml:mi></mml:mrow></mml:mfrac></mml:math></alternatives><label>(20)</label></disp-formula>
where, <italic>tp</italic> is the number of true positive reviews correctly classified, <italic>fp</italic> is the number false positive negative reviews incorrectly classified as a positive, <italic>tn</italic> is the number of true negative reviews correctly classified, and <italic>fn</italic> is the number of false positive reviews incorrectly classified as a negative.</p><p>The First experiment was carried out to investigate the effect of noise reduction steps applied on the three datasets. <xref ref-type="table" rid="pone.0171649.t007">Table 7</xref> summarize the results obtained during noise reduction phase by depicting the total number of sentences, number words extracted as incorrect, number of words extracted as correct and the accuracy of the noise reduction steps. Therefore, the proposed noise reductions steps assist in resolving the data sparseness issue efficiently.</p><table-wrap id="pone.0171649.t007" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t007</object-id><label>Table 7</label><caption><title>Comparative results obtained for noise reduction phase.</title></caption><alternatives><graphic id="pone.0171649.t007g" xlink:href="pone.0171649.t007"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">Datasets</th><th align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">Sentences</th><th align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">Incorrect Words Extracted</th><th align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">Correct Words Extracted</th><th align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">Accuracy (%)</th></tr></thead><tbody><tr><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">Dataset1</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">8540</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">1431</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">1291</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">90.216</td></tr><tr><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">Dataset2</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">2000</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">524</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">462</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">88.167</td></tr><tr><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">Dataset3</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">2543</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">874</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">728</td><td align="center" style="background-color:#FFFFFF" rowspan="1" colspan="1">83.295</td></tr></tbody></table></alternatives></table-wrap><p>To determine the effect of emoticons in user&#x02019;s content, we further passed the text through emoticon classifier (EC) module. Our results (<xref ref-type="fig" rid="pone.0171649.g002">Fig 2</xref>) revealed that when we incorporated the emoticon handling features in the proposed setup then the accuracy has improved from 63% to 74%.</p><fig id="pone.0171649.g002" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.g002</object-id><label>Fig 2</label><caption><title>Accuracy results of EC module.</title></caption><graphic xlink:href="pone.0171649.g002"/></fig><p>As described in the section &#x0201c;Modifier and Negation Classifier (MNC)&#x0201d;, modifiers and negations play an important and decisive role in the sentiment classification of user reviews, as they change the polarity of opinion words. In order to evaluate the effectiveness of proposed MNC module, we conducted an experiment on 1951 reviews, split into 14321 sentences. <xref ref-type="fig" rid="pone.0171649.g003">Fig 3</xref> shows that the proposed MNC module yields promising results to classify the input text into +ive, -ive and neutral, effectively increasing the efficiency of sentiment classification of user&#x02019;s reviews.</p><fig id="pone.0171649.g003" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.g003</object-id><label>Fig 3</label><caption><title>Accuracy results of MNC module.</title></caption><graphic xlink:href="pone.0171649.g003"/></fig><p>Fourth experiment was conducted to determine effectiveness of proposed method for the sentiment classification of input text with respect to domain specific words. Due to the specialized nature of certain words, such as words in health-care domain, the sentiment score of such words is not accurately available in existing general-purpose lexicon (SWN). For example, the term &#x0201c;hospital&#x0201d; in SWN has neutral polarity, whereas it is manually annotated as &#x0201c;negative&#x0201d; by medical experts, as most of the times it reflects negative sentiment in our datasets, such as &#x0201c;<italic>I went to hospital due to severe stomach problem</italic>&#x0201d;. Therefore, the term &#x0201c;hospital&#x0201d; is tagged in the negative sentiment class. The comparative results show that when we apply DSC classifier on domain specific words then accuracy of sentiment classification is improved significantly. <xref ref-type="fig" rid="pone.0171649.g004">Fig 4</xref> shows that the proposed method significantly outperforms the non-DSC approach, effectively reducing the number reviews classified as neutral, which was one of challenging task in previous studies.</p><fig id="pone.0171649.g004" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.g004</object-id><label>Fig 4</label><caption><title>Accuracy results of DSC module.</title></caption><graphic xlink:href="pone.0171649.g004"/></fig><p>The final experiment investigates the efficiency of the proposed algorithm on 3 datasets with respect to classification of each review into +ive, -ive or neutral classes. The performance of each of the sub module(classifier) of the proposed framework is evaluated in terms of precision, recall and F-measure. The comparative results show that when all of the classifiers are applied in pipelined way then we achieve promising results. Tables <xref ref-type="table" rid="pone.0171649.t008">8</xref>, <xref ref-type="table" rid="pone.0171649.t009">9</xref> and <xref ref-type="table" rid="pone.0171649.t010">10</xref> show that the proposed method significantly outperforms the baseline methods.</p><table-wrap id="pone.0171649.t008" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t008</object-id><label>Table 8</label><caption><title>Experimental Results for Dataset1 (P: Precision, R: Recall, F: F-measure).</title></caption><alternatives><graphic id="pone.0171649.t008g" xlink:href="pone.0171649.t008"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" colspan="2" rowspan="1"/><th align="left" colspan="3" rowspan="1">Positive</th><th align="left" colspan="3" rowspan="1">Negative</th></tr><tr><th align="left" rowspan="1" colspan="1">Study</th><th align="left" rowspan="1" colspan="1">Technique</th><th align="left" rowspan="1" colspan="1">P</th><th align="left" rowspan="1" colspan="1">R</th><th align="left" rowspan="1" colspan="1">F</th><th align="left" rowspan="1" colspan="1">P</th><th align="left" rowspan="1" colspan="1">R</th><th align="left" rowspan="1" colspan="1">F</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Kalaivani and Shunmuganathan [<xref rid="pone.0171649.ref030" ref-type="bibr">30</xref>]</td><td align="left" rowspan="1" colspan="1">Supervised (opinion words)</td><td align="left" rowspan="1" colspan="1">0.80</td><td align="left" rowspan="1" colspan="1">0.76</td><td align="left" rowspan="1" colspan="1">0.69</td><td align="left" rowspan="1" colspan="1">0.74</td><td align="left" rowspan="1" colspan="1">0.64</td><td align="left" rowspan="1" colspan="1">0.51</td></tr><tr><td align="left" rowspan="1" colspan="1">Kundi et al. [<xref rid="pone.0171649.ref005" ref-type="bibr">5</xref>]</td><td align="left" rowspan="1" colspan="1">Lexicon-based unsupervised (opinion words and emoticons)</td><td align="left" rowspan="1" colspan="1">0.81</td><td align="left" rowspan="1" colspan="1">0.79</td><td align="left" rowspan="1" colspan="1">0.80</td><td align="left" rowspan="1" colspan="1">0.79</td><td align="left" rowspan="1" colspan="1">0.82</td><td align="left" rowspan="1" colspan="1">0.80</td></tr><tr><td align="left" rowspan="1" colspan="1">Kundi et al.[<xref rid="pone.0171649.ref003" ref-type="bibr">3</xref>]</td><td align="left" rowspan="1" colspan="1">Lexicon-based Unsupervised (opinion words and emoticons)</td><td align="left" rowspan="1" colspan="1">0.86</td><td align="left" rowspan="1" colspan="1">0.78</td><td align="left" rowspan="1" colspan="1">0.81</td><td align="left" rowspan="1" colspan="1">0.80</td><td align="left" rowspan="1" colspan="1">0.82</td><td align="left" rowspan="1" colspan="1">0.80</td></tr><tr><td align="left" rowspan="1" colspan="1">Proposed</td><td align="justify" rowspan="1" colspan="1">Lexicon-enhanced-Rule-based (<bold><italic>emoticons</italic>, <italic>opinion words</italic>, <italic>modifiers</italic>, <italic>negations</italic></bold>)</td><td align="left" rowspan="1" colspan="1"><bold>0.89</bold></td><td align="left" rowspan="1" colspan="1"><bold>0.81</bold></td><td align="left" rowspan="1" colspan="1">0.79</td><td align="left" rowspan="1" colspan="1">0.84</td><td align="left" rowspan="1" colspan="1">0.89</td><td align="left" rowspan="1" colspan="1">0.81</td></tr></tbody></table></alternatives></table-wrap><table-wrap id="pone.0171649.t009" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t009</object-id><label>Table 9</label><caption><title>Experimental Results for Dataset2 (P: Precision, R:Recall, F:F-measure).</title></caption><alternatives><graphic id="pone.0171649.t009g" xlink:href="pone.0171649.t009"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" colspan="2" rowspan="1"/><th align="left" colspan="3" rowspan="1">Positive</th><th align="left" colspan="3" rowspan="1">Negative</th></tr><tr><th align="left" rowspan="1" colspan="1">Study</th><th align="left" rowspan="1" colspan="1">Technique</th><th align="left" rowspan="1" colspan="1">P</th><th align="left" rowspan="1" colspan="1">R</th><th align="left" rowspan="1" colspan="1">F</th><th align="left" rowspan="1" colspan="1">P</th><th align="left" rowspan="1" colspan="1">R</th><th align="left" rowspan="1" colspan="1">F</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Kalaivani and Shunmuganathan [<xref rid="pone.0171649.ref030" ref-type="bibr">30</xref>]</td><td align="left" rowspan="1" colspan="1">Supervised (opinion words)</td><td align="left" rowspan="1" colspan="1">0.79</td><td align="left" rowspan="1" colspan="1">0.63</td><td align="left" rowspan="1" colspan="1">0.70</td><td align="left" rowspan="1" colspan="1">0.78</td><td align="left" rowspan="1" colspan="1">0.71</td><td align="left" rowspan="1" colspan="1">0.74</td></tr><tr><td align="left" rowspan="1" colspan="1">Kundi et al. [<xref rid="pone.0171649.ref005" ref-type="bibr">5</xref>]</td><td align="left" rowspan="1" colspan="1">Lexicon-based unsupervised (opinion words and emoticons)</td><td align="left" rowspan="1" colspan="1">0.74</td><td align="left" rowspan="1" colspan="1">0.51</td><td align="left" rowspan="1" colspan="1">0.60</td><td align="left" rowspan="1" colspan="1">0.73</td><td align="left" rowspan="1" colspan="1">0.63</td><td align="left" rowspan="1" colspan="1">0.67</td></tr><tr><td align="left" rowspan="1" colspan="1">Kundi et al.[<xref rid="pone.0171649.ref003" ref-type="bibr">3</xref>]</td><td align="left" rowspan="1" colspan="1">Lexicon-based Unsupervised (opinion words and emoticons)</td><td align="left" rowspan="1" colspan="1">0.82</td><td align="left" rowspan="1" colspan="1">0.78</td><td align="left" rowspan="1" colspan="1">0.79</td><td align="left" rowspan="1" colspan="1">0.75</td><td align="left" rowspan="1" colspan="1">0.73</td><td align="left" rowspan="1" colspan="1">0.73</td></tr><tr><td align="left" rowspan="1" colspan="1">Proposed</td><td align="justify" rowspan="1" colspan="1">Lexicon-enhanced-Rule-based (<bold><italic>emoticons</italic>, <italic>opinion words</italic>, <italic>modifiers</italic>, <italic>negations</italic></bold>)</td><td align="left" rowspan="1" colspan="1"><bold>0.83</bold></td><td align="left" rowspan="1" colspan="1"><bold>0.94</bold></td><td align="left" rowspan="1" colspan="1"><bold>0.85</bold></td><td align="left" rowspan="1" colspan="1">0.79</td><td align="left" rowspan="1" colspan="1">0.77</td><td align="left" rowspan="1" colspan="1">0.74</td></tr></tbody></table></alternatives></table-wrap><table-wrap id="pone.0171649.t010" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t010</object-id><label>Table 10</label><caption><title>Experimental Results for Dataset3 (P: Precision, R: Recall, F:F-measure).</title></caption><alternatives><graphic id="pone.0171649.t010g" xlink:href="pone.0171649.t010"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" colspan="2" rowspan="1"/><th align="left" colspan="3" rowspan="1">Positive</th><th align="left" colspan="3" rowspan="1">Negative</th></tr><tr><th align="left" rowspan="1" colspan="1">Study</th><th align="left" rowspan="1" colspan="1">Technique</th><th align="left" rowspan="1" colspan="1">P</th><th align="left" rowspan="1" colspan="1">R</th><th align="left" rowspan="1" colspan="1">F</th><th align="left" rowspan="1" colspan="1">P</th><th align="left" rowspan="1" colspan="1">R</th><th align="left" rowspan="1" colspan="1">F</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Kalaivani and Shunmuganathan [<xref rid="pone.0171649.ref030" ref-type="bibr">30</xref>]</td><td align="left" rowspan="1" colspan="1">Supervised (opinion words)</td><td align="left" rowspan="1" colspan="1">0.52</td><td align="left" rowspan="1" colspan="1">0.71</td><td align="left" rowspan="1" colspan="1">0.59</td><td align="left" rowspan="1" colspan="1">0.83</td><td align="left" rowspan="1" colspan="1">0.76</td><td align="left" rowspan="1" colspan="1">0.79</td></tr><tr><td align="left" rowspan="1" colspan="1">Kundi et al. [<xref rid="pone.0171649.ref005" ref-type="bibr">5</xref>]</td><td align="left" rowspan="1" colspan="1">Lexicon-based unsupervised (opinion words and emoticons)</td><td align="left" rowspan="1" colspan="1">0.74</td><td align="left" rowspan="1" colspan="1"><bold>0.95</bold></td><td align="left" rowspan="1" colspan="1">0.65</td><td align="left" rowspan="1" colspan="1">0.72</td><td align="left" rowspan="1" colspan="1"><bold>0.96</bold></td><td align="left" rowspan="1" colspan="1">0.82</td></tr><tr><td align="left" rowspan="1" colspan="1">Kundi et al.[<xref rid="pone.0171649.ref003" ref-type="bibr">3</xref>]</td><td align="left" rowspan="1" colspan="1">Lexicon-based Unsupervised (opinion words and emoticons)</td><td align="left" rowspan="1" colspan="1">0.71</td><td align="left" rowspan="1" colspan="1">0.85</td><td align="left" rowspan="1" colspan="1">0.77</td><td align="left" rowspan="1" colspan="1">0.77</td><td align="left" rowspan="1" colspan="1">0.77</td><td align="left" rowspan="1" colspan="1">0.77</td></tr><tr><td align="left" rowspan="1" colspan="1">Proposed</td><td align="justify" rowspan="1" colspan="1">Lexicon-enhanced-Rule-based (<bold><italic>emoticons</italic>, <italic>opinion words</italic>, <italic>modifiers</italic>, <italic>negations</italic></bold>)</td><td align="left" rowspan="1" colspan="1"><bold>0.81</bold></td><td align="left" rowspan="1" colspan="1">0.93</td><td align="left" rowspan="1" colspan="1"><bold>0.88</bold></td><td align="left" rowspan="1" colspan="1"><bold>0.84</bold></td><td align="left" rowspan="1" colspan="1">0.74</td><td align="left" rowspan="1" colspan="1"><bold>0.84</bold></td></tr></tbody></table></alternatives></table-wrap></sec><sec id="sec015"><title>Descriptive statistics on review data</title><p>In <xref ref-type="table" rid="pone.0171649.t011">Table 11</xref>, we present statistics based on the review data obtained from publically available datasets. We randomly sampled a set of 350, 373 and 412 reviews from drug, car and hotel domains. The three datasets are composed of approximately 3,500 sentences and 52,000 tokens. The average length of review is almost same in all of the three domains, while drug reviews (10.61 sentences/review) are slightly lengthy as compared to other two domains (9.56 and 10.21 sentences/review). Similarly, the average length of a sentence is same with 18.47, 18.58 and 18.38 tokens per sentence. The standard deviation of sentences in a review of drug dataset is low as compared to other two datasets. The smallest review in all datasets are comprised of single sentence and the smallest sentences composed of a single token only. The standard deviation of tokens in a sentence of car dataset is low as compared to other two datasets. The average number of stop words per sentence is between and 3 and 4. The average number of negations per sentence is between and 1 and 2, and the average number of modifiers per sentence is between and 2 and 3.</p><table-wrap id="pone.0171649.t011" orientation="portrait" position="float"><object-id pub-id-type="doi">10.1371/journal.pone.0171649.t011</object-id><label>Table 11</label><caption><title>Descriptive statistics of the proposed system on three datasets.</title></caption><alternatives><graphic id="pone.0171649.t011g" xlink:href="pone.0171649.t011"/><table frame="hsides" rules="groups"><colgroup span="1"><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/><col align="left" valign="middle" span="1"/></colgroup><thead><tr><th align="left" rowspan="1" colspan="1">Statistic</th><th align="left" rowspan="1" colspan="1">Drug</th><th align="left" rowspan="1" colspan="1">Car</th><th align="left" rowspan="1" colspan="1">Hotel</th></tr></thead><tbody><tr><td align="left" rowspan="1" colspan="1">Reviews</td><td align="left" rowspan="1" colspan="1">350</td><td align="left" rowspan="1" colspan="1">373</td><td align="left" rowspan="1" colspan="1">412</td></tr><tr><td align="left" rowspan="1" colspan="1">Sentences</td><td align="left" rowspan="1" colspan="1">3525</td><td align="left" rowspan="1" colspan="1">3553</td><td align="left" rowspan="1" colspan="1">3561</td></tr><tr><td align="left" rowspan="1" colspan="1">Average Length (sentence/review)</td><td align="left" rowspan="1" colspan="1">10.61</td><td align="left" rowspan="1" colspan="1">9.56</td><td align="left" rowspan="1" colspan="1">10.21</td></tr><tr><td align="left" rowspan="1" colspan="1">Std. Dev sentence/review</td><td align="left" rowspan="1" colspan="1">8.06</td><td align="left" rowspan="1" colspan="1">12.14</td><td align="left" rowspan="1" colspan="1">11.21</td></tr><tr><td align="left" rowspan="1" colspan="1">Min. sentence/review</td><td align="left" rowspan="1" colspan="1">1.00</td><td align="left" rowspan="1" colspan="1">1.00</td><td align="left" rowspan="1" colspan="1">1.00</td></tr><tr><td align="left" rowspan="1" colspan="1">Max. sentence/review</td><td align="left" rowspan="1" colspan="1">35.00</td><td align="left" rowspan="1" colspan="1">19.00</td><td align="left" rowspan="1" colspan="1">41.00</td></tr><tr><td align="left" rowspan="1" colspan="1">Total no. of tokens</td><td align="left" rowspan="1" colspan="1">52041</td><td align="left" rowspan="1" colspan="1">52231</td><td align="left" rowspan="1" colspan="1">52482</td></tr><tr><td align="left" rowspan="1" colspan="1">Average tokens (tokens/sentence)</td><td align="left" rowspan="1" colspan="1">18.47</td><td align="left" rowspan="1" colspan="1">18.58</td><td align="left" rowspan="1" colspan="1">18.38</td></tr><tr><td align="left" rowspan="1" colspan="1">std. Dev tokens/sentence</td><td align="left" rowspan="1" colspan="1">10.21</td><td align="left" rowspan="1" colspan="1">10.04</td><td align="left" rowspan="1" colspan="1">10.43</td></tr><tr><td align="left" rowspan="1" colspan="1">Min. tokens/sentence</td><td align="left" rowspan="1" colspan="1">1.00</td><td align="left" rowspan="1" colspan="1">1.00</td><td align="left" rowspan="1" colspan="1">1.00</td></tr><tr><td align="left" rowspan="1" colspan="1">Max. tokens/sentence</td><td align="left" rowspan="1" colspan="1">82.00</td><td align="left" rowspan="1" colspan="1">79.00</td><td align="left" rowspan="1" colspan="1">88.00</td></tr><tr><td align="left" rowspan="1" colspan="1">avg. stop words/sentence</td><td align="left" rowspan="1" colspan="1">4.00</td><td align="left" rowspan="1" colspan="1">3.00</td><td align="left" rowspan="1" colspan="1">4.00</td></tr><tr><td align="left" rowspan="1" colspan="1">avg. negations/sentence</td><td align="left" rowspan="1" colspan="1">2.00</td><td align="left" rowspan="1" colspan="1">1.00</td><td align="left" rowspan="1" colspan="1">1.00</td></tr><tr><td align="left" rowspan="1" colspan="1">avg. modifiers/sentence</td><td align="left" rowspan="1" colspan="1">2.00</td><td align="left" rowspan="1" colspan="1">2.00</td><td align="left" rowspan="1" colspan="1">3.00</td></tr></tbody></table></alternatives></table-wrap></sec></sec><sec id="sec016"><title>Conclusions and future work</title><p>This article presents the results of applying an improved method based on four way rule-based classification scheme to detect and classify sentiments expressed by users in online discussion forums. The proposed method is comprised of following modules: 1) Acquire set of reviews that mention user reviews about different products; 2) Apply noise reduction steps; 3) Use emoticon classifier to detect and score the emoticons expressed in reviews; 4) Perform classification and scoring of modifiers and negations using a set of positive and negative modifiers and negation list; 5) Apply sentiment classification of words using SentiWordNet-based classifier; 6) Detect the domain specific words and label them with correct sentiment class and score, and; 7) Perform sentiment classification of reviews at sentence and review level.</p><p>This approach provides an integrated rule-based framework for sentiment analysis with emphasis on emoticon classification, proper management of modifiers and negations, performs SWN-based sentiment classification, and improves the classification accuracy and enhances the performance of sentiment classification for domain specific words using domain specific classifier. We obtained classification results with improved accuracy, precision, recall and F-measure as compared to comparing methods. The proposed method is quite generalized and can classify the sentiments in cross domain.</p><p>A possible limitation of this method regarding its classification efficacy for domain specific words is the need for automatic classification and scoring of words. In order to reduce the amount of manpower required for manual scoring of domain specific words, the possibility of using auto-scoring techniques should be investigated. Another possible way of improving and extending the technique is by exploiting semantic and contextual features to classify the sentiments efficiently. Another interesting research direction would be to study the sentiments of online users in microblogging sites, such as Twitter, in streaming fashion.</p></sec><sec sec-type="supplementary-material" id="sec017"><title>Supporting information</title><supplementary-material content-type="local-data" id="pone.0171649.s001"><label>S1 File</label><caption><p>(RAR)</p></caption><media xlink:href="pone.0171649.s001.rar"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></sec></body><back><ref-list><title>References</title><ref id="pone.0171649.ref001"><label>1</label><mixed-citation publication-type="journal"><name><surname>Pang</surname><given-names>B</given-names></name> and <name><surname>Lillian</surname><given-names>L</given-names></name> (<year>2008</year>)<article-title>Opinion Mining and Sentiment Analysis</article-title>, <source>Foundations and trends in information retrieval</source>, <volume>2</volume>(<issue>1</issue>):<fpage>1</fpage>&#x02013;<lpage>13</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref002"><label>2</label><mixed-citation publication-type="journal"><name><surname>Neviarouskaya</surname><given-names>A</given-names></name> and <name><surname>Aono</surname><given-names>M</given-names></name> (<year>2013</year>) <article-title>Sentiment Word Relations with Affect, Judgment, and Appreciation</article-title>, <source>IEEE Transactions on Affective Computing</source>, <volume>4</volume>(<issue>4</issue>):<fpage>425</fpage>&#x02013;<lpage>438</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref003"><label>3</label><mixed-citation publication-type="journal"><name><surname>Kundi</surname><given-names>F</given-names></name>, <name><surname>Ahmad</surname><given-names>S</given-names></name>, <name><surname>Khan</surname><given-names>A</given-names></name>, <name><surname>Asghar</surname></name> (<year>2014</year>) <article-title>Detection and Scoring of Internet Slangs for Sentiment Analysis Using SentiWordNet</article-title>, <source>Life Science Journal</source>, <volume>11</volume>(<issue>9</issue>):<fpage>66</fpage>&#x02013;<lpage>72</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref004"><label>4</label><mixed-citation publication-type="journal"><name><surname>Liu</surname><given-names>C</given-names></name>, <name><surname>Hsaio</surname><given-names>W</given-names></name>, <name><surname>Lee</surname><given-names>C</given-names></name>, <name><surname>Lu</surname><given-names>G</given-names></name>, <name><surname>Jou</surname><given-names>E</given-names></name> (<year>2012</year>) <article-title>Movie rating and review summarization in mobile environment</article-title>, <source>IEEE Transactions on Systems, Man, and Cybernetics, Part C: Applications and Reviews</source>, <volume>42</volume>(<issue>3</issue>):<fpage>397</fpage>&#x02013;<lpage>407</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref005"><label>5</label><mixed-citation publication-type="journal"><name><surname>Kundi</surname><given-names>FM</given-names></name>, <name><surname>Khan</surname><given-names>A</given-names></name>, <name><surname>Ahmad</surname><given-names>S</given-names></name>, and <name><surname>Asghar</surname><given-names>MZ</given-names></name> (<year>2014</year>), <article-title>Lexicon-Based Sentiment Analysis in the Social Web</article-title>, <source>Journal of Basic and Applied Scientific</source>, <volume>4</volume>(<issue>6</issue>): <fpage>238</fpage>&#x02013;<lpage>248</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref006"><label>6</label><mixed-citation publication-type="journal"><name><surname>Ferrara</surname></name> and <name><surname>Yang</surname></name> (<year>2015</year>)<article-title>Quantifying the effect of sentiment on information diffusion in social media</article-title>. <source>PeerJ Comput. Sci</source>. <volume>1</volume>: <fpage>1</fpage>&#x02013;<lpage>10</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref007"><label>7</label><mixed-citation publication-type="other">Poria, S., Cambria, E., &#x00026; Gelbukh, A. F. (2015, September). Deep Convolutional Neural Network Textual Features and Multiple Kernel Learning for Utterance-level Multimodal Sentiment Analysis. In EMNLP (pp. 2539&#x02013;2544)</mixed-citation></ref><ref id="pone.0171649.ref008"><label>8</label><mixed-citation publication-type="other">Severyn, A., &#x00026; Moschitti, A. (2015, August). Twitter sentiment analysis with deep convolutional neural networks. In Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval (pp. 959&#x02013;962). ACM</mixed-citation></ref><ref id="pone.0171649.ref009"><label>9</label><mixed-citation publication-type="journal"><name><surname>Taboada</surname><given-names>M</given-names></name>, <name><surname>Brooke</surname><given-names>J</given-names></name>, <name><surname>Tofiloski</surname><given-names>M</given-names></name>, <name><surname>Voll</surname><given-names>K</given-names></name> and <name><surname>Stede</surname><given-names>M</given-names></name> (<year>2011</year>) <article-title>Lexicon-based methods for sentiment analysis</article-title>. <source>Computational linguistics</source>,<volume>37</volume>(<issue>2</issue>), pp.<fpage>267</fpage>&#x02013;<lpage>307</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref010"><label>10</label><mixed-citation publication-type="journal"><name><surname>Pensa</surname><given-names>R. G.</given-names></name>, <name><surname>Sapino</surname><given-names>M. L.</given-names></name>, <name><surname>Schifanella</surname><given-names>C.</given-names></name>, &#x00026; <name><surname>Vignaroli</surname><given-names>L.</given-names></name> (<year>2016</year>). <article-title>Leveraging Cross-Domain Social Media Analytics to Understand TV Topics Popularity</article-title>. <source>IEEE Computational Intelligence Magazine</source>, <volume>11</volume>(<issue>3</issue>), <fpage>10</fpage>&#x02013;<lpage>21</lpage></mixed-citation></ref><ref id="pone.0171649.ref011"><label>11</label><mixed-citation publication-type="journal"><name><surname>Cambria</surname><given-names>E</given-names></name> (<year>2016</year>) <article-title>Affective computing and sentiment analysis</article-title>, <source>IEEE Intelligent Systems</source>
<volume>31</volume>(<issue>2</issue>), pp. <fpage>102</fpage>&#x02013;<lpage>107</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref012"><label>12</label><mixed-citation publication-type="other">Aminu M, Nirmalie W and Robert L (2016), Contextual Sentiment Analysis for Social Media Genres, Knowledge-Based Systems,</mixed-citation></ref><ref id="pone.0171649.ref013"><label>13</label><mixed-citation publication-type="other">Boratto L., Carta, S, Fenu, G and Saia, R (2016), Using neural word embeddings to model user behavior and detect user segments, Knowledge- Based Systems (2016),</mixed-citation></ref><ref id="pone.0171649.ref014"><label>14</label><mixed-citation publication-type="journal"><name><surname>Kennedy</surname><given-names>A</given-names></name> and <name><surname>Inkpen</surname><given-names>D</given-names></name> (<year>2006</year>), <article-title>Sentiment classification of movie reviews using contextual valence shifters</article-title>. <source>Computational intelligence</source>, <volume>22</volume>(<issue>2</issue>), pp.<fpage>110</fpage>&#x02013;<lpage>125</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref015"><label>15</label><mixed-citation publication-type="journal"><name><surname>Gu</surname><given-names>B.</given-names></name>, <name><surname>Sheng</surname><given-names>V. S.</given-names></name>, <name><surname>Tay</surname><given-names>K. Y.</given-names></name>, <name><surname>Romano</surname><given-names>W.</given-names></name>, &#x00026; <name><surname>Li</surname><given-names>S.</given-names></name> (<year>2015</year>). <article-title>Incremental support vector learning for ordinal regression</article-title>. <source>IEEE Transactions on Neural networks and learning systems</source>, <volume>26</volume>(<issue>7</issue>), <fpage>1403</fpage>&#x02013;<lpage>1416</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1109/TNNLS.2014.2342533">10.1109/TNNLS.2014.2342533</ext-link></comment>
<pub-id pub-id-type="pmid">25134094</pub-id></mixed-citation></ref><ref id="pone.0171649.ref016"><label>16</label><mixed-citation publication-type="other">Gu, B., Sheng, V. S., &#x00026; Li, S. (2015, July). Bi-Parameter Space Partition for Cost-Sensitive SVM. In IJCAI (pp. 3532&#x02013;3539).</mixed-citation></ref><ref id="pone.0171649.ref017"><label>17</label><mixed-citation publication-type="journal"><name><surname>Zou</surname><given-names>Q.</given-names></name>, <name><surname>Wan</surname><given-names>S.</given-names></name>, <name><surname>Ju</surname><given-names>Y.</given-names></name>, <name><surname>Tang</surname><given-names>J.</given-names></name>, &#x00026; <name><surname>Zeng</surname><given-names>X.</given-names></name> (<year>2016</year>). <article-title>Pretata: predicting TATA binding proteins with novel features and dimensionality reduction strategy</article-title>. <source>BMC Systems Biology</source>, <volume>10</volume>(<issue>4</issue>), <fpage>401</fpage>.</mixed-citation></ref><ref id="pone.0171649.ref018"><label>18</label><mixed-citation publication-type="other">Asghar MZ, (2015) Opinion Extraction From Online Blogs And Public Reviews, PhD thesis, Gomal University, D.I. Khan, Higher Education Commission (HEC) of Pakistan, <ext-link ext-link-type="uri" xlink:href="http://prr.hec.gov.pk/Thesis/2319S.pdf">http://prr.hec.gov.pk/Thesis/2319S.pdf</ext-link>.</mixed-citation></ref><ref id="pone.0171649.ref019"><label>19</label><mixed-citation publication-type="journal"><name><surname>Khan</surname><given-names>F</given-names></name>. H., Bashir S, and Qamar U (<year>2014</year>). <article-title>TOM: Twitter opinion mining framework using hybrid classification scheme</article-title>, <source>Decision Support Systems</source>, <volume>57</volume>, <fpage>245</fpage>&#x02013;<lpage>257</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref020"><label>20</label><mixed-citation publication-type="journal"><name><surname>Khan</surname><given-names>A</given-names></name>, <name><surname>Baharudin</surname><given-names>B</given-names></name>, and <name><surname>Khan</surname><given-names>K</given-names></name> (<year>2011</year>), <article-title>Sentiment classification using sentence-level lexical based semantic orientation of online reviews</article-title>, <source>Trends in Applied Sciences Research</source>, <volume>6</volume>(<issue>10</issue>) <fpage>1141</fpage>&#x02013;<lpage>1157</lpage>.</mixed-citation></ref><ref id="pone.0171649.ref021"><label>21</label><mixed-citation publication-type="journal"><name><surname>Zhao</surname><given-names>J</given-names></name>, <name><surname>Liu</surname><given-names>K</given-names></name>. and <name><surname>Xu</surname><given-names>L</given-names></name>. (<year>2016</year>) <article-title>Sentiment Analysis: Mining Opinions, Sentiments, and Emotions Bing Liu (University of Illinois at Chicago) Cambridge University Press, 2015 ISBN 9781107017894</article-title>. <source>Computational Linguistics</source>.</mixed-citation></ref><ref id="pone.0171649.ref022"><label>22</label><mixed-citation publication-type="other">Y Choi and C Cardie (2009) Adapting a polarity lexicon using integer linear programming for domain specific sentiment classification, In the Proceedings of the Conference on Empirical Methods in Natural Language Processing, ACL and AFNLP,590&#x02013;598.</mixed-citation></ref><ref id="pone.0171649.ref023"><label>23</label><mixed-citation publication-type="book"><name><surname>Asghar</surname><given-names>MZ</given-names></name>, <name><surname>Ahmad</surname><given-names>S</given-names></name>, <name><surname>Qasim</surname><given-names>M</given-names></name>, <name><surname>Zahra</surname><given-names>SR</given-names></name>, <name><surname>Kundi</surname><given-names>FM</given-names></name> (<year>2016</year>) <source>SentiHealth: Creating health-related sentiment lexicon using hybrid approach</source>, <publisher-name>SpringerPlus</publisher-name>,</mixed-citation></ref><ref id="pone.0171649.ref024"><label>24</label><mixed-citation publication-type="other">Baccianella S, Esuli A, Sebastiani F (2015) SENTIWORDNET 3.0: an enhanced lexical resource for sentiment analysis and opinion Mining, <ext-link ext-link-type="uri" xlink:href="http://nmis.isti.cnr.it/sebastiani/Publications/LREC10.pdf">http://nmis.isti.cnr.it/sebastiani/Publications/LREC10.pdf</ext-link>, 10:2200&#x02013;2204.</mixed-citation></ref><ref id="pone.0171649.ref025"><label>25</label><mixed-citation publication-type="journal"><name><surname>Wang</surname><given-names>Y.</given-names></name>, <name><surname>Wu</surname><given-names>S.</given-names></name>, <name><surname>Li</surname><given-names>D.</given-names></name>, <name><surname>Mehrabi</surname><given-names>S.</given-names></name> and <name><surname>Liu</surname><given-names>H.</given-names></name>, (<year>2016</year>). <article-title>A Part-Of-Speech term weighting scheme for biomedical information retrieval</article-title>. <source>Journal of Biomedical Informatics</source>, <volume>63</volume>, pp.<fpage>379</fpage>&#x02013;<lpage>389</lpage>. <comment>doi: <ext-link ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.jbi.2016.08.026">10.1016/j.jbi.2016.08.026</ext-link></comment>
<pub-id pub-id-type="pmid">27593166</pub-id></mixed-citation></ref><ref id="pone.0171649.ref026"><label>26</label><mixed-citation publication-type="journal"><name><surname>Asghar</surname><given-names>MZ</given-names></name>, <name><surname>Khan</surname><given-names>A</given-names></name>, <name><surname>Ahmad</surname><given-names>S</given-names></name>, <name><surname>Khan</surname><given-names>I</given-names></name>, <name><surname>Kundi</surname><given-names>FM</given-names></name> (<year>2015</year>) <article-title>A Unified Framework for Creating Domain Dependent Polarity Lexicons from User Generated Reviews</article-title>, <source>PLOS ONE</source><volume>10</volume>(<issue>10</issue>):<fpage>1</fpage>&#x02013;<lpage>19</lpage>: e0140204.</mixed-citation></ref><ref id="pone.0171649.ref027"><label>27</label><mixed-citation publication-type="other">Li S, Lee S, Chen Y, Huang, CR, and Zhou, G(2010) Sentiment classification and polarity shifting, In the Proceedings of the 23rd International Conference on Computational Linguistics, COLING &#x02019;10,Stroudsburg, PA, USA: Association for Computational Linguistics, 635&#x02013;643, <ext-link ext-link-type="uri" xlink:href="http://dl.acm.org/citation.cfm?id=1873781.1873853">http://dl.acm.org/citation.cfm?id=1873781.1873853</ext-link>.</mixed-citation></ref><ref id="pone.0171649.ref028"><label>28</label><mixed-citation publication-type="other">Ikeda D, Takamura H, Ratinov L, and Okumura M (2008), Learning to shift the polarity of words for sentiment classification, In the Proceedings of the Third International Joint Conference on Natural Language Processing (IJCNLP), 296&#x02013;303.</mixed-citation></ref><ref id="pone.0171649.ref029"><label>29</label><mixed-citation publication-type="book"><name><surname>Bird</surname><given-names>S</given-names></name>, <name><surname>Klein</surname><given-names>E</given-names></name>, <name><surname>Loper</surname><given-names>E</given-names></name> (<year>2009</year>) <source>Natural language processing with Python</source>, <publisher-name>O&#x02019;Reilly Media, Inc</publisher-name>.</mixed-citation></ref><ref id="pone.0171649.ref030"><label>30</label><mixed-citation publication-type="journal"><name><surname>Kalaivani</surname><given-names>P</given-names></name> and <name><surname>Shunmuganathan</surname><given-names>KL</given-names></name> (<year>2013</year>) <article-title>Sentiment classification of movie reviews by supervised machine learning approaches</article-title>. <source>Indian Journal of Computer Science and Engineering</source>, <volume>4</volume>(<issue>4</issue>), pp.<fpage>285</fpage>&#x02013;<lpage>292</lpage>.</mixed-citation></ref></ref-list></back></article>