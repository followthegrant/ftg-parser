<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Nat Commun</journal-id><journal-id journal-id-type="iso-abbrev">Nat Commun</journal-id><journal-title-group><journal-title>Nature Communications</journal-title></journal-title-group><issn pub-type="epub">2041-1723</issn><publisher><publisher-name>Nature Publishing Group</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">26988654</article-id><article-id pub-id-type="pmc">4802033</article-id><article-id pub-id-type="pii">ncomms10904</article-id><article-id pub-id-type="doi">10.1038/ncomms10904</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Cross-modal representations of first-hand and vicarious pain, disgust and fairness in insular and cingulate cortex</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Corradi-Dell'Acqua</surname><given-names>Corrado</given-names></name><xref ref-type="corresp" rid="c2">b</xref><xref ref-type="aff" rid="a1">1</xref><xref ref-type="aff" rid="a2">2</xref><xref ref-type="aff" rid="a3">3</xref><xref ref-type="author-notes" rid="n1">*</xref></contrib><contrib contrib-type="author"><name><surname>Tusche</surname><given-names>Anita</given-names></name><xref ref-type="corresp" rid="c1">a</xref><xref ref-type="aff" rid="a4">4</xref><xref ref-type="aff" rid="a5">5</xref><xref ref-type="author-notes" rid="n1">*</xref></contrib><contrib contrib-type="author"><name><surname>Vuilleumier</surname><given-names>Patrik</given-names></name><xref ref-type="aff" rid="a1">1</xref><xref ref-type="aff" rid="a2">2</xref></contrib><contrib contrib-type="author"><name><surname>Singer</surname><given-names>Tania</given-names></name><xref ref-type="aff" rid="a4">4</xref></contrib><aff id="a1"><label>1</label><institution>Swiss Centre for Affective Sciences, University of Geneva</institution>, Geneva CH-1211, <country>Switzerland</country></aff><aff id="a2"><label>2</label><institution>Laboratory for Neurology and Imaging of Cognition, Department of Neurosciences and Clinic of Neurology, University Medical Center</institution>, Geneva CH-1211, <country>Switzerland</country></aff><aff id="a3"><label>3</label><institution>Department of Psychology, FPSE, University of Geneva</institution>, Campus Biotech, 9, Chemin des Mines, Geneva CH-1211, <country>Switzerland</country></aff><aff id="a4"><label>4</label><institution>Max Planck Institute for Human Cognitive and Brain Sciences, Department of Social Neuroscience</institution>, Leipzig DE-04103, <country>Germany</country></aff><aff id="a5"><label>5</label><institution>Caltech Emotion and Social Cognition Laboratory, Division of the Humanities and Social Sciences, California Institute of Technology</institution>, Los Angeles, California 91125, <country>USA</country></aff></contrib-group><author-notes><corresp id="c1"><label>a</label><email>anita.tusche@gmail.com</email></corresp><corresp id="c2"><label>b</label><email>Corrado.Corradi@unige.ch</email></corresp><fn id="n1"><label>*</label><p>These authors contributed equally to this work.</p></fn></author-notes><pub-date pub-type="epub"><day>18</day><month>03</month><year>2016</year></pub-date><pub-date pub-type="collection"><year>2016</year></pub-date><volume>7</volume><elocation-id>10904</elocation-id><history><date date-type="received"><day>18</day><month>08</month><year>2015</year></date><date date-type="accepted"><day>01</day><month>02</month><year>2016</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2016, Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.</copyright-statement><copyright-year>2016</copyright-year><copyright-holder>Nature Publishing Group, a division of Macmillan Publishers Limited. All Rights Reserved.</copyright-holder><license xmlns:xlink="http://www.w3.org/1999/xlink" license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><!--author-paid--><license-p>This work is licensed under a Creative Commons Attribution 4.0 International License. The images or other third party material in this article are included in the article's Creative Commons license, unless indicated otherwise in the credit line; if the material is not included under the Creative Commons license, users will need to obtain permission from the license holder to reproduce the material. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license></permissions><abstract><p>The anterior insula (AI) and mid-anterior cingulate cortex (mACC) have repeatedly been implicated in first-hand and vicarious experiences of pain, disgust and unfairness. However, it is debated whether these regions process different aversive events through a common modality-independent code, reflecting the shared unpleasantness of the experiences or through independent modality-specific representations. Using functional magnetic resonance imaging, we subjected 19 participants (and 19 confederates) to equally unpleasant painful and disgusting stimulations, as well as unfair monetary treatments. Multivoxel pattern analysis identified modality-independent activation maps in the left AI and mACC, pointing to common coding of affective unpleasantness, but also response patterns specific for the events' sensory properties and the person to whom it was addressed, particularly in the right AI. Our results provide evidence of both functional specialization and integration within AI and mACC, and support a comprehensive role of this network in processing aversive experiences for self and others.</p></abstract><abstract abstract-type="web-summary"><p>
<inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="i1" xlink:href="ncomms10904-i1.jpg"/>Anterior insula (AI) and medial anterior cingulate cortex (mACC) are activated by self and vicarious pain, disgust and fairness, yet the overlap of these representations are not known. Here the authors provide evidence for shared neural codes in the left AI and mACC and distinct codes in the right AI.</p></abstract></article-meta></front><body><p>In the last decade, neuroscience research made considerable efforts to elucidate the neuronal processes underlying our ability to understand the mind of others<xref ref-type="bibr" rid="b1">1</xref><xref ref-type="bibr" rid="b2">2</xref><xref ref-type="bibr" rid="b3">3</xref>. Studies on the neural bases of empathy revealed that witnessing others' emotional states such as pain or disgust recruits a network comprising the anterior insula (AI) and mid-anterior cingulate cortex (mACC)<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b6">6</xref><xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b9">9</xref><xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b11">11</xref>, both of which are also implicated in our first-person experience of the same aversive feelings<xref ref-type="bibr" rid="b12">12</xref><xref ref-type="bibr" rid="b13">13</xref><xref ref-type="bibr" rid="b14">14</xref><xref ref-type="bibr" rid="b15">15</xref>. Furthermore, witnessing transgressions of social norms (unfair transactions<xref ref-type="bibr" rid="b16">16</xref> or unmoral acts<xref ref-type="bibr" rid="b17">17</xref>) has also been associated with activity in AI and mACC. These results represent an important cornerstone for embodied approaches of social cognition, according to which basal sensorimotor experiences, and their associated neural underpinnings, are instrumental in the processing of social events<xref ref-type="bibr" rid="b18">18</xref><xref ref-type="bibr" rid="b19">19</xref><xref ref-type="bibr" rid="b20">20</xref>.</p><p>It has been frequently proposed that neural signals in AI/mACC might not code for specific experiences (pain, disgust, unfairness, and so on), but instead mediate a broader function across different domains<xref ref-type="bibr" rid="b9">9</xref><xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b21">21</xref>. Unlike for the posterior and middle insula, that receive primary gustatory<xref ref-type="bibr" rid="b22">22</xref><xref ref-type="bibr" rid="b23">23</xref> and nociceptive<xref ref-type="bibr" rid="b24">24</xref><xref ref-type="bibr" rid="b25">25</xref><xref ref-type="bibr" rid="b26">26</xref> inputs from thalamic nuclei, the nature of the information coded by AI/mACC is still unclear. The sensitivity of these areas to different sensory and affective events<xref ref-type="bibr" rid="b9">9</xref><xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b21">21</xref> might be interpreted in terms of a common neural coding of features such as unpleasantness, arousal or even the salience of the experience<xref ref-type="bibr" rid="b27">27</xref><xref ref-type="bibr" rid="b28">28</xref>. In particular, it has been suggested that pain-evoked activity in AI/mACC reflects a combination of neural processes similarly engaged by non-nociceptive events, arguing against the presence of any pain-specific<xref ref-type="bibr" rid="b29">29</xref> (and possibly also disgust-specific) signal.</p><p>However, empirical evidence on the functional properties of AI/mACC has mainly been obtained by neuroimaging techniques such as functional magnetic resonance imaging (fMRI), whose spatial resolution does not allow recording from isolated neurons, but provides pooled signal from a large volume of grey matter. It is therefore possible that AI and mACC hold independent (but intermingled) neuronal populations that encode aversive states in a modality-specific (pain, disgust, unfairness) or even target-specific (self, other) manner.</p><p>In the present study, we investigated whether the neural processes subserved by AI/mACC are best described in terms of modality-specific representations of pain, disgust or unfairness, or rather in terms of modality-independent features shared by these different experiences, such as unpleasantness. To this end, we used multivoxel pattern analysis (MVPA) which allows for more detailed investigation of fMRI activation maps<xref ref-type="bibr" rid="b30">30</xref><xref ref-type="bibr" rid="b31">31</xref><xref ref-type="bibr" rid="b32">32</xref>. MVPA exploits the variability of neural signal over a cortical area that reflects the idiosyncratic distribution of a given neuronal population across neighbouring voxels. Thus, the identification of shared or independent activity patterns represents a more stringent assessment of whether two conditions recruit the same or different neuronal processes<xref ref-type="bibr" rid="b30">30</xref><xref ref-type="bibr" rid="b31">31</xref><xref ref-type="bibr" rid="b32">32</xref><xref ref-type="bibr" rid="b33">33</xref>. Using MVPA, we compared activity patterns from 19 female<xref ref-type="bibr" rid="b7">7</xref> volunteers when they were subjected to either electrical (painful (Ps)/non-painful (nPs)) or gustatory stimuli (disgusting (Ds)/non-disguting (nDs)), which were carefully matched for subjective unpleasantness<xref ref-type="bibr" rid="b34">34</xref> (self-related trials). In separate (other-related) trials, they saw a befriended confederate receiving equivalent electrical (Po/nPo) or gustatory (Do/nDo) stimuli<xref ref-type="bibr" rid="b5">5</xref>. Finally, participants also performed an Ultimatum Game (UG) task, in which they faced unknown people who proposed unfair or moderately fair economic transactions, either to the participants themselves (Us/Ms) or to the confederate (Uo/Mo)<xref ref-type="bibr" rid="b16">16</xref><xref ref-type="bibr" rid="b35">35</xref><xref ref-type="bibr" rid="b36">36</xref><xref ref-type="bibr" rid="b37">37</xref><xref ref-type="bibr" rid="b38">38</xref><xref ref-type="bibr" rid="b39">39</xref>.</p><p>First, we tested whether activity patterns evoked in AI/mACC by first-person painful experiences were similar to (or dissociated from) those evoked by first-person disgust, as a neural signature of modality-specific or modality-independent coding. Second, we assessed whether response patterns elicited by first-person experiences were shared with those elicited by vicarious pain/disgust, as well as unfairness. Third, and most importantly, we explored the nature of shared information for vicarious responses. If AI/mACC process others' affective states in terms of modality-specific features (&#x02018;it hurts when I see you in pain', &#x02018;it is bitter when I see you disgusted'), then activity patterns evoked by a first-person event should generalize to vicarious experience of the same, but not different, modality. Alternatively, if AI/mACC process others' affective states in terms of modality-independent features (&#x02018;it is unpleasant when I see you in pain/disgusted'), then activity evoked by a first-person event should generalize to vicarious experiences of another modality. Finally, MVPA across different tasks could also shed light on the nature of the neural coding of unfairness in AI/mACC: if the role of these regions in unfairness reflects the engagement of disgust-specific neural responses (&#x02018;unfairness is disgusting'), as previously assumed<xref ref-type="bibr" rid="b16">16</xref>, then the activity patterns elicited during the UG should generalize to first-person disgust, but not pain. Alternatively, if AI/mACC code unfairness in terms of modality-independent features (&#x02018;unfairness is unpleasant'), then we expect shared information with both first-person pain and disgust.</p><p>Our results provide first evidence of both shared and independent coding in AI/mACC. In particular, we found that left AI and mACC disclose activity patterns which are shared between different modalities (pain, disgust and unfairness) but also between first-hand and vicarious aversive experiences, pointing to common coding of affective unpleasantness. Instead, right AI discloses activity patterns which are specific for the events' sensory properties and the target of the experience.</p><sec disp-level="1"><title>Results</title><sec disp-level="2"><title>Behavioural data</title><p>Prior to scanning, electrical and gustatory stimuli were calibrated on an individual basis to ensure their painful or disgusting nature (see Methods). During the scanning session, participants rated the subjective unpleasantness associated with each stimulus event (see <xref ref-type="fig" rid="f1">Fig. 1</xref>). The analysis of median unpleasantness ratings revealed that, for both the pain and disgust tasks, and for each target of the stimulation (self, other), aversive events were significantly more unpleasant than the corresponding neutral controls (paired <italic>t</italic>-tests on <italic>N</italic>=19, all <italic>t</italic><sub>(18)</sub>s&#x02265;12.89 and <italic>P</italic>&#x0003c;0.001; see <xref ref-type="fig" rid="f1">Fig. 1a,b</xref>). Furthermore, for both pain and disgust, the unpleasantness of aversive and neutral events was comparable across targets (paired <italic>t</italic>-tests all |<italic>t</italic><sub>(18)</sub>s|&#x02264;1.92, not significant (NS), <italic>N</italic>=19). No modality-specific differences were found between pain and disgust, for each target and for each unpleasantness level (paired <italic>t</italic>-tests all |<italic>t</italic><sub>(18)</sub>s|&#x02264;1.21, NS, <italic>N</italic>=19).</p><p>As the UG comprised a wide range of offers (most unfair, moderately fair, extremely fair), we used the unpleasantness ratings acquired during the scanning session to identify, on an individual basis, a sub-portion of UG trials that were most comparable with the pain and disgust tasks. Thus, for each participant, and for each target of the offer, we identified as &#x02018;aversive' those UG trials that were rated as the most unpleasant, whereas the remaining trials whose unpleasantness was closest to 0 were identified as &#x02018;neutral' (see <xref ref-type="fig" rid="f1">Fig. 1c</xref>). <xref ref-type="supplementary-material" rid="S1">Supplementary Figure 1</xref> reports all details about the selected trials, with the most aversive being most frequently associated with unfair offers and neutral controls being associated with moderately fair (midfair) offers. As for pain and disgust, unpleasantness was matched across targets, both for unfair and midfair offers (paired <italic>t</italic>-tests all |<italic>t</italic><sub>(18)</sub>s|&#x02264;1.46, NS, <italic>N</italic>=19). However, aversive and neutral events in the UG task were rated as slightly more positive than corresponding conditions in the pain and disgust tasks (paired <italic>t</italic>-tests all <italic>t</italic><sub>(18)</sub>s&#x02265;2.35, <italic>P</italic>&#x0003c;0.05, <italic>N</italic>=19).</p></sec><sec disp-level="2"><title>Neural responses in AI and mACC</title><p>As first step, we focused on response patterns in AI and mACC, because these regions have repeatedly been implicated in both first-person and vicarious pain<xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b12">12</xref><xref ref-type="bibr" rid="b13">13</xref>, disgust<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b6">6</xref><xref ref-type="bibr" rid="b14">14</xref><xref ref-type="bibr" rid="b15">15</xref> and unfair UG offers<xref ref-type="bibr" rid="b16">16</xref><xref ref-type="bibr" rid="b36">36</xref><xref ref-type="bibr" rid="b37">37</xref><xref ref-type="bibr" rid="b38">38</xref><xref ref-type="bibr" rid="b39">39</xref>. Furthermore, these regions are part of an intrinsically connected circuit (called saliency network) that appears conserved even during rest<xref ref-type="bibr" rid="b28">28</xref>. We therefore took advantage of an independent resting-state session to localize this network in each subject and to obtain reliable regions-of-interest (ROIs) of AI and mACC without any bias related to tasks or stimuli. These ROIs provide subject-specific AI coordinates which are consistently connected with mACC and <italic>vice versa</italic>. See <xref ref-type="fig" rid="f2">Fig. 2a</xref> for an illustration of the AI&#x02013;mACC network at the group level, and Methods section for details.</p><p>As manipulation check, we investigated whether activation patterns in each ROI discriminated between aversive and non-aversive states (pain, disgust, unfairness), which could occur to participants themselves or the befriended confederate (within-task classification). A linear kernel support vector machine (SVM) classifier<xref ref-type="bibr" rid="b40">40</xref> was trained on data from the respective task and condition, and then tested using cross-validation approaches. This led, for each participant, to a <italic>d&#x02032;</italic> parameter that quantified the ability of the classifier to detect an aversive state as opposed to its neutral control (for example, Ps versus nPs). The significance of the <italic>d&#x02032;</italic> values at the group level was estimated through rigorous permutation techniques (see Methods). In line with earlier studies using each task separately, we confirmed that the bilateral AI and mACC reliably encoded aversive states in all three modalities and both target-conditions. Repeated measure analysis of variances (ANOVAs) revealed no significant differences across ROIs in their sensitivity to self-/other-related pain and disgust. Regions differed, however, in their sensitivity to unfairness, reflecting greater sensitivity of mACC with respect to AI (see <xref ref-type="table" rid="t1">Table 1</xref>).</p><p>Subsequently, we ran a cross-modal pattern analyses to assess whether a classifier trained to detect one specific aversive event (for example, Ps versus nPs) could also detect aversiveness from an independent condition (for example, Ds versus nDs) and <italic>vice versa</italic> (see <xref ref-type="fig" rid="f2">Fig. 2b</xref> for illustration). Reliable evidence for shared activity patterns between first-hand pain and disgust (Ps versus nPs&#x02194;Ds versus nDs; hereafter Ps&#x02194;Ds) was found in the left AI and mACC (<italic>d&#x02032;</italic>s&#x02265;0.30; permutation-based test corrected for multiple comparisons for the 3 ROIs: cutoff=0.18, <italic>P</italic>&#x0003c;0.01, <italic>N</italic>=19, see <xref ref-type="fig" rid="f3">Fig. 3a</xref> and <xref ref-type="table" rid="t2">Table 2</xref>). In contrast, no cross-modal effects were observed in the right AI (<italic>d&#x02032;</italic>=0.02, NS), although this region reliably encoded both pain and disgust in the within-task classifications. Indeed, <italic>d&#x02032;s</italic> in the right AI obtained for within-task classifications of both first-hand pain and disgust were significantly larger than those obtained for the cross-modal effect (Ps&#x0003e;PS&#x02194;Ds and Ds&#x0003e;Ps&#x02194;Ds; d&#x02032; differences (diff-<italic>d&#x02032;</italic>s)&#x02265;0.33, permutation tests on <italic>d&#x02032;</italic> differences: cutoffs&#x02264;0.29, <italic>P</italic>&#x0003c;0.05, <italic>N</italic>=19), thus suggesting the presence of modality-independent (but overlapping) activity patterns for pain and disgust. Results of a repeated measure ANOVA confirmed differences in cross-modal effect between first-hand pain and disgust across ROIs (permutation-based ANOVA: F=6.77, cutoff=3.40, <italic>P</italic>&#x0003c;0.01, <italic>N</italic>=19), reflecting lower <italic>d&#x02032;</italic>s in right AI relative to both left AI and mACC (|diff-<italic>d&#x02032;</italic>s|&#x02265;0.28, permutation tests on <italic>d&#x02032;</italic> differences: |cutoffs|&#x02264;0.25, <italic>P</italic>&#x0003c;0.05, <italic>N</italic>=19). Overall, our data hint that the neural signal in left AI and mACC may be partly shared between pain and disgust, whereas the signal in right AI may instead reflect modality-specific coding.</p><p>Having established that AI/mACC disclose both modality-specific and modality-independent activity patterns for first-hand pain and disgust, we tested whether these neural responses were re-activated when the same experiences occurred to the confederate. This was achieved by assessing whether a classifier trained at detecting first-person pain (or disgust) could successfully detect others' pain (or disgust) and <italic>vice versa</italic> (cross-target classification: Ps&#x02194;Po, Ds&#x02194;Do). For left AI and mACC, significant effects were found for both pain and disgust (<italic>d&#x02032;</italic>s&#x02265;0.21, permutation tests: cutoffs&#x02265;0.20, <italic>P</italic>&#x0003c;0.05 corrected for the 3 ROIs; except for Ds&#x02194;Do in left AI: <italic>d&#x02032;</italic>=0.19, significant under an uncorrected cutoff=0.15, <italic>P</italic>&#x0003c;0.05, <italic>N</italic>=19). Critically, evidence in left AI and mACC for shared activity between first-hand and vicarious aversive experiences extended to stimuli of different modalities: that is, between first-person pain and vicarious disgust or first-person disgust and vicarious pain (Ds&#x02194;Po, Ps&#x02194;Do: <italic>d&#x02032;</italic>s&#x02265;0.30, permutation tests: cutoffs&#x02264;0.20, <italic>P</italic>&#x0003c;0.01 corrected; except for Ds&#x02194;Po in left AI: <italic>d&#x02032;</italic>=0.18, uncorrected cutoff=0.15, <italic>P</italic>&#x0003c;0.05, <italic>N</italic>=19). These findings reveal that vicarious pain and disgust elicit neural responses in left AI and mACC that are partly shared with those associated with first-hand experiences, regardless of whether the experience is of the same or different modality (see <xref ref-type="fig" rid="f3">Fig. 3b</xref>).</p><p>Interestingly, we found no conclusive evidence of shared activity between first-hand and vicarious pain and disgust in right AI (<italic>d&#x02032;s</italic>&#x02264;0.12 permutation tests: cutoffs&#x02265;0.19, NS; but for Ds&#x02194;Po: <italic>d&#x02032;</italic>=0.26, <italic>P</italic>&#x0003c;0.05, <italic>N</italic>=19). However, the right AI disclosed reliable detection of pain and disgust in the within-task classification for both self and other (see <xref ref-type="fig" rid="f3">Fig. 3a,b</xref>). Indeed, <italic>d&#x02032;</italic>s obtained in right AI for the within-task classification of others' pain and disgust were greater than for the cross-target classifications between first-hand and vicarious experiences, both when the modality was the same (diff-<italic>d&#x02032;</italic>=0.33, permutation test of <italic>d&#x02032;</italic> differences: cutoff=0.25, <italic>P</italic>&#x0003c;0.01 corrected, <italic>N</italic>=19) or different (diff-<italic>d&#x02032;</italic>=0.26, cutoff=0.25, <italic>P</italic>&#x0003c;0.05 corrected, <italic>N</italic>=19; see <xref ref-type="fig" rid="f3">Fig. 3b</xref>). Taken together, these findings suggest a dissociation in neural responses between first-person and vicarious sensations for both pain and disgust in right AI.</p><p>Finally, we investigated whether a classifier trained to detect unfair (as opposed to marginally fair) UG offers could also detect first-person experiences of pain/disgust and <italic>vice versa</italic> (Ps&#x02194;Us, Ds&#x02194;Us, Ps&#x02194;Uo, Ds&#x02194;Uo). See <xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 2</xref> for exhaustive representation of the results, which were comparable regardless of the target of the unfairness. For readability purposes, here we report effects identified when combining together self- and other-related UG trials, which indicated significant cross-modal effects of UG responses for both first-person pain and disgust in left AI and mACC (Ps&#x02194;U: <italic>d&#x02032;</italic>s&#x02265;0.27, permutation test: cutoff=0.17; Ds&#x02194;U: <italic>d&#x02032;</italic>s&#x02265;0.25, cutoff=0.16; <italic>P</italic>&#x0003c;0.05 corrected, <italic>N</italic>=19; see <xref ref-type="fig" rid="f3">Fig. 3c</xref>). Moreover, <italic>d&#x02032;</italic>s were comparable for cross-modal effects of UG patterns when compared with either pain or disgust (Ps&#x02194;U versus Ds&#x02194;U; |diff-<italic>d&#x02032;</italic>s|&#x02264;0.20, permutation tests of <italic>d&#x02032;</italic> differences: |cutoffs|&#x02265;0.23, NS, <italic>N</italic>=19), suggesting that neural representations of unfairness were not specifically related to disgust experiences. By contrast, no cross-modal effect was found in right AI (<italic>d&#x02032;</italic>s&#x02264;0.04, NS), although this region disclosed reliable detection of unfairness in the within-task classification. Furthermore, in right AI, the <italic>d&#x02032;</italic>s obtained in the within-task classification of unfairness were larger than those obtained in the cross-modal classification (U&#x0003e;Ps&#x02194;U and U&#x0003e;Ps&#x02194;U: diff-<italic>d&#x02032;</italic>&#x02265;0.34, permutation tests of <italic>d&#x02032;</italic> differences: cutoffs&#x02264;0.27, <italic>P</italic>&#x0003c;0.05 corrected, <italic>N</italic>=19). Finally, results of a repeated measure ANOVA confirmed differential cross-modal effects across ROIs for unfair UG offers and both first-hand pain (permutation-based ANOVA, F=4.56, cutoff=3.53, <italic>P</italic>&#x0003c;0.05, <italic>N</italic>=19) and disgust (permutation-based ANOVA, F=2.84, cutoff=3.16, <italic>p</italic> (one-tailed)&#x0003c;0.05, <italic>N</italic>=19), reflecting lower <italic>d&#x02032;</italic>s in right AI than in both left AI and mACC (|diff-<italic>d&#x02032;</italic>s|&#x02265;0.21, permutation tests of <italic>d&#x02032;</italic> differences: |cutoffs|&#x02264;0.21, <italic>P</italic>&#x0003c;0.05, <italic>N</italic>=19).</p><p>Overall, the analysis of UG data points to shared activity patterns between pain, disgust and unfairness in left AI and mACC. These responses in the UG might reflect a general aversive affective experience shared with other primary negative experiences such as pain and disgust, rather than the activation of neuronal responses specific for a particular nociceptive or distasteful sensation. On the other hand, evidence from right AI suggests that part of the signal is specific to the experience of unfairness, which converges with our previous analyses for pain and disgust.</p><p>To summarize results from these analyses, we depicted for each ROI separately the <italic>d&#x02032;</italic>-matrixes obtained from all within-task, cross-modal and cross-target classifications (<xref ref-type="fig" rid="f2">Fig. 2c</xref>). A clear difference between the three ROIs is apparent, with the right AI displaying higher-than-chance <italic>d&#x02032;</italic>s prevalently in within-task classifications (on the outer diagonal line), whereas the left AI and mACC displayed reliable <italic>d&#x02032;</italic>s also in many cross-modal and cross-target classifications. Importantly, the absence of shared effects in right AI cannot be imputed to reduced signal or larger noise, as this region sensitivity to aversiveness in the within-task classification was comparable to that of other ROIs (in particular left AI; see also previous sections above).</p></sec><sec disp-level="2"><title>Whole-brain searchlight analysis</title><p>To test for additional brain regions relevant for the encoding of unpleasantness across targets and tasks, we repeated the pattern analyses using a whole-brain searchlight approach as implemented in other studies<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b32">32</xref><xref ref-type="bibr" rid="b33">33</xref><xref ref-type="bibr" rid="b41">41</xref><xref ref-type="bibr" rid="b42">42</xref>. This approach has the advantage of not relying on <italic>a priori</italic> assumptions about specific brain regions but looks for discriminative local information throughout the whole brain. Results from this analysis were entirely in line with those obtained using ROIs. First of all, they confirmed the role of left AI and ACC in supramodal representations of negative affect, with shared activity patterns across all conditions. In addition, modality-independent effects were also observed in the posterior portion of the superior temporal sulcus and the inferior frontal gyrus, whereas the posterior cingulate cortex, supplementary motor area and orbitofrontal cortex exhibited modality-specific activity patterns. Please see <xref ref-type="supplementary-material" rid="S1">Supplementary Figs 3&#x02013;7</xref> and <xref ref-type="supplementary-material" rid="S1">Supplementary Tables 1&#x02013;7</xref> for more details.</p></sec></sec><sec disp-level="1"><title>Discussion</title><p>Neuroscientific research has repeatedly shown that AI and mACC are engaged in first-person and vicarious experiences of pain<xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b12">12</xref><xref ref-type="bibr" rid="b13">13</xref> and disgust<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b6">6</xref><xref ref-type="bibr" rid="b14">14</xref><xref ref-type="bibr" rid="b15">15</xref>, but also unfairness<xref ref-type="bibr" rid="b16">16</xref><xref ref-type="bibr" rid="b36">36</xref><xref ref-type="bibr" rid="b37">37</xref><xref ref-type="bibr" rid="b38">38</xref><xref ref-type="bibr" rid="b39">39</xref>. However, the exact nature of the processes encoded in these regions is still debated<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b29">29</xref><xref ref-type="bibr" rid="b43">43</xref>. Here we tested whether AI/mACC encode aversive states in terms of general affective features that are blind to the modality (pain, disgust, unfairness) and the target of the experience (self, other), or in terms of distinct modality-specific or target-specific neural responses. By using MVPA, we systematically compared the activity patterns elicited by painful (electrical), disgusting (gustatory) and unfair (monetary) events, directed at either the participant or another person. Notably, the left AI and mACC disclosed shared neural representations not only between first-person and vicarious experiences (extending previous MVPA results for pain<xref ref-type="bibr" rid="b7">7</xref> to other domains), but also between different stimulus modalities including pain, disgust and unfairness. Furthermore, we also found neural responses specific to the modality and the target of the aversive experience, particularly in right AI. These results provide evidence for both domain-general and domain-specific coding in AI and mACC, thus demonstrating how this network might contribute to a comprehensive representation of aversive experiences.</p><p>Studies in primates and humans previously suggested that the insula might process first-hand experiences of pain and disgust in a sensory-specific manner. The posterior and middle insula are thought to receive inputs from neurons in ventral posteromedial thalamic nuclei sensitive to gustation<xref ref-type="bibr" rid="b22">22</xref><xref ref-type="bibr" rid="b23">23</xref> and nociception<xref ref-type="bibr" rid="b24">24</xref><xref ref-type="bibr" rid="b25">25</xref><xref ref-type="bibr" rid="b26">26</xref>, and then to project to the AI for higher level coding of affect and interoceptive information<xref ref-type="bibr" rid="b19">19</xref><xref ref-type="bibr" rid="b44">44</xref><xref ref-type="bibr" rid="b45">45</xref>. However, the nature of the information coded in AI has still remained elusive. On the one hand, its sensitivity to a wide range of sensory and affective experiences<xref ref-type="bibr" rid="b9">9</xref><xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b21">21</xref> suggests that AI (and mACC) may not code for modality-specific information, but rather represent more general properties of affective experiences common to pain, disgust and unfairness. On the other hand, anatomical studies on primates point to several distinct subfields in AI<xref ref-type="bibr" rid="b46">46</xref>, which are difficult to map in humans through radiological imaging, but nevertheless appear consistent with highly specialized modules for different sensory domains. The finding of shared activity patterns between pain, disgust and unfairness in left AI and mACC strongly supports the former interpretation, pointing to a supramodal representation of negative affect transcending sensory domains and event target. In this perspective, left AI/mACC might respond to the unpleasantness of events and therefore mediate signals of negative valence, or alternatively code for their arousal or perceptual salience<xref ref-type="bibr" rid="b27">27</xref><xref ref-type="bibr" rid="b28">28</xref><xref ref-type="bibr" rid="b29">29</xref>. Note, however, that arousal and salience also include positive affect. Future investigations will therefore need to test whether the effects identified here extend also to high-arousing positive stimuli.</p><p>Critically, a reliable part of our findings cannot be explained in terms of general, amodal features of aversive experiences. Instead, we found that activity patterns in right AI were specific for pain, disgust, unfairness, as well as the target of the experience. Indeed, overlapping fMRI activations are not necessarily diagnostic of common underlying representations<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b47">47</xref>, but might reflect the presence of distinct (intermingled) neuronal populations related to modality- or target-specific representations. MVPA is well-suited to address these issues, as it investigates whether idiosyncratic spatial variations in the neural signal are shared or dissociated across experimental manipulations. Using this approach, Chikazoe <italic>et al</italic>.<xref ref-type="bibr" rid="b47">47</xref> found modality-specific representations of unpleasantness in AI for gustatory and visual stimuli, as well as modality-independent representations in medial prefrontal regions. Our data extend these previous findings by demonstrating that AI codes for first-person pain and disgust through both modality-specific and modality-independent neural representations.</p><p>Taken together, our findings provide new and comprehensive insights into the neural processing of various aversive experiences. We show that the right AI contributes to modality-specific analysis of gustatory/nociceptive inputs, whereas the left AI and mACC might integrate the output of modality-specific computations into more abstract representations of these events. Future studies will need to further examine the differential role played by left AI and mACC in amodal processing of unpleasantness. For instance, it has been proposed that mACC might integrate negative affect, pain and cognitive control, presumably reflecting a key role played by this region in the selection of behavioural responses to unpleasant events<xref ref-type="bibr" rid="b48">48</xref>. Also the functional nature of the differential lateralization within AI for modality-specific and modality-independent processing remains to be elucidated. This could be partially determined by the lateralized nature of electrical stimuli (delivered on the left wrist), and consistent with suggestions that the insula contralateral to the stimulation site might process the sensory properties of a stimulus event, whereas the ipsilateral AI might code for its subjective meaning<xref ref-type="bibr" rid="b25">25</xref>. Evidence from experiments in which pain is delivered also on the right side of the body might support this claim<xref ref-type="bibr" rid="b7">7</xref> (see <xref ref-type="supplementary-material" rid="S1">Supplementary Note 1</xref> and <xref ref-type="supplementary-material" rid="S1">Supplementary Table 8</xref>). Alternatively, the right and left AI might exhibit distinctive contributions of sympathetic and parasympathetic systems, with the former involved in processing specific aversive events and the latter promoting shared regulatory/coping processes<xref ref-type="bibr" rid="b49">49</xref>. The observation of hemispheric differences in the disgust and fairness tasks (where stimuli were not lateralized) supports the latter interpretation. Overall, our results dovetail with seminal theoretical accounts of insula function, according to which AI and mACC mediate subjective feelings in terms of comprehensive representations of affective states that integrate multiple sources of information<xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b19">19</xref><xref ref-type="bibr" rid="b45">45</xref>.</p><p>AI and mACC were also engaged when participants observed a confederate undergoing pain or disgust. This finding converges with previous evidence demonstrating that these regions encode empathic responses elicited by various cues about others' negative states (abstract symbols, facial expressions, injured bodies and so on)<xref ref-type="bibr" rid="b4">4</xref><xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b6">6</xref><xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b11">11</xref>. The role of AI/mACC in both first-person and vicarious experiences has often been interpreted in favour of embodied models of social cognition, according to which the states of people are inferable by activating a representation of the same state in the observer<xref ref-type="bibr" rid="b18">18</xref><xref ref-type="bibr" rid="b19">19</xref>. In support of this view, we recently showed using MVPA that AI and mACC disclosed common activity patterns between felt and observed pain<xref ref-type="bibr" rid="b7">7</xref>. Yet, our previous results did not allow ascertaining whether the information shared between self and others concerned modality-specific or modality-independent features. The cross-modal effects observed in left AI and mACC strongly support a unique neuronal signature coding for aversive events regardless of the modality or recipient of the experience. Critically, however, we also found that activity evoked by vicarious empathic experiences in right AI was not shared with that elicited by first-person aversive states. This finding is consistent with previous evidence that human and monkey AI might process social emotions in partial dissociation from first-person pain<xref ref-type="bibr" rid="b43">43</xref><xref ref-type="bibr" rid="b50">50</xref> or disgust<xref ref-type="bibr" rid="b51">51</xref>, and suggests the presence of target-specific neural activity complementing the shared representations.</p><p>Taken together these findings support embodied interpretation of left AI and mACC function, but at the same time circumscribe their reach. While neural responses encoding first-hand aversive experiences are re-activated when empathizing with others, these do not seem to contain modality-specific information related to the nociceptive or gustatory input anymore. A more suitable interpretation is that others' states trigger a neural representation of non-specific properties such as an unpleasant bodily experience, which was an inherent dimension of all events tested in our study<xref ref-type="bibr" rid="b19">19</xref>.</p><p>Finally, we show that neural signals in left AI and mACC related to the first-hand sensation of pain and disgust are in part shared with those associated with unfair treatments in the UG. Again no shared effects were observed in right AI, even though this region disclosed reliable activity patterns for unfairness. This suggests that right AI disclose modality-specific information, not only for pain and disgust, but also for the experience of unfairness, in parallel with an amodal representation of aversive events in left AI and mACC.</p><p>Although AI and mACC have frequently been implicated in unfair UG offers<xref ref-type="bibr" rid="b16">16</xref><xref ref-type="bibr" rid="b36">36</xref><xref ref-type="bibr" rid="b37">37</xref><xref ref-type="bibr" rid="b38">38</xref><xref ref-type="bibr" rid="b39">39</xref>, different accounts have been put forward to interpret the functional role of these regions in the bargaining game. Sanfey <italic>et al</italic>.<xref ref-type="bibr" rid="b16">16</xref> suggested that AI activity might reflect an activation of disgust-specific representation in insular cortex, as a neural signature of &#x02018;being disgusted by people's unfair behaviour'. This interpretation, in keeping with accounts suggesting how representations of unmoral behaviour are grounded on personal disgusting experiences<xref ref-type="bibr" rid="b20">20</xref>, is not supported by our data. Instead, our findings fit best the predictions of the wounded pride/spite model, according to which unfair behaviour elicits a broad negative emotional reaction in the observer<xref ref-type="bibr" rid="b52">52</xref>, with consequent physiological and neural responses.</p><p>Note, however, that previous studies have suggested a role of AI and mACC in the detection of equality violations in the UG<xref ref-type="bibr" rid="b36">36</xref><xref ref-type="bibr" rid="b37">37</xref>. Our data do not rule out a fairness-specific interpretation, since part of the predictive information about unfairness in right AI and mACC was independent from first-person experiences of pain or disgust. Hence, it is possible that AI/mACC process unfair offers in a multidimensional manner, taking into account both the equality of the offer and its emotional impact on individuals.</p><p>To our knowledge, our UG results are the first showing that a neural representation of first-hand pain/disgust is re-enacted, not only when empathizing with others, but also during other unpleasant social experiences. Interestingly, several studies also implicated the mACC during social pain, including aversive experiences caused by social exclusion, rejection or loss<xref ref-type="bibr" rid="b53">53</xref><xref ref-type="bibr" rid="b54">54</xref>. The role of the mACC in social pain has often been interpreted as a re-activation of signals of physical pain<xref ref-type="bibr" rid="b54">54</xref><xref ref-type="bibr" rid="b55">55</xref> (but see Woo <italic>et al</italic>.<xref ref-type="bibr" rid="b43">43</xref>). Our data are in keeping with this interpretation, but only under the assumption that physical and social pain share a modality-independent representation of the unpleasantness of the experience. Future studies need to formally test this hypothesis by adopting the current decoding approach with the addition of social exclusion.</p><p>In conclusion, the present study aimed at clarifying the nature of information represented in AI and mACC, a network commonly engaged in first-hand pain, disgust or unfairness, but also when witnessing others undergoing the same aversive events. The recruitment of this network has often been interpreted in terms of domain-general affective processing, according to which these regions respond to common properties of the affective experience such as unpleasantness. Our data support domain-general coding in left AI/mACC while also promoting domain-specific processing, particularly in right AI that exhibited activity patterns uniquely distinctive for pain, disgust and unfairness, as well as for the person to whom the events were addressed. Taken together, these findings suggest that the AI&#x02013;mACC network might subserve a comprehensive, multi-layer, representation of aversive experiences<xref ref-type="bibr" rid="b25">25</xref><xref ref-type="bibr" rid="b44">44</xref><xref ref-type="bibr" rid="b45">45</xref>, which takes into account both modality- and target-specific information and more general affective properties of the event.</p></sec><sec disp-level="1"><title>Methods</title><sec disp-level="2"><title>Participants</title><p>Nineteen right-handed female volunteers (average age of 25.16&#x000b1;3.44 years, s.d.) took part in the experiment (see <xref ref-type="supplementary-material" rid="S1">Supplementary Note 2</xref> and <xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 9</xref> for power analyses on independent pilot data). All participants were accompanied by a friend (12 females) who acted as confederate during the experimental session. Participants were free of psychiatric or neurological history and had normal or corrected-to-normal vision. They were all compensated according to both the overall experimental duration (8&#x020ac; per hour) and participants' choices in the randomly selected trials of the UG task (see below). Written informed consent was obtained from all participants and confederates. The experiment was approved by the Ethical Committee at the faculty of Medicine of the University of Leipzig (Ethik-Kommission an der Medizinischen Fakult&#x000e4;t der Universit&#x000e4;t Leipzig) and conducted according to the declaration of Helsinki.</p></sec><sec disp-level="2"><title>Experimental set-up</title><p>Participants and confederates took part in three experimental tasks implemented in blocks in alternating orders. The first task was a cue-based &#x02018;empathy for pain' paradigm (pain task)<xref ref-type="bibr" rid="b5">5</xref>, in which participants either received an electrical (Ps or nPs) stimulation or were informed that their confederate was about to receive the same stimulation. In the second task, the cue-based empathy for pain paradigm was modified so that gustatory stimuli (Ds or nDs) were delivered either to participants or to the confederates (disgust task). The third task was the well-known UG paradigm in which participants were presented with monetary offers (unfair or moderately fair), which were addressed either to themselves or to the confederate<xref ref-type="bibr" rid="b35">35</xref><xref ref-type="bibr" rid="b37">37</xref>. Despite their differences, the employed experimental manipulations converged in exposing either participants or the confederates to aversive or neutral stimuli. This led, for each of the three tasks, to a 2 (UNPLEASANTNESS: aversive, neutral) &#x000d7; 2 (TARGET: self, other) factorial design, and to an overall of 12 conditions. All conditions were implemented while participants were lying supine in a MRI scanner and the confederates sat next to the scanner table in the MRI room.</p><p>The pain task was organized as follows. Consistently with earlier implementations of the &#x02018;empathy for pain' task<xref ref-type="bibr" rid="b5">5</xref>, each trial started with the presentation of a coloured, arrow-shaped cue (2&#x02009;s) that informed participants of the target and the unpleasantness of the upcoming stimulation (see <xref ref-type="fig" rid="f1">Fig. 1a</xref>). Arrows pointing vertically downwards (&#x02193;) indicated stimulations directed to participants (self) while arrows pointing diagonally towards the confederate (&#x02199;) cued stimulations directed to the latter (other). The intensity of the cue's colour indicated the unpleasantness of the upcoming stimulation with light tones referring to non-noxious (neutral) stimulations and dark tones referring to noxious (aversive) stimulations. Different colours were used for self- and other-related trials. Colour codes changed across participants. Cues were followed by an electrical stimulation of 1&#x02009;s (100&#x02009;Hz) that was applied to participants' (or confederates') left wrist. Electrical stimulations were followed by a horizontal visual analogue rating scale (5&#x02009;s) ranging from &#x02212;3 (highly unpleasant) to &#x0002b;3 (highly pleasant). The direction of the scale was counterbalanced across trials to avoid motor preparation during the preceding stimulation periods. Participants marked the position of the scale corresponding to their judgment, by moving a slider (randomized initial position) with the index and middle fingers of their right hand operating a button box. Trials were separated by an inter-trial-interval ranging from 2.5 to 7.5&#x02009;s (average 5&#x02009;s) during which a white fixation cross was presented. Each of the four conditions of the pain task (pain stimuli delivered to self (Ps) or other (Po), plus corresponding nPs controls (nPs and nPo)) was repeated 16 times.</p><p>As for the pain task, in the disgust task as well participants were initially presented with cues (2&#x02009;s) whose orientation (&#x02193; or &#x02199;) and colour informed about the target and the unpleasantness of the upcoming gustatory stimulation (see <xref ref-type="fig" rid="f1">Fig. 1b</xref>). Colours were different from those used in pain trials and changed across participants. Cues were followed by 0.5&#x02009;ml of liquid delivered on participants' (or confederates') tongues through the aid of plastic tubes. Participants were instructed to keep the liquid in their mouth and taste it for 4&#x02009;s, until a &#x02018;swallow' instruction (3&#x02009;s) was presented on the screen. This ensured that movement artifacts in the neural signal due to swallowing occurred prevalently after the stimulation period. Subsequently, participants were asked to rate the experienced unpleasantness of the gustatory stimulus on the same scale used for the pain task (5&#x02009;s). Finally, to minimize carry-over effects between subsequent trials, 2&#x02009;ml of water were delivered via a separate tube to rinse (3&#x02009;s), followed by another 3-s long swallowing period. Trials were separated by an interval of 2.5&#x02013;7.5&#x02009;s. Each of the four conditions of the disgust task (disgust stimuli to self (Ds) or other (Do), plus corresponding neutral controls (nDs and nDo)) was repeated 16 times. Participants didn't report coughing or other trouble due to the administration of gustatory stimuli.</p><p>Finally, we implemented an MRI-compatible version of the UG<xref ref-type="bibr" rid="b16">16</xref>. In each trial, participants faced an unknown proposer who made an offer on how to divide an initial endowment of 10&#x020ac;. The UG offers were addressed either to the self (standard UG) or to the other (third-party UG)<xref ref-type="bibr" rid="b35">35</xref><xref ref-type="bibr" rid="b37">37</xref>. In self-related trials of the UG, participants were told that if they accepted the offer, the money would be divided between them and the proposer accordingly, whereas if they rejected it, both they and the proposer would not get any money. In other-related trials, participants responded to the offers on behalf of the confederate without any economical consequence for themselves. Thus, if participants accepted, the money would be divided between the confederate and the proposer while both got nothing if participants rejected the offer. Proposers were described as 96 university students from a different city (Geneva, Switzerland), which previously made one single UG offer, thus leading to 96 independent 1-shot interactions with the participants (recruited in Leipzig, Germany). Regardless of the cover story, participants faced offers that were defined <italic>a priori</italic> by the experimenters, and which ranged from extremely unfair (the proposer offered 1 or 2&#x020ac; out of 10&#x020ac; (1:9, 2:8) and wished to keep the remaining), to moderately unfair (3:7, 4:6) and extremely fair (5:5, 6:4). Participants and confederates knew that 2 of the 96 bargaining trials (one self- and one other-related) would be randomly selected at the end of the experimental session and implemented according to the participants' choices. Self-reports obtained subsequent to scanning confirmed that participants believed that the proposers were genuinely human (average of 4.16&#x000b1;1.21 s.d. on a scale ranging from 1 (I did not believe at all) to 5 (I absolutely believed)).</p><p>Reminiscently to the pain and disgust tasks, UG trials were introduced by a cue (2&#x02009;s) whose orientation (&#x02193; or &#x02199;) and colour informed about the target of the upcoming offer. Unlike for the other tasks, UG cues were not informative of the alleged unpleasantness of the upcoming event (same brightness for all six implemented offers). To increase the plausibility of the cover story, arrows were presented together with a photo taken from the NimStim face database<xref ref-type="bibr" rid="b56">56</xref> (48 males, 48 females displaying neutral facial expression; age ranging from 18 to 34 years). Cues were followed by an offer screen (4&#x02009;s), which was schematically represented as two piles of coins (left for proposer, right for participant/confederate). The proposed split was also explicitly reported beneath the piles. Participants responded by pressing one of two buttons assigned to &#x02018;accept' or &#x02018;reject' as displayed at the lower portion of the screen. Following their response, participants were asked to rate the experienced unpleasantness on the same scale used for the other tasks (5&#x02009;s). Trials were separated by an interval of 2.5&#x02013;7.5&#x02009;s. Overall, the UG comprehended 48 self- and 48 other-related trials: 32 of these conveyed 1:9 and 4:6 offers (16 repetitions each), whereas the remaining 16 trials conveyed 2:8, 3:7, 5:5 and 6:4 offers (4 repetitions each). Based on individuals' unpleasantness ratings, these trials were then sorted into 4 subgroups of 16 trials each (unfair offer to self or to other (U), plus corresponding midfair controls (M)) which were most closely matched for unpleasantness with homologous conditions in the pain and disgust tasks. Please notice that, for the purpose of the present study, we are focusing on UG effects obtained when merging self-related and other-related trials together <xref ref-type="supplementary-material" rid="S1">Supplementary Fig. 2</xref> report effects associated with each target separately.</p></sec><sec disp-level="2"><title>Procedure and apparatus</title><p>Prior to scanning, participants and confederates underwent brief thresholding sessions to identify electrical and gustatory stimuli that elicited comparable levels of unpleasantness<xref ref-type="bibr" rid="b34">34</xref> (see below). The scanning session was divided into four functional runs. Each run was in turn divided into three blocks, corresponding to the three tasks. A text string (3&#x02009;s) informed the participant of the task in the upcoming block. The order of blocks was counterbalanced across runs and across participants. During the four functional runs, confederates were placed in a chair next to the scanner with their eyes masked, and were cued for tasks and trial conditions using different audible beep signals presented via headphones. Subsequent to the four functional runs, we obtained functional resting-state data and a high-resolution anatomical scan for each participant. During the resting-state session, participants were instructed to keep their eyes open, to fixate a centrally presented white cross against a black background and to think of nothing in particular. Following the scanning session, participants and confederates were debriefed. Each experimental session took &#x0223c;2.5&#x02009;h.</p><p>Electrical stimulations to the left wrist were delivered via MRI-compatible, gold-based electrodes attached to a DS7A Constant Current Stimulator (Digitimer Ltd). Liquids were automatically presented via separate plastic tubes (diameter of 1.5&#x02009;mm) that rested at the tip of the tongue using a custom-build computer-controlled pump-system. Tubes were fixated to the head coil with a plastic holder. Visual stimuli were projected on a screen (about 19&#x000b0; &#x000d7; 14&#x000b0; of visual angle) placed inside the scanner bore. Key-presses were recorded on an MRI-compatible response button box. The task was programmed using Presentation 14 (Neurobehavioral Systems) software.</p></sec><sec disp-level="2"><title>Pain thresholding</title><p>The amplitudes of noxious and non-noxious stimulations varied on an individual basis and were selected, for participants and confederates separately, prior to the scanning session through a multiple-random-staircase approach<xref ref-type="bibr" rid="b57">57</xref>. Computerized pain thresholding was realized using four staircases of single electrical stimulations (ranging from 0&#x02009;mA to a maximum of 2.5&#x02009;mA). Each electrical stimulus (1&#x02009;s) was announced by a countdown (&#x02018;Stimulus in 3/2/1', duration of 3&#x02009;s), and followed by a VAS ranging from 1 (barely detectable) to 10 (strongest imaginable pain) through which subjects rated their subjective pain experience. Subjects had also the option to select a value of 0 (presented left to the scale) to report imperceptible stimuli. Ratings were self-paced and followed, after 200&#x02009;ms, by a new electrical stimulation from a different (randomly selected) staircase. Two staircases aimed at identifying the subject-specific threshold intensity of a noxious stimulus, whereas the remaining two aimed at identifying the intensity of the non-noxious (but yet detectable) stimulus.</p><p>The staircases started with electrical intensities randomly ranging from 0.6 to 0.8&#x02009;mA (noxious stimulus) or from 0.25 to 0.45&#x02009;mA (non-noxious stimulus). Subsequently, intensities were systematically increased or decreased by increments of 0.08&#x02009;mA until the experienced pain exceeded or fell below a predefined subjective pain value. In that case, the staircase was reversed until the subjective pain value was met again (turning points). Each staircase stopped once collecting eight turning points (four below and four above the subjective pain value). Noxious stimuli were calculated as the average intensity (mA) associated with 14 turning points (the last seven of two staircases) around a subjective pain value of 7.5 (out of 10). Non-noxious (but detectable) stimuli were calculated as the average intensity associated with 14 turning points around a subjective pain value of 1.5 (out of 10). The subjective pain value used to identify noxious and non-noxious stimuli was unknown to the subjects.</p><p>The noxious and non-noxious intensities identified through the staircase approach were then re-tested in a second self-paced, computerized task that required subjects to judge the subjective unpleasantness of stimuli on a VAS similar to the one used in the experimental session. The pain stimuli were expected to elicit subjective unpleasantness levels comparable to those triggered by the gustatory stimuli, that is between &#x02212;2 and &#x02212;2.5 for noxious stimuli (on a scale from &#x02212;3 to 3) and between &#x02212;0.5 and 0 for non-noxious stimuli. If this was not the case, the intensity of the stimuli was further adjusted. Overall, in 19 participants undergoing fMRI, the pain thresholding procedure led to an average noxious stimulus of 1.2&#x02009;mA (&#x000b1;0.1, s.d.), and to an average non-noxious stimulus of 0.4&#x02009;mA (&#x000b1;0.03).</p></sec><sec disp-level="2"><title>Disgust thresholding</title><p>Disgusting and neutral liquids were selected prior to the experimental session to identify, for participants and confederates separately, two gustatory stimulations whose unpleasantness matched the electrical stimuli used for the pain task. In keeping with earlier neuroimaging studies<xref ref-type="bibr" rid="b6">6</xref><xref ref-type="bibr" rid="b58">58</xref><xref ref-type="bibr" rid="b59">59</xref> and pilot data collected on independent subjects (see <xref ref-type="supplementary-material" rid="S1">Supplementary Note 1</xref>), negative stimuli were chosen from three salt solutions (NaCl) of different degrees of dilution (0.1, 0.5, 1&#x02009;mol) and three concentrations of quinine solution (0.25, 1, 10&#x02009;mM). Neutral gustatory stimuli consisted of four solutions with the main ionic components of saliva (25&#x02009;mM KCl and 2.5&#x02009;mM NaHCO<sub>3</sub>), diluted with various amounts of distilled water (20, 40, 60 and 80&#x00025;).</p><p>The thresholding procedure was organized as follows. On each trial, 0.5&#x02009;ml of a solution were administered (via syringes without needle) to the subject who evaluated the experienced unpleasantness on a VAS similar to the one used during scanning. Three kinds of substance (salt, quinine, saliva) were administered separately, with the order of substances and concentrations randomized across individuals. For each subject, we selected one negative stimulus associated with an unpleasantness range from &#x02212;2.5 to &#x02212;2 (on a scale from &#x02212;3 to 3) and one neutral stimulus with a rating from &#x02212;0.5 to 0. Furthermore, subjects were screened for their taste sensitivity concerning the gustatory stimuli using a labelled magnitude scale with a continuous rating from 0 (barely detectable) to 100 (strongest imaginable)<xref ref-type="bibr" rid="b60">60</xref>. The subjective taste intensities for the chosen negative solutions were found to be within the range of 30&#x02013;75, consistent with earlier studies<xref ref-type="bibr" rid="b59">59</xref>.</p></sec><sec disp-level="2"><title>fMRI data aquisition</title><p>Functional imaging was performed on a 3T Verio scanner (Siemens Medical Systems, Erlangen) equipped with a 12-channel head coil. An echoplanar imaging sequence (repetition time (TR)=2&#x02009;s, echo time (TE)=30&#x02009;ms, flip angle=90&#x000b0;, 3 &#x000d7; 3 &#x000d7; 3&#x02009;mm, 1&#x02009;mm interslice gap, matrix size 64 &#x000d7; 64, 30 slices tilted at &#x0223c;30&#x000b0; from axial orientation) was used to obtain T2&#x0002a;-weighted functional images. Functional image acquisition was realized in 4 functional runs, each consisting of 524 volumes (&#x0223c;18&#x02009;min, total of &#x0223c;72&#x02009;min). Functional runs were divided by breaks of &#x0223c;2&#x02009;min, where no functional images were obtained. In addition, we collected task-free fMRI time series, consisting of 200 volumes acquired over &#x0223c;7&#x02009;min using the same sequence as the task-related fMRI. Subsequent to the functional image acquisition, a T1-weighted high-resolution anatomical image was obtained using a MPRAGE sequence (TR=2.3&#x02009;s, TE=2.98&#x02009;ms, flip angle=9&#x000b0;, 1 &#x000d7; 1 &#x000d7; 1&#x02009;mm, matrix size 240 &#x000d7; 256, 176 sagittal slices, ipat=2) and a 32-channel head coil (&#x0223c;5&#x02009;min).</p></sec><sec disp-level="2"><title>fMRI data processing</title><p>The acquired images were processed using the SPM8 software (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/">http://www.fil.ion.ucl.ac.uk/spm/</ext-link>). For each subject and for each functional run, the first three volumes were discarded. The remaining images were corrected for head movement between scans by an affine registration. In none of the subjects, head movements within each functional run exceeded 3&#x02009;mm per degree, confirming that electrical stimulation and swallowing of gustatory stimuli did not result in unusual movement artifacts in the present study. Subsequently, to compensate for time-acquisition delays, each temporal slice was temporally realigned to the 15th (of 30) reference slice through interpolation. The resulting functional images were aligned to the T1-weighted anatomical image through rigid-body registration, and smoothed using a 6&#x02009;mm full-width at half-maximum (FWHM) Gaussian kernel.</p><p>We analysed the preprocessed data from our task-positive sessions using the general linear model (GLM) framework implemented in SPM. For each participant and in each functional run, the onsets of each trial were modelled independently, yielding trial-wise parameter estimates of the conditions-of-interest<xref ref-type="bibr" rid="b7">7</xref>. In line with previous implementations of the pain task<xref ref-type="bibr" rid="b5">5</xref>, for the pain and disgust trials we considered relevant the neural activity associated with both the presentation of the cue and the subsequent stimulation, thus leading to epochs which were 3-s (pain) and 6-s (disgust) long (see <xref ref-type="fig" rid="f1">Fig. 1a,b</xref>). For the UG, in which the cue was not informative of the unpleasantness of the upcoming event, we modelled the epochs in which the monetary offers were made (4&#x02009;s) (see <xref ref-type="fig" rid="f1">Fig. 1c</xref>). In addition, we also modelled epochs in which the cues were presented as regressors of no interest (2&#x02009;s). All the resulting vectors were convolved with a canonical haemodynamic response function as implemented in SPM. Movement parameters were included as covariates of no interest. Low-frequency signal drifts were filtered using a cutoff period of 128&#x02009;s. For each subject, this GLM lead to as many parameter estimate (<italic>&#x003b2;</italic>s) images as experimental trials were employed in the study. These images were then fed to multivoxel pattern analysis (MVPA) routines.</p></sec><sec disp-level="2"><title>Multivoxel pattern analysis</title><p>We run classification-based MVPA to assess the similarity between the neural representations of our experimental conditions. The analysis was conducted by first defining a ROI and then by extracting, from each of its constitutive coordinates, the parameters estimates (<italic>&#x003b2;</italic>s) associated with each experimental trial. Furthermore, for each individual subject, and for each condition, response patterns were mean centred through <italic>z</italic>-transformation to ensure that the MVPA analysis would not be biased by differences in the average ROI activity across conditions<xref ref-type="bibr" rid="b61">61</xref>. Data were then fed into a linear kernel SVM classifier (using a fixed regularization parameter, <italic>C</italic>=1), which operates by finding an optimal linear decision boundary (hyperplane) that separates experimental classes with maximum margin. New data (not used to define the decision boundary) are classified according to which side of the hyperplane they fall onto<xref ref-type="bibr" rid="b62">62</xref>. Signal detection methods were used to compute <italic>d</italic><xref ref-type="bibr" rid="b63">63</xref> as a measure of the sensitivity of the hyperplane to detect, in new data, the occurrence of one aversive condition. Classification analysis was performed using the LIBSVM 3.18 software<xref ref-type="bibr" rid="b40">40</xref>.</p><p>Statistical validation of the average <italic>d&#x02032;</italic> obtained at the group level was achieved through rigorous non-parametric permutation techniques, following guidelines on statistical assessment of decoding accuracies<xref ref-type="bibr" rid="b64">64</xref>. In particular, for each classification analysis, we created 1,000 permutation schemes aimed at breaking the relationship between the data and the condition labels. Each of these permutations was applied to the data of all subjects and all ROIs, which were then fed to the same classification routines used for the original data set. All the group-wise <italic>d&#x02032;</italic> values obtained through permuted data sets were used to estimate critical cutoffs, above which an effect could be considered significantly higher than null. More specifically, to assess significant (albeit uncorrected) effects within each ROI, we used as cutoff the 95th percentile of the permutation distribution of 1,000 group-wise <italic>d&#x02032;</italic>s obtained from the data of that ROI. Following previous implementations of <italic>P</italic> value adjustment in permutation-based multiple testing<xref ref-type="bibr" rid="b65">65</xref>, we computed the permutation distribution of the 1,000 maximal group-wise <italic>d&#x02032;</italic>s over all ROIs to provide corrections for multiple comparisons. The 95th percentile of this &#x02018;maximal group-wise <italic>d&#x02032;</italic>s' distribution represents a reliable cutoff for <italic>d</italic>&#x02032;s that are unlikely (<italic>P</italic>&#x0003c;0.05) to be achieved in any ROI under the null hypothesis. Similar permutation analyses were carried out to assess whether the <italic>d&#x02032;</italic> difference between two conditions (diff-<italic>d&#x02032;</italic>), or the value from standardized statistical tests (for example, F test in a repeated measure ANOVA testing <italic>d&#x02032;</italic> differences across ROIs), were significantly higher-than-chance.</p><p>As a manipulation check, we first assessed the ability of a linear SVM classifier to discriminate between data associated with each aversive condition from the data associated with its tailored neutral control (for example, Ps versus nPs). Specifically, we employed leave-one-pair-out cross-validation, in which the 16 aversive and 16 neutral trials were randomly paired together. We then tested, in 16 independent folds, whether the data from each pair could be correctly classified by a hyperplane estimated on the remaining 15 pairs. For each participant, we estimated <italic>d&#x02032;</italic> from the classified trials of all the implemented folds. This analysis provides an estimate of the information about unpleasantness present in each ROI, separately for each modality and target, regardless of whether or not it is shared with other experimental manipulations (within-task classification).</p><p>Subsequently, we ran cross-modal classification that assessed whether a classifier trained to detect unpleasantness in one specific task (for example, Ps) could discriminate unpleasantness from another modality (for example, Ds). The analysis was conducted through 2 independent folds: we first trained a SVM on the 32 trials associated with Ps and nPs, and then tested the ability of the estimated hyperplane to classify the 32 trials associated with Ds and nDs. In the second fold, we trained a SVM on the trials associated with Ds and nDs, and then tested the estimated hyperplane on the trials associated with Ps and nPs. <italic>d&#x02032;</italic> values were then estimated from the classified trials from both folds. Reliable cross-modal classifications (Ps&#x02194;Ds) can be interpreted consistently with Ps and Ds triggering (each relatively to its tailored control) a partly similar response pattern. A similar approach was implemented to test for shared activity patterns across different targets (cross-target classification) (for example, Ps&#x02194;Po), or for cross-modal effects in different targets (Ps&#x02194;Do).</p><p>The MVPA analyses described were first run on <italic>a priori</italic> defined ROIs of AI and mACC (see below and Results). Furthermore, we implemented a searchlight-decoding approach that does not rely on <italic>a priori</italic> assumptions about informative brain region but searches for predictive information throughout the whole brain<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b32">32</xref><xref ref-type="bibr" rid="b33">33</xref><xref ref-type="bibr" rid="b41">41</xref><xref ref-type="bibr" rid="b42">42</xref>: for each coordinate of the individual native brain image, a spherical volume-of-interest surrounding the coordinate was defined (5 voxels radius, 81 voxels total). The parameter estimates of all voxels in the sphere were extracted and a classification procedure similar to the ROI-based MPVA was implemented. Resulting <italic>d&#x02032;</italic> values were assigned to the centre voxel of the sphere and the procedure was repeated for the next voxel. For each participant, this led to <italic>d&#x02032;</italic>-maps which were then spatially normalized to the Montreal Neurological Institute (MNI) single-subject template, using the deformation field obtained during the normalization of the T1-weigthed anatomical image. The resulting normalized images were smoothed using a 6&#x02009;mm FWHM Gaussian kernel and fed into group level analyses using one-sample <italic>t</italic>-tests to search for regions in which the group-wise <italic>d&#x02032;</italic>&#x0003e;0. Voxels were identified as significant only if they passed an extent threshold corresponding to <italic>P</italic>&#x0003c;0.05 corrected for multiple comparison, with an underlying height threshold of at least <italic>t</italic><sub>(18)</sub>=3.61, corresponding to <italic>P</italic>&#x0003c;0.001 (uncorrected). We used as extent threshold the 95th percentile of the distribution of the largest cluster obtained through 1,000 replications of the same analysis on permuted data sets. Second-level <italic>t</italic>-tests were performed using the SnPM toolbox of SPM (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="http://warwick.ac.uk/snpm">http://warwick.ac.uk/snpm</ext-link>).</p></sec><sec disp-level="2"><title>Resting-state analysis and ROI definition</title><p>We used group-independent component analysis (ICA) toolbox GIFT 3.0a (<ext-link xmlns:xlink="http://www.w3.org/1999/xlink" ext-link-type="uri" xlink:href="http://icatb.sourceforge.net/">http://icatb.sourceforge.net/</ext-link>) to estimate the ICs corresponding to functional networks, based on fMRI data from the resting-state sessions. Group ICA, which seeks ICs for the group data instead of estimating networks separately for each individual, was chosen to avoid the ambiguity arising from combining different individual networks obtained by separate estimations. For this reason, the resting-state data from individual subjects were fed to the same preprocessing routines of the task-positive sessions, with the exception than functional images were first warped in the common stereotaxic MNI space before being smoothed with a 6&#x02009;mm FWHM Gaussian kernel. The minimum-description-length algorithm<xref ref-type="bibr" rid="b66">66</xref> run on the data estimated the number of sources to be 28. Then, subjects' data were reduced to a lower dimensionality by using a two-stage principal component analysis (one at an individual level and one at a group level). Then, data from all subjects/sessions were concatenated and independent group components were estimated using the Infomax approach<xref ref-type="bibr" rid="b67">67</xref>. The ICASSO method<xref ref-type="bibr" rid="b68">68</xref> was used to assess the reliability of the networks by running the algorithm 30 times, each time with different initial conditions and bootstrap resampled data sets.</p><p><xref ref-type="fig" rid="f2">Figure 2a</xref> shows the IC implicating the bilateral AI and mACC, and therefore corresponding to the relevant affective/salience network described in previous studies<xref ref-type="bibr" rid="b28">28</xref>. Representations of AI and mACC in each individual native space were obtained through an anatomically constrained functional approach. Back reconstruction of the IC and time courses was done with the GICA3 algorithm<xref ref-type="bibr" rid="b69">69</xref>. The resulting individual maps were masked by excluding coordinates outside of the insular cortex (for AI) or the cingulate cortex (for mACC) as defined by the AAL atlas<xref ref-type="bibr" rid="b70">70</xref>. The resulting masked image was then warped into the individual native space using a deformation field inverse to the one estimated during normalization. We finally selected, as features for the MVPA analysis, those 81 coordinates (same number as in the whole-brain searchlight approach) in the native space that exhibited the largest contribution in the IC-of-interest. For each participant, three individual ROIs were created, corresponding to right and left AI and mACC. <xref ref-type="supplementary-material" rid="S1">Supplementary Figure 8</xref> depicts these selected coordinates in six different representative brains.</p></sec></sec><sec disp-level="1"><title>Additional information</title><p><bold>How to cite this article:</bold> Corradi-Dell'Acqua, C. <italic>et al</italic>. Cross-modal representations of first-hand and vicarious pain, disgust and fairness in insular and cingulate cortex. <italic>Nat. Commun.</italic> 7:10904 doi: 10.1038/ncomms10904 (2016).</p></sec><sec sec-type="supplementary-material" id="S1"><title>Supplementary Material</title><supplementary-material id="d33e18" content-type="local-data"><caption><title>Supplementary Information</title><p>Supplementary Figures 1-9, Supplementary Tables 1-8, Supplementary Notes 1-2 and Supplementary References</p></caption><media xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ncomms10904-s1.pdf"/></supplementary-material></sec></body><back><ack><p>This research was financed by the Swiss National Science Foundation grant n&#x000b0; 32003B_138413 awarded to P.V. and C.C.-D. We thank Ferdinand Hoffmann and Christoph Hofstetter for the assistance with the acquisition of the independent pilot data used for power analysis.</p></ack><ref-list><ref id="b1"><mixed-citation publication-type="journal"><name><surname>Singer</surname><given-names>T.</given-names></name>
<article-title>The past, present and future of social neuroscience: a European perspective</article-title>. <source>Neuroimage</source>
<volume>61</volume>, <fpage>437</fpage>&#x02013;<lpage>449</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22305955</pub-id></mixed-citation></ref><ref id="b2"><mixed-citation publication-type="journal"><name><surname>Keysers</surname><given-names>C.</given-names></name>, <name><surname>Kaas</surname><given-names>J. H.</given-names></name> &#x00026; <name><surname>Gazzola</surname><given-names>V.</given-names></name>
<article-title>Somatosensation in social perception</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>11</volume>, <fpage>417</fpage>&#x02013;<lpage>428</lpage> (<year>2010</year>).</mixed-citation></ref><ref id="b3"><mixed-citation publication-type="journal"><name><surname>Adolphs</surname><given-names>R.</given-names></name>
<article-title>The social brain: neural basis of social knowledge</article-title>. <source>Annu. Rev. Psychol.</source>
<volume>60</volume>, <fpage>693</fpage>&#x02013;<lpage>716</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">18771388</pub-id></mixed-citation></ref><ref id="b4"><mixed-citation publication-type="journal"><name><surname>Wicker</surname><given-names>B.</given-names></name>
<etal/>. <article-title>Both of us disgusted in My insula: the common neural basis of seeing and feeling disgust</article-title>. <source>Neuron</source>
<volume>40</volume>, <fpage>655</fpage>&#x02013;<lpage>664</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">14642287</pub-id></mixed-citation></ref><ref id="b5"><mixed-citation publication-type="journal"><name><surname>Singer</surname><given-names>T.</given-names></name>
<etal/>. <article-title>Empathy for pain involves the affective but not sensory components of pain</article-title>. <source>Science</source>
<volume>303</volume>, <fpage>1157</fpage>&#x02013;<lpage>1162</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">14976305</pub-id></mixed-citation></ref><ref id="b6"><mixed-citation publication-type="journal"><name><surname>Jabbi</surname><given-names>M.</given-names></name>, <name><surname>Swart</surname><given-names>M.</given-names></name> &#x00026; <name><surname>Keysers</surname><given-names>C.</given-names></name>
<article-title>Empathy for positive and negative emotions in the gustatory cortex</article-title>. <source>Neuroimage</source>
<volume>34</volume>, <fpage>1744</fpage>&#x02013;<lpage>1753</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17175173</pub-id></mixed-citation></ref><ref id="b7"><mixed-citation publication-type="journal"><name><surname>Corradi-Dell'Acqua</surname><given-names>C.</given-names></name>, <name><surname>Hofstetter</surname><given-names>C.</given-names></name> &#x00026; <name><surname>Vuilleumier</surname><given-names>P.</given-names></name>
<article-title>Felt and seen pain evoke the same local patterns of cortical activity in insular and cingulate cortex</article-title>. <source>J. Neurosci.</source>
<volume>31</volume>, <fpage>17996</fpage>&#x02013;<lpage>18006</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">22159113</pub-id></mixed-citation></ref><ref id="b8"><mixed-citation publication-type="journal"><name><surname>Lamm</surname><given-names>C.</given-names></name>, <name><surname>Decety</surname><given-names>J.</given-names></name> &#x00026; <name><surname>Singer</surname><given-names>T.</given-names></name>
<article-title>Meta-analytic evidence for common and distinct neural networks associated with directly experienced pain and empathy for pain</article-title>. <source>Neuroimage</source>
<volume>54</volume>, <fpage>2492</fpage>&#x02013;<lpage>2502</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">20946964</pub-id></mixed-citation></ref><ref id="b9"><mixed-citation publication-type="journal"><name><surname>Fan</surname><given-names>Y.</given-names></name>, <name><surname>Duncan</surname><given-names>N. W.</given-names></name>, <name><surname>de Greck</surname><given-names>M.</given-names></name> &#x00026; <name><surname>Northoff</surname><given-names>G.</given-names></name>
<article-title>Is there a core neural network in empathy? an fMRI based quantitative meta-analysis</article-title>. <source>Neurosci. Biobehav. Rev.</source>
<volume>35</volume>, <fpage>903</fpage>&#x02013;<lpage>911</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">20974173</pub-id></mixed-citation></ref><ref id="b10"><mixed-citation publication-type="journal"><name><surname>Bzdok</surname><given-names>D.</given-names></name>
<etal/>. <article-title>Parsing the neural correlates of moral cognition: ALE meta-analysis on morality, theory of mind, and empathy</article-title>. <source>Brain Struct. Funct.</source>
<volume>217</volume>, <fpage>783</fpage>&#x02013;<lpage>796</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22270812</pub-id></mixed-citation></ref><ref id="b11"><mixed-citation publication-type="journal"><name><surname>Benuzzi</surname><given-names>F.</given-names></name>, <name><surname>Lui</surname><given-names>F.</given-names></name>, <name><surname>Duzzi</surname><given-names>D.</given-names></name>, <name><surname>Nichelli</surname><given-names>P. F.</given-names></name> &#x00026; <name><surname>Porro</surname><given-names>C. A.</given-names></name>
<article-title>Does it look painful or disgusting? Ask your parietal and cingulate cortex</article-title>. <source>J. Neurosci. Off. J. Soc. Neurosci.</source>
<volume>28</volume>, <fpage>923</fpage>&#x02013;<lpage>931</lpage> (<year>2008</year>).</mixed-citation></ref><ref id="b12"><mixed-citation publication-type="journal"><name><surname>Farrell</surname><given-names>M. J.</given-names></name>, <name><surname>Laird</surname><given-names>A. R.</given-names></name> &#x00026; <name><surname>Egan</surname><given-names>G. F.</given-names></name>
<article-title>Brain activity associated with painfully hot stimuli applied to the upper limb: a meta-analysis</article-title>. <source>Hum. Brain Mapp.</source>
<volume>25</volume>, <fpage>129</fpage>&#x02013;<lpage>139</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">15846813</pub-id></mixed-citation></ref><ref id="b13"><mixed-citation publication-type="journal"><name><surname>Salimi-Khorshidi</surname><given-names>G.</given-names></name>, <name><surname>Smith</surname><given-names>S. M.</given-names></name>, <name><surname>Keltner</surname><given-names>J. R.</given-names></name>, <name><surname>Wager</surname><given-names>T. D.</given-names></name> &#x00026; <name><surname>Nichols</surname><given-names>T. E.</given-names></name>
<article-title>Meta-analysis of neuroimaging data: a comparison of image-based and coordinate-based pooling of studies</article-title>. <source>Neuroimage</source>
<volume>45</volume>, <fpage>810</fpage>&#x02013;<lpage>823</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19166944</pub-id></mixed-citation></ref><ref id="b14"><mixed-citation publication-type="journal"><name><surname>Murphy</surname><given-names>F. C.</given-names></name>, <name><surname>Nimmo-Smith</surname><given-names>I.</given-names></name> &#x00026; <name><surname>Lawrence</surname><given-names>A. D.</given-names></name>
<article-title>Functional neuroanatomy of emotions: A meta-analysis</article-title>. <source>Cogn. Affect. Behav. Neurosci.</source>
<volume>3</volume>, <fpage>207</fpage>&#x02013;<lpage>233</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">14672157</pub-id></mixed-citation></ref><ref id="b15"><mixed-citation publication-type="journal"><name><surname>Vytal</surname><given-names>K.</given-names></name> &#x00026; <name><surname>Hamann</surname><given-names>S.</given-names></name>
<article-title>Neuroimaging support for discrete neural correlates of basic emotions: a voxel-based meta-analysis</article-title>. <source>J. Cogn. Neurosci.</source>
<volume>22</volume>, <fpage>2864</fpage>&#x02013;<lpage>2885</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19929758</pub-id></mixed-citation></ref><ref id="b16"><mixed-citation publication-type="journal"><name><surname>Sanfey</surname><given-names>A. G.</given-names></name>, <name><surname>Rilling</surname><given-names>J. K.</given-names></name>, <name><surname>Aronson</surname><given-names>J. A.</given-names></name>, <name><surname>Nystrom</surname><given-names>L. E.</given-names></name> &#x00026; <name><surname>Cohen</surname><given-names>J. D.</given-names></name>
<article-title>The neural basis of economic decision-making in the Ultimatum Game</article-title>. <source>Science</source>
<volume>300</volume>, <fpage>1755</fpage>&#x02013;<lpage>1758</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12805551</pub-id></mixed-citation></ref><ref id="b17"><mixed-citation publication-type="journal"><name><surname>Schaich Borg</surname><given-names>J.</given-names></name>, <name><surname>Lieberman</surname><given-names>D.</given-names></name> &#x00026; <name><surname>Kiehl</surname><given-names>K. A.</given-names></name>
<article-title>Infection, incest, and iniquity: investigating the neural correlates of disgust and morality</article-title>. <source>J. Cogn. Neurosci.</source>
<volume>20</volume>, <fpage>1529</fpage>&#x02013;<lpage>1546</lpage> (<year>2008</year>).<pub-id pub-id-type="pmid">18345982</pub-id></mixed-citation></ref><ref id="b18"><mixed-citation publication-type="journal"><name><surname>Gallese</surname><given-names>V.</given-names></name>
<article-title>The manifold nature of interpersonal relations: the quest for a common mechanism</article-title>. <source>Philos. Trans. R. Soc. Lond. B. Biol. Sci.</source>
<volume>358</volume>, <fpage>517</fpage>&#x02013;<lpage>528</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12689377</pub-id></mixed-citation></ref><ref id="b19"><mixed-citation publication-type="journal"><name><surname>Singer</surname><given-names>T.</given-names></name>, <name><surname>Critchley</surname><given-names>H. D.</given-names></name> &#x00026; <name><surname>Preuschoff</surname><given-names>K.</given-names></name>
<article-title>A common role of insula in feelings, empathy and uncertainty</article-title>. <source>Trends Cogn. Sci.</source>
<volume>13</volume>, <fpage>334</fpage>&#x02013;<lpage>340</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19643659</pub-id></mixed-citation></ref><ref id="b20"><mixed-citation publication-type="journal"><name><surname>Eskine</surname><given-names>K. J.</given-names></name>
<article-title>On the representation and processing of social information in grounded cognitive systems: why terminology matters</article-title>. <source>Front. Psychol.</source>
<volume>4</volume>, <fpage>180</fpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23596434</pub-id></mixed-citation></ref><ref id="b21"><mixed-citation publication-type="journal"><name><surname>Kurth</surname><given-names>F.</given-names></name>, <name><surname>Zilles</surname><given-names>K.</given-names></name>, <name><surname>Fox</surname><given-names>P. T.</given-names></name>, <name><surname>Laird</surname><given-names>A. R.</given-names></name> &#x00026; <name><surname>Eickhoff</surname><given-names>S. B.</given-names></name>
<article-title>A link between the systems: functional differentiation and integration within the human insula revealed by meta-analysis</article-title>. <source>Brain Struct. Funct.</source>
<volume>214</volume>, <fpage>519</fpage>&#x02013;<lpage>534</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20512376</pub-id></mixed-citation></ref><ref id="b22"><mixed-citation publication-type="journal"><name><surname>Pritchard</surname><given-names>T. C.</given-names></name>, <name><surname>Hamilton</surname><given-names>R. B.</given-names></name>, <name><surname>Morse</surname><given-names>J. R.</given-names></name> &#x00026; <name><surname>Norgren</surname><given-names>R.</given-names></name>
<article-title>Projections of thalamic gustatory and lingual areas in the monkey, Macaca fascicularis</article-title>. <source>J. Comp. Neurol.</source>
<volume>244</volume>, <fpage>213</fpage>&#x02013;<lpage>228</lpage> (<year>1986</year>).<pub-id pub-id-type="pmid">3950095</pub-id></mixed-citation></ref><ref id="b23"><mixed-citation publication-type="journal"><name><surname>Small</surname><given-names>D. M.</given-names></name>
<article-title>Taste representation in the human insula</article-title>. <source>Brain Struct. Funct.</source>
<volume>214</volume>, <fpage>551</fpage>&#x02013;<lpage>561</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20512366</pub-id></mixed-citation></ref><ref id="b24"><mixed-citation publication-type="journal"><name><surname>Craig</surname><given-names>A. D. B.</given-names></name>, <name><surname>Bushnell</surname><given-names>M. C.</given-names></name>, <name><surname>Zhang</surname><given-names>E.-T.</given-names></name> &#x00026; <name><surname>Blomqvist</surname><given-names>A.</given-names></name>
<article-title>A thalamic nucleus specific for pain and temperature sensation</article-title>. <source>Nature</source>
<volume>372</volume>, <fpage>770</fpage>&#x02013;<lpage>773</lpage> (<year>1994</year>).<pub-id pub-id-type="pmid">7695716</pub-id></mixed-citation></ref><ref id="b25"><mixed-citation publication-type="journal"><name><surname>Craig</surname><given-names>A. D. B.</given-names></name>, <name><surname>Chen</surname><given-names>K.</given-names></name>, <name><surname>Bandy</surname><given-names>D.</given-names></name> &#x00026; <name><surname>Reiman</surname><given-names>E. M.</given-names></name>
<article-title>Thermosensory activation of insular cortex</article-title>. <source>Nat. Neurosci.</source>
<volume>3</volume>, <fpage>184</fpage>&#x02013;<lpage>190</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">10649575</pub-id></mixed-citation></ref><ref id="b26"><mixed-citation publication-type="journal"><name><surname>Segerdahl</surname><given-names>A. R.</given-names></name>, <name><surname>Mezue</surname><given-names>M.</given-names></name>, <name><surname>Okell</surname><given-names>T. W.</given-names></name>, <name><surname>Farrar</surname><given-names>J. T.</given-names></name> &#x00026; <name><surname>Tracey</surname><given-names>I.</given-names></name>
<article-title>The dorsal posterior insula subserves a fundamental role in human pain</article-title>. <source>Nat. Neurosci.</source>
<volume>18</volume>, <fpage>499</fpage>&#x02013;<lpage>500</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25751532</pub-id></mixed-citation></ref><ref id="b27"><mixed-citation publication-type="journal"><name><surname>Legrain</surname><given-names>V.</given-names></name>, <name><surname>Iannetti</surname><given-names>G. D.</given-names></name>, <name><surname>Plaghki</surname><given-names>L.</given-names></name> &#x00026; <name><surname>Mouraux</surname><given-names>A.</given-names></name>
<article-title>The pain matrix reloaded: a salience detection system for the body</article-title>. <source>Prog. Neurobiol.</source>
<volume>93</volume>, <fpage>111</fpage>&#x02013;<lpage>124</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21040755</pub-id></mixed-citation></ref><ref id="b28"><mixed-citation publication-type="journal"><name><surname>Seeley</surname><given-names>W. W.</given-names></name>
<etal/>. <article-title>Dissociable intrinsic connectivity networks for salience processing and executive control</article-title>. <source>J. Neurosci.</source>
<volume>27</volume>, <fpage>2349</fpage>&#x02013;<lpage>2356</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17329432</pub-id></mixed-citation></ref><ref id="b29"><mixed-citation publication-type="journal"><name><surname>Mouraux</surname><given-names>A.</given-names></name>, <name><surname>Diukova</surname><given-names>A.</given-names></name>, <name><surname>Lee</surname><given-names>M. C.</given-names></name>, <name><surname>Wise</surname><given-names>R. G.</given-names></name> &#x00026; <name><surname>Iannetti</surname><given-names>G. D.</given-names></name>
<article-title>A multisensory investigation of the functional significance of the &#x02018;pain matrix'</article-title>. <source>Neuroimage</source>
<volume>54</volume>, <fpage>2237</fpage>&#x02013;<lpage>2249</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">20932917</pub-id></mixed-citation></ref><ref id="b30"><mixed-citation publication-type="journal"><name><surname>Haynes</surname><given-names>J.-D.</given-names></name> &#x00026; <name><surname>Rees</surname><given-names>G.</given-names></name>
<article-title>Predicting the orientation of invisible stimuli from activity in human primary visual cortex</article-title>. <source>Nat. Neurosci.</source>
<volume>8</volume>, <fpage>686</fpage>&#x02013;<lpage>691</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">15852013</pub-id></mixed-citation></ref><ref id="b31"><mixed-citation publication-type="journal"><name><surname>Peelen</surname><given-names>M. V.</given-names></name> &#x00026; <name><surname>Downing</surname><given-names>P. E.</given-names></name>
<article-title>Using multi-voxel pattern analysis of fMRI data to interpret overlapping functional activations</article-title>. <source>Trends Cogn. Sci.</source>
<volume>11</volume>, <fpage>4</fpage>&#x02013;<lpage>5</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17129747</pub-id></mixed-citation></ref><ref id="b32"><mixed-citation publication-type="journal"><name><surname>Corradi-Dell'Acqua</surname><given-names>C.</given-names></name>, <name><surname>Hofstetter</surname><given-names>C.</given-names></name> &#x00026; <name><surname>Vuilleumier</surname><given-names>P.</given-names></name>
<article-title>Cognitive and affective theory of mind share the same local patterns of activity in posterior temporal but not medial prefrontal cortex</article-title>. <source>Soc. Cogn. Affect. Neurosci.</source>
<volume>9</volume>, <fpage>1175</fpage>&#x02013;<lpage>1184</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">23770622</pub-id></mixed-citation></ref><ref id="b33"><mixed-citation publication-type="journal"><name><surname>Tusche</surname><given-names>A.</given-names></name>, <name><surname>Smallwood</surname><given-names>J.</given-names></name>, <name><surname>Bernhardt</surname><given-names>B. C.</given-names></name> &#x00026; <name><surname>Singer</surname><given-names>T.</given-names></name>
<article-title>Classifying the wandering mind: revealing the affective content of thoughts during task-free rest periods</article-title>. <source>Neuroimage</source>
<volume>97</volume>, <fpage>107</fpage>&#x02013;<lpage>116</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24705200</pub-id></mixed-citation></ref><ref id="b34"><mixed-citation publication-type="journal"><name><surname>Sharvit</surname><given-names>G.</given-names></name>, <name><surname>Vuilleumier</surname><given-names>P.</given-names></name>, <name><surname>Delplanque</surname><given-names>S.</given-names></name> &#x00026; <name><surname>Corradi-Dell'Acqua</surname><given-names>C.</given-names></name>
<article-title>Cross-modal and modality-specific expectancy effects between pain and disgust</article-title>. <source>Sci. Rep.</source>
<volume>5</volume>, <fpage>17487</fpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26631975</pub-id></mixed-citation></ref><ref id="b35"><mixed-citation publication-type="journal"><name><surname>Civai</surname><given-names>C.</given-names></name>, <name><surname>Corradi-Dell'Acqua</surname><given-names>C.</given-names></name>, <name><surname>Gamer</surname><given-names>M.</given-names></name> &#x00026; <name><surname>Rumiati</surname><given-names>R. I.</given-names></name>
<article-title>Are irrational reactions to unfairness truly emotionally-driven? dissociated behavioural and emotional responses in the Ultimatum Game task</article-title>. <source>Cognition</source>
<volume>114</volume>, <fpage>89</fpage>&#x02013;<lpage>95</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">19786275</pub-id></mixed-citation></ref><ref id="b36"><mixed-citation publication-type="journal"><name><surname>Civai</surname><given-names>C.</given-names></name>, <name><surname>Crescentini</surname><given-names>C.</given-names></name>, <name><surname>Rustichini</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Rumiati</surname><given-names>R. I.</given-names></name>
<article-title>Equality versus self-interest in the brain: differential roles of anterior insula and medial prefrontal cortex</article-title>. <source>Neuroimage</source>
<volume>62</volume>, <fpage>102</fpage>&#x02013;<lpage>112</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22548807</pub-id></mixed-citation></ref><ref id="b37"><mixed-citation publication-type="journal"><name><surname>Corradi-Dell'Acqua</surname><given-names>C.</given-names></name>, <name><surname>Civai</surname><given-names>C.</given-names></name>, <name><surname>Rumiati</surname><given-names>R. I.</given-names></name> &#x00026; <name><surname>Fink</surname><given-names>G. R.</given-names></name>
<article-title>Disentangling self- and fairness-related neural mechanisms involved in the ultimatum game: an fMRI study</article-title>. <source>Soc. Cogn. Affect. Neurosci.</source>
<volume>8</volume>, <fpage>424</fpage>&#x02013;<lpage>431</lpage> (<year>2013</year>).<pub-id pub-id-type="pmid">22287263</pub-id></mixed-citation></ref><ref id="b38"><mixed-citation publication-type="journal"><name><surname>Feng</surname><given-names>C.</given-names></name>, <name><surname>Luo</surname><given-names>Y.-J.</given-names></name> &#x00026; <name><surname>Krueger</surname><given-names>F.</given-names></name>
<article-title>Neural signatures of fairness-related normative decision making in the ultimate game: a coordinate-based meta-analysis</article-title>. <source>Hum. Brain Mapp.</source>
<volume>36</volume>, <fpage>591</fpage>&#x02013;<lpage>602</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">25327760</pub-id></mixed-citation></ref><ref id="b39"><mixed-citation publication-type="journal"><name><surname>Gabay</surname><given-names>A. S.</given-names></name>, <name><surname>Radua</surname><given-names>J.</given-names></name>, <name><surname>Kempton</surname><given-names>M. J.</given-names></name> &#x00026; <name><surname>Mehta</surname><given-names>M. A.</given-names></name>
<article-title>The Ultimatum Game and the brain: a meta-analysis of neuroimaging studies</article-title>. <source>Neurosci. Biobehav. Rev.</source>
<volume>47</volume>, <fpage>549</fpage>&#x02013;<lpage>558</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">25454357</pub-id></mixed-citation></ref><ref id="b40"><mixed-citation publication-type="journal"><name><surname>Chang</surname><given-names>C.-C.</given-names></name> &#x00026; <name><surname>Lin</surname><given-names>C.-J.</given-names></name>
<article-title>LIBSVM: a library for support vector machines</article-title>. <source>ACM Trans. Intell. Syst. Technol.</source>
<volume>2</volume>, <fpage>27</fpage> (<year>2011</year>).</mixed-citation></ref><ref id="b41"><mixed-citation publication-type="journal"><name><surname>Tusche</surname><given-names>A.</given-names></name>, <name><surname>Bode</surname><given-names>S.</given-names></name> &#x00026; <name><surname>Haynes</surname><given-names>J.-D.</given-names></name>
<article-title>Neural responses to unattended products predict later consumer choices</article-title>. <source>J. Neurosci. Off. J. Soc. Neurosci.</source>
<volume>30</volume>, <fpage>8024</fpage>&#x02013;<lpage>8031</lpage> (<year>2010</year>).</mixed-citation></ref><ref id="b42"><mixed-citation publication-type="journal"><name><surname>Wisniewski</surname><given-names>D.</given-names></name>, <name><surname>Reverberi</surname><given-names>C.</given-names></name>, <name><surname>Tusche</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Haynes</surname><given-names>J.-D.</given-names></name>
<article-title>The neural representation of voluntary task-set selection in dynamic environments</article-title>. <source>Cereb. Cortex</source>
<volume>25</volume>, <fpage>4715</fpage>&#x02013;<lpage>4726</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">25037922</pub-id></mixed-citation></ref><ref id="b43"><mixed-citation publication-type="journal"><name><surname>Woo</surname><given-names>C.-W.</given-names></name>
<etal/>. <article-title>Separate neural representations for physical pain and social rejection</article-title>. <source>Nat. Commun.</source>
<volume>5</volume>, <fpage>5380</fpage> (<year>2014</year>).<pub-id pub-id-type="pmid">25400102</pub-id></mixed-citation></ref><ref id="b44"><mixed-citation publication-type="journal"><name><surname>Craig</surname><given-names>A. D. B.</given-names></name>
<article-title>Interoception: the sense of the physiological condition of the body</article-title>. <source>Curr. Opin. Neurobiol.</source>
<volume>13</volume>, <fpage>500</fpage>&#x02013;<lpage>505</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12965300</pub-id></mixed-citation></ref><ref id="b45"><mixed-citation publication-type="journal"><name><surname>Craig</surname><given-names>A. D. B.</given-names></name>
<article-title>How do you feel--now? The anterior insula and human awareness</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>10</volume>, <fpage>59</fpage>&#x02013;<lpage>70</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19096369</pub-id></mixed-citation></ref><ref id="b46"><mixed-citation publication-type="journal"><name><surname>Evrard</surname><given-names>H. C.</given-names></name>, <name><surname>Logothetis</surname><given-names>N. K.</given-names></name> &#x00026; <name><surname>Craig</surname><given-names>A. D. B.</given-names></name>
<article-title>Modular architectonic organization of the insula in the macaque monkey</article-title>. <source>J. Comp. Neurol.</source>
<volume>522</volume>, <fpage>64</fpage>&#x02013;<lpage>97</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">23900781</pub-id></mixed-citation></ref><ref id="b47"><mixed-citation publication-type="journal"><name><surname>Chikazoe</surname><given-names>J.</given-names></name>, <name><surname>Lee</surname><given-names>D. H.</given-names></name>, <name><surname>Kriegeskorte</surname><given-names>N.</given-names></name> &#x00026; <name><surname>Anderson</surname><given-names>A. K.</given-names></name>
<article-title>Population coding of affect across stimuli, modalities and individuals</article-title>. <source>Nat. Neurosci.</source>
<volume>17</volume>, <fpage>1114</fpage>&#x02013;<lpage>1122</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24952643</pub-id></mixed-citation></ref><ref id="b48"><mixed-citation publication-type="journal"><name><surname>Shackman</surname><given-names>A. J.</given-names></name>
<etal/>. <article-title>The integration of negative affect, pain and cognitive control in the cingulate cortex</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>12</volume>, <fpage>154</fpage>&#x02013;<lpage>167</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21331082</pub-id></mixed-citation></ref><ref id="b49"><mixed-citation publication-type="journal"><name><surname>Craig</surname><given-names>A. D. B.</given-names></name>
<article-title>Forebrain emotional asymmetry: a neuroanatomical basis?</article-title>
<source>Trends Cogn. Sci.</source>
<volume>9</volume>, <fpage>566</fpage>&#x02013;<lpage>571</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">16275155</pub-id></mixed-citation></ref><ref id="b50"><mixed-citation publication-type="journal"><name><surname>Wager</surname><given-names>T. D.</given-names></name>
<etal/>. <article-title>An fMRI-based neurologic signature of physical pain</article-title>. <source>N. Engl. J. Med.</source>
<volume>368</volume>, <fpage>1388</fpage>&#x02013;<lpage>1397</lpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23574118</pub-id></mixed-citation></ref><ref id="b51"><mixed-citation publication-type="journal"><name><surname>Caruana</surname><given-names>F.</given-names></name>, <name><surname>Jezzini</surname><given-names>A.</given-names></name>, <name><surname>Sbriscia-Fioretti</surname><given-names>B.</given-names></name>, <name><surname>Rizzolatti</surname><given-names>G.</given-names></name> &#x00026; <name><surname>Gallese</surname><given-names>V.</given-names></name>
<article-title>Emotional and social behaviors elicited by electrical stimulation of the insula in the macaque monkey</article-title>. <source>Curr. Biol.</source>
<volume>21</volume>, <fpage>195</fpage>&#x02013;<lpage>199</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21256020</pub-id></mixed-citation></ref><ref id="b52"><mixed-citation publication-type="journal"><name><surname>Pillutla</surname><given-names>M. M.</given-names></name> &#x00026; <name><surname>Murnighan</surname><given-names>J. K.</given-names></name>
<article-title>Unfairness, anger, and spite: emotional rejections of ultimatum offers</article-title>. <source>Organ. Behav. Hum. Decis. Process</source>
<volume>68</volume>, <fpage>208</fpage>&#x02013;<lpage>224</lpage> (<year>1996</year>).</mixed-citation></ref><ref id="b53"><mixed-citation publication-type="journal"><name><surname>Rotge</surname><given-names>J.-Y.</given-names></name>
<etal/>. <article-title>A meta-analysis of the anterior cingulate contribution to social pain</article-title>. <source>Soc. Cogn. Affect. Neurosci.</source>
<volume>10</volume>, <fpage>19</fpage>&#x02013;<lpage>27</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25140048</pub-id></mixed-citation></ref><ref id="b54"><mixed-citation publication-type="journal"><name><surname>Eisenberger</surname><given-names>N. I.</given-names></name>
<article-title>Social pain and the brain: controversies, questions, and where to go from here</article-title>. <source>Annu. Rev. Psychol.</source>
<volume>66</volume>, <fpage>601</fpage>&#x02013;<lpage>629</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25251482</pub-id></mixed-citation></ref><ref id="b55"><mixed-citation publication-type="journal"><name><surname>Eisenberger</surname><given-names>N. I.</given-names></name>
<article-title>The pain of social disconnection: examining the shared neural underpinnings of physical and social pain</article-title>. <source>Nat. Rev. Neurosci.</source>
<volume>13</volume>, <fpage>421</fpage>&#x02013;<lpage>434</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22551663</pub-id></mixed-citation></ref><ref id="b56"><mixed-citation publication-type="journal"><name><surname>Tottenham</surname><given-names>N.</given-names></name>
<etal/>. <article-title>The NimStim set of facial expressions: judgments from untrained research participants</article-title>. <source>Psychiatry Res.</source>
<volume>168</volume>, <fpage>242</fpage>&#x02013;<lpage>249</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19564050</pub-id></mixed-citation></ref><ref id="b57"><mixed-citation publication-type="journal"><name><surname>Gracely</surname><given-names>R. H.</given-names></name>, <name><surname>Lota</surname><given-names>L.</given-names></name>, <name><surname>Walter</surname><given-names>D. J.</given-names></name> &#x00026; <name><surname>Dubner</surname><given-names>R.</given-names></name>
<article-title>A multiple random staircase method of psychophysical pain assessment</article-title>. <source>Pain</source>
<volume>32</volume>, <fpage>55</fpage>&#x02013;<lpage>63</lpage> (<year>1988</year>).<pub-id pub-id-type="pmid">3340422</pub-id></mixed-citation></ref><ref id="b58"><mixed-citation publication-type="journal"><name><surname>O'Doherty</surname><given-names>J.</given-names></name>, <name><surname>Rolls</surname><given-names>E. T.</given-names></name>, <name><surname>Francis</surname><given-names>S.</given-names></name>, <name><surname>Bowtell</surname><given-names>R.</given-names></name> &#x00026; <name><surname>McGlone</surname><given-names>F.</given-names></name>
<article-title>Representation of pleasant and aversive taste in the human brain</article-title>. <source>J. Neurophysiol.</source>
<volume>85</volume>, <fpage>1315</fpage>&#x02013;<lpage>1321</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">11248000</pub-id></mixed-citation></ref><ref id="b59"><mixed-citation publication-type="journal"><name><surname>Small</surname><given-names>D. M.</given-names></name>
<etal/>. <article-title>Dissociation of neural representation of intensity and affective valuation in human gustation</article-title>. <source>Neuron</source>
<volume>39</volume>, <fpage>701</fpage>&#x02013;<lpage>711</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12925283</pub-id></mixed-citation></ref><ref id="b60"><mixed-citation publication-type="journal"><name><surname>Green</surname><given-names>B. G.</given-names></name>
<etal/>. <article-title>Evaluating the &#x02018;labelled magnitude scale' for measuring sensations of taste and smell</article-title>. <source>Chem. Senses</source>
<volume>21</volume>, <fpage>323</fpage>&#x02013;<lpage>334</lpage> (<year>1996</year>).<pub-id pub-id-type="pmid">8670711</pub-id></mixed-citation></ref><ref id="b61"><mixed-citation publication-type="journal"><name><surname>Misaki</surname><given-names>M.</given-names></name>, <name><surname>Kim</surname><given-names>Y.</given-names></name>, <name><surname>Bandettini</surname><given-names>P. A.</given-names></name> &#x00026; <name><surname>Kriegeskorte</surname><given-names>N.</given-names></name>
<article-title>Comparison of multivariate classifiers and response normalizations for pattern-information fMRI</article-title>. <source>Neuroimage</source>
<volume>53</volume>, <fpage>103</fpage>&#x02013;<lpage>118</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">20580933</pub-id></mixed-citation></ref><ref id="b62"><mixed-citation publication-type="journal"><name><surname>Boser</surname><given-names>B. E.</given-names></name>, <name><surname>Guyon</surname><given-names>I. M.</given-names></name> &#x00026; <name><surname>Vapnik</surname><given-names>V. N.</given-names></name> in <source>Proceedings of the Fifth Annual Workshop on Computational Learning Theory</source>
<fpage>144</fpage>&#x02013;<lpage>152</lpage>Association for Computing Machinery (<year>1992</year>).</mixed-citation></ref><ref id="b63"><mixed-citation publication-type="journal"><name><surname>Green</surname><given-names>D. M.</given-names></name> &#x00026; <name><surname>Swets</surname><given-names>J. A.</given-names></name>
<source>Signal Detection Theory and Psychophysics</source> Wiley (<year>1966</year>).</mixed-citation></ref><ref id="b64"><mixed-citation publication-type="journal"><name><surname>Combrisson</surname><given-names>E.</given-names></name> &#x00026; <name><surname>Jerbi</surname><given-names>K.</given-names></name>
<article-title>Exceeding chance level by chance: The caveat of theoretical chance levels in brain signal classification and statistical assessment of decoding accuracy</article-title>. <source>J. Neurosci. Methods</source>
<volume>250</volume>, <fpage>126</fpage>&#x02013;<lpage>136</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25596422</pub-id></mixed-citation></ref><ref id="b65"><mixed-citation publication-type="journal"><name><surname>Westfall</surname><given-names>P. H.</given-names></name> &#x00026; <name><surname>Young</surname><given-names>S. S.</given-names></name>
<source>Resampling-Based Multiple Testing: Examples and Methods for P-Value Adjustment</source>
<volume>279</volume>, John Wiley &#x00026; Sons (<year>1993</year>).</mixed-citation></ref><ref id="b66"><mixed-citation publication-type="journal"><name><surname>Li</surname><given-names>Y.-O.</given-names></name>, <name><surname>Adal&#x00131;</surname><given-names>T.</given-names></name> &#x00026; <name><surname>Calhoun</surname><given-names>V. D.</given-names></name>
<article-title>Estimating the number of independent components for functional magnetic resonance imaging data</article-title>. <source>Hum. Brain Mapp.</source>
<volume>28</volume>, <fpage>1251</fpage>&#x02013;<lpage>1266</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17274023</pub-id></mixed-citation></ref><ref id="b67"><mixed-citation publication-type="journal"><name><surname>Bell</surname><given-names>A. J.</given-names></name> &#x00026; <name><surname>Sejnowski</surname><given-names>T. J.</given-names></name>
<article-title>An information-maximization approach to blind separation and blind deconvolution</article-title>. <source>Neural Comput.</source>
<volume>7</volume>, <fpage>1129</fpage>&#x02013;<lpage>1159</lpage> (<year>1995</year>).<pub-id pub-id-type="pmid">7584893</pub-id></mixed-citation></ref><ref id="b68"><mixed-citation publication-type="journal"><name><surname>Himberg</surname><given-names>J.</given-names></name>, <name><surname>Hyv&#x000e4;rinen</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Esposito</surname><given-names>F.</given-names></name>
<article-title>Validating the independent components of neuroimaging time series via clustering and visualization</article-title>. <source>Neuroimage</source>
<volume>22</volume>, <fpage>1214</fpage>&#x02013;<lpage>1222</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">15219593</pub-id></mixed-citation></ref><ref id="b69"><mixed-citation publication-type="journal"><name><surname>Erhardt</surname><given-names>E. B.</given-names></name>
<etal/>. <article-title>Comparison of multi-subject ICA methods for analysis of fMRI data</article-title>. <source>Hum. Brain Mapp.</source>
<volume>32</volume>, <fpage>2075</fpage>&#x02013;<lpage>2095</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21162045</pub-id></mixed-citation></ref><ref id="b70"><mixed-citation publication-type="journal"><name><surname>Tzourio-Mazoyer</surname><given-names>N.</given-names></name>
<etal/>. <article-title>Automated anatomical labeling of activations in SPM using a macroscopic anatomical parcellation of the MNI MRI single-subject brain</article-title>. <source>Neuroimage</source>
<volume>15</volume>, <fpage>273</fpage>&#x02013;<lpage>289</lpage> (<year>2002</year>).<pub-id pub-id-type="pmid">11771995</pub-id></mixed-citation></ref></ref-list><fn-group><fn><p><bold>Author contributions</bold> C.C.-D. and A.T. contributed to the design of the experiment, the acquisition and analysis of the data, and the editing of the manuscript. P.V. and T.S. contributed to the design of the experiment and the editing of the manuscript.</p></fn></fn-group></back><floats-group><fig id="f1"><label>Figure 1</label><caption><title>Trial structure and behavioural results.</title><p>For (<bold>a</bold>) pain, (<bold>b</bold>) disgust and (<bold>c</bold>) ultimatum game (UG) tasks, trials were introduced by an arrow-shaped cue whose orientation and colour informed whether the upcoming event affected either the participants themselves (&#x02193;) or the confederate (&#x02199;). For the UG, cues were also associated with the photo of an unknown proposer. Cues (2&#x02009;s) were followed by a stimulus event of varying unpleasantness (aversive versus neutral). For the pain task, this consisted of a 1-s-long electrical stimulation delivered to the left wrist. For the disgust task, 0.5&#x02009;ml of liquid was delivered into the mouth, which had to be swallowed after 4&#x02009;s when prompted by an instruction screen (3&#x02009;s). To avoid transfer to the next trial, 2&#x02009;ml of water were then delivered in the mouth (3&#x02009;s), again followed by a 3-s swallowing instruction. For the UG, a 4-s screen was presented depicting the offer with 10 coins organized into 2 piles. At the bottom of the screen, the response options &#x02018;accept/reject' were presented. For each task, stimuli were followed by a visual analogue scale, which participants used to rate the subjective unpleasantness evoked by the previous stimulation. Inter-trial intervals (ITI) in all three tasks varied from 2.5 to 7.5&#x02009;s (average 5&#x02009;s). For each task, average unpleasantness ratings are displayed in separate subplots (single experiment, sample size <italic>N</italic>=19). White bars refer to stimuli directed to the participants (self), whereas striped bars refer to stimuli directed to the confederates (other). For each subplot, aversive and neutral events are displayed separately along the horizontal axis. Error bars refer to bootstrap-based 95&#x00025; confidence intervals.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ncomms10904-f1"/></fig><fig id="f2"><label>Figure 2</label><caption><title>ROIs and MVPA overview.</title><p>(<bold>a</bold>) Independent component analysis performed on participants' resting-state data, to map the AI&#x02013;mACC network<xref ref-type="bibr" rid="b28">28</xref> in an unbiased manner (surface rendering displayed at <italic>P</italic>&#x0003c;0.001). ROIs were based on significant clusters in the bilateral AI and mACC that were then used for MVPA on independent functional data obtained for the pain, disgust and UG tasks. (<bold>b</bold>) Processing steps in MVPA. For each ROI, data were extracted from every constitutive voxels and fed to a SVM classifier<xref ref-type="bibr" rid="b40">40</xref><xref ref-type="bibr" rid="b62">62</xref>, to identify multivoxel patterns informative about an aversive event relative to its corresponding neutral control (for example, Ps versus nPs). The so trained classifier was then tested on independent data from the same task (within-task classification) or another task, for example, when aversive experiences occur in a different sensory modality (cross-modal classification). (<bold>c</bold>) Matrixes displaying the results of within-task, cross-target and cross-modal classifications for each of the three ROIs. In each matrix, row and column labels refer to classification of an aversive state, each relative to its corresponding neutral control: self-related pain (Ps), self-related disgust (Ds), other-related pain (Po), other-related disgust (Do) and unfairness (U). <italic>D'</italic> values from within-task classifications are displayed in the outer diagonal line of the matrixes. The remaining cells in the matrixes reflect cross-target and cross-modal classifications. White striped cells refer to <italic>d&#x02032;</italic> effects which are not significantly higher-than-chance, whereas green cells refer to effects significantly higher-than-chance. The luminance of green cells reflects the magnitude of the <italic>d&#x02032;</italic> values. Single experiment, sample size <italic>N</italic>=19.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ncomms10904-f2"/></fig><fig id="f3"><label>Figure 3</label><caption><title>Bar plots displaying <italic>d&#x02032;</italic> values from MVPA analyses in left AI, mACC and right AI.</title><p>(<bold>a</bold>) Self-pain and -disgust. Bar plots display <italic>d&#x02032;</italic> values representing the ability of a linear kernel SVM classifier to detect activity patterns characteristic for first-person experience of pain and disgust in ROIs in left AI, mACC and right AI. Ps and Ds refer to within-task classifications of self-related pain (Ps) and self-related disgust (Ds) compared with their respective neutral controls. Ps&#x02194;Ds refers to cross-modal classifications between both self-related aversive events. (<bold>b</bold>) Others' pain and disgust. <italic>D'</italic> values reflect within-task classification of other-related pain (Po) and disgust (Do) compared with their respective neutral controls, as well as cross-target classifications between aversive events directed at self and other for same modality (Ps&#x02194;Po; Ds&#x02194;Do) and different modality (Ds&#x02194;Po; Ps&#x02194;Do). (<bold>c</bold>) Ultimatum game. Bar plots display <italic>d&#x02032;</italic> values related to the within-task classification of unfair events (U) compared with midfair events; and the cross-modal classification between unfairness and first-person pain (Ps&#x02194;U) or first-person disgust (Ds&#x02194;U). Bars are coloured consistently to the corresponding cells in the classification matrixes displayed in each panel. The significance of permutation tests comparing <italic>d&#x02032;</italic> values against chance (or against values from other conditions) are also reported. &#x0002a;&#x0002a;<italic>P</italic>&#x0003c;0.05 corrected for multiple comparisons for the three ROIs; &#x0002a;<italic>P</italic>&#x0003c;0.05 uncorrected. Error bars refer to bootstrap-based 95&#x00025; confidence intervals. Single experiment, sample size <italic>N</italic>=19.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="ncomms10904-f3"/></fig><table-wrap position="float" id="t1"><label>Table 1</label><caption><title>Within-task pattern analysis.</title></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="left"/></colgroup><thead valign="bottom"><tr><th align="left" valign="top" charoff="50">&#x000a0;</th><th align="center" valign="top" charoff="50"><italic>d'</italic> (corrected cutoff)</th></tr></thead><tbody valign="top"><tr><td colspan="2" align="center" valign="top" charoff="50"><italic>Left AI</italic></td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic> versus <italic>nPs</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.98</bold> (0.32)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic> versus <italic>nDs</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.61</bold> (0.29)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Po</italic> versus <italic>nPo</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.49</bold> (0.27)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Do</italic> versus <italic>nDo</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.24</bold> (0.26)&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Us</italic> versus <italic>Ms</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.30</bold> (0.28)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Uo</italic> versus <italic>Mo</italic></td><td align="char" valign="top" char="(" charoff="50">0.19 (0.20)<sup>&#x02020;</sup></td></tr><tr><td align="left" valign="top" charoff="50">&#x000a0;</td><td align="left" valign="top" charoff="50">&#x000a0;</td></tr><tr><td colspan="2" align="center" valign="top" charoff="50"><italic>Right AI</italic></td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic> versus <italic>nPs</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>1.29</bold> (0.32)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic> versus <italic>nDs</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.49</bold> (0.29)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Po</italic> versus <italic>nPo</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.36</bold> (0.27)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Do</italic> versus <italic>nDo</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.40</bold> (0.26)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Us</italic> versus <italic>Ms</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.33</bold> (0.28)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Uo</italic> versus <italic>Mo</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.38</bold> (0.28)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x000a0;</td><td align="left" valign="top" charoff="50">&#x000a0;</td></tr><tr><td colspan="2" align="center" valign="top" charoff="50"><italic>mACC</italic></td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic> versus <italic>nPs</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>1.61</bold> (0.32)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic> versus <italic>nDs</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.65</bold> (0.29)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Po</italic> versus <italic>nPo</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.46</bold> (0.27)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Do</italic> versus <italic>nDo</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.53</bold> (0.26)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Us</italic> versus <italic>Ms</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.77</bold> (0.28)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Uo</italic> versus <italic>Mo</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.76</bold> (0.28)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x000a0;</td><td>&#x000a0;</td></tr><tr><td align="left" valign="top" charoff="50">&#x000a0;</td><td align="center" valign="top" charoff="50"><bold><italic>F</italic> (cutoff)</bold></td></tr><tr><td align="left" valign="top" charoff="50"><italic>Rep. Meas. ANOVA</italic></td><td align="center" valign="top" charoff="50">&#x000a0;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic> versus <italic>nPs</italic></td><td align="char" valign="top" char="(" charoff="50">1.96 (3.54)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic> versus <italic>nDs</italic></td><td align="char" valign="top" char="(" charoff="50">0.62 (3.00)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Po</italic> versus <italic>nPo</italic></td><td align="char" valign="top" char="(" charoff="50">0.21 (3.35)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Do</italic> versus <italic>nDo</italic></td><td align="char" valign="top" char="(" charoff="50">0.91 (3.21)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Us</italic> versus <italic>Ms</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>3.18</bold> (3.12)&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Uo</italic> versus <italic>Mo</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>4.57</bold> (3.25)&#x0002a;</td></tr></tbody></table><table-wrap-foot><fn id="t1-fn1"><p>AI, anterior insula; ANOVA, analysis of variance; mACC, mid-anterior cingulate cortex; MVPA, multivoxel pattern analysis; ROI, region-of-interest.</p></fn><fn id="t1-fn2"><p>&#x0002a;&#x0002a;<italic>P</italic>&#x0003c;0.05, &#x0002a;<italic>P</italic>&#x0003c;0.05 under uncorrected cutoff, <sup>&#x02020;</sup><italic>P</italic>=0.06.</p></fn><fn id="t1-fn3"><p>For each ROI, MVPA was conducted to assess the presence of multivoxel activity patterns discriminative of one negative condition relative to its tailored neutral control. Detection of negative events was measured as <italic>d&#x02032;</italic> coefficients. Higher-than-chance detections are reported when <italic>d&#x02032;</italic> values exceeded the 95th percentile of null <italic>d&#x02032;</italic>-distribution (cutoff), obtained with 1,000 replications of the analysis on permuted data sets (see Methods section). F values (and corresponding permutation-based cutoffs) from repeated measure ANOVAs testing for ROI differences are also reported. Significant effects are highlighted with corresponding <italic>P</italic> values in the table.</p></fn></table-wrap-foot></table-wrap><table-wrap position="float" id="t2"><label>Table 2</label><caption><title>Cross-modal and cross-target pattern analysis.</title></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="left"/></colgroup><thead valign="bottom"><tr><th align="left" valign="top" charoff="50">&#x000a0;</th><th align="center" valign="top" charoff="50"><italic>d'</italic> (corrected cutoff)</th></tr></thead><tbody valign="top"><tr><td colspan="2" align="center" valign="top" charoff="50"><italic>Left AI</italic></td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Ds</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.31</bold> (0.18)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Po</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.21</bold> (0.20)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>Do</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.19</bold> (0.19)&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Do</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.30</bold> (0.20)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>Po</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.18</bold> (0.20)&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>U</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.27</bold> (0.17)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>U</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.32</bold> (0.16)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x000a0;</td><td align="left" valign="top" charoff="50">&#x000a0;</td></tr><tr><td colspan="2" align="center" valign="top" charoff="50"><italic>Right AI</italic></td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Ds</italic></td><td align="char" valign="top" char="(" charoff="50">0.02 (0.18)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Po</italic></td><td align="char" valign="top" char="(" charoff="50">0.11 (0.20)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>Do</italic></td><td align="char" valign="top" char="(" charoff="50">0.12 (0.19)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Do</italic></td><td align="char" valign="top" char="(" charoff="50">0.10 (0.20)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>Po</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.23</bold> (0.20)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>U</italic></td><td align="char" valign="top" char="(" charoff="50">0.03 (0.17)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>U</italic></td><td align="char" valign="top" char="(" charoff="50">0.03 (0.16)</td></tr><tr><td align="left" valign="top" charoff="50">&#x000a0;</td><td align="left" valign="top" charoff="50">&#x000a0;</td></tr><tr><td colspan="2" align="center" valign="top" charoff="50"><italic>mACC</italic></td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Ds</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.63</bold> (0.18)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Po</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.35</bold> (0.20)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>Do</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.25</bold> (0.19)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Do</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.59</bold> (0.20)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>Po</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.43</bold> (0.20)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>U</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.44</bold> (0.17)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>U</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>0.24</bold> (0.16)&#x0002a;&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x000a0;</td><td>&#x000a0;</td></tr><tr><td align="left" valign="top" charoff="50">&#x000a0;</td><td align="center" valign="top" charoff="50"><bold><italic>F</italic> (cutoff)</bold></td></tr><tr><td align="left" valign="top" charoff="50"><italic>Rep. Meas. ANOVA</italic></td><td align="center" valign="top" charoff="50">&#x000a0;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Ds</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>6.77</bold> (3.39)&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Po</italic></td><td align="char" valign="top" char="(" charoff="50">1.66 (3.14)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>Do</italic></td><td align="char" valign="top" char="(" charoff="50">0.36 (3.06)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>Do</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>4.08</bold> (3.21)&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>Po</italic></td><td align="char" valign="top" char="(" charoff="50">1.54 (3.35)</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ps</italic>&#x02194;<italic>U</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>4.56</bold> (3.53)&#x0002a;</td></tr><tr><td align="left" valign="top" charoff="50">&#x02003;<italic>Ds</italic>&#x02194;<italic>U</italic></td><td align="char" valign="top" char="(" charoff="50"><bold>2.87</bold> (3.16)<sup>&#x02020;</sup></td></tr></tbody></table><table-wrap-foot><fn id="t2-fn1"><p>AI, anterior insula; ANOVA, analysis of variance; mACC, mid-anterior cingulate cortex; MVPA, multivoxel pattern analysis; ROI, region-of-interest.</p></fn><fn id="t2-fn2"><p>&#x0002a;&#x0002a;<italic>P</italic>&#x0003c;0.05, &#x0002a;<italic>P</italic>&#x0003c;0.05 under uncorrected cutoff; <sup>&#x02020;</sup>F test <italic>P</italic> (one-tailed)=0.05.</p></fn><fn id="t2-fn3"><p>For each ROI, MVPA was conducted to assess whether multivoxel activity patterns discriminative of one specific unpleasant experience (for example, self-pain) could detect unpleasantness of another modality/target. Detection of negative events was measured as <italic>d&#x02032;</italic> coefficients. Higher than chance detections are reported when <italic>d&#x02032;</italic> values exceeded the 95th percentile of the null <italic>d&#x02032;</italic>-distribution (cutoff), obtained with 1,000 replications of the analysis on permuted data sets (see Methods). F values (and corresponding permutation-based cutoffs) from repeated measure ANOVAs testing for differences in <italic>d&#x02032;</italic>s across ROI are also reported. Significant effects are highlighted with corresponding <italic>P</italic> values.</p></fn></table-wrap-foot></table-wrap></floats-group></article>