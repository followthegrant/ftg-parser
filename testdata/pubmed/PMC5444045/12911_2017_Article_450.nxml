<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">BMC Med Inform Decis Mak</journal-id><journal-id journal-id-type="iso-abbrev">BMC Med Inform Decis Mak</journal-id><journal-title-group><journal-title>BMC Medical Informatics and Decision Making</journal-title></journal-title-group><issn pub-type="epub">1472-6947</issn><publisher><publisher-name>BioMed Central</publisher-name><publisher-loc>London</publisher-loc></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28539122</article-id><article-id pub-id-type="pmc">5444045</article-id><article-id pub-id-type="publisher-id">450</article-id><article-id pub-id-type="doi">10.1186/s12911-017-0450-4</article-id><article-categories><subj-group subj-group-type="heading"><subject>Research</subject></subj-group></article-categories><title-group><article-title>An inference method from multi-layered structure of biomedical data</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Kim</surname><given-names>Myungjun</given-names></name><address><email>junkim930@ajou.ac.kr</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author"><name><surname>Nam</surname><given-names>Yonghyun</given-names></name><address><email>namyh123@ajou.ac.kr</email></address><xref ref-type="aff" rid="Aff1"/></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Shin</surname><given-names>Hyunjung</given-names></name><address><email>shin@ajou.ac.kr</email></address><xref ref-type="aff" rid="Aff1"/></contrib><aff id="Aff1"><institution-wrap><institution-id institution-id-type="ISNI">0000 0004 0532 3933</institution-id><institution-id institution-id-type="GRID">grid.251916.8</institution-id><institution>Department of Industrial Engineering, </institution><institution>Ajou University, </institution></institution-wrap>206 Worldcup-ro, Yeongtong-gu, Suwon 16499 South Korea </aff></contrib-group><pub-date pub-type="epub"><day>18</day><month>5</month><year>2017</year></pub-date><pub-date pub-type="pmc-release"><day>18</day><month>5</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>17</volume><issue>Suppl 1</issue><issue-sponsor>Publication of this supplement has not been supported by sponsorship. Information about the source of funding for publication charges can be found in the individual articles. The articles have undergone the journal's standard peer review process for supplements. The Supplement Editors declare that they have no competing interests.</issue-sponsor><elocation-id>52</elocation-id><permissions><copyright-statement>&#x000a9; The Author(s). 2017</copyright-statement><license license-type="OpenAccess"><license-p>
<bold>Open Access</bold>This article is distributed under the terms of the Creative Commons Attribution 4.0 International License (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link>), which permits unrestricted use, distribution, and reproduction in any medium, provided you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The Creative Commons Public Domain Dedication waiver (<ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/publicdomain/zero/1.0/">http://creativecommons.org/publicdomain/zero/1.0/</ext-link>) applies to the data made available in this article, unless otherwise stated.</license-p></license></permissions><abstract id="Abs1"><sec><title>Background</title><p>Biological system is a multi-layered structure of omics with genome, epigenome, transcriptome, metabolome, proteome, etc., and can be further stretched to clinical/medical layers such as diseasome, drugs, and symptoms. One advantage of omics is that we can figure out an unknown component or its trait by inferring from known omics components. The component can be inferred by the ones in the same level of omics or the ones in different levels.</p></sec><sec><title>Methods</title><p>To implement the inference process, an algorithm that can be applied to the multi-layered complex system is required. In this study, we develop a semi-supervised learning algorithm that can be applied to the multi-layered complex system. In order to verify the validity of the inference, it was applied to the prediction problem of disease co-occurrence with a two-layered network composed of symptom-layer and disease-layer.</p></sec><sec><title>Results</title><p>The symptom-disease layered network obtained a fairly high value of AUC, 0.74, which is regarded as noticeable improvement when comparing 0.59 AUC of single-layered disease network. If further stretched to whole layered structure of omics, the proposed method is expected to produce more promising results.</p></sec><sec><title>Conclusion</title><p>This research has novelty in that it is a new integrative algorithm that incorporates the vertical structure of omics data, on contrary to other existing methods that integrate the data in parallel fashion. The results can provide enhanced guideline for disease co-occurrence prediction, thereby serve as a valuable tool for inference process of multi-layered biological system.</p></sec></abstract><kwd-group xml:lang="en"><title>Keywords</title><kwd>Integrative inference on biomedical data</kwd><kwd>Semi-supervised learning</kwd><kwd>Semi-supervised learning for multiple networks</kwd><kwd>Symptom-disease multi-layered network</kwd><kwd>Disease co-occurrence prediction</kwd></kwd-group><conference><conf-name>The 6th Translational Bioinformatics Conference</conf-name><conf-acronym>TBC 2016</conf-acronym><conf-loc>Je Ju Island, Korea</conf-loc><conf-date>15-17 October 2016</conf-date></conference><custom-meta-group><custom-meta><meta-name>issue-copyright-statement</meta-name><meta-value>&#x000a9; The Author(s) 2017</meta-value></custom-meta></custom-meta-group></article-meta></front><body><sec id="Sec1"><title>Background</title><p>Omics is a comprehensive study of a specific layer in a cellular system [<xref ref-type="bibr" rid="CR1">1</xref>] and the molecular components in each layer constitute the biological system. These layers include genome, epigenome, transcriptome, metabolome, proteome, etc., and can further be extended to clinical/medical layers such as diseasome, drugs, and symptoms. There exist complex interactions between each layers, such as translation, transcription, and reactions, and such interactions allow us to view biological system as a multi-layered structure of omics. In recent years, there has been great advances in high throughput experimental techniques and brought influx of omics data including DNA sequence data, mRNA, miRNA, methylation patterns, etc [<xref ref-type="bibr" rid="CR2">2</xref>]. While there had been many works concerning single layer of omics data, complex interactions between different layers hinder one from capturing comprehensive information on total system. Therefore, comprehensive analysis of multiple omics is required for more profound understanding of the total biological system [<xref ref-type="bibr" rid="CR3">3</xref>]. One integrative approach for multiple levels of information that is receiving much attention is network-based or graph-based approach. A network or a graph concerning omics data consists of nodes and edges, where nodes represent biological components, such as genes or diseases, and edges represent relationships or interactions among them [<xref ref-type="bibr" rid="CR4">4</xref>]. The main reason for the popularity of network-based analysis of biological system lies on the fact that the network structure can captures associations of biological components while managing large amount of data [<xref ref-type="bibr" rid="CR5">5</xref>]. The network can vary from gene co-expression networks [<xref ref-type="bibr" rid="CR6">6</xref>&#x02013;<xref ref-type="bibr" rid="CR9">9</xref>], protein networks [<xref ref-type="bibr" rid="CR10">10</xref>&#x02013;<xref ref-type="bibr" rid="CR13">13</xref>], metabolic networks [<xref ref-type="bibr" rid="CR14">14</xref>, <xref ref-type="bibr" rid="CR15">15</xref>], disease networks [<xref ref-type="bibr" rid="CR16">16</xref>, <xref ref-type="bibr" rid="CR17">17</xref>], and many more, for single layered networks while multi-layered networks can be created by connecting the layers using data that reflects interactions between different layers [<xref ref-type="bibr" rid="CR18">18</xref>].</p><p>Given a multi-layered network, one can extend the usage of such networks by implementing prediction process for finding traits (or labels) of interest with machine learning algorithms. While many traits have been discovered in numerous studies, there still remain a large room for finding more unknown traits of biological components. Instead of leaving unknown components in dark space, one can utilize both known and unknown components with semi-supervised learning. Semi-supervised learning (SSL), in general, deals with both labeled and unlabeled data where labeled data are given scarcely compared to vast amount of unlabeled data, and obtaining labels for unknown traits is costly. In this sense, SSL can serve as a cost-effective tool for prediction process [<xref ref-type="bibr" rid="CR19">19</xref>]. For SSL in network setting [<xref ref-type="bibr" rid="CR20">20</xref>&#x02013;<xref ref-type="bibr" rid="CR24">24</xref>], the key idea is the &#x02018;label propagation&#x02019; [<xref ref-type="bibr" rid="CR25">25</xref>] where known labels propagate to neighboring unlabeled data points through edges. Through label propagation and basic kernel of graphs using graph Laplacian [<xref ref-type="bibr" rid="CR26">26</xref>], we obtain predictive values for unlabeled data, which we can utilize for prediction process for networks of biological systems.</p><p>In past works, there have been extensive studies incorporating SSL for various omics data. In [<xref ref-type="bibr" rid="CR27">27</xref>&#x02013;<xref ref-type="bibr" rid="CR29">29</xref>] graph integration method, consisting of finding convex combination of graph Laplacians, is applied to four different types of yeast protein networks along with SSL to predict protein functions and also extends to protein function prediction by incorporating deletion process of noisy connections [<xref ref-type="bibr" rid="CR30">30</xref>]. For more practical purpose on clinical data, [<xref ref-type="bibr" rid="CR31">31</xref>&#x02013;<xref ref-type="bibr" rid="CR33">33</xref>] applies graph integration methods on multiple graphs from CNA, methylation, miRNA, and gene expression along with SSL to predict clinical outcomes of cancer. In [<xref ref-type="bibr" rid="CR34">34</xref>], SSL schemes are applied to predict disease genes from protein-protein interaction network, constructed with multiple proteomics and genomic data. In [<xref ref-type="bibr" rid="CR35">35</xref>], SSL was applied to predict synthetic genetic interactions from integrated network of protein-protein interaction, protein complex, and gene expression data. For inter-layer relationships, [<xref ref-type="bibr" rid="CR36">36</xref>] provides algorithms for reconstructing intra-layer relations by utilizing SSL and inter-layer relations between different levels of genomic data. In [<xref ref-type="bibr" rid="CR37">37</xref>], the authors provides miRNA-disease associations by utilizing SSL algorithm. In [<xref ref-type="bibr" rid="CR38">38</xref>], SSL was applied to for disease comorbidity scoring for complemented disease network of metabolic disease group.</p><p>Most of the above works, however, only consider integrating multiple sources of data in parallel fashion, ignoring hierarchical, or vertical structure of multi-omics data. Furthermore, only few machine learning algorithms, including SSL, deals with networks of vertical structure. The purpose of the paper is to develop a semi-supervised learning algorithm for multiple layered networks that utilize matrix separation and graph integration method in vertical fashion. For biological systems, however, vast number of components in each layers and countless unknown relations between different layers cause issues of computational complexity and sparseness for analyzing with multi-layered networks. To alleviate the problems, we propose an efficient matrix inversion algorithm composed with Nystr&#x000f6;m method [<xref ref-type="bibr" rid="CR39">39</xref>] and Woodbury formula [<xref ref-type="bibr" rid="CR40">40</xref>]. The remainder of the paper is organized as the following. In <xref rid="Sec2" ref-type="sec">Methods</xref>, we discuss graph based semi-supervised learning for multiple-layered networks. In <xref rid="Sec7" ref-type="sec">Experiments</xref> and <xref rid="Sec10" ref-type="sec">Results and Discussion</xref>, we present experimental results of the proposed algorithm that was applied to disease co-occurrence prediction problem on two layered network of symptom and disease.</p></sec><sec id="Sec2"><title>Methods</title><sec id="Sec3"><title>Graph based semi-supervised learning</title><p>In graph based semi-supervised learning, a set of data can be represented by a graph <italic>G</italic>(<italic>V, E</italic>) which consists of nodes (<italic>V</italic>) and edges (<italic>E</italic>). Given a graph <italic>G</italic>(<italic>V, E</italic>) for <italic>n</italic> data points, nodes represent data points with <italic>V</italic>&#x02009;=&#x02009;{<italic>x</italic>
<sub>1</sub>,&#x000a0;<italic>x</italic>
<sub>2</sub>,&#x000a0;&#x02026;,&#x000a0;<italic>x</italic>
<sub><italic>n</italic></sub>_<italic>tween&#x000a0;dats&#x000a0;epresetn</italic>&#x000a0;}. and edges represent similarities between data points. The similarities are given by the weight matrix <italic>W</italic>, where elements, <italic>W</italic>
<sub><italic>ij</italic></sub>, of <italic>W</italic> represent strength of connection between nodes <italic>x</italic>
<sub><italic>i</italic></sub> and <italic>x</italic>
<sub><italic>j</italic></sub>. The problem of semi-supervised learning on graph <italic>G</italic>(<italic>V, E</italic>) deals with labeled and unlabeled nodes where labeling is given by <italic>Y</italic>&#x02009;=&#x02009;{<italic>Y</italic>
<sub><italic>l</italic></sub>,&#x000a0;<italic>Y</italic>
<sub><italic>u</italic></sub>} with <italic>Y</italic>
<sub><italic>l</italic></sub>&#x02009;&#x02208;&#x02009;{&#x02212;1,&#x000a0;1} for labeled nodes and <italic>Y</italic>
<sub><italic>u</italic></sub>&#x02009;=&#x02009;0 for unlabeled nodes. Through learning process, we determine the output vector <italic>f</italic>&#x02009;=&#x02009;(<italic>f</italic>
<sub>1</sub>,&#x02009;<italic>f</italic>
<sub>2</sub>,&#x000a0;&#x02026;,&#x000a0;<italic>f</italic>
<sub><italic>n</italic></sub>)<sup><italic>T</italic></sup> using available information and minimizing the following quadratic cost functional [<xref ref-type="bibr" rid="CR41">41</xref>]:<disp-formula id="Equ1"><label>1</label><alternatives><tex-math id="M1">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \begin{array}{c}\hfill \mathrm{minimize}\hfill \\ {}\hfill f\hfill \end{array}\ {\displaystyle \sum_i^n}{\left({f}_i-{Y}_i\right)}^2+\mu {\displaystyle \sum_{i, j}^n}{W}_{i j}{\left({f}_i-{f}_j\right)}^2. $$\end{document}</tex-math><mml:math id="M2"><mml:mtable columnalign="center"><mml:mtr columnalign="center"><mml:mtd columnalign="center"><mml:mi mathvariant="normal">minimize</mml:mi></mml:mtd></mml:mtr><mml:mtr columnalign="center"><mml:mtd columnalign="center"><mml:mi>f</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mspace width="0.25em"/><mml:mstyle displaystyle="true"><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>&#x003bc;</mml:mi><mml:mstyle displaystyle="true"><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ1.gif" position="anchor"/></alternatives></disp-formula>
</p><p>By the symmetry of the weight matrix, problem (<xref rid="Equ1" ref-type="">1</xref>) can be translated into<disp-formula id="Equ2"><label>2</label><alternatives><tex-math id="M3">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \begin{array}{c}\hfill \mathrm{minimize}\hfill \\ {}\hfill f\hfill \end{array}\ {\left( f- Y\right)}^T\left( f- Y\right)+\mu {f}^T L f, $$\end{document}</tex-math><mml:math id="M4"><mml:mtable columnalign="center"><mml:mtr columnalign="center"><mml:mtd columnalign="center"><mml:mi mathvariant="normal">minimize</mml:mi></mml:mtd></mml:mtr><mml:mtr columnalign="center"><mml:mtd columnalign="center"><mml:mi>f</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mspace width="0.25em"/><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>f</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:mfenced><mml:mi>T</mml:mi></mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>f</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:mi>&#x003bc;</mml:mi><mml:msup><mml:mi>f</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mi>L</mml:mi><mml:mi>f</mml:mi><mml:mtext>,</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ2.gif" position="anchor"/></alternatives></disp-formula>where <italic>L</italic> is the graph Laplacian [<xref ref-type="bibr" rid="CR26">26</xref>] defined as <italic>D&#x02013;W</italic> for <italic>D</italic>&#x02009;=&#x02009;<italic>diag</italic>(<italic>d</italic>
<sub><italic>i</italic></sub>) and <italic>d</italic>
<sub><italic>i</italic></sub>&#x02009;=&#x02009;&#x02211;<sub><italic>j</italic></sub>
<italic>W</italic>
<sub><italic>ij</italic></sub>. In (<xref rid="Equ2" ref-type="">2</xref>), the first term is the loss term for consistency with initial labeling, the second term is the smoothness term for consistency with geometry of the data, and &#x003bc; is a parameter for trade-off between the loss term and the smoothness term [<xref ref-type="bibr" rid="CR41">41</xref>]. The solution to minimization problem (<xref rid="Equ2" ref-type="">2</xref>) is given by:<disp-formula id="Equ3"><label>3</label><alternatives><tex-math id="M5">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ f={\left( I+\mu L\right)}^{-1} Y, $$\end{document}</tex-math><mml:math id="M6"><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:mi mathvariant="italic">&#x003bc;L</mml:mi></mml:mrow></mml:mfenced><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mtext>,</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ3.gif" position="anchor"/></alternatives></disp-formula>where I is the identity matrix.</p></sec><sec id="Sec4"><title>Semi-supervised learning for multi-layered biomedical data</title><p>For multi-layered biomedical data, it can be represented by multi-layered graph, <italic>G</italic>(<italic>V, E, S</italic>), which consists of nodes (<italic>V</italic>), edges (<italic>E</italic>), and strata (<italic>S</italic>). In addition to nodes and edges, strata in <italic>G</italic>(<italic>V, E, S</italic>) denote <italic>K</italic> distinct layers with <italic>S</italic>&#x02009;=&#x02009;{<italic>S</italic>
<sub>1</sub>,&#x000a0;<italic>S</italic>
<sub>2</sub>,&#x000a0;&#x02026;,&#x000a0;<italic>S</italic>
<sub><italic>K</italic></sub>}. Each <italic>G</italic>(<italic>V, E, S</italic>) contains intra- and inter-layer relations, where the former characterize relations between two nodes in same layer and the latter characterize relations between two nodes each of which belongs to different adjacent layer. Given a graph <italic>G</italic>(<italic>V, E, S</italic>) with <italic>K</italic> number of layers and <italic>n</italic>
<sub><italic>k</italic></sub> data points for each layer <italic>k</italic>, the weight matrix <italic>W</italic> is a <italic>N</italic>&#x02009;&#x000d7;&#x02009;<italic>N</italic>, where <italic>N</italic>&#x02009;=&#x02009;<italic>n</italic>
<sub>1</sub>&#x02009;+&#x02009;<italic>n</italic>
<sub>2</sub>&#x02009;+&#x02009;&#x02026;&#x02009;+&#x02009;<italic>n</italic>
<sub><italic>K</italic></sub>, block tri-diagonal matrix with 3<italic>K</italic>&#x02009;&#x02212;&#x02009;2 non-zero blocks. <italic>K</italic> symmetric diagonal blocks represent intra-layer relations and 2<italic>K</italic>&#x02009;&#x02212;&#x02009;2 rectangular banded diagonal blocks represent inter-layer relations. Figure&#x000a0;<xref rid="Fig1" ref-type="fig">1</xref> depicts a multi-layered graph for three layers with structure of its corresponding weight matrix. An exemplary network would be a multi-layered network with <italic>S</italic>
<sub>1</sub>, <italic>S</italic>
<sub>2</sub>, and <italic>S</italic>
<sub>3</sub> as symptoms, diseases, and proteins, respectively, in the context of disease co-occurrence prediction. To incorporate graph based semi-supervised learning into multi-layered omics systems, we first apply matrix separation on the weight matrix, <italic>W</italic>, then implement graph integration method [<xref ref-type="bibr" rid="CR28">28</xref>].<fig id="Fig1"><label>Fig. 1</label><caption><p>Multi-layered graph for three layers with block tri-diagonal structure of its weight matrix</p></caption><graphic xlink:href="12911_2017_450_Fig1_HTML" id="MO1"/></fig>
</p><p>First, matrix separation is a representation of a block matrix with summation of its sub-matrices of same dimension with associated blocks. For the weight matrix <italic>W</italic> in a multi-layered graph, let <inline-formula id="IEq1"><alternatives><tex-math id="M7">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {W}^{\left\{{S}_p,\ {S}_q\right\}} $$\end{document}</tex-math><mml:math id="M8"><mml:msup><mml:mi>W</mml:mi><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:msup></mml:math><inline-graphic xlink:href="12911_2017_450_Article_IEq1.gif"/></alternatives></inline-formula> be a matrix that only contains a sub-block of <italic>W</italic> associated with stratum <italic>S</italic>
<sub><italic>p</italic></sub> and <italic>S</italic>
<sub><italic>q</italic></sub>, masking other blocks to zeros. Then, we have<disp-formula id="Equ4"><label>4</label><alternatives><tex-math id="M9">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ W={\displaystyle \sum_{S_p,{S}_q}^K}{W}^{\left\{{S}_p,\ {S}_q\right\}}, $$\end{document}</tex-math><mml:math id="M10"><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mstyle><mml:msup><mml:mi>W</mml:mi><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:msup><mml:mtext>,</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ4.gif" position="anchor"/></alternatives></disp-formula>where <italic>S</italic>
<sub><italic>p</italic></sub>&#x02009;=&#x02009;<italic>S</italic>
<sub><italic>q</italic></sub> denotes a sub-matrix for intra-layer relation of <italic>S</italic>
<sub><italic>p</italic></sub> (or <italic>S</italic>
<sub><italic>q</italic></sub>) and <italic>S</italic>
<sub><italic>p</italic></sub>&#x02009;&#x02260;&#x02009;<italic>S</italic>
<sub><italic>q</italic></sub> denotes a sub-matrix for inter-stratum relation of two different strata, <italic>S</italic>
<sub><italic>p</italic></sub> and <italic>S</italic>
<sub><italic>q</italic></sub>. Since effects of label propagation can be different for intra-layer and inter-layer connections, we want to look at them separately. Using (<xref rid="Equ5" ref-type="">4</xref>), we have<disp-formula id="Equ5"><label>5</label><alternatives><tex-math id="M11">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ W={\displaystyle \sum_{S_p,{S}_q}^K}{W}^{\left\{{S}_p,\ {S}_q\right\}}={\displaystyle \sum_{S_p={S}_q}^K}{W}^{\left\{{S}_p,\ {S}_q\right\}}+{\displaystyle \sum_{S_p\ne {S}_q}^K}{W}^{\left\{{S}_p,\ {S}_q\right\}}\equiv {W}^{\left\{ intra\right\}}+{W}^{\left\{ inter\right\}}, $$\end{document}</tex-math><mml:math id="M12"><mml:mi>W</mml:mi><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mstyle><mml:msup><mml:mi>W</mml:mi><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:msup><mml:mo>=</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>=</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mstyle><mml:msup><mml:mi>W</mml:mi><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:msup><mml:mo>+</mml:mo><mml:mstyle displaystyle="true"><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>&#x02260;</mml:mo><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow><mml:mi>K</mml:mi></mml:munderover></mml:mstyle><mml:msup><mml:mi>W</mml:mi><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:msup><mml:mtext>&#x02261;</mml:mtext><mml:msup><mml:mi>W</mml:mi><mml:mfenced close="}" open="{"><mml:mi mathvariant="italic">intra</mml:mi></mml:mfenced></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>W</mml:mi><mml:mfenced close="}" open="{"><mml:mi mathvariant="italic">inter</mml:mi></mml:mfenced></mml:msup><mml:mtext>,</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ5.gif" position="anchor"/></alternatives></disp-formula>where <italic>W</italic>
<sup>{<italic>intra</italic>}</sup> consists of <italic>K</italic> diagonal blocks of intra-layer relations and <italic>W</italic>
<sup>{<italic>inter</italic>}</sup> consists of 2<italic>K</italic>&#x02009;&#x02212;&#x02009;2 banded diagonal blocks of inter-layer relations. By accounting for different parameters <italic>&#x003bc;</italic>
<sub><italic>a</italic></sub>(&#x02265;0) and <italic>&#x003bc;</italic>
<sub><italic>b</italic></sub>(&#x02265;0) for <italic>W</italic>
<sup>{<italic>intra</italic>}</sup> and <italic>W</italic>
<sup>{<italic>inter</italic>}</sup>, respectively, the formalization (<xref rid="Equ1" ref-type="">1</xref>) becomes<disp-formula id="Equ6"><label>6</label><alternatives><tex-math id="M13">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \begin{array}{c}\hfill \mathrm{minimize}\hfill \\ {}\hfill f\hfill \end{array}\ {\displaystyle \sum_i^n}{\left({f}_i-{Y}_i\right)}^2+{\mu}_a{\displaystyle \sum_{i, j}^n}{W}_{i j}^{\left\{ i ntra\right\}}{\left({f}_i-{f}_j\right)}^2+{\mu}_b{\displaystyle \sum_{i, j}^n}{W}_{i j}^{\left\{ i nter\right\}}{\left({f}_i-{f}_j\right)}^2. $$\end{document}</tex-math><mml:math id="M14"><mml:mtable columnalign="center"><mml:mtr columnalign="center"><mml:mtd columnalign="center"><mml:mi mathvariant="normal">minimize</mml:mi></mml:mtd></mml:mtr><mml:mtr columnalign="center"><mml:mtd columnalign="center"><mml:mi>f</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mspace width="0.25em"/><mml:mstyle displaystyle="true"><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mi>i</mml:mi><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>Y</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:mstyle displaystyle="true"><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mfenced close="}" open="{"><mml:mi mathvariant="italic">intra</mml:mi></mml:mfenced></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mstyle displaystyle="true"><mml:munderover><mml:mo stretchy="true">&#x02211;</mml:mo><mml:mrow><mml:mi>i</mml:mi><mml:mo>,</mml:mo><mml:mi>j</mml:mi></mml:mrow><mml:mi>n</mml:mi></mml:munderover></mml:mstyle><mml:msubsup><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow><mml:mfenced close="}" open="{"><mml:mi mathvariant="italic">inter</mml:mi></mml:mfenced></mml:msubsup><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>f</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>f</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ6.gif" position="anchor"/></alternatives></disp-formula>
</p><p>Since <italic>W</italic>
<sup>{<italic>intra</italic>}</sup> and <italic>W</italic>
<sup>{<italic>inter</italic>}</sup> themselves are weight matrices, each has graph Laplacian denoted as <italic>L</italic>
<sup>{<italic>intra</italic>}</sup> and <italic>L</italic>
<sup>{<italic>inter</italic>}</sup>, respectively. This implies that we can translate problem (<xref rid="Equ6" ref-type="">5</xref>) into<disp-formula id="Equ7"><label>7</label><alternatives><tex-math id="M15">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ \begin{array}{c}\hfill \mathrm{minimize}\hfill \\ {}\hfill f\hfill \end{array}\ {\left( f- Y\right)}^T\left( f- Y\right)+{f}^T\left({\mu}_a{L}^{\left\{ intra\right\}}+{\mu}_b{L}^{\left\{ inter\right\}}\right) f. $$\end{document}</tex-math><mml:math id="M16"><mml:mtable columnalign="center"><mml:mtr columnalign="center"><mml:mtd columnalign="center"><mml:mi mathvariant="normal">minimize</mml:mi></mml:mtd></mml:mtr><mml:mtr columnalign="center"><mml:mtd columnalign="center"><mml:mi>f</mml:mi></mml:mtd></mml:mtr></mml:mtable><mml:mspace width="0.25em"/><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>f</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:mfenced><mml:mi>T</mml:mi></mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>f</mml:mi><mml:mo>&#x02212;</mml:mo><mml:mi>Y</mml:mi></mml:mrow></mml:mfenced><mml:mo>+</mml:mo><mml:msup><mml:mi>f</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:msup><mml:mi>L</mml:mi><mml:mfenced close="}" open="{"><mml:mi mathvariant="italic">intra</mml:mi></mml:mfenced></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:msup><mml:mi>L</mml:mi><mml:mfenced close="}" open="{"><mml:mi mathvariant="italic">inter</mml:mi></mml:mfenced></mml:msup></mml:mrow></mml:mfenced><mml:mi>f</mml:mi><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ7.gif" position="anchor"/></alternatives></disp-formula>
</p><p>As sum of positive semidefinite matrices is still positive semidefinite, <italic>&#x003bc;</italic>
<sub><italic>a</italic></sub>
<italic>L</italic>
<sup>{<italic>intra</italic>}</sup>&#x02009;+&#x02009;<italic>&#x003bc;</italic>
<sub><italic>b</italic></sub>
<italic>L</italic>
<sup>{<italic>inter</italic>}</sup>
<italic>s</italic> is positive semidefinite. This means that the optimization problem (<xref rid="Equ7" ref-type="">6</xref>) is a convex problem, where the solution is given as<disp-formula id="Equ8"><label>8</label><alternatives><tex-math id="M17">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ f={\left( I+{\mu}_a{L}^{\left\{ intra\right\}}+{\mu}_b{L}^{\left\{ inter\right\}}\right)}^{-1} Y. $$\end{document}</tex-math><mml:math id="M18"><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:msup><mml:mi>L</mml:mi><mml:mfenced close="}" open="{"><mml:mi mathvariant="italic">intra</mml:mi></mml:mfenced></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:msup><mml:mi>L</mml:mi><mml:mfenced close="}" open="{"><mml:mi mathvariant="italic">inter</mml:mi></mml:mfenced></mml:msup></mml:mrow></mml:mfenced><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ8.gif" position="anchor"/></alternatives></disp-formula>
</p><p>Note that when <italic>&#x003bc;</italic>
<sub><italic>b</italic></sub>&#x02009;=&#x02009;0, (<xref rid="Equ8" ref-type="">7</xref>) reduces to (<xref rid="Equ3" ref-type="">3</xref>).</p></sec><sec id="Sec5"><title>Revised matrix inversion method for multi-layered biomedical data</title><p>In eq. (<xref rid="Equ8" ref-type="">7</xref>), the matrix inversion requires <italic>O</italic>(<italic>N</italic>
<sup>3</sup>) computational complexity for <italic>N</italic> number of data. For multi-layered structure of omics, the size of data can be tremendous which implies expensive computation for (<xref rid="Equ8" ref-type="">7</xref>). To overcome such difficulty, various inversion algorithms for block tri-diagonal matrices, such in [<xref ref-type="bibr" rid="CR42">42</xref>&#x02013;<xref ref-type="bibr" rid="CR45">45</xref>], can be considered. These algorithms, however, require square banded diagonal blocks which is not applicable since non-zero blocks in <inline-formula id="IEq2"><alternatives><tex-math id="M19">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {W}^{\left\{{S}_p,\ {S}_q\right\}} $$\end{document}</tex-math><mml:math id="M20"><mml:msup><mml:mi>W</mml:mi><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>S</mml:mi><mml:mi>p</mml:mi></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.25em"/><mml:msub><mml:mi>S</mml:mi><mml:mi>q</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:msup></mml:math><inline-graphic xlink:href="12911_2017_450_Article_IEq2.gif"/></alternatives></inline-formula> can be rectangular because of difference in sizes of different omics (<italic>n</italic>
<sub><italic>p</italic></sub>&#x02009;&#x02260;&#x02009;<italic>n</italic>
<sub><italic>q</italic></sub>). In addition, sparseness of multi-layered structure of omics and the block tri-diagonal matrix can lead to inefficiency in matrix inversion involved in (<xref rid="Equ8" ref-type="">7</xref>).</p><p>Revised matrix inversion method involves combination of Nystr&#x000f6;m method [<xref ref-type="bibr" rid="CR39">39</xref>] and Woodbury formula [<xref ref-type="bibr" rid="CR40">40</xref>]. The idea is to apply low rank approximation to <italic>L</italic>
<sup>{<italic>inter</italic>}</sup> with Nystr&#x000f6;m method and utilize Woodbury formula to obtain the solution to problem (<xref rid="Equ7" ref-type="">6</xref>). First, let us look at Nystr&#x000f6;m method and Woodbury formula.</p><p>[Nystr&#x000f6;m method] Nystr&#x000f6;m method is a low rank approximation of a positive semidefinite matrix from a subset of its columns. Given a positive semidefinite matrix <italic>H</italic> of size <italic>n</italic>, randomly sample <italic>r</italic>&#x02009;&#x0226a;&#x02009;<italic>n</italic> columns, namely <italic>C</italic>. By defining <italic>Q</italic> as the intersection of <italic>C</italic> and its corresponding rows in <italic>H</italic>, Nystr&#x000f6;m approximation <italic>&#x00124;</italic>, is given by<disp-formula id="Equ9"><label>9</label><alternatives><tex-math id="M21">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ H\approx \widehat{H}= C{Q}^{+}{C}^T, $$\end{document}</tex-math><mml:math id="M22"><mml:mi>H</mml:mi><mml:mo>&#x02248;</mml:mo><mml:mover accent="true"><mml:mi>H</mml:mi><mml:mo stretchy="true">^</mml:mo></mml:mover><mml:mo>=</mml:mo><mml:mi>C</mml:mi><mml:msup><mml:mi>Q</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mtext>,</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ9.gif" position="anchor"/></alternatives></disp-formula>where <italic>Q</italic>
<sup>+</sup> is the pseudo-inverse of <italic>Q</italic> with rank of <italic>&#x00124;</italic> equal to <italic>r</italic>.</p><p>[Woodbury formula] Woodbury formula matrix is inversion identity for sum of two matrices. Suppose <italic>A</italic> is an <italic>n</italic>&#x02009;&#x000d7;&#x02009;<italic>n</italic> invertible matrix, <italic>B</italic> is a <italic>r</italic>&#x02009;&#x000d7;&#x02009;<italic>r</italic> (<italic>r</italic> not necessarily equal to <italic>n</italic>) invertible matrix, <italic>U</italic> is a <italic>n</italic>&#x02009;&#x000d7;&#x02009;<italic>r</italic> matrix. Suppose furthermore that B<sup>&#x02212;&#x02009;1</sup>&#x02009;+&#x02009;<italic>U</italic>
<sup><italic>T</italic></sup>
<italic>A</italic>
<sup>&#x02212;&#x02009;1</sup>
<italic>U</italic> is invertible. Then,<disp-formula id="Equ10"><label>10</label><alternatives><tex-math id="M23">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {\left( A+ UB{U}^T\right)}^{-1}={A}^{-1}-{A}^{-1} U{\left({B}^{-1}+{U}^T{A}^{-1} U\right)}^{-1}{U}^T{A}^{-1}. $$\end{document}</tex-math><mml:math id="M24"><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>A</mml:mi><mml:mo>+</mml:mo><mml:mi>U</mml:mi><mml:mi>B</mml:mi><mml:msup><mml:mi>U</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mfenced><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>=</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>U</mml:mi><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>U</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>U</mml:mi></mml:mrow></mml:mfenced><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>U</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ10.gif" position="anchor"/></alternatives></disp-formula>
</p><p>Woodbury formula is useful when computational cost of obtaining <italic>A</italic>
<sup>&#x02212;&#x02009;1</sup> is cheap and the total matrix has sparse structure [<xref ref-type="bibr" rid="CR43">43</xref>].</p><p>In eq. (<xref rid="Equ8" ref-type="">7</xref>), <italic>L</italic>
<sup>{<italic>inter</italic>}</sup> is a positive semidefinite matrix by the property of graph Laplacian [<xref ref-type="bibr" rid="CR26">26</xref>], and thus applicable for Nystr&#x000f6;m method. By applying Nystr&#x000f6;m method to <italic>L</italic>
<sup>{<italic>inter</italic>}</sup>, we obtain<disp-formula id="Equ11"><label>11</label><alternatives><tex-math id="M25">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {L}^{(inter)}\approx C{Q}^{+}{C}^T, $$\end{document}</tex-math><mml:math id="M26"><mml:msup><mml:mi>L</mml:mi><mml:mfenced close=")" open="("><mml:mi mathvariant="italic">inter</mml:mi></mml:mfenced></mml:msup><mml:mo>&#x02248;</mml:mo><mml:mi>C</mml:mi><mml:msup><mml:mi>Q</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:mtext>,</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ11.gif" position="anchor"/></alternatives></disp-formula>where <italic>C</italic> is a <italic>n</italic>&#x02009;&#x000d7;&#x02009;<italic>r</italic>&#x000a0;(<italic>r</italic>&#x02009;&#x0226a;&#x02009;<italic>n</italic>) matrix and <italic>Q</italic>
<sup>+</sup> is a <italic>r</italic>&#x02009;&#x000d7;&#x02009;<italic>r</italic> matrix. Substituting the result to eq. (<xref rid="Equ8" ref-type="">7</xref>) yields<disp-formula id="Equ12"><label>12</label><alternatives><tex-math id="M27">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ f={\left( I+{\mu}_a{L}^{\left\{ intra\right\}}+{\mu}_b C{Q}^{+}{C}^T\right)}^{-1} Y. $$\end{document}</tex-math><mml:math id="M28"><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mi>I</mml:mi><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>a</mml:mi></mml:msub><mml:msup><mml:mi>L</mml:mi><mml:mfenced close="}" open="{"><mml:mi mathvariant="italic">intra</mml:mi></mml:mfenced></mml:msup><mml:mo>+</mml:mo><mml:msub><mml:mi>&#x003bc;</mml:mi><mml:mi>b</mml:mi></mml:msub><mml:mi>C</mml:mi><mml:msup><mml:mi>Q</mml:mi><mml:mo>+</mml:mo></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mi>T</mml:mi></mml:msup></mml:mrow></mml:mfenced><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ12.gif" position="anchor"/></alternatives></disp-formula>
</p><p>To use Woodbury formula, let <italic>A</italic>&#x02009;=&#x000a0;<italic>I</italic>&#x02009;+&#x02009;<italic>&#x003bc;</italic>
<sub><italic>a</italic></sub>
<italic>L</italic>
<sup>{<italic>intra</italic>}</sup>, and <italic>B</italic>&#x02009;=&#x02009;<italic>&#x003bc;</italic>
<sub><italic>b</italic></sub>
<italic>Q</italic>
<sup>+</sup>, By Woodbury formula, we have the final solution to problem (<xref rid="Equ7" ref-type="">6</xref>) in the form<disp-formula id="Equ13"><label>13</label><alternatives><tex-math id="M29">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ f={A}^{-1} Y-{A}^{-1} C{\left({B}^{-1}+{C}^T{A}^{-1} C\right)}^{-1}{C}^T{A}^{-1}{Y}^{-1}. $$\end{document}</tex-math><mml:math id="M30"><mml:mi>f</mml:mi><mml:mo>=</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>Y</mml:mi><mml:mo>&#x02212;</mml:mo><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>C</mml:mi><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mi>B</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mi>C</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mi>C</mml:mi></mml:mrow></mml:mfenced><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>C</mml:mi><mml:mi>T</mml:mi></mml:msup><mml:msup><mml:mi>A</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:msup><mml:mi>Y</mml:mi><mml:mrow><mml:mo>&#x02212;</mml:mo><mml:mn>1</mml:mn></mml:mrow></mml:msup><mml:mtext>.</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ13.gif" position="anchor"/></alternatives></disp-formula>
</p></sec><sec id="Sec6"><title>Overview of the proposed method</title><p>The justification for using the proposed method starts with observing Woodbury formula used for matrix inversion in (<xref rid="Equ12" ref-type="">11</xref>). From (<xref rid="Equ12" ref-type="">11</xref>), we see that the matrix <italic>A</italic>, defined as <italic>I</italic>&#x02009;+&#x02009;<italic>&#x003bc;</italic>
<sub><italic>a</italic></sub>
<italic>L</italic>
<sup>{<italic>intra</italic>}</sup>, is a block diagonal matrix and that the total matrix has sparse structure arising from the property of block tri-diagonal matrix. Since obtaining the inverse of block diagonal matrix is cheap and the total matrix is sparse, we can infer from [<xref ref-type="bibr" rid="CR43">43</xref>] that Woodbury formula is an effective approach for obtaining the inverse in eq. (<xref rid="Equ12" ref-type="">11</xref>). The complexity for Woodbury formula (in fact the overall complexity) is given by<disp-formula id="Equ14"><label>14</label><alternatives><tex-math id="M31">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ O\left({\left( \max \kern0.5em \left\{{n}_1,\kern0.5em {n}_2,\dots, {n}_K\right\}\right)}^3+ r{N}^2\right), $$\end{document}</tex-math><mml:math id="M32"><mml:mi>O</mml:mi><mml:mfenced close=")" open="("><mml:mrow><mml:msup><mml:mfenced close=")" open="("><mml:mrow><mml:mo>max</mml:mo><mml:mspace width="0.5em"/><mml:mfenced close="}" open="{"><mml:mrow><mml:msub><mml:mi>n</mml:mi><mml:mn>1</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mspace width="0.5em"/><mml:msub><mml:mi>n</mml:mi><mml:mn>2</mml:mn></mml:msub><mml:mo>,</mml:mo><mml:mo>&#x02026;</mml:mo><mml:mo>,</mml:mo><mml:msub><mml:mi>n</mml:mi><mml:mi>K</mml:mi></mml:msub></mml:mrow></mml:mfenced></mml:mrow></mml:mfenced><mml:mn>3</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:mi>r</mml:mi><mml:msup><mml:mi>N</mml:mi><mml:mn>2</mml:mn></mml:msup></mml:mrow></mml:mfenced><mml:mtext>,</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ14.gif" position="anchor"/></alternatives></disp-formula>where <italic>n</italic>
<sub><italic>k</italic></sub> denotes size of stratum <italic>S</italic>
<sub><italic>k</italic></sub> and <italic>r</italic>&#x02009;&#x0226a;&#x02009;<italic>N</italic>.</p><p>In regards to Nystr&#x000f6;m method, a natural question could be brought upon selection of <italic>L</italic>
<sup>{<italic>inter</italic>}</sup> for low-rank approximation. It is true that we could apply Nystr&#x000f6;m method on <italic>&#x003bc;</italic>
<sub><italic>a</italic></sub>
<italic>L</italic>
<sup>{<italic>intra</italic>}</sup>&#x02009;+&#x02009;<italic>&#x003bc;</italic>
<sub><italic>b</italic></sub>
<italic>L</italic>
<sup>{<italic>inter</italic>}</sup> as the sum of positive semi-definite matrices is still positive semidefinite. This approach, however, could lead to loss of structure and properties of each layer since we are approximating the graph Laplacian with randomly sampled columns. By selecting only <italic>L</italic>
<sup>{<italic>inter</italic>}</sup> for Nystr&#x000f6;m method, we prevent from such loss. In addition, in contrast to various inversion algorithms for block tri-diagonal matrices, Nystr&#x000f6;m method is utilization of rectangular banded diagonal blocks combined with property of the graph Laplacian.</p><p>Finally, with respect to integrative analysis of multi-omics data, the overall complexity (<xref rid="Equ14" ref-type="">13</xref>) is reduced from <italic>O</italic>(<italic>N</italic>
<sup>3</sup>), achieving faster matrix inversion. Since the size of multi-omics data can get very large, the proposed method can adjust effectively to multi-layer structure of omics.</p></sec></sec><sec id="Sec7"><title>Experiments</title><sec id="Sec8"><title>Data</title><p>To validate the performance of the proposed method, we compared the performance of the multi-layered network with the proposed method to that of the non-hierarchical single layered network with ordinary semi-supervised learning scheme. For problem setting, we applied it to disease co-occurrence prediction problem on two-layered network consisting of symptom-layer and disease-layer. Disease co-occurrence prediction has importance for treatment and prevention, in practice [<xref ref-type="bibr" rid="CR46">46</xref>]. For example, examining disease co-occurrence of cancer, which has high disease co-occurrence rate, can serve as a crucial prognostic factor for patients with cancer [<xref ref-type="bibr" rid="CR47">47</xref>] and has direct influence on treatment of patients [<xref ref-type="bibr" rid="CR48">48</xref>]. Therefore, disease co-occurrence had been studied but only on single layer of omics [<xref ref-type="bibr" rid="CR38">38</xref>]. In our study, we employ the fact that knowing common symptoms of two diseases can aid disease co-occurrence prediction. For instance, knowing that a patient has coughing can lead to a diagnosis of both flu and pneumonia, which are co-occurring diseases.</p><p>To construct the multi-layered network of symptoms and diseases, a list of disease and symptoms was obtained from Medical Subject Headings (MeSH) of the National Library of Medicine [<xref ref-type="bibr" rid="CR49">49</xref>], yielding 4,318 diseases and 322 symptoms. For disease co-occurrence information, we collected the data from HuDiNe [<xref ref-type="bibr" rid="CR50">50</xref>], which contained information for 1,015 diseases, out of 4,318 diseases. The obtained diseases were selected as nodes for disease-layer and 319 symptoms, out of 322 symptoms, with symptom-disease information from [<xref ref-type="bibr" rid="CR17">17</xref>] were selected as nodes for symptom-layer. For intra-layer relations of diseases, <italic>W</italic>
<sup>{<italic>Disease</italic>}</sup>, we utilized similarity between diseases in terms of shared proteins (out of 15,777 proteins). For similarity measurement, we used Tanimoto kernel [<xref ref-type="bibr" rid="CR51">51</xref>] which is given as<disp-formula id="Equ15"><label>15</label><alternatives><tex-math id="M33">\documentclass[12pt]{minimal}
				\usepackage{amsmath}
				\usepackage{wasysym} 
				\usepackage{amsfonts} 
				\usepackage{amssymb} 
				\usepackage{amsbsy}
				\usepackage{mathrsfs}
				\usepackage{upgreek}
				\setlength{\oddsidemargin}{-69pt}
				\begin{document}$$ {W}_{i j}=\frac{x_i\cdot {x}_j}{{\left\Vert {x}_i\right\Vert}^2+{\left\Vert {x}_j\right\Vert}^2-{x}_i\cdot {x}_j}, $$\end{document}</tex-math><mml:math id="M34"><mml:msub><mml:mi>W</mml:mi><mml:mrow><mml:mi>i</mml:mi><mml:mi>j</mml:mi></mml:mrow></mml:msub><mml:mo>=</mml:mo><mml:mfrac><mml:mrow><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x022c5;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow><mml:mrow><mml:msup><mml:mfenced close="&#x02016;" open="&#x02016;"><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>+</mml:mo><mml:msup><mml:mfenced close="&#x02016;" open="&#x02016;"><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mfenced><mml:mn>2</mml:mn></mml:msup><mml:mo>&#x02212;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>i</mml:mi></mml:msub><mml:mo>&#x022c5;</mml:mo><mml:msub><mml:mi>x</mml:mi><mml:mi>j</mml:mi></mml:msub></mml:mrow></mml:mfrac><mml:mtext>,</mml:mtext></mml:math><graphic xlink:href="12911_2017_450_Article_Equ15.gif" position="anchor"/></alternatives></disp-formula>where <italic>x</italic>
<sub><italic>i</italic></sub> and <italic>x</italic>
<sub><italic>j</italic></sub> are given as bit vectors. For intra-stratum relations of symptoms, <italic>W</italic>
<sup>{<italic>Symptom</italic>}</sup>, we utilized similarity between symptoms in terms of disease accompanying the symptoms. Tanimoto kernel was also used as similarity measurement for symptom relations. For inter-layer relations of symptom and disease, we used the symptom-disease data and binary weight where <italic>W</italic>
<sub arrange="stack"><italic>ij</italic></sub><sup arrange="stack">{<italic>inter</italic>}</sup>&#x02009;=&#x02009;1, if co-occurrence is present, and <italic>W</italic>
<sub arrange="stack"><italic>ij</italic></sub><sup arrange="stack">{<italic>inter</italic>}</sup>&#x02009;=&#x02009;0, otherwise, for <italic>i</italic>&#x02009;&#x02208;&#x02009;<italic>Disease</italic>, and <italic>j</italic>&#x02009;&#x02208;&#x02009;<italic>Symptom</italic>. Table&#x000a0;<xref rid="Tab1" ref-type="table">1</xref> summarizes the data.<table-wrap id="Tab1"><label>Table 1</label><caption><p>Data source for symptom-disease stratified network and disease co-occurrence information</p></caption><table frame="hsides" rules="groups"><thead><tr><th>Data</th><th>Number of data</th><th>Sources</th></tr></thead><tbody><tr><td>Symptom-Disease</td><td>319 symptoms/2,454 diseases</td><td>Supplementary information in [<xref ref-type="bibr" rid="CR17">17</xref>]</td></tr><tr><td>Disease</td><td>4318 diseases/15,777 proteins</td><td>CTD, GAD, OMIM, PharmGKD, TTD</td></tr><tr><td>Disease Co-occurrence</td><td>1,015 diseases</td><td>HuDiNe</td></tr></tbody></table></table-wrap>
</p><p>Figure&#x000a0;<xref rid="Fig2" ref-type="fig">2a</xref> shows the number of associated symptoms for a particular disease. Out of 1,015 diseases, brain neoplasm has the most number of associated symptoms with 202 records, followed by HIV infections, Lewy body disease, and cerebral hemorrhage. About 10% of diseases have 100 or more associated symptoms, about 73% have associated symptoms in between 100 and 10, and about 17% have less than or equal to 10 associated symptoms. Similarly, Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2b</xref> show the number of associated diseases for a particular symptom. Out of 319 symptoms, pain is the most common symptom among diseases (677 diseases), followed by fever, change in body weight, and edema. About 18% of symptoms have 300 or more associated diseases, about 36% have associated diseases in between 300 and 100, and about 46% have less than or equal to 100 associated diseases.<fig id="Fig2"><label>Fig. 2</label><caption><p>
<bold>a</bold> Bar graph of the number of associated symptoms for a particular disease. <bold>b</bold> Bar graph of the number of associated disease for a particular symptom</p></caption><graphic xlink:href="12911_2017_450_Fig2_HTML" id="MO2"/></fig>
</p></sec><sec id="Sec9"><title>Experimental setting</title><p>For disease co-occurrence prediction problem, we employ the disease scoring setting, as in [<xref ref-type="bibr" rid="CR38">38</xref>], where the semi-supervised learning algorithm provides the scores for disease. With the two-layered network of symptom and diseases, we first selected a target disease and gave label &#x02018;1&#x02019; to target disease, indicating the presence of diseases. For other unlabeled diseases, we gave label &#x02018;0&#x02019;s. Then, we randomly gave label &#x02018;1&#x02019;s to 0 ~ 100% on 20% interval to related symptoms and gave &#x02018;0&#x02019;s to unrelated symptoms. The 0% of labeled symptoms represent the reference network, or the single disease network. We assume that we know 20% of co-occurring diseases in a priori, and therefore we randomly set and assign 20% of co-occurring diseases with label &#x02018;1&#x02019;s. Note that we can change the percentages but the effect is similar for both single-layered network and multi-layered network. The parameters, <italic>&#x003bc;</italic>
<sub><italic>a</italic></sub> and <italic>&#x003bc;</italic>
<sub><italic>b</italic></sub> were determined in the range {0.01,&#x02009;&#x02026;,&#x02009;100} and the performance of two-layered network of symptoms and diseases was compared to that of the reference network. The performance was measured by Area Under ROC Curve (AUC) [<xref ref-type="bibr" rid="CR52">52</xref>], which compared prediction output <italic>f</italic>&#x02009;=&#x02009;(<italic>f</italic>
<sub>1</sub>,&#x02009;<italic>f</italic>
<sub>2</sub>,&#x000a0;&#x02026;,&#x000a0;<italic>f</italic>
<sub><italic>n</italic></sub>)<sup><italic>T</italic></sup> with true labels. For validation, Leave-One-Out method [<xref ref-type="bibr" rid="CR53">53</xref>] was used and the experiment was repeated 10 times.</p></sec></sec><sec id="Sec10"><title>Results and Discussion</title><sec id="Sec11"><title>Results on validity of the proposed algorithm</title><p>The results are summarized in Fig.&#x000a0;<xref rid="Fig3" ref-type="fig">3</xref>. Figure&#x000a0;<xref rid="Fig3" ref-type="fig">3a</xref> illustrates AUC performance comparison in predicting disease co-occurrence for symptom-disease layered network and single disease network. It shows that for every increase in % of labels in symptom-layer achieves higher AUC than 0.59 of the reference network. Furthermore, it shows that increase in the number of labels for related symptoms leads to higher AUC performance. In the view of practitioner, this result suggests that knowing more symptoms disclose more information regarding characteristics of disease and its co-occurrence. Figure&#x000a0;<xref rid="Fig3" ref-type="fig">3b</xref> depicts AUC for multi-layered network with 100% labeled symptoms against the reference network. If a point in scatter plot is above the diagonal line, then the multi-layered network performs better for a particular target disease. From the figure, we can see that most of the points are above the diagonal line, indicating better performance of the multi-layered network over the reference network. Such results consolidate the fact that labels in symptom-layer can benefit predictions for disease co-occurrence.<fig id="Fig3"><label>Fig. 3</label><caption><p>
<bold>a</bold> Mean AUC for multi-layered network with 0 ~ 100%, on 20% interval, of labeled symptoms. 0% indicates the single disease network (reference network) where no labels and inter-stratum connections are given. <bold>b</bold> AUC for multi-layered network with 100% labeled symptoms against the reference network. Dots above diagonal line indicates higher AUC of multi-layered network for a particular target disease</p></caption><graphic xlink:href="12911_2017_450_Fig3_HTML" id="MO3"/></fig>
</p></sec><sec id="Sec12"><title>Enrichment analysis: relevance of use of symptom data for disease co-occurrence</title><p>To examine relevance of use of symptoms for disease co-occurrence, we compared the difference between the average number of shared symptoms with co-occurring diseases and non-co-occurring diseases for each target disease. The main reason for such inspection is that the number of shared symptoms affect inter-layer label propagation in semi-supervised learning setting. If there exists a significant difference between the average number of shared symptoms with co-occurring diseases and non-co-occurring diseases for a target disease, then symptoms, indeed, have relevance with disease co-occurrence. Figure&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref> illustrates the average number of shared symptoms with co-occurring and non-co-occurring diseases, respectively, for total list of diseases and the tiers that correspond to those in Fig.&#x000a0;<xref rid="Fig2" ref-type="fig">2a</xref>. For statistical evaluation, we carried out one sided t-test of difference in means for each group, where the null hypothesis is that the difference in means is zero and alternative is that the average of shared symptoms with co-occurring diseases is higher than that with non-co-occurring diseases. The results are shown in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>.<fig id="Fig4"><label>Fig. 4</label><caption><p>Comparison of the average number of shared symptoms with co-occurring diseases and with non-co-occurring diseases for total list of diseases, tier 1, tier 2, and tier 3</p></caption><graphic xlink:href="12911_2017_450_Fig4_HTML" id="MO4"/></fig>
<table-wrap id="Tab2"><label>Table 2</label><caption><p>Results for statistical evaluation with one-sided t-test for difference in means</p></caption><table frame="hsides" rules="groups"><thead><tr><th/><th>Total list of diseases</th><th>Tier 1</th><th>Tier 2</th><th>Tier 3</th></tr></thead><tbody><tr><td>
<italic>p</italic>-value</td><td>&#x0003c;0.001</td><td>&#x0003c;0.001</td><td>&#x0003c;0.001</td><td>&#x0003c;0.001</td></tr><tr><td>T-statistics</td><td>11.238</td><td>5.558</td><td>12.131</td><td>6.391</td></tr><tr><td>Degree of Freedom</td><td>1,014</td><td>100</td><td>738</td><td>174</td></tr><tr><td>Standard Deviation</td><td>3.654</td><td>8.822</td><td>2.378</td><td>0.368</td></tr></tbody></table></table-wrap>
</p><p>In Fig.&#x000a0;<xref rid="Fig4" ref-type="fig">4</xref>, it shows that the average number of share symptoms is higher with co-occurring disease than that with non-co-occurring diseases for each group. It is also noticeable to see that in Table&#x000a0;<xref rid="Tab2" ref-type="table">2</xref>, the results of t-tests allow us to reject the null hypothesis for each case with <italic>p</italic>-value &#x0003c;0.001 and conclude the alternative. Thus, we can deduce that there exists a definite relevance between shared symptoms between diseases and disease co-occurrence.</p><p>To elucidate more understanding of effects in use of symptom-layer, we selected thrombocytopenia as the target disease and analyzed the distribution of the number of shared symptoms. Thrombocytopenia refers to any disorders in which there is an abnormally low amount of platelets that help blood to clot [<xref ref-type="bibr" rid="CR54">54</xref>, <xref ref-type="bibr" rid="CR55">55</xref>]. Figure&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref> shows the number of shared symptoms with other diseases, in the order of value of predicative output, <italic>f</italic>, in eq. (<xref rid="Equ13" ref-type="">12</xref>). These values represent relative closeness to being labeled as co-occurring disease with the target disease compared to one another. In Fig.&#x000a0;<xref rid="Fig5" ref-type="fig">5</xref>, it shows that higher number of shared symptoms yields relatively higher value of predicative output of predicting disease co-occurrence. This solidifies the relevance of use of symptoms for prediction of disease co-occurrence.<fig id="Fig5"><label>Fig. 5</label><caption><p>Number of shared symptoms for Thrombocytopenia in the order of <italic>f</italic> values</p></caption><graphic xlink:href="12911_2017_450_Fig5_HTML" id="MO5"/></fig>
</p></sec></sec><sec id="Sec13"><title>Conclusion</title><p>In this paper, we develop a graph based semi-supervised learning for prediction process in multi-layered biomedical systems. The algorithm involves matrix separation and graph integration methods but issues with computational complexity and sparseness must be solved. To resolve the issues, we devise a revised matrix inversion scheme consisting of Nystr&#x000f6;m method and Woodbury formula. Theoretically, the proposed method can reduce computational complexity by coping with sparseness, while preserving innate structure and properties of each layer.</p><p>To test the proposed algorithm, it was applied to two-layered system of symptoms and diseases to predict disease co-occurrence. The results showed improvement in prediction in terms of AUC where the performance increased from 0.59 of single disease network to 0.74 of symptom-disease network. Furthermore, it also showed relevance of use of symptoms on disease co-occurrence prediction with statistical evidence for higher average of shared symptoms with co-occurring diseases than that of non-co-occurring diseases. In theoretical perspective, although the proposed algorithm was applied on two-layered network for our experiments, it has scalability power as it is applicable to multi-layered structure with large number of biomedical data, and achieves faster inversion than normal matrix inversion.</p><p>As an extension of the research, since disease co-occurrence prediction problem has been studied for many years, it is possible to consider comparing the proposed method with other works such as [<xref ref-type="bibr" rid="CR56">56</xref>]. In addition, we can consider extending additional layers where the extra layers convey relevant information. In case of disease co-occurrence prediction, inclusion of additional layers of phenotype/clinical data would be beneficial as they serve as important information to construct comorbidity map. In different perspective, we can also consider cases outside the box of the central dogma of biology, where multi-layered network can exist in a non-hierarchical structure.</p><p>On the other hand, the research has novelty in that it is a new integrative algorithm that incorporates vertical structure of omics data, on contrary to other existing methods that integrate the data in parallel fashion. Moreover, the experiment results not only reflect the viewpoints of practitioners where they observe or seek for symptoms as primary diagnosis but also provide enhanced guideline for disease co-occurrence prediction, where it has importance for treatment and prevention in practice. Thus, the proposed algorithm can serve as a valuable tool for inference process of multi-layered biological system.</p></sec></body><back><ack><p>The authors would like to gratefully acknowledge support from the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2012-0000994/2015R1A5A7037630) and the Ajou University Research Fund.</p><sec id="FPar1"><title>Funding</title><p>Publication of this article was funded by the National Research Foundation of Korea (NRF) grant funded by the Korea government (MSIP) (No. 2012-0000994).</p></sec><sec id="FPar2"><title>Availability of data and materials</title><p>The datasets used and/or analyzed during the current study available from the corresponding author on reasonable request.</p></sec><sec id="FPar3"><title>Authors&#x02019; contributions</title><p>HJS designed the idea and supervised the study process. MJK and YHN analyzed the data, implemented the results and wrote the manuscript. SJS provided implications and interpretations of the results. All of the authors read and approved the final manuscript.</p></sec><sec id="FPar4"><title>Competing interests</title><p>The authors declare that they have no competing interests.</p></sec><sec id="FPar5"><title>Consent for publication</title><p>Not Applicable.</p></sec><sec id="FPar6"><title>Ethics approval and consent to participate</title><p>Not Applicable.</p></sec><sec id="FPar7"><title>About this supplement</title><p>This article has been published as part of BMC Medical Informatics and Decision Making Volume 17 Supplement 1, 2017: Selected articles from the 6th Translational Bioinformatics Conference (TBC 2016): medical informatics and decision making. The full contents of the supplement are available online at &#x0003c;<ext-link ext-link-type="uri" xlink:href="https://bmcmedinformdecismak.biomedcentral.com/articles/supplements/volume-17-supplement-1">https://bmcmedinformdecismak.biomedcentral.com/articles/supplements/volume-17-supplement-1</ext-link>&#x0003e;.</p></sec><sec id="FPar8"><title>Publisher&#x02019;s Note</title><p>Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></sec></ack><ref-list id="Bib1"><title>References</title><ref id="CR1"><label>1.</label><mixed-citation publication-type="other">Ishii N, Tomita M. Multi-omics data-driven systems biology of E. coli. In: Systems biology and biotechnology of Escherichia coli. Springer Netherlands; 2009. p. 41&#x02013;57.</mixed-citation></ref><ref id="CR2"><label>2.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ritchie</surname><given-names>MD</given-names></name><name><surname>Holzinger</surname><given-names>ER</given-names></name><name><surname>Li</surname><given-names>R</given-names></name><name><surname>Pendergrass</surname><given-names>SA</given-names></name><name><surname>Kim</surname><given-names>D</given-names></name></person-group><article-title>Methods of integrating data to uncover genotype-phenotype interactions</article-title><source>Nat Rev Genet</source><year>2015</year><volume>16</volume><issue>2</issue><fpage>85</fpage><lpage>97</lpage><pub-id pub-id-type="doi">10.1038/nrg3868</pub-id><pub-id pub-id-type="pmid">25582081</pub-id></element-citation></ref><ref id="CR3"><label>3.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Bersanelli</surname><given-names>M</given-names></name><name><surname>Mosca</surname><given-names>E</given-names></name><name><surname>Remondini</surname><given-names>D</given-names></name><name><surname>Giampieri</surname><given-names>E</given-names></name><name><surname>Sala</surname><given-names>C</given-names></name><name><surname>Castellani</surname><given-names>G</given-names></name><name><surname>Milanesi</surname><given-names>L</given-names></name></person-group><article-title>Methods for the integration of multi-omics data: mathematical aspects</article-title><source>BMC bioinformatics</source><year>2016</year><volume>17</volume><issue>2</issue><fpage>167</fpage><pub-id pub-id-type="pmid">27091357</pub-id></element-citation></ref><ref id="CR4"><label>4.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Berger</surname><given-names>B</given-names></name><name><surname>Peng</surname><given-names>J</given-names></name><name><surname>Singh</surname><given-names>M</given-names></name></person-group><article-title>Computational solutions for omics data</article-title><source>Nat Rev Genet</source><year>2013</year><volume>14</volume><issue>5</issue><fpage>333</fpage><lpage>346</lpage><pub-id pub-id-type="doi">10.1038/nrg3433</pub-id><pub-id pub-id-type="pmid">23594911</pub-id></element-citation></ref><ref id="CR5"><label>5.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>S</given-names></name></person-group><article-title>Network based approaches to the analysis of omics data</article-title><source>Methods (San Diego, Calif)</source><year>2015</year><volume>83</volume><fpage>1</fpage><lpage>2</lpage><pub-id pub-id-type="doi">10.1016/j.ymeth.2015.06.003</pub-id></element-citation></ref><ref id="CR6"><label>6.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Presson</surname><given-names>AP</given-names></name><name><surname>Sobel</surname><given-names>EM</given-names></name><name><surname>Papp</surname><given-names>JC</given-names></name><name><surname>Suarez</surname><given-names>CJ</given-names></name><name><surname>Whistler</surname><given-names>T</given-names></name><name><surname>Rajeevan</surname><given-names>MS</given-names></name><name><surname>Vernon</surname><given-names>SD</given-names></name><name><surname>Horvath</surname><given-names>S</given-names></name></person-group><article-title>Integrated weighted gene co-expression network analysis with an application to chronic fatigue syndrome</article-title><source>BMC Syst Biol</source><year>2008</year><volume>2</volume><issue>1</issue><fpage>1</fpage><pub-id pub-id-type="doi">10.1186/1752-0509-2-95</pub-id><pub-id pub-id-type="pmid">18171472</pub-id></element-citation></ref><ref id="CR7"><label>7.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stuart</surname><given-names>JM</given-names></name><name><surname>Segal</surname><given-names>E</given-names></name><name><surname>Koller</surname><given-names>D</given-names></name><name><surname>Kim</surname><given-names>SK</given-names></name></person-group><article-title>A gene-coexpression network for global discovery of conserved genetic modules</article-title><source>Science</source><year>2003</year><volume>302</volume><issue>5643</issue><fpage>249</fpage><lpage>255</lpage><pub-id pub-id-type="doi">10.1126/science.1087447</pub-id><pub-id pub-id-type="pmid">12934013</pub-id></element-citation></ref><ref id="CR8"><label>8.</label><mixed-citation publication-type="other">Weirauch MT. Gene coexpression networks for the analysis of DNA microarray data. Appl Stat Netw Biol. 2011:215&#x02013;250.</mixed-citation></ref><ref id="CR9"><label>9.</label><mixed-citation publication-type="other">Butte AJ, Kohane IS. Mutual information relevance networks: functional genomic clustering using pairwise entropy measurements. In: Pacific Symposium on Biocomputing. 2000;5:418-429.</mixed-citation></ref><ref id="CR10"><label>10.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Dreze</surname><given-names>M</given-names></name><name><surname>Monachello</surname><given-names>D</given-names></name><name><surname>Lurin</surname><given-names>C</given-names></name><name><surname>Cusick</surname><given-names>ME</given-names></name><name><surname>Hill</surname><given-names>DE</given-names></name><name><surname>Vidal</surname><given-names>M</given-names></name><name><surname>Braun</surname><given-names>P</given-names></name></person-group><article-title>High-quality binary interactome mapping</article-title><source>Methods Enzymol</source><year>2010</year><volume>470</volume><fpage>281</fpage><lpage>315</lpage><pub-id pub-id-type="doi">10.1016/S0076-6879(10)70012-4</pub-id><pub-id pub-id-type="pmid">20946815</pub-id></element-citation></ref><ref id="CR11"><label>11.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Rual</surname><given-names>J-F</given-names></name><name><surname>Venkatesan</surname><given-names>K</given-names></name><name><surname>Hao</surname><given-names>T</given-names></name><name><surname>Hirozane-Kishikawa</surname><given-names>T</given-names></name><name><surname>Dricot</surname><given-names>A</given-names></name><name><surname>Li</surname><given-names>N</given-names></name><name><surname>Berriz</surname><given-names>GF</given-names></name><name><surname>Gibbons</surname><given-names>FD</given-names></name><name><surname>Dreze</surname><given-names>M</given-names></name><name><surname>Ayivi-Guedehoussou</surname><given-names>N</given-names></name></person-group><article-title>Towards a proteome-scale map of the human protein&#x02013;protein interaction network</article-title><source>Nature</source><year>2005</year><volume>437</volume><issue>7062</issue><fpage>1173</fpage><lpage>1178</lpage><pub-id pub-id-type="doi">10.1038/nature04209</pub-id><pub-id pub-id-type="pmid">16189514</pub-id></element-citation></ref><ref id="CR12"><label>12.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Venkatesan</surname><given-names>K</given-names></name><name><surname>Rual</surname><given-names>J-F</given-names></name><name><surname>Vazquez</surname><given-names>A</given-names></name><name><surname>Stelzl</surname><given-names>U</given-names></name><name><surname>Lemmens</surname><given-names>I</given-names></name><name><surname>Hirozane-Kishikawa</surname><given-names>T</given-names></name><name><surname>Hao</surname><given-names>T</given-names></name><name><surname>Zenkner</surname><given-names>M</given-names></name><name><surname>Xin</surname><given-names>X</given-names></name><name><surname>Goh</surname><given-names>K-I</given-names></name></person-group><article-title>An empirical framework for binary interactome mapping</article-title><source>Nat Methods</source><year>2009</year><volume>6</volume><issue>1</issue><fpage>83</fpage><lpage>90</lpage><pub-id pub-id-type="doi">10.1038/nmeth.1280</pub-id><pub-id pub-id-type="pmid">19060904</pub-id></element-citation></ref><ref id="CR13"><label>13.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stelzl</surname><given-names>U</given-names></name><name><surname>Worm</surname><given-names>U</given-names></name><name><surname>Lalowski</surname><given-names>M</given-names></name><name><surname>Haenig</surname><given-names>C</given-names></name><name><surname>Brembeck</surname><given-names>FH</given-names></name><name><surname>Goehler</surname><given-names>H</given-names></name><name><surname>Stroedicke</surname><given-names>M</given-names></name><name><surname>Zenkner</surname><given-names>M</given-names></name><name><surname>Schoenherr</surname><given-names>A</given-names></name><name><surname>Koeppen</surname><given-names>S</given-names></name></person-group><article-title>A human protein-protein interaction network: a resource for annotating the proteome</article-title><source>Cell</source><year>2005</year><volume>122</volume><issue>6</issue><fpage>957</fpage><lpage>968</lpage><pub-id pub-id-type="doi">10.1016/j.cell.2005.08.029</pub-id><pub-id pub-id-type="pmid">16169070</pub-id></element-citation></ref><ref id="CR14"><label>14.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Duarte</surname><given-names>NC</given-names></name><name><surname>Becker</surname><given-names>SA</given-names></name><name><surname>Jamshidi</surname><given-names>N</given-names></name><name><surname>Thiele</surname><given-names>I</given-names></name><name><surname>Mo</surname><given-names>ML</given-names></name><name><surname>Vo</surname><given-names>TD</given-names></name><name><surname>Srivas</surname><given-names>R</given-names></name><name><surname>Palsson</surname><given-names>B&#x000d8;</given-names></name></person-group><article-title>Global reconstruction of the human metabolic network based on genomic and bibliomic data</article-title><source>Proc Natl Acad Sci</source><year>2007</year><volume>104</volume><issue>6</issue><fpage>1777</fpage><lpage>1782</lpage><pub-id pub-id-type="doi">10.1073/pnas.0610772104</pub-id><pub-id pub-id-type="pmid">17267599</pub-id></element-citation></ref><ref id="CR15"><label>15.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Ma</surname><given-names>H</given-names></name><name><surname>Sorokin</surname><given-names>A</given-names></name><name><surname>Mazein</surname><given-names>A</given-names></name><name><surname>Selkov</surname><given-names>A</given-names></name><name><surname>Selkov</surname><given-names>E</given-names></name><name><surname>Demin</surname><given-names>O</given-names></name><name><surname>Goryanin</surname><given-names>I</given-names></name></person-group><article-title>The Edinburgh human metabolic network reconstruction and its functional analysis</article-title><source>Mol Syst Biol</source><year>2007</year><volume>3</volume><issue>1</issue><fpage>135</fpage><pub-id pub-id-type="pmid">17882155</pub-id></element-citation></ref><ref id="CR16"><label>16.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Goh</surname><given-names>K-I</given-names></name><name><surname>Cusick</surname><given-names>ME</given-names></name><name><surname>Valle</surname><given-names>D</given-names></name><name><surname>Childs</surname><given-names>B</given-names></name><name><surname>Vidal</surname><given-names>M</given-names></name><name><surname>Barab&#x000e1;si</surname><given-names>A-L</given-names></name></person-group><article-title>The human disease network</article-title><source>Proc Natl Acad Sci</source><year>2007</year><volume>104</volume><issue>21</issue><fpage>8685</fpage><lpage>8690</lpage><pub-id pub-id-type="doi">10.1073/pnas.0701361104</pub-id><pub-id pub-id-type="pmid">17502601</pub-id></element-citation></ref><ref id="CR17"><label>17.</label><mixed-citation publication-type="other">Zhou X, Menche J, Barab&#x000e1;si A-L, Sharma A. Human symptoms&#x02013;disease network. Nat Commun. 2014;5.</mixed-citation></ref><ref id="CR18"><label>18.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Yugi</surname><given-names>K</given-names></name><name><surname>Kubota</surname><given-names>H</given-names></name><name><surname>Hatano</surname><given-names>A</given-names></name><name><surname>Kuroda</surname><given-names>S</given-names></name></person-group><article-title>Trans-Omics: How To Reconstruct Biochemical Networks Across Multiple &#x02018;Omic&#x02019;Layers</article-title><source>Trends Biotechnol</source><year>2016</year><volume>34</volume><issue>4</issue><fpage>276</fpage><lpage>290</lpage><pub-id pub-id-type="doi">10.1016/j.tibtech.2015.12.013</pub-id><pub-id pub-id-type="pmid">26806111</pub-id></element-citation></ref><ref id="CR19"><label>19.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Stanescu</surname><given-names>A</given-names></name><name><surname>Caragea</surname><given-names>D</given-names></name></person-group><article-title>An empirical study of ensemble-based semi-supervised learning approaches for imbalanced splice site datasets</article-title><source>BMC Syst Biol</source><year>2015</year><volume>9</volume><issue>5</issue><fpage>1</fpage><pub-id pub-id-type="doi">10.1186/1752-0509-9-S5-S1</pub-id><pub-id pub-id-type="pmid">25582171</pub-id></element-citation></ref><ref id="CR20"><label>20.</label><mixed-citation publication-type="other">Belkin M, Matveeva I, Niyogi P. Regularization and semi-supervised learning on large graphs. In: International Conference on Computational Learning Theory: 2004. Springer. p. 624&#x02013;638.</mixed-citation></ref><ref id="CR21"><label>21.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Belkin</surname><given-names>M</given-names></name><name><surname>Niyogi</surname><given-names>P</given-names></name><name><surname>Sindhwani</surname><given-names>V</given-names></name></person-group><article-title>Manifold regularization: A geometric framework for learning from labeled and unlabeled examples</article-title><source>J Mach Learn Res</source><year>2006</year><volume>7</volume><issue>Nov</issue><fpage>2399</fpage><lpage>2434</lpage></element-citation></ref><ref id="CR22"><label>22.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Zhou</surname><given-names>D</given-names></name><name><surname>Bousquet</surname><given-names>O</given-names></name><name><surname>Lal</surname><given-names>TN</given-names></name><name><surname>Weston</surname><given-names>J</given-names></name><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name></person-group><article-title>Learning with local and global consistency</article-title><source>Adv Neural Inf Proces Syst</source><year>2004</year><volume>16</volume><issue>16</issue><fpage>321</fpage><lpage>328</lpage></element-citation></ref><ref id="CR23"><label>23.</label><mixed-citation publication-type="other">Zhu X, Ghahramani Z, Lafferty J. Semi-supervised learning using gaussian fields and harmonic functions. In: Proceedings of the Twenty-first International Conference on Machine Learning (ICML). 2003;3:912&#x02013;919.</mixed-citation></ref><ref id="CR24"><label>24.</label><mixed-citation publication-type="other">Chapelle O, Weston J, Sch&#x000f6;lkopf B. Cluster kernels for semi-supervised learning. In: Proceedings of the Advances in Neural Information Processing Systems 15 (NIPS). 2002;585&#x02013;592.</mixed-citation></ref><ref id="CR25"><label>25.</label><mixed-citation publication-type="other">Zhu X, Ghahramani Z. Learning from labeled and unlabeled data with label propagation. In: Citeseer; 2002</mixed-citation></ref><ref id="CR26"><label>26.</label><mixed-citation publication-type="other">Chung FR. Spectral graph theory. Issue 92 in Regional Conference Series in Mathematics. Providence RI. American Mathematical Soc. 1997.</mixed-citation></ref><ref id="CR27"><label>27.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>H</given-names></name><name><surname>Tsuda</surname><given-names>K</given-names></name><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name></person-group><article-title>Protein functional class prediction with a combined graph</article-title><source>Expert Syst Appl</source><year>2009</year><volume>36</volume><issue>2</issue><fpage>3284</fpage><lpage>3292</lpage><pub-id pub-id-type="doi">10.1016/j.eswa.2008.01.006</pub-id></element-citation></ref><ref id="CR28"><label>28.</label><element-citation publication-type="book"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>H</given-names></name><name><surname>Tsuda</surname><given-names>K</given-names></name><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name><name><surname>Zien</surname><given-names>A</given-names></name></person-group><source>Prediction of protein function from networks</source><year>2006</year><publisher-loc>In</publisher-loc><publisher-name>Semi-supervised learning. MIT press</publisher-name><fpage>361</fpage><lpage>376</lpage></element-citation></ref><ref id="CR29"><label>29.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Tsuda</surname><given-names>K</given-names></name><name><surname>Shin</surname><given-names>H</given-names></name><name><surname>Sch&#x000f6;lkopf</surname><given-names>B</given-names></name></person-group><article-title>Fast protein classification with multiple networks</article-title><source>Bioinformatics</source><year>2005</year><volume>21</volume><issue>suppl 2</issue><fpage>ii59</fpage><lpage>ii65</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/bti1110</pub-id><pub-id pub-id-type="pmid">16204126</pub-id></element-citation></ref><ref id="CR30"><label>30.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Shin</surname><given-names>H</given-names></name><name><surname>Lisewski</surname><given-names>AM</given-names></name><name><surname>Lichtarge</surname><given-names>O</given-names></name></person-group><article-title>Graph sharpening plus graph integration: a synergy that improves protein functional classification</article-title><source>Bioinformatics</source><year>2007</year><volume>23</volume><issue>23</issue><fpage>3217</fpage><lpage>3224</lpage><pub-id pub-id-type="doi">10.1093/bioinformatics/btm511</pub-id><pub-id pub-id-type="pmid">17977886</pub-id></element-citation></ref><ref id="CR31"><label>31.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>D</given-names></name><name><surname>Shin</surname><given-names>H</given-names></name><name><surname>Song</surname><given-names>YS</given-names></name><name><surname>Kim</surname><given-names>JH</given-names></name></person-group><article-title>Synergistic effect of different levels of genomic data for cancer clinical outcome prediction</article-title><source>J Biomed Inform</source><year>2012</year><volume>45</volume><issue>6</issue><fpage>1191</fpage><lpage>1198</lpage><pub-id pub-id-type="doi">10.1016/j.jbi.2012.07.008</pub-id><pub-id pub-id-type="pmid">22910106</pub-id></element-citation></ref><ref id="CR32"><label>32.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>D</given-names></name><name><surname>Joung</surname><given-names>J-G</given-names></name><name><surname>Sohn</surname><given-names>K-A</given-names></name><name><surname>Shin</surname><given-names>H</given-names></name><name><surname>Park</surname><given-names>YR</given-names></name><name><surname>Ritchie</surname><given-names>MD</given-names></name><name><surname>Kim</surname><given-names>JH</given-names></name></person-group><article-title>Knowledge boosting: a graph-based integration approach with multi-omics data and genomic knowledge for cancer clinical outcome prediction</article-title><source>J Am Med Inform Assoc</source><year>2015</year><volume>22</volume><issue>1</issue><fpage>109</fpage><lpage>120</lpage><pub-id pub-id-type="pmid">25002459</pub-id></element-citation></ref><ref id="CR33"><label>33.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>D</given-names></name><name><surname>Shin</surname><given-names>H</given-names></name><name><surname>Sohn</surname><given-names>K-A</given-names></name><name><surname>Verma</surname><given-names>A</given-names></name><name><surname>Ritchie</surname><given-names>MD</given-names></name><name><surname>Kim</surname><given-names>JH</given-names></name></person-group><article-title>Incorporating inter-relationships between different levels of genomic data into cancer clinical outcome prediction</article-title><source>Methods</source><year>2014</year><volume>67</volume><issue>3</issue><fpage>344</fpage><lpage>353</lpage><pub-id pub-id-type="doi">10.1016/j.ymeth.2014.02.003</pub-id><pub-id pub-id-type="pmid">24561168</pub-id></element-citation></ref><ref id="CR34"><label>34.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nguyen</surname><given-names>T-P</given-names></name><name><surname>Ho</surname><given-names>T-B</given-names></name></person-group><article-title>Detecting disease genes based on semi-supervised learning and protein&#x02013;protein interaction networks</article-title><source>Artif Intell Med</source><year>2012</year><volume>54</volume><issue>1</issue><fpage>63</fpage><lpage>71</lpage><pub-id pub-id-type="doi">10.1016/j.artmed.2011.09.003</pub-id><pub-id pub-id-type="pmid">22000346</pub-id></element-citation></ref><ref id="CR35"><label>35.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>You</surname><given-names>Z-H</given-names></name><name><surname>Yin</surname><given-names>Z</given-names></name><name><surname>Han</surname><given-names>K</given-names></name><name><surname>Huang</surname><given-names>D-S</given-names></name><name><surname>Zhou</surname><given-names>X</given-names></name></person-group><article-title>A semi-supervised learning approach to predict synthetic genetic interactions by combining functional and topological properties of functional gene network</article-title><source>Bmc Bioinformatics</source><year>2010</year><volume>11</volume><issue>1</issue><fpage>1</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-11-S11-S1</pub-id><pub-id pub-id-type="pmid">20043860</pub-id></element-citation></ref><ref id="CR36"><label>36.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Kim</surname><given-names>D</given-names></name><name><surname>Shin</surname><given-names>H</given-names></name><name><surname>Joung</surname><given-names>J-G</given-names></name><name><surname>Lee</surname><given-names>S-Y</given-names></name><name><surname>Kim</surname><given-names>JH</given-names></name></person-group><article-title>Intra-relation reconstruction from inter-relation: miRNA to gene expression</article-title><source>BMC Syst Biol</source><year>2013</year><volume>7</volume><issue>3</issue><fpage>1</fpage><pub-id pub-id-type="pmid">23280066</pub-id></element-citation></ref><ref id="CR37"><label>37.</label><mixed-citation publication-type="other">Chen X, Yan G-Y. Semi-supervised learning for potential human microRNA-disease associations inference. Sci Rep. 2014;4:5501.</mixed-citation></ref><ref id="CR38"><label>38.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Nam</surname><given-names>Y</given-names></name><name><surname>Kim</surname><given-names>M</given-names></name><name><surname>Lee</surname><given-names>K</given-names></name><name><surname>Shin</surname><given-names>H</given-names></name></person-group><article-title>CLASH: Complementary Linkage with Anchoring and Scoring for Heterogeneous biomolecular and clinical data</article-title><source>BMC Med Inform Decis Mak</source><year>2016</year><volume>16</volume><issue>3</issue><fpage>72</fpage><pub-id pub-id-type="doi">10.1186/s12911-016-0315-2</pub-id><pub-id pub-id-type="pmid">27454118</pub-id></element-citation></ref><ref id="CR39"><label>39.</label><mixed-citation publication-type="other">Williams C, Seeger M. Using the Nystr&#x000f6;m method to speed up kernel machines. In: Proceedings of the 14th annual conference on neural information processing systems: 2001. p. 682&#x02013;688.</mixed-citation></ref><ref id="CR40"><label>40.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Woodbury</surname><given-names>MA</given-names></name></person-group><article-title>Inverting modified matrices</article-title><source>Memorandum Rep</source><year>1950</year><volume>42</volume><fpage>106</fpage></element-citation></ref><ref id="CR41"><label>41.</label><mixed-citation publication-type="other">Bengio Y, Delalleau O, Le Roux N. Label propagation and quadratic criterion. Semi-supervised Learn. 2006;10.</mixed-citation></ref><ref id="CR42"><label>42.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Boffi</surname><given-names>NM</given-names></name><name><surname>Hill</surname><given-names>JC</given-names></name><name><surname>Reuter</surname><given-names>MG</given-names></name></person-group><article-title>Characterizing the inverses of block tridiagonal, block Toeplitz matrices</article-title><source>Comput Sci Discov</source><year>2014</year><volume>8</volume><issue>1</issue><fpage>015001</fpage><pub-id pub-id-type="doi">10.1088/1749-4680/8/1/015001</pub-id></element-citation></ref><ref id="CR43"><label>43.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Hager</surname><given-names>WW</given-names></name></person-group><article-title>Updating the inverse of a matrix</article-title><source>SIAM Rev</source><year>1989</year><volume>31</volume><issue>2</issue><fpage>221</fpage><lpage>239</lpage><pub-id pub-id-type="doi">10.1137/1031049</pub-id></element-citation></ref><ref id="CR44"><label>44.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Meurant</surname><given-names>G</given-names></name></person-group><article-title>A review on the inverse of symmetric tridiagonal and block tridiagonal matrices</article-title><source>SIAM J Matrix Anal Appl</source><year>1992</year><volume>13</volume><issue>3</issue><fpage>707</fpage><lpage>728</lpage><pub-id pub-id-type="doi">10.1137/0613045</pub-id></element-citation></ref><ref id="CR45"><label>45.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Terekhov</surname><given-names>AV</given-names></name></person-group><article-title>A fast parallel algorithm for solving block-tridiagonal systems of linear equations including the domain decomposition method</article-title><source>Parallel Comput</source><year>2013</year><volume>39</volume><issue>6</issue><fpage>245</fpage><lpage>258</lpage><pub-id pub-id-type="doi">10.1016/j.parco.2013.03.003</pub-id></element-citation></ref><ref id="CR46"><label>46.</label><mixed-citation publication-type="other">Degenhardt L, Hall W, Lynskey M. What is comorbidity and why does it occur? Comorbid Mental disorders and substance use disorders: Epidemiology, prevention and treatment. 2003;10&#x02013;25.</mixed-citation></ref><ref id="CR47"><label>47.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piccirillo</surname><given-names>JF</given-names></name><name><surname>Tierney</surname><given-names>RM</given-names></name><name><surname>Costas</surname><given-names>I</given-names></name><name><surname>Grove</surname><given-names>L</given-names></name><name><surname>Spitznagel</surname><given-names>EL</given-names><suffix>Jr</suffix></name></person-group><article-title>Prognostic importance of comorbidity in a hospital-based cancer registry</article-title><source>Jama</source><year>2004</year><volume>291</volume><issue>20</issue><fpage>2441</fpage><lpage>2447</lpage><pub-id pub-id-type="doi">10.1001/jama.291.20.2441</pub-id><pub-id pub-id-type="pmid">15161894</pub-id></element-citation></ref><ref id="CR48"><label>48.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Piccirillo</surname><given-names>JF</given-names></name></person-group><article-title>Importance of comorbidity in head and neck cancer</article-title><source>Laryngoscope</source><year>2000</year><volume>110</volume><issue>4</issue><fpage>593</fpage><lpage>602</lpage><pub-id pub-id-type="doi">10.1097/00005537-200004000-00011</pub-id><pub-id pub-id-type="pmid">10764003</pub-id></element-citation></ref><ref id="CR49"><label>49.</label><mixed-citation publication-type="other">U.S. National Library of Medicine, Medical Subject Headings (<ext-link ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/mesh">www.ncbi.nlm.nih.gov/mesh</ext-link>, Acessed 5 Jan 2016)</mixed-citation></ref><ref id="CR50"><label>50.</label><mixed-citation publication-type="other">HuDiNe (<ext-link ext-link-type="uri" xlink:href="http://www.hudine.neu.edu/">www.hudine.neu.edu</ext-link>, Acessed 17 Jan 2016)</mixed-citation></ref><ref id="CR51"><label>51.</label><mixed-citation publication-type="other">Tanimoto TT. elementary mathematical theory of classification and prediction. New York; 1958.</mixed-citation></ref><ref id="CR52"><label>52.</label><mixed-citation publication-type="other">Swets JA. Signal detection theory and ROC analysis in psychology and diagnostics: Collected papers. New York. Psychology Press; 2014.</mixed-citation></ref><ref id="CR53"><label>53.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Fukunaga</surname><given-names>K</given-names></name><name><surname>Hummels</surname><given-names>DM</given-names></name></person-group><article-title>Leave-one-out procedures for nonparametric error estimates</article-title><source>IEEE Trans Pattern Anal Mach Intell</source><year>1989</year><volume>11</volume><issue>4</issue><fpage>421</fpage><lpage>423</lpage><pub-id pub-id-type="doi">10.1109/34.19039</pub-id></element-citation></ref><ref id="CR54"><label>54.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>McDonald</surname><given-names>V</given-names></name><name><surname>Scully</surname><given-names>M</given-names></name></person-group><article-title>Causes of thrombocytopenia</article-title><source>Medicine</source><year>2009</year><volume>3</volume><issue>37</issue><fpage>149</fpage><lpage>154</lpage><pub-id pub-id-type="doi">10.1016/j.mpmed.2008.12.007</pub-id></element-citation></ref><ref id="CR55"><label>55.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Warkentin</surname><given-names>TE</given-names></name><name><surname>Levine</surname><given-names>MN</given-names></name><name><surname>Hirsh</surname><given-names>J</given-names></name><name><surname>Horsewood</surname><given-names>P</given-names></name><name><surname>Roberts</surname><given-names>RS</given-names></name><name><surname>Gent</surname><given-names>M</given-names></name><name><surname>Kelton</surname><given-names>JG</given-names></name></person-group><article-title>Heparin-induced thrombocytopenia in patients treated with low-molecular-weight heparin or unfractionated heparin</article-title><source>N Engl J Med</source><year>1995</year><volume>332</volume><issue>20</issue><fpage>1330</fpage><lpage>1336</lpage><pub-id pub-id-type="doi">10.1056/NEJM199505183322003</pub-id><pub-id pub-id-type="pmid">7715641</pub-id></element-citation></ref><ref id="CR56"><label>56.</label><element-citation publication-type="journal"><person-group person-group-type="author"><name><surname>Sun</surname><given-names>K</given-names></name><name><surname>Gon&#x000e7;alves</surname><given-names>JP</given-names></name><name><surname>Larminie</surname><given-names>C</given-names></name><name><surname>Pr&#x0017e;ulj</surname><given-names>N</given-names></name></person-group><article-title>Predicting disease associations via biological network analysis</article-title><source>BMC bioinformatics</source><year>2014</year><volume>15</volume><issue>1</issue><fpage>1</fpage><pub-id pub-id-type="doi">10.1186/1471-2105-15-S6-S1</pub-id><pub-id pub-id-type="pmid">24383880</pub-id></element-citation></ref></ref-list></back></article>