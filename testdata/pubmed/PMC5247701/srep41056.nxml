<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.0 20120330//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">Sci Rep</journal-id><journal-id journal-id-type="iso-abbrev">Sci Rep</journal-id><journal-title-group><journal-title>Scientific Reports</journal-title></journal-title-group><issn pub-type="epub">2045-2322</issn><publisher><publisher-name>Nature Publishing Group</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">28106139</article-id><article-id pub-id-type="pmc">5247701</article-id><article-id pub-id-type="pii">srep41056</article-id><article-id pub-id-type="doi">10.1038/srep41056</article-id><article-categories><subj-group subj-group-type="heading"><subject>Article</subject></subj-group></article-categories><title-group><article-title>Spatio-Temporal Tolerance of Visuo-Tactile Illusions in Artificial Skin by Recurrent Neural Network with Spike-Timing-Dependent Plasticity</article-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Pitti</surname><given-names>Alexandre</given-names></name><xref ref-type="corresp" rid="c1">a</xref><xref ref-type="aff" rid="a1">1</xref></contrib><contrib contrib-type="author"><name><surname>Pugach</surname><given-names>Ganna</given-names></name><xref ref-type="aff" rid="a1">1</xref><xref ref-type="aff" rid="a2">2</xref><xref ref-type="author-notes" rid="n1">*</xref></contrib><contrib contrib-type="author"><name><surname>Gaussier</surname><given-names>Philippe</given-names></name><xref ref-type="aff" rid="a1">1</xref><xref ref-type="author-notes" rid="n1">*</xref></contrib><contrib contrib-type="author"><name><surname>Shimada</surname><given-names>Sotaro</given-names></name><xref ref-type="aff" rid="a3">3</xref><xref ref-type="author-notes" rid="n1">*</xref></contrib><aff id="a1"><label>1</label><institution>ETIS Laboratory, UMR CNRS 8051, University of Cergy-Pontoise</institution>, ENSEA, Cergy-Pontoise, <country>France</country></aff><aff id="a2"><label>2</label><institution>Energy and Metallurgy Department, Donetsk National Technical University</institution>, Krasnoarmeysk, <country>Ukraine</country></aff><aff id="a3"><label>3</label><institution>Dept. of Electronics and Bioinformatics, School of Science and Technology, Meiji University</institution>, Kawasaki, <country>Japan</country></aff></contrib-group><author-notes><corresp id="c1"><label>a</label><email>alexandre.pitti@u-cergy.fr</email> or <email>sshimada@meiji.ac.jp</email></corresp><fn id="n1"><label>*</label><p>These authors contributed equally to this work.</p></fn></author-notes><pub-date pub-type="epub"><day>20</day><month>01</month><year>2017</year></pub-date><pub-date pub-type="collection"><year>2017</year></pub-date><volume>7</volume><elocation-id>41056</elocation-id><history><date date-type="received"><day>23</day><month>03</month><year>2016</year></date><date date-type="accepted"><day>16</day><month>12</month><year>2016</year></date></history><permissions><copyright-statement>Copyright &#x000a9; 2017, The Author(s)</copyright-statement><copyright-year>2017</copyright-year><copyright-holder>The Author(s)</copyright-holder><license xmlns:xlink="http://www.w3.org/1999/xlink" license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><!--author-paid--><license-p>This work is licensed under a Creative Commons Attribution 4.0 International License. The images or other third party material in this article are included in the article&#x02019;s Creative Commons license, unless indicated otherwise in the credit line; if the material is not included under the Creative Commons license, users will need to obtain permission from the license holder to reproduce the material. To view a copy of this license, visit <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/">http://creativecommons.org/licenses/by/4.0/</ext-link></license-p></license></permissions><abstract><p>Perceptual illusions across multiple modalities, such as the rubber-hand illusion, show how dynamic the brain is at adapting its body image and at determining what is part of it (the self) and what is not (others). Several research studies showed that redundancy and contingency among sensory signals are essential for perception of the illusion and that a lag of 200&#x02013;300&#x02009;ms is the critical limit of the brain to represent one&#x02019;s own body. In an experimental setup with an artificial skin, we replicate the visuo-tactile illusion within artificial neural networks. Our model is composed of an associative map and a recurrent map of spiking neurons that learn to predict the contingent activity across the visuo-tactile signals. Depending on the temporal delay incidentally added between the visuo-tactile signals or the spatial distance of two distinct stimuli, the two maps detect contingency differently. Spiking neurons organized into complex networks and synchrony detection at different temporal interval can well explain multisensory integration regarding self-body.</p></abstract></article-meta></front><body><p>Accumulated evidence demonstrates the extraordinary lability of the body image, which is thought to emerge from the dynamic integration of signals from the different senses<xref ref-type="bibr" rid="b1">1</xref><xref ref-type="bibr" rid="b2">2</xref><xref ref-type="bibr" rid="b3">3</xref><xref ref-type="bibr" rid="b4">4</xref>. The redundancy of the signals and, in particular, their contingency is strongly believed to be captured for acquiring body image. However, its neural embedding should be robust enough to permit slightly incongruous signals to bind each other while retaining the ability to detect inconsistency for largely incongruous ones. For instance, <italic>spatial</italic> or <italic>temporal</italic> mismatches during visuo-tactile events can distort spatial judgment of the location of the body limbs, whereas its perfect congruence can enhance judgment of the spatial location<xref ref-type="bibr" rid="b5">5</xref><xref ref-type="bibr" rid="b6">6</xref>. Exemplary experiments are the rubber-hand illusion (visuo-tactile congruence), amputees with phantom-limb illusions, patients with spatial hemineglect, and asomatognosic patients who deny the ownership of their own limb (proprioceptive and efferent copy binding)<xref ref-type="bibr" rid="b1">1</xref>. These cases are based on malfunction of the detection of contingency in the ongoing sensorimotor information flow or in the virtual one reconstructed in the parieto-motor circuits. Perception of the contingency is accompanied by sense of agency and body ownership<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b9">9</xref>, whereas its distortion can give rise to a sense of other, which is essential for inter-subjectivity. The congruence of multi-sensory signals has been acknowledged for self-perceptual experiences<xref ref-type="bibr" rid="b6">6</xref>. Among the studies that emphasize this aspect in the rubber-hand illusion (RHI), Shimada <italic>et al</italic>.<xref ref-type="bibr" rid="b10">10</xref> showed that delayed visual feedback as short as 200&#x02013;300 milliseconds can disrupt the illusion effect.</p><p>The perception of self-body in RHI is associated with different brain areas, mainly the parietal cortex interconnected to other regions like the premotor cortex or the extrastriate body area in the lateral occipitotemporal cortex as revealed by recent fMRI studies; e.g.<xref ref-type="bibr" rid="b11">11</xref><xref ref-type="bibr" rid="b12">12</xref>. Within the parietal cortex, neurons in the superior parietal lobe (SPL) and intra-parietal sulcus (IPS) are found more active during self-motion, whereas their activity is more attenuated as the delay lengthened<xref ref-type="bibr" rid="b13">13</xref><xref ref-type="bibr" rid="b14">14</xref>. In contrast, there is only a few neurons in these regions that show opposite responses to the delay and during the actions of others whereas they are found in a bigger proportion in the right inferior parietal lobe (rIPL)<xref ref-type="bibr" rid="b13">13</xref><xref ref-type="bibr" rid="b14">14</xref>. Based on these observations, many researchers have suggested a comparator model for self-assessment. In this view, a forward dynamic model predicts the consequences of motor commands, and these are compared with the actual feedback<xref ref-type="bibr" rid="b15">15</xref>. Depending on the degree of sensory discrepancy (e.g., the contingency between the afferent signals), one brain network will identify self-produced actions as our own actions or will recognize another person&#x02019;s actions<xref ref-type="bibr" rid="b16">16</xref><xref ref-type="bibr" rid="b17">17</xref>.</p><p>However, the network identification cannot explain (<italic>1</italic>) why the peculiar 200&#x02013;300&#x02009;ms delays are detected or (<italic>2</italic>) the functional organization of the parietal cortex for self-other recognition that links the external biological motion (macroscopic level) with the internal neuron dynamics (microscopic scale). We propose to answer these questions with neurocomputational models. Because timing (i.e., synchrony, contingency, rhythmical patterns and temporal delays) is a crucial computational factor in neural networks, we believe that Hebbian learning is at the root of the temporal integration within sensorimotor networks<xref ref-type="bibr" rid="b18">18</xref>. More precisely, the biologically inspired mechanism of spike-timing-dependent plasticity (STDP<xref ref-type="bibr" rid="b19">19</xref><xref ref-type="bibr" rid="b20">20</xref>) can serve to detect the contingency at the neural level for categorizing the sensorimotor signals in a situation of interaction with others<xref ref-type="bibr" rid="b21">21</xref>. Because STDP permits reinforcement of the synaptic links between synchronous neurons and prediction of long sensorimotor patterns in real time<xref ref-type="bibr" rid="b22">22</xref>, the prediction level can serve for contingency detection and self-motion recognition<xref ref-type="bibr" rid="b23">23</xref><xref ref-type="bibr" rid="b24">24</xref>.</p><p>In this paper, we relate neural models with the previous work by Shimada <italic>et al</italic>.<xref ref-type="bibr" rid="b10">10</xref> to elucidate how the rubber-hand illusion is performed in the parietal lobe and why it does not occur when the visual and tactile inputs are separated by 200&#x02013;300&#x02009;ms. Using an artificial skin, a video camera and recurrent neural networks of spiking neurons, we studied how multi-modal integration occurs within the networks and how spatio-temporal patterns are learned based on contingency detection. We assumed that the most congruent sensorimotor patterns strengthen their links more than the incongruent ones and that the activity level within the network is associated with the recognition of self or other. The comparison of the activity levels of these two clusters of neurons may enable differentiation of, to some extent, true synchronization from false ones. The main findings of our study is that the combination of STDP and recurrent NN can reproduce the limited attenuation of multisensory integration with temporally incongruent sensory inputs (150&#x02009;ms) regarding the body, similarly seen in RHI. A recurrent multimodal network hierarchically organized into a complex network is more robust to delays and incongruous signals similarly seen in RHI than a simple associative map.</p><sec disp-level="1"><title>Results</title><p>The learning process within the neural maps is performed sequentially by presenting instances of visuo-tactile signals when the hand (contact point of 2&#x02009;<italic>cm</italic><sup>2</sup>) moves above the tactile device and is always in contact with it, under the vision field of the camera (see <xref ref-type="fig" rid="f1">Fig. 1</xref> and the Device and Methods section).</p><sec disp-level="2"><title>Receptive Fields of Associative and Recurrent Maps</title><p>Each map learns its proper incoming signals so that we can observe functional differences between the unimodal maps, the associative (asso.) and recurrent (rec.) maps to represent the visual and tactile as well as the visuo-tactile receptive fields (RFs), see <xref ref-type="fig" rid="f2">Fig. 2</xref>. To better understand how the neural maps behave for different initial conditions, we plotted the neural map activity for two different spatial locations of the contact point, which means there were two different RFs. The first two plots in <xref ref-type="fig" rid="f2">Fig. 2(a)</xref> (resp. g) display the tactile and visual RFs associated with the two unimodal maps recorded for one particular location. The next two plots in <xref ref-type="fig" rid="f2">Fig. 2(b)</xref> (resp. h) present the visuo-tactile RFs associated with the activity of one selected bimodal neuron in the asso. map, which is also the most active for that particular location. The two plots presented in <xref ref-type="fig" rid="f2">Fig. 2(c)</xref> (resp. i) correspond to the spatial RFs of one selected bimodal neuron in the rec. map, which also corresponds most closely to that particular spatial location. The respective plots in <xref ref-type="fig" rid="f2">Fig. 2(e) and (f)</xref> (resp. k and l) are the corresponding visual RFs of the asso. neuron and of the rec. neuron when a visual delay of 300&#x02009;<italic>ms</italic> is added; see plots in (d) and (j). These sets of graphs show that the asso. and rec. neurons have similar visual and tactile RFs located in the upper-left area. The asso. map successfully learns the bimodal correspondence between the spatial RFs of each unimodal map as well as their spatial limits; for instance, the bimodal association is restricted to a small tactile area and to a small visual area, in comparison with the unimodal RFs. At the same time, we observe that the RFs of the asso. neuron are slightly different from their current location in the unimodal map, whereas the RFs of the rec. neuron cover a broader area, similar with the spatial range of the stimulus in the unimodal maps. Moreover, when a visual delay of 300&#x02009;<italic>ms</italic> is added, the two maps show some added noise in the spatial estimation of their respective RFs.</p><p>We propose that at some points the bimodal maps show how the asso. and rec. maps have learned a unified multimodal representation. These differences between the two maps can reflect some functional differences in the detection of visuo-tactile contingency and in the processing of erroneous signals or illusory events. The comparison between the two maps or their dynamic registration can serve then to better detect the contingent signals.</p></sec><sec disp-level="2"><title>Visuo-Tactile Interference Patterns of the Neural Activity</title><p>The plots in <xref ref-type="fig" rid="f3">Fig. 3</xref> show a novel method that we propose and name an interferogram. As an analogy with signal processing, we propose to study the <italic>interference patterns</italic> that one signal makes on another when they are combined with respect to delays; how delayed visual signals interfere with tactile signals in the bimodal neurons of the asso and rec maps? The analysis of interferograms can help us better understand how delays influence the occurrence of a signal degradations (negative interferences) and signal enhancement during illusion effect) at the neuron level and for delays in the interval range between [0, 600&#x02009;<italic>ms</italic>]. The interferograms in <xref ref-type="fig" rid="f3">Fig. 3</xref> present the dynamics of two neurons plotted for visual delays up to 600&#x02009;<italic>ms</italic> (vertical axis) from the associative map in a) and from the recurrent map in b).</p><p>A strong vertical activity of the neuron indicates the spatial proximity of the visuo-tactile stimulus to the neuron receptive field, whereas a lower vertical activity of the neuron indicates the situations of distal and non-congruent tactile stimuli. Therefore, the vertical lines represent the sensitivity of the neuron to the immediate tactile stimulation (its tactile receptive field), whereas the diagonal lines represent the sensitivity of the neuron to the delayed visual input (its visual receptive field). Strong activity in the vertical lines indicates that the network holds visual input for a while so that immediate tactile stimulation can fire the neuron, whereas strong activity in the diagonal lines indicates that the network holds tactile input for a while so that delayed visual input can fire the neuron. This property is more prominent in rec. neurons than in asso. neurons, where the former behave more like a working memory for the self-body image, with anticipatory and hysteresis effects. The working memory effect is due to the recurrent links in the rec. map, which permit the neurons to learn spatio-temporal sequences, although the temporal interval of each neural pair is limited to only 50&#x02009;<italic>ms</italic>, as fixed in the experiment (see Devices and methods).</p><p>At the neural mass level, the mean and the standard deviation of the neurons for each map can provide a metric of the confidence level of the neurons for contingency detection; see resp. <xref ref-type="fig" rid="f4">Fig. 4(a,b)</xref>. In <xref ref-type="fig" rid="f4">Fig. 4a</xref>), the variations between the situation in the no-delay condition and the situation in the delayed condition (500&#x02009;<italic>ms</italic> visual delays) show that the variance is increased in the case of the delay condition, almost the double. Moreover, the recurrent map is more robust to delays than the associative map as it has a lower variance (one-third lower), the confidence level is therefore better in this case. This suggests that the comparison of the neural activity to a threshold value can permit detecting temporal discrepancy and determining with a confidence level whether an illusion has occurred.</p><p>The confidence level computed in <xref ref-type="fig" rid="f4">Fig. 4b</xref>) corresponds to the mean and the standard deviation of the difference between the most active neurons with respect to the local field potential. It can provide a metric of the signal to the noise at the population level for contingency detection. This graph shows similar results to <xref ref-type="fig" rid="f4">Fig. 4a</xref>) for which, the variations between the situation in the no-delay condition and the situation in the delayed condition for the confidence level is diminishing in the case of the delay condition, with a higher value for the rec map.</p><p>We further investigated this issue with the use of temporal delays in the visual input to manipulate the visuo-tactile associations within the networks. Any temporal delays between the visual and tactile signals will distort the activity level within the neural maps, although the amplitude level cannot provide clear insight into the presence or absence of an illusion. As an example, the plot in <xref ref-type="fig" rid="f5">Fig. 5(a,b)</xref> shows the neural activity of one neuron in the associative map selective to one spatial location when the hand is entering its area of influence or leaving it and for various visual delays up to 150&#x02009;<italic>ms</italic> whereas the plot in <xref ref-type="fig" rid="f5">Fig. 5(c,d)</xref> shows the neural activity of one neuron in the associative map and of one neuron in the recurrent map when the hand is entering their area of influence and for various visual delays up to 150&#x02009;<italic>ms</italic>. The vertical black line corresponds to the time-to-contact, which is the period when we enter in the tactile neuron&#x02019;s receptive field. The two plots (a-b) correspond to the situation when the spatial location of the hand with the visual feedback delay is outside from the spatial location of the neuron&#x02019;s visual RF in <xref ref-type="fig" rid="f5">Fig. 5(a)</xref> and when the spatial location of the hand with the visual feedback delay is inside the spatial location of the neuron&#x02019;s visual RF in <xref ref-type="fig" rid="f5">Fig. 5(b)</xref>. The plots <xref ref-type="fig" rid="f5">Fig. 5(c) and (d)</xref> is a comparison of the behavior between the asso neuron and the rec neuron, which shows an anticipatory effect and a much stronger activity of the rec neuron before the time-to-contact than the asso neuron.</p><p>Although a visual delay has been added, the graphs in <xref ref-type="fig" rid="f5">Fig. 5(a,d)</xref> show that the neuron always fires when the hand is moving within the neuron&#x02019;s tactile RF; i.e., the time-to-contact on this spatial location in the tactile sheet. Nonetheless, the behavior is different for the two maps. For the asso map, the signal degradation is caused by the spatial distance between the current location of the hand (tactile response) and the visual location in the delayed image (visual response). By contrast, for the recurrent map, the signal enhancement is due by the network property of the recurrent map (its recurrent links), which has bigger receptive fields. These latter situations <xref ref-type="fig" rid="f5">Fig. 5(b) and (d)</xref> may correspond to an illusory effect: the spatial proximity of each RF enhances the neural activity, giving the illusion of temporal contingency, although a temporal delay was added.</p><p>On the one hand, when the visual and tactile RFs are misaligned, which corresponds to <xref ref-type="fig" rid="f5">Fig. 5(a)</xref>, gradually adding a delay greater than 50&#x02009;<italic>ms</italic> has the direct effect of diminishing the neural activity level, although the precise timing of the time-to-contact of the hand entering the neuron RF is preserved. On the other hand, in situations of spatially contiguous visuo-tactile RFs, which correspond to <xref ref-type="fig" rid="f5">Fig. 5(b)</xref>, we can observe the counter-intuitive result of an <italic>increasing</italic> neural activity when visual delays are added, even though the precise timing of the time-to-contact is preserved. In this situation, the spatial congruity gives the illusion of temporal contingency.</p></sec><sec disp-level="2"><title>Neural Property with Respect to Visual Feedback Delay</title><p>To analyze the statistical properties of the two maps, we measure how their neural dynamics behave with respect to the visual feedback delays. The plot in <xref ref-type="fig" rid="f6">Fig. 6</xref> shows the spatial estimation in the asso. and rec. maps, their synchronization level, and their amplitude level with respect to delays; the top, middle and bottom charts, respectively. These measures of the delayed neural activity were analyzed and compared with the neural activity retrieved when the hand is inside each neuron&#x02019;s tactile RFs at the time-to-contact in the zero-delay condition, which occurred when the neuronal signals are above the threshold value of 1.5, as heuristically chosen. The neuron spikes above this threshold correspond to the vertical lines displayed in <xref ref-type="fig" rid="f3">Fig. 3(a,b)</xref>, when the current visuo-tactile signals are within its receptive field. The bottom chart presents the congruent mean activity for the recurrent map (resp. associative) as a red line (resp. in blue line) for visual delays less than 1000&#x02009;<italic>ms</italic>. The middle chart displays the spike distance measure proposed by Victor and Purpura (VP), which computes the spike variability and the level of phase synchronization between two spike trains with a cost function<xref ref-type="bibr" rid="b25">25</xref>. The VP distance was calculated between a spike train in the non-delay condition and its corresponding spike train in the delayed condition. The top chart corresponds to the visual spatial error estimated for all the neurons with respect to delays and calculated as the euclidean distance between the visual spatial position estimated during the non-delay condition and the current visual spatial position retrieved during the delayed condition.</p><p>The graphs present three different neural regimes with respect to the visual delay added. Below 50&#x02009;<italic>ms</italic>. the first regime can be defined with a power-law function with a rapid discrepancy in the neurons&#x02019; dynamics for the asso. map only. Below 150&#x02009;<italic>ms</italic>., the second regime can also be defined with a power-law function but with a slower discrepancy, for the rec. map only. Above 150&#x02009;<italic>ms</italic>, however, the two curves confound each other or present similar trends for the three charts. These three different neural regimes characterize the conditions that determine whether the illusory effects occur.</p><p>During the discrepancy stage for delays &#x0003c;150&#x02009;<italic>ms</italic>, the neural signals are inversely proportional to the visual delay added; therefore, adding a visual delay affects the gain level of the neurons, which means that the two neural maps are sensitive to visual delays. The two maps have similar trends in the bottom chart but different amplitude levels. These differences can also be seen in the two other charts, where the VP distance indicates a better response of the rec. map than the asso. map to phase-synchronize to the correct signals even in the presence of delays. The top chart shows a spatial estimation error or a spatial drift of the visual location of the target relative to delays. The RFs of the neurons in the rec. map are sensitive to a larger spatial area than those of the asso. map. In the temporal domain, the response characteristics of the rec map to visual delays in the bottom graph are slightly higher than the asso map during the 200&#x02013;500&#x02009;ms interval although no t-tests were performed. In comparison to the associative neurons, the robustness of the rec. map can be explained by its recurrent links, which form neural groups capable of sustaining longer spatio-temporal sequences chained dynamically, better anticipating the spatio-temporal memory traces and recovering from erroneous signals.</p><p>These three results adequately support the observations made on the asso. and rec. maps for multimodal integration and spatio-temporal binding in RHI-like experiments; i.e., the decrease in neural activity, phase lags and spatial estimation errors. The comparison of the two threshold values of 50&#x02009;<italic>ms</italic> and 150&#x02009;<italic>ms</italic> for each parameter (spatial, temporal and amplitude-level) and for the two maps may make it possible to distinguish the first case of self-recognition during the illusion (both thresholds below 50&#x02009;<italic>ms</italic>) from the second case of illusion perception and its detection at the same time (for the intervals 50&#x02009;<italic>ms</italic> and 150&#x02009;<italic>ms</italic>).</p><p>Above 150&#x02009;<italic>ms</italic>, the neural signals present low but stable dynamics (bottom chart). A similar trend is depicted in the two other charts, with a static phase lag and visual error, which correspond to the temporal limit of the illusory effect. The stable VP distance corresponds to phasic errors for the two maps, and if the rec. map has a lower VP index, it predicts more accurately than the asso. map. These temporal errors have some influence in the spatial estimation (top chart), with more fluctuation for the asso. map. The two maps have similar trends for the three measures, with variations proportional to the delays. This interval range is above the limit of the contingency perception of the delayed signal.</p></sec><sec disp-level="2"><title>Small-world Network Property in Recurrent Map</title><p>To understand better how the functional organization of the rec. network and its topology relate to each other, we analyzed three quantitative methods taken from graph theory and complex networks<xref ref-type="bibr" rid="b26">26</xref>. <xref ref-type="fig" rid="f7">Figure 7</xref> shows different indices that characterize the topology of complex networks in general and of the neural circuits found in the human brain in particular<xref ref-type="bibr" rid="b27">27</xref><xref ref-type="bibr" rid="b28">28</xref><xref ref-type="bibr" rid="b29">29</xref>. These measures are named the centrality index, the similarity index and the connectivity index for the neurons of the rec. map; <xref ref-type="fig" rid="f7">Fig. 7(a,b)</xref>, (c-c&#x02019;-d) and (e,f), respectively. We want to explain why the recurrent map is more robust against small delays than the associative map as showed in <xref ref-type="fig" rid="f6">Fig. 6</xref>. It is important in order to characterize multimodal networks based on timing in associative areas such as the parietal cortex. The measures presented show that the recurrent network splits the neural population into two class of neurons, neurons with strong bimodal coupling and neurons with loose bimodal coupling. This topology corresponds to a complex network demonstrating nonlinear behaviors as in perceptual illusion.</p><p>The centrality index plotted in <xref ref-type="fig" rid="f7">Fig. 7(a)</xref> defines the density distribution of neurons within the network that are found central to it. These neurons are the most connected ones (the green line), receiving the most information from the upstream signals of the pre-synaptic neurons and propagating the most to the downstream signals of the post-synaptic neurons (the blue and red dashed lines, respectively). The centrality index indicates that few neurons within the network (less than 10%) are highly connected and possess a high score, whereas the majority of the neurons have an average or a very low score. These latter neurons are at the periphery of the network in comparison to the most connected neurons, which are few in number. The logarithmic curve in the histogram plot in <xref ref-type="fig" rid="f7">Fig. 7(b)</xref> is typical of small-world networks<xref ref-type="bibr" rid="b28">28</xref><xref ref-type="bibr" rid="b29">29</xref>.</p><p>The similarity index in <xref ref-type="fig" rid="f7">Fig. 7(c-c&#x02019;</xref>) is defined as the inverse of the distance between the neurons&#x02019; weights computed for all neuron pairs. In complement to the similarity index of the rec map in <xref ref-type="fig" rid="f7">Fig. 7(c)</xref>, we add the similarity index of the asso map in <xref ref-type="fig" rid="f7">Fig. 7(c&#x02019;)</xref> for comparison. The matrix for the asso map shows that there exists a lot of redundancy among the neurons that overly encode bimodal signals, which are then difficult to separate or discriminate. This topology is different from a small-world network. The rec matrix in (c) instead is sparse, which is characteristic of a hierarchical organization within the network, with the neurons as part of isolated groups. The histogram in <xref ref-type="fig" rid="f7">Fig. 7(d)</xref> shows that a large population of neurons are part of the same group, as they have more or less the same similarity index centered around the value 0.002, with some neurons very similar to each other (similarity index above 0.004) and others very unique (similarity index near 0.00). As for the centrality measure, these latter two groups differ from the bulk of the neuron, and can therefore correspond to distinct functional behaviors within the network.</p><p>Finally, the connectivity matrix plotted in <xref ref-type="fig" rid="f7">Fig. 7(e)</xref> is defined as the one-to-one and unidirectional connection strength between two neurons taken from their synaptic links. In comparison to the two previous qualitative measures, the connectivity index is another measure of the importance of particular neurons at the network level. In accordance with them, this measure again informs about the importance of some neurons, with a histogram of the connectivity index plotted in <xref ref-type="fig" rid="f7">Fig. 7(f)</xref> following a power-law curve as for the centrality index, typical of a small-world network.</p></sec></sec><sec disp-level="1"><title>Discussion</title><p>Our current experiment attempts to replicate visuo-tactile illusions such as the so-called RHI experiment to understand how neurons establish a unified representation by means of visuo-tactile experiences and how delays can extinguish its perception. Although it is not explicitly labeled as &#x0201c;self-body&#x0201d;, and that the neural activation does not have a subjective feeling of RHI reported in the literature<xref ref-type="bibr" rid="b30">30</xref>, the visual hand that coincides with tactile sensation should be understood as a unified perception, and our neural nets learned this task properly. Our main message is that STDP and a recurrent network can reproduce the attenuation of multisensory integration with temporally incongruent sensory inputs (150&#x02009;ms) regarding the body and that spiking neurons organized into complex networks can duplicate timely-based as well as distorted signals similarly seen in RHI. We summarize in <xref ref-type="table" rid="t1">Table 1</xref> the different situations for attenuation of multisensory integration depending on the visuo-tactile delays on the two maps, which may correspond to self recognition for real or perceived illusions or as other when no illusions are perceived.</p><p>The same mechanism for detect (in)congruencies in predicted and actual sensory action feedback may serve for self-other distinction. Each neuron learns its own visuo-tactile RF, which permits detection of the contingency of the visuo-tactile signals so that the temporal delays and spatial distance to its respective RF can affect the amplitude level of the neurons per se. The amplitude level of the neuron describes the conditions for self-body detection for inducing perceptual illusions such as in the RHI. Considering the difference between the two maps, the recurrent neurons are very robust to delays, sometimes with a tolerance of 150&#x02009;<italic>ms</italic> or so, whereas asso. neurons sometimes showed fluctuations in activity with a delay shorter than 50&#x02009;<italic>ms</italic>. Even the interval within 200&#x02013;500&#x02009;ms is slightly differentiated between the amplitude values of the rec map and of the asso map in <xref ref-type="fig" rid="f6">Fig. 6</xref> in the bottom chart. This information may serve to sketch a conceptual model regarding the neural mechanisms involved in spatial estimation of multimodal events as during RHI or even ventriloquism.</p><sec disp-level="2"><title>Neurons anchored in the tactile receptive fields</title><p>Our experimental results show that visuo-tactile neurons are anchored in tactile receptive fields as can be inferred from the interferograms in <xref ref-type="fig" rid="f3">Fig. 3</xref>, where vertical lines indicate the neuron sensitivity to tactile RF. The diagonal lines instead indicate the neurons&#x02019; sensitivity to only the visual RF. The rec. map is noticeably more tolerant than the asso. map to contradictory locations of the RFs and is therefore more robust to visual delays, as can also be seen from the better neural responses of the rec map in <xref ref-type="fig" rid="f3">Fig. 3</xref> with respect to the visual delays. We can understand that the functional role of those neurons is to translate a spatial distance from their visuo-tactile RFs into an amplitude variation, and temporal delays can also modulate their responses. Therefore, a &#x0201c;spatial distance&#x0201d; between the visuo-tactile signals or a &#x0201c;time lag&#x0201d; between the two modalities can be seen as variables that can be equally interchanged. Nonetheless, their relationship is non-linear, so within the limit of 150&#x02009;<italic>ms</italic>, the neural amplitude level can convey information about the distance of one object to the RF. This distance measure can serve for, for instance, perceiving the body in its own reference frame and the space around it; the so-called peri-personal space is important for body ownership as well as for reaching objects nearby and defensive behaviors for object avoidance<xref ref-type="bibr" rid="b31">31</xref>.</p><p>The learning of visuo-tactile integration is rapid in the neural networks, which is in line with previous observations and models in favor of an acquisition at an early stage of somatotopic and visuo-tactile body maps<xref ref-type="bibr" rid="b32">32</xref><xref ref-type="bibr" rid="b33">33</xref><xref ref-type="bibr" rid="b34">34</xref><xref ref-type="bibr" rid="b35">35</xref><xref ref-type="bibr" rid="b36">36</xref>. Experiments with infants as old as 6 months show their sensitivity to small temporal delays for self-body registration and for self-other differentiation<xref ref-type="bibr" rid="b7">7</xref><xref ref-type="bibr" rid="b8">8</xref>.</p></sec><sec disp-level="2"><title>STDP and contingency detection</title><p>The temporal coherency needed for the neuron to be fired is different for the simple associative map and for the recurrent map, which also describes a difference in their functional organization.</p><p>In our experiments, the amplitude level of the neurons characterizes the visuo-tactile contingency level, which is in line with the results found in fMRI studies showing the existence of contingency detectors for self-motion in experiments similar to those with the delayed RHI<xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b16">16</xref>. At the brain level, the mechanism for contingency detection in multisensory neurons is often attributed to the neural mechanism of spike-timing-dependent plasticity<xref ref-type="bibr" rid="b37">37</xref> (STDP) because the precise timing of a pre-synaptic neuron can determine whether a post-synaptic neuron is fired. With respect to sensorimotor networks, we propose that STDP supports the release of contingency detectors at the millisecond order so that the temporal coordination of groups of neurons can describe a certain level of self-motion prediction, which can be used at the population level for error prediction; e.g., for self-assessment of body motion<xref ref-type="bibr" rid="b37">37</xref> or limb ownership<xref ref-type="bibr" rid="b24">24</xref>. The organization of the recurrent network follows a small-world network structure so that few neurons can integrate and anticipate slightly distant multimodal events (loose contigency detection) with respect to the majority of neurons that can encode only unique multimodal events (strict contingency detection), see <xref ref-type="fig" rid="f8">Fig. 8</xref>.</p></sec><sec disp-level="2"><title>150&#x02009;ms contingency discrepancy and the peri-personal space</title><p>One critical result is the 150&#x02009;ms contingency discrepancy found in the visuo-tactile neural networks, which is very near the temporal constant of 100&#x02013;140&#x02009;ms found in the recording of event-related potentials during tactile remapping experiments<xref ref-type="bibr" rid="b38">38</xref><xref ref-type="bibr" rid="b39">39</xref> and the temporal responses found by Shokur and colleagues to virtual touches of neurons in S1 and M1 during RHI, which occurred 50 to 70&#x02009;ms later than those to physical touch, whereas V-only responses occurred 90&#x02009;ms after the stimulus<xref ref-type="bibr" rid="b40">40</xref>. These intervals are also similar to the 200&#x02013;300&#x02009;ms found in the delayed RHI task in a previous study<xref ref-type="bibr" rid="b10">10</xref>.</p><p>The 150&#x02009;<italic>ms</italic> temporal discrepancy can be understood as the limit of the visuo-tactile integration of the neurons&#x02019; respective RFs; see <xref ref-type="table" rid="t1">Table 1</xref>
<italic>cases</italic> #1 and #2. This temporal limit represents the visual spatial error with respect to the tactile RF, which corresponds to its area of influence at this location when an object enters this region<xref ref-type="bibr" rid="b41">41</xref><xref ref-type="bibr" rid="b42">42</xref>. Above this limit, any visuo-tactile signal is considered outside its area of influence and the multimodal integration effect is not perceived; see <xref ref-type="table" rid="t1">Table 1</xref>
<italic>case</italic> #3.</p><p>This result agrees with the idea that reference frames and anatomical and external spatial coding are concurrently active or interfering, and the dominance of one reference frame over the other and the integration of different reference frames are based on sensorimotor contingencies<xref ref-type="bibr" rid="b38">38</xref>. However, this work does not address the problem of coordinate transformations between different modalities in multisensory integration. Previous works done by the authors model the mechanism of gain-modulation found in parietal neurons for audio-visual and visuomotor coordinate transformations<xref ref-type="bibr" rid="b43">43</xref><xref ref-type="bibr" rid="b44">44</xref>. In future works, one attempt will be to extend this model to coordinate tranformation of visuo-tactile and proprioceptive reference frames for simulating RHI with a robotic hand.</p></sec><sec disp-level="2"><title>The comparator/identification model</title><p>Our architecture relies on the functional organization of two different maps&#x02013;the asso. map and the rec. map&#x02013;which provide different types of information that can be combined with each other; see <xref ref-type="table" rid="t1">Table 1</xref>. We propose that parietal neurons can use these mechanisms during self-motion as well as during other-motion<xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b45">45</xref>.</p><p>For instance, we may compare the amplitude level between these two maps to falsify self-based motion from someone else&#x02019;s motion. Below 50&#x02009;ms, the contingency detection is strict and is validated two times by the two maps; see <xref ref-type="table" rid="t1">Table 1</xref>
<italic>case</italic> #1. In the interval 50&#x02009;ms&#x02013;150&#x02009;ms, the contingency detection is weaker and validated only one time by the rec map; see <xref ref-type="table" rid="t1">Table 1</xref>
<italic>case</italic> #2. A comparator model would require at least 150&#x02009;ms to wait for the end of the process for the two maps. However, a more elaborate version of it, an <italic>identification layer</italic>, would require even more time if it had to identify (<italic>1</italic>) the nature of the input signals received and (<italic>2</italic>) how far they are from the expected ones<xref ref-type="bibr" rid="b15">15</xref>. This idea is an extension of the comparator model proposed by Blanke and others<xref ref-type="bibr" rid="b9">9</xref><xref ref-type="bibr" rid="b46">46</xref>, as well as Hiraki and colleagues, for body ownership<xref ref-type="bibr" rid="b8">8</xref><xref ref-type="bibr" rid="b14">14</xref>, in which the parietal cortex is at the-forefront of comparing and distinguishing the even of integrated proprioceptive/multimodal information from the odds of non-strict contingent information, see <xref ref-type="fig" rid="f8">Fig. 8</xref>. The rIPL may be a candidate for detecting (in)congruencies in predicted and actual sensory action feedback and its structure may be organized as a small-world network (right figure).</p><p>On the one hand, the contingency detection performed by the asso. map (middle) is rather strict because a small temporal perturbation can affect the neurons&#x02019; integrity. On the other hand, the contingency detection performed by the rec. map is robust to account for larger temporal perturbations.</p></sec></sec><sec disp-level="1"><title>Devices and Methods</title><sec disp-level="2"><title>Experimental Setup</title><p>Our experimental setup replicated the settings of the rubber-hand illusion experiment<xref ref-type="bibr" rid="b10">10</xref><xref ref-type="bibr" rid="b47">47</xref> and employed the apparatus we used in ref. <xref ref-type="bibr" rid="b23">23</xref>, with neural networks receive the incoming signals from a haptic device and a video camera, see <xref ref-type="fig" rid="f1">Fig. 1(b)</xref>.</p><p>Our setup consisted of a conductive tactile device with a camera mounted on it that captures the contingent visuo-tactile signals from the experimenter&#x02019;s hand moving above the artificial tactile sheet and continuously touching it on one point with a metallic weight, see <xref ref-type="fig" rid="f1">Fig. 1(b)</xref>. The experimenter was free to move his hand in all directions at a variable speed for a period of 5&#x02009;minutes and at a system sampling rate of 30&#x02009;<italic>Hz</italic>. <bold>New</bold> This sampling rate is low due to the signal processing done by the device but it is enough for detecting tactile displacement below the centimeter by the neural network. The raw incoming signals are sent to the neural networks, which then attempt to combine the visuo-tactile signals; see <xref ref-type="fig" rid="f1">Fig. 1(a)</xref>.</p></sec><sec disp-level="2"><title>Tactile Device</title><p>The haptic device consists of a pressure-sensitive conductive sheet with 16 electrodes placed on its boundary, see <xref ref-type="fig" rid="f1">Fig. 1(b)</xref>. Its implementation is explained in refs <xref ref-type="bibr" rid="b48">48</xref>, <xref ref-type="bibr" rid="b49">49</xref>, <xref ref-type="bibr" rid="b50">50</xref>. The voltage of the electrical current injected into each pair of electrodes is read out, and the potential distribution on the global surface of the sensor sheet is estimated based on the inverse analysis of the local resistance in each pair, called electrical impedance tomography (EIT). Using this method, it is possible to detect any change in the resistance distribution of the material and to identify locations where pressure is being applied on the sensor sheet or to determine when it is stretched.</p><p>The sensor has a reasonable sensitivity threshold and can detect forces greater than 1&#x02009;<italic>N</italic>. Hence, it can also detect tactile stimuli larger than 1% of the sensor area, which was an acceptable resolution for our experiment. The frame rate of the device is 10&#x02009;<italic>ms</italic>.</p><p>The camera resolution is 320&#x02009;&#x000d7;&#x02009;240 pixels and the pixels&#x02019; colors are converted into gray intensities. The camera is fixed in front of the tactile device in the same position of the subject&#x02019;s eye field in the RH experiment so that the spatial coordinates in the visual eye field and in the tactile sensor sheet correlate with each other. Its frame rate is set synchronized to the tactile device, which is 10&#x02009;<italic>ms</italic>.</p></sec><sec disp-level="2"><title>Neuron Definition and STDP-like Algorithm</title><p>In the four neural networks we used a variant of the Hebbian algorithm, the rank order coding algorithm, which effectively grasps the structure of the spike-timing-dependent plasticity algorithm and of the classical Delta rule in the spatio-temporal domain<xref ref-type="bibr" rid="b51">51</xref>.</p><p>STDP has been found to modulate the neural activity of temporally related neurons in many brain regions by reinforcing their links. The rank order coding (ROC) algorithm was proposed by Thorpe and colleagues as a discrete and faster model of the derivative integrate-and-fire neuron and of the standard STDP reinforcement learning algorithm<xref ref-type="bibr" rid="b52">52</xref>. The rationale is that ROC neurons are sensitive to the sequential order of the incoming signals, that is, their <italic>rank code</italic>. The distance similarity to this code is transformed into an amplitude value. The scalar product between the input&#x02019;s rank code and the synaptic weights then furnishes a distance measure and the activity level of the neuron. More precisely, the ordinal rank code can be obtained by sorting the signals&#x02019; vector relative to their amplitude levels or to their temporal order in a sequence. If the rank code of the input signal perfectly matches that of the synaptic weights, then the neuron fully integrates this activity over time and fires. By contrast, if the rank coding of the signal vector does not properly match the ordinal sequence of the synaptic weights, then the integration is weak and the neuron discharges proportionally to it. However, the ROC algorithm modulates the activity of one neuron with respect to the proper order or phase of its afferent sensory signals; in a sense, the rank code preserves the signal&#x02019;s information structure (i.e., its phase). In this respect, this mechanism captures the intrinsic property of cortical neurons.</p><p>The neurons&#x02019; output <italic>v</italic> is computed by multiplying the rank order of the sensory signal vector <italic>I, rank(I</italic>), by the synaptic weights <italic>w</italic>; <italic>w</italic>&#x02009;&#x02208;&#x02009;[0, 1]. For a vector signal of dimension <italic>M</italic> and for a population of <italic>N</italic> neurons (<italic>M</italic> afferent synapses), we have</p><p><disp-formula id="eq1"><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d32e673" xlink:href="srep41056-m1.jpg"/></disp-formula></p><p>The updating rule of the neurons&#x02019; weights is similar to the winner-takes-all learning algorithm of Kohonen&#x02019;s self-organizing maps<xref ref-type="bibr" rid="b53">53</xref>. For the best neuron <italic>win</italic> and for all afferent signals <italic>m</italic>&#x02009;&#x02208;&#x02009;<italic>M</italic>, we have</p><p><disp-formula id="eq2"><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d32e689" xlink:href="srep41056-m2.jpg"/></disp-formula></p></sec><sec disp-level="2"><title>Neural architecture</title><p>The neural architecture consists of four maps arranged as in <xref ref-type="fig" rid="f1">Fig. 1(a)</xref>. In the first stage, the unisensory maps learn to categorize their respective inputs into unimodal receptive fields (32&#x02009;&#x000d7;&#x02009;32 neurons each). In the second stage, an associative map (asso. map) learns the instantaneous coupling between the neurons of the two unisensory maps (64 neurons). Finally, in the third stage, a recurrent map (rec. map) encodes a temporal sequence from the associative network. The temporal horizon for each synaptic link is less than 50&#x02009;<italic>ms</italic>, which is therefore the maximum possible time length of the synaptic links. This parameter is important in the simulation. The rationale is that the learning interval of STDP and the average synaptic length in the cortical maps are less than 50&#x02009;<italic>ms</italic><xref ref-type="bibr" rid="b20">20</xref>. This last map then models the properties of a working memory as it could be performed in the superior parietal cortex (rec. map)<xref ref-type="bibr" rid="b54">54</xref> (64 neurons).</p><p>The EIT tactile matrix is directly fed into the neural network as the tactile input. The number of neurons in the tactile network is a 32&#x02009;&#x000d7;&#x02009;32 matrix, and it is chosen to be lower than the number of tactile elements so that the whole network can learn to generalize the entire mesh.</p><p>In parallel, the visual map receives pre-processed signals from a camera device to detect motion within the image. The visual network is of the dimensions 32&#x02009;&#x000d7;&#x02009;32, as is the tactile map.</p><p>The associative layer, which receives information from the two previous maps, is downsized to a network of only 64 neurons. The recurrent map also possesses 64 neurons, except that it receives as input the temporal buffer of its own activity over a period of time of 50&#x02009;<italic>ms</italic>, which corresponds to a [64&#x02009;&#x000d7;&#x02009;5] input vector (10&#x02009;<italic>ms</italic> sampling time). The neurons of the associative map are connected to the neurons of the recurrent map by directly adding their current dynamics to the values of the output neurons of same index multiplied by 0.5; <inline-formula id="d32e719"><inline-graphic xmlns:xlink="http://www.w3.org/1999/xlink" id="d32e720" xlink:href="srep41056-m3.jpg"/></inline-formula>.</p></sec><sec disp-level="2"><title>VP spike distance</title><p>Victor and Purpura proposed a measure of spike-train synchrony by computing the minimal cost necessary to transform one spike train into another by means of basic operations (spike deletion, spike insertion, spike shift)<xref ref-type="bibr" rid="b25">25</xref>. Each basic operation costs 1, which makes the distance sensitive to the timing of the individual spikes (phase synchronization).</p></sec></sec><sec disp-level="1"><title>Additional Information</title><p><bold>How to cite this article</bold>: Pitti, A. <italic>et al</italic>. Spatio-Temporal Tolerance of Visuo-Tactile Illusions in Artificial Skin by Recurrent Neural Network with Spike-Timing-Dependent Plasticity. <italic>Sci. Rep.</italic>
<bold>7</bold>, 41056; doi: 10.1038/srep41056 (2017).</p><p><bold>Publisher's note:</bold> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></sec></body><back><ack><p>We thank Mathias Quoy and Nicolas Rougier for their helpful feedback on the anterior versions of the paper. This work was partially supported by grants from the Agence Universitaire de France (AUF), the EQUIPEX-ROBOTEX (CNRS), the chaire d&#x02019;excellence CNRS-UCP, and a travel grant from the University of Cergy-Pontoise.</p></ack><ref-list><ref id="b1"><mixed-citation publication-type="journal"><name><surname>Ramachandran</surname><given-names>V.</given-names></name> &#x00026; <name><surname>Blakeslee</surname><given-names>S.</given-names></name>
<source>Phantoms in the Brain</source> (Harper Collins, <year>1998</year>).</mixed-citation></ref><ref id="b2"><mixed-citation publication-type="journal"><name><surname>Maravita</surname><given-names>A.</given-names></name>, <name><surname>Spence</surname><given-names>C.</given-names></name> &#x00026; <name><surname>Driver</surname><given-names>J.</given-names></name>
<article-title>Multisensory integration and the body schema: Close to hand and within reach</article-title>. <source>Current Biology</source>
<volume>13</volume>, <fpage>R531</fpage>&#x02013;<lpage>R539</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12842033</pub-id></mixed-citation></ref><ref id="b3"><mixed-citation publication-type="journal"><name><surname>Holmes</surname><given-names>N.</given-names></name> &#x00026; <name><surname>Spence</surname><given-names>C.</given-names></name>
<article-title>The body schema and the multisensory representation(s) of peripersonal space</article-title>. <source>Cogn. Process.</source>
<volume>5</volume>, <fpage>94</fpage>&#x02013;<lpage>105</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">16467906</pub-id></mixed-citation></ref><ref id="b4"><mixed-citation publication-type="journal"><name><surname>Stein</surname><given-names>B. E.</given-names></name> &#x00026; <name><surname>Meredith</surname><given-names>M.</given-names></name>
<source>The Merging of the Senses</source> (A Bradford Book, cambridge, MA, <year>1993</year>).</mixed-citation></ref><ref id="b5"><mixed-citation publication-type="journal"><name><surname>Tsakiris</surname><given-names>M.</given-names></name>, <name><surname>Prabhu</surname><given-names>G.</given-names></name> &#x00026; <name><surname>Haggard</surname><given-names>P.</given-names></name>
<article-title>Having a body versus moving your body: How agency structures body-ownership</article-title>. <source>Consciousness and Cognition</source>
<volume>15</volume>, <fpage>423</fpage>&#x02013;<lpage>432</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">16343947</pub-id></mixed-citation></ref><ref id="b6"><mixed-citation publication-type="journal"><name><surname>Longo</surname><given-names>M.</given-names></name>, <name><surname>Long</surname><given-names>C.</given-names></name> &#x00026; <name><surname>Haggard</surname><given-names>P.</given-names></name>
<article-title>Mapping the invisible hand: A body model of a phantom limb</article-title>. <source>Psychological Science</source>
<volume>23</volume>, <fpage>740</fpage>&#x02013;<lpage>742</lpage> (<year>2012</year>).<pub-id pub-id-type="pmid">22653797</pub-id></mixed-citation></ref><ref id="b7"><mixed-citation publication-type="journal"><name><surname>Rochat</surname><given-names>P.</given-names></name>
<article-title>Self-perception and action in infancy</article-title>. <source>Exp. Brain Res.</source>
<volume>123</volume>, <fpage>102</fpage>&#x02013;<lpage>109</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9835398</pub-id></mixed-citation></ref><ref id="b8"><mixed-citation publication-type="journal"><name><surname>Hiraki</surname><given-names>K.</given-names></name>
<article-title>Detecting contingency: A key to understanding development of self and social cognition</article-title>. <source>Japanese Psychological Research</source>
<volume>48</volume>, <fpage>204</fpage>&#x02013;<lpage>212</lpage> (<year>2006</year>).</mixed-citation></ref><ref id="b9"><mixed-citation publication-type="journal"><name><surname>David</surname><given-names>N.</given-names></name>, <name><surname>Newen</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Vogeley</surname><given-names>K.</given-names></name>
<article-title>The &#x0201c;sense of agency&#x0201d; and its underlying cognitive and neural mechanisms</article-title>. <source>Consciousness and Cognition</source>
<volume>17</volume>, <fpage>523</fpage>&#x02013;<lpage>534</lpage> (<year>2008</year>).<pub-id pub-id-type="pmid">18424080</pub-id></mixed-citation></ref><ref id="b10"><mixed-citation publication-type="journal"><name><surname>Shimada</surname><given-names>S.</given-names></name>, <name><surname>Fukuda</surname><given-names>K.</given-names></name> &#x00026; <name><surname>Hiraki</surname><given-names>K.</given-names></name>
<article-title>Rubber hand illusion under delayed visual feedback</article-title>. <source>PLoS ONE</source>
<volume>4</volume>, <fpage>e6185</fpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19587780</pub-id></mixed-citation></ref><ref id="b11"><mixed-citation publication-type="journal"><name><surname>Gentile</surname><given-names>G.</given-names></name>
<etal/>. <article-title>Disintegration of Multisensory Signals from the Real Hand Reduces Default Limb Self-Attribution: An fMRI Study</article-title>. <source>The Journal of Neuroscience</source>
<volume>6</volume>, <fpage>13350</fpage>&#x02013;<lpage>13366</lpage> (<year>2013</year>).</mixed-citation></ref><ref id="b12"><mixed-citation publication-type="journal"><name><surname>Limanowski</surname><given-names>J.</given-names></name> &#x00026; <name><surname>Blankeburg</surname><given-names>F.</given-names></name>
<article-title>Network Activity Underlying the Illusory Self-Attribution of a Dummy Arm</article-title>. <source>Human Brain Mapping</source>
<volume>36</volume>, <fpage>2284</fpage>&#x02013;<lpage>22304</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25708317</pub-id></mixed-citation></ref><ref id="b13"><mixed-citation publication-type="journal"><name><surname>Farrer</surname><given-names>C.</given-names></name>
<etal/>. <article-title>Modulating the experience of agency: a positron emission tomography study</article-title>. <source>NeuroImage</source>
<volume>18</volume>, <fpage>324</fpage>&#x02013;<lpage>333</lpage> (<year>2003</year>).<pub-id pub-id-type="pmid">12595186</pub-id></mixed-citation></ref><ref id="b14"><mixed-citation publication-type="journal"><name><surname>Shimada</surname><given-names>S.</given-names></name>, <name><surname>Hiraki</surname><given-names>K.</given-names></name> &#x00026; <name><surname>Oda</surname><given-names>I.</given-names></name>
<article-title>The parietal role in the sense of self-ownership with temporal discrepancy between visual and proprioceptive feedbacks</article-title>. <source>NeuroImage</source>
<volume>24</volume>, <fpage>1225</fpage>&#x02013;<lpage>1232</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">15670700</pub-id></mixed-citation></ref><ref id="b15"><mixed-citation publication-type="journal"><name><surname>Purves</surname><given-names>D.</given-names></name>, <name><surname>Wojtach</surname><given-names>W.</given-names></name> &#x00026; <name><surname>Lotto</surname><given-names>R.</given-names></name>
<article-title>Understanding vision in wholly empirical terms</article-title>. <source>PNAS</source>
<volume>108</volume>, <fpage>15588</fpage>&#x02013;<lpage>15595</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">21383192</pub-id></mixed-citation></ref><ref id="b16"><mixed-citation publication-type="journal"><name><surname>Blakemore</surname><given-names>S.</given-names></name>, <name><surname>Frith</surname><given-names>C.</given-names></name> &#x00026; <name><surname>Wolpert</surname><given-names>D.</given-names></name>
<article-title>Spatio-temporal prediction modulates the perception of self-produced stimuli</article-title>. <source>Journal of Cognitive Neuroscience</source>
<volume>11</volume>, <fpage>555</fpage>&#x02013;<lpage>559</lpage> (<year>1999</year>).</mixed-citation></ref><ref id="b17"><mixed-citation publication-type="journal"><name><surname>Blakemore</surname><given-names>S.</given-names></name>, <name><surname>Wolpert</surname><given-names>D.</given-names></name> &#x00026; <name><surname>Frith</surname><given-names>C.</given-names></name>
<article-title>Abnormalities in the awareness of action</article-title>. <source>Trends Cogn. Sci.</source>
<volume>6</volume>, <fpage>237</fpage>&#x02013;<lpage>242</lpage> (<year>2002</year>).<pub-id pub-id-type="pmid">12039604</pub-id></mixed-citation></ref><ref id="b18"><mixed-citation publication-type="journal"><name><surname>Brass</surname><given-names>M.</given-names></name> &#x00026; <name><surname>Heyes</surname><given-names>C.</given-names></name>
<article-title>Imitation: is cognitive neuroscience solving the correspondence problem?</article-title>
<source>Trends in Cognitive Sciences</source>
<volume>9</volume>, <fpage>489</fpage>&#x02013;<lpage>495</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">16126449</pub-id></mixed-citation></ref><ref id="b19"><mixed-citation publication-type="journal"><name><surname>Bi</surname><given-names>G.</given-names></name> &#x00026; <name><surname>Poo</surname><given-names>M.</given-names></name>
<article-title>Activity-induced synaptic modifications in hippocampal culture, dependence of spike timing, synaptic strength and cell type</article-title>. <source>J. Neurscience</source>
<volume>18</volume>, <fpage>10464</fpage>&#x02013;<lpage>10472</lpage> (<year>1998</year>).</mixed-citation></ref><ref id="b20"><mixed-citation publication-type="journal"><name><surname>Abbott</surname><given-names>L.</given-names></name> &#x00026; <name><surname>Nelson</surname><given-names>S.</given-names></name>
<article-title>Synaptic plasticity: taming the beast</article-title>. <source>Nature neuroscience</source>
<volume>3</volume>, <fpage>1178</fpage>&#x02013;<lpage>1182</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">11127835</pub-id></mixed-citation></ref><ref id="b21"><mixed-citation publication-type="journal"><name><surname>Keysers</surname><given-names>C.</given-names></name>
<article-title>Demystifying social cognition: a hebbian perspective</article-title>. <source>Trends in Cognitive Sciences</source>
<volume>8</volume>, <fpage>501</fpage>&#x02013;<lpage>507</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">15491904</pub-id></mixed-citation></ref><ref id="b22"><mixed-citation publication-type="journal"><name><surname>Izhikevich</surname><given-names>E. M.</given-names></name>, <name><surname>Gally</surname><given-names>J. A.</given-names></name> &#x00026; <name><surname>Edelman</surname><given-names>G. M.</given-names></name>
<article-title>Spike-timing dynamics of neuronal groups</article-title>. <source>Cerebral Cortex</source>
<volume>14</volume>, <fpage>933</fpage>&#x02013;<lpage>944</lpage> (<year>2004</year>).<pub-id pub-id-type="pmid">15142958</pub-id></mixed-citation></ref><ref id="b23"><mixed-citation publication-type="journal"><name><surname>Pitti</surname><given-names>A.</given-names></name>, <name><surname>Alirezaei</surname><given-names>H.</given-names></name> &#x00026; <name><surname>Kuniyoshi</surname><given-names>Y.</given-names></name>
<article-title>Cross-modal and scale-free action representations through enaction</article-title>. <source>Neural Networks</source>
<volume>22</volume>, <fpage>144</fpage>&#x02013;<lpage>154</lpage> (<year>2009</year>).<pub-id pub-id-type="pmid">19203857</pub-id></mixed-citation></ref><ref id="b24"><mixed-citation publication-type="journal"><name><surname>Pitti</surname><given-names>A.</given-names></name>, <name><surname>Mori</surname><given-names>H.</given-names></name>, <name><surname>Kozuma</surname><given-names>S.</given-names></name> &#x00026; <name><surname>Kuniyoshi</surname><given-names>Y.</given-names></name>
<article-title>Contingency perception and agency measure in visuo-motor spiking neural networks</article-title>. <source>IEEE Trans. on Autonomous Mental Development</source>
<volume>1</volume>, <fpage>86</fpage>&#x02013;<lpage>97</lpage> (<year>2009</year>).</mixed-citation></ref><ref id="b25"><mixed-citation publication-type="journal"><name><surname>Victor</surname><given-names>J.</given-names></name> &#x00026; <name><surname>Purpura</surname><given-names>K.</given-names></name>
<article-title>Metric-space analysis of spike trains: theory, algorithms and application</article-title>. <source>Network</source>
<volume>8</volume>, <fpage>127</fpage>&#x02013;<lpage>164</lpage> (<year>1997</year>).</mixed-citation></ref><ref id="b26"><mixed-citation publication-type="journal"><name><surname>Watts</surname><given-names>D.</given-names></name> &#x00026; <name><surname>Strogatz</surname><given-names>S.</given-names></name>
<article-title>Collective dynamics of &#x02018;small-world&#x02019; networks</article-title>. <source>Nature</source>
<volume>393</volume>, <fpage>440</fpage>&#x02013;<lpage>442</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9623998</pub-id></mixed-citation></ref><ref id="b27"><mixed-citation publication-type="journal"><name><surname>Sporns</surname><given-names>O.</given-names></name>, <name><surname>Tononi</surname><given-names>G.</given-names></name> &#x00026; <name><surname>Edelman</surname><given-names>G. M.</given-names></name>
<article-title>Connectivity and complexity: the relationship between neuroanatomy and brain dynamics</article-title>. <source>Neural Networks</source>
<volume>13</volume><bold>(8-9)</bold>, <fpage>909</fpage>&#x02013;<lpage>922</lpage> (<year>2000</year>).<pub-id pub-id-type="pmid">11156201</pub-id></mixed-citation></ref><ref id="b28"><mixed-citation publication-type="journal"><name><surname>Sporns</surname><given-names>O.</given-names></name> &#x00026; <name><surname>Honey</surname><given-names>C.</given-names></name>
<article-title>Small worlds inside big brains</article-title>. <source>PNAS</source>
<volume>103</volume>, <fpage>19219</fpage>&#x02013;<lpage>19220</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">17159140</pub-id></mixed-citation></ref><ref id="b29"><mixed-citation publication-type="journal"><name><surname>Bassett</surname><given-names>D.</given-names></name> &#x00026; <name><surname>Bullmore</surname><given-names>E.</given-names></name>
<article-title>Small-world brain networks</article-title>. <source>The Neuroscientist</source>
<volume>12</volume>, <fpage>512</fpage>&#x02013;<lpage>523</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">17079517</pub-id></mixed-citation></ref><ref id="b30"><mixed-citation publication-type="journal"><name><surname>Ehrsson</surname><given-names>H.</given-names></name>, <name><surname>Holmes</surname><given-names>N.</given-names></name> &#x00026; <name><surname>Passingham</surname><given-names>R.</given-names></name>
<article-title>Touching a rubber hand: feeling of body ownership is associated with activity in multisensory brain areas</article-title>. <source>The Journal of Neuroscience: The Official Journal of the Society for Neuroscience</source>
<volume>25</volume>, <fpage>10564</fpage>&#x02013;<lpage>10573</lpage> (<year>2005</year>).<pub-id pub-id-type="pmid">16280594</pub-id></mixed-citation></ref><ref id="b31"><mixed-citation publication-type="journal"><name><surname>Graziano</surname><given-names>M.</given-names></name>, <name><surname>Hu</surname><given-names>X.</given-names></name> &#x00026; <name><surname>Cooke</surname><given-names>D.</given-names></name>
<article-title>Visuospatial properties of ventral premotor cortex</article-title>. <source>Journal of Neurophysiology</source>
<volume>77</volume>, <fpage>2268</fpage>&#x02013;<lpage>2292</lpage> (<year>1997</year>).<pub-id pub-id-type="pmid">9163357</pub-id></mixed-citation></ref><ref id="b32"><mixed-citation publication-type="journal"><name><surname>Groh</surname><given-names>J. M.</given-names></name> &#x00026; <name><surname>Saccades</surname><given-names>D. L.</given-names></name>
<article-title>to somatosensory targets. iii. eye-position-dependent somatosensory activity in primate superior colliculus</article-title>. <source>Journal of Neurophysiology</source>
<volume>75</volume>, <fpage>439</fpage>&#x02013;<lpage>453</lpage> (<year>1996</year>).<pub-id pub-id-type="pmid">8822569</pub-id></mixed-citation></ref><ref id="b33"><mixed-citation publication-type="journal"><name><surname>Marshal</surname><given-names>P.</given-names></name> &#x00026; <name><surname>Meltzoff</surname><given-names>A.</given-names></name>
<article-title>Body maps in the infant brain</article-title>. <source>Trends in Cognitive Sciences</source>
<volume>19</volume>, <fpage>499</fpage>&#x02013;<lpage>505</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">26231760</pub-id></mixed-citation></ref><ref id="b34"><mixed-citation publication-type="journal"><name><surname>Pitti</surname><given-names>A.</given-names></name>, <name><surname>Kuniyoshi</surname><given-names>Y.</given-names></name>, <name><surname>Quoy</surname><given-names>M.</given-names></name> &#x00026; <name><surname>Gaussier</surname><given-names>P.</given-names></name>
<article-title>Modeling the minimal newborn&#x02019;s intersubjective mind: The visuotopic-somatotopic alignment hypothesis in the superior colliculus</article-title>. <source>PLoS ONE</source>
<volume>8</volume>, <fpage>e69474</fpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23922718</pub-id></mixed-citation></ref><ref id="b35"><mixed-citation publication-type="other"><name><surname>Mori</surname><given-names>H.</given-names></name> &#x00026; <name><surname>Kuniyoshi</surname><given-names>Y.</given-names></name> A human fetus development simulation: Self-organization of behaviors through tactile sensation. <italic>IEEE 9th International Conference on Development and Learning</italic> 82&#x02013;97 (<year>2010</year>).</mixed-citation></ref><ref id="b36"><mixed-citation publication-type="journal"><name><surname>Yamada</surname><given-names>Y.</given-names></name>
<etal/>. <article-title>An embodied brain model of the human foetus</article-title>. <source>Scientific Reports</source>
<volume>6</volume>, <fpage>27893</fpage> (<year>2016</year>).<pub-id pub-id-type="pmid">27302194</pub-id></mixed-citation></ref><ref id="b37"><mixed-citation publication-type="journal"><name><surname>Keysers</surname><given-names>C.</given-names></name>, <name><surname>Perrett</surname><given-names>D.</given-names></name> &#x00026; <name><surname>Gazzola</surname><given-names>V.</given-names></name>
<article-title>Hebbian learning is about contingency, not contiguity, and explains the emergence of predictive mirror neurons</article-title>. <source>Behavioral and Brain Sciences</source>
<volume>37</volume>, <fpage>205</fpage>&#x02013;<lpage>206</lpage> (<year>2014</year>).<pub-id pub-id-type="pmid">24775162</pub-id></mixed-citation></ref><ref id="b38"><mixed-citation publication-type="journal"><name><surname>Heed</surname><given-names>T.</given-names></name>, <name><surname>Buchholz</surname><given-names>V.</given-names></name>, <name><surname>Engel</surname><given-names>A.</given-names></name> &#x00026; <name><surname>R oder</surname><given-names>B.</given-names></name>
<article-title>Tactile remapping: from coordinate transformation to integration in sensorimotor processing</article-title>. <source>Trends in Cogn. Sci</source>. <volume>19</volume>, <fpage>251</fpage>&#x02013;<lpage>258</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25843541</pub-id></mixed-citation></ref><ref id="b39"><mixed-citation publication-type="journal"><name><surname>Heed</surname><given-names>T.</given-names></name> &#x00026; <name><surname>R&#x000f6;der</surname><given-names>B.</given-names></name>
<article-title>Common anatomical and external coding for hands and feet in tactile attention: evidence from event-related potentials</article-title>. <source>J. Cogn. Neurosci.</source>
<volume>22</volume>, <fpage>184</fpage>&#x02013;<lpage>202</lpage> (<year>2010</year>).<pub-id pub-id-type="pmid">19199399</pub-id></mixed-citation></ref><ref id="b40"><mixed-citation publication-type="journal"><name><surname>Shokur</surname><given-names>S.</given-names></name>
<etal/>. <article-title>Expanding the primate body schema in sensorimotor cortex by virtual touches of an avatar</article-title>. <source>PNAS</source>
<volume>110</volume>, <fpage>15121</fpage>&#x02013;<lpage>15126</lpage> (<year>2013</year>).<pub-id pub-id-type="pmid">23980141</pub-id></mixed-citation></ref><ref id="b41"><mixed-citation publication-type="journal"><name><surname>Iriki</surname><given-names>A.</given-names></name>, <name><surname>Tanaka</surname><given-names>M.</given-names></name>, <name><surname>Obayashi</surname><given-names>S.</given-names></name> &#x00026; <name><surname>Iwamura</surname><given-names>Y.</given-names></name>
<article-title>Self-images in the video monitor coded by monkey intraparietal neurons</article-title>. <source>Neuroscience Research</source>
<volume>40</volume>, <fpage>163</fpage>&#x02013;<lpage>173</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">11377755</pub-id></mixed-citation></ref><ref id="b42"><mixed-citation publication-type="journal"><name><surname>Graziano</surname><given-names>M.</given-names></name> &#x00026; <name><surname>Cooke</surname><given-names>D.</given-names></name>
<article-title>Parieto-frontal interactions, personal space, and defensive behavior</article-title>. <source>Neuropsychologia</source>
<volume>44</volume>, <fpage>845</fpage>&#x02013;<lpage>859</lpage> (<year>2006</year>).<pub-id pub-id-type="pmid">16277998</pub-id></mixed-citation></ref><ref id="b43"><mixed-citation publication-type="other"><name><surname>Pitti</surname><given-names>A.</given-names></name>
<etal/>. Gain-Field Modulation Mechanism in Multimodal Networks for Spatial Perception. <italic>2th IEEE-RAS International Conference on Humanoid Robots Nov.29-Dec.1, 2012. Business Innovation Center Osaka, Japan</italic>, 297&#x02013;302 (2013).</mixed-citation></ref><ref id="b44"><mixed-citation publication-type="journal"><name><surname>Mah&#x000e9;</surname><given-names>S.</given-names></name>
<etal/>. <article-title>Exploiting the gain-modulation mechanism in parieto-motor neurons: Application to visuomotor transformations and embodied simulation</article-title>. <source>Neural Networks</source>
<volume>62</volume>, <fpage>102</fpage>&#x02013;<lpage>111</lpage> (<year>2015</year>).<pub-id pub-id-type="pmid">25240580</pub-id></mixed-citation></ref><ref id="b45"><mixed-citation publication-type="journal"><name><surname>Buchholz</surname><given-names>V.</given-names></name>, <name><surname>Jensen</surname><given-names>O.</given-names></name> &#x00026; <name><surname>Medendorp</surname><given-names>W.</given-names></name>
<article-title>Multiple reference frames in cortical oscillatory activity during tactile remapping for saccades</article-title>. <source>J. Neurosci.</source>
<volume>31</volume>, <fpage>16864</fpage>&#x02013;<lpage>16871</lpage> (<year>2011</year>).<pub-id pub-id-type="pmid">22090512</pub-id></mixed-citation></ref><ref id="b46"><mixed-citation publication-type="journal"><name><surname>Schwabe</surname><given-names>L.</given-names></name> &#x00026; <name><surname>Blanke</surname><given-names>O.</given-names></name>
<article-title>Cognitive neuroscience of ownership and agency</article-title>. <source>Conscious. Cogn.</source>
<volume>16</volume>, <fpage>661</fpage>&#x02013;<lpage>666</lpage> (<year>2007</year>).<pub-id pub-id-type="pmid">17920522</pub-id></mixed-citation></ref><ref id="b47"><mixed-citation publication-type="journal"><name><surname>Botvinick</surname><given-names>M.</given-names></name> &#x00026; <name><surname>Cohen</surname><given-names>J.</given-names></name>
<article-title>Rubber hands &#x02018;feel&#x02019; touch that eyes see</article-title>. <source>Nature</source>
<volume>391</volume>, <fpage>756</fpage>&#x02013;<lpage>756</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">9486643</pub-id></mixed-citation></ref><ref id="b48"><mixed-citation publication-type="other"><name><surname>Pugach</surname><given-names>G.</given-names></name>
<etal/>. Electronic hardware design of a low cost tactile sensor device for physical human-robot interactions. <italic>IEEE XXXIII Int. Scientific Conf. Electronics and Nanotechnology, ELNANO</italic>
<fpage>445</fpage>&#x02013;<lpage>449</lpage> (<year>2013</year>).</mixed-citation></ref><ref id="b49"><mixed-citation publication-type="journal"><name><surname>Pugach</surname><given-names>G.</given-names></name>, <name><surname>Pitti</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Gaussier</surname><given-names>P.</given-names></name>
<article-title>Neural learning of the topographic tactile sensory information of an artificial skin through a self-organizing map</article-title>. <source>Advanced Robotics</source>
<volume>29</volume>, <fpage>1393</fpage>&#x02013;<lpage>1409</lpage> (<year>2015</year>).</mixed-citation></ref><ref id="b50"><mixed-citation publication-type="other"><name><surname>Pugach</surname><given-names>G.</given-names></name>, <name><surname>Melnyk</surname><given-names>A.</given-names></name>, <name><surname>Tolochko</surname><given-names>O.</given-names></name>, <name><surname>Pitti</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Gaussier</surname><given-names>P.</given-names></name> Touch-based Admittance Control of a Robotic Arm using Neural Learning of an Artificial Skin. <italic>IEEE Int. Conf. IROS</italic> (<year>2016</year>).</mixed-citation></ref><ref id="b51"><mixed-citation publication-type="journal"><name><surname>Thorpe</surname><given-names>S.</given-names></name>, <name><surname>Delorme</surname><given-names>A.</given-names></name> &#x00026; <name><surname>Van Rullen</surname><given-names>R.</given-names></name>
<article-title>Spike-based strategies for rapid processing</article-title>. <source>Neural Networks</source>
<volume>14</volume>, <fpage>715</fpage>&#x02013;<lpage>725</lpage> (<year>2001</year>).<pub-id pub-id-type="pmid">11665765</pub-id></mixed-citation></ref><ref id="b52"><mixed-citation publication-type="journal"><name><surname>Van Rullen</surname><given-names>R.</given-names></name> &#x00026; <name><surname>Thorpe</surname><given-names>S.</given-names></name>
<article-title>Surfing a spike wave down the ventral stream</article-title>. <source>Vision Research</source>
<volume>42</volume>, <fpage>2593</fpage>&#x02013;<lpage>2615</lpage> (<year>2002</year>).<pub-id pub-id-type="pmid">12446033</pub-id></mixed-citation></ref><ref id="b53"><mixed-citation publication-type="journal"><name><surname>Kohonen</surname><given-names>T.</given-names></name>
<article-title>Self-organized formation of topologically correct feature maps</article-title>. <source>Biological Cybernetics</source>
<volume>43</volume>, <fpage>59</fpage>&#x02013;<lpage>69</lpage> (<year>1982</year>).</mixed-citation></ref><ref id="b54"><mixed-citation publication-type="journal"><name><surname>Wolpert</surname><given-names>D.</given-names></name>, <name><surname>Goodbody</surname><given-names>S.</given-names></name> &#x00026; <name><surname>Husain</surname><given-names>M.</given-names></name>
<article-title>Maintaining internal representations: the role of the human superior parietal lobe</article-title>. <source>Nat. Neurosci.</source>
<volume>1</volume>, <fpage>529</fpage>&#x02013;<lpage>533</lpage> (<year>1998</year>).<pub-id pub-id-type="pmid">10196553</pub-id></mixed-citation></ref></ref-list><fn-group><fn><p><bold>Author Contributions</bold> A.P. and S.S. developed the concept of the study, conducted the analysis, interpreted the data and drafted the manuscript. G.P. contributed to the development of the data acquisition, data interpretation and drafting of the manuscript. P.G. contributed to the drafting of the manuscript.</p></fn></fn-group></back><floats-group><fig id="f1"><label>Figure 1</label><caption><title>Experimental setup for modeling illusory effects in a visuo-tactile neural architecture of the parietal cortex using a tactile device and delayed visual feedback.</title><p>In (<bold>a</bold>), the artificial neural networks receive the unimodal visual and tactile sensory inputs as incoming information. The first layer performs an initial pre-filtering, and the second layer consists of an associative map that binds the two unimodal neural populations. Finally, the third layer corresponds to a recurrent map that integrates over time the instantaneous visuo-tactile signals. This last network has the capabilities of a working memory to resist noise and temporal delays, as it governs the internal representation of the parietal cortex. In (<bold>b</bold>), visual temporal delays on the camera are equivalent to the spatial tactile displacement on the artificial skin.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="srep41056-f1"/></fig><fig id="f2"><label>Figure 2</label><caption><title>Receptive fields for two different spatial locations of the contact point in the unimodal and bimodal tactile and visual maps.</title><p>The RFs for the asso. and rec. maps are displayed during the no-delay and delay conditions (300&#x02009;<italic>ms</italic>). (<bold>a</bold>) and (<bold>g</bold>) correspond to the strict visual and tactile spatial RFs of the unisensory maps taken at one snapshot for two arbitrarily chosen locations. (<bold>b</bold>) and (<bold>h</bold>) correspond to the spatial RFs of two bimodal neurons of the asso. map firing the most for the visuo-tactile locations in (<bold>a</bold>) and (<bold>g</bold>). (<bold>c</bold>) and (<bold>i</bold>) correspond to the spatial RFs of two bimodal neurons of the recurrent map firing the most for the visuo-tactile locations in (<bold>a</bold>) and (<bold>g</bold>). Plots (<bold>d</bold>&#x02013;<bold>f</bold>) and (<bold>j</bold>&#x02013;<bold>l</bold>) are the neurons&#x02019; activity in the asso. and rec. neurons, when a visual delay of 300&#x02009;<italic>ms</italic> is added.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="srep41056-f2"/></fig><fig id="f3"><label>Figure 3</label><caption><title>Interference patterns of the neural activity in the associative and recurrent maps for various visual delays of up to 600&#x02009;<italic>ms</italic>.</title><p>In (<bold>a</bold>), the associative neuron&#x02019;s activity is weakly sensitive to the interference patterns due to contiguous visuo-tactile activity between the vertical lines (current tactile input) and the diagonals (visual delays). In (<bold>b</bold>), the recurrent neuron is more sensitive to the visuo-tactile contingency as the activity level increases, although it also discharges in advance or later when strict contingency is not respected (memory effect).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="srep41056-f3"/></fig><fig id="f4"><label>Figure 4</label><caption><p>Mean and the standard deviation for the asso. and rec. maps and their confidence level (the signal to the noise), resp. (<bold>a</bold>) and (<bold>b</bold>). (<bold>a</bold>) The graph presents the mean and variance of the neural activity in the non-delay condition (on the left side) and in the situation of a visual delay of 500&#x02009;<italic>ms</italic> (on the right side). Visual delays influence the amplitude discrepancy of this measure for the two maps and increase the variance, twice more for the asso map than for the rec map. (<bold>b</bold>) This measurement quantifies the confidence level of the neural maps to the input stimuli with respect to non-delayed and delayed visual feedback (500&#x02009;<italic>ms</italic>). It is computed as the maximum activity minus the local field activity. This measure shows that at the population level it is possible to detect contingency by comparing the activity to a threshold value.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="srep41056-f4"/></fig><fig id="f5"><label>Figure 5</label><caption><p>Visual delay sensitivity of one neuron in the associative map in conditions of spatially non-contiguous and contiguous visuo-tactile signals; (<bold>a</bold>) and (<bold>b</bold>), respectively. Comparison between visual delay sensitivity of one neuron in the associative map and in the recurrent map; (<bold>c</bold>) and (<bold>d</bold>). Adding a temporal delay gives different neural activities whether or not the visuo-tactile receptive fields coincide. In the case of a spatial mismatch of the visuo-tactile receptive fields as in (<bold>a</bold>), the neuron activity decreases, cancelling the perception of contingency. In the case of a spatial overlap of the visuo-tactile receptive fields as in (<bold>b</bold>), the neuron activity increases, giving the illusion of contingency. Besides, the recurrent neuron in (<bold>d</bold>) is more robust to delays than the asso neurons in (<bold>c</bold>).</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="srep41056-f5"/></fig><fig id="f6"><label>Figure 6</label><caption><p>Average neural activity of the associative and recurrent maps with respect to visual delays and for spatially congruent visuo-tactile signals (bottom), temporal spike precision relative to visual delays added with the VP distance (middle), and visual spatial error with respect to delays (top). For the three plots, the activity level quadratically decreases for visual delays less than 150&#x02009;<italic>ms</italic>. This interval corresponds to the sensitivity of the neurons within their RF, for which the rec. map is more robust than the asso. map to cancel out the effect of delays with lower spatio-temporal error and with less variability (middle and top charts). The asso. map, which is more sensitive than the rec. map, has an amplitude level less than 50&#x02009;<italic>ms</italic>. With a delay longer than 150&#x02009;<italic>ms</italic>, the neurons of the two maps linearly decay.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="srep41056-f6"/></fig><fig id="f7"><label>Figure 7</label><caption><title>Measures and indices to characterize the functional organization of the recurrent neural network based on complex networks and graph theory.</title><p>(<bold>a</bold>,<bold>b</bold>) The centrality index describes the relative effectiveness of neurons within the network in terms of the number of pre-synaptic and post-synaptic connections. The power-law curve is characteristic of small-world-networks, where the most connected neurons represent the network&#x02019;s &#x0201c;hubs.&#x0201d; (<bold>c</bold>-c&#x02019;-<bold>d</bold>) The similarity index measures the similarity among the neurons by comparing their weights; asso map in (c&#x02019;) and rec map in (<bold>c</bold>). An important mass of neurons constitutes the network, which guaranties some redundancy, but the less similar ones potentially correspond to the most critical ones. (<bold>e</bold>,<bold>f</bold>) The connectivity matrix permits identification of the unidirectional connections or causal links between the pairs of neurons. This method is complementary to the centrality measure. The stronger the value of this index, the stronger the influence of the neuron on its associated neurons. Again, the logarithmic curve of the histogram is characteristic of complex and hierarchical networks.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="srep41056-f7"/></fig><fig id="f8"><label>Figure 8</label><caption><title>The integration of visual and tactile signals in the associative map and then in the recurrent map permits to be robust to spatio-temporal disturbances of distal multimodal events.</title><p>The organization of the recurrent map into a small-world network can explain the synaptic multisensory integration for loose contingency detection; graphics inspired by<xref ref-type="bibr" rid="b28">28</xref><xref ref-type="bibr" rid="b38">38</xref>.</p></caption><graphic xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="srep41056-f8"/></fig><table-wrap position="float" id="t1"><label>Table 1</label><caption><title>Summary of the different situations found for the asso. map and the rec. map depending on their neural activity and their relationship to temporal delay thresholds, their perceptual experiences and the brain areas associated with them.</title></caption><table frame="hsides" rules="groups" border="1"><colgroup><col align="left"/><col align="center"/><col align="center"/><col align="center"/><col align="center"/></colgroup><thead valign="bottom"><tr><th align="left" valign="top" charoff="50">&#x000a0;</th><th align="center" valign="top" charoff="50">Asso map Threshold 1</th><th align="center" valign="top" charoff="50">Rec map Threshold 2</th><th align="center" valign="top" charoff="50">Perceptual Experience</th><th align="center" valign="top" charoff="50">Illusion</th></tr></thead><tbody valign="top"><tr><td align="left" valign="top" charoff="50"><italic>case #1</italic></td><td align="center" valign="top" charoff="50">&#x02264;50&#x02009;ms</td><td align="center" valign="top" charoff="50">&#x02264;150&#x02009;ms</td><td align="center" valign="top" charoff="50">Self</td><td align="center" valign="top" charoff="50">Perceived</td></tr><tr><td align="left" valign="top" charoff="50"><italic>case #2</italic></td><td align="center" valign="top" charoff="50">&#x0003e;50&#x02009;ms</td><td align="center" valign="top" charoff="50">&#x02264;150&#x02009;ms</td><td align="center" valign="top" charoff="50">Self-Other</td><td align="center" valign="top" charoff="50">can be perceived</td></tr><tr><td align="left" valign="top" charoff="50"><italic>case #3</italic></td><td align="center" valign="top" charoff="50">&#x0003e;50&#x02009;ms</td><td align="center" valign="top" charoff="50">&#x0003e;150&#x02009;ms</td><td align="center" valign="top" charoff="50">Other</td><td align="center" valign="top" charoff="50">Not perceived</td></tr></tbody></table><table-wrap-foot><fn id="t1-fn1"><p>Depending on the neural activity within the two maps, two thresholds&#x02013;below 50&#x02009;ms and below 150&#x02009;ms&#x02013;are found for the asso. map and the rec. map, respectively. In case #1, below 50&#x02009;ms for the two maps, the multimodal event, illusory or not, is perceived. This experience may bes associated with RHI. In case #3 above 150&#x02009;ms, the multimodal event is not perceived. In case #2 in between, only the rec map is active, and the ambiguous signal (illusion) can be perceived and may be detected as well as fake.</p></fn></table-wrap-foot></table-wrap></floats-group></article>