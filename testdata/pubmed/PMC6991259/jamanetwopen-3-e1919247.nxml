<!DOCTYPE article
PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD with MathML3 v1.2 20190208//EN" "JATS-archivearticle1-mathml3.dtd">
<article xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:mml="http://www.w3.org/1998/Math/MathML" article-type="research-article"><?properties open_access?><front><journal-meta><journal-id journal-id-type="nlm-ta">JAMA Netw Open</journal-id><journal-id journal-id-type="iso-abbrev">JAMA Netw Open</journal-id><journal-id journal-id-type="pmc">JAMA Netw Open</journal-id><journal-title-group><journal-title>JAMA Network Open</journal-title></journal-title-group><issn pub-type="epub">2574-3805</issn><publisher><publisher-name>American Medical Association</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="pmid">31940037</article-id><article-id pub-id-type="pmc">6991259</article-id><article-id pub-id-type="doi">10.1001/jamanetworkopen.2019.19247</article-id><article-id pub-id-type="publisher-id">zoi190718</article-id><article-categories><subj-group subj-group-type="category" specific-use="electronic"><subject>Research</subject></subj-group><subj-group subj-group-type="heading"><subject>Original Investigation</subject></subj-group><subj-group subj-group-type="featured" specific-use="electronic"><subject>Featured</subject></subj-group><subj-group subj-group-type="online-only"><subject>Online Only</subject></subj-group><subj-group subj-group-type="subject-area"><subject>Surgery</subject></subj-group></article-categories><title-group><article-title>Recognizing Emotional Expression as an Outcome Measure After Face Transplant</article-title><alt-title alt-title-type="headline">Recognizing Emotional Expression as an Outcome Measure After Face Transplant</alt-title><alt-title alt-title-type="running-head">Recognizing Emotional Expression as an Outcome Measure After Face Transplant</alt-title></title-group><contrib-group><contrib contrib-type="author"><name><surname>Dorante</surname><given-names>Miguel I.</given-names></name><degrees>MD</degrees><degrees>MBE</degrees><xref ref-type="aff" rid="zoi190718aff1"><sup>1</sup></xref><xref ref-type="aff" rid="zoi190718aff2"><sup>2</sup></xref></contrib><contrib contrib-type="author"><name><surname>Kollar</surname><given-names>Branislav</given-names></name><degrees>MD</degrees><xref ref-type="aff" rid="zoi190718aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Obed</surname><given-names>Doha</given-names></name><xref ref-type="aff" rid="zoi190718aff1"><sup>1</sup></xref></contrib><contrib contrib-type="author"><name><surname>Haug</surname><given-names>Valentin</given-names></name><degrees>MD</degrees><xref ref-type="aff" rid="zoi190718aff1"><sup>1</sup></xref><xref ref-type="aff" rid="zoi190718aff3"><sup>3</sup></xref></contrib><contrib contrib-type="author"><name><surname>Fischer</surname><given-names>Sebastian</given-names></name><degrees>MD</degrees><xref ref-type="aff" rid="zoi190718aff1"><sup>1</sup></xref><xref ref-type="aff" rid="zoi190718aff3"><sup>3</sup></xref></contrib><contrib contrib-type="author" corresp="yes"><name><surname>Pomahac</surname><given-names>Bohdan</given-names></name><degrees>MD</degrees><xref ref-type="aff" rid="zoi190718aff1"><sup>1</sup></xref></contrib></contrib-group><aff id="zoi190718aff1"><label>1</label>Division of Plastic Surgery, Department of Surgery, Brigham and Women&#x02019;s Hospital, Harvard Medical School, Boston, Massachusetts</aff><aff id="zoi190718aff2"><label>2</label>Lahey Hospital and Medical Center, Department of Plastic and Reconstructive Surgery, Beth Israel Lahey Health, Burlington, Massachusetts</aff><aff id="zoi190718aff3"><label>3</label>Department of Hand, Plastic, and Reconstructive Surgery, Burn Trauma Center, BG Trauma Center Ludwigshafen, University of Heidelberg, Ludwigshafen, Germany</aff><author-notes><title>Article Information</title><p><bold>Accepted for Publication:</bold> November 19, 2019.</p><p content-type="published-online"><bold>Published:</bold> January 15, 2020. doi:<uri content-type="doi">10.1001/jamanetworkopen.2019.19247</uri></p><p content-type="open-access-note"><bold>Open Access:</bold> This is an open access article distributed under the terms of the <ext-link ext-link-type="uri" xlink:href="https://jamanetwork.com/journals/jamanetworkopen/pages/instructions-for-authors#SecOpenAccess">CC-BY License</ext-link>. &#x000a9; 2020 Dorante MI et al. <italic>JAMA Network Open</italic>.</p><corresp id="zoi190718cor1"><bold>Corresponding Author:</bold> Bohdan Pomahac, MD, Division of Plastic Surgery, Department of Surgery, Brigham and Women&#x02019;s Hospital, Harvard Medical School, 75 Francis St, Boston, MA 02115 (<email xlink:href="bpomahac@bwh.harvard.edu">bpomahac@bwh.harvard.edu</email>).</corresp><p content-type="author-contributions"><bold>Author Contributions:</bold> Drs Dorante and Pomahac had full access to all of the data in the study and take responsibility for the integrity of the data and the accuracy of the data analysis.</p><p><italic>Concept and design:</italic> Dorante, Kollar, Haug, Fischer, Pomahac.</p><p><italic>Acquisition, analysis, or interpretation of data:</italic> Dorante, Kollar, Obed, Haug, Pomahac.</p><p><italic>Drafting of the manuscript:</italic> Dorante, Kollar, Fischer, Pomahac.</p><p><italic>Critical revision of the manuscript for important intellectual content:</italic> Dorante, Kollar, Obed, Haug, Pomahac.</p><p><italic>Statistical analysis:</italic> Dorante, Kollar.</p><p><italic>Obtained funding:</italic> Dorante, Pomahac.</p><p><italic>Administrative, technical, or material support:</italic> Dorante, Obed, Pomahac.</p><p><italic>Supervision:</italic> Kollar, Haug, Fischer, Pomahac.</p><p content-type="COI-statement"><bold>Conflict of Interest Disclosures:</bold> Dr Kollar reported receiving a Plastic Surgery Foundation research fellowship grant outside the submitted work. No other disclosures were reported.</p><p content-type="funding-statement"><bold>Funding/Support:</bold> This study was supported by grant W81XWH-18-1-0702 from the US Department of Defense under their Reconstructive Transplant Research Program to Drs Dorante and Pomahac.</p><p><bold>Role of the Funder/Sponsor:</bold> The funder had no role in the design and conduct of the study; collection, management, analysis, and interpretation of the data; preparation, review, or approval of the manuscript; and decision to submit the manuscript for publication.</p><p><bold>Disclaimer:</bold> The opinions, interpretations, conclusions, and recommendations in this work are those of the authors and are not necessarily endorsed by the US Department of Defense.</p><p><bold>Meeting Presentation:</bold> This article was presented as an oral abstract at the 6th Biennial Meeting of the American Society for Reconstructive Transplantation; November 16, 2018; Chicago, Illinois.</p><p><bold>Additional Contributions:</bold> We thank the face transplant recipients for their continued availability and willingness to participate in research studies. Their personal contributions to the field of vascularized composite allotransplantation are invaluable. We also thank the all members of the Center for Reconstructive and Restorative Surgery research team and the clinical care team at Brigham and Women&#x02019;s Hospital. In particular, we thank Sotirios Tasigiorgos, MD; Kevin McComiskey, RN; Elaine Devine, MSW, LICSW; Elif Ko&#x000e7;ak, MBE; Jan Sokol, MBE; and Zoe Fullerton, MBE (all from Brigham and Women&#x02019;s Hospital); for their thoughtful contributions in the care of our patients and in the development of this study. There was no financial compensation.</p></author-notes><pub-date pub-type="epub" iso-8601-date="2020-01-15T10:00"><day>15</day><month>1</month><year>2020</year></pub-date><pub-date pub-type="collection"><month>1</month><year>2020</year></pub-date><pub-date pub-type="pmc-release"><day>15</day><month>1</month><year>2020</year></pub-date><!-- PMC Release delay is 0 months and
						0 days and was based on the <pub-date
						pub-type="epub"/>. --><volume>3</volume><issue>1</issue><elocation-id>e1919247</elocation-id><history><date date-type="received"><day>24</day><month>9</month><year>2019</year></date><date date-type="accepted"><day>19</day><month>11</month><year>2019</year></date></history><permissions><copyright-statement>Copyright 2020 Dorante MI et al. <italic>JAMA Network Open</italic>.</copyright-statement><license license-type="open-access" xlink:href="http://creativecommons.org/licenses/by/4.0/"><license-p>This is an open access article distributed under the terms of the CC-BY License.</license-p></license></permissions><self-uri content-type="pdf-version" xlink:href="jamanetwopen-3-e1919247.pdf">jamanetwopen-3-e1919247.pdf</self-uri><self-uri content-type="silverchair" xlink:href="https://jamanetwork.com/journals/jamanetworkopen/fullarticle/10.1001/jamanetworkopen.2019.19247"/><abstract abstract-type="key-points"><title>Key Points</title><sec id="ab-zoi190718-1"><title>Question</title><p>Does face transplant restore the possibility of facial emotional expression, and can software-based video analysis be used to track progress over time?</p></sec><sec id="ab-zoi190718-2"><title>Findings</title><p>In this case-control study including 6 patients who underwent face transplant, all emotions were detectable, but only expression of happiness was reliably restored to 43% of the level of healthy controls and showed statistically significant improvement 1 year after transplant.</p></sec><sec id="ab-zoi190718-3"><title>Meaning</title><p>Software-based video analysis can be used as an objective, noninvasive, and nonobtrusive method of detecting and tracking facial emotional expression restoration after face transplant.</p></sec></abstract><abstract abstract-type="teaser"><p>This case-control study uses software-based video analysis to detect and track restoration of facial emotional expression after face transplant.</p></abstract><abstract><sec id="ab-zoi190718-4"><title>Importance</title><p>Limited quantitative data exist on the restoration of nonverbal communication via facial emotional expression after face transplant. Objective and noninvasive methods for measuring outcomes and tracking rehabilitation after face transplant are lacking.</p></sec><sec id="ab-zoi190718-5"><title>Objective</title><p>To measure emotional expression as an indicator of functional outcomes and rehabilitation after face transplant via objective, noninvasive, and nonobtrusive software-based video analysis.</p></sec><sec id="ab-zoi190718-6"><title>Design, Setting, and Participants</title><p>This single-center case-control study analyzed videos with commercially available video analysis software capable of detecting emotional expression. The study participants were 6 patients who underwent face transplant at Brigham and Women&#x02019;s Hospital between April 2009 and March 2014. They were matched by age, race/ethnicity, culture, and sex to 6 healthy controls with no prior facial surgical procedures. Participants were asked to perform either emotional expressions (direct evaluation) or standardized facial movements (indirect evaluation). Videos were obtained in a clinical setting, except for direct evaluation videos of 3 patients that were recorded at the patients&#x02019; residences. Data analysis was performed from June 2018 to November 2018.</p></sec><sec id="ab-zoi190718-7"><title>Main Outcomes and Measures</title><p>The possibility of detecting the emotional expressions of happiness, sadness, anger, fear, surprise, and disgust was evaluated using intensity score values between 0 and 1, representing expressions that are absent or fully present, respectively.</p></sec><sec id="ab-zoi190718-8"><title>Results</title><p>Six patients underwent face transplant (4 men; mean [SD] age, 42 [14] years). Four underwent full face transplants, and 2 underwent partial face transplants of the middle and lower two-thirds of the face. In healthy controls, happiness was the only emotion reliably recognized in both indirect (mean [SD] intensity score, 0.92&#x02009;[0.05]) and direct (mean [SD] intensity score, 0.91&#x02009;[0.04]) evaluation. Indirect evaluation showed that expression of happiness significantly improved 1 year after transplant (0.04 point per year; 95% CI, 0.02 to 0.06 point per year; <italic>P</italic>&#x02009;=&#x02009;.002). Expression of happiness was restored to a mean of 43% (range, 14% to 75%) of that of healthy controls after face transplant. The expression of sadness showed a significant change only during the first year after transplant (&#x02212;0.53 point per year; 95% CI, &#x02212;0.82 to &#x02212;0.24 point per year; <italic>P</italic>&#x02009;=&#x02009;.005). All other emotions were detectable with no significant change after transplant. Nearly all emotions were detectable in long-term direct evaluation of 3 patients, with expression of happiness restored to a mean of 26% (range, 5% to 59%) of that of healthy controls.</p></sec><sec id="ab-zoi190718-9"><title>Conclusions and Relevance</title><p>Partial restoration of facial emotional expression is possible after face transplant. Video analysis software may provide useful clinical information and aid rehabilitation after face transplant.</p></sec></abstract></article-meta></front><body><sec id="H1-1-ZOI190718"><title>Introduction</title><p>Face transplant is a viable reconstructive option for patients with severe facial deformity that shows promising long-term results in improving functionality and quality of life.<sup><xref rid="zoi190718r1" ref-type="bibr">1</xref></sup> Outcome measures of face transplant have traditionally assessed the recovery of vital functions (eg, ability to breathe,<sup><xref rid="zoi190718r2" ref-type="bibr">2</xref></sup> eat, and speak<sup><xref rid="zoi190718r3" ref-type="bibr">3</xref></sup>) and independent functions (eg, motor movement and protective and discriminative sensation),<sup><xref rid="zoi190718r4" ref-type="bibr">4</xref>,<xref rid="zoi190718r5" ref-type="bibr">5</xref>,<xref rid="zoi190718r6" ref-type="bibr">6</xref>,<xref rid="zoi190718r7" ref-type="bibr">7</xref></sup> as well as the procedure&#x02019;s functional psychological impact on quality of life and mental health.<sup><xref rid="zoi190718r8" ref-type="bibr">8</xref>,<xref rid="zoi190718r9" ref-type="bibr">9</xref>,<xref rid="zoi190718r10" ref-type="bibr">10</xref></sup> Measuring the restoration of these functions is necessary to determine the value of face transplant to the individual patient, but their recovery alone is not sufficient to achieve or explain societal reintegration after face transplant.</p><p>Nonverbal communication via facial emotional expression, a social function of the face, has evolved under the pressures of interacting in a social environment.<sup><xref rid="zoi190718r11" ref-type="bibr">11</xref></sup> Six specific emotional expressions&#x02014;happiness, sadness, anger, surprise, fear, and disgust&#x02014;are recognized across cultures and are the focus of social psychology research.<sup><xref rid="zoi190718r12" ref-type="bibr">12</xref>,<xref rid="zoi190718r13" ref-type="bibr">13</xref>,<xref rid="zoi190718r14" ref-type="bibr">14</xref></sup> Despite their high relevance, limited quantitative data are available on the restoration of facial emotional expression after face transplant. Existing evidence comes from methods such as facial surface electromyography,<sup><xref rid="zoi190718r15" ref-type="bibr">15</xref></sup> which is sensitive but requires painstaking placement of several electrodes on the skin,<sup><xref rid="zoi190718r16" ref-type="bibr">16</xref></sup> and appearance-based facial feature extraction, which is similar to facial recognition technology but requires significant data processing that limits reproducibility.<sup><xref rid="zoi190718r17" ref-type="bibr">17</xref></sup> These methods are obtrusive and prone to human instrumentation error. Their clinical implementation would be time-consuming and would bind patients to laboratory settings, which could affect medical adherence over time.<sup><xref rid="zoi190718r18" ref-type="bibr">18</xref></sup> The need to find a less obtrusive and more reliable method for evaluating emotional expression as an outcome measure of face transplant remains.</p><p>Software-based video analysis, a merger of facial recognition technology and deep learning, has proven to be capable of assessing facial motor movement functions after face transplant.<sup><xref rid="zoi190718r19" ref-type="bibr">19</xref></sup> We used a commercially available video analysis software that automatically analyzes facial movement for emotional expression to evaluate recovery of social functions after face transplant because it has been shown to do so in a manner similar to that of an objective human observer.<sup><xref rid="zoi190718r20" ref-type="bibr">20</xref></sup> Simultaneously, this method remains unobtrusive and capable of producing standardized measurements to track an individual&#x02019;s rehabilitation progress or for group comparison.</p><p>We hypothesize that face transplant restores the possibility of emotional expression because it restores both the face&#x02019;s human aesthetic and its underlying musculature, allowing for nonverbal communication perceivable to human observers. We believe that quantitative evaluation of emotional expression recovery in patients with face transplants could provide another objective outcome measure of face transplant. To our knowledge, this is the first study to detect and track facial emotional expression in patients with face transplants via an objective, noninvasive, and nonobtrusive method.</p></sec><sec id="H1-2-ZOI190718"><title>Methods</title><sec id="H2-1-ZOI190718"><title>Study Participants</title><p>This study was approved by the institutional review board of the Partners Human Research Committee. Written informed consent was obtained from all study participants. This study follows the Strengthening the Reporting of Observational Studies in Epidemiology (<ext-link ext-link-type="uri" xlink:href="http://www.equator-network.org/reporting-guidelines/strobe/">STROBE</ext-link>) reporting guideline for case-control studies.</p><p>This retrospective case-control study was performed using 44 videos from 6 patients with face transplants (representing 15% of patients with face transplants worldwide) taken at regular intervals over a maximal posttransplant period of 9.5 years. Also used were 12 videos from 6 healthy controls who were matched according to the age of the donor and sex and cultural ethnicity of the recipient and who had no history of previous reconstructive or cosmetic facial procedures.</p></sec><sec id="H2-2-ZOI190718"><title>Study Tools</title><p>Videos were acquired using a commercially available camera (EOS Rebel T3i; Canon) and tripod. Analysis was based on conventional video formats; thus, no special equipment or extra processing was required. FaceReader facial expression recognition software version 6.1 (Noldus) was used to detect and track faces, extract facial features, and analyze facial expressions.<sup><xref rid="zoi190718r21" ref-type="bibr">21</xref></sup> The software uses the Viola-Jones cascaded classifier algorithm<sup><xref rid="zoi190718r22" ref-type="bibr">22</xref></sup> to identify facial features and create a neutral face state. Then using the Active Appearance Method,<sup><xref rid="zoi190718r23" ref-type="bibr">23</xref></sup> an artificial face model is synthesized to compare vector variations between baseline and simulated faces with a database of annotated images.</p><p>The video analysis software achieves this by relying on the Facial Action Coding System,<sup><xref rid="zoi190718r24" ref-type="bibr">24</xref></sup> which taxonomizes visibly different facial movements on the basis of underlying anatomical structures into individual action units. For example, when people produce the prototypical facial expression for happiness, their cheeks raise (action unit 6) and the commissures of their mouth are pulled laterally (action unit 12). These facial expressions performed in concert effectively increase the width of the lower two-thirds of the face and may increase the distance from the chin to the brows, depending on the intensity of expression (<xref ref-type="fig" rid="zoi190718f1">Figure 1</xref>). The resultant smile is detectable and perceivable as the emotional expression for happiness, objectively, by untrained human observers<sup><xref rid="zoi190718r25" ref-type="bibr">25</xref></sup> and trained video analysis software.<sup><xref rid="zoi190718r26" ref-type="bibr">26</xref></sup></p><fig id="zoi190718f1" fig-type="figure" orientation="portrait" position="float"><label>Figure 1. </label><caption><title>Action Units and Their Facial Regions</title><p>The simple facial action units, as first described by Ekman et al,<sup><xref rid="zoi190718r12" ref-type="bibr">12</xref></sup> are presented with the muscles responsible for their motor movement. We assigned them into regions of the face commonly amenable to restoration by face transplant. Notably, there are no action units 3, 8, 19, and 21. Action units 25 and 26 are not represented visually because they are dependent on muscle relaxation. Action unit 27 is not represented visually because the force vector for the pterygoid muscles are not in the same plane of the image. Image by visual artist Coralie Vogelaar, 2018, used with permission.</p></caption><graphic xlink:href="jamanetwopen-3-e1919247-g001"/></fig><p>The video analysis software determines the magnitude of vector variation between neutral and simulated facial expressions using a trained artificial neural network<sup><xref rid="zoi190718r27" ref-type="bibr">27</xref></sup> and then compares them with prototypical features of 6 basic emotions to produce an intensity score for each. This intensity score value ranges from 0 to 1, depending on whether the emotional expression is entirely absent or fully present, respectively. According to the FaceReader software manufacturer, intensity score values greater than 0.5 are detectable by objective human observers.<sup><xref rid="zoi190718r21" ref-type="bibr">21</xref></sup></p></sec><sec id="H2-3-ZOI190718"><title>Study Design</title><p>All study participants were recorded performing commands from 2 different protocols to either indirectly or directly evaluate emotional expression. For indirect evaluation, patients with face transplants were filmed every 6 months after transplant. All study participants performed a series of 12 facial movements: smile, frown, purse lips, open mouth wide, shut mouth tight, open eyes wide, close eyes tight, wrinkle nose, pucker lips, wink with right eye, wink with left eye, and puff cheeks. For direct evaluation, all healthy controls and 3 patients with face transplants (patient 1 at 9.5 years, patient 4 at 7.5 years, and patient 5 at 5.5 years) performed a series of 6 simulated faces for when they feel happy, sad, angry, surprised, scared, and disgusted. For both protocols, all study participants were asked to return to their neutral resting face between commands. Each video was less than 2 minutes long, and we attempted to standardize the background and lighting implemented.</p><p>Video analysis was performed after individual video calibration to correct for participant-specific biases toward certain facial expressions. Baseline emotional expressions were set to 0 (ie, intensity score equal to 0) using the first neutral resting face in each video. For indirect evaluation, maximum intensity score values for each emotion were used, and the possibility of expression was verified by correlating the protocol command, with correspondent action units, to the emotional state detected for consistency. For direct evaluation, the maximal intensity score values were extracted from the video sequence dedicated to the performed emotion. Data from all study participants were used for analysis of happiness. For all other emotions, patients with partial face transplants were excluded because not all action units necessary for the emotional expression were transplanted. For indirect evaluation, the highest intensity score value after the first year was chosen for each patient with face transplant to allow comparison with healthy controls.</p></sec><sec id="H2-4-ZOI190718"><title>Statistical Analysis</title><p>To study changes in emotional expression over time in patients with face transplants, a piecewise linear regression model with random slope and intercept was fitted to the data with a knot at 1 year after transplant to allow for changes in the slope. The knot location was chosen because previous scientific literature<sup><xref rid="zoi190718r28" ref-type="bibr">28</xref>,<xref rid="zoi190718r29" ref-type="bibr">29</xref></sup> reported that motor recovery improvements occurred mostly during the first year after transplant and because quantitative data beyond that time frame are mostly lacking. Statistical significance of the model was calculated from the comparison with hypothetical model, with a slope of&#x02009;0. Two-sided <italic>P</italic> values less than .05 were considered statistically significant and were calculated using the exact sum-of-squares <italic>F</italic> test. The continuous parametric variables are presented as mean (95% CI) or mean (SD). All statistical analysis was performed using Prism statistical software version 8.02 (GraphPad Software). Data analysis was performed from June 2018 to November 2018.</p></sec></sec><sec id="H1-3-ZOI190718"><title>Results</title><sec id="H2-5-ZOI190718"><title>Study Participant Characteristics</title><p>Six patients underwent face transplant (4 men; mean [SD] age, 42 [14] years). Four patients received all action unit regions after full face transplant,<sup><xref rid="zoi190718r30" ref-type="bibr">30</xref>,<xref rid="zoi190718r31" ref-type="bibr">31</xref>,<xref rid="zoi190718r32" ref-type="bibr">32</xref>,<xref rid="zoi190718r33" ref-type="bibr">33</xref></sup> whereas the 2 patients with partial face transplants received all and nearly all action units of the entire middle and lower two-thirds of the face (<xref rid="zoi190718t1" ref-type="table">Table 1</xref>). The mean (SD) donor allograft age and mean healthy control age were both 48 (10) years. All patients underwent pertinent facial nerve and facial sensory nerve neurorrhaphies, bilaterally, with 3 patients requiring intraoperative nerve grafts, 1 of which required a revision nerve transfer (<xref rid="zoi190718t1" ref-type="table">Table 1</xref>).</p><table-wrap id="zoi190718t1" orientation="landscape" position="float"><label>Table 1. </label><caption><title>Characteristics of Patients With Face Transplants and Healthy Controls</title></caption><table frame="hsides" rules="groups"><col width="5.31%" span="1"/><col width="6.06%" span="1"/><col width="6.06%" span="1"/><col width="6.06%" span="1"/><col width="6.82%" span="1"/><col width="6.82%" span="1"/><col width="9.09%" span="1"/><col width="12.12%" span="1"/><col width="9.85%" span="1"/><col width="11.36%" span="1"/><col width="8.33%" span="1"/><col width="12.12%" span="1"/><thead><tr><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Patient No.</th><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Date of Transplant</th><th colspan="3" valign="top" align="left" scope="colgroup" rowspan="1">Age and Sex</th><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Indication</th><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Allograft Structures</th><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Facial Nerve Neurorrhaphies</th><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Sensory Neurorrhaphies</th><th colspan="2" valign="top" align="left" scope="colgroup" rowspan="1">Nerve Transfers and Grafts</th><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Transplanted Action Unit Regions</th></tr><tr><th valign="top" colspan="1" align="left" scope="colgroup" rowspan="1">Donor</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Recipient</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Healthy Controls</th><th valign="top" colspan="1" align="left" scope="colgroup" rowspan="1">Intraoperative</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Revision</th></tr></thead><tbody><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">1</td><td valign="top" align="left" rowspan="1" colspan="1">April 2009</td><td valign="top" align="left" rowspan="1" colspan="1">Early 60s, male</td><td valign="top" align="left" rowspan="1" colspan="1">Late 50s, male</td><td valign="top" align="left" rowspan="1" colspan="1">Early 60s, male</td><td valign="top" align="left" rowspan="1" colspan="1">High-voltage burn</td><td valign="top" align="left" rowspan="1" colspan="1">Nose, cheeks, upper lip, midface bone<sup><xref rid="zoi190718r5" ref-type="bibr">5</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">5 Branches of the facial nerve, bilaterally<sup><xref rid="zoi190718r30" ref-type="bibr">30</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">Bilateral infraorbital and buccal nerves<sup><xref rid="zoi190718r30" ref-type="bibr">30</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">NA</td><td valign="top" align="left" rowspan="1" colspan="1">NA</td><td valign="top" align="left" rowspan="1" colspan="1">Midface plus lower two-thirds (except action unit 17)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">2</td><td valign="top" align="left" rowspan="1" colspan="1">March 2011</td><td valign="top" align="left" rowspan="1" colspan="1">Late 40s, male</td><td valign="top" align="left" rowspan="1" colspan="1">Mid 20s, male</td><td valign="top" align="left" rowspan="1" colspan="1">Late 40s, male</td><td valign="top" align="left" rowspan="1" colspan="1">High-voltage burn</td><td valign="top" align="left" rowspan="1" colspan="1">Full face, partial scalp<sup><xref rid="zoi190718r31" ref-type="bibr">31</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">Only upper and lower divisions of the facial nerve on the left; frontal, zygomatic, buccal and marginal mandibular branches on the right<sup><xref rid="zoi190718r31" ref-type="bibr">31</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">Left mental nerve; right supraorbital, infraorbital, and mental nerves<sup><xref rid="zoi190718r31" ref-type="bibr">31</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">Recipient thoracodorsal nerve graft for superior and inferior divisions of facial nerve on the left, and marginal mandibular on the right<sup><xref rid="zoi190718r7" ref-type="bibr">7</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">NA</td><td valign="top" align="left" rowspan="1" colspan="1">All</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">3</td><td valign="top" align="left" rowspan="1" colspan="1">April 2011</td><td valign="top" align="left" rowspan="1" colspan="1">Early 30s, male</td><td valign="top" align="left" rowspan="1" colspan="1">Early 30s, male</td><td valign="top" align="left" rowspan="1" colspan="1">Early 30s, male</td><td valign="top" align="left" rowspan="1" colspan="1">High-voltage burn</td><td valign="top" align="left" rowspan="1" colspan="1">Full face</td><td valign="top" align="left" rowspan="1" colspan="1">Buccal and marginal mandibular branches of the facial nerve, bilaterally<sup><xref rid="zoi190718r31" ref-type="bibr">31</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">Bilateral supraorbital, infraorbital, and mental nerves<sup><xref rid="zoi190718r31" ref-type="bibr">31</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">NA</td><td valign="top" align="left" rowspan="1" colspan="1">NA</td><td valign="top" align="left" rowspan="1" colspan="1">All</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">4</td><td valign="top" align="left" rowspan="1" colspan="1">May 2011</td><td valign="top" align="left" rowspan="1" colspan="1">Early 40s, female</td><td valign="top" align="left" rowspan="1" colspan="1">Late 50s, female</td><td valign="top" align="left" rowspan="1" colspan="1">Late 40s, female</td><td valign="top" align="left" rowspan="1" colspan="1">Animal attack</td><td valign="top" align="left" rowspan="1" colspan="1">Full face, partial scalp, midface bone</td><td valign="top" align="left" rowspan="1" colspan="1">6 Branches of the facial nerve, bilaterally, including frontal, zygomatic, buccal, and marginal mandibular<sup><xref rid="zoi190718r31" ref-type="bibr">31</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">Bilateral supraorbital, supratrochlear, and mental nerves<sup><xref rid="zoi190718r31" ref-type="bibr">31</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">Recipient great auricular nerve graft for 2 inferior buccal branches of facial nerve on the left<sup><xref rid="zoi190718r7" ref-type="bibr">7</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">11 mo after surgery; masseter to facial nerve transfer with recipient great auricular nerve interposition graft on the right<sup><xref rid="zoi190718r7" ref-type="bibr">7</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">All</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">5</td><td valign="top" align="left" rowspan="1" colspan="1">February 2013</td><td valign="top" align="left" rowspan="1" colspan="1">Mid 50s, female</td><td valign="top" align="left" rowspan="1" colspan="1">Mid 40s, female</td><td valign="top" align="left" rowspan="1" colspan="1">Early 50s, female</td><td valign="top" align="left" rowspan="1" colspan="1">Chemical burn</td><td valign="top" align="left" rowspan="1" colspan="1">Full face</td><td valign="top" align="left" rowspan="1" colspan="1">5 Branches of the facial nerve, bilaterally<sup><xref rid="zoi190718r32" ref-type="bibr">32</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">Bilateral supraorbital, buccal, and mental nerves<sup><xref rid="zoi190718r32" ref-type="bibr">32</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">Nerve grafts had to be used on the left</td><td valign="top" align="left" rowspan="1" colspan="1">NA</td><td valign="top" align="left" rowspan="1" colspan="1">All</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">6</td><td valign="top" align="left" rowspan="1" colspan="1">March 2014</td><td valign="top" align="left" rowspan="1" colspan="1">Early 50s, male</td><td valign="top" align="left" rowspan="1" colspan="1">Late 30s, male</td><td valign="top" align="left" rowspan="1" colspan="1">Late 40s, male</td><td valign="top" align="left" rowspan="1" colspan="1">Self-inflicted gunshot wound</td><td valign="top" align="left" rowspan="1" colspan="1">Nose, lower two-thirds, maxilla, mandible</td><td valign="top" align="left" rowspan="1" colspan="1">Buccal and marginal mandibular branches of the facial nerve, bilaterally<sup><xref rid="zoi190718r33" ref-type="bibr">33</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">Infraorbital nerves, bilaterally<sup><xref rid="zoi190718r33" ref-type="bibr">33</xref></sup></td><td valign="top" align="left" rowspan="1" colspan="1">NA</td><td valign="top" align="left" rowspan="1" colspan="1">NA</td><td valign="top" align="left" rowspan="1" colspan="1">Midface plus lower two-thirds</td></tr></tbody></table><table-wrap-foot><p>Abbreviation: NA, not applicable.</p></table-wrap-foot></table-wrap></sec><sec id="H2-6-ZOI190718"><title>Evaluation of Healthy Controls</title><p>The healthy control videos were analyzed first to validate the sensitivity and specificity of both protocols and the video analysis software. Only the emotion of happiness could be reliably detected, with mean (SD) intensity score values of 0.92&#x02009;(0.05) for indirect evaluation and 0.91&#x02009;(0.04) for direct evaluation (<xref rid="zoi190718t2" ref-type="table">Table 2</xref> and eFigure 1 in the <xref ref-type="supplementary-material" rid="note-ZOI190718-1-s">Supplement</xref>). All other emotions were detectable, but mean intensity score values did not pass the threshold for objective observer detection during both indirect and direct evaluation (eFigure 1 in the <xref ref-type="supplementary-material" rid="note-ZOI190718-1-s">Supplement</xref>).</p><table-wrap id="zoi190718t2" orientation="portrait" position="float"><label>Table 2. </label><caption><title>Evaluation of Emotional Expression<xref ref-type="table-fn" rid="zoi190718t2n1"><sup>a</sup></xref></title></caption><table frame="hsides" rules="groups"><col width="12.83%" span="1"/><col width="21.85%" span="1"/><col width="17.74%" span="1"/><col width="15.32%" span="1"/><col width="16.13%" span="1"/><col width="16.13%" span="1"/><thead><tr><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Emotional Expression</th><th rowspan="2" valign="top" align="left" scope="col" colspan="1">Action Units Involved</th><th colspan="2" valign="top" align="left" scope="colgroup" rowspan="1">Patients With Face Transplant, Mean (SD), Intensity Score Value</th><th colspan="2" valign="top" align="left" scope="colgroup" rowspan="1">Healthy Controls, Mean (SD), Intensity Score Value</th></tr><tr><th valign="top" colspan="1" align="left" scope="colgroup" rowspan="1">Indirect Evaluation (n&#x02009;=&#x02009;6)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Direct Evaluation (n&#x02009;=&#x02009;3)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Indirect Evaluation (n&#x02009;=&#x02009;6)</th><th valign="top" align="left" scope="col" rowspan="1" colspan="1">Direct Evaluation (n&#x02009;=&#x02009;6)</th></tr></thead><tbody><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">Happiness</td><td valign="top" align="left" rowspan="1" colspan="1">6&#x02009;+&#x02009;12</td><td valign="top" align="left" rowspan="1" colspan="1">0.38 (0.24)</td><td valign="top" align="left" rowspan="1" colspan="1">0.24 (0.26)</td><td valign="top" align="left" rowspan="1" colspan="1">0.92 (0.05)</td><td valign="top" align="left" rowspan="1" colspan="1">0.91 (0.04)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">Sadness</td><td valign="top" align="left" rowspan="1" colspan="1">1&#x02009;+&#x02009;4&#x02009;+&#x02009;15</td><td valign="top" align="left" rowspan="1" colspan="1">0.34 (0.16)</td><td valign="top" align="left" rowspan="1" colspan="1">0.13 (0.11)</td><td valign="top" align="left" rowspan="1" colspan="1">0.44 (0.28)</td><td valign="top" align="left" rowspan="1" colspan="1">0.34 (0.31)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">Anger</td><td valign="top" align="left" rowspan="1" colspan="1">1&#x02009;+&#x02009;2&#x02009;+&#x02009;5 + 26</td><td valign="top" align="left" rowspan="1" colspan="1">0.17 (0.21)</td><td valign="top" align="left" rowspan="1" colspan="1">0</td><td valign="top" align="left" rowspan="1" colspan="1">0.33 (0.16)</td><td valign="top" align="left" rowspan="1" colspan="1">0.28 (0.21)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">Surprise</td><td valign="top" align="left" rowspan="1" colspan="1">1&#x02009;+&#x02009;2&#x02009;+&#x02009;4 + 5&#x02009;+&#x02009;7&#x02009;+&#x02009;20 + 26</td><td valign="top" align="left" rowspan="1" colspan="1">0.28 (0.23)</td><td valign="top" align="left" rowspan="1" colspan="1">0.22 (0.37)</td><td valign="top" align="left" rowspan="1" colspan="1">0.47 (0.14)</td><td valign="top" align="left" rowspan="1" colspan="1">0.19 (0.14)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">Fear</td><td valign="top" align="left" rowspan="1" colspan="1">4&#x02009;+&#x02009;5&#x02009;+&#x02009;7 + 23</td><td valign="top" align="left" rowspan="1" colspan="1">0.24 (0.16)</td><td valign="top" align="left" rowspan="1" colspan="1">0.06 (0.09)</td><td valign="top" align="left" rowspan="1" colspan="1">0.23 (0.16)</td><td valign="top" align="left" rowspan="1" colspan="1">0.11 (0.15)</td></tr><tr><td valign="top" align="left" scope="row" rowspan="1" colspan="1">Disgust</td><td valign="top" align="left" rowspan="1" colspan="1">9&#x02009;+&#x02009;15&#x02009;+&#x02009;16</td><td valign="top" align="left" rowspan="1" colspan="1">0.09 (0.10)</td><td valign="top" align="left" rowspan="1" colspan="1">0.02 (0.02)</td><td valign="top" align="left" rowspan="1" colspan="1">0.34 (0.26)</td><td valign="top" align="left" rowspan="1" colspan="1">0.19 (0.25)</td></tr></tbody></table><table-wrap-foot><fn id="zoi190718t2n1"><label><sup>a</sup></label><p>The results for the indirect and direct evaluation of emotional expression in patients with face transplants and healthy controls are displayed. For each emotion, their corresponding action units are included and results display the mean (SD) intensity score values. For indirect evaluation, the highest intensity score value after the first year was chosen for each patient with a face transplant to allow comparison with healthy controls.</p></fn></table-wrap-foot></table-wrap></sec><sec id="H2-7-ZOI190718"><title>Indirect Evaluation of Patients With Face Transplant</title><p>We found that the emotional expression of happiness, sadness, anger, surprise, fear, and disgust was possible after face transplant with nonzero intensity score values detectable in all patients with face transplants. The mean (SD) group intensity score values were 0.38&#x02009;(0.24) for happiness, 0.34&#x02009;(0.16) for sadness, 0.17&#x02009;(0.21) for anger, 0.28&#x02009;(0.23) for surprise, 0.24&#x02009;(0.16) for fear, and 0.09&#x02009;(0.10) for disgust (<xref rid="zoi190718t2" ref-type="table">Table 2</xref>). To determine percentage recovery, maximum intensity score values for each patient were compared with mean intensity score values of healthy controls for every emotion. This made recovery greater than 100% of the level of healthy controls possible for individual patients with face transplants. Happiness expression after face transplant was found to be restored to 43% (range, 14%-75%) of that of healthy controls (<xref ref-type="fig" rid="zoi190718f2">Figure 2</xref>), with other emotions compared in similar fashion but yielding unreliable results (eFigure 2 in the <xref ref-type="supplementary-material" rid="note-ZOI190718-1-s">Supplement</xref>).</p><fig id="zoi190718f2" fig-type="figure" orientation="portrait" position="float"><label>Figure 2. </label><caption><title>Restoration of Happiness Expression After Face Transplant Compared With Healthy Controls</title><p>For indirect evaluation of expression of happiness, the maximum intensity score values of each patient with face transplant after the first posttransplant year were compared with the mean intensity score values of healthy controls. We found that expression of happiness, based on the recovery of the ability to smile (action units 6&#x02009;+&#x02009;12), was restored to a mean of 43% of that of healthy controls (dashed line) in the first 5 years after transplant.</p></caption><graphic xlink:href="jamanetwopen-3-e1919247-g002"/></fig><p>Intensity score values for indirect evaluation of patients with face transplants were tracked over time. During posttransplant year 1, the intensity score values for happiness decreased nonsignificantly by 0.06 point per year (95% CI, &#x02212;0.34 to 0.23 point per year; <italic>P</italic>&#x02009;=&#x02009;.66). Afterward, intensity score values for happiness increased significantly by 0.04 point per year (95% CI, 0.02 to 0.06 point per year; <italic>P</italic>&#x02009;=&#x02009;.002) (<xref ref-type="fig" rid="zoi190718f3">Figure 3</xref>). The intensity score values for sadness decreased significantly by 0.53 point during posttransplant year 1 (95% CI, &#x02212;0.82 to &#x02212;0.24 point per year; <italic>P</italic>&#x02009;=&#x02009;.005), with negligible changes afterward (0.01 point per year; 95% CI, &#x02212;0.01 to 0.03 point per year; <italic>P</italic>&#x02009;=&#x02009;.48) (<xref ref-type="fig" rid="zoi190718f3">Figure 3</xref>). Individual patient trends for happiness and sadness are displayed in eFigure 3 in the <xref ref-type="supplementary-material" rid="note-ZOI190718-1-s">Supplement</xref>. The remaining emotions of anger, surprise, fear, and disgust had intensity score values with nonsignificant changes (<italic>P</italic>&#x02009;&#x0003e;&#x02009;.05) after transplant (eFigure 4 in the <xref ref-type="supplementary-material" rid="note-ZOI190718-1-s">Supplement</xref>).</p><fig id="zoi190718f3" fig-type="figure" orientation="portrait" position="float"><label>Figure 3. </label><caption><title>Longitudinal Evaluation of Expression of Happiness and Sadness After Face Transplant</title><p>The intensity score values for expression of happiness and sadness during longitudinal indirect evaluation were modeled using piecewise linear regression with a knot at posttransplant year 1 (dashed lines). A, Expression of happiness was found to increase significantly by 0.04 point per year (95% CI, 0.02 to 0.06 point per year; <italic>P</italic>&#x02009;=&#x02009;.002) after the knot at year 1 (before year 1, &#x02212;0.06 point per year; 95% CI, &#x02212;0.34 to 0.23 point per year). B, The intensity score values for expression of sadness decreased significantly by 0.53 point per year in posttransplant year 1 (95% CI, &#x02212;0.82 to &#x02212;0.24 point per year; <italic>P</italic>&#x02009;=&#x02009;.005), but afterward the change was negligible (0.01 point per year, 95% CI, &#x02212;0.01 to 0.03 point per year; <italic>P</italic>&#x02009;=&#x02009;.48).</p></caption><graphic xlink:href="jamanetwopen-3-e1919247-g003"/></fig></sec><sec id="H2-8-ZOI190718"><title>Long-term Direct Evaluation of Patients With Face Transplant</title><p>Three of 6 patients with face transplants were able to be filmed for the direct evaluation protocol. The mean (SD) group intensity score values were 0.24&#x02009;(0.26) for happiness, 0.13&#x02009;(0.11) for sadness, 0 for anger, 0.22&#x02009;(0.37) for surprise, 0.06&#x02009;(0.09) for fear, and 0.02&#x02009;(0.02) for disgust (<xref rid="zoi190718t2" ref-type="table">Table 2</xref>). On the basis of limited cohort data, expression of happiness was restored to a mean of 26% (range, 5%-59%) of that of healthy controls in the long term (eFigure 5 in the <xref ref-type="supplementary-material" rid="note-ZOI190718-1-s">Supplement</xref>).</p></sec></sec><sec id="H1-4-ZOI190718"><title>Discussion</title><p>Facial recognition technology has been proposed as a method to improve performance metrics in vascularized composite allotransplant.<sup><xref rid="zoi190718r34" ref-type="bibr">34</xref></sup> In this study, we show that using software-based video analysis to detect and track nonverbal communication via facial emotional expression after face transplant is feasible. This method is noninvasive, nonobtrusive, able to be implemented widely, and capable of producing objective intensity score values that are amenable to standardization. All 6 basic emotions&#x02014;happiness, sadness, anger, surprise, fear, and disgust&#x02014;were detectable with nonzero intensity score values in patients with face transplants during indirect evaluation. This finding suggests that restoration of functional human aesthetic and underlying facial musculature after face transplant surpasses the threshold necessary for objective perception by software.</p><p>A prior study<sup><xref rid="zoi190718r19" ref-type="bibr">19</xref></sup> using software-based analysis showed that smile significantly improves over time after face transplant and is comparable with that of the healthy population, consistent with reported outcomes from most other face transplant teams.<sup><xref rid="zoi190718r5" ref-type="bibr">5</xref></sup> The current study found that the potential to express happiness after face transplant recovers to 43% of that of healthy controls in the first 5 years; after year 1, expression of happiness significantly improves by 0.04 intensity score point per year. These findings are significant because they are the first objective values on smile restoration after face transplant that can be standardized and tracked over time. Despite having a mean intensity score value less than 0.50, or below the threshold for recognition by objective human observers, happiness may be the only valid and reliable marker after face transplant. This emotional expression is uniquely and reliably recognized in healthy controls with high specificity and sensitivity. Furthermore, given that the video analysis software recognizes happiness similarly to objective human observers with accuracy greater than 90%,<sup><xref rid="zoi190718r25" ref-type="bibr">25</xref>,<xref rid="zoi190718r35" ref-type="bibr">35</xref>,<xref rid="zoi190718r36" ref-type="bibr">36</xref>,<xref rid="zoi190718r37" ref-type="bibr">37</xref></sup> its ability to detect happiness after face transplant at subclinical levels not perceptible to human observers highlights the potential of video analysis software as a rehabilitative tool.</p><p>Although reliable interpretation is possible for happiness only, sadness was the only other expression that significantly changed after transplant. We believe that the high intensity score values before year 1 are the result of tissues drooping because of their weight and from incomplete recovery of muscle tone. Increased intensity score values for sadness in all patients with face transplants before calibration before year 1 further support this theory. Given no significant change in sadness expression thereafter, the theory that neuromuscular recovery after year 1 creates a true baseline expression of the new face is supported.</p><p>Both the present study and our previous study<sup><xref rid="zoi190718r19" ref-type="bibr">19</xref></sup> using facial recognition technology independently validate our findings that mean motor function at 5 years after transplant reaches 60% of maximal possible recovery.<sup><xref rid="zoi190718r1" ref-type="bibr">1</xref></sup> Currently, we evaluate motor recovery using the Daniels and Worthingham manual muscle testing technique,<sup><xref rid="zoi190718r38" ref-type="bibr">38</xref></sup> which is the standard for measurement but is liable to subjective evaluation, time-consuming, and exhausting for patients. Using software-based video analysis to measure underlying muscle recovery indirectly via emotional expression could address these limitations and provide novel information about a patient&#x02019;s recovery. In essence, this tool measures the return of recognizable human aesthetic and nonverbal communication, both social functions of the face, in an unbiased manner. It can objectively provide data helpful to determine whether face transplant meets its ethical goal of restoring functions necessary for societal reintegration.</p><p>Some studies have attempted to measure emotional expression after face transplant. Top&#x000e7;u et al<sup><xref rid="zoi190718r15" ref-type="bibr">15</xref></sup> found that the frequency and spatial distribution of facial surface electromyography data recorded during emotional expression were significantly different between patients with face transplants and healthy controls after 2 years. One of their 3 patients with full face transplants had high-frequency firing distribution similar to that of healthy controls for happiness, whereas other expressions had similar distribution patterns but lower frequency. This could be due to limitations in electromyography measurement of emotional expression.<sup><xref rid="zoi190718r39" ref-type="bibr">39</xref></sup> Supporting this claim are findings from De Letter et al<sup><xref rid="zoi190718r40" ref-type="bibr">40</xref></sup> showing that electromyography detected signs of remyelinization after face transplant without clinically meaningful return of function. Bedeloglu et al<sup><xref rid="zoi190718r17" ref-type="bibr">17</xref></sup> acknowledged this limitation, performed image-based analysis of emotional expression in 2 patients with full face transplants, and found that happiness could be detected to 45% of that of healthy controls after 3 years. Their methods, despite being similar to processes required for software analysis and yielding results comparable to ours, require trained interpretation of the data. The video analysis software in our study has sensitivity on par with that of electromyography,<sup><xref rid="zoi190718r41" ref-type="bibr">41</xref></sup> but because it depends on visual data necessary for human visual system processing,<sup><xref rid="zoi190718r26" ref-type="bibr">26</xref>,<xref rid="zoi190718r42" ref-type="bibr">42</xref></sup> clinical specificity for emotional expression detection is greater. Reliability of the tool improves with optimization of lighting and background, and when it is combined with easily interpretable intensity score values amenable to standardization and reduced sensitivity to human instrumentation error, the argument for video analysis software as a clinical assessment tool is stronger than that for electromyography.</p><p>Future research should prioritize face transplant rehabilitation programs. Top&#x000e7;u et al<sup><xref rid="zoi190718r43" ref-type="bibr">43</xref></sup> observed gradual recovery of emotional expressions after rehabilitation with functional electrical stimulation in 2 patients with full face transplants after 3 years. Their findings are subject to the same pitfalls of using electromyography and would make long-term comparison unreliable given the high likelihood of human instrumentation error. Incorporating software-based video analysis into posttransplant rehabilitation could allow for both intensity score value tracking and personalized rehabilitation goals based on expected face transplant cohort data. A second research focus should seek to improve on the Cleveland Clinic FACES Scoring System for Face Transplant Candidate Evaluation.<sup><xref rid="zoi190718r44" ref-type="bibr">44</xref>,<xref rid="zoi190718r45" ref-type="bibr">45</xref></sup> Development of a specific functional outcome scale for face transplant should rely on objective measures of vital, independent, psychological, and social functions of the face. Software-based video analysis could provide objective intensity score values to standardize a grading system for the recovery of emotional expression potential after face transplant. Another area for implementing software-based video analysis is the detection of allograft rejection. Visible redness and swelling of the facial allograft are associated with rejection episodes within the first 2 years.<sup><xref rid="zoi190718r46" ref-type="bibr">46</xref></sup> These may be features amenable to software detection that could provide objective data to supplement more-specific biomarkers of rejection.<sup><xref rid="zoi190718r47" ref-type="bibr">47</xref></sup></p><sec id="H2-9-ZOI190718"><title>Limitations</title><p>Motivation of patients to perform facial expressions and their comfort in expressing emotions is a limitation of this study. Rehabilitation after face transplant is strenuous because it burdens the patient with numerous, lengthy appointments that can result in follow-up fatigue. This could affect participation in research and may be responsible for intensity score variability within the same patient and between patients. Software-based video analysis could address follow-up fatigue by reducing the need for long-distance travel to the transplant hospital.<sup><xref rid="zoi190718r48" ref-type="bibr">48</xref></sup> Videos could be filmed at a patient&#x02019;s home, analyzed, and then shared with the transplant team, as was done for long-term direct evaluation in patients with face transplants for this study. This could facilitate a more honest appreciation of functional recovery outside of a laboratory setting,<sup><xref rid="zoi190718r49" ref-type="bibr">49</xref></sup> aid rehabilitation,<sup><xref rid="zoi190718r50" ref-type="bibr">50</xref></sup> and, on the basis of solid-organ transplantation data, may improve medical adherence and outcomes while decreasing the economic cost after transplant.<sup><xref rid="zoi190718r51" ref-type="bibr">51</xref></sup></p><p>Objective evaluation of emotional expressions after face transplant is a challenge because of cultural, regional,<sup><xref rid="zoi190718r52" ref-type="bibr">52</xref></sup> and personal variance in expression and presents another limitation to this study. The deep learning algorithm in the video analysis software is trained on images displaying prototypical emotions specific to Western cultures, with exaggerated facial expressions that may not depict realistic expression by individuals. It is possible that not every study participant performed all prototypical features while making facial emotional expressions under direct evaluation. This could explain why intensity score values for healthy controls under direct evaluation demonstrated large variability due to personal differences in expressivity. These biases could also explain why only happiness was reliably recognized in healthy controls, because its recognition is dependent on a smile that requires 2 action units to perform. More-complex emotional expressions, such as fear, require a greater number of units firing in concert to be detected, allowing for greater likelihood of personal and cultural biases to affect individual emotional expression.</p><p>Along these lines, new research shows that Eastern and Western cultures appreciate facial emotional expressions differently,<sup><xref rid="zoi190718r53" ref-type="bibr">53</xref>,<xref rid="zoi190718r54" ref-type="bibr">54</xref>,<xref rid="zoi190718r55" ref-type="bibr">55</xref></sup> which suggests that universality in expression relies more on valence, arousal, and dominance.<sup><xref rid="zoi190718r56" ref-type="bibr">56</xref>,<xref rid="zoi190718r57" ref-type="bibr">57</xref></sup> We believe our findings support this latter point in 2 ways. Happiness and sadness (positive and negative valence, respectively) were the only emotions that were detected with statistical significance and were the 2 emotions with the largest mean intensity score values under direct evaluation in healthy controls. Interestingly, for all study participants, the mean intensity score values were greater for indirect evaluation of every emotional expression than for direct evaluation while maintaining similar variability. This could be explained by decreased effort and recruitment of motor units necessary to activate single action units. However, this would only explain these findings for simple emotional expressions, such as happiness and sadness, but not for more complex emotional expressions, such as anger, surprise, fear, and disgust, which require multiple action units firing simultaneously to be detected. This suggests that action units necessary for emotional expression detection are functional after face transplant and cultural bias in emotional expression was mitigated under indirect evaluation.</p><p>There is evidence that face transplant restores the potential to perform a function important for social integration,<sup><xref rid="zoi190718r58" ref-type="bibr">58</xref></sup> one that provides clues on biological and mental health.<sup><xref rid="zoi190718r59" ref-type="bibr">59</xref>,<xref rid="zoi190718r60" ref-type="bibr">60</xref></sup> Although our results are reflective of only 15% of patients with face transplants worldwide, future collaborative studies between face transplantation centers should validate our results. If and when face transplantation occurs in Eastern societies, software will have to be trained on a more culturally appropriate set of images to accurately detect emotional expression as an outcome.</p></sec></sec><sec id="H1-5-ZOI190718"><title>Conclusions</title><p>This study demonstrates the potential for quantitative evaluation of emotional expression after face transplant to complement existing outcome measures. We believe that vital and independent functions restore the hardware of the face, with psychological and social functions acting as its necessary software. The use of video analysis software&#x02014;an objective, noninvasive, and nonobtrusive method&#x02014;to detect and track emotional expression in patients with face transplants provides novel evidence supporting the procedure&#x02019;s viability as a treatment modality for severe facial deformity. Results from our case-control study suggest that partial restoration of facial emotional expression is possible after face transplant. The results indicate the potential for video analysis software to provide useful clinical information and aid rehabilitation after face transplant.</p></sec></body><back><ref-list id="REF-ZOI190718"><title>References</title><ref id="zoi190718r1"><label>1</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Tasigiorgos</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kollar</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Turk</surname><given-names>M</given-names></name>, <etal/></person-group>
<article-title>Five-year follow-up after face transplantation</article-title>. <source>N Engl J Med</source>. <year>2019</year>;<volume>380</volume>(<issue>26</issue>):-. doi:<pub-id pub-id-type="doi">10.1056/NEJMc1810468</pub-id><pub-id pub-id-type="pmid">31141626</pub-id></mixed-citation></ref><ref id="zoi190718r2"><label>2</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Fischer</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Wallins</surname><given-names>JS</given-names></name>, <name name-style="western"><surname>Bueno</surname><given-names>EM</given-names></name>, <etal/></person-group>
<article-title>Airway recovery after face transplantation</article-title>. <source>Plast Reconstr Surg</source>. <year>2014</year>;<volume>134</volume>(<issue>6</issue>):<fpage>946e</fpage>-<lpage>954e</lpage>. doi:<pub-id pub-id-type="doi">10.1097/PRS.0000000000000752</pub-id><pub-id pub-id-type="pmid">25415117</pub-id></mixed-citation></ref><ref id="zoi190718r3"><label>3</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Grigos</surname><given-names>MI</given-names></name>, <name name-style="western"><surname>LeBlanc</surname><given-names>&#x000c9;</given-names></name>, <name name-style="western"><surname>Hagedorn</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Diaz-Siso</surname><given-names>JR</given-names></name>, <name name-style="western"><surname>Plana</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Rodriguez</surname><given-names>ED</given-names></name></person-group>
<article-title>Changes in articulatory control pre- and post-facial transplant: a case report</article-title>. <source>J Speech Lang Hear Res</source>. <year>2019</year>;<volume>62</volume>(<issue>2</issue>):<fpage>297</fpage>-<lpage>306</lpage>. doi:<pub-id pub-id-type="doi">10.1044/2018_JSLHR-S-18-0147</pub-id><pub-id pub-id-type="pmid">30950699</pub-id></mixed-citation></ref><ref id="zoi190718r4"><label>4</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Petruzzo</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Dubernard</surname><given-names>JM</given-names></name></person-group>
<article-title>The International Registry on Hand and Composite Tissue Allotransplantation</article-title>. <source>Clin Transpl</source>. <year>2011</year>;<fpage>247</fpage>-<lpage>253</lpage>.<pub-id pub-id-type="pmid">22755418</pub-id></mixed-citation></ref><ref id="zoi190718r5"><label>5</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Fischer</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kueckelhaus</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Pauzenberger</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Bueno</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Pomahac</surname><given-names>B</given-names></name></person-group>
<article-title>Functional outcomes of face transplantation</article-title>. <source>Am J Transplant</source>. <year>2015</year>;<volume>15</volume>(<issue>1</issue>):<fpage>220</fpage>-<lpage>233</lpage>. doi:<pub-id pub-id-type="doi">10.1111/ajt.12956</pub-id><pub-id pub-id-type="pmid">25359281</pub-id></mixed-citation></ref><ref id="zoi190718r6"><label>6</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Siemionow</surname><given-names>M</given-names></name></person-group>
<article-title>The decade of face transplant outcomes</article-title>. <source>J Mater Sci Mater Med</source>. <year>2017</year>;<volume>28</volume>(<issue>5</issue>):<fpage>64</fpage>. doi:<pub-id pub-id-type="doi">10.1007/s10856-017-5873-z</pub-id><pub-id pub-id-type="pmid">28303433</pub-id></mixed-citation></ref><ref id="zoi190718r7"><label>7</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Aycart</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Perry</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Alhefzi</surname><given-names>M</given-names></name>, <etal/></person-group>
<article-title>Surgical optimization of motor recovery in face transplantation</article-title>. <source>J Craniofac Surg</source>. <year>2016</year>;<volume>27</volume>(<issue>2</issue>):<fpage>286</fpage>&#x02013;<lpage>292</lpage>. doi:<pub-id pub-id-type="doi">10.1097/scs.0000000000002305</pub-id><pub-id pub-id-type="pmid">26967066</pub-id></mixed-citation></ref><ref id="zoi190718r8"><label>8</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Furr</surname><given-names>LA</given-names></name>, <name name-style="western"><surname>Wiggins</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Cunningham</surname><given-names>M</given-names></name>, <etal/></person-group>
<article-title>Psychosocial implications of disfigurement and the future of human face transplantation</article-title>. <source>Plast Reconstr Surg</source>. <year>2007</year>;<volume>120</volume>(<issue>2</issue>):<fpage>559</fpage>-<lpage>565</lpage>. doi:<pub-id pub-id-type="doi">10.1097/01.prs.0000267584.66732.e5</pub-id><pub-id pub-id-type="pmid">17632364</pub-id></mixed-citation></ref><ref id="zoi190718r9"><label>9</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Aycart</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Kiwanuka</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Krezdorn</surname><given-names>N</given-names></name>, <etal/></person-group>
<article-title>Quality of life after face transplantation: outcomes, assessment tools, and future directions</article-title>. <source>Plast Reconstr Surg</source>. <year>2017</year>;<volume>139</volume>(<issue>1</issue>):<fpage>194</fpage>-<lpage>203</lpage>. doi:<pub-id pub-id-type="doi">10.1097/PRS.0000000000002890</pub-id><pub-id pub-id-type="pmid">28027248</pub-id></mixed-citation></ref><ref id="zoi190718r10"><label>10</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Nizzi</surname><given-names>M-C</given-names></name>, <name name-style="western"><surname>Tasigiorgos</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Turk</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Moroni</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Bueno</surname><given-names>E</given-names></name>, <name name-style="western"><surname>Pomahac</surname><given-names>B</given-names></name></person-group>
<article-title>Psychological outcomes in face transplant recipients: a literature review</article-title>. <source>Curr Surg Rep</source>. <year>2017</year>;<volume>5</volume>(<issue>10</issue>):<fpage>26</fpage>. doi:<pub-id pub-id-type="doi">10.1007/s40137-017-0189-y</pub-id></mixed-citation></ref><ref id="zoi190718r11"><label>11</label><mixed-citation publication-type="book"><person-group><name name-style="western"><surname>Darwin</surname><given-names>C</given-names></name></person-group>
<source>The Expression of the Emotions in Man and Animals</source>. <edition>3rd ed</edition>
<publisher-loc>London, UK</publisher-loc>: <publisher-name>Fontana Press</publisher-name>; <year>1999</year>.</mixed-citation></ref><ref id="zoi190718r12"><label>12</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Ekman</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Sorenson</surname><given-names>ER</given-names></name>, <name name-style="western"><surname>Friesen</surname><given-names>WV</given-names></name></person-group>
<article-title>Pan-cultural elements in facial displays of emotion</article-title>. <source>Science</source>. <year>1969</year>;<volume>164</volume>(<issue>3875</issue>):<fpage>86</fpage>-<lpage>88</lpage>. doi:<pub-id pub-id-type="doi">10.1126/science.164.3875.86</pub-id><pub-id pub-id-type="pmid">5773719</pub-id></mixed-citation></ref><ref id="zoi190718r13"><label>13</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Ekman</surname><given-names>P</given-names></name></person-group>
<article-title>Are there basic emotions?</article-title>
<source>Psychol Rev</source>. <year>1992</year>;<volume>99</volume>(<issue>3</issue>):<fpage>550</fpage>-<lpage>553</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0033-295X.99.3.550</pub-id><pub-id pub-id-type="pmid">1344638</pub-id></mixed-citation></ref><ref id="zoi190718r14"><label>14</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Ekman</surname><given-names>P</given-names></name></person-group>
<article-title>What scientists who study emotion agree about</article-title>. <source>Perspect Psychol Sci</source>. <year>2016</year>;<volume>11</volume>(<issue>1</issue>):<fpage>31</fpage>-<lpage>34</lpage>. doi:<pub-id pub-id-type="doi">10.1177/1745691615596992</pub-id><pub-id pub-id-type="pmid">26817724</pub-id></mixed-citation></ref><ref id="zoi190718r15"><label>15</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Top&#x000e7;u</surname><given-names>&#x000c7;</given-names></name>, <name name-style="western"><surname>Uysal</surname><given-names>H</given-names></name>, <name name-style="western"><surname>&#x000d6;zkan</surname><given-names>&#x000d6;</given-names></name>, <etal/></person-group>
<article-title>Assessment of emotional expressions after full-face transplantation</article-title>. <source>Neural Plast</source>. <year>2017</year>;<volume>2017</volume>:<elocation-id>8789724</elocation-id>. doi:<pub-id pub-id-type="doi">10.1155/2017/8789724</pub-id><pub-id pub-id-type="pmid">28717523</pub-id></mixed-citation></ref><ref id="zoi190718r16"><label>16</label><mixed-citation publication-type="book"><person-group><name name-style="western"><surname>Mallat</surname><given-names>S</given-names></name></person-group>
<chapter-title>Wavelet packet and local cosine bases</chapter-title> In: <person-group><name name-style="western"><surname>Mallat</surname><given-names>S</given-names></name></person-group>, ed. <source>A Wavelet Tour of Signal Processing: The Sparse Way</source>. <edition>3rd ed</edition>
<publisher-loc>Cambridge, UK</publisher-loc>: <publisher-name>Academic Press</publisher-name>; <year>2008</year>:<fpage>377</fpage>-<lpage>431</lpage>.</mixed-citation></ref><ref id="zoi190718r17"><label>17</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Bedeloglu</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Top&#x000e7;u</surname><given-names>&#x000c7;</given-names></name>, <name name-style="western"><surname>Akgul</surname><given-names>A</given-names></name>, <etal/></person-group>
<article-title>Image-based analysis of emotional facial expressions in full face transplants</article-title>. <source>J Med Syst</source>. <year>2018</year>;<volume>42</volume>(<issue>3</issue>):<fpage>42</fpage>. doi:<pub-id pub-id-type="doi">10.1007/s10916-018-0895-8</pub-id><pub-id pub-id-type="pmid">29353390</pub-id></mixed-citation></ref><ref id="zoi190718r18"><label>18</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Tasigiorgos</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Dorante</surname><given-names>MI</given-names></name>, <name name-style="western"><surname>Devine</surname><given-names>E</given-names></name>, <etal/></person-group>
<article-title>American Society for Reconstructive Transplantation Conference Abstracts 2018: can we predict adherence in face transplantation recipients? the Brigham and Women&#x02019;s Hospital experience</article-title>. <source>SAGE Open Med</source>. <year>2018</year>;<volume>6</volume>:<fpage>42</fpage>-<lpage>43</lpage>. doi:<pub-id pub-id-type="doi">10.1177/2050312118808661</pub-id></mixed-citation></ref><ref id="zoi190718r19"><label>19</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Fischer</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Diehm</surname><given-names>Y</given-names></name>, <name name-style="western"><surname>Dorante</surname><given-names>MI</given-names></name>, <etal/></person-group>
<article-title>Software-based video analysis of functional outcomes of face transplantation</article-title>. <source>Microsurgery</source>. <year>2019</year>;<volume>39</volume>(<issue>1</issue>):<fpage>53</fpage>-<lpage>61</lpage>. doi:<pub-id pub-id-type="doi">10.1002/micr.30360</pub-id><pub-id pub-id-type="pmid">30159931</pub-id></mixed-citation></ref><ref id="zoi190718r20"><label>20</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Wegrzyn</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Vogt</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Kireclioglu</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Schneider</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Kissler</surname><given-names>J</given-names></name></person-group>
<article-title>Mapping the emotional face: how individual face parts contribute to successful emotion recognition</article-title>. <source>PLoS One</source>. <year>2017</year>;<volume>12</volume>(<issue>5</issue>):<fpage>e0177239</fpage>. doi:<pub-id pub-id-type="doi">10.1371/journal.pone.0177239</pub-id><pub-id pub-id-type="pmid">28493921</pub-id></mixed-citation></ref><ref id="zoi190718r21"><label>21</label><mixed-citation publication-type="web"><person-group><collab>Noldus Information Technology</collab></person-group> FaceReader version 6.1, reference manual. <ext-link ext-link-type="uri" xlink:href="https://www.noldus.com/human-behavior-research/products/facereader">https://www.noldus.com/human-behavior-research/products/facereader</ext-link>. Published <year>2015</year>. Accessed November 26, 2019.</mixed-citation></ref><ref id="zoi190718r22"><label>22</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Viola</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Jones</surname><given-names>MJ</given-names></name></person-group>
<article-title>Robust real-time face detection</article-title>. <source>Int J Comput Vis</source>. <year>2004</year>;<volume>57</volume>(<issue>2</issue>):<fpage>137</fpage>-<lpage>154</lpage>. doi:<pub-id pub-id-type="doi">10.1023/B:VISI.0000013087.49260.fb</pub-id></mixed-citation></ref><ref id="zoi190718r23"><label>23</label><mixed-citation publication-type="web"><person-group><name name-style="western"><surname>Cootes</surname><given-names>TF</given-names></name>, <name name-style="western"><surname>Taylor</surname><given-names>CJ</given-names></name></person-group> Statistical models of appearance for computer vision. <ext-link ext-link-type="uri" xlink:href="http://www.face-rec.org/algorithms/AAM/app_models.pdf">http://www.face-rec.org/algorithms/AAM/app_models.pdf</ext-link>. Published March 8, <year>2004</year>. Accessed November 26, 2019.</mixed-citation></ref><ref id="zoi190718r24"><label>24</label><mixed-citation publication-type="book"><person-group><name name-style="western"><surname>Ekman</surname><given-names>P</given-names></name>, <name name-style="western"><surname>Friesen</surname><given-names>WV</given-names></name></person-group>
<source>Facial Action Coding System: A Technique for the Measurement of Facial Movement</source>. <publisher-loc>Sunnyvale, CA</publisher-loc>: <publisher-name>Consulting Psychologists Press</publisher-name>; <year>1978</year>.</mixed-citation></ref><ref id="zoi190718r25"><label>25</label><mixed-citation publication-type="book"><person-group><name name-style="western"><surname>Terzis</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Moridis</surname><given-names>CN</given-names></name>, <name name-style="western"><surname>Economides</surname><given-names>AA</given-names></name></person-group> Measuring instant emotions during a self-assessment test: the use of FaceReader. In: <italic>Proceedings of the 7th International Conference on Methods and Techniques in Behavioral Research</italic>
<publisher-loc>Eindhoven, the Netherlands</publisher-loc>: <publisher-name>ACM Press</publisher-name>; <year>2010</year>:<fpage>1</fpage>-<lpage>4</lpage>. doi:<pub-id pub-id-type="doi">10.1145/1931344.1931362</pub-id></mixed-citation></ref><ref id="zoi190718r26"><label>26</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Martinez</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Du</surname><given-names>S</given-names></name></person-group>
<article-title>A model of the perception of facial expressions of emotion by humans: research overview and perspectives</article-title>. <source>J Mach Learn Res</source>. <year>2012</year>;<volume>13</volume>:<fpage>1589</fpage>-<lpage>1608</lpage>.<pub-id pub-id-type="pmid">23950695</pub-id></mixed-citation></ref><ref id="zoi190718r27"><label>27</label><mixed-citation publication-type="book"><person-group><name name-style="western"><surname>Bishop</surname><given-names>CM</given-names></name></person-group>
<source>Neural Networks for Pattern Recognition</source>. <publisher-loc>Oxford, UK</publisher-loc>: <publisher-name>Oxford University Press</publisher-name>; <year>1995</year>.</mixed-citation></ref><ref id="zoi190718r28"><label>28</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Khalifian</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Brazio</surname><given-names>PS</given-names></name>, <name name-style="western"><surname>Mohan</surname><given-names>R</given-names></name>, <etal/></person-group>
<article-title>Facial transplantation: the first 9 years</article-title>. <source>Lancet</source>. <year>2014</year>;<volume>384</volume>(<issue>9960</issue>):<fpage>2153</fpage>-<lpage>2163</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0140-6736(13)62632-X</pub-id><pub-id pub-id-type="pmid">24783986</pub-id></mixed-citation></ref><ref id="zoi190718r29"><label>29</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Rifkin</surname><given-names>WJ</given-names></name>, <name name-style="western"><surname>David</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Plana</surname><given-names>NM</given-names></name>, <etal/></person-group>
<article-title>Achievements and challenges in facial transplantation</article-title>. <source>Ann Surg</source>. <year>2018</year>;<volume>268</volume>(<issue>2</issue>):<fpage>260</fpage>-<lpage>270</lpage>. doi:<pub-id pub-id-type="doi">10.1097/SLA.0000000000002723</pub-id><pub-id pub-id-type="pmid">29489486</pub-id></mixed-citation></ref><ref id="zoi190718r30"><label>30</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Pomahac</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Lengele</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Ridgway</surname><given-names>EB</given-names></name>, <etal/></person-group>
<article-title>Vascular considerations in composite midfacial allotransplantation</article-title>. <source>Plast Reconstr Surg</source>. <year>2010</year>;<volume>125</volume>(<issue>2</issue>):<fpage>517</fpage>-<lpage>522</lpage>. doi:<pub-id pub-id-type="doi">10.1097/PRS.0b013e3181c82e6f</pub-id><pub-id pub-id-type="pmid">19910848</pub-id></mixed-citation></ref><ref id="zoi190718r31"><label>31</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Pomahac</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Pribaz</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Eriksson</surname><given-names>E</given-names></name>, <etal/></person-group>
<article-title>Three patients with full facial transplantation</article-title>. <source>N Engl J Med</source>. <year>2012</year>;<volume>366</volume>(<issue>8</issue>):<fpage>715</fpage>-<lpage>722</lpage>. doi:<pub-id pub-id-type="doi">10.1056/NEJMoa1111432</pub-id><pub-id pub-id-type="pmid">22204672</pub-id></mixed-citation></ref><ref id="zoi190718r32"><label>32</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Perry</surname><given-names>BJ</given-names></name>, <name name-style="western"><surname>Richburg</surname><given-names>BD</given-names></name>, <name name-style="western"><surname>Pomahac</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Bueno</surname><given-names>EM</given-names></name>, <name name-style="western"><surname>Green</surname><given-names>JR</given-names></name></person-group>
<article-title>The effects of lip-closure exercise on lip strength and function following full facial transplantation: a case report</article-title>. <source>Am J Speech Lang Pathol</source>. <year>2017</year>;<volume>26</volume>(<issue>2</issue>):<fpage>682</fpage>-<lpage>686</lpage>. doi:<pub-id pub-id-type="doi">10.1044/2017_AJSLP-16-0101</pub-id><pub-id pub-id-type="pmid">28654949</pub-id></mixed-citation></ref><ref id="zoi190718r33"><label>33</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Kiwanuka</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Aycart</surname><given-names>MA</given-names></name>, <name name-style="western"><surname>Gitlin</surname><given-names>DF</given-names></name>, <etal/></person-group>
<article-title>The role of face transplantation in the self-inflicted gunshot wound</article-title>. <source>J Plast Reconstr Aesthet Surg</source>. <year>2016</year>;<volume>69</volume>(<issue>12</issue>):<fpage>1636</fpage>-<lpage>1647</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.bjps.2016.08.014</pub-id><pub-id pub-id-type="pmid">27720683</pub-id></mixed-citation></ref><ref id="zoi190718r34"><label>34</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Zuo</surname><given-names>KJ</given-names></name>, <name name-style="western"><surname>Saun</surname><given-names>TJ</given-names></name>, <name name-style="western"><surname>Forrest</surname><given-names>CR</given-names></name></person-group>
<article-title>Facial recognition technology: a primer for plastic surgeons</article-title>. <source>Plast Reconstr Surg</source>. <year>2019</year>;<volume>143</volume>(<issue>6</issue>):<fpage>1298e</fpage>-<lpage>1306e</lpage>. doi:<pub-id pub-id-type="doi">10.1097/PRS.0000000000005673</pub-id><pub-id pub-id-type="pmid">31033810</pub-id></mixed-citation></ref><ref id="zoi190718r35"><label>35</label><mixed-citation publication-type="book"><person-group><name name-style="western"><surname>van Kuilenburg</surname><given-names>H</given-names></name>, <name name-style="western"><surname>Wiering</surname><given-names>M</given-names></name>, <name name-style="western"><surname>den Uyl</surname><given-names>M</given-names></name></person-group>
<chapter-title>A model based method for automatic facial expression recognition</chapter-title> In: <person-group><name name-style="western"><surname>Gama</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Camacho</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Brazdil</surname><given-names>PB</given-names></name>, <name name-style="western"><surname>Jorge</surname><given-names>AM</given-names></name>, <name name-style="western"><surname>Torgo</surname><given-names>L</given-names></name></person-group>, eds. <source>Machine Learning: ECML 2005</source>. <publisher-loc>Berlin, Germany</publisher-loc>: <publisher-name>Springer</publisher-name>; <year>2005</year>;<volume>3720</volume>:<fpage>194</fpage>-<lpage>205</lpage>. doi:<pub-id pub-id-type="doi">10.1007/11564096_22</pub-id>.</mixed-citation></ref><ref id="zoi190718r36"><label>36</label><mixed-citation publication-type="web"><person-group><name name-style="western"><surname>den Uyl</surname><given-names>MJ</given-names></name>, <name name-style="western"><surname>van Kuilenburg</surname><given-names>H</given-names></name></person-group> The FaceReader: online facial expression recognition. <ext-link ext-link-type="uri" xlink:href="http://www.vicarvision.nl/pub/fc_denuyl_and_vankuilenburg_2005.pdf">http://www.vicarvision.nl/pub/fc_denuyl_and_vankuilenburg_2005.pdf</ext-link>. Published September <year>2008</year>. Accessed November 26, 2019.</mixed-citation></ref><ref id="zoi190718r37"><label>37</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Langner</surname><given-names>O</given-names></name>, <name name-style="western"><surname>Dotsch</surname><given-names>R</given-names></name>, <name name-style="western"><surname>Bijlstra</surname><given-names>G</given-names></name>, <name name-style="western"><surname>Wigboldus</surname><given-names>DHJ</given-names></name>, <name name-style="western"><surname>Hawk</surname><given-names>ST</given-names></name>, <name name-style="western"><surname>van Knippenberg</surname><given-names>A</given-names></name></person-group>
<article-title>Presentation and validation of the Radboud Faces Database</article-title>. <source>Cogn Emotion</source>. <year>2010</year>;<volume>24</volume>(<issue>8</issue>):<fpage>1377</fpage>-<lpage>1388</lpage>. doi:<pub-id pub-id-type="doi">10.1080/02699930903485076</pub-id></mixed-citation></ref><ref id="zoi190718r38"><label>38</label><mixed-citation publication-type="book"><person-group><name name-style="western"><surname>Hislop</surname><given-names>HJ</given-names></name>, <name name-style="western"><surname>Avers</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Brown</surname><given-names>M</given-names></name></person-group>
<source>Daniels and Worthingham&#x02019;s Muscle Testing: Techniques of Manual Examination and Performance Testing</source>. <edition>9th ed</edition>
<publisher-loc>St. Louis, MO</publisher-loc>: <publisher-name>Elsevier Saunders</publisher-name>; <year>2014</year>.</mixed-citation></ref><ref id="zoi190718r39"><label>39</label><mixed-citation publication-type="web"><person-group><name name-style="western"><surname>van Boxtel</surname><given-names>A</given-names></name></person-group> Facial EMG as a tool for inferring affective states. <ext-link ext-link-type="uri" xlink:href="https://www.measuringbehavior.org/files/ProceedingsPDF(website)/Boxtel_Symposium6.4.pdf">https://www.measuringbehavior.org/files/ProceedingsPDF(website)/Boxtel_Symposium6.4.pdf</ext-link>. Published <year>2010</year>. Accessed November 26, 2019.</mixed-citation></ref><ref id="zoi190718r40"><label>40</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>De Letter</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Vanhoutte</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Aerts</surname><given-names>A</given-names></name>, <etal/></person-group>
<article-title>Facial nerve regeneration after facial allotransplantation: a longitudinal clinical and electromyographic follow-up of lip movements during speech</article-title>. <source>J Plast Reconstr Aesthet Surg</source>. <year>2017</year>;<volume>70</volume>(<issue>6</issue>):<fpage>729</fpage>-<lpage>733</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.bjps.2017.02.025</pub-id><pub-id pub-id-type="pmid">28351610</pub-id></mixed-citation></ref><ref id="zoi190718r41"><label>41</label><mixed-citation publication-type="web"><person-group><name name-style="western"><surname>D&#x02019;Arcey</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Johnson</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Ennis</surname><given-names>M</given-names></name></person-group> Assessing the validity of FaceReader using facial electromyography. <ext-link ext-link-type="uri" xlink:href="http://www.darcey.us/pdf/facereader.pdf">http://www.darcey.us/pdf/facereader.pdf</ext-link>. Published <year>2012</year>. November 26, 2019.</mixed-citation></ref><ref id="zoi190718r42"><label>42</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Martinez</surname><given-names>AM</given-names></name></person-group>
<article-title>Visual perception of facial expressions of emotion</article-title>. <source>Curr Opin Psychol</source>. <year>2017</year>;<volume>17</volume>:<fpage>27</fpage>-<lpage>33</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.copsyc.2017.06.009</pub-id><pub-id pub-id-type="pmid">28950969</pub-id></mixed-citation></ref><ref id="zoi190718r43"><label>43</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Top&#x000e7;u</surname><given-names>&#x000c7;</given-names></name>, <name name-style="western"><surname>Uysal</surname><given-names>H</given-names></name>, <name name-style="western"><surname>&#x000d6;zkan</surname><given-names>&#x000d6;</given-names></name>, <etal/></person-group>
<article-title>Recovery of facial expressions using functional electrical stimulation after full-face transplantation</article-title>. <source>J Neuroeng Rehabil</source>. <year>2018</year>;<volume>15</volume>(<issue>1</issue>):<fpage>15</fpage>. doi:<pub-id pub-id-type="doi">10.1186/s12984-018-0356-0</pub-id><pub-id pub-id-type="pmid">29510722</pub-id></mixed-citation></ref><ref id="zoi190718r44"><label>44</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Gordon</surname><given-names>CR</given-names></name>, <name name-style="western"><surname>Siemionow</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Coffman</surname><given-names>K</given-names></name>, <etal/></person-group>
<article-title>The Cleveland Clinic FACES Score: a preliminary assessment tool for identifying the optimal face transplant candidate</article-title>. <source>J Craniofac Surg</source>. <year>2009</year>;<volume>20</volume>(<issue>6</issue>):<fpage>1969</fpage>-<lpage>1974</lpage>. doi:<pub-id pub-id-type="doi">10.1097/SCS.0b013e3181bd2c86</pub-id><pub-id pub-id-type="pmid">19881387</pub-id></mixed-citation></ref><ref id="zoi190718r45"><label>45</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Chopra</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Susarla</surname><given-names>SM</given-names></name>, <name name-style="western"><surname>Goodrich</surname><given-names>D</given-names></name>, <etal/></person-group>
<article-title>Clinical application of the FACES score for face transplantation</article-title>. <source>J Craniofac Surg</source>. <year>2014</year>;<volume>25</volume>(<issue>1</issue>):<fpage>64</fpage>-<lpage>69</lpage>. doi:<pub-id pub-id-type="doi">10.1097/SCS.0b013e3182a2dda9</pub-id><pub-id pub-id-type="pmid">24240764</pub-id></mixed-citation></ref><ref id="zoi190718r46"><label>46</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Haug</surname><given-names>V</given-names></name>, <name name-style="western"><surname>Kollar</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Obed</surname><given-names>D</given-names></name>, <etal/></person-group>
<article-title>The evolving clinical presentation of acute rejection in facial transplantation</article-title>. <source>JAMA Facial Plast Surg</source>. <year>2019</year>;<volume>21</volume>(<issue>4</issue>):<fpage>278</fpage>-<lpage>285</lpage>. doi:<pub-id pub-id-type="doi">10.1001/jamafacial.2019.0076</pub-id><pub-id pub-id-type="pmid">30998810</pub-id></mixed-citation></ref><ref id="zoi190718r47"><label>47</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Kollar</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Shubin</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Borges</surname><given-names>TJ</given-names></name>, <etal/></person-group>
<article-title>Increased levels of circulating MMP3 correlate with severe rejection in face transplantation</article-title>. <source>Sci Rep</source>. <year>2018</year>;<volume>8</volume>(<issue>1</issue>):<fpage>14915</fpage>. doi:<pub-id pub-id-type="doi">10.1038/s41598-018-33272-7</pub-id><pub-id pub-id-type="pmid">30297859</pub-id></mixed-citation></ref><ref id="zoi190718r48"><label>48</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Rifkin</surname><given-names>WJ</given-names></name>, <name name-style="western"><surname>Manjunath</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Kimberly</surname><given-names>LL</given-names></name>, <etal/></person-group>
<article-title>Long-distance care of face transplant recipients in the United States</article-title>. <source>J Plast Reconstr Aesthet Surg</source>. <year>2018</year>;<volume>71</volume>(<issue>10</issue>):<fpage>1383</fpage>-<lpage>1391</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.bjps.2018.05.019</pub-id><pub-id pub-id-type="pmid">30244707</pub-id></mixed-citation></ref><ref id="zoi190718r49"><label>49</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Spokas</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Luterek</surname><given-names>JA</given-names></name>, <name name-style="western"><surname>Heimberg</surname><given-names>RG</given-names></name></person-group>
<article-title>Social anxiety and emotional suppression: the mediating role of beliefs</article-title>. <source>J Behav Ther Exp Psychiatry</source>. <year>2009</year>;<volume>40</volume>(<issue>2</issue>):<fpage>283</fpage>-<lpage>291</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.jbtep.2008.12.004</pub-id><pub-id pub-id-type="pmid">19135648</pub-id></mixed-citation></ref><ref id="zoi190718r50"><label>50</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Nakamura</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Toda</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Sakamaki</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Kashima</surname><given-names>K</given-names></name>, <name name-style="western"><surname>Takeda</surname><given-names>N</given-names></name></person-group>
<article-title>Biofeedback rehabilitation for prevention of synkinesis after facial palsy</article-title>. <source>Otolaryngol Head Neck Surg</source>. <year>2003</year>;<volume>128</volume>(<issue>4</issue>):<fpage>539</fpage>-<lpage>543</lpage>. doi:<pub-id pub-id-type="doi">10.1016/S0194-5998(02)23254-4</pub-id><pub-id pub-id-type="pmid">12707658</pub-id></mixed-citation></ref><ref id="zoi190718r51"><label>51</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Schmid</surname><given-names>A</given-names></name>, <name name-style="western"><surname>Hils</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Kramer-Zucker</surname><given-names>A</given-names></name>, <etal/></person-group>
<article-title>Telemedically supported case management of living-donor renal transplant recipients to optimize routine evidence-based aftercare: a single-center randomized controlled trial</article-title>. <source>Am J Transplant</source>. <year>2017</year>;<volume>17</volume>(<issue>6</issue>):<fpage>1594</fpage>-<lpage>1605</lpage>. doi:<pub-id pub-id-type="doi">10.1111/ajt.14138</pub-id><pub-id pub-id-type="pmid">27873477</pub-id></mixed-citation></ref><ref id="zoi190718r52"><label>52</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Elfenbein</surname><given-names>HA</given-names></name></person-group>
<article-title>Nonverbal dialects and accents in facial expressions of emotion</article-title>. <source>Emotion Rev</source>. <year>2013</year>;<volume>5</volume>(<issue>1</issue>):<fpage>90</fpage>-<lpage>96</lpage>. doi:<pub-id pub-id-type="doi">10.1177/1754073912451332</pub-id></mixed-citation></ref><ref id="zoi190718r53"><label>53</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Masuda</surname><given-names>T</given-names></name>, <name name-style="western"><surname>Ellsworth</surname><given-names>PC</given-names></name>, <name name-style="western"><surname>Mesquita</surname><given-names>B</given-names></name>, <name name-style="western"><surname>Leu</surname><given-names>J</given-names></name>, <name name-style="western"><surname>Tanida</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Van de Veerdonk</surname><given-names>E</given-names></name></person-group>
<article-title>Placing the face in context: cultural differences in the perception of facial emotion</article-title>. <source>J Pers Soc Psychol</source>. <year>2008</year>;<volume>94</volume>(<issue>3</issue>):<fpage>365</fpage>-<lpage>381</lpage>. doi:<pub-id pub-id-type="doi">10.1037/0022-3514.94.3.365</pub-id><pub-id pub-id-type="pmid">18284287</pub-id></mixed-citation></ref><ref id="zoi190718r54"><label>54</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Chen</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Jack</surname><given-names>RE</given-names></name></person-group>
<article-title>Discovering cultural differences (and similarities) in facial expressions of emotion</article-title>. <source>Curr Opin Psychol</source>. <year>2017</year>;<volume>17</volume>:<fpage>61</fpage>-<lpage>66</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.copsyc.2017.06.010</pub-id><pub-id pub-id-type="pmid">28950974</pub-id></mixed-citation></ref><ref id="zoi190718r55"><label>55</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Niedenthal</surname><given-names>PM</given-names></name>, <name name-style="western"><surname>Rychlowska</surname><given-names>M</given-names></name>, <name name-style="western"><surname>Wood</surname><given-names>A</given-names></name></person-group>
<article-title>Feelings and contexts: socioecological influences on the nonverbal expression of emotion</article-title>. <source>Curr Opin Psychol</source>. <year>2017</year>;<volume>17</volume>:<fpage>170</fpage>-<lpage>175</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.copsyc.2017.07.025</pub-id><pub-id pub-id-type="pmid">28950965</pub-id></mixed-citation></ref><ref id="zoi190718r56"><label>56</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Jack</surname><given-names>RE</given-names></name>, <name name-style="western"><surname>Sun</surname><given-names>W</given-names></name>, <name name-style="western"><surname>Delis</surname><given-names>I</given-names></name>, <name name-style="western"><surname>Garrod</surname><given-names>OG</given-names></name>, <name name-style="western"><surname>Schyns</surname><given-names>PG</given-names></name></person-group>
<article-title>Four not six: revealing culturally common facial expressions of emotion</article-title>. <source>J Exp Psychol Gen</source>. <year>2016</year>;<volume>145</volume>(<issue>6</issue>):<fpage>708</fpage>-<lpage>730</lpage>. doi:<pub-id pub-id-type="doi">10.1037/xge0000162</pub-id><pub-id pub-id-type="pmid">27077757</pub-id></mixed-citation></ref><ref id="zoi190718r57"><label>57</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Calvo</surname><given-names>MG</given-names></name>, <name name-style="western"><surname>Nummenmaa</surname><given-names>L</given-names></name></person-group>
<article-title>Perceptual and affective mechanisms in facial expression recognition: an integrative review</article-title>. <source>Cogn Emot</source>. <year>2016</year>;<volume>30</volume>(<issue>6</issue>):<fpage>1081</fpage>-<lpage>1106</lpage>. doi:<pub-id pub-id-type="doi">10.1080/02699931.2015.1049124</pub-id><pub-id pub-id-type="pmid">26212348</pub-id></mixed-citation></ref><ref id="zoi190718r58"><label>58</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Chanes</surname><given-names>L</given-names></name>, <name name-style="western"><surname>Wormwood</surname><given-names>JB</given-names></name>, <name name-style="western"><surname>Betz</surname><given-names>N</given-names></name>, <name name-style="western"><surname>Barrett</surname><given-names>LF</given-names></name></person-group>
<article-title>Facial expression predictions as drivers of social perception</article-title>. <source>J Pers Soc Psychol</source>. <year>2018</year>;<volume>114</volume>(<issue>3</issue>):<fpage>380</fpage>-<lpage>396</lpage>. doi:<pub-id pub-id-type="doi">10.1037/pspa0000108</pub-id><pub-id pub-id-type="pmid">29369657</pub-id></mixed-citation></ref><ref id="zoi190718r59"><label>59</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Kitayama</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Park</surname><given-names>J</given-names></name></person-group>
<article-title>Emotion and biological health: the socio-cultural moderation</article-title>. <source>Curr Opin Psychol</source>. <year>2017</year>;<volume>17</volume>:<fpage>99</fpage>-<lpage>105</lpage>. doi:<pub-id pub-id-type="doi">10.1016/j.copsyc.2017.06.016</pub-id><pub-id pub-id-type="pmid">28950982</pub-id></mixed-citation></ref><ref id="zoi190718r60"><label>60</label><mixed-citation publication-type="journal"><person-group><name name-style="western"><surname>Baudry</surname><given-names>A-S</given-names></name>, <name name-style="western"><surname>Grynberg</surname><given-names>D</given-names></name>, <name name-style="western"><surname>Dassonneville</surname><given-names>C</given-names></name>, <name name-style="western"><surname>Lelorain</surname><given-names>S</given-names></name>, <name name-style="western"><surname>Christophe</surname><given-names>V</given-names></name></person-group>
<article-title>Sub-dimensions of trait emotional intelligence and health: a critical and&#x000a0;systematic review of the literature</article-title>. <source>Scand J Psychol</source>. <year>2018</year>;<volume>59</volume>(<issue>2</issue>):<fpage>206</fpage>-<lpage>222</lpage>. doi:<pub-id pub-id-type="doi">10.1111/sjop.12424</pub-id><pub-id pub-id-type="pmid">29388210</pub-id></mixed-citation></ref></ref-list><notes notes-type="supplementary-material" id="note-ZOI190718-1"><supplementary-material content-type="local-data" id="note-ZOI190718-1-s"><label>Supplement.</label><caption><p><bold>eFigure 1. </bold>Emotional Expression in Healthy Controls</p><p><bold>eFigure 2. </bold>Comparison of Emotions</p><p><bold>eFigure 3. </bold>Individual Patient Trends of Longitudinal Evaluation of Happiness and Sadness After Face Transplantation</p><p><bold>eFigure 4. </bold>Longitudinal Evaluation of Emotions After Face Transplantation</p><p><bold>eFigure 5. </bold>Long-term Comparison of Happiness</p></caption><media xlink:href="jamanetwopen-3-e1919247-s001.pdf"><caption><p>Click here for additional data file.</p></caption></media></supplementary-material></notes></back></article>