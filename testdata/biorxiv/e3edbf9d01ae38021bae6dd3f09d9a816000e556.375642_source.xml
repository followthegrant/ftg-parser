<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/375642</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;375642v3</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;375642</article-id><article-id pub-id-type="other" hwp:sub-type="slug">375642</article-id><article-id pub-id-type="other" hwp:sub-type="tag">375642</article-id><article-version>1.3</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Neuroscience" hwp:journal="biorxiv"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">How exerting control over outcomes affects the neural coding of tasks and outcomes</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1"><label>*</label><bold>Corresponding author</bold> David Wisniewski, Department of Experimental Psychology, Ghent University, Henri Dunantlaan 2, 9000 Gent, Tel: +32 (0)9 2649428, Email: <email hwp:id="email-1">david.wisniewski@ugent.be</email></corresp><fn fn-type="conflict" hwp:id="fn-1"><p hwp:id="p-1">Conflict of interest: The authors declare not competing financial interests.</p></fn></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" corresp="yes" hwp:id="contrib-1"><name name-style="western" hwp:sortable="Wisniewski David"><surname>Wisniewski</surname><given-names>David</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref></contrib><contrib contrib-type="author" hwp:id="contrib-2"><name name-style="western" hwp:sortable="Forstmann Birte"><surname>Forstmann</surname><given-names>Birte</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref></contrib><contrib contrib-type="author" hwp:id="contrib-3"><name name-style="western" hwp:sortable="Brass Marcel"><surname>Brass</surname><given-names>Marcel</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">1</xref></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2"><label>1</label><institution hwp:id="institution-1">Department of Experimental Psychology, Ghent University</institution>, <country>Belgium</country></aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1"><label>2</label><institution hwp:id="institution-2">Integrative Model-Based Cognitive Neuroscience Research Unit, University of Amsterdam</institution>, <country>The Netherlands</country></aff></contrib-group><pub-date pub-type="epub-original" hwp:start="2018"><year>2018</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2018-07-24T08:09:24-07:00">
    <day>24</day><month>7</month><year>2018</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2018-08-01T10:33:09-07:00">
    <day>1</day><month>8</month><year>2018</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2018-07-24T08:15:54-07:00">
    <day>24</day><month>7</month><year>2018</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2018-08-01T10:39:37-07:00">
    <day>1</day><month>8</month><year>2018</year>
  </pub-date><elocation-id>375642</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2018-07-24"><day>24</day><month>7</month><year>2018</year></date>
<date date-type="rev-recd" hwp:start="2018-08-01"><day>01</day><month>8</month><year>2018</year></date>
<date date-type="accepted" hwp:start="2018-08-01"><day>01</day><month>8</month><year>2018</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2018</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/" hwp:id="license-1"><p hwp:id="p-2">This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by/4.0/</ext-link></p></license></permissions><self-uri xlink:href="375642.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2019/pdf/375642v3.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="375642.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2019/abstracts/375642v3/375642v3.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2019/fulltext/375642v3/375642v3.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-3">Humans make choices every day, which are often intended to lead to desirable outcomes. While we often have some degree of control over the outcomes of our actions, in many cases this control remains limited. Here, we investigate the effect of control over outcomes on the neural correlates of outcome valuation and implementation of behavior, as desired outcomes can only be reached if choices are implemented as intended. In a value-based decision-making task, reward outcomes were either contingent on trial-by-trial choices between two different tasks, or were unrelated to these choices. Using fMRI, multivariate pattern analysis, and model-based neuroscience methods, we identified reward representations in a large network including the striatum, dorso-medial prefrontal cortex (dmPFC) and parietal cortex. These representations were amplified when rewards were contingent on subjects’ choices. We further assessed the implementation of chosen tasks by identifying brain regions encoding tasks during a preparation or maintenance phase, and found them to be encoded in the dmPFC and parietal cortex. Importantly, outcome contingency did not affect neural coding of chosen tasks. This suggests that controlling choice outcomes selectively affects the neural coding of these outcomes, but has no effect on the means to reach them. Overall, our findings highlight the role of the dmPFC and parietal cortex in processing of value-related and task-related information, linking motivational and control-related processes in the brain. These findings inform current debates on the neural basis of motivational and cognitive control, as well as their interaction.</p><sec hwp:id="sec-1"><title hwp:id="title-2">Significance statement</title><p hwp:id="p-4">We all make hundreds of choices every day, and we want them to have positive consequences. Often, the link between a choice and its outcomes is fairly clear (healthy diet -&gt; lower risk of cardiovascular disease), but we do not always have a high degree of control over the outcomes of our choices (genetic risk factors -&gt; high risk despite a healthy diet). Control over outcomes is a key factor for decision-making, yet its neural correlates remain poorly understood. Here, subjects performed a value-based decision-making task, while we manipulated the degree of control over choice outcomes. We found that more control enhances the neural coding of choice outcomes, but had no effect on the implementation of the chosen behavior.</p></sec></abstract><counts><page-count count="53"/></counts><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-1">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta><ack hwp:id="ack-1"><title hwp:id="title-3">Acknowledgements</title><p hwp:id="p-5">We would like to thank Anita Tusche, Carlo Reverberi, and Ruth Krebs for valuable discussions on this project. This research was supported by the Research Foundation Flanders (FWO), the European Union’s Horizon 2020 research and innovation program under the Marie Skłodowska-Curie grant agreement No 665501, FWO grant FWO.OPR.2013.0136.01, an ERC StG grant and NWO Vidi grant.</p></ack></front><body><sec id="s1" hwp:id="sec-2"><title hwp:id="title-4">Introduction</title><p hwp:id="p-6">Making decisions is an integral part of our life. Most of these choices are value-based, i.e. they are made with expected outcomes in mind. Value-based choices are made in separate stages: we first evaluate all options, and then select the option with the highest subjective value (<xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">Domenech et al., 2018</xref>). After implementing the chosen behavior (<xref ref-type="bibr" rid="c60" hwp:id="xref-ref-60-1" hwp:rel-id="ref-60">Rubinstein et al., 2001</xref>), predicted and experienced outcomes are compared, and prediction errors are computed (<xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-1" hwp:rel-id="ref-49">Matsumoto et al., 2007</xref>; <xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">Daw et al., 2011</xref>; <xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">Collins et al., 2017</xref>). This dopamine-mediated learning signal (<xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-1" hwp:rel-id="ref-64">Schultz, 2016</xref>) indicates the need to update our internal models of action-outcome contingencies (<xref ref-type="bibr" rid="c53" hwp:id="xref-ref-53-1" hwp:rel-id="ref-53">O’Reilly et al., 2013</xref>), which then leads to an adaption of future behavior.</p><p hwp:id="p-7">This process is modulated by various properties of choice outcomes, e.g. their magnitude (<xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">Doya, 2008</xref>). However, one crucial aspect has received little attention in the past: to which degree we have direct control over the outcomes of our behavior. Clearly, whether or not we believe our choices to <italic toggle="yes">cause</italic> their outcomes affects decision-making considerably, yet previous work largely focused on direct control over behavior (<xref ref-type="bibr" rid="c68" hwp:id="xref-ref-68-1" hwp:rel-id="ref-68">Sperduti et al., 2011</xref>) and not its outcomes. Some previous research in non-human primates demonstrated that control over choice outcomes affects valuation processes in the brain. Choice-contingent rewards elicit different responses in the caudate (<xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">Izquierdo et al., 2004</xref>) and anterior cingulate cortex (<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">Chudasama et al., 2013</xref>), as compared to non-contingent rewards (see also <xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">Elliott et al., 2004</xref>). Importantly, in order to lead to any rewarding outcome, the selected behavior needs to be implemented as intended first. Arguably, having control over choice outcomes should affect the means to reach those outcomes. One might expect chosen behaviors to be shielded more strongly against interference if outcomes are contingent on them (<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">Dreisbach and Wenke, 2011</xref>), as not performing the behavior as intended is potentially costly. For non-contingent outcomes the need for shielding is lower, as e.g. executing the wrong behavior has no effect on outcomes (see <xref ref-type="bibr" rid="c83" hwp:id="xref-ref-83-1" hwp:rel-id="ref-83">Waskom et al., 2014</xref> for a similar argument, but <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">Botvinick and Cohen, 2014</xref>). Previous work demonstrated that implementation of chosen actions, which includes their maintenance and execution, is supported by a brain network including the frontopolar (<xref ref-type="bibr" rid="c67" hwp:id="xref-ref-67-1" hwp:rel-id="ref-67">Soon et al., 2013</xref>), lateral prefrontal and parietal cortex (<xref ref-type="bibr" rid="c89" hwp:id="xref-ref-89-1" hwp:rel-id="ref-89">Zhang et al., 2013</xref>; <xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-1" hwp:rel-id="ref-84">Wisniewski et al., 2016</xref>; <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-1" hwp:rel-id="ref-48">Loose et al., 2017</xref>). Some initial evidence suggests that rewarding correct performance of externally cued tasks indeed enhances their neural representations (<xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">Etzel et al., 2016</xref>), but this work did not address the issue of varying degrees of control over choice outcomes.</p><p hwp:id="p-8">Here, we report an experiment investigating the effects of control over choice outcomes on value-based decision making. We used a value-based decision-making task to assess the effects of reward contingency (choice-contingent vs. non-contingent rewards) on valuation and, more importantly, on choice implementation. For this purpose, we used a combination of multivariate pattern analysis (MVPA, <xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">Haynes, 2015</xref>) and model-based neuroscience methods (<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-1" hwp:rel-id="ref-27">Forstmann and Wagenmakers, 2015</xref>). We first hypothesized that reward contingency affects the neural coding of outcome values in humans, as it does in non-human primates (<xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-2" hwp:rel-id="ref-36">Izquierdo et al., 2004</xref>; <xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-2" hwp:rel-id="ref-13">Chudasama et al., 2013</xref>). We further assessed whether implementation of chosen behavior (i.e. coding of chosen tasks) is similarly affected by contingency. We hypothesized that the lateral prefrontal cortex, and especially the parietal cortex to play a key role in the implementation of chosen behavior. The parietal cortex represents chosen tasks and actions (<xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-2" hwp:rel-id="ref-84">Wisniewski et al., 2016</xref>; <xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-2" hwp:rel-id="ref-18">Domenech et al., 2018</xref>), subjective stimulus and action values (<xref ref-type="bibr" rid="c70" hwp:id="xref-ref-70-1" hwp:rel-id="ref-70">Sugrue, 2004</xref>; <xref ref-type="bibr" rid="c39" hwp:id="xref-ref-39-1" hwp:rel-id="ref-39">Kahnt et al., 2014</xref>), as well as associations between choice options and their outcomes (<xref ref-type="bibr" rid="c85" hwp:id="xref-ref-85-1" hwp:rel-id="ref-85">Wisniewski et al., 2015a</xref>). Using MVPA, we tested whether task representations in these brain regions were enhanced when rewards were choice-contingent vs when they were not.</p></sec><sec id="s2" hwp:id="sec-3"><title hwp:id="title-5">Materials and Methods</title><sec id="s2a" hwp:id="sec-4"><title hwp:id="title-6">Participants</title><p hwp:id="p-9">A total of 42 subjects participated in this experiment (20 males, 21 females, 1 other). The average age was 22.6 years (min = 18, max = 33 years), 41 subjects were right-handed, one was left-handed. All subjects had normal or corrected-to-normal vision and volunteered to participate. Subjects gave written informed consent and received between 45€ and 55€ for their participation. The experiment was approved by the local ethics committee. Seven subjects showed excessive head movement in the MR scanner (&gt;4mm) and were excluded. All reported analyses were thus performed on a sample of 35 subjects. Despite the fact that the multivariate analyses performed in this experiment (see below for details) show notoriously small effects (<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">Bhandari et al., 2018</xref>), we believe to have sufficient statistical power with the given sample size.</p></sec><sec id="s2b" hwp:id="sec-5"><title hwp:id="title-7">Experimental Design</title><p hwp:id="p-10">The experiment was programmed using PsychoPy (version 1.85.2, psychopy.org, RRID:SCR_006571, <xref ref-type="bibr" rid="c55" hwp:id="xref-ref-55-1" hwp:rel-id="ref-55">Peirce, 2007</xref>)). In each trial, subjects were free to choose between two different tasks, and could either earn a high or a low reward for correct performance. The paradigm is described in more detail below.</p><sec id="s2b1" hwp:id="sec-6"><title hwp:id="title-8">Trial structure</title><p hwp:id="p-11">Each trial started with the presentation of a fixation cross centrally on-screen for 300ms (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1 A</xref>). This was followed by the presentation of a choice cue, the word ‘CHOOSE’, for 600ms. This cue instructed subjects to freely choose one of the two tasks to perform in this trial. After a variable delay period (2000-6000ms, mean delay duration = 4000ms), the task screen was presented for a total of 3000ms. In this experiment, we used the same tasks as (<xref ref-type="bibr" rid="c86" hwp:id="xref-ref-86-1" hwp:rel-id="ref-86">Wisniewski et al., 2015b</xref>), in order to better compare current results to this previous experiment on value-based decision-making. The task screen consisted of a visual object presented centrally on screen (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Figure 1 B</xref>). This object was picked pseudo-randomly out of a pool of 9 different objects in 3 categories: musical instruments, furniture, means of transportation. Below, 4 colored squares were presented (magenta, yellow, cyan, gray), with the square positions being mapped onto 4 buttons, operated using the left and right index and middle fingers. Subjects were given the option to choose which of two stimulus-response-mappings to apply to the presented object. For instance, in task ‘X’, means of transportation were associated with the magenta, furniture with the yellow, and musical instruments with the cyan button. In task ‘Y’, means of transportation were associated with the cyan, furniture with the magenta, and musical instruments with the yellow button. Thus, depending on the chosen task and the presented object, one of the colored buttons was correct for each task, and subjects were instructed to react as quickly and accurately as possible. We inferred subjects’ choices from their responses. Note, that the grey button was never task-relevant and was merely included to balance left and right hand responses. Furthermore, the mapping of the colored buttons on screen was pseudo-randomized in each trial, preventing subjects from preparing a specific motor response before the onset of the task screen. The specific stimulus-response-mappings called <italic toggle="yes">task X</italic> and <italic toggle="yes">task Y</italic> were counter-balanced across subjects. Subsequently to the task-screen presentation, subjects were given trial-by-trial reward feedback, by presenting either an image of a 1€ coin (high reward), a 10€cent coin (low reward), or a red circle (no reward). The feedback was presented for 400ms. After a variable inter-trial-interval (4000-14000ms, geometrically distributed, mean duration = 5860ms), the next trial began.</p><fig id="fig1" position="float" orientation="portrait" fig-type="figure" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2 xref-fig-1-3 xref-fig-1-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;375642v3/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1.</label><caption hwp:id="caption-1"><title hwp:id="title-9">Experimental paradigm.</title><p hwp:id="p-12"><bold>A.</bold> Trial structure. Each trial started with the cue ‘choose’ presented on screen. After a variable delay, the task screen was presented for a fixed duration. Reward feedback was presented subsequently after each trial. All trials were separated by variable inter trial intervals. <bold>B.</bold> Tasks. Subjects were instructed to identify the visual object presented on screen, and press a corresponding colored button. The object-category to color mappings are depicted here. Note that the specific mappings were counterbalanced across subjects. Which task was implemented in each trial was chosen freely by the subjects. <bold>C.</bold> Reward contingencies. In contingent (RC) trials, one task always yielded a high reward with a higher probability (80%) than the other task (20%). Which specific task was currently the high-reward task depended on the current task-reward-mapping, which changed according to a probabilistic reversal learning procedure (see Materials and Methods for more details). In non-contingent (NCR) trials, the chance to receive a high and low reward were equal, irrespective of the chosen task.</p></caption><graphic xlink:href="375642_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig></sec><sec id="s2b2" hwp:id="sec-7"><title hwp:id="title-10">Reward conditions</title><p hwp:id="p-13">Subjects were rewarded for correct performance on every trial. There were a total of two different reward conditions: contingent rewards (CR) and non-contingent rewards (NCR). In the NCR condition, the chosen reward in each trial was determined randomly. Irrespective of the chosen task, subjects had a 50% chance of receiving a high and a 50% chance of receiving a low reward (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-3" hwp:rel-id="F1">Figure 1 C</xref>). Subjects were instructed to choose tasks randomly in this condition, by imagining flipping a coin in their head in each trial (<xref ref-type="bibr" rid="c89" hwp:id="xref-ref-89-2" hwp:rel-id="ref-89">Zhang et al., 2013</xref>). In the CR condition, subjects performed a probabilistic reward reversal-learning task, similar to (<xref ref-type="bibr" rid="c30" hwp:id="xref-ref-30-1" hwp:rel-id="ref-30">Hampton and O’Doherty, 2007</xref>). In each trial, one task led to a high reward with an 80% and a low reward with a 20% probability (high-reward task, HR). These probabilities were reversed for the other task (low-reward task, LR), e.g., in a specific trial, <italic toggle="yes">task X</italic> might be the HR task, while <italic toggle="yes">task Y</italic> might be the LR task. Subjects were unaware which of the two tasks was the HR task, and needed to learn this from the reward-feedback provided after each trial. Once they chose the HR task on 3 consecutive trials, the mapping of rewards onto tasks reversed with a chance of 25% on each subsequent trial, e.g., whereas before <italic toggle="yes">task X</italic> was the HR and <italic toggle="yes">task Y</italic> the LR task, now <italic toggle="yes">task X</italic> was the LR and <italic toggle="yes">task Y</italic> the HR task. Again, subjects were unaware of this change in reward-contingencies, and needed to learn when such a switch occurred from the reward-feedback provided at the end of each trial.</p><p hwp:id="p-14">At the end of the experiment, 15 trials were chosen randomly, and whichever reward was earned in these trials was paid out as a bonus payment to the subjects. One half of these trials was chosen from CR trials, the other from NCR trials, which was communicated to the subjects in order to ensure that both conditions are equally salient. Thus, subjects were motivated to maximize the reward in CR trials, choosing the HR task as often as possible. Given that rewards were randomly chosen in NCR trials, they had no influence over the earned reward in this condition.</p><p hwp:id="p-15">This reward manipulation was chosen to manipulate the degree of control subjects had over the outcome of their choices. In CR trials subjects made choices that were directed at earning as much money as they could, by learning the changing reward contingencies and thus controlling reward outcomes. In NCR trials, subjects were unable to control outcomes through their choices, as there were no contingencies to learn. This allowed us to assess effects of control over outcomes on valuation and implementation processes. A second important reason for manipulating reward ‘relevance’ instead of reward presence (as in <xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-2" hwp:rel-id="ref-25">Etzel et al., 2016</xref>), was that this allowed us to assess specific reward effects on valuation and implementation processes. When contrasting choices in which subjects could earn a reward, with choices in which no reward is present (e.g. <xref ref-type="bibr" rid="c46" hwp:id="xref-ref-46-1" hwp:rel-id="ref-46">Libet et al., 1983</xref>; <xref ref-type="bibr" rid="c66" hwp:id="xref-ref-66-1" hwp:rel-id="ref-66">Soon et al., 2008</xref>), any difference between these conditions might arise from unspecific processes merely correlated with the presence of reward, like attentional or motor preparation (<xref ref-type="bibr" rid="c39" hwp:id="xref-ref-39-2" hwp:rel-id="ref-39">Kahnt et al., 2014</xref>). This is mainly because strong differences in expected outcomes immediately trigger these preparatory processes selectively in rewarded trials. In contrast, when rewards are always present, but only sometimes contingent on choices, reward expectations are much more similar across conditions. In fact, if a subject chose tasks randomly in all trials, the expected value would be identical in both reward conditions. Thus, only specific reward-related effects, like the fact that reward outcomes are a relevant factor for making choice only in CR trials, can explain potential differences between CR and NCR trials.</p></sec><sec id="s2b3" hwp:id="sec-8"><title hwp:id="title-11">Design</title><p hwp:id="p-16">Subjects performed 5 identical runs of this experiment, with 60 trials each. Each run contained 2 blocks with CR and 2 blocks with NCR trials. The length of each block was between 10 and 14 trials, and all trials were all separated by a long and variable ITI. CR and NCR blocks alternated and block order was counterbalanced across runs for each subject. Each block started with either ‘Contingent block now starting’ or ‘Non-contingent block now starting’ presented on screen for 5000ms. This mixed blocked and event-related design minimized cross-talk and interference between the reward conditions, and allowed us to estimate cleaner neural signals.</p><p hwp:id="p-17">Each run also contained 20% (n=12) catch trials. In these trials, subjects were externally cued which task to perform, by presenting the words ‘TASK X’ or ‘TASK Y’ instead of the ‘CHOOSE’ cue. The delay between cue and task execution was 1000ms in these trials. Catch trials were included to prevent subjects from choosing all tasks in a block at its beginning. For instance, in an NCR block, subjects could theoretically decide upon a whole sequence of tasks at the beginning of that block (e.g. X,X,X,Y,X,Y,Y,X,…), and then only implementing that fixed sequence in each trial. In order to encourage subjects to make a conscious choice in each individual trial, catch trials were included. These trials would frequently disrupt any planned sequence of task choices, making such a strategy less feasible. In order to increase the salience of these catch trials, subjects always received a high reward for correct performance. Catch trials were excluded from all analyses.</p><p hwp:id="p-18">Furthermore, we ensured that the reward condition was not correlated with any other design variable (target stimulus, delay duration, button mapping, ITI duration), in order to ensure that estimated neural signals were not confounded. Lastly, multivariate pattern analyses can be biased if signal estimates are not based on trials which are IID. Thus we ensured that conditions of the previous trial were not predictive of the current trial, to make each trial as independent of all other trials as possible.</p></sec><sec id="s2b4" hwp:id="sec-9"><title hwp:id="title-12">Training session</title><p hwp:id="p-19">Subjects were familiarized with the task in a separate training session outside the MR scanner, lasting about 1h10min. Subjects first learned to perform the two tasks, were then instructed about the reward conditions and lastly performed 3 runs of the full experiment (as described above). This training session was performed to minimize learning effects during the MR session, which can be detrimental to multivariate pattern analyses. Training sessions were scheduled between 1-5 days before the MR session. Just before the start of the MR session, subjects performed 10 trials of the task in the MR scanner, in order to familiarize themselves with the novel environment. These trials were not analyzed.</p></sec><sec id="s2b5" hwp:id="sec-10"><title hwp:id="title-13">Additional measures</title><p hwp:id="p-20">After completing the MR session, subjects filled in multiple questionnaires. They answered custom questions (e.g., How believable were the instructions? How different were the reward conditions? How difficult was making a choice between the two tasks? How difficult was performing the two tasks? Was one task more difficult than the other? At which point in time did you choose the task to perform in each trial?), and the following questionnaires: behavioral inhibition / activation scale (BISBAS, <xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">Carver and White, 1994</xref>), need for cognition (NFC, <xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">Cacioppo et al., 1984</xref>), sensitivity to reward / punishment (SPSRQS, <xref ref-type="bibr" rid="c76" hwp:id="xref-ref-76-1" hwp:rel-id="ref-76">Torrubia et al., 2001</xref>), and impulsivity (BIS11, <xref ref-type="bibr" rid="c54" hwp:id="xref-ref-54-1" hwp:rel-id="ref-54">Patton et al., 1995</xref>). We also acquired pupil dilation data while subjects performed the experiment in the MR scanner. Pupil dilation data is not the focus of the current paper, and is not reported.</p></sec><sec id="s2b6" hwp:id="sec-11"><title hwp:id="title-14">Image acquisition</title><p hwp:id="p-21">fMRI data was collected using a 3T Magnetom Trio MRI scanner system (Siemens Medical Systems, Erlangen, Germany), with a standard thirty-two-channel radio-frequency head coil. A 3D high-resolution anatomical image of the whole brain was acquired for co-registration and normalization of the functional images, using a T1-weighted MPRAGE sequence (TR = 2250 ms, TE = 4.18 ms, TI = 900 ms, acquisition matrix = 256 × 256, FOV = 256 mm, flip angle = 9°, voxel size = 1 × 1 × 1 mm). Furthermore, a field map was acquired for each participant, in order to correct for magnetic field inhomogeneities (TR = 400 ms, TE<sub>1</sub> = 5.19 ms, TE<sub>2</sub> = 7.65 ms, image matrix = 64 x 64, FOV = 192 mm, flip angle = 60°, slice thickness = 3 mm, voxel size = 3 x 3 x 3 mm, distance factor = 20%, 33 slices). Whole brain functional images were collected using a T2*-weighted EPI sequence (TR = 2000 ms, TE = 30 ms, image matrix = 64 × 64, FOV = 192 mm, flip angle = 78°, slice thickness = 3 mm, voxel size = 3 x 3 x 3 x mm, distance factor = 20%, 33 slices). Slices were orientated along the AC-PC line for each subject.</p></sec></sec><sec id="s2c" hwp:id="sec-12"><title hwp:id="title-15">Statistical Analysis</title><sec id="s2c1" hwp:id="sec-13"><title hwp:id="title-16">Data Analysis: Behavior</title><p hwp:id="p-22">All behavioral analyses were performed in R (RStudio version 1.1.383, RRID:SCR_000432, <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.rstudio.com" ext-link-type="uri" xlink:href="http://www.rstudio.com" hwp:id="ext-link-2">www.rstudio.com</ext-link>). We first characterized subjects’ performance by computing error rates and reaction times (RT). We tested for potential effects of reward condition on error rates using a Bayesian two-sided paired t-tests (using <italic toggle="yes">ttestBF</italic> from the BayesFactor package in R). Error trials, and trials with RTs &lt;300ms were removed from the data analysis. In order to identify potential effects of task and reward condition on RTs, we performed a Bayesian repeated measures ANOVA (using <italic toggle="yes">anovaBF</italic> from the BayesFactor package in R). This ANOVA included the factors task (X, Y) and reward (CR, NCR), and outputs Bayes Factors (BF) for all main effects and interaction terms. We did not expect tasks to strongly affect RTs, but did expect RTs to be lower in the CR condition, as compared to the NCR condition.</p><p hwp:id="p-23">The Bayesian hypothesis testing employed here allows quantifying the evidence in favor of the alternative hypothesis (BF10) <italic toggle="yes">and</italic> the null hypothesis (BF01), allowing us to conclude whether we find evidence for or against a hypothesized effect, or whether the current evidence remains inconclusive (<xref ref-type="bibr" rid="c58" hwp:id="xref-ref-58-1" hwp:rel-id="ref-58">Rouder, Speckman, Sun, Morey, and Iverson, 2009</xref>). Unfortunately, in classical frequentist hypothesis testing we are unable to provide evidence for the null hypothesis in a similar way (<xref ref-type="bibr" rid="c81" hwp:id="xref-ref-81-1" hwp:rel-id="ref-81">Wagenmakers, 2007</xref>). In line with previous research (e.g. <xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">Andraszewicz et al., 2015</xref>; <xref ref-type="bibr" rid="c50" hwp:id="xref-ref-50-1" hwp:rel-id="ref-50">Mertens and De Houwer, 2016</xref>), we considered BFs between 1 and 0.3 as anecdotal evidence, BFs between 0.3 and 0.1 as moderate evidence, and BFs smaller than 0.1 as strong evidence against a hypothesis. BFs between 1 and 3 were considered as anecdotal evidence, BFs between 3 and 10 as moderate evidence, and BFs larger than 10 as strong evidence for a hypothesis. Although our conclusions are based solely on the BFs, we also provide frequentists statistical test outcomes for the interested reader.</p><p hwp:id="p-24">Given that subjects were free to choose between the two tasks, some subjects might have shown biases to choosing one of the two tasks more often (although that would not have led to a higher overall reward, if anything biases should lower overall rewards). In order to quantify biases, we computed the proportion of trials in which subjects chose task X, separately for the CR and NCR conditions, and tested whether this value differed from 50% using a two-sided Bayesian t-test. The output BF was interpreted in the same way as in the previous analysis.</p><p hwp:id="p-25">Choices in CR trials were assessed two-fold. First, we quantified how well subjects performed the probabilistic reversal learning task. If subjects were reliably able to determine which of the two tasks was currently the HR task, they should have chosen that task more often than expected by chance (50%). Thus the proportion of HR task choices in CR trials is our main measure of how successful subjects were in performing the task. This measure was compared to chance level using a one-sided Bayesian t-test. Furthermore, we expected the proportion of HR choices to be higher in CR, than in NCR trials (where it should be 50%). This was tested using a paired one-sided Bayesian t-test.</p><p hwp:id="p-26">Second, we assessed whether subjects were able to learn and update reward contingencies in the reversal learning task. Reinforcement learning (RL) theory suggest that such learning can take place by comparing received rewards with expected rewards, which are computed from the reward history (<xref ref-type="bibr" rid="c71" hwp:id="xref-ref-71-1" hwp:rel-id="ref-71">Sutton and Barto, 1990</xref>; <xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-2" hwp:rel-id="ref-14">Collins et al., 2017</xref>). Discrepancies between actual and expected rewards (reward prediction errors, RPE) are thought to signal surprise in the brain and to guide adjustment of behavior (<xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">Daw and Doya, 2006</xref>), a process which relies on dopaminergic signals in the midbrain (<xref ref-type="bibr" rid="c56" hwp:id="xref-ref-56-1" hwp:rel-id="ref-56">Pessiglione et al., 2006</xref>; <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-2" hwp:rel-id="ref-64">Schultz, 2016</xref>). Here, we fitted a RL model to the choice data of each subject (separately for CR and NCR trials) in order to assess the learning process. Fitted RL models used simple delta-rule learning (as implemented in the <italic toggle="yes">rlfit</italic> package in Matlab, <ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/jmxpearson/rlfit" ext-link-type="uri" xlink:href="https://github.com/jmxpearson/rlfit" hwp:id="ext-link-3">https://github.com/jmxpearson/rlfit</ext-link>). For each task choice <italic toggle="yes">c</italic> the expected reward <italic toggle="yes">Q(c)</italic> was learned from the reward history by comparing the expected and observed rewards at trial <italic toggle="yes">t</italic>:
<disp-formula id="eqn1" hwp:id="disp-formula-1">
<alternatives hwp:id="alternatives-1"><graphic xlink:href="375642_ueqn1.gif" position="float" orientation="portrait" hwp:id="graphic-2"/></alternatives>
</disp-formula>
with <italic toggle="yes">δ<sub>t</sub></italic> = <italic toggle="yes">r<sub>t</sub></italic> – <italic toggle="yes">Q<sub>t</sub></italic>(<italic toggle="yes">c</italic>) being the RPE, and <italic toggle="yes">α</italic> being the learning rate. Choices were generated following a softmax choice function (as implemented in the rlfit package). The parameters were fitted over n = 10 iterations, with random starting values in each iteration. Learning rates were fitted with constraints [0, 1]. In order to assess the model fit, we also estimated a ‘null’ model for each subject. In this model, we again estimated expected outcomes and RPEs using the same algorithm described above, only fixing the learning rate to 0. The null model thus assumed that subjects do not learn changing reward contingencies, and we expected our RL model to outperform this null model. Model fit was assessed using the AIC and BIC (<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">Burnham and Anderson, 2004</xref>). We also assessed an alternative ‘hybrid’ model, in which learning rates are allowed to vary on a trial-by-trial basis, instead of being fixed for each subject (<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">Bai et al., 2014</xref>). It has been argued that such a model better captures behavior in probabilistic reversal learning tasks. In our experiment the simple delta-rule learning model outperformed the more complex hybrid model (as assessed using AIC and BIC), and results from the hybrid model were not assessed further.</p><p hwp:id="p-27">For each subject, the learning rate was extracted from the best-fitting model. We expected learning rates to be higher in CR than in NCR trials. In CR trials, the specific reward contingencies changed frequently, and thus subjects needed to update their contingency representations frequently as well. The learning rate in CR trials was also expected to correlate with successful task performance (% high reward choices), given that the reversal learning task can only be performed well if the represented reward contingencies change over time. In NCR trials, we expected learning rates to be low and uncorrelated with choice performance, because reward outcomes were randomly chosen and there were no contingencies to learn.</p><p hwp:id="p-28">Choices in NCR trials were assessed by testing whether subjects were able to choose tasks randomly in these trials. For this purpose, we computed the distribution of run lengths for each subject, i.e., the number of trials subjects chose to consecutively perform the same task. If subjects chose tasks randomly, this distribution can be expected to follow an exponential distribution (cf. <xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">Arrington and Logan, 2004</xref>; <xref ref-type="bibr" rid="c66" hwp:id="xref-ref-66-2" hwp:rel-id="ref-66">Soon et al., 2008</xref>). The average run length was computed for each subject, separately for CR and NCR trials, and compared to the expected run length under random choice behavior. We expected subjects to show longer runs in CR than in NCR trials, given that the probabilistic reward reversal learning task encourages subjects to perform the same task repeatedly. This was again tested using a one-sided Bayesian t-test.</p></sec><sec id="s2c2" hwp:id="sec-14"><title hwp:id="title-17">Data Analysis: fMRI</title><p hwp:id="p-29">fMRI data analysis was performed using Matlab (version R2014b 8.4.0, RRID:SCR_001622, The MathWorks) and SPM12 (RRID:SCR_007037, <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.fil.ion.ucl.ac.uk/spm/software/spm12/" ext-link-type="uri" xlink:href="http://www.fil.ion.ucl.ac.uk/spm/software/spm12/" hwp:id="ext-link-4">www.fil.ion.ucl.ac.uk/spm/software/spm12/</ext-link>). Raw data was imported according to BIDS standards (RRID:SCR_016124, <ext-link l:rel="related" l:ref-type="uri" l:ref="http://bids.neuroimaging.io/" ext-link-type="uri" xlink:href="http://bids.neuroimaging.io/" hwp:id="ext-link-5">http://bids.neuroimaging.io/</ext-link>). In order to assess which brain regions contained information about reward outcomes and task choices, raw data was unwarped, realigned and slice time corrected. It was then entered into a first level general linear model analysis (GLM, <xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">Friston et al., 1994</xref>), and subsequently into a multivariate pattern analysis (MVPA, <xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">Cox and Savoy, 2003</xref>; <xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-1" hwp:rel-id="ref-44">Kriegeskorte et al., 2006</xref>; <xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">Haxby, 2012</xref>; <xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-2" hwp:rel-id="ref-32">Haynes, 2015</xref>). In order to assess which brain regions represented reward-learning signals, raw data was unwarped, realigned, slice time corrected, normalized, and smoothed. It was then entered into a GLM, adding reward prediction errors as a regressor. Results were analyzed using a mass-univariate approach. Full details of the analyses can be found below.</p><sec id="s2c2a" hwp:id="sec-15"><title hwp:id="title-18">Neural processing of reward</title><sec id="s2c2a1" hwp:id="sec-16"><title hwp:id="title-19">Multivariate decoding of reward outcomes</title><p hwp:id="p-30">In a first step, we assessed whether we can replicate previous findings demonstrating contingency effects on reward processing (<xref ref-type="bibr" rid="c77" hwp:id="xref-ref-77-1" hwp:rel-id="ref-77">Tricomi et al., 2004</xref>). For this purpose, we estimated a GLM for each subject. For each of the 5 runs we added regressors for each combination of reward value (high vs low) and contingency (CR vs NCR). All regressors were locked to the feedback onset, the duration was set to 0. Regressors were convolved with a canonical haemodynamic response function (as implemented in SPM12). Estimated movement parameters were added as regressors of non-interest to this and all other GLMs reported here.</p><sec id="s2c2a1a" hwp:id="sec-17"><title hwp:id="title-20">Baseline decoding</title><p hwp:id="p-31">In a next step, we performed a decoding analysis on the parameter estimates of the GLM. A support-vector classifier (SVC, see <xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-2" hwp:rel-id="ref-15">Cox and Savoy, 2003</xref>; <xref ref-type="bibr" rid="c51" hwp:id="xref-ref-51-1" hwp:rel-id="ref-51">Mitchell et al., 2004</xref>; <xref ref-type="bibr" rid="c40" hwp:id="xref-ref-40-1" hwp:rel-id="ref-40">Kamitani and Tong, 2005</xref>), as implemented in <italic toggle="yes">The Decoding Toolbox</italic> (<xref ref-type="bibr" rid="c34" hwp:id="xref-ref-34-1" hwp:rel-id="ref-34">Hebart et al., 2014</xref>), was used using a fixed regularization parameter (C = 1). We performed searchlight decoding (<xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-2" hwp:rel-id="ref-44">Kriegeskorte et al., 2006</xref>; <xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">Haynes et al., 2007</xref>), which looks for information in local spatial patterns in the brain and makes no a prior assumptions about informative brain regions. A sphere with a radius of 3 voxels was defined around each measured voxel, and parameter estimates for high rewards (both in CR and NCR trials), and for low rewards (again, both in CR and NCR trials) were extracted within that sphere, separately in each run. 4 out of 5 runs were used to train the SVC to distinguish the neural patterns of high and low rewards. Classifier performance was then tested on the remaining, independent run. This procedure was repeated until each run was left out once, resulting in a 5-fold cross-validation and countering potential problems with overfitting. Mean prediction accuracy was calculated across all folds and written into the center voxel of the sphere. This was repeated for each measured voxel in the brain, resulting in a 3D accuracy map. These maps were computed for each subject, normalized to a standard space (Montreal Neurological Institute template as implemented in SPM12), and smoothed (Gaussian kernel, FWHM = 6mm) in order to account for potential differences in information localization across subjects. Group analyses were performed using a random effects model on the accuracy maps, using voxel-by-voxel t-tests against chance level (50%). The chance level was subtracted from all reported accuracy values. A statistical threshold of p&lt;0.0001 (uncorrected) at the voxel level, and p&lt;0.05 (family-wise error corrected) at the cluster level was applied to all analyses. This threshold is sufficient to rule out inflated false-positive rates in fMRI analyses (<xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">Eklund et al., 2016</xref>). Any regions surpassing this threshold were used as masks for the following decoding analyses (an approach previously used by (<xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-2" hwp:rel-id="ref-48">Loose et al., 2017</xref>). Given that we are mainly interested in <italic toggle="yes">differences</italic> between the baseline and other analyses, this comparison does not constitute a case of double dipping. Please also note that this analysis is sensitive to differences in outcome value, but might possibly also identify brain regions related to unspecific preparatory (e.g., attentional) processes. Although preparatory processes should be identical in CR and NCR trials, due to the fact that the same high and low rewards were given in both conditions, we cannot fully exclude such effects either if subjects were generally more motivated to perform CR than NCR trials. The underlying cause of any observed effects remain differences in reward outcomes however.</p></sec><sec id="s2c2a1b" hwp:id="sec-18"><title hwp:id="title-21">Differences in reward outcome coding</title><p hwp:id="p-32">Although the baseline decoding analysis should have the maximum power to detect any outcome-related brain regions, results do not allow us to conclude whether outcome processing differed between CR and NCR trials. For this purpose, we repeated the decoding analysis, now only using CR trials, and only NCR trials, respectively. If contingent rewards indeed enhance encoding of reward outcomes in the brain, we should see higher accuracies in the CR than in the NCR decoding analysis. Please note, that we only used half the number of trials as before, thus considerably reducing the signal-to-noise ratio in these analyses. We thus expected lower statistical power and smaller effects.</p></sec><sec id="s2c2a1c" hwp:id="sec-19"><title hwp:id="title-22">Similarities in in reward outcome coding</title><p hwp:id="p-33">Previous work demonstrated that not all brain regions show a contingency-related modulation of value signals (<xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-2" hwp:rel-id="ref-24">Elliott et al., 2004</xref>), and we thus tested whether some brain regions encoded reward outcomes invariantly across the contingency conditions. We trained a classifier to discriminate between high and low reward outcomes in the CR condition, and tested its performance in the NCR condition, and vice versa. This resulted in two accuracy maps per subject, which were averaged and then entered into a group analysis just like in the previous analyses. Importantly, only brain regions where patterns do not differ across both contingency conditions will show above-chance accuracies in this analysis. This so-called cross classification analysis can be used to identify brain regions in which outcome representations are invariant with respect to the contingency manipulation employed here (see also <xref ref-type="bibr" rid="c41" hwp:id="xref-ref-41-1" hwp:rel-id="ref-41">Kaplan et al., 2015</xref>), thus providing positive evidence for contingency-invariant coding of reward outcomes.</p></sec></sec><sec id="s2c2a2" hwp:id="sec-20"><title hwp:id="title-23">Neural correlates of reward-learning signals</title><p hwp:id="p-34">While the previous analyses investigated the neural correlates of processing the hedonic value of reward outcomes, here, we directly assessed whether reward-learning signals are affected by reward contingency. Reward prediction errors (RPE) act as learning signals in our reversal learning task (<xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-2" hwp:rel-id="ref-49">Matsumoto et al., 2007</xref>; <xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-2" hwp:rel-id="ref-17">Daw et al., 2011</xref>). They indicate the need to update the internal model of the current task-reward associations (e.g. task X = high reward task). In order to identify brain regions encoding this important reward signal, we used a model-based fMRI approach (<xref ref-type="bibr" rid="c52" hwp:id="xref-ref-52-1" hwp:rel-id="ref-52">O’Doherty et al., 2007</xref>; <xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-2" hwp:rel-id="ref-27">Forstmann and Wagenmakers, 2015</xref>). In model-based fMRI, a computational model fitted to behavioral data is used to construct regressors, which are then used to estimate GLMs on fMRI data. This approach links brain and behavior in a mechanistic framework and has been used successfully in a number of different settings (for an overview see <xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-3" hwp:rel-id="ref-27">Forstmann and Wagenmakers, 2015</xref>). We used the reinforcement learning models fitted to the behavioral data, and computed trial-by-trial RPEs from the best fitting model of each subject. We then estimated two separate GLMs, one for CR trials and one for NCR trials, on normalized and smoothed raw data. For each of the 5 runs, we added one regressor (duration = 0) locked to the onset of the feedback screen of each trial. Prediction errors should be strongest at this point in time. We added the trial-by-trial RPEs as a parametric modulator, allowing us to identify brain regions correlating with RPE signals. As before, regressors were convolved with a canonical haemodynamic response function. For each subject, a t-contrast map was computed to identify regions reflecting RPEs. These maps were then entered into a group level random effects analysis (within-subjects ANOVA with the factor contingency (CR, NCR)) in order to identify brain regions where prediction errors were modulated by reward contingency. Results were thresholded at p &lt; 0.001 (uncorrected) at the voxel level, p &lt;0.05 (FWE corrected) at the cluster level.</p></sec></sec><sec id="s2c2b" hwp:id="sec-21"><title hwp:id="title-24">Multivariate decoding of tasks</title><p hwp:id="p-35">All analyses described above aimed at assessing effects of reward contingency on reward processing. Now, we turn to also test whether any such potential effects could be demonstrated on the implementation of chosen behavior in the brain. For this purpose, we assessed which brain regions encoded the chosen tasks. Two GLMs were estimated for each subject, one modelling task-related brain activity at the time of decision-making, and one modelling activity during a subsequent maintenance phase. It has been shown that formation and maintenance of intentions rely on partly dissociable brain networks (<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">Bunge et al., 2003</xref>; <xref ref-type="bibr" rid="c29" hwp:id="xref-ref-29-1" hwp:rel-id="ref-29">Gilbert, 2011</xref>), and our design allowed us to estimate independent signals related to both epochs as they were separated by a variable inter-trial-interval.</p><p hwp:id="p-36">In the first GLM (GLM<sub>maintenance</sub>), for each of the 5 runs we added regressors for each combination of chosen task (task X, task Y) and reward contingency (CR, NCR). All 4 regressors were locked to the cue onset, the duration was set to cover the whole delay period. Please note that due to the jittered delay period duration, the modelled signals were dissociated from the task execution and feedback presentation. These boxcar regressors were then convolved with a canonical haemodynamic response function. This model is highly similar to the model used in (<xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-3" hwp:rel-id="ref-84">Wisniewski et al., 2016</xref>), where subjects were also free to choose one of two different tasks in each trial, making current results highly comparable to this previous study. In sum, this model estimated task-specific brain activity during intention maintenance, i.e. while subjects had to represent their intention to perform a specific chosen task, without yet being able to prepare a specific motor response. A second GLM was estimated (GLM<sub>decisiontime</sub>), in order to extract task-specific brain activity at the time subjects made their choice which of the two tasks to perform. Note that although the cue suggested that subjects should make a task choice at that point in time, there is no strong way of controlling the exact point in time at which choices were made. In fact, choices could have been made earlier than the presentation of the choice cue. It has been shown before that under free choice conditions, subjects choose a task as soon as all necessary information to make a choice is available (<xref ref-type="bibr" rid="c30" hwp:id="xref-ref-30-2" hwp:rel-id="ref-30">Hampton and O’Doherty, 2007</xref>; <xref ref-type="bibr" rid="c86" hwp:id="xref-ref-86-2" hwp:rel-id="ref-86">Wisniewski et al., 2015b</xref>). In this experiment, this time point is the feedback presentation of the previous trial. At this point, subjects can judge whether they e.g. chose the HR or LR task and determine which of the two tasks to perform in the next trial. We used this approach successfully in a previous experiment (<xref ref-type="bibr" rid="c86" hwp:id="xref-ref-86-3" hwp:rel-id="ref-86">Wisniewski et al., 2015b</xref>), again making current results highly comparable with these previous findings. All further task decoding analyses were performed on both GLMs.</p><sec id="s2c2b1" hwp:id="sec-22"><title hwp:id="title-25">Baseline decoding</title><p hwp:id="p-37">The task decoding analyses followed the same logic as the reward outcome analyses described above. We first performed a searchlight decoding analysis (radius = 3 voxels, C = 1), contrasting parameter estimates for tasks X and Y in all trials (CR and NCR combined). This analysis has the maximum power to detect any brain regions containing task information, which can be notoriously difficult (<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-2" hwp:rel-id="ref-5">Bhandari et al., 2018</xref>). Resulting accuracy maps were normalized, smoothed (6mm FWHM), and entered into a random effects group analysis (t-test vs chance level, 50%). Results were thresholded at p&lt;0.001 (uncorrected) at the voxel level, and p&lt;0.05 (family-wise error corrected) at the cluster level. Again, regions surpassing this threshold were used to define functional regions-of-interest for the following decoding analyses (see <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-3" hwp:rel-id="ref-48">Loose et al., 2017</xref>).</p></sec><sec id="s2c2b2" hwp:id="sec-23"><title hwp:id="title-26">Differences in task coding</title><p hwp:id="p-38">In order to assess whether task coding is modulated by reward contingency, we repeated the decoding analysis separately for CR and NCR trials. If contingent rewards indeed increase task shielding in the brain, we should see higher accuracies in the CR than in the NCR decoding analysis. This effect should be especially pronounced if both tasks are similar and easily confused, which is the case in our experiment. Please note, that we again only used half the number of trials as before, reducing the signal-to-noise ratio in these analyses. We thus expected lower statistical power and smaller effects.</p></sec><sec id="s2c2b3" hwp:id="sec-24"><title hwp:id="title-27">Similarities in task coding</title><p hwp:id="p-39">Some previous work suggests that tasks are encoded in a context-invariant format in the brain (<xref ref-type="bibr" rid="c89" hwp:id="xref-ref-89-3" hwp:rel-id="ref-89">Zhang et al., 2013</xref>; <xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-4" hwp:rel-id="ref-84">Wisniewski et al., 2016</xref>), and we directly tested whether this was also true in this experiment. Using a cross-classification (xclass) approach, we trained a classifier on CR trials and then tested it on NCR trials (and vice versa). And brain regions showing above chance decoding accuracies in this analysis provides positive evidence of task coding that is invariant with respect to contingent vs non-contingent reward outcomes.</p></sec><sec id="s2c2b4" hwp:id="sec-25"><title hwp:id="title-28">Region of interest analyses</title><p hwp:id="p-40">We also assessed task information in a number of a priori defined regions of interest (ROI). First, we attempted to replicate results from one of our previous experiments (Wisniewski et al. 2015). There, the dmPFC has been found to encode task choices at the time of decision-making. We extracted this functional ROI, and tested whether we could replicate the finding in this independent and larger sample. Although the overall design differed considerably (e.g. 3 vs 2 tasks, changing reward outcomes vs changing task difficulty), both studies used the same object-categorization task. Second, two previous experiments found task information to be maintained in the fronto-parietal cortex in a context invariant fashion (Loose et al. <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-4" hwp:rel-id="ref-48">2017</xref>; Wisniewski et al. <xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-5" hwp:rel-id="ref-84">2016</xref>). In one paper, task coding was invariant with respect to freely chosen vs. externally cued tasks (Wisniewski et al. <xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-6" hwp:rel-id="ref-84">2016</xref>), while in the other paper, task coding was invariant with respect to high vs. low control demands (Loose et al. <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-5" hwp:rel-id="ref-48">2017</xref>). If we were to show that the regions identified in these two experiments also encode tasks invariantly across reward contingency conditions, that would provide additional evidence for general, context invariant task coding in the fronto-parietal cortex. We thus extracted functional ROIs from both papers (Wisniewski et al. <xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-7" hwp:rel-id="ref-84">2016</xref>: left parietal cortex, left PFC, Brodman area 8; Loose et al. <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-6" hwp:rel-id="ref-48">2017</xref>: left parietal cortex, left PFC), and tested this hypothesis in this independent data-set. For all ROIs defined, we extracted accuracy values for all voxels within the ROI, which were then averaged. One-sided Bayesian t-tests across subjects were performed to assess whether they were above chance.</p></sec><sec id="s2c2b5" hwp:id="sec-26"><title hwp:id="title-29">Control analyses</title><p hwp:id="p-41">In order to further corroborate the reliability of our results, we performed a number of control analyses. It has been pointed out before, that RT effects might partly explain task decoding results (<xref ref-type="bibr" rid="c75" hwp:id="xref-ref-75-1" hwp:rel-id="ref-75">Todd et al., 2013</xref>), although others were unable to show any such effects (<xref ref-type="bibr" rid="c88" hwp:id="xref-ref-88-1" hwp:rel-id="ref-88">Woolgar et al., 2014</xref>; <xref ref-type="bibr" rid="c86" hwp:id="xref-ref-86-4" hwp:rel-id="ref-86">Wisniewski et al., 2015b</xref>). Given that we expected RTs to differ across reward conditions, we decided to conservatively control for RTs effects. First, we repeated the GLM estimation, only adding reaction times as an additional regressor of non-interest. We then repeated the main decoding analyses, and tested whether accuracy values differed significantly. If RTs indeed explain our task decoding results, we should see a reduction in decoding accuracies when RT effects were regressed out of the data.</p><p hwp:id="p-42">Furthermore, it is possible that some subjects exhibit excessive error rates or have a strong bias to choose one task more often than the other. High error rates might decrease the signal-to-noise ratio and thus affect observed results. Very strong choice biases might have a similar effect, in extreme cases subjects might have performed only one of the two tasks in a given run (although this was unlikely). In order to ensure that we had enough trials to estimate each regressor, we first excluded subjects with excessively high error-rates (more than 1.5*IQR above average), and then excluded subjects with strong choice biases (more than 1.5*IQR above average). We then tested whether each regressor in all remaining subjects could be estimated from at least 6 trials. If a regressor could only be estimated from fewer trials, that run was excluded from the analysis. Subjects in which more than 1 run was thusly excluded were altogether excluded from the analysis. These criteria were highly similar to the criterion used in (<xref ref-type="bibr" rid="c86" hwp:id="xref-ref-86-5" hwp:rel-id="ref-86">Wisniewski et al., 2015b</xref>), which proved an effective control. After excluding these subjects, we repeated the main analyses on the remaining subjects and tested whether they differed from the analysis including all subjects.</p><p hwp:id="p-43">Two further control analyses were performed to confirm the validity of the decoding procedure used. First, we performed a ROI decoding analysis on a brain region that is not related to task-performance in any way, expecting accuracies to be at chance level. We chose the primary auditory cortex for this purpose, defined using the WFU_pickatlas tool (<ext-link l:rel="related" l:ref-type="uri" l:ref="https://www.nitrc.org/frs/?group_id=46" ext-link-type="uri" xlink:href="https://www.nitrc.org/frs/?group_id=46" hwp:id="ext-link-6">https://www.nitrc.org/frs/?group_id=46</ext-link>, RRID: SCR_007378). Second, we tested whether our chance level was indeed 50%, or whether it was biased. For this purpose, we performed a permutation analysis (as implemented in the Decoding Toolbox). We repeated the baseline decoding analysis 1000 times for each subject, only randomly assigning the test labels in each of the 1000 permutations. A null distribution was calculated from these permutations separately for each subject, and the mean accuracy value of the null distribution served as an empirical estimate of the chance level. In order to test whether the estimated chance level deviated from 50%, we performed a two-sided Bayesian t-test. Additional exploratory analyses were performed to assess possible correlations between behavioral measures, questionnaires, and fMRI results (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2–1</xref>).</p><fig id="fig2" position="float" orientation="portrait" fig-type="figure" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3 xref-fig-2-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;375642v3/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2.</label><caption hwp:id="caption-2"><title hwp:id="title-30">Behavioral Results.</title><p hwp:id="p-44"><bold>A.</bold> Reaction Times (RT). The bar graph depicts the average reaction times for each combination of task and reward condition. Contingent (CR) trials are shown in black, non-contingent (NCR) trials are shown in grey. The violin plot depicts the RT distributions of the same data. <bold>B.</bold> Choice run length. This plot depicts the distribution of run lengths (the number of consecutive trials in the same task). Data from CR trials is shown in black, data from NCR trials is shown in grey. The expected distribution if choices were completely random is depicted in light grey. All error bars depict the SEM. <bold>C.</bold> Correlation of learning rate and success. Learning rates were extracted form a fitted RL model. Success was measured as % HR task choices. In CR trial, subjects who learned the changing reward contingencies quickly, were more successful. In NCR, no such correlation was observed. Each dot represents one subject, and linear functions were fitted to the data (lines). Further information on correlations between performance and additional questionnaire measures can be found in <xref ref-type="fig" rid="figS1" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Supplementary Figure 1</xref>.</p></caption><graphic xlink:href="375642_fig2" position="float" orientation="portrait" hwp:id="graphic-3"/></fig></sec></sec></sec></sec></sec><sec id="s3" hwp:id="sec-27"><title hwp:id="title-31">Results</title><sec id="s3a" hwp:id="sec-28"><title hwp:id="title-32">Behavioral results</title><p hwp:id="p-45">We first assessed the effects of tasks (X, Y) and reward condition (CR, NCR) on error rates and reaction times (RT). The average error rate across all subjects was 5.89% (SEM = 0.74%). Thus, subjects were able to perform the task accurately. There was no evidence for an effect of reward condition on error rates (Bayes Factor (BF10) = 0.88, t(34) = 1.96, p = 0.06). Error trials were removed from all further analyses. A repeated-measures ANOVA on the reaction times (RT) including the factors task and reward condition revealed no main effect of reward (BF01 = 31.95, F(1,34) = 0.38, p = 0.53, <xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2 A</xref>). This is likely due to the fact that subjects had a long time to prepare the execution of the task, which minimized potential contingency-related differences in RTs. There was a strong main effect of task however (BF10 &gt; 150, F(1,34) = 3.78, p = 0.05), with task X (RT<sub>X</sub> = 1415ms, SEM = 29ms) being faster than task Y (RT<sub>Y</sub> = 1467ms, SEM = 35ms). Please note, that this cannot be simply due to a difficulty difference between the two S-R-mappings called task X and task Y, as the specific S-R-mappings were counter-balanced across subjects. Given the long delay phase, subjects should have had enough time to prepare both tasks well, and we were somewhat surprised to see this RT difference. This results might reflect the encoding sequence in the learning phase. Subjects might have learned the S-R-mapping labelled X first, and then learned the S-R-mapping labelled Y second. If the second task is mainly encoded by how it differs from the first, this might lead to a RT difference (see also <xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-1" hwp:rel-id="ref-47">Lien et al., 2005</xref>). There was no evidence for an interaction between task and reward (BF10 = 0.26, F(1,34) = 6.63, p = 0.01).</p><p hwp:id="p-46">We then assessed whether subjects showed choice biases towards one of the two tasks, which might indicate stable preferences for specific tasks and might in turn affect fMRI analyses (see below). In order to quantify any potential choice biases, we computed the percentage of task X choices for both reward conditions separately. Subjects chose task X in 52.14% (SEM = 1.44%) of the CR trials, and 52.29% (1.72%) of the NCR trials. These values did not differ from 50% in the CR condition (BF10 = 0.48, t(34) = 1.47, p = 0.14), and NCR condition (BF10 = 0.40, t(34) = 1.32, p = 0.19). There was also no difference between the two reward conditions (BF01 = 5.45, t(34) = 0.14, p = 0.88), indicating that subjects did not exhibit strong choice biases in this experiment.</p><p hwp:id="p-47">Next, we measured subjects’ success in solving the reversal learning task presented in CR trials, by computing the percentage of high-reward (HR) task choices for each subject. If they were unable to learn which of the two tasks was the HR task, this value should be 50%. Higher values indicate increasing success in performing the reversal learning task. We hypothesized that subjects chose HR tasks more often in CR, as compared to NCR trials. Subjects chose the HR task in 56.40% (SEM = 1.15%) of the CR trials, which was above chance level (BF10 &gt;150, t(34) = 5.56, p &lt; 0.001). They chose the HR task in 49.47% (SEM = 0.84%) of the NCR trials, which did not differ from the chance level (BF01 = 4.59, t(34) = 0.62, p = 0.53). Importantly, we found strong evidence for our hypothesis that subjects chose HR tasks more often in the CR, than in the NCR condition (BF10 &gt; 150, t(34) = 5.44, p &lt; 0.001). These findings demonstrate that subjects indeed chose tasks strategically in the CR condition, in order to maximize their reward outcome.</p><p hwp:id="p-48">We then described the learning process in the CR trials in more details by fitting a reinforcement learning (RL) model (<xref ref-type="bibr" rid="c71" hwp:id="xref-ref-71-2" hwp:rel-id="ref-71">Sutton and Barto, 1990</xref>, see Materials and Methods for more details) to the choice data of each subject, and extracting the estimated learning rate (α). We expected subjects to show high learning rates in CR trials, reflecting the fact that subjects frequently needed to update which of the two tasks yielded higher reward outcomes. We compared fitted models in both CR and NCR trials to a null model, in which the learning rate was fixed to 0, assuming that subjects never learned about the reward contingencies in this experiment. Model fit was assessed using the AIC and BIC (<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-2" hwp:rel-id="ref-9">Burnham and Anderson, 2004</xref>). As expected, the RL model provided a better fit to the data than the null model in both CR trials (AIC<sub>RL_CR</sub>=129.97, AIC<sub>NULL_CR</sub>=159.54, BIC<sub>RL_CR</sub>=132.71, BIC<sub>NULL_CR</sub>=159.54), as well as NCR trials (AIC<sub>RL_NCR</sub>=158.70, AIC<sub>NULL_NCR</sub>=158.90, BIC<sub>RL_NCR</sub>=132.71, BIC<sub>NULL_NCR</sub>=158.90). Given that reward contingencies changed frequently in the CR trials, we expected learning rates to be higher in CR than in NCR trials. We found strong evidence in favor of this hypothesis (α<sub>CR</sub>: mean = .78, median = .96, sd = .33, min/max = &lt;.001/1; α<sub>NCR</sub>: mean = .36, median = .06, sd = .41, min/max = &lt;.001/1; BF10 &gt; 150, t(34) = 4.63, p &lt; 0.001). We then correlated estimated learning rates with successful task performance (% HR task choices), again using a Bayesian framework for correlation estimation (using <italic toggle="yes">bayes.cor.test</italic> form the BayesianFirstAid package in R). Specifically, we estimated the probability of the correlation being above 0 (p(r&gt;0)), and also estimated 95% credible intervals (95% CI), which indicates the range of values within which the correlation falls with a 95% probability. If this interval did not include 0, we interpreted the correlation as either positive or negative. The estimated learning rate in CR trials was indeed correlated with successful task performance (% HR task choices), r = .44 (95% CI = [.026, .74], p(r&gt;0) = .97, <xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Figure 2 C</xref>), linking our computational modelling more closely to behavior. As a control analysis, we also correlated learning rate in NCR with proportion of HR task choices in NCR trials. As expected, we found no correlation, r=-.12 (95% CI = [-.46, .21], p(r&gt;0) = .21). Classically estimated correlations confirmed these results, r = .56, p &lt; 0.001, and r = -.12, p = 0.46, respectively. These results indicate that successful subjects were able to learn about changing reward contingencies more quickly, and also demonstrate that subjects treated both reward conditions differently.</p><p hwp:id="p-49">Lastly, in NCR trials we expected subjects to choose tasks randomly, as their choices had no effect on reward outcomes (see Materials and Methods for more details). In order to test this, we computed the run length for each subject, i.e. the average number of consecutive trials in the same task (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-2" hwp:rel-id="ref-2">Arrington and Logan, 2004</xref>). The average run length was then compared to the expected theoretical distribution if choices were fully random (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-4" hwp:rel-id="F2">Figure 2 B</xref>). The average run length in NCR trials was 1.95 trials (SEM = 0.07 trials), which did not differ from the expected ‘random-choice’ run length (BF01 = 4.85, t(34) = 0.52, p = 0.60). Subjects in this experiment thus did not exhibit repetition bias, which has been reported previously for free-choice tasks (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-3" hwp:rel-id="ref-2">Arrington and Logan, 2004</xref>). The average run length in CR trials was 2.54 trials (SEM = 0.08 trials), which was longer than in NCR trials (BF10 &gt;150, t(34) = 5.91, p &lt; 0.001), demonstrating that subjects stayed longer in the same task. This is a viable strategy in the reversal-learning task they performed. Once they identified which was the HR task, repeatedly performing that task maximized reward outcomes.</p></sec><sec id="s3b" hwp:id="sec-29"><title hwp:id="title-33">Reward-related brain activity</title><sec id="s3b1" hwp:id="sec-30"><title hwp:id="title-34">Multivariate decoding of reward outcome values</title><p hwp:id="p-50">One of our main goals was to assess whether reward contingency affects valuation processes in the brain. In a first analysis, we aimed to extend previous findings demonstrating an effect of reward contingency on the processing of its hedonic value (<xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-3" hwp:rel-id="ref-24">Elliott et al., 2004</xref>). For this purpose, identified brain regions encoding outcome values (high vs low) at the time of feedback presentation. We found an extensive network to encode outcome values including subcortical brain regions, as well as large parts of the prefrontal and parietal cortex (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure 3 A</xref>). Please note that this contrast might not <italic toggle="yes">only</italic> capture specific reward value signals, it might also reflect effects caused by differences in reward outcomes, like attention or motor preparation. We explicitly assessed whether reaction times affected outcome coding (see <xref ref-type="bibr" rid="c75" hwp:id="xref-ref-75-2" hwp:rel-id="ref-75">Todd et al., 2013</xref>), and found no effect (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Figure 3-1</xref>). Subsequently, we assessed whether these outcome signals were modulated by reward contingency, hypothesizing that contingent rewards showed stronger decoding results than non-contingent rewards. For this purpose, we repeated the decoding analysis described above, now separately for CR and NCR trials, respectively. The two resulting accuracy maps were entered into a within-subjects ANOVA, and a contrast was computed identifying brain regions with higher accuracies in CR than in NCR trials. Using small-volume correction (p &lt; 0.001 uncorrected, p &lt; 0.05 FWE corrected), we assessed which of the brain regions identified in the <italic toggle="yes">baseline</italic> analysis also showed stronger value coding for contingent rewards. We found the striatum, bilateral lateral PFC, dACC, anterior medial PFC, and IPS to show stronger reward value coding for contingent rewards, as compared to non-contingent rewards. In a last step, we directly assessed whether there were brain regions that encoded reward values in a contingency-invariant fashion, using a cross-classification approach. Here, we trained a classifier to distinguish high from low rewards only on CR trials, and then tested its performance on NCR trials, and vice versa. This allowed us to identify brain regions in which outcome values are encoded invariantly across the two contingency conditions, i.e. where neural patterns do not differ across contingency conditions (<xref ref-type="bibr" rid="c41" hwp:id="xref-ref-41-2" hwp:rel-id="ref-41">Kaplan et al., 2015</xref>). We found the striatum, lateral and medial PFC, dACC, and IPS to encode rewards in a contingency invariant form. This pattern of results suggests that the neural code for different reward values did not change across contingency conditions, yet value signals were still stronger in CR than in NCR trials. This is compatible with an increased gain or amplification of value representations through contingency (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Figure 3 B</xref>), where representations do not change but become more separable in neural state space (see <xref ref-type="bibr" rid="c83" hwp:id="xref-ref-83-2" hwp:rel-id="ref-83">Waskom et al., 2014</xref> for a similar argument).</p><fig id="fig3" position="float" orientation="portrait" fig-type="figure" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3 xref-fig-3-4 xref-fig-3-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;375642v3/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3:</label><caption hwp:id="caption-3"><title hwp:id="title-35">Reward-related brain activity.</title><p hwp:id="p-51"><bold>A.</bold> Multivariate decoding of reward outcome value. Above: baseline decoding. Depicted are regions that encoded the value of reward outcomes (high vs. low). The regions identified were used as masks for the following analyses. Results are displayed at p &lt; 0.05 (FWE corrected). Middle: regions with a stronger coding of reward value in contingent (CR) than in non-contingent (NCR) trials. Below: regions encoding reward values in similar formats in both contingency conditions, as tested using a cross-classification (xclass) analysis. We also repeated this analysis, explicitly controlling for the effect of reaction times, and results can be found in <xref ref-type="fig" rid="figS2" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Supplementary Figure 2</xref>. <bold>B.</bold> Amplification vs change of format of neural coding. Most regions identified in A showed both stronger decoding in CR trials, and similar formats across both contingency conditions. This is compatible with an amplification or gain increase of neural codes. In the middle, a hypothetical example of a pattern decoding is depicted. High reward trials are depicted as blue, low reward trials as orange dots. The classifier fits a decision boundary to separate the two distributions. If this code changes between the two contingency conditions (left), decoding is still possible at similar accuracy levels as before, but a classifier trained on NCR trials will be unsuccessful in classifying CR trials. If this code is amplified in the CR condition however (right), the same classifier can will be successful in both conditions. Accuracies increase, as the two distributions become more separable. <bold>C.</bold> Brain regions correlating with reward prediction error signals (in both CR and NCR trials).</p></caption><graphic xlink:href="375642_fig3" position="float" orientation="portrait" hwp:id="graphic-4"/></fig></sec><sec id="s3b2" hwp:id="sec-31"><title hwp:id="title-36">Learning signals: Reward prediction errors</title><p hwp:id="p-52">In the previous analysis, we assessed which brain regions directly encoded different reward outcomes in individual trials. We now turn to identifying brain regions supporting reward-based learning processes across multiple trials. We used the fitted RL models (see above) to extract trial-by-trials reward prediction errors (RPEs), which signal the need to adapt one’s behavior (<xref ref-type="bibr" rid="c53" hwp:id="xref-ref-53-2" hwp:rel-id="ref-53">O’Reilly et al., 2013</xref>). Following a model-based neuroscience approach (<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-4" hwp:rel-id="ref-27">Forstmann and Wagenmakers, 2015</xref>), we identified brain regions in which activity correlated with RPEs. These learning signals should be strongest at the time of decision-making (in our case the reward feedback presentation, see Materials and Methods for more details), and we found the left parietal cortex and anterior medial PFC to correlate with RPEs in CR trials (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-4" hwp:rel-id="F3">Figure 3 C</xref>). In NCR trials, we found anterior cingulate and anterior medial prefrontal cortex to encode RPEs. We statistically assessed the difference between these two results, using a within-subjects ANOVA with the factor ‘model’ (2 levels). We found no significant differences (p &lt; 0.001 (uncorrected) at the voxel level, p &lt;0.05 (FWE corrected) at the cluster level), and thus decided to combine both conditions to increase statistical power. Running the same analysis over all trials (CR and NCR) again revealed the left parietal cortex (overlapping with the region identified in Analysis 1), ACC and anterior medial PFC, but also the precuneus. These regions thus signal discrepancies between expected and received rewards during feedback presentation, indicating the need to adapt behavior in the subsequent trial.</p><p hwp:id="p-53">These brain regions could either signal general surprise, as RPEs are the difference between expected and received rewards (<xref ref-type="bibr" rid="c53" hwp:id="xref-ref-53-3" hwp:rel-id="ref-53">O’Reilly et al., 2013</xref>). They could also signal the need to update an internal model of our environment. Our findings are more in line with the former option. Any region signaling the need to update the internal model of the environment should be specifically involved only in CR trials (where updating is required), and not in NCR trials (where updating is not needed). In order to test this, we identified subjects that only showed high learning rates in CR and low learning rates in NCR trials (n=19). For these subjects, prediction errors only signaled the need to update their internal model. Results showed that for this subset of subjects, only the anterior medial PFC correlated with RPEs (p &lt; 0.001 uncorrected at the voxel, and p &lt; 0.05 FWE corrected at the cluster level). This seems to suggest that the anterior medial PFC was involved in model updating, while the left parietal cortex and precuneus signaled general surprise. Given that the sample size was considerably smaller in this analysis, results should be interpreted with caution however.</p></sec></sec><sec id="s3c" hwp:id="sec-32"><title hwp:id="title-37">Multivariate decoding of tasks</title><sec id="s3c1" hwp:id="sec-33"><title hwp:id="title-38">Baseline decoding analysis</title><p hwp:id="p-54">The previous analysis demonstrated that reward contingency indeed affected the neural processing of the hedonic value of reward outcomes, and possibly also related learning signals. In the following analysis we assessed whether these effects propagated to the implementation of chosen behavior, i.e. the coding of chosen tasks as well. For this purpose, we first estimated a GLM modelling task-related neural activity during the maintenance of chosen tasks, from the onset of the ‘choose’ cue to the onset of the task execution screen. (see Materials and Methods for more details, and Haynes et al. (<xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-2" hwp:rel-id="ref-33">2007</xref>) for a similar approach). During this time, subjects needed to maintain their intention to perform one of the two tasks. We performed a searchlight decoding analysis contrasting task X and task Y, combining both CR and NCR trials in order to maximize the power to detect any brain regions containing task information (see <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-7" hwp:rel-id="ref-48">Loose et al., 2017</xref> for a similar approach). Please note that during this time subjects cannot prepare specific motor responses yet, but they can use this time to retrieve the current S-R-mapping. We found two brain regions to contain task information, the left posterior parietal cortex (mean accuracy = 4.61%, SEM = 0.65%), spanning over the midline into the right parietal cortex, and the right anterior middle frontal gyrus (aMFG, mean accuracy = 4.66%, SEM = 0.89%, see <xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Figure 4 A</xref>, <xref ref-type="table" rid="tbl1" hwp:id="xref-table-wrap-1-1" hwp:rel-id="T1">Table 1</xref>). Interestingly, the parietal cluster identified in this analysis partly overlapped with the parietal cluster found to encode reward prediction errors in the previous analysis, suggesting that the left parietal cortex is involved in both reward-learning and task processing.</p><fig id="fig4" position="float" orientation="portrait" fig-type="figure" hwp:id="F4" hwp:rev-id="xref-fig-4-1 xref-fig-4-2 xref-fig-4-3 xref-fig-4-4 xref-fig-4-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;375642v3/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4.</label><caption hwp:id="caption-4"><title hwp:id="title-39">Task coding.</title><p hwp:id="p-55"><bold>A.</bold> Task coding during maintenance. Results from the baseline decoding analysis are depicted above. Two clusters passed the significance threshold, one in the parietal cortex, and one in the right anterior MFG. These two clusters were then used as ROIs, and accuracies were extracted for the contingent (CR), non-contingent (NCR), and cross-classification (xclass) task decoding analyses. Results can be seen below. Above the boxplots, Bayes factors (BF10) of a t-test vs. chance level are shown. Please note, that we do not report BF10 for the baseline analysis, as this analysis was used to define the ROIs, and running additional statistical tests on this data would constitute double dipping. <bold>B.</bold> Task coding at the time of decision-making. Above the ROI in the right dmPFC used in this analysis from Wisniewski et al. (2015) is depicted. This study demonstrated that the right dmPFC encodes tasks at the time of decision-making. The box plot depicts results from our data in this ROI, for all four analyses performed (baseline, CR, NCR, xclass). We largely replicate these previous findings. The dissociation plot depicts a double dissociation between two ROIs (right dmPFC, as defined using data from Wisniewski et al., 2015, and the left parietal cortex, as defined using data from <xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-8" hwp:rel-id="ref-84">Wisniewski et al., 2016</xref>), and two time points in the trial (time of decision-making, maintenance). It can be seen that the dmPFC only encodes tasks at the time of decision-making, while the left parietal cortex only encodes tasks during the maintenance phase. All error bars represent SEM. <bold>C.</bold> Overlap with previous results. Results from the current study (red) are overlain on previous findings from Wisniewski et al. <xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-9" hwp:rel-id="ref-84">2016</xref> (blue), and Loose et al. <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-8" hwp:rel-id="ref-48">2017</xref> (green). All results are based on task decoding analyses (searchlight decoding, radius = 3 voxels, C = 1, chance level = 50%), albeit with different specific tasks being contrasted in each study. Despite this fact, all three studies find task information around the intraparietal sulcus. Findings in the PFC are less consistent. We further assessed task information encoded throughout the multiple-demand network, results can be found in <xref ref-type="fig" rid="figS3" hwp:id="xref-fig-7-1" hwp:rel-id="F7">Supplementary Figure 3</xref>.</p></caption><graphic xlink:href="375642_fig4" position="float" orientation="portrait" hwp:id="graphic-5"/></fig><table-wrap id="tbl1" orientation="portrait" position="float" hwp:id="T1" hwp:rev-id="xref-table-wrap-1-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;375642v3/TBL1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">tbl1</object-id><label>Table 1:</label><caption hwp:id="caption-5"><title hwp:id="title-40">Baseline task decoding</title></caption><graphic xlink:href="375642_tbl1" position="float" orientation="portrait" hwp:id="graphic-6"/></table-wrap></sec><sec id="s3c2" hwp:id="sec-34"><title hwp:id="title-41">Differences in task coding</title><p hwp:id="p-56">In a next step, we assessed whether tasks were encoded with a higher accuracy in CR, than in NCR trials, similar to what we found for reward outcomes. Previous research demonstrated higher decoding accuracies in rewarded, as compared to non-rewarded tasks (<xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-3" hwp:rel-id="ref-25">Etzel et al., 2016</xref>). We built functional ROIs from the two regions identified in the baseline analysis, and extracted the average accuracy values for the task decoding analyses performed on CR trials only, and NCR trials only. Please note that these two analyses use only half as many trials as the baseline analysis, and the signal-to-noise-ratio can be expected to be lower. We found no task information in the parietal cortex in these two analyses (CR: 1.29%, SEM = 0.91%, BF10 = 1.06, t(34) = 1.59, p = 0.06; NCR: 1.73%, SEM = 1.44%, BF10 = 0.64, t(34) = 1.23, p = 0.11), and found no evidence for stronger task coding in CR than in NCR trials (BF10 = 0.16, t(34) = 0.09, p = 0.53). A similar pattern of results was found in the right aMFG (CR: 1.79%, SEM = 1.37%, BF10 = 0.85, t(34) = 1.44, p = 0.07; NCR: 0.48%, SEM = 1.35%, BF10 = 0.22, t(34) = 0.25, p = 0.40; CR &gt; NCR: BF10 = 0.40, t(34) = 0.84, p = 0.20). Thus, we find no evidence for an effect of reward contingency on task representations, despite the fact that behavior clearly differed between the two reward conditions, and that contingency has been found to modulate the coding of reward outcomes. In order to assess whether the lack of evidence for differences in task coding might stem from a lack in statistical power, we performed an additional control analysis. We again performed two separate task decoding analysis, only using high reward and low reward trials (instead of CR and NCR trials), respectively. We then tested whether decoding accuracies differed between these two conditions. Importantly, this analysis has a similar statistical power, as the same number of trials is used. And indeed, we found task coding to differ between these two conditions even at the whole brain level (p &lt; 0.001 uncorrected at the voxel, and p &lt; 0.05 FWE corrected at the cluster level). Please note that this comparison might confound effects of reward value with attentional processes. Nevertheless, this shows that our analysis approach is able to identify differences in task coding in this dataset, although it fails to do so for our reward contingency manipulation.</p></sec><sec id="s3c3" hwp:id="sec-35"><title hwp:id="title-42">Similarities in task coding</title><p hwp:id="p-57">We also directly tested whether task representations were invariant across the two reward conditions, using a cross-classification approach. We trained a classifier to distinguish tasks in CR trials, and tested its performance in NCR trials, and vice versa. In this analysis, accuracies can only be above chance if task coding is invariant across both conditions. Results indicate than both the parietal cortex (4.03%, SEM = 0.76%, BF10 &gt; 150), as well as the right aMFG (3.71%, SEM = 1.16%, BF10 = 49.39) show this type of contingency-invariant task coding. We further tested whether accuracies in the cross-classification differed from the baseline accuracies, finding moderate evidence for an absence of any differences (parietal cortex BF01 = 4.34, t(34) = 0.71, p = 0.47, aMFG BF01 = 3.94, t(34) = 0.84, p = 0.40). These results thus show that the parietal cortex and aMFG encode tasks using a general, reward-contingency-invariant format.</p></sec><sec id="s3c4" hwp:id="sec-36"><title hwp:id="title-43">ROI analyses and replications</title><p hwp:id="p-58">We also tested for task information in several a-priori ROIs, taken from two previous experiments (Loose et al. <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-9" hwp:rel-id="ref-48">2017</xref>, Wisniewski et al. <xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-10" hwp:rel-id="ref-84">2016</xref>), which tested for effects of cognitive control, and free choice on task coding, respectively. Both previous studies found the left parietal cortex to be involved in context-invariant task coding, and we thus set out to replicate these previous results here. We extracted the ROIs reported in these two studies, and extracted decoding accuracies in each of these ROIs, for all 4 analyses performed here (baseline, CR, NCR, xclass). We were able to replicate Loose and colleagues’ left parietal results (baseline BF10 = 133.69, t(34) = 3.89, p &lt; 0.001; CR BF10 = 0.68, t(34) = 1.23, p = 0.10; NCR BF10 = 0.54, t(34) = 1.11, p = 0.13; xclass BF10 = 33.17, t(34) = 3.33, p = 0.001). Although somewhat weaker, we also replicated their right parietal results (baseline BF10 = 8.49, t(34) = 2.72, p = 0.004; CR BF10 = 0.77, t(34) = 1.37, p = 0.08; NCR BF10 = 0.14, t(34) = 0.28, p = 0.61; xclass BF10 = 8.10, t(34) = 2.70, p = 0.005). However, we were unable to detect task information in left PFC (baseline BF10 = 0.49, t(34) = 1.03, p = 0.15; CR BF10 = 0.21, t(34) = 0.23, p = 0.40; NCR BF10 = 0.44, t(34) = 0.93, p = 0.17; xclass BF10 = 0.29, t(34) = 0.54, p = 0.29), which is in line with the original paper, where PFC findings were also somewhat less robust. Additionally, we were able to replicate Wisniewski and colleagues’ left parietal finding (baseline BF10 = &gt;150, t(34) = 4.20, p &lt; 0.001; CR BF10 = 0.80, t(34) = 1.40, p = 0.08; NCR BF10 = 0.47, t(34) = 1.00, p = 0.16; xclass BF10 = 87.28, t(34) = 3.72, p &lt; 0.001), as well as left BA8 (baseline BF10 = 9.3, t(34) = 2.77, p = 0.004; CR BF10 = 0.39, t(34) = 0.83, p = 0.20; NCR BF10 = 0.36, t(34) = 0.76, p = 0.22; xclass BF10 = 3.09, t(34) = 2.22, p = 0.16), but not the left PFC (baseline BF10 = 0.59, t(34) = 1.17, p = 0.12; CR BF10 = 0.37, t(34) = 0.78, p = 0.21; NCR BF10 = 0.16, t(34) = 0.15, p = 0.56; xclass BF10 = 0.38, t(34) = 0.81, p = 0.21). Thus, three studies with similar overall designs but considerable differences in the specific tasks used consistently find invariant task coding in the parietal, but not in the prefrontal cortex.</p><p hwp:id="p-59">Furthermore, Wisniewski et al. 2015 found task information at the time of decision-making in the right dorso-medial PFC (<xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-2" hwp:rel-id="F4">Figure 4 B</xref>). In order to replicate this finding, we repeated all 4 task decoding analysis, only looking at the time of decision-making instead of intention maintenance (which was the reward feedback presentation in this experiment, see Materials and Methods for more details). The right dmPFC, as identified by Wisniewski and colleagues, was found to encode tasks also in the current study (baseline 3.76%, SEM = 1.07%, BF10 = 51.27, t(34) = 3.51, p &lt; 0.001, <xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-3" hwp:rel-id="F4">Figure 4 B</xref>). This was despite the fact that there were considerable differences in the overall experimental design of these two studies (e.g. 2 class vs. 3 class decoding, changing reward outcomes vs. changing task difficulty). We found anecdotal evidence for contingency-invariant task coding in this region (xclass 2.03%, SEM = 0.98%, BF10 = 2.35, t(34) = 2.07, p = 0.02), although the baseline and xclass analyses did not differ (BF10 = 1.64, t(34) = 1.63, p = 0.11). Interestingly, the dmPFC was also found to encode reward outcome values, with its outcome signal being amplified by our contingency manipulation (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-5" hwp:rel-id="F3">Figure 3 A</xref>). This region thus simultaneously encoded both reward outcomes and the choices informed by these outcomes, highlighting its role in linking value to intention processing in the brain. Additionally, we found a double dissociation in task coding between the right dmPFC and left parietal cortex (<xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-4" hwp:rel-id="F4">Figure 4B</xref>), with the former only encoding tasks at the time of decision-making, and the latter only encoding tasks during intention maintenance. Please note that due a jittered inter-trial-interval, the decision-time and intention maintenance could be investigated independently. This dissociation was assessed statistically by performing an ANOVA on the accuracy values, using the factors ‘time in trial’ (time of decision vs intention maintenance) and ‘ROI’ (right dmPFC vs left parietal cortex). We found moderate evidence for a time x ROI interaction (BF10 = 5.39, F(1,34) = 10.49, p = 0.04). Furthermore, the right dmPFC only encoded tasks at the time of decision (BF10 = 51.27, t(34) = 3.51, p &lt; 0.001), but not during intention maintenance (BF10 = 0.68, t(34) = 1.28, p = 0.10). The left parietal cortex only encoded tasks during intention maintenance (BF10 &gt; 150, t(34) = 4.20, p &lt; 0.001), but not at time of decision (BF10 = 0.19, t(34) = 0.09, p = 0.46). This double dissociation thus suggests a temporal order of task processing in the brain, with the medial PFC transiently encoding chosen tasks at the time of decision-making, and the left parietal cortex then maintaining that information until the tasks can be executed. Lastly, we also assessed task information throughout the multiple demand network (<xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">Duncan, 2010</xref>; <xref ref-type="bibr" rid="c87" hwp:id="xref-ref-87-1" hwp:rel-id="ref-87">Woolgar et al., 2015</xref>), and found tasks to be encoded in a contingency-invariant format (<xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-5" hwp:rel-id="F4">Figure 4-1</xref>).</p></sec><sec id="s3c5" hwp:id="sec-37"><title hwp:id="title-44">Control analyses</title><p hwp:id="p-60">In order to provide further support for our main results, we decided to perform a number of additional control analyses. First, we controlled for potential effects of RTs on task decoding results. It has been pointed out before, that task information in the brain can at least partly be explained through RT effects (<xref ref-type="bibr" rid="c75" hwp:id="xref-ref-75-3" hwp:rel-id="ref-75">Todd et al., 2013</xref>). Although others have found no such effects (<xref ref-type="bibr" rid="c88" hwp:id="xref-ref-88-2" hwp:rel-id="ref-88">Woolgar et al., 2014</xref>), we decided to conservatively control for RT effects nonetheless, especially given that we found RT differences between tasks (see above). We thus repeated the task decoding analyses, only first regressing RT-related effects out of the data. We used the parietal and aMFG ROIs defined in the baseline analysis and tested whether task information was still present after controlling for potential RT effects. We still found the parietal cortex to encode tasks (4.61%, SEM = 0.65%, BF10 &gt; 150, t(34) = 6.99, p &lt; 0.001), and also found the task coding to be reward-invariant (4.03%, SEM = 0.76%, BF10 &gt; 150, t(34) = 5.24, p &lt; 0.001). The same was true for the aMFG (4.66%, SEM = 0.89%, BF10 &gt; 150, t(34) = 5.19, p &lt; 0.001; and 3.71%, SEM = 1.16%, BF10 = 23.38, t(34) = 3.18, p = 0.001; respectively). Results in the baseline and xclass analysis were equal in both regions, BFs10 &gt;= 3.24, ts(34) &lt; 0.67, ps &gt; 0.25. These results thus mirror the main analysis above, showing that RT-related variance cannot explain task decoding results in our experiment.</p><p hwp:id="p-61">Although overall error rates were low and choice biases were largely absent, it was still possible that individual subjects showed excessively high error rates or strong choice biases, affecting task decoding results. The influence of individual subjects should be relatively small given our large sample size, but we still repeated the main analyses, excluding subjects with excessively high error rates and excessively strong choice biases. Additionally, we excluded subjects in which regressors could not be estimated from a sufficient number of trials (see Materials and Methods for more details). Using these highly conservative exclusion criteria, we removed an additional 12 subjects from the sample, leading to a sample size of 23 subjects. Even though statistical power was considerably lower because of the smaller sample size, we were still able to detect task information in the parietal cortex (5.20%, SEM = 0.79%, BF10 &gt;150, t(22) = 6.54, p &lt; 0.001), which was again reward-invariant (3.81%, SEM = 0.96%, BF10 = 96.61, t(22) = 3.93, p &lt; 0.001), and the same was true for the aMFG (5.03%, SEM = 1.09%, BF10 &gt;150, t(22) = 4.60, p &lt; 0.001, and 3.71%, SEM = 1.39%, BF10 = 7.34, t(22) = 2.66, p = 0.006, respectively). Therefore, neither error rates, nor choice biases can explain the reported task decoding results.</p><p hwp:id="p-62">In order to validate the decoding procedure, we also extracted task decoding accuracies from a region not involved in performing this task, the primary auditory cortex. As expected, we found accuracies not to differ from chance level in this region (−0.36%, SEM = 0.93%, BF01 = 7.22, t(34) = 0.38, p = 0.64), showing that the task decoding analysis was not biased towards positive accuracy values. Lastly, we empirically estimated the chance level of our decoding analysis using permutation tests, in order to rule out a biased chance level. The estimated chance level was 49.98%, which did not differ from the theoretical chance level of 50% (BF01 &gt; 150, t(34999) = 0.41, p = 0.67). Thus, comparing our decoding accuracies against a chance level of 50% was valid.</p></sec></sec></sec><sec id="s4" hwp:id="sec-38"><title hwp:id="title-45">Discussion</title><p hwp:id="p-63">Here, we investigated the effects of control over choice outcomes on outcome valuation and choice implementation. Subjects performed a probabilistic reward reversal learning task, in which they had control over the outcomes of their choices. They also performed a free choice task with non-contingent reward outcomes, in which outcomes were not under their direct control. Although we found reward contingency to modulate outcome valuation, we found no effects on choice implementation. Furthermore, we found two main brain regions to be crucial for encoding tasks and reward outcomes: the right dmPFC and the left parietal cortex (around the IPS). The dmPFC was found to encode chosen tasks at the time of decision-making, and simultaneously encoded reward outcome values, emphasizing its role in linking value-related with intentional control processes. While the parietal cortex encoded reward-prediction errors at the time of decision-making, it encoded chosen tasks during a subsequent maintenance phase. We found a double dissociation between both regions, with the dmPFC encoding tasks only at the time of decision-making, and the parietal cortex only during intention maintenance.</p><sec id="s4a" hwp:id="sec-39"><title hwp:id="title-46">Control over choice outcomes affects outcome valuation but not choice implementation</title><p hwp:id="p-64">Much previous research on the effects of reward motivation on cognition investigated the effects of reward prospect (<xref ref-type="bibr" rid="c38" hwp:id="xref-ref-38-1" hwp:rel-id="ref-38">Jimura et al., 2010</xref>; <xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">Dreisbach and Fischer, 2012</xref>). These findings demonstrated that positive reinforcement improves cognition, as compared to no reinforcement at all. However, an equally important and often overlooked property of reinforcement is the degree of control we have in reaching it. Sometimes, an action will cause on outcomes in a fairly clear way, other times, that link will be less close. Previous work on non-human primates has shown that the strength of such action-outcome contingencies modulates the neural processing of reward outcomes (<xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-3" hwp:rel-id="ref-36">Izquierdo et al., 2004</xref>; <xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-3" hwp:rel-id="ref-13">Chudasama et al., 2013</xref>). Our results show that this is also true in humans (see also <xref ref-type="bibr" rid="c77" hwp:id="xref-ref-77-2" hwp:rel-id="ref-77">Tricomi et al., 2004</xref>), and that neural representations of outcome values (and correlated processes) are amplified by reward contingency. Although somewhat weaker, evidence for reward learning signals points in the same direction. This is in line with predictions from gain-theories of motivation. It has been suggested that rewards increase the gain of subcortical dopaminergic neurons (<xref ref-type="bibr" rid="c74" hwp:id="xref-ref-74-1" hwp:rel-id="ref-74">Tobler et al., 2005</xref>), making them more sensitive to changes in rewards (see also <xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-1" hwp:rel-id="ref-35">Ikeda and Hikosaka, 2003</xref>; <xref ref-type="bibr" rid="c73" hwp:id="xref-ref-73-1" hwp:rel-id="ref-73">Thurley et al., 2008</xref>). We directly demonstrate such gain increases, in subcortical dopaminergic regions and beyond.</p><p hwp:id="p-65">Importantly, in order for this value signal to lead to actual rewards, chosen behavior has to be implemented as intended first (see also <xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-1" hwp:rel-id="ref-62">Ruge et al., 2010</xref>). One might thus expect contingency to lead to stronger task shielding and coding (<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-2" hwp:rel-id="ref-21">Dreisbach and Wenke, 2011</xref>), as the costs of confusing both tasks are potentially high. However, we found no evidence for such effects. On the contrary, we found evidence for a similar or invariant coding of tasks across both contingency conditions. This finding informs current debates on the nature of task coding in the brain. On the one hand, some have argued for flexible task coding especially in the fronto-parietal cortex (<xref ref-type="bibr" rid="c87" hwp:id="xref-ref-87-2" hwp:rel-id="ref-87">Woolgar et al., 2015</xref>; <xref ref-type="bibr" rid="c57" hwp:id="xref-ref-57-1" hwp:rel-id="ref-57">Qiao et al., 2017</xref>), often based on the multiple-demand network theory (<xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-2" hwp:rel-id="ref-22">Duncan, 2010</xref>). This account predicts that task coding should be stronger when task demands are high (<xref ref-type="bibr" rid="c87" hwp:id="xref-ref-87-3" hwp:rel-id="ref-87">Woolgar et al., 2015</xref>), or when correct performance is rewarded (<xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-4" hwp:rel-id="ref-25">Etzel et al., 2016</xref>). Despite our efforts to replicate these findings in our data-set, we found no evidence for an influence of reward contingency on task coding. This was despite the fact that behavior differed between these conditions and that value-related signals were affected by reward contingency. One might argue that our analysis had insufficient statistical power to detect true effects, though we believe this to be unlikely. First, we decided to have a relatively large sample size (n=35). Second, additional control analyses showed that other analyses, matched for statistical power, do show significant results.</p><p hwp:id="p-66">On the other hand, others have argued that the same task representations could be used in multiple different situations (i.e. ‘multiplexing’ of task information), and that this allows us to flexibly react to novel and changing demands (<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">Botvinick and Cohen, 2014</xref>). Multiplexing predicts that task information should be invariant across different contexts (<xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-1" hwp:rel-id="ref-45">Levine and Schwarzbach, 2017</xref>), which has been shown previously (<xref ref-type="bibr" rid="c89" hwp:id="xref-ref-89-4" hwp:rel-id="ref-89">Zhang et al., 2013</xref>; <xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-11" hwp:rel-id="ref-84">Wisniewski et al., 2016</xref>; <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-10" hwp:rel-id="ref-48">Loose et al., 2017</xref>). Here, we replicate and extend these findings, by showing that tasks are encoded in an outcome-contingency-invariant format in frontal and parietal brain regions, strengthening the idea of multiplexing of task information in the brain. One possible alternative explanation for this finding might be that subjects were highly trained in performing the two tasks, and were at their performance ceiling. This might make a modulation of task coding too small to detect. Although we cannot fully exclude this interpretation, we want to point out that contingency did have robust effects on behavior. Also, most related previous experiments trained their subjects, those who found effects (<xref ref-type="bibr" rid="c87" hwp:id="xref-ref-87-4" hwp:rel-id="ref-87">Woolgar et al., 2015</xref>; <xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-5" hwp:rel-id="ref-25">Etzel et al., 2016</xref>) and those that did not (<xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-12" hwp:rel-id="ref-84">Wisniewski et al., 2016</xref>). We thus believe this alternative explanation to be unlikely. Overall, our task decoding results are in line with the idea of multiplexing of task information in the brain. Future research will have to test more directly which environmental conditions lead to multiplexing of task information in the brain, and which do not.</p></sec><sec id="s4b" hwp:id="sec-40"><title hwp:id="title-47">The roles of dmPFC and parietal cortex in value-related and task-related processes</title><p hwp:id="p-67">The dmPFC is a key region for decision-making in dynamic environments. It is supports effort-based foraging choices (<xref ref-type="bibr" rid="c86" hwp:id="xref-ref-86-6" hwp:rel-id="ref-86">Wisniewski et al., 2015b</xref>), and here we extend this finding by showing its involvement in a different task with different outcomes (reward reversal learning). The dmPFC is important for cognitive control, supporting rule and action selection (<xref ref-type="bibr" rid="c59" hwp:id="xref-ref-59-1" hwp:rel-id="ref-59">Rowe et al., 2008</xref>), working memory (<xref ref-type="bibr" rid="c72" hwp:id="xref-ref-72-1" hwp:rel-id="ref-72">Taylor et al., 2004</xref>), and processing uncertainty (<xref ref-type="bibr" rid="c80" hwp:id="xref-ref-80-1" hwp:rel-id="ref-80">Volz et al., 2003</xref>). It has further been associated with valuation processes, anticipating both positive and negative outcomes (<xref ref-type="bibr" rid="c37" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">Jensen et al., 2003</xref>; <xref ref-type="bibr" rid="c43" hwp:id="xref-ref-43-1" hwp:rel-id="ref-43">Knutson et al., 2003</xref>), and encoding reward prediction errors (<xref ref-type="bibr" rid="c78" hwp:id="xref-ref-78-1" hwp:rel-id="ref-78">Vassena et al., 2014</xref>). In this experiment, we demonstrated that the dmPFC is specifically involved in encoding tasks only at the time at which a choice is made, other regions later maintain that choice outcome until it can be executed. We also demonstrated the dmPFC to encode outcome values at the same time. Please note that we do not claim this value signal to only represent the magnitude of reward outcomes, it might also represent related processes (e.g. attention). Nevertheless, the cause of this effect are different outcome values, and this highlights the importance of dmPFC in linking valuation to strategic decision-making, providing an explanation to how it might support goal-directed behavior (<xref ref-type="bibr" rid="c79" hwp:id="xref-ref-79-1" hwp:rel-id="ref-79">Viard et al., 2011</xref>).</p><p hwp:id="p-68">The second key region identified in this experiment was the left parietal cortex, especially around the IPS. This brain region encodes prediction errors (<xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-2" hwp:rel-id="ref-16">Daw and Doya, 2006</xref>; <xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-3" hwp:rel-id="ref-49">Matsumoto et al., 2007</xref>; <xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-1" hwp:rel-id="ref-42">Katahira et al., 2015</xref>), which might signal model updating (<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">Behrens et al., 2007</xref>; <xref ref-type="bibr" rid="c82" hwp:id="xref-ref-82-1" hwp:rel-id="ref-82">Walton et al., 2007</xref>; <xref ref-type="bibr" rid="c63" hwp:id="xref-ref-63-1" hwp:rel-id="ref-63">Rutledge et al., 2010</xref>). Alternatively, it has been suggested that the parietal cortex signals surprise, and does not reflect model updating (<xref ref-type="bibr" rid="c53" hwp:id="xref-ref-53-4" hwp:rel-id="ref-53">O’Reilly et al., 2013</xref>). Our findings are more in line with surprise signaling, the only brain region possibly involved in model updating in our experiment was the anterior medial PFC (see also <xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">Braem et al., 2013</xref>). The parietal cortex is also a key region for cognitive control (<xref ref-type="bibr" rid="c61" hwp:id="xref-ref-61-1" hwp:rel-id="ref-61">Ruge et al., 2009</xref>), and working memory (<xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">Christophel et al., 2017</xref>). It is part of the multiple demand network (<xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-3" hwp:rel-id="ref-22">Duncan, 2010</xref>; <xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">Fedorenko et al., 2013</xref>), a set of brain regions characterized by their high flexibility to adapt to changing demands. Previous work on non-human primates demonstrated that the prefrontal cortex flexibly switches between representing different control-related information within single trials (<xref ref-type="bibr" rid="c65" hwp:id="xref-ref-65-1" hwp:rel-id="ref-65">Sigala et al., 2008</xref>; <xref ref-type="bibr" rid="c69" hwp:id="xref-ref-69-1" hwp:rel-id="ref-69">Stokes et al., 2013</xref>). Our results show that the parietal cortex in humans exhibits similar flexibility. It switches between encoding control-related and value-related variables within single trials. This provides compelling evidence for the flexibility of the parietal cortex in adapting to rapidly changing task demands.</p></sec></sec><sec id="s5" hwp:id="sec-41"><title hwp:id="title-48">Conclusion</title><p hwp:id="p-69">In this experiment, we assessed whether controlling outcomes affects outcome valuation and choice implementation in the brain. By comparing choices that are informed by expected outcomes as well as choices that are not, we linked largely parallel research on ‘free choice’ (<xref ref-type="bibr" rid="c46" hwp:id="xref-ref-46-2" hwp:rel-id="ref-46">Libet et al., 1983</xref>) and value-based decision-making (<xref ref-type="bibr" rid="c30" hwp:id="xref-ref-30-3" hwp:rel-id="ref-30">Hampton and O’Doherty, 2007</xref>), which has been long overdue. While we found strong effects on outcome valuation, we found no such effects on choice implementation. Our results further highlight the importance of both the dmPFC and parietal cortex in bridging valuation and executive processes in the brain. Both regions have been involved in processing task choices and their reward outcomes, flexibly switching between encoding value-related and task-related information.</p></sec></body><back><ref-list hwp:id="ref-list-1"><title hwp:id="title-49">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Andraszewicz S"><surname>Andraszewicz</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Scheibehenne B"><surname>Scheibehenne</surname> <given-names>B</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rieskamp J"><surname>Rieskamp</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Grasman R"><surname>Grasman</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Verhagen J"><surname>Verhagen</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wagenmakers E-J"><surname>Wagenmakers</surname> <given-names>E-J</given-names></string-name> (<year>2015</year>) <article-title hwp:id="article-title-2">An Introduction to Bayesian Hypothesis Testing for Management Research</article-title>. <source hwp:id="source-1">J Manag</source> <volume>41</volume>:<fpage>521</fpage>–<lpage>543</lpage>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1 xref-ref-2-2 xref-ref-2-3"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Arrington CM"><surname>Arrington</surname> <given-names>CM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Logan GD"><surname>Logan</surname> <given-names>GD</given-names></string-name> (<year>2004</year>) <article-title hwp:id="article-title-3">The cost of a voluntary task switch</article-title>. <source hwp:id="source-2">Psychol Sci</source> <volume>15</volume>:<fpage>610</fpage>–<lpage>615</lpage>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.3" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Bai Y"><surname>Bai</surname> <given-names>Y</given-names></string-name>, <string-name name-style="western" hwp:sortable="Katahira K"><surname>Katahira</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ohira H"><surname>Ohira</surname> <given-names>H</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-4">Dual learning processes underlying human decision-making in reversal learning tasks: functional significance and evidence from the model fit to human behavior</article-title>. <source hwp:id="source-3">Front Psychol</source> <fpage>5</fpage> Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00871/full" ext-link-type="uri" xlink:href="https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00871/full" hwp:id="ext-link-7">https://www.frontiersin.org/articles/10.3389/fpsyg.2014.00871/full</ext-link> [<date-in-citation content-type="access-date" iso-8601-date="2018-05-31">Accessed May 31, 2018</date-in-citation>].</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Behrens TEJ"><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Woolrich MW"><surname>Woolrich</surname> <given-names>MW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Walton ME"><surname>Walton</surname> <given-names>ME</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rushworth MFS"><surname>Rushworth</surname> <given-names>MFS</given-names></string-name> (<year>2007</year>) <article-title hwp:id="article-title-5">Learning the value of information in an uncertain world</article-title>. <source hwp:id="source-4">Nat Neurosci</source> <volume>10</volume>:<fpage>1214</fpage>–<lpage>1221</lpage>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1 xref-ref-5-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.5" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Bhandari A"><surname>Bhandari</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gagne C"><surname>Gagne</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Badre D"><surname>Badre</surname> <given-names>D</given-names></string-name> (<year>2018</year>) <article-title hwp:id="article-title-6">Just above Chance: Is It Harder to Decode Information from Human Prefrontal Cortex Blood Oxygenation Level-dependent Signals?</article-title> <source hwp:id="source-5">J Cogn Neurosci</source>:<fpage>1</fpage>–<lpage>26</lpage>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Botvinick MM"><surname>Botvinick</surname> <given-names>MM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-7">The Computational and Neural Basis of Cognitive Control: Charted Territory and New Frontiers</article-title>. <source hwp:id="source-6">Cogn Sci</source> <volume>38</volume>:<fpage>1249</fpage>–<lpage>1285</lpage>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Braem S"><surname>Braem</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="King JA"><surname>King</surname> <given-names>JA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Korb FM"><surname>Korb</surname> <given-names>FM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Krebs RM"><surname>Krebs</surname> <given-names>RM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Notebaert W"><surname>Notebaert</surname> <given-names>W</given-names></string-name>, <string-name name-style="western" hwp:sortable="Egner T"><surname>Egner</surname> <given-names>T</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-8">Affective Modulation of Cognitive Control is Determined by Performance-Contingency and Mediated by Ventromedial Prefrontal and Cingulate Cortex</article-title>. <source hwp:id="source-7">J Neurosci</source> <volume>33</volume>:<fpage>16961</fpage>–<lpage>16970</lpage>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Bunge SA"><surname>Bunge</surname> <given-names>SA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kahn I"><surname>Kahn</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wallis JD"><surname>Wallis</surname> <given-names>JD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Miller EK"><surname>Miller</surname> <given-names>EK</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wagner AD"><surname>Wagner</surname> <given-names>AD</given-names></string-name> (<year>2003</year>) <article-title hwp:id="article-title-9">Neural Circuits Subserving the Retrieval and Maintenance of Abstract Rules</article-title>. <source hwp:id="source-8">J Neurophysiol</source> <volume>90</volume>:<fpage>3419</fpage>–<lpage>3428</lpage>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1 xref-ref-9-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Burnham KP"><surname>Burnham</surname> <given-names>KP</given-names></string-name>, <string-name name-style="western" hwp:sortable="Anderson DR"><surname>Anderson</surname> <given-names>DR</given-names></string-name> (<year>2004</year>) <article-title hwp:id="article-title-10">Multimodel Inference: Understanding AIC and BIC in Model Selection</article-title>. <source hwp:id="source-9">Sociol Methods Res</source> <volume>33</volume>:<fpage>261</fpage>–<lpage>304</lpage>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Cacioppo JT"><surname>Cacioppo</surname> <given-names>JT</given-names></string-name>, <string-name name-style="western" hwp:sortable="Petty RE"><surname>Petty</surname> <given-names>RE</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chuan Feng Kao"><surname>Chuan Feng</surname> <given-names>Kao</given-names></string-name> (<year>1984</year>) <article-title hwp:id="article-title-11">The Efficient Assessment of Need for Cognition</article-title>. <source hwp:id="source-10">J Pers Assess</source> <volume>48</volume>:<fpage>306</fpage>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Carver CS"><surname>Carver</surname> <given-names>CS</given-names></string-name>, <string-name name-style="western" hwp:sortable="White TL"><surname>White</surname> <given-names>TL</given-names></string-name> (<year>1994</year>) <article-title hwp:id="article-title-12">Behavioral inhibition, behavioral activation, and affective responses to impending reward and punishment: the BIS/BAS scales</article-title>. <source hwp:id="source-11">J Pers Soc Psychol</source> <volume>67</volume>:<fpage>319</fpage>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.12" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Christophel TB"><surname>Christophel</surname> <given-names>TB</given-names></string-name>, <string-name name-style="western" hwp:sortable="Klink PC"><surname>Klink</surname> <given-names>PC</given-names></string-name>, <string-name name-style="western" hwp:sortable="Spitzer B"><surname>Spitzer</surname> <given-names>B</given-names></string-name>, <string-name name-style="western" hwp:sortable="Roelfsema PR"><surname>Roelfsema</surname> <given-names>PR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name> (<year>2017</year>) <article-title hwp:id="article-title-13">The Distributed Nature of Working Memory</article-title>. <source hwp:id="source-12">Trends Cogn Sci</source> <volume>21</volume>:<fpage>111</fpage>–<lpage>124</lpage>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1 xref-ref-13-2 xref-ref-13-3"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Chudasama Y"><surname>Chudasama</surname> <given-names>Y</given-names></string-name>, <string-name name-style="western" hwp:sortable="Daniels TE"><surname>Daniels</surname> <given-names>TE</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gorrin DP"><surname>Gorrin</surname> <given-names>DP</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rhodes SEV"><surname>Rhodes</surname> <given-names>SEV</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rudebeck PH"><surname>Rudebeck</surname> <given-names>PH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Murray EA"><surname>Murray</surname> <given-names>EA</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-14">The Role of the Anterior Cingulate Cortex in Choices based on Reward Value and Reward Contingency</article-title>. <source hwp:id="source-13">Cereb Cortex</source> <volume>23</volume>:<fpage>2884</fpage>–<lpage>2898</lpage>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1 xref-ref-14-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Collins AGE"><surname>Collins</surname> <given-names>AGE</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ciullo B"><surname>Ciullo</surname> <given-names>B</given-names></string-name>, <string-name name-style="western" hwp:sortable="Frank MJ"><surname>Frank</surname> <given-names>MJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Badre D"><surname>Badre</surname> <given-names>D</given-names></string-name> (<year>2017</year>) <article-title hwp:id="article-title-15">Working Memory Load Strengthens Reward Prediction Errors</article-title>. <source hwp:id="source-14">J Neurosci</source> <volume>37</volume>:<fpage>4332</fpage>–<lpage>4342</lpage>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1 xref-ref-15-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.15" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Cox DD"><surname>Cox</surname> <given-names>DD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Savoy RL"><surname>Savoy</surname> <given-names>RL</given-names></string-name> (<year>2003</year>) <article-title hwp:id="article-title-16">Functional magnetic resonance imaging (fMRI) “brain reading”: detecting and classifying distributed patterns of fMRI activity in human visual cortex</article-title>. <source hwp:id="source-15">NeuroImage</source> <volume>19</volume>:<fpage>261</fpage>–<lpage>270</lpage>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1 xref-ref-16-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Daw ND"><surname>Daw</surname> <given-names>ND</given-names></string-name>, <string-name name-style="western" hwp:sortable="Doya K"><surname>Doya</surname> <given-names>K</given-names></string-name> (<year>2006</year>) <article-title hwp:id="article-title-17">The computational neurobiology of learning and reward</article-title>. <source hwp:id="source-16">Curr Opin Neurobiol</source> <volume>16</volume>:<fpage>199</fpage>–<lpage>204</lpage>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1 xref-ref-17-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Daw ND"><surname>Daw</surname> <given-names>ND</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gershman SJ"><surname>Gershman</surname> <given-names>SJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Seymour B"><surname>Seymour</surname> <given-names>B</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dayan P"><surname>Dayan</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dolan RJ"><surname>Dolan</surname> <given-names>RJ</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-18">Model-Based Influences on Humans’ Choices and Striatal Prediction Errors</article-title>. <source hwp:id="source-17">Neuron</source> <volume>69</volume>:<fpage>1204</fpage>–<lpage>1215</lpage>.</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1 xref-ref-18-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Domenech P"><surname>Domenech</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Redouté J"><surname>Redouté</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Koechlin E"><surname>Koechlin</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dreher J-C"><surname>Dreher</surname> <given-names>J-C</given-names></string-name> (<year>2018</year>) <article-title hwp:id="article-title-19">The Neuro-Computational Architecture of Value-Based Selection in the Human Brain</article-title>. <source hwp:id="source-18">Cereb Cortex</source> <volume>28</volume>:<fpage>585</fpage>–<lpage>601</lpage>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Doya K"><surname>Doya</surname> <given-names>K</given-names></string-name> (<year>2008</year>) <article-title hwp:id="article-title-20">Modulators of decision making</article-title>. <source hwp:id="source-19">Nat Neurosci</source> <volume>11</volume>:<fpage>410</fpage>–<lpage>416</lpage>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.20" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Dreisbach G"><surname>Dreisbach</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fischer R"><surname>Fischer</surname> <given-names>R</given-names></string-name> (<year>2012</year>) <article-title hwp:id="article-title-21">The role of affect and reward in the conflict-triggered adjustment of cognitive control</article-title>. <source hwp:id="source-20">Front Hum Neurosci</source> <fpage>6</fpage> Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc3533233/" ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc3533233/" hwp:id="ext-link-8">http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3533233/</ext-link> [<date-in-citation content-type="access-date" iso-8601-date="2014-10-30">Accessed October 30, 2014</date-in-citation>].</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1 xref-ref-21-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Dreisbach G"><surname>Dreisbach</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wenke D"><surname>Wenke</surname> <given-names>D</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-22">The shielding function of task sets and its relaxation during task switching</article-title>. <source hwp:id="source-21">J Exp Psychol Learn Mem Cogn</source> <volume>37</volume>:<fpage>1540</fpage>–<lpage>1546</lpage>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1 xref-ref-22-2 xref-ref-22-3"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Duncan J"><surname>Duncan</surname> <given-names>J</given-names></string-name> (<year>2010</year>) <article-title hwp:id="article-title-23">The multiple-demand (MD) system of the primate brain: mental programs for intelligent behaviour</article-title>. <source hwp:id="source-22">Trends Cogn Sci</source> <volume>14</volume>:<fpage>172</fpage>–<lpage>179</lpage>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Eklund A"><surname>Eklund</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Nichols TE"><surname>Nichols</surname> <given-names>TE</given-names></string-name>, <string-name name-style="western" hwp:sortable="Knutsson H"><surname>Knutsson</surname> <given-names>H</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-24">Cluster failure: Why fMRI inferences for spatial extent have inflated false-positive rates</article-title>. <source hwp:id="source-23">Proc Natl Acad Sci</source> <volume>113</volume>:<fpage>7900</fpage>–<lpage>7905</lpage>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1 xref-ref-24-2 xref-ref-24-3"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Elliott R"><surname>Elliott</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newman JL"><surname>Newman</surname> <given-names>JL</given-names></string-name>, <string-name name-style="western" hwp:sortable="Longe OA"><surname>Longe</surname> <given-names>OA</given-names></string-name>, <string-name name-style="western" hwp:sortable="William Deakin JF"><surname>William Deakin</surname> <given-names>JF</given-names></string-name> (<year>2004</year>) <article-title hwp:id="article-title-25">Instrumental responding for rewards is associated with enhanced neuronal response in subcortical reward systems</article-title>. <source hwp:id="source-24">NeuroImage</source> <volume>21</volume>:<fpage>984</fpage>–<lpage>990</lpage>.</citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1 xref-ref-25-2 xref-ref-25-3 xref-ref-25-4 xref-ref-25-5"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Etzel JA"><surname>Etzel</surname> <given-names>JA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cole MW"><surname>Cole</surname> <given-names>MW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zacks JM"><surname>Zacks</surname> <given-names>JM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kay KN"><surname>Kay</surname> <given-names>KN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Braver TS"><surname>Braver</surname> <given-names>TS</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-26">Reward Motivation Enhances Task Coding in Frontoparietal Cortex</article-title>. <source hwp:id="source-25">Cereb Cortex</source> <volume>26</volume>:<fpage>1647</fpage>–<lpage>1659</lpage>.</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.26" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Fedorenko E"><surname>Fedorenko</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Duncan J"><surname>Duncan</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kanwisher N"><surname>Kanwisher</surname> <given-names>N</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-27">Broad domain generality in focal regions of frontal and parietal cortex</article-title>. <source hwp:id="source-26">Proc Natl Acad Sci</source> <volume>110</volume>:<fpage>16616</fpage>–<lpage>16621</lpage>.</citation></ref><ref id="c27" hwp:id="ref-27" hwp:rev-id="xref-ref-27-1 xref-ref-27-2 xref-ref-27-3 xref-ref-27-4"><citation publication-type="book" citation-type="book" ref:id="375642v3.27" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Forstmann BU"><surname>Forstmann</surname> <given-names>BU</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wagenmakers E-J"><surname>Wagenmakers</surname> <given-names>E-J</given-names></string-name> (<year>2015</year>) <chapter-title>An Introduction to Model-Based Cognitive Neuroscience</chapter-title>. <publisher-name>Springer</publisher-name>.</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.28" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Friston KJ"><surname>Friston</surname> <given-names>KJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Holmes AP"><surname>Holmes</surname> <given-names>AP</given-names></string-name>, <string-name name-style="western" hwp:sortable="Worsley KJ"><surname>Worsley</surname> <given-names>KJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Poline J-P"><surname>Poline</surname> <given-names>J-P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Frith CD"><surname>Frith</surname> <given-names>CD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Frackowiak RS"><surname>Frackowiak</surname> <given-names>RS</given-names></string-name> (<year>1994</year>) <article-title hwp:id="article-title-28">Statistical parametric maps in functional imaging: a general linear approach</article-title>. <source hwp:id="source-27">Hum Brain Mapp</source> <volume>2</volume>:<fpage>189</fpage>–<lpage>210</lpage>.</citation></ref><ref id="c29" hwp:id="ref-29" hwp:rev-id="xref-ref-29-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.29" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="Gilbert SJ"><surname>Gilbert</surname> <given-names>SJ</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-29">Decoding the Content of Delayed Intentions</article-title>. <source hwp:id="source-28">J Neurosci</source> <volume>31</volume>:<fpage>2888</fpage>–<lpage>2894</lpage>.</citation></ref><ref id="c30" hwp:id="ref-30" hwp:rev-id="xref-ref-30-1 xref-ref-30-2 xref-ref-30-3"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.30" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="Hampton AN"><surname>Hampton</surname> <given-names>AN</given-names></string-name>, <string-name name-style="western" hwp:sortable="O’Doherty JP"><surname>O’Doherty</surname> <given-names>JP</given-names></string-name> (<year>2007</year>) <article-title hwp:id="article-title-30">Decoding the neural substrates of reward-related decision making with functional MRI</article-title>. <source hwp:id="source-29">Proc Natl Acad Sci</source> <volume>104</volume>:<fpage>1377</fpage>–<lpage>1382</lpage>.</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="Haxby JV"><surname>Haxby</surname> <given-names>JV</given-names></string-name> (<year>2012</year>) <article-title hwp:id="article-title-31">Multivariate pattern analysis of fMRI: The early beginnings</article-title>. <source hwp:id="source-30">NeuroImage</source> <volume>62</volume>:<fpage>852</fpage>–<lpage>855</lpage>.</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1 xref-ref-32-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.32" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name> (<year>2015</year>) <article-title hwp:id="article-title-32">A Primer on Pattern-Based Approaches to fMRI: Principles, Pitfalls, and Perspectives</article-title>. <source hwp:id="source-31">Neuron</source> <volume>87</volume>:<fpage>257</fpage>–<lpage>270</lpage>.</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1 xref-ref-33-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.33" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sakai K"><surname>Sakai</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rees G"><surname>Rees</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gilbert SJ"><surname>Gilbert</surname> <given-names>SJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Frith C"><surname>Frith</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Passingham RE"><surname>Passingham</surname> <given-names>RE</given-names></string-name> (<year>2007</year>) <article-title hwp:id="article-title-33">Reading Hidden Intentions in the Human Brain</article-title>. <source hwp:id="source-32">Curr Biol</source> <volume>17</volume>:<fpage>323</fpage>–<lpage>328</lpage>.</citation></ref><ref id="c34" hwp:id="ref-34" hwp:rev-id="xref-ref-34-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.34" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Hebart MN"><surname>Hebart</surname> <given-names>MN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Görgen K"><surname>Görgen</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-34">The Decoding Toolbox (TDT): A versatile software package for multivariate analyses of functional imaging data</article-title>. <source hwp:id="source-33">Front Neuroinformatics</source> <volume>8</volume>:<fpage>88</fpage>.</citation></ref><ref id="c35" hwp:id="ref-35" hwp:rev-id="xref-ref-35-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.35" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Ikeda T"><surname>Ikeda</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hikosaka O"><surname>Hikosaka</surname> <given-names>O</given-names></string-name> (<year>2003</year>) <article-title hwp:id="article-title-35">Reward-Dependent Gain and Bias of Visual Responses in Primate Superior Colliculus</article-title>. <source hwp:id="source-34">Neuron</source> <volume>39</volume>:<fpage>693</fpage>–<lpage>700</lpage>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1 xref-ref-36-2 xref-ref-36-3"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.36" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Izquierdo A"><surname>Izquierdo</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Suda RK"><surname>Suda</surname> <given-names>RK</given-names></string-name>, <string-name name-style="western" hwp:sortable="Murray EA"><surname>Murray</surname> <given-names>EA</given-names></string-name> (<year>2004</year>) <article-title hwp:id="article-title-36">Bilateral Orbital Prefrontal Cortex Lesions in Rhesus Monkeys Disrupt Choices Guided by Both Reward Value and Reward Contingency</article-title>. <source hwp:id="source-35">J Neurosci</source> <volume>24</volume>:<fpage>7540</fpage>–<lpage>7548</lpage>.</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.37" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Jensen J"><surname>Jensen</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="McIntosh AR"><surname>McIntosh</surname> <given-names>AR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Crawley AP"><surname>Crawley</surname> <given-names>AP</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mikulis DJ"><surname>Mikulis</surname> <given-names>DJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Remington G"><surname>Remington</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kapur S"><surname>Kapur</surname> <given-names>S</given-names></string-name> (<year>2003</year>) <article-title hwp:id="article-title-37">Direct Activation of the Ventral Striatum in Anticipation of Aversive Stimuli</article-title>. <source hwp:id="source-36">Neuron</source> <volume>40</volume>:<fpage>1251</fpage>–<lpage>1257</lpage>.</citation></ref><ref id="c38" hwp:id="ref-38" hwp:rev-id="xref-ref-38-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.38" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-38"><string-name name-style="western" hwp:sortable="Jimura K"><surname>Jimura</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Locke HS"><surname>Locke</surname> <given-names>HS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Braver TS"><surname>Braver</surname> <given-names>TS</given-names></string-name> (<year>2010</year>) <article-title hwp:id="article-title-38">Prefrontal cortex mediation of cognitive enhancement in rewarding motivational contexts</article-title>. <source hwp:id="source-37">Proc Natl Acad Sci</source> <volume>107</volume>:<fpage>8871</fpage>–<lpage>8876</lpage>.</citation></ref><ref id="c39" hwp:id="ref-39" hwp:rev-id="xref-ref-39-1 xref-ref-39-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.39" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-39"><string-name name-style="western" hwp:sortable="Kahnt T"><surname>Kahnt</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Park SQ"><surname>Park</surname> <given-names>SQ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tobler PN"><surname>Tobler</surname> <given-names>PN</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-39">Disentangling neural representations of value and salience in the human brain</article-title>. <source hwp:id="source-38">Proc Natl Acad Sci</source> <volume>111</volume>:<fpage>5000</fpage>–<lpage>5005</lpage>.</citation></ref><ref id="c40" hwp:id="ref-40" hwp:rev-id="xref-ref-40-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.40" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-40"><string-name name-style="western" hwp:sortable="Kamitani Y"><surname>Kamitani</surname> <given-names>Y</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tong F"><surname>Tong</surname> <given-names>F</given-names></string-name> (<year>2005</year>) <article-title hwp:id="article-title-40">Decoding the visual and subjective contents of the human brain</article-title>. <source hwp:id="source-39">Nat Neurosci</source> <volume>8</volume>:<fpage>679</fpage>–<lpage>685</lpage>.</citation></ref><ref id="c41" hwp:id="ref-41" hwp:rev-id="xref-ref-41-1 xref-ref-41-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.41" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-41"><string-name name-style="western" hwp:sortable="Kaplan JT"><surname>Kaplan</surname> <given-names>JT</given-names></string-name>, <string-name name-style="western" hwp:sortable="Man K"><surname>Man</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Greening SG"><surname>Greening</surname> <given-names>SG</given-names></string-name> (<year>2015</year>) <article-title hwp:id="article-title-41">Multivariate cross-classification: applying machine learning techniques to characterize abstraction in neural representations</article-title>. <source hwp:id="source-40">Front Hum Neurosci</source> <fpage>9</fpage> Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc4373279/" ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pmc/articles/pmc4373279/" hwp:id="ext-link-9">http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4373279/</ext-link> [<date-in-citation content-type="access-date" iso-8601-date="2015-12-10">Accessed December 10, 2015</date-in-citation>].</citation></ref><ref id="c42" hwp:id="ref-42" hwp:rev-id="xref-ref-42-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.42" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-42"><string-name name-style="western" hwp:sortable="Katahira K"><surname>Katahira</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Matsuda Y-T"><surname>Matsuda</surname> <given-names>Y-T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fujimura T"><surname>Fujimura</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ueno K"><surname>Ueno</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Asamizuya T"><surname>Asamizuya</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Suzuki C"><surname>Suzuki</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cheng K"><surname>Cheng</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Okanoya K"><surname>Okanoya</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Okada M"><surname>Okada</surname> <given-names>M</given-names></string-name> (<year>2015</year>) <article-title hwp:id="article-title-42">Neural basis of decision making guided by emotional outcomes</article-title>. <source hwp:id="source-41">J Neurophysiol</source> <volume>113</volume>:<fpage>3056</fpage>–<lpage>3068</lpage>.</citation></ref><ref id="c43" hwp:id="ref-43" hwp:rev-id="xref-ref-43-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.43" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-43"><string-name name-style="western" hwp:sortable="Knutson B"><surname>Knutson</surname> <given-names>B</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fong GW"><surname>Fong</surname> <given-names>GW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bennett SM"><surname>Bennett</surname> <given-names>SM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Adams CM"><surname>Adams</surname> <given-names>CM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hommer D"><surname>Hommer</surname> <given-names>D</given-names></string-name> (<year>2003</year>) <article-title hwp:id="article-title-43">A region of mesial prefrontal cortex tracks monetarily rewarding outcomes: characterization with rapid event-related fMRI</article-title>. <source hwp:id="source-42">NeuroImage</source> <volume>18</volume>:<fpage>263</fpage>–<lpage>272</lpage>.</citation></ref><ref id="c44" hwp:id="ref-44" hwp:rev-id="xref-ref-44-1 xref-ref-44-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.44" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-44"><string-name name-style="western" hwp:sortable="Kriegeskorte N"><surname>Kriegeskorte</surname> <given-names>N</given-names></string-name>, <string-name name-style="western" hwp:sortable="Goebel R"><surname>Goebel</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bandettini P"><surname>Bandettini</surname> <given-names>P</given-names></string-name> (<year>2006</year>) <article-title hwp:id="article-title-44">Information-based functional brain mapping</article-title>. <source hwp:id="source-43">Proc Natl Acad Sci</source> <volume>103</volume>:<fpage>3863</fpage>–<lpage>3868</lpage>.</citation></ref><ref id="c45" hwp:id="ref-45" hwp:rev-id="xref-ref-45-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.45" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-45"><string-name name-style="western" hwp:sortable="Levine SM"><surname>Levine</surname> <given-names>SM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schwarzbach J"><surname>Schwarzbach</surname> <given-names>J</given-names></string-name> (<year>2017</year>) <article-title hwp:id="article-title-45">Decoding of auditory and tactile perceptual decisions in parietal cortex</article-title>. <source hwp:id="source-44">NeuroImage</source> <volume>162</volume>:<fpage>297</fpage>–<lpage>305</lpage>.</citation></ref><ref id="c46" hwp:id="ref-46" hwp:rev-id="xref-ref-46-1 xref-ref-46-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.46" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-46"><string-name name-style="western" hwp:sortable="Libet B"><surname>Libet</surname> <given-names>B</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gleason CA"><surname>Gleason</surname> <given-names>CA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wright EW"><surname>Wright</surname> <given-names>EW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pearl DK"><surname>Pearl</surname> <given-names>DK</given-names></string-name> (<year>1983</year>) <article-title hwp:id="article-title-46">Time of conscious intention to act in relation to onset of cerebral activity (readiness-potential) the unconscious initiation of a freely voluntary act</article-title>. <source hwp:id="source-45">Brain</source> <volume>106</volume>:<fpage>623</fpage>–<lpage>642</lpage>.</citation></ref><ref id="c47" hwp:id="ref-47" hwp:rev-id="xref-ref-47-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.47" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-47"><string-name name-style="western" hwp:sortable="Lien M-C"><surname>Lien</surname> <given-names>M-C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ruthruff E"><surname>Ruthruff</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Remington RW"><surname>Remington</surname> <given-names>RW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Johnston JC"><surname>Johnston</surname> <given-names>JC</given-names></string-name> (<year>2005</year>) <article-title hwp:id="article-title-47">On the limits of advance preparation for a task switch: do people prepare all the task some of the time or some of the task all the time?</article-title> <source hwp:id="source-46">J Exp Psychol Hum Percept Perform</source> <volume>31</volume>:<fpage>299</fpage>–<lpage>315</lpage>.</citation></ref><ref id="c48" hwp:id="ref-48" hwp:rev-id="xref-ref-48-1 xref-ref-48-2 xref-ref-48-3 xref-ref-48-4 xref-ref-48-5 xref-ref-48-6 xref-ref-48-7 xref-ref-48-8 xref-ref-48-9 xref-ref-48-10"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.48" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-48"><string-name name-style="western" hwp:sortable="Loose LS"><surname>Loose</surname> <given-names>LS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wisniewski D"><surname>Wisniewski</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rusconi M"><surname>Rusconi</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Goschke T"><surname>Goschke</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name> (<year>2017</year>) <article-title hwp:id="article-title-48">Switch-Independent Task Representations in Frontal and Parietal Cortex</article-title>. <source hwp:id="source-47">J Neurosci</source> <volume>37</volume>:<fpage>8033</fpage>–<lpage>8042</lpage>.</citation></ref><ref id="c49" hwp:id="ref-49" hwp:rev-id="xref-ref-49-1 xref-ref-49-2 xref-ref-49-3"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.49" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-49"><string-name name-style="western" hwp:sortable="Matsumoto M"><surname>Matsumoto</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Matsumoto K"><surname>Matsumoto</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Abe H"><surname>Abe</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tanaka K"><surname>Tanaka</surname> <given-names>K</given-names></string-name> (<year>2007</year>) <article-title hwp:id="article-title-49">Medial prefrontal cell activity signaling prediction errors of action values</article-title>. <source hwp:id="source-48">Nat Neurosci</source> <volume>10</volume>:<fpage>647</fpage>–<lpage>656</lpage>.</citation></ref><ref id="c50" hwp:id="ref-50" hwp:rev-id="xref-ref-50-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.50" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-50"><string-name name-style="western" hwp:sortable="Mertens G"><surname>Mertens</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="De Houwer J"><surname>De Houwer</surname> <given-names>J</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-50">Potentiation of the startle reflex is in line with contingency reversal instructions rather than the conditioning history</article-title>. <source hwp:id="source-49">Biol Psychol</source> <volume>113</volume>:<fpage>91</fpage>–<lpage>99</lpage>.</citation></ref><ref id="c51" hwp:id="ref-51" hwp:rev-id="xref-ref-51-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.51" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-51"><string-name name-style="western" hwp:sortable="Mitchell TM"><surname>Mitchell</surname> <given-names>TM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hutchinson R"><surname>Hutchinson</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Niculescu RS"><surname>Niculescu</surname> <given-names>RS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pereira F"><surname>Pereira</surname> <given-names>F</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wang X"><surname>Wang</surname> <given-names>X</given-names></string-name>, <string-name name-style="western" hwp:sortable="Just M"><surname>Just</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newman S"><surname>Newman</surname> <given-names>S</given-names></string-name> (<year>2004</year>) <article-title hwp:id="article-title-51">Learning to decode cognitive states from brain images</article-title>. <source hwp:id="source-50">Mach Learn</source> <volume>57</volume>:<fpage>145</fpage>–<lpage>175</lpage>.</citation></ref><ref id="c52" hwp:id="ref-52" hwp:rev-id="xref-ref-52-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.52" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-52"><string-name name-style="western" hwp:sortable="O’Doherty JP"><surname>O’Doherty</surname> <given-names>JP</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hampton A"><surname>Hampton</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kim H"><surname>Kim</surname> <given-names>H</given-names></string-name> (<year>2007</year>) <article-title hwp:id="article-title-52">Model-Based fMRI and Its Application to Reward Learning and Decision Making</article-title>. <source hwp:id="source-51">Ann N Y Acad Sci</source> <volume>1104</volume>:<fpage>35</fpage>–<lpage>53</lpage>.</citation></ref><ref id="c53" hwp:id="ref-53" hwp:rev-id="xref-ref-53-1 xref-ref-53-2 xref-ref-53-3 xref-ref-53-4"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.53" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-53"><string-name name-style="western" hwp:sortable="O’Reilly JX"><surname>O’Reilly</surname> <given-names>JX</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schüffelgen U"><surname>Schüffelgen</surname> <given-names>U</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cuell SF"><surname>Cuell</surname> <given-names>SF</given-names></string-name>, <string-name name-style="western" hwp:sortable="Behrens TEJ"><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mars RB"><surname>Mars</surname> <given-names>RB</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rushworth MFS"><surname>Rushworth</surname> <given-names>MFS</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-53">Dissociable effects of surprise and model update in parietal and anterior cingulate cortex</article-title>. <source hwp:id="source-52">Proc Natl Acad Sci</source> <volume>110</volume>:<fpage>E3660</fpage>–<lpage>E3669</lpage>.</citation></ref><ref id="c54" hwp:id="ref-54" hwp:rev-id="xref-ref-54-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.54" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-54"><string-name name-style="western" hwp:sortable="Patton JH"><surname>Patton</surname> <given-names>JH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Stanford MS"><surname>Stanford</surname> <given-names>MS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Barratt ES"><surname>Barratt</surname> <given-names>ES</given-names></string-name> (<year>1995</year>) <article-title hwp:id="article-title-54">Factor structure of the Barratt impulsiveness scale</article-title>. <source hwp:id="source-53">J Clin Psychol</source> <volume>51</volume>:<fpage>768</fpage>–<lpage>774</lpage>.</citation></ref><ref id="c55" hwp:id="ref-55" hwp:rev-id="xref-ref-55-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.55" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-55"><string-name name-style="western" hwp:sortable="Peirce JW"><surname>Peirce</surname> <given-names>JW</given-names></string-name> (<year>2007</year>) <article-title hwp:id="article-title-55">PsychoPy—Psychophysics software in Python</article-title>. <source hwp:id="source-54">J Neurosci Methods</source> <volume>162</volume>:<fpage>8</fpage>–<lpage>13</lpage>.</citation></ref><ref id="c56" hwp:id="ref-56" hwp:rev-id="xref-ref-56-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.56" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-56"><string-name name-style="western" hwp:sortable="Pessiglione M"><surname>Pessiglione</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Seymour B"><surname>Seymour</surname> <given-names>B</given-names></string-name>, <string-name name-style="western" hwp:sortable="Flandin G"><surname>Flandin</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dolan RJ"><surname>Dolan</surname> <given-names>RJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Frith CD"><surname>Frith</surname> <given-names>CD</given-names></string-name> (<year>2006</year>) <article-title hwp:id="article-title-56">Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans</article-title>. <source hwp:id="source-55">Nature</source> <volume>442</volume>:<fpage>1042</fpage>–<lpage>1045</lpage>.</citation></ref><ref id="c57" hwp:id="ref-57" hwp:rev-id="xref-ref-57-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.57" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-57"><string-name name-style="western" hwp:sortable="Qiao L"><surname>Qiao</surname> <given-names>L</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zhang L"><surname>Zhang</surname> <given-names>L</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chen A"><surname>Chen</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Egner T"><surname>Egner</surname> <given-names>T</given-names></string-name> (<year>2017</year>) <article-title hwp:id="article-title-57">Dynamic Trial-by-Trial Recoding of Task-Set Representations in the Frontoparietal Cortex Mediates Behavioral Flexibility</article-title>. <source hwp:id="source-56">J Neurosci</source> <volume>37</volume>:<fpage>11037</fpage>–<lpage>11050</lpage>.</citation></ref><ref id="c58" hwp:id="ref-58" hwp:rev-id="xref-ref-58-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.58" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-58"><string-name name-style="western" hwp:sortable="Rouder JN"><surname>Rouder</surname> <given-names>JN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Speckman PL"><surname>Speckman</surname> <given-names>PL</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sun D"><surname>Sun</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Morey RD"><surname>Morey</surname> <given-names>RD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Iverson G"><surname>Iverson</surname> <given-names>G</given-names></string-name> (<year>2009</year>) <article-title hwp:id="article-title-58">Bayesian tests for accepting and rejecting the null hypothesis</article-title>. <source hwp:id="source-57">Psychon Bull Rev</source> <volume>16</volume>:<fpage>225</fpage>–<lpage>237</lpage>.</citation></ref><ref id="c59" hwp:id="ref-59" hwp:rev-id="xref-ref-59-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.59" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-59"><string-name name-style="western" hwp:sortable="Rowe J"><surname>Rowe</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hughes L"><surname>Hughes</surname> <given-names>L</given-names></string-name>, <string-name name-style="western" hwp:sortable="Eckstein D"><surname>Eckstein</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Owen AM"><surname>Owen</surname> <given-names>AM</given-names></string-name> (<year>2008</year>) <article-title hwp:id="article-title-59">Rule-Selection and Action-Selection have a Shared Neuroanatomical Basis in the Human Prefrontal and Parietal Cortex</article-title>. <source hwp:id="source-58">Cereb Cortex</source> <volume>18</volume>:<fpage>2275</fpage>–<lpage>2285</lpage>.</citation></ref><ref id="c60" hwp:id="ref-60" hwp:rev-id="xref-ref-60-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.60" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-60"><string-name name-style="western" hwp:sortable="Rubinstein JS"><surname>Rubinstein</surname> <given-names>JS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Meyer DE"><surname>Meyer</surname> <given-names>DE</given-names></string-name>, <string-name name-style="western" hwp:sortable="Evans JE"><surname>Evans</surname> <given-names>JE</given-names></string-name> (<year>2001</year>) <article-title hwp:id="article-title-60">Executive control of cognitive processes in task switching</article-title>. <source hwp:id="source-59">J Exp Psychol Hum Percept Perform</source> <volume>27</volume>:<fpage>763</fpage>–<lpage>797</lpage>.</citation></ref><ref id="c61" hwp:id="ref-61" hwp:rev-id="xref-ref-61-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.61" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-61"><string-name name-style="western" hwp:sortable="Ruge H"><surname>Ruge</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Braver T"><surname>Braver</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Meiran N"><surname>Meiran</surname> <given-names>N</given-names></string-name> (<year>2009</year>) <article-title hwp:id="article-title-61">Attention, intention, and strategy in preparatory control</article-title>. <source hwp:id="source-60">Neuropsychologia</source> <volume>47</volume>:<fpage>1670</fpage>–<lpage>1685</lpage>.</citation></ref><ref id="c62" hwp:id="ref-62" hwp:rev-id="xref-ref-62-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.62" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-62"><string-name name-style="western" hwp:sortable="Ruge H"><surname>Ruge</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Müller S"><surname>Müller</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Braver T"><surname>Braver</surname> <given-names>T</given-names></string-name> (<year>2010</year>) <article-title hwp:id="article-title-62">Anticipating the consequences of action: An fMRI study of intention-based task preparation</article-title>. <source hwp:id="source-61">Psychophysiology</source> <volume>47</volume>:<fpage>1019</fpage>–<lpage>1027</lpage>.</citation></ref><ref id="c63" hwp:id="ref-63" hwp:rev-id="xref-ref-63-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.63" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-63"><string-name name-style="western" hwp:sortable="Rutledge RB"><surname>Rutledge</surname> <given-names>RB</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dean M"><surname>Dean</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Caplin A"><surname>Caplin</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Glimcher PW"><surname>Glimcher</surname> <given-names>PW</given-names></string-name> (<year>2010</year>) <article-title hwp:id="article-title-63">Testing the Reward Prediction Error Hypothesis with an Axiomatic Model</article-title>. <source hwp:id="source-62">J Neurosci</source> <volume>30</volume>:<fpage>13525</fpage>–<lpage>13536</lpage>.</citation></ref><ref id="c64" hwp:id="ref-64" hwp:rev-id="xref-ref-64-1 xref-ref-64-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.64" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-64"><string-name name-style="western" hwp:sortable="Schultz W"><surname>Schultz</surname> <given-names>W</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-64">Dopamine reward prediction-error signalling: a two-component response</article-title>. <source hwp:id="source-63">Nat Rev Neurosci</source> <volume>17</volume>:<fpage>183</fpage>–<lpage>195</lpage>.</citation></ref><ref id="c65" hwp:id="ref-65" hwp:rev-id="xref-ref-65-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.65" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-65"><string-name name-style="western" hwp:sortable="Sigala N"><surname>Sigala</surname> <given-names>N</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kusunoki M"><surname>Kusunoki</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Nimmo-Smith I"><surname>Nimmo-Smith</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gaffan D"><surname>Gaffan</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Duncan J"><surname>Duncan</surname> <given-names>J</given-names></string-name> (<year>2008</year>) <article-title hwp:id="article-title-65">Hierarchical coding for sequential task events in the monkey prefrontal cortex</article-title>. <source hwp:id="source-64">Proc Natl Acad Sci</source> <volume>105</volume>:<fpage>11969</fpage>–<lpage>11974</lpage>.</citation></ref><ref id="c66" hwp:id="ref-66" hwp:rev-id="xref-ref-66-1 xref-ref-66-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.66" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-66"><string-name name-style="western" hwp:sortable="Soon CS"><surname>Soon</surname> <given-names>CS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Brass M"><surname>Brass</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Heinze H-J"><surname>Heinze</surname> <given-names>H-J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name> (<year>2008</year>) <article-title hwp:id="article-title-66">Unconscious determinants of free decisions in the human brain</article-title>. <source hwp:id="source-65">Nat Neurosci</source> <volume>11</volume>:<fpage>543</fpage>–<lpage>545</lpage>.</citation></ref><ref id="c67" hwp:id="ref-67" hwp:rev-id="xref-ref-67-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.67" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-67"><string-name name-style="western" hwp:sortable="Soon CS"><surname>Soon</surname> <given-names>CS</given-names></string-name>, <string-name name-style="western" hwp:sortable="He AH"><surname>He</surname> <given-names>AH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bode S"><surname>Bode</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-67">Predicting free choices for abstract intentions</article-title>. <source hwp:id="source-66">Proc Natl Acad Sci</source> <volume>110</volume>:<fpage>6217</fpage>–<lpage>6222</lpage>.</citation></ref><ref id="c68" hwp:id="ref-68" hwp:rev-id="xref-ref-68-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.68" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-68"><string-name name-style="western" hwp:sortable="Sperduti M"><surname>Sperduti</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Delaveau P"><surname>Delaveau</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fossati P"><surname>Fossati</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Nadel J"><surname>Nadel</surname> <given-names>J</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-68">Different brain structures related to self- and external-agency attribution: a brief review and meta-analysis</article-title>. <source hwp:id="source-67">Brain Struct Funct</source> <volume>216</volume>:<fpage>151</fpage>–<lpage>157</lpage>.</citation></ref><ref id="c69" hwp:id="ref-69" hwp:rev-id="xref-ref-69-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.69" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-69"><string-name name-style="western" hwp:sortable="Stokes MG"><surname>Stokes</surname> <given-names>MG</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kusunoki M"><surname>Kusunoki</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sigala N"><surname>Sigala</surname> <given-names>N</given-names></string-name>, <string-name name-style="western" hwp:sortable="Nili H"><surname>Nili</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gaffan D"><surname>Gaffan</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Duncan J"><surname>Duncan</surname> <given-names>J</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-69">Dynamic Coding for Cognitive Control in Prefrontal Cortex</article-title>. <source hwp:id="source-68">Neuron</source> <volume>78</volume>:<fpage>364</fpage>–<lpage>375</lpage>.</citation></ref><ref id="c70" hwp:id="ref-70" hwp:rev-id="xref-ref-70-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.70" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-70"><string-name name-style="western" hwp:sortable="Sugrue LP"><surname>Sugrue</surname> <given-names>LP</given-names></string-name> (<year>2004</year>) <article-title hwp:id="article-title-70">Matching Behavior and the Representation of Value in the Parietal Cortex</article-title>. <source hwp:id="source-69">Science</source> <volume>304</volume>:<fpage>1782</fpage>–<lpage>1787</lpage>.</citation></ref><ref id="c71" hwp:id="ref-71" hwp:rev-id="xref-ref-71-1 xref-ref-71-2"><citation publication-type="book" citation-type="book" ref:id="375642v3.71" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-71"><string-name name-style="western" hwp:sortable="Sutton RS"><surname>Sutton</surname> <given-names>RS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Barto AG"><surname>Barto</surname> <given-names>AG</given-names></string-name> (<year>1990</year>) <chapter-title>Time-derivative models of Pavlovian reinforcement</chapter-title>. In: <source hwp:id="source-70">Learning and computational neuroscience: Foundations of adaptive networks</source> (<person-group person-group-type="editor" hwp:id="person-group-1"><string-name name-style="western" hwp:sortable="Gabriel M"><surname>Gabriel</surname> <given-names>M</given-names></string-name></person-group>, <person-group person-group-type="editor" hwp:id="person-group-2"><string-name name-style="western" hwp:sortable="Moore J"><surname>Moore</surname> <given-names>J</given-names></string-name></person-group>, eds), pp <fpage>497</fpage>–<lpage>537</lpage>. <publisher-loc>Cambridge, MA, US</publisher-loc>: <publisher-name>The MIT Press</publisher-name>.</citation></ref><ref id="c72" hwp:id="ref-72" hwp:rev-id="xref-ref-72-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.72" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-72"><string-name name-style="western" hwp:sortable="Taylor SF"><surname>Taylor</surname> <given-names>SF</given-names></string-name>, <string-name name-style="western" hwp:sortable="Welsh RC"><surname>Welsh</surname> <given-names>RC</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wager TD"><surname>Wager</surname> <given-names>TD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Luan Phan K"><surname>Luan Phan</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fitzgerald KD"><surname>Fitzgerald</surname> <given-names>KD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gehring WJ"><surname>Gehring</surname> <given-names>WJ</given-names></string-name> (<year>2004</year>) <article-title hwp:id="article-title-71">A functional neuroimaging study of motivation and executive function</article-title>. <source hwp:id="source-71">NeuroImage</source> <volume>21</volume>:<fpage>1045</fpage>–<lpage>1054</lpage>.</citation></ref><ref id="c73" hwp:id="ref-73" hwp:rev-id="xref-ref-73-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.73" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-73"><string-name name-style="western" hwp:sortable="Thurley K"><surname>Thurley</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Senn W"><surname>Senn</surname> <given-names>W</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lüscher H-R"><surname>Lüscher</surname> <given-names>H-R</given-names></string-name> (<year>2008</year>) <article-title hwp:id="article-title-72">Dopamine Increases the Gain of the Input-Output Response of Rat Prefrontal Pyramidal Neurons</article-title>. <source hwp:id="source-72">J Neurophysiol</source> <volume>99</volume>:<fpage>2985</fpage>–<lpage>2997</lpage>.</citation></ref><ref id="c74" hwp:id="ref-74" hwp:rev-id="xref-ref-74-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.74" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-74"><string-name name-style="western" hwp:sortable="Tobler PN"><surname>Tobler</surname> <given-names>PN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fiorillo CD"><surname>Fiorillo</surname> <given-names>CD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schultz W"><surname>Schultz</surname> <given-names>W</given-names></string-name> (<year>2005</year>) <article-title hwp:id="article-title-73">Adaptive Coding of Reward Value by Dopamine Neurons</article-title>. <source hwp:id="source-73">Science</source> <volume>307</volume>:<fpage>1642</fpage>–<lpage>1645</lpage>.</citation></ref><ref id="c75" hwp:id="ref-75" hwp:rev-id="xref-ref-75-1 xref-ref-75-2 xref-ref-75-3 xref-ref-75-4"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.75" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-75"><string-name name-style="western" hwp:sortable="Todd MT"><surname>Todd</surname> <given-names>MT</given-names></string-name>, <string-name name-style="western" hwp:sortable="Nystrom LE"><surname>Nystrom</surname> <given-names>LE</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-74">Confounds in multivariate pattern analysis: Theory and rule representation case study</article-title>. <source hwp:id="source-74">NeuroImage</source> <volume>77</volume>:<fpage>157</fpage>–<lpage>165</lpage>.</citation></ref><ref id="c76" hwp:id="ref-76" hwp:rev-id="xref-ref-76-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.76" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-76"><string-name name-style="western" hwp:sortable="Torrubia R"><surname>Torrubia</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ávila C"><surname>Ávila</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Moltó J"><surname>Moltó</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Caseras X"><surname>Caseras</surname> <given-names>X</given-names></string-name> (<year>2001</year>) <article-title hwp:id="article-title-75">The Sensitivity to Punishment and Sensitivity to Reward Questionnaire (SPSRQ) as a measure of Gray’s anxiety and impulsivity dimensions</article-title>. <source hwp:id="source-75">Personal Individ Differ</source> <volume>31</volume>:<fpage>837</fpage>–<lpage>862</lpage>.</citation></ref><ref id="c77" hwp:id="ref-77" hwp:rev-id="xref-ref-77-1 xref-ref-77-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.77" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-77"><string-name name-style="western" hwp:sortable="Tricomi EM"><surname>Tricomi</surname> <given-names>EM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Delgado MR"><surname>Delgado</surname> <given-names>MR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fiez JA"><surname>Fiez</surname> <given-names>JA</given-names></string-name> (<year>2004</year>) <article-title hwp:id="article-title-76">Modulation of Caudate Activity by Action Contingency</article-title>. <source hwp:id="source-76">Neuron</source> <volume>41</volume>:<fpage>281</fpage>–<lpage>292</lpage>.</citation></ref><ref id="c78" hwp:id="ref-78" hwp:rev-id="xref-ref-78-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.78" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-78"><string-name name-style="western" hwp:sortable="Vassena E"><surname>Vassena</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Krebs RM"><surname>Krebs</surname> <given-names>RM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Silvetti M"><surname>Silvetti</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fias W"><surname>Fias</surname> <given-names>W</given-names></string-name>, <string-name name-style="western" hwp:sortable="Verguts T"><surname>Verguts</surname> <given-names>T</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-77">Dissociating contributions of ACC and vmPFC in reward prediction, outcome, and choice</article-title>. <source hwp:id="source-77">Neuropsychologia</source> <volume>59</volume>:<fpage>112</fpage>–<lpage>123</lpage>.</citation></ref><ref id="c79" hwp:id="ref-79" hwp:rev-id="xref-ref-79-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.79" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-79"><string-name name-style="western" hwp:sortable="Viard A"><surname>Viard</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Doeller CF"><surname>Doeller</surname> <given-names>CF</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hartley T"><surname>Hartley</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bird CM"><surname>Bird</surname> <given-names>CM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Burgess N"><surname>Burgess</surname> <given-names>N</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-78">Anterior Hippocampus and Goal-Directed Spatial Decision Making</article-title>. <source hwp:id="source-78">J Neurosci</source> <volume>31</volume>:<fpage>4613</fpage>–<lpage>4621</lpage>.</citation></ref><ref id="c80" hwp:id="ref-80" hwp:rev-id="xref-ref-80-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.80" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-80"><string-name name-style="western" hwp:sortable="Volz KG"><surname>Volz</surname> <given-names>KG</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schubotz RI"><surname>Schubotz</surname> <given-names>RI</given-names></string-name>, <string-name name-style="western" hwp:sortable="von Cramon DY"><surname>von Cramon</surname> <given-names>DY</given-names></string-name> (<year>2003</year>) <article-title hwp:id="article-title-79">Predicting events of varying probability: uncertainty investigated by fMRI</article-title>. <source hwp:id="source-79">NeuroImage</source> <volume>19</volume>:<fpage>271</fpage>–<lpage>280</lpage>.</citation></ref><ref id="c81" hwp:id="ref-81" hwp:rev-id="xref-ref-81-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.81" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-81"><string-name name-style="western" hwp:sortable="Wagenmakers E-J"><surname>Wagenmakers</surname> <given-names>E-J</given-names></string-name> (<year>2007</year>) <article-title hwp:id="article-title-80">A practical solution to the pervasive problems of p values</article-title>. <source hwp:id="source-80">Psychon Bull Rev</source> <volume>14</volume>:<fpage>779</fpage>–<lpage>804</lpage>.</citation></ref><ref id="c82" hwp:id="ref-82" hwp:rev-id="xref-ref-82-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.82" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-82"><string-name name-style="western" hwp:sortable="Walton ME"><surname>Walton</surname> <given-names>ME</given-names></string-name>, <string-name name-style="western" hwp:sortable="Croxson PL"><surname>Croxson</surname> <given-names>PL</given-names></string-name>, <string-name name-style="western" hwp:sortable="Behrens TEJ"><surname>Behrens</surname> <given-names>TEJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kennerley SW"><surname>Kennerley</surname> <given-names>SW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rushworth MFS"><surname>Rushworth</surname> <given-names>MFS</given-names></string-name> (<year>2007</year>) <article-title hwp:id="article-title-81">Adaptive decision making and value in the anterior cingulate cortex</article-title>. <source hwp:id="source-81">NeuroImage</source> <volume>36</volume>:<fpage>T142</fpage>–<lpage>T154</lpage>.</citation></ref><ref id="c83" hwp:id="ref-83" hwp:rev-id="xref-ref-83-1 xref-ref-83-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.83" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-83"><string-name name-style="western" hwp:sortable="Waskom ML"><surname>Waskom</surname> <given-names>ML</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kumaran D"><surname>Kumaran</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gordon AM"><surname>Gordon</surname> <given-names>AM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rissman J"><surname>Rissman</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wagner AD"><surname>Wagner</surname> <given-names>AD</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-82">Frontoparietal Representations of Task Context Support the Flexible Control of Goal-Directed Cognition</article-title>. <source hwp:id="source-82">J Neurosci</source> <volume>34</volume>:<fpage>10743</fpage>–<lpage>10755</lpage>.</citation></ref><ref id="c84" hwp:id="ref-84" hwp:rev-id="xref-ref-84-1 xref-ref-84-2 xref-ref-84-3 xref-ref-84-4 xref-ref-84-5 xref-ref-84-6 xref-ref-84-7 xref-ref-84-8 xref-ref-84-9 xref-ref-84-10 xref-ref-84-11 xref-ref-84-12"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.84" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-84"><string-name name-style="western" hwp:sortable="Wisniewski D"><surname>Wisniewski</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Goschke T"><surname>Goschke</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-83">Similar coding of freely chosen and externally cued intentions in a fronto-parietal network</article-title>. <source hwp:id="source-83">NeuroImage</source> <volume>134</volume>:<fpage>450</fpage>–<lpage>458</lpage>.</citation></ref><ref id="c85" hwp:id="ref-85" hwp:rev-id="xref-ref-85-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.85" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-85"><string-name name-style="western" hwp:sortable="Wisniewski D"><surname>Wisniewski</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Reverberi C"><surname>Reverberi</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Momennejad I"><surname>Momennejad</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kahnt T"><surname>Kahnt</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name> (<year>2015a</year>) <article-title hwp:id="article-title-84">The Role of the Parietal Cortex in the Representation of Task–Reward Associations</article-title>. <source hwp:id="source-84">J Neurosci</source> <volume>35</volume>:<fpage>12355</fpage>–<lpage>12365</lpage>.</citation></ref><ref id="c86" hwp:id="ref-86" hwp:rev-id="xref-ref-86-1 xref-ref-86-2 xref-ref-86-3 xref-ref-86-4 xref-ref-86-5 xref-ref-86-6"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.86" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-86"><string-name name-style="western" hwp:sortable="Wisniewski D"><surname>Wisniewski</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Reverberi C"><surname>Reverberi</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tusche A"><surname>Tusche</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haynes J-D"><surname>Haynes</surname> <given-names>J-D</given-names></string-name> (<year>2015b</year>) <article-title hwp:id="article-title-85">The Neural Representation of Voluntary Task-Set Selection in Dynamic Environments</article-title>. <source hwp:id="source-85">Cereb Cortex</source> <volume>25</volume>:<fpage>4715</fpage>–<lpage>4726</lpage>.</citation></ref><ref id="c87" hwp:id="ref-87" hwp:rev-id="xref-ref-87-1 xref-ref-87-2 xref-ref-87-3 xref-ref-87-4"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.87" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-87"><string-name name-style="western" hwp:sortable="Woolgar A"><surname>Woolgar</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Afshar S"><surname>Afshar</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Williams MA"><surname>Williams</surname> <given-names>MA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rich AN"><surname>Rich</surname> <given-names>AN</given-names></string-name> (<year>2015</year>) <article-title hwp:id="article-title-86">Flexible Coding of Task Rules in Frontoparietal Cortex: An Adaptive System for Flexible Cognitive Control</article-title>. <source hwp:id="source-86">J Cogn Neurosci</source>:<fpage>1</fpage>–<lpage>17</lpage>.</citation></ref><ref id="c88" hwp:id="ref-88" hwp:rev-id="xref-ref-88-1 xref-ref-88-2"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.88" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-88"><string-name name-style="western" hwp:sortable="Woolgar A"><surname>Woolgar</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Golland P"><surname>Golland</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bode S"><surname>Bode</surname> <given-names>S</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-87">Coping with confounds in multivoxel pattern analysis: What should we do about reaction time differences? A comment on <xref ref-type="bibr" rid="c75" hwp:id="xref-ref-75-4" hwp:rel-id="ref-75">Todd, Nystrom &amp; Cohen 2013</xref></article-title>. <source hwp:id="source-87">NeuroImage</source> <volume>98</volume>:<fpage>506</fpage>–<lpage>512</lpage>.</citation></ref><ref id="c89" hwp:id="ref-89" hwp:rev-id="xref-ref-89-1 xref-ref-89-2 xref-ref-89-3 xref-ref-89-4"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.89" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-89"><string-name name-style="western" hwp:sortable="Zhang J"><surname>Zhang</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kriegeskorte N"><surname>Kriegeskorte</surname> <given-names>N</given-names></string-name>, <string-name name-style="western" hwp:sortable="Carlin JD"><surname>Carlin</surname> <given-names>JD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rowe JB"><surname>Rowe</surname> <given-names>JB</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-88">Choosing the Rules: Distinct and Overlapping Frontoparietal Representations of Task Rules for Perceptual Decisions</article-title>. <source hwp:id="source-88">J Neurosci</source> <volume>33</volume>:<fpage>11852</fpage>–<lpage>11862</lpage>.</citation></ref></ref-list><sec sec-type="supplementary-material" hwp:id="sec-42"><title hwp:id="title-50">Supplementary Material</title><fig id="figS1" position="float" orientation="portrait" fig-type="figure" hwp:id="F5" hwp:rev-id="xref-fig-5-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;375642v3/FIGS1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">figS1</object-id><label>Supplementary Figure 1:</label><caption hwp:id="caption-6"><p hwp:id="p-70">Correlation analysis. An additional exploratory analysis was performed to correlate performance, questionnaire measures, and decoding accuracies (baseline task decoding, from the parietal cortex cluster). Depicted are all pairwise correlations between % high reward choices in CR trials (successCR), % high reward chocies in NCR trials (successNCR), motor impulsivity (BIS11motor), attentional impulsivity (BIS11att), non-planning impulsivity (BIS11nonpl), behavioral inhibition (BIS), behavioral approach (BAS), need for cognition (NFC), sensitivity to reward (SR), sensitivity to punishment (SP), and decoding accuracies in the baseline task decoding analysis in the parietal cortex (%acc). The plot was generated using the <italic toggle="yes">corrplot</italic> package in R.</p></caption><graphic xlink:href="375642_figS1" position="float" orientation="portrait" hwp:id="graphic-7"/></fig><p hwp:id="p-71">Despite this descriptive approach, we also tested the strength of these correlations in a Bayesian framework (using <italic toggle="yes">bayes.cor.test</italic> form the BayesianFirstAid package in R). Although our conclusions are based on this correlation analysis, we also report classically estimated correlations and corresponding p-values for the interested reader. We expected successful performance to be correlated with higher need for cognition, lower impulsivity, and higher sensitivity to reward. We also expected task coding to be related to task performance, with better performance related to higher accuracies. Higher accuracies could also be related to lower impulsivity, higher sensitivity to reward, and higher need for cognition. Successful performance was correlated with impulsivity, as measured using the BIS11, r = -.34 (95%CI = [-.62 -.024]; classical estimation r = -.33, p = 0.052), with impulsive subjects being less successful in performing the reversal learning task. The BIS11 further splits impulsivity into three components: attentional, motor, and non-planning impulsivity. The observed correlation was mostly driven by motor impulsivity (r = -.45, 95%CI = [-.70 -.15]; r = -.47, p = 0.004), but not by non-planning (r = -.19, 95%CI = [-.52 .14]; r = -.20, p = 0.24) or attentional impulsivity (r = -.11, 95%CI = [-.45 .02]; r = -.11, p = 0.51). There was no correlation of success with either sensitivity to reward (r = .04, 95%CI = [-.29 .38]; r = .06, p = 0.71), or the need for cognition (r = .26, 95%CI = [-.07 .56]; r = .26, p = 0.11), despite the fact the need for cognition seems to be associated with reward decision-making (<xref ref-type="bibr" rid="c90" hwp:id="xref-ref-90-1" hwp:rel-id="ref-90">Sandra and Otto 2018</xref>). A qualitatively similar pattern was evident for decoding accuracies, extracted during intention maintenance from the parietal cortex. Correlations with impulsivity (r = -.27, 95%CI = [-.57 .07]; r = -.32, p = 0.053), sensitivity to reward (r = -.04, 95%CI = [-.38 .31], r = .17, p = 0.30), and need for cognition (r = .09, 95%CI = [-.24 .41]; r = -.24, p – 0.16) were at least similar numerically to the correlations with task success. Given that the evidence was somewhat weaker in this analysis, results should be interpreted with care however. Overall, task performance and to a lesser degree decoding accuracies seem to be most strongly related to impulsivity, and not to sensitivity to reward or need for cognition. This unexpected link to impulsivity should be addressed directly in future research.</p><fig id="figS2" position="float" orientation="portrait" fig-type="figure" hwp:id="F6" hwp:rev-id="xref-fig-6-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;375642v3/FIGS2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">figS2</object-id><label>Supplementary Figure 2.</label><caption hwp:id="caption-7"><p hwp:id="p-72">Controlling RT-effects in reward outcome coding. We repeated the reward outcome decoding analysis, using a similar first-level GLM to estimate signals (4 regressors: each combination of high vs low reward, contingent vs non-contingent reward, locked to feedback onset). Additionally, we added regressors of non-interest capturing RT-related variance in the data. The rest of the analysis was identical to the reward outcome decoding analysis presented in the main body of the text. Results from the reward outcome decoding analysis (red), and the same analysis with RT-related effects regressed out of the data (blue) are depicted. As can be seen, the overlap between both analyses is substantial. Results depicted at p &lt; 0.05 (FWE, corrected at the voxel level). This indicates that controlling for RT did not strongly alter our results.</p></caption><graphic xlink:href="375642_figS2" position="float" orientation="portrait" hwp:id="graphic-8"/></fig><fig id="figS3" position="float" orientation="portrait" fig-type="figure" hwp:id="F7" hwp:rev-id="xref-fig-7-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;375642v3/FIGS3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F7</object-id><object-id pub-id-type="publisher-id">figS3</object-id><label>Supplementary Figure 3.</label><caption hwp:id="caption-8"><p hwp:id="p-73">Task information in the multiple demand (MD) network. Depicted are task decoding results in the bilateral functional ROIS provided by <xref ref-type="bibr" rid="c91" hwp:id="xref-ref-91-1" hwp:rel-id="ref-91">Fedorenko, Duncan, &amp; Kanwisher (2013)</xref>, specifically the anterior insula (aINS), cerebellum, inferior frontal gyrus pars opercularis (IFGop), intraparietal sulcus (IPS), middle frontal gyrus (MFG), pre-central gyrus (precG), supplementary and pre-supplementary motor area (SMA/preSMA), as well as thalamus. Averaging across all MD regions, we found strong evidence for the presence of task information (2.23%, SEM = 0.61%, BF10 = 69.08, t(34) = 3.63, p &lt; 0.001, <xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-4" hwp:rel-id="F1">Figure 1</xref>). We then tested whether accuracies were higher in CR trials than in NCR trials, using the same analysis as used for the regions identified in the main task decoding analysis. We found no evidence for a higher accuracy in CR, as compared to NCR trials (BF10 = 0.37, t(34) = 0.68, p = 0.24). Furthermore, we found task coding to be contingency-invariant, using a cross-classification approach (2.02%, SEM = 0.67%, BF10 = 14.52, t(34) = 2.97, p = 0.002). Accuracies in the baseline and cross-classification analysis did not differ (BF10 = 5.11, t(34) = 0.40, p = 0.68). This suggests that the MD network encodes tasks in a contingency-invariant fashion, and shows that the current context does not affect task coding in the MD network. This is despite the clear effects contingency has on the coding of reward outcomes.</p></caption><graphic xlink:href="375642_figS3" position="float" orientation="portrait" hwp:id="graphic-9"/></fig><p hwp:id="p-74">Looking at individual MD regions, we found task information in the aINS (2.25%, SEM = 1.00%, BF10 = 3.23, t(34) = 2.24, p = 0.01), IPS (2.83%, SEM = 0.72%, BF10 = 131.02, t(34) = 3.88, p &lt; 0.001), MFG (2.44%, SEM = 0.90%, BF10 = 8.26, t(34) = 2.71, p = 0.005), precentral gyrus (2.48%, SEM = 0.87, BF10 = 9.86, t(34) = 2.79, p = 0.004), but not in the cerebellum (0.85%, SEM = 0.90%, BF10 = 0.44, t(34) = 0.94, p = 0.17), IFGop (2.11%, SEM = 1.02%, BF10 = 2.31, t(34) = 2.06, p = 0.02) SMA/preSMA (1.48%, SEM = 1.07%, BF10 = 0.77, t(34) = 1.37, p = 0.08), and thalamus (0.58%, SEM = 1.06%, BF10 = 0.29, t(34) = 0.54, p = 0.29). None of these regions showed a higher accuracy in CR than in NCR trials (BFs10 &lt;= 0.60, ts(34) &lt; 1.19, ps &gt; 0.12). However, in all of those regions the accuracy in the baseline and xclass analyses was equal (BFs10 &gt;= 3.47, ts(34) &lt; 1.00, ps &gt; 0.32). In sum, we did not find our reward manipulation to affect task coding in the MD network. We did find contingency-invariant task information in this network however. Also, not all parts of the MD network seemed to be encoding tasks in our experiment.</p><ref-list hwp:id="ref-list-2"><ref id="c90" hwp:id="ref-90" hwp:rev-id="xref-ref-90-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.90" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-90"><string-name name-style="western" hwp:sortable="Sandra D.A."><surname>Sandra</surname>, <given-names>D.A.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Otto A.R."><surname>Otto</surname> <given-names>A.R.</given-names></string-name> (<year>2018</year>) <article-title hwp:id="article-title-89">Cognitive Capacity Limitations and Need for Cognition Differentially Predict Reward-Induced Cognitive Effort Expenditure</article-title>. <source hwp:id="source-89">Cognition</source>, <volume>172</volume>: <fpage>101</fpage>–<lpage>6</lpage>.</citation></ref><ref id="c91" hwp:id="ref-91" hwp:rev-id="xref-ref-91-1"><citation publication-type="journal" citation-type="journal" ref:id="375642v3.91" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-91"><string-name name-style="western" hwp:sortable="Fedorenko E"><surname>Fedorenko</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Duncan J"><surname>Duncan</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kanwisher N."><surname>Kanwisher</surname> <given-names>N.</given-names></string-name> <year>2013</year>. <article-title hwp:id="article-title-90">Broad domain generality in focal regions of frontal and parietal cortex</article-title>. <source hwp:id="source-90">P Natl Acad Sci USA</source>. <volume>110</volume>:<fpage>16616</fpage>–<lpage>16621</lpage>.</citation></ref></ref-list></sec></back></article>
