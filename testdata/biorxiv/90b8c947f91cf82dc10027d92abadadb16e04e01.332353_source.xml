<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/332353</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;332353v1</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;332353</article-id><article-id pub-id-type="other" hwp:sub-type="slug">332353</article-id><article-id pub-id-type="other" hwp:sub-type="tag">332353</article-id><article-version>1.1</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Neuroscience" hwp:journal="biorxiv"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">Revealing nonlinear neural decoding by analyzing choices</article-title></title-group><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" hwp:id="contrib-1"><name name-style="western" hwp:sortable="Yang Qianli"><surname>Yang</surname><given-names>Qianli</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref></contrib><contrib contrib-type="author" hwp:id="contrib-2"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-6376-329X</contrib-id><name name-style="western" hwp:sortable="Pitkow Xaq"><surname>Pitkow</surname><given-names>Xaq</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-1" hwp:rel-id="aff-3">3</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0001-6376-329X"/></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2"><label>1</label><institution hwp:id="institution-1">Rice University, Department of Electrical and Computer Engineering</institution></aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1"><label>2</label><institution hwp:id="institution-2">Baylor College of Medicine, Department of Neuroscience</institution></aff><aff id="a3" hwp:id="aff-3" hwp:rev-id="xref-aff-3-1"><label>3</label><institution hwp:id="institution-3">Baylor College of Medicine, Center for Neuroscience and Artificial Intelligence</institution></aff></contrib-group><pub-date pub-type="epub-original" hwp:start="2018"><year>2018</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2018-05-28T08:30:05-07:00">
    <day>28</day><month>5</month><year>2018</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2018-05-28T08:30:05-07:00">
    <day>28</day><month>5</month><year>2018</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2018-05-28T08:37:03-07:00">
    <day>28</day><month>5</month><year>2018</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2018-05-28T08:37:03-07:00">
    <day>28</day><month>5</month><year>2018</year>
  </pub-date><elocation-id>332353</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2018-05-27"><day>27</day><month>5</month><year>2018</year></date>
<date date-type="rev-recd" hwp:start="2018-05-27"><day>27</day><month>5</month><year>2018</year></date>
<date date-type="accepted" hwp:start="2018-05-28"><day>28</day><month>5</month><year>2018</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2018</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/" hwp:id="license-1"><p hwp:id="p-1">This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by/4.0/</ext-link></p></license></permissions><self-uri xlink:href="332353.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2019/pdf/332353v1.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="332353.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2019/abstracts/332353v1/332353v1.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2019/fulltext/332353v1/332353v1.htslp"/><abstract hwp:id="abstract-1"><p hwp:id="p-2">Sensory data about most natural task-relevant variables are confounded by task-irrelevant sensory variations, called nuisance variables. To be useful, the sensory signals that encode the relevant variables must be untangled from the nuisance variables through nonlinear transformations, before the brain can use or decode them to drive behaviors. The information to be untangled is represented in the cortex by the activity of large populations of neurons, constituting a nonlinear population code. Here we provide a new way of thinking about non-linear population codes and nuisance variables, leading to a theory of nonlinear feedforward decoding of neural population activity. This theory obeys fundamental mathematical limitations on information content that are inherited from the sensory periphery, producing redundant codes when there are many more corti-cal neurons than primary sensory neurons. The theory predicts a simple, easily computed quantitative relationship between fluctuating neural activity and behavioral choices if the brain uses its nonlinear population codes optimally: more informative patterns should be more correlated with choices.</p></abstract><counts><page-count count="24"/></counts></article-meta></front><body><sec id="s1" hwp:id="sec-1"><label>1</label><title hwp:id="title-1">Introduction</title><p hwp:id="p-3">How does an animal use, or ‘decode’, the information represented in its brain? When the average responses of some neurons are well-tuned to a stimulus of interest, this is straightforward. In binary discrimination tasks, for example, a choice can be reached simply by a linear weighted sum of these tuned neural responses. Yet real neurons are rarely tuned to precisely one variable: variation in multiple stimulus dimensions influence their responses. As we show below, this can dilute or even abolish the mean tuning to the relevant stimulus. The brain cannot simply use linear computation, nor can we understand neural processing using linear models.</p><p hwp:id="p-4">To see this problem in a simple case, imagine a simplified model of a visual neuron that includes an oriented edge-detecting linear filter followed by additive noise, with a Gabor receptive field like simple cells in primary visual cortex (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1A</xref>). If an edge is presented to this model neuron, different rotation angles will change the overlap, producing a different mean. This neuron is then tuned to orientation.</p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2 xref-fig-1-3 xref-fig-1-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;332353v1/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1:</label><caption hwp:id="caption-1"><p hwp:id="p-5">Simple nonlinear code for orientation induced by two polarities. (<bold>A</bold>) Receptive field for a linear neuron. (<bold>B</bold>) Four example images, each with an orientation <italic toggle="yes">s ∈</italic> [0, <italic toggle="yes">π</italic>) and a polarity <bold><italic toggle="yes">n</italic></bold> <italic toggle="yes">∈</italic> {<italic toggle="yes">-</italic>1, +1}. (<bold>C</bold>) Even though the mean response of the linear neuron is tuned to orientation if polarity were specified (conditional mean, red), the mean response is untuned when the polarity is unknown and could take any value (marginal mean, black). (<bold>D</bold>) Tuning is recovered by the marginal variance even if the polarity is unknown (blue).</p></caption><graphic xlink:href="332353_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-6">However, when the edge has the opposite polarity, with black and white reversed, then the linear response is reversed also. If the two polarities occur with equal frequency, then the positive and negative responses cancel on average. The mean response of this linear neuron to any given orientation is therefore precisely constant, so the model neuron is untuned.</p><p hwp:id="p-7">Notice that stimuli aligned with the neuron’s preferred orientation will generally elicit the highest or lowest response magnitude, depending on polarity. Edges with the smallest response to one polarity will also have the smallest response to its inverse. Thus, even though the mean response of this linear neuron is zero, independent of orientation, the <italic toggle="yes">variance</italic> is tuned.</p><p hwp:id="p-8">To estimate the variance, and thereby the orientation itself, the brain can compute the square of the linear responses. This would allow the brain to estimate the orientation independently from polarity. This is consistent with the well-known energy model of complex cells in primary visual cortex, which use squaring nonlinearities to achieve invariance to the polarity of an edge [<xref rid="c1" ref-type="bibr" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">1</xref>]. We will return to this paradigmatic example of simple nonlinear computation throughout this article.</p><p hwp:id="p-9">Generalizing from this example, we identify edge polarity as a ‘nuisance variable’ — a property in the world that alters how task-relevant stimuli appear but is, itself, irrelevant for the current task (here, perceiving orientation). Other examples of nuisance variables include the illuminant for guessing surface color, position for object recognition, expression for face identification, or pitch for speech recognition. Nuisance variables generally make it hard to extract the task-relevant variables from sense data, which is the central task of perception [<xref rid="c2" ref-type="bibr" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">2</xref>–<xref rid="c5" ref-type="bibr" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">5</xref>]. (Of course, what is a nuisance for one task might be a target variable in another task, and vice versa.)</p><p hwp:id="p-10">The prevailing neuroscience view of this disentangling process is deterministic: the output of a complex (often multi-stage) nonlinear function identifies the variables of interest [<xref rid="c2" ref-type="bibr" hwp:id="xref-ref-2-2" hwp:rel-id="ref-2">2</xref>, <xref rid="c3" ref-type="bibr" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">3</xref>, <xref rid="c6" ref-type="bibr" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">6</xref>]. Here we take a statistical perspective: the brain learns from its history of sensory inputs which statistics of its many sense data can be used to extract the task-relevant variable. In the orientation estimation task above, the relevant statistic was not the mean but the variance.</p><p hwp:id="p-11">Just because a neural population encodes information, it does not mean that the brain decodes it all.Here, <italic toggle="yes">encoding</italic> specifies how the neural responses re-late to the stimulus input; similarly, <italic toggle="yes">decoding</italic> specifies how the neural responses relate to the behavioral out-put. To understand the brain’s computational strategy we must understand how encoding and decoding are related, <italic toggle="yes">i.e.</italic> how the brain uses the information it has. As we will see, our statistical perspective provides a simple way of testing whether the brain’s decoding strategy is efficient, based on whether neural response patterns that are informative about the task-relevant sensory input are also informative about the animal’s behavior in the task.</p></sec><sec id="s2" hwp:id="sec-2"><label>2</label><title hwp:id="title-2">Results</title><sec id="s2a" hwp:id="sec-3"><label>2.1</label><title hwp:id="title-3">Task, stimulus, neural responses, action</title><p hwp:id="p-12">To specify our mathematical framework for nonlinear decoding, we model a task, a stimulus with both relevant and irrelevant variables, neural responses, and behavioral choices.</p><p hwp:id="p-13">In our task, an agent observes a multidimensional stimulus (<italic toggle="yes">s,</italic> <bold><italic toggle="yes">n</italic></bold>) and must act upon one particular relevant aspect of that stimulus, <italic toggle="yes">s</italic>, while ignoring the rest, <bold><italic toggle="yes">n</italic></bold>. The irrelevant stimulus aspects serve as nuisance variables for the task (the letter <bold><italic toggle="yes">n</italic></bold> stands for nuisance).</p><p hwp:id="p-14">Together, these stimulus properties determine a complete sensory input that drives some responses <bold><italic toggle="yes">r</italic></bold> in a population of <italic toggle="yes">N</italic> neurons according to the distribution <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s,</italic> <bold><italic toggle="yes">n</italic></bold>).</p><p hwp:id="p-15">We consider a feedforward processing chain for the brain, in which the neural responses <bold><italic toggle="yes">r</italic></bold> are nonlinearly transformed downstream into other neural responses <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>), which in turn are used to create a perceptual estimate of the relevant stimulus ŝ:
<disp-formula id="eqn1" hwp:id="disp-formula-1">
<alternatives hwp:id="alternatives-1"><graphic xlink:href="332353_eqn1.gif" position="float" orientation="portrait" hwp:id="graphic-2"/></alternatives>
</disp-formula>
</p><p hwp:id="p-16">We model the brain’s estimate as a linear function of the downstream responses <bold><italic toggle="yes">R</italic></bold>. Ultimately these estimates are used to generate an action that the experimenter can observe. Here we assume that the task is local or fine-scale estimation: the subject must directly report its estimate <inline-formula hwp:id="inline-formula-1"><alternatives hwp:id="alternatives-2"><inline-graphic xlink:href="332353_inline1.gif" hwp:id="inline-graphic-1"/></alternatives></inline-formula> for the relevant stimuli near a reference <italic toggle="yes">s</italic><sub>0</sub>. We measure performance by the variance of this estimate,<inline-formula hwp:id="inline-formula-2"><alternatives hwp:id="alternatives-3"><inline-graphic xlink:href="332353_inline2.gif" hwp:id="inline-graphic-2"/></alternatives></inline-formula>.</p><p hwp:id="p-17">We assume that we have recorded activity only from some of the upstream neurons, so we don’t have direct access to <bold><italic toggle="yes">R</italic></bold>, only <bold><italic toggle="yes">r</italic></bold>. Nonetheless we would like to learn something about the downstream computations used in decoding. In this paper we show how to use the statistics of cofluctuations in r and <inline-formula hwp:id="inline-formula-3"><alternatives hwp:id="alternatives-4"><inline-graphic xlink:href="332353_inline3a.gif" hwp:id="inline-graphic-3"/></alternatives></inline-formula> to estimate the quality of nonlinear decoding.</p></sec><sec id="s2b" hwp:id="sec-4" hwp:rev-id="xref-sec-4-1 xref-sec-4-2"><label>2.2</label><title hwp:id="title-4">Signal and noise</title><p hwp:id="p-18">The population response, which we take here to be the spike counts of each neuron in a specified time window, reflects both <italic toggle="yes">signal</italic> and <italic toggle="yes">noise</italic>, where signal is the repeatable stimulus-dependent aspects of the response, and noise reflects trial-to-trial variation. Conventionally in neuroscience, the signal is often thought to be the stimulus dependence of the <italic toggle="yes">average</italic> response, <italic toggle="yes">i.e.</italic> the tuning curve <bold><italic toggle="yes">f</italic></bold> (<italic toggle="yes">s</italic>) = Σ<sub><bold><italic toggle="yes">r</italic></bold></sub> <bold><italic toggle="yes">r</italic></bold> <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>) = ⟨<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>⟩ (angle brackets denote an average over all responses given the condition after the vertical bar). Below we will broaden this conventional definition to allow the signal to include any stimulus-dependent statistical property of the population response.</p><p hwp:id="p-19">Noise is the non-repeatable part of the response, characterized by the variation of responses to a fixed stimulus. It is convenient to distinguish <italic toggle="yes">internal</italic> noise from <italic toggle="yes">external</italic> noise. Internal noise is internal to the animal, and is described by response distribution <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s,</italic> <bold><italic toggle="yes">n</italic></bold>) when everything about the stimulus is fixed. This could also include uncontrolled variation in internal states [<xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">7</xref>–<xref rid="c10" ref-type="bibr" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">10</xref>], like attention, motivation, or wander-ing thoughts. External noise is variability generated by the external world, or nuisance variables, such as the positions of all dots in a random dot kinematogram [<xref rid="c11" ref-type="bibr" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">11</xref>] or the polarity of an edge (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Figure 1</xref>). External noise leads to a neural response distribution <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>) where only the relevant variables are held fixed. Both types of noise can lead to uncertainty about the true stimulus.</p><p hwp:id="p-20">Trial-to-trial variability can of course be correlated across neurons. Neuroscientists often measure two types of second-order correlations: signal correlations and noise correlations [<xref rid="c12" ref-type="bibr" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">12</xref>–<xref rid="c20" ref-type="bibr" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">20</xref>]. Signal correlations mea-sure shared variation in responses <bold><italic toggle="yes">r</italic></bold> averaged over the set of stimuli <italic toggle="yes">s</italic>: <italic toggle="yes">ρ</italic><sub>signal</sub> = Corr(<bold><italic toggle="yes">r</italic></bold>). (Internal) noise correlations measure shared variation that persists even when the stimulus is completely identical, nuisance variables and all: <italic toggle="yes">ρ</italic><sub>noise</sub>(<italic toggle="yes">s,</italic> <bold><italic toggle="yes">n</italic></bold>) = Corr(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s,</italic> <bold><italic toggle="yes">n</italic></bold>).</p><p hwp:id="p-21">For multidimensional stimuli, however, these are only two extremes on a spectrum, depending on how many stimulus aspects are fixed across the trials to be averaged. We propose an intermediate type of correlation: <italic toggle="yes">nuisance correlations</italic>. Here we fix the task-relevant stimulus variable(s) <italic toggle="yes">s</italic>, and average over the nuisance variables <bold><italic toggle="yes">n</italic></bold>: <italic toggle="yes">ρ</italic><sub>nuisance</sub> = Corr(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>). Just as signal correlations don’t mean correlations between signals, nuisance correlations are not correlations between nuisance variables, but rather between neural responses induced by the external noise or nuisance variation. Of course nuisance correlations will be task-dependent, since the task determines which variables are nuisance and which are relevant [<xref rid="c21" ref-type="bibr" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">21</xref>, <xref rid="c22" ref-type="bibr" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">22</xref>].</p><p hwp:id="p-22">Critically, but confusingly, some so-called ‘noise’ correlations and nuisance correlations actually serve as signals. This happens whenever the statistical pattern of trial-by-trial fluctuations depends on the stimulus, and thus contain information. For example, a stimulus-dependent noise covariance functions as a signal. There would still be true noise, <italic toggle="yes">i.e.</italic> irrelevant trial-to-trial variability that makes the signal uncertain, but it would be relegated to higher-order fluctuations [<xref rid="c23" ref-type="bibr" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">23</xref>] such as the variance of the response covariance (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2D</xref>, <xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-1" hwp:rel-id="T1">Table 1</xref>). Stimulus-dependent correlations, principally due to nuisance variation, lead naturally to non-linear population codes, as we will explain below.</p><table-wrap id="tbl1" orientation="portrait" position="float" hwp:id="T1" hwp:rev-id="xref-table-wrap-1-1 xref-table-wrap-1-2 xref-table-wrap-1-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;332353v1/TBL1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">tbl1</object-id><label>Table 1:</label><caption hwp:id="caption-2"><p hwp:id="p-23">Neural response properties relevant for linear and nonlinear codes. In each case, the brain must estimate the stimulus from a single example of neural data, but the relevant function of that data is linear for linear codes, and nonlinear for nonlinear codes. The noise and signal can be quantified by the correspond-ing covariance and stimulus-dependent changes in the corresponding means (<italic toggle="yes">i.e.</italic> the tuning curve slope).</p></caption><graphic xlink:href="332353_tbl1" position="float" orientation="portrait" hwp:id="graphic-3"/></table-wrap><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3 xref-fig-2-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;332353v1/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2:</label><caption hwp:id="caption-3"><p hwp:id="p-24">Nonlinear codes. <bold>A</bold>: Simple example in which a stimulus <italic toggle="yes">s</italic> is the XOR of two neural responses (top). Conditional probabilities <italic toggle="yes">p</italic>(<italic toggle="yes">r</italic><sub>1</sub>, <italic toggle="yes">r</italic><sub>2</sub><italic toggle="yes">|s</italic>) of those responses (bottom) show they are anti-correlated when <italic toggle="yes">s</italic> = +1 (red) and positively correlated when <italic toggle="yes">s</italic> = <italic toggle="yes">-</italic>1 (blue). This stimulus-dependent correlation between responses creates a nonlinear code. The remaining panels show that a similar stimulus-dependent correlation emerges in orientation discrimination with unknown spatial phase. <bold>B</bold>: Gabor images with two orientations and three spatial phases. <bold>C</bold>: Mean responses of linear neurons with Gabor receptive fields are sensitive to orientation when phase is fixed (arrows), but point in different directions for different spatial phases. When phase is an unknown nuisance variable, this mean tuning therefore vanishes (black dot). <bold>D</bold>: The response covariance Cov(<italic toggle="yes">r</italic><sub>1</sub>, <italic toggle="yes">r</italic><sub>2</sub><italic toggle="yes">|s</italic>) between these linear neurons is tuned to orientation even when averaging over spatial phase. Response covariances for four orientations are depicted by ellipses. <bold>E</bold>: A continuous view of the covariance tuning to orientation for a pair of neurons.</p></caption><graphic xlink:href="332353_fig2" position="float" orientation="portrait" hwp:id="graphic-4"/></fig></sec><sec id="s2c" hwp:id="sec-5"><label>2.3</label><title hwp:id="title-5">Nonlinear encoding by neural popula-tions</title><p hwp:id="p-25">Most accounts of neural population codes actually address <italic toggle="yes">linear</italic> codes, in which the mean response is tuned to the variable of interest and completely captures all signal about it [<xref rid="c24" ref-type="bibr" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">24</xref>–<xref rid="c28" ref-type="bibr" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">28</xref>]. We call these codes linear be-cause the neural response property needed to best es-timate the stimulus near a reference (or even infer the entire likelihood of the stimulus, Supplement S1.2) is a linear function of the response. Linear codes for different variables may arise early in sensory processing, or after many stages of computation [<xref rid="c2" ref-type="bibr" hwp:id="xref-ref-2-3" hwp:rel-id="ref-2">2</xref>, <xref rid="c5" ref-type="bibr" hwp:id="xref-ref-5-2" hwp:rel-id="ref-5">5</xref>].</p><p hwp:id="p-26">If any of the relevant signal can only be extracted using nonlinear functions of the neural responses, then we say that the population code is nonlinear.</p><p hwp:id="p-27">It is illuminating to take a statistical view: unlike a linear code, the information is not encoded in mean neural responses but instead by higher-order statistics of responses [<xref rid="c16" ref-type="bibr" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">16</xref>, <xref rid="c29" ref-type="bibr" hwp:id="xref-ref-29-1" hwp:rel-id="ref-29">29</xref>]. These functional and statistical views are naturally linked because estimating higher-order statistics requires nonlinear operations. For instance, information from a stimulus-dependent covariance <italic toggle="yes">Q</italic>(<italic toggle="yes">s</italic>) = ⟨<bold><italic toggle="yes">rr</italic></bold><sup><italic toggle="yes">┬</italic></sup><italic toggle="yes">|s⟩</italic> can be decoded by quadratic operations <bold><italic toggle="yes">R</italic></bold> = <bold><italic toggle="yes">rr</italic></bold><sup><italic toggle="yes">┬</italic></sup>[<xref rid="c22" ref-type="bibr" hwp:id="xref-ref-22-2" hwp:rel-id="ref-22">22</xref>, <xref rid="c30" ref-type="bibr" hwp:id="xref-ref-30-1" hwp:rel-id="ref-30">30</xref>, <xref rid="c31" ref-type="bibr" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">31</xref>]. <xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-2" hwp:rel-id="T1">Table 1</xref> compares the relevant neural response properties for linear and non-linear codes.</p><p hwp:id="p-28">A simple example of a nonlinear code is the exclusive-or (XOR) problem. Given the responses of two binary neurons, r<sub>1</sub> and <italic toggle="yes">r</italic><sub>2</sub>, we would like to de-code the value of a task-relevant signal <italic toggle="yes">s</italic> = XOR(<italic toggle="yes">r</italic><sub>1</sub>, <italic toggle="yes">r</italic><sub>2</sub>) (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2A</xref>). We don’t care about the specific value of <italic toggle="yes">r</italic><sub>1</sub> by itself, and in fact <italic toggle="yes">r</italic><sub>1</sub> alone tells us nothing about <italic toggle="yes">s</italic>. The same is true for <italic toggle="yes">r</italic><sub>2</sub>. The signal is actually re-flected in the trial-by-trial <italic toggle="yes">correlation</italic> between <italic toggle="yes">r</italic><sub>1</sub> and <italic toggle="yes">r</italic><sub>2</sub>: when they are the same then <italic toggle="yes">s</italic> = <italic toggle="yes">-</italic>1, and when they are opposite then <italic toggle="yes">s</italic> = +1. The correlation, and thus the relevant variable <italic toggle="yes">s</italic>, can be estimated nonlin-early from <italic toggle="yes">r</italic><sub>1</sub> and <italic toggle="yes">r</italic><sub>2</sub> as <inline-formula hwp:id="inline-formula-4"><alternatives hwp:id="alternatives-5"><inline-graphic xlink:href="332353_inline3.gif" hwp:id="inline-graphic-4"/></alternatives></inline-formula>.</p><p hwp:id="p-29">Some experiments have reported stimulus-dependent internal noise correlations that depend on the signal, even for a completely fixed stimulus without any nuisance variation [<xref rid="c32" ref-type="bibr" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">32</xref>–<xref rid="c36" ref-type="bibr" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">36</xref>]. Other experiments have turned up evidence for nonlinear population codes by characterizing the nonlinear selectivity directly [<xref rid="c6" ref-type="bibr" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">6</xref>, <xref rid="c37" ref-type="bibr" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">37</xref>, <xref rid="c38" ref-type="bibr" hwp:id="xref-ref-38-1" hwp:rel-id="ref-38">38</xref>].</p><p hwp:id="p-30">More typically, however, stimulus-dependent corre-lations arise from external noise, leading to what we call nuisance correlations. In the introduction (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-3" hwp:rel-id="F1">Figure 1</xref>) we showed a simple orientation estimation example in which fluctuations of an unknown contrast eliminate the orientation tuning of mean responses, relegating the tuning to variances. <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Figure 2B</xref>–E shows a slightly more sophisticated version of this example, where instead of two image polarities, we introduce spatial phase as a continuous nuisance variable. This again eliminates mean tuning, but introduces nuisance covariances that are orientation tuned.</p><p hwp:id="p-31">One might object that although the nuisance covariance is tuned to orientation, a subject cannot compute the covariance on a single trial because it does not experience all possible nuisance variables to average over. This objection stems from a conceptual error that conflates the tuning (signal) with the raw sense data (signal+noise). In linear codes, the subject does not have access to the tuned mean response ⟨<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>⟩, just a noisy single-trial version of the mean, namely <bold><italic toggle="yes">r</italic></bold>. Analogously, the subject does not need access to the tuned covariance, just a noisy single-trial version of the covariance, <bold><italic toggle="yes">rr</italic></bold><sup><italic toggle="yes">⊤</italic></sup>(<xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-3" hwp:rel-id="T1">Table 1</xref>). In this simple example, the nuisance variable of spatial phase ensures that quadratic statistics contains relevant information.</p></sec><sec id="s2d" hwp:id="sec-6"><label>2.4</label><title hwp:id="title-6">Decoding and choice correlations</title><p hwp:id="p-32">To study how neural information is used or decoded, past studies have examined whether neurons that are sensitive to sensory inputs also reflect an animal’s behavioral outputs or choices [<xref rid="c39" ref-type="bibr" hwp:id="xref-ref-39-1" hwp:rel-id="ref-39">39</xref>–<xref rid="c47" ref-type="bibr" hwp:id="xref-ref-47-1" hwp:rel-id="ref-47">47</xref>]. However, this choice-related activity is hard to interpret, because it may reflect decoding of the recorded neurons, or merely correlations between them and other neurons that are decoded instead [<xref rid="c48" ref-type="bibr" hwp:id="xref-ref-48-1" hwp:rel-id="ref-48">48</xref>].</p><p hwp:id="p-33">In principle, we could discount such indirect relationships with complete recordings of all neural activity. This is currently impractical for most animals, and even if we could record from all neurons simultaneously, data limitations would prevent us from fully disambiguating how neural activities directly influence behavior.</p><p hwp:id="p-34">To understand key principles of neural computation, however, we may not care about all detailed patterns of decoding weights and their underlying synaptic connectivity. Instead we may want to know only certain properties of the brain’s strategies. One important property is the efficiency with which the brain decodes available neural information as it generates an animal’s choices.</p><p hwp:id="p-35">Conveniently, testable predictions about choice-related activity can reveal the brain’s decoding efficiency, in the case of linear codes [<xref rid="c28" ref-type="bibr" hwp:id="xref-ref-28-2" hwp:rel-id="ref-28">28</xref>]. Next we review these predictions, and then generalize them to nonlin-ear codes.</p></sec><sec id="s2e" hwp:id="sec-7"><label>2.5</label><title hwp:id="title-7">Choice correlations predicted for opti-mal linear decoding</title><p hwp:id="p-36">We define ‘choice correlation’ <italic toggle="yes">C</italic><sub><italic toggle="yes">r</italic></sub> <sub><italic toggle="yes">k</italic></sub> as the correlation coefficient between the response <italic toggle="yes">r</italic><sub><italic toggle="yes">k</italic></sub> of neuron <italic toggle="yes">k</italic> and the stimulus estimate (which we view as a continuous ‘choice’) <inline-formula hwp:id="inline-formula-5"><alternatives hwp:id="alternatives-6"><inline-graphic xlink:href="332353_inline5.gif" hwp:id="inline-graphic-5"/></alternatives></inline-formula>, given a fixed stimulus <italic toggle="yes">s</italic>:
<disp-formula id="eqn2" hwp:id="disp-formula-2">
<alternatives hwp:id="alternatives-7"><graphic xlink:href="332353_eqn2.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives>
</disp-formula>
</p><p hwp:id="p-37">This choice correlation is a conceptually simpler and more convenient measure than the more conventional statistic, ‘choice probability’ [<xref rid="c49" ref-type="bibr" hwp:id="xref-ref-49-1" hwp:rel-id="ref-49">49</xref>], but it has almost identical properties (Methods 4.2) [<xref rid="c28" ref-type="bibr" hwp:id="xref-ref-28-3" hwp:rel-id="ref-28">28</xref>, <xref rid="c48" ref-type="bibr" hwp:id="xref-ref-48-2" hwp:rel-id="ref-48">48</xref>].</p><p hwp:id="p-38">Intuitively, if an animal is decoding its neural information efficiently, then those neurons encoding more information should be more correlated with the choice. Mathematically, one can show that choice correlations indeed have this property when decoding is optimal [<xref rid="c28" ref-type="bibr" hwp:id="xref-ref-28-4" hwp:rel-id="ref-28">28</xref>]:
<disp-formula id="eqn3" hwp:id="disp-formula-3" hwp:rev-id="xref-disp-formula-3-1 xref-disp-formula-3-2">
<alternatives hwp:id="alternatives-8"><graphic xlink:href="332353_eqn3.gif" position="float" orientation="portrait" hwp:id="graphic-6"/></alternatives>
</disp-formula>
where <italic toggle="yes">J</italic> and <italic toggle="yes">J</italic><sub><italic toggle="yes">rk</italic></sub> are, respectively, the linear Fisher Information [<xref rid="c23" ref-type="bibr" hwp:id="xref-ref-23-2" hwp:rel-id="ref-23">23</xref>] based on the entire population <bold><italic toggle="yes">r</italic></bold> or on neuron <italic toggle="yes">k</italic>’s response <italic toggle="yes">r</italic><sub><italic toggle="yes">k</italic></sub> (Methods 4.2). This relation-ship holds for a locally optimal linear estimator,
<disp-formula id="eqn4" hwp:id="disp-formula-4" hwp:rev-id="xref-disp-formula-4-1">
<alternatives hwp:id="alternatives-9"><graphic xlink:href="332353_eqn4.gif" position="float" orientation="portrait" hwp:id="graphic-7"/></alternatives>
</disp-formula>
regardless of the structure of noise correlations.</p><p hwp:id="p-39">Another way to test for optimal linear decoding would be to measure whether the animal’s behavioral discriminability matches the discriminability for an ideal observer of the neural population response. Yet this approach is not feasible, as it requires one to measure simultaneous responses of many, or even all, relevant neurons. In contrast, the optimality test (<xref ref-type="disp-formula" rid="eqn3" hwp:id="xref-disp-formula-3-1" hwp:rel-id="disp-formula-3">Eq 3</xref>) requires measuring only single neuron responses, which is vastly easier. Neural recordings in the vestibular system are consistent with optimal decoding according to this prediction [<xref rid="c28" ref-type="bibr" hwp:id="xref-ref-28-5" hwp:rel-id="ref-28">28</xref>].</p></sec><sec id="s2f" hwp:id="sec-8"><label>2.6</label><title hwp:id="title-8">Nonlinear choice correlations for optimal decoding</title><p hwp:id="p-40">However, when nuisance variables wash out the mean tuning of neuronal responses, we may well find that a single neuron has both zero choice correlation and zero information about the stimulus. The optimality test would thus be inconclusive.</p><p hwp:id="p-41">This situation is exactly the same one that gives rise to nonlinear codes. A natural generalization of <xref ref-type="disp-formula" rid="eqn3" hwp:id="xref-disp-formula-3-2" hwp:rel-id="disp-formula-3">Equation 3</xref> can reveal the quality of neural computation on nonlinear codes. We simply define a ‘<italic toggle="yes">nonlinear</italic> choice correlation’ between the stimulus estimate <inline-formula hwp:id="inline-formula-6"><alternatives hwp:id="alternatives-10"><inline-graphic xlink:href="332353_inline4.gif" hwp:id="inline-graphic-6"/></alternatives></inline-formula> and non-linear functions of neural activity <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>):
<disp-formula id="eqn5" hwp:id="disp-formula-5" hwp:rev-id="xref-disp-formula-5-1">
<alternatives hwp:id="alternatives-11"><graphic xlink:href="332353_eqn5.gif" position="float" orientation="portrait" hwp:id="graphic-8"/></alternatives>
</disp-formula>
</p><p hwp:id="p-42">(Methods 4.2), where <italic toggle="yes">R</italic><sub><italic toggle="yes">k</italic></sub>(<bold><italic toggle="yes">r</italic></bold>) is a nonlinear function of the neural responses. If the brain optimally decodes the information encoded in the nonlinear statistics of neural activity, according to the simple nonlinear extension to <xref ref-type="disp-formula" rid="eqn4" hwp:id="xref-disp-formula-4-1" hwp:rel-id="disp-formula-4">Eq 4</xref>,
<disp-formula id="eqn6" hwp:id="disp-formula-6">
<alternatives hwp:id="alternatives-12"><graphic xlink:href="332353_eqn6.gif" position="float" orientation="portrait" hwp:id="graphic-9"/></alternatives>
</disp-formula>
then the nonlinear choice correlation satisfies the equation
<disp-formula id="eqn7" hwp:id="disp-formula-7" hwp:rev-id="xref-disp-formula-7-1 xref-disp-formula-7-2 xref-disp-formula-7-3 xref-disp-formula-7-4 xref-disp-formula-7-5 xref-disp-formula-7-6 xref-disp-formula-7-7 xref-disp-formula-7-8 xref-disp-formula-7-9 xref-disp-formula-7-10 xref-disp-formula-7-11 xref-disp-formula-7-12 xref-disp-formula-7-13">
<alternatives hwp:id="alternatives-13"><graphic xlink:href="332353_eqn7.gif" position="float" orientation="portrait" hwp:id="graphic-10"/></alternatives>
</disp-formula>
where <italic toggle="yes">J</italic><sub><italic toggle="yes">R</italic></sub> <sub><italic toggle="yes">k</italic></sub>(<italic toggle="yes">r</italic>) is the linear Fisher Information in <italic toggle="yes">R</italic><sub><italic toggle="yes">k</italic></sub>(<bold><italic toggle="yes">r</italic></bold>) (Methods 4.2.2).</p><p hwp:id="p-43">As an example of this relationship, we return to the orientation example. Here the response covariance Σ(<italic toggle="yes">s</italic>) = Cov(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>) depends on the stimulus, but the mean <bold><italic toggle="yes">f</italic></bold> = ⟨ <bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic> ⟩ = ⟨ <bold><italic toggle="yes">r</italic></bold> ⟩ does not. In this model, optimally decoded neurons would have no linear correlation with behavioral choice. Instead, the choice should be driven by the product of the neural responses, <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) = vec(<bold><italic toggle="yes">rr</italic></bold> <sup><italic toggle="yes">⊤</italic></sup>), where vec(<italic toggle="yes">·</italic>) is a vectorization that flattens an array into a one-dimensional list of numbers. Such quadratic computation is what the energy model for complex cells is thought to accomplish for phase-invariant orientation coding [<xref rid="c1" ref-type="bibr" hwp:id="xref-ref-1-2" hwp:rel-id="ref-1">1</xref>]. <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure 3</xref> shows linear and nonlinear choice correlations for pairs of neurons, defined as <italic toggle="yes"><inline-formula hwp:id="inline-formula-7"><alternatives hwp:id="alternatives-14"><inline-graphic xlink:href="332353_inline6.gif" hwp:id="inline-graphic-7"/></alternatives></inline-formula></italic>. When decoding is linear, linear choice correlations are strong while nonlinear choice correlations are near zero (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Figure 3A,B</xref>). When the decoding is quadratic, here mediated by an intermediate layer that multiplies pairs of neural activity, the nonlinear choice correlations are strong while the linear ones are insignificant (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Figure 3C,D</xref>).</p><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;332353v1/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3:</label><caption hwp:id="caption-4"><p hwp:id="p-44">Linear and nonlinear choice correlations successfully distinguish network structure. A linearly decoded population (<bold>A</bold>) produces nonzero linear choice correlations (<bold>B</bold>), while the nonlinear choice correlations are randomly distributed around zero. The situation is reverse for a nonlinear network (<bold>C</bold>), with insignificant linear choice correlations but strong nonlinear ones (<bold>D</bold>). Here the network implements a quadratic nonlinearity, so the relevant choice correlations are quadratic as well, <italic toggle="yes">C</italic><sub><italic toggle="yes">jk</italic></sub> = Corr(<italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">k</italic></sub>, <italic toggle="yes">c</italic>).</p></caption><graphic xlink:href="332353_fig3" position="float" orientation="portrait" hwp:id="graphic-11"/></fig></sec><sec id="s2g" hwp:id="sec-9"><label>2.7</label><title hwp:id="title-9">Which nonlinearity?</title><p hwp:id="p-45">If the brain’s decoder optimally uses all available information, choice correlations will obey the prediction of <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-1" hwp:rel-id="disp-formula-7">Eq. 7</xref> even if the specific nonlinearities used by the brain differ from those selected for evaluating choice correlations (Methods 4.2.3). The prediction will hold as long as the brain’s nonlinearity can be expressed as a linear combination of the tested nonlinearities (Methods 4.2.3). <xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Figure 4</xref> shows a situation where information is encoded by quadratic and cubic sufficient statistics of neural responses, while a simulated brain decodes them near-optimally using a generic neural network rather than a set of nonlinearities matched to those sufficient statistics. Despite this mismatch we can successfully identify that the brain is near-optimal by applying <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-2" hwp:rel-id="disp-formula-7">Eq 7</xref>, even without knowing the simulated brain’s true nonlinear transformations.</p><fig id="fig4" position="float" fig-type="figure" orientation="portrait" hwp:id="F4" hwp:rev-id="xref-fig-4-1 xref-fig-4-2 xref-fig-4-3 xref-fig-4-4 xref-fig-4-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;332353v1/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4:</label><caption hwp:id="caption-5"><p hwp:id="p-46">Identifying optimal nonlinear decoding by a generic neural network using nonlinear choice correlation. <bold>A</bold>: Responses encode stimulus information in polynomial sufficient statistics up to cubic, simulated brain using ReLu nonlinearities trained to extract that information <bold>B</bold>: Simulated brain using matched pol nomial nonlinearities to extract the information from responses. <bold>C,D</bold>: Choice correlations with polynomial nonlinear statistics show the network computations are consistent with optimal nonlinear decoding, regardless if the tested statistics match(Network <bold>B</bold>) or not match(Network <bold>A</bold>) the actual decoder(Methods 4.2.3).</p></caption><graphic xlink:href="332353_fig4" position="float" orientation="portrait" hwp:id="graphic-12"/></fig></sec><sec id="s2h" hwp:id="sec-10"><label>2.8</label><title hwp:id="title-10">Redundant codes</title><p hwp:id="p-47">It might seem unlikely that the brain uses optimal, or even near-optimal, nonlinear decoding. Even if it does, there are an enormous number of high-order statistics for neural responses, so the information content in any one statistic could be tiny compared to the total information in all of them. For example, with <italic toggle="yes">N</italic> neurons there are on the order of <italic toggle="yes">N</italic> <sup>2</sup> quadratic statistics, <italic toggle="yes">N</italic> <sup>3</sup> cubic statistics, and so on. With so many statistics contributing information, the choice correlation for any single one would then be tiny according to the ratio in <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-3" hwp:rel-id="disp-formula-7">Eq 7</xref>, and would be indistinguishable from zero with reasonable amounts of data. Past theoretical studies have described nonlinear (specifically, quadratic) codes with extensive information that grows proportionally with the number of neurons [<xref rid="c16" ref-type="bibr" hwp:id="xref-ref-16-2" hwp:rel-id="ref-16">16</xref>, <xref rid="c30" ref-type="bibr" hwp:id="xref-ref-30-2" hwp:rel-id="ref-30">30</xref>]. This would in-deed imply immeasurably small choice correlations for large, optimally decoded populations.</p><p hwp:id="p-48">A resolution to these concerns is information-limiting correlations [<xref rid="c27" ref-type="bibr" hwp:id="xref-ref-27-1" hwp:rel-id="ref-27">27</xref>]. The past studies that derive extensive nonlinear information treat large cortical populations in isolation from the smaller sensory population that would naturally provide its input [<xref rid="c16" ref-type="bibr" hwp:id="xref-ref-16-3" hwp:rel-id="ref-16">16</xref>, <xref rid="c30" ref-type="bibr" hwp:id="xref-ref-30-3" hwp:rel-id="ref-30">30</xref>]. However, when a network inherits information from a much smaller input population, the expanded neural code becomes highly redundant: the brain cannot have more information than it receives. Noise in the input is processed by the same pathway as the signal, and this generates noise correlations that can never be averaged away [<xref rid="c27" ref-type="bibr" hwp:id="xref-ref-27-2" hwp:rel-id="ref-27">27</xref>].</p><p hwp:id="p-49">Previous work [<xref rid="c27" ref-type="bibr" hwp:id="xref-ref-27-3" hwp:rel-id="ref-27">27</xref>] characterized linear information-limiting correlations for fine discrimination tasks by de-composing the noise covariance into <inline-formula hwp:id="inline-formula-8"><alternatives hwp:id="alternatives-15"><inline-graphic xlink:href="332353_inline10a.gif" hwp:id="inline-graphic-8"/></alternatives></inline-formula>, where <italic toggle="yes">∈</italic> is the variance of the information-limiting com-ponent and Σ<sub>0</sub> is noise that can be averaged away with many neurons.</p><p hwp:id="p-50">For <italic toggle="yes">nonlinear</italic> population codes, it is not just the mean that encodes the signal, <bold><italic toggle="yes">f</italic></bold> (<italic toggle="yes">s</italic>) = ⟨ <bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic> ⟩, but rather the nonlinear statistics <bold><italic toggle="yes">F</italic></bold> (<italic toggle="yes">s</italic>) = ⟨ <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>)<italic toggle="yes">|s</italic> ⟩. Likewise, the noise does not comprise only second-order covariance of <bold><italic toggle="yes">r</italic></bold>, Cov(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>), but rather the second-order covariance of the relevant nonlinear statistics, Γ = Cov(<bold><italic toggle="yes">R</italic></bold><italic toggle="yes">|s</italic>) (<xref rid="s2b" ref-type="sec" hwp:id="xref-sec-4-1" hwp:rel-id="sec-4">Section 2.2</xref>). Analogous to the linear case, these correlations can be locally decomposed as
<disp-formula id="eqn8" hwp:id="disp-formula-8">
<alternatives hwp:id="alternatives-16"><graphic xlink:href="332353_eqn8.gif" position="float" orientation="portrait" hwp:id="graphic-13"/></alternatives>
</disp-formula>
where <italic toggle="yes">∈</italic> is again the variance of the information-limiting component, and Γ<sub>0</sub> is any other covariance which can be averaged away in large populations. The information-limiting noise bounds the estimator variance <italic toggle="yes"><inline-formula hwp:id="inline-formula-9"><alternatives hwp:id="alternatives-17"><inline-graphic xlink:href="332353_inline7.gif" hwp:id="inline-graphic-9"/></alternatives></inline-formula></italic> to no smaller than <italic toggle="yes">∈</italic> even with optimal decoding.</p><p hwp:id="p-51">Neither additional neurons nor additional decoded statistics can improve performance beyond this bound. As a direct consequence, when there are many fewer sensory inputs than cortical neurons, many distinct statistics <italic toggle="yes">R</italic><sub><italic toggle="yes">k</italic></sub>(<bold><italic toggle="yes">r</italic></bold>) will carry redundant information. Un-der these conditions, many ratios <italic toggle="yes">J</italic><sub><italic toggle="yes">Rk</italic></sub>/<italic toggle="yes">J</italic>. (<xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-4" hwp:rel-id="disp-formula-7">Eq 7</xref>) can be measurably large even for optimal nonlinear decoding (<xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Figure 5</xref>).</p><fig id="fig5" position="float" fig-type="figure" orientation="portrait" hwp:id="F5" hwp:rev-id="xref-fig-5-1 xref-fig-5-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;332353v1/FIG5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">fig5</object-id><label>Figure 5:</label><caption hwp:id="caption-6"><p hwp:id="p-52">Information-limiting noise makes a network more robust to suboptimal decoding. (Left) A sim-ulated optimal decoder produces choice correlations that match our optimal predictions (blue, on diagonal). In contrast, a suboptimal decoder, such as one that is blind to higher-order correlations (<bold><italic toggle="yes">w</italic></bold> <italic toggle="yes">∝</italic> <bold><italic toggle="yes">F</italic></bold> ′), exhibits a suboptimal pattern of choice correlations (red, off-diagonal) in the presence of noise Γ<sub>0</sub> that permits the population to have extensive information. (Right) When information is limited, the same decoding weights are less detrimental, and thus exhibit a similar pattern of choice correlations as an optimal decoder.</p></caption><graphic xlink:href="332353_fig5" position="float" orientation="portrait" hwp:id="graphic-14"/></fig></sec><sec id="s2i" hwp:id="sec-11"><label>2.9</label><title hwp:id="title-11">Decoding efficiency revealed by choice correlations</title><p hwp:id="p-53">Even if decoding is not strictly optimal, <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-5" hwp:rel-id="disp-formula-7">Eq. 7</xref> can be satisfied due to information-limiting correlations. Decoders that seem substantially suboptimal because they fail to avoid the largest noise components in Γ<sub>0</sub> can be nonetheless dominated by the bound from information-limiting correlations. This will occur whenever the variability from suboptimally decoding Γ<sub>0</sub> is smaller than <italic toggle="yes">∈</italic>. Just as we can decompose the nonlinear noise correlations into information-limiting and other parts, we can decompose nonlinear choice correlations into corresponding parts as well, with the result that
<disp-formula id="eqn9" hwp:id="disp-formula-9">
<alternatives hwp:id="alternatives-18"><graphic xlink:href="332353_eqn9.gif" position="float" orientation="portrait" hwp:id="graphic-15"/></alternatives>
</disp-formula>
where <italic toggle="yes">ζ</italic><sub><italic toggle="yes">R</italic></sub> depends on the particular type of suboptimal decoding (Supporting Information S7). The slope <italic toggle="yes">α</italic> between choice correlations and those predicted from optimality is given by the fraction of estimator variance explained by information-limiting noise, <italic toggle="yes"><inline-formula hwp:id="inline-formula-10"><alternatives hwp:id="alternatives-19"><inline-graphic xlink:href="332353_inline8.gif" hwp:id="inline-graphic-10"/></alternatives></inline-formula></italic>. This slope therefore provides an estimate of the efficiency of the brain’s decoding.</p><p hwp:id="p-54"><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-2" hwp:rel-id="F5">Figure 5</xref> shows an example of a decoder that would be highly suboptimal without considering redundancy, but is nonetheless close to optimal when information limits are inherited.</p><p hwp:id="p-55">In realistically redundant models that have more cortical neurons than sensory neurons, many decoders could be near-optimal, as we recently discovered in experimental data for a linear population code [<xref rid="c28" ref-type="bibr" hwp:id="xref-ref-28-6" hwp:rel-id="ref-28">28</xref>]. However, even in redundant codes there may be substantial inefficiencies, especially for unnatural tasks [<xref rid="c50" ref-type="bibr" hwp:id="xref-ref-50-1" hwp:rel-id="ref-50">50</xref>].</p></sec></sec><sec id="s3" hwp:id="sec-12"><label>3</label><title hwp:id="title-12">Discussion</title><p hwp:id="p-56">This study introduced a theory of nonlinear population codes, grounded in the natural computational task of separating relevant and irrelevant variables. The theory considers both encoding and decoding — how stimuli drive neurons, and how neurons drive behavioral choices. It showed how correlated fluctuations between neural activity and behavioral choices could reveal properties of the brain’s decoding. Unlike previous theories [<xref rid="c16" ref-type="bibr" hwp:id="xref-ref-16-4" hwp:rel-id="ref-16">16</xref>, <xref rid="c30" ref-type="bibr" hwp:id="xref-ref-30-4" hwp:rel-id="ref-30">30</xref>], ours remains consistent with bio-logical constraints due to the large cortical expansion of sensory representations by incorporating redundancy through information-limiting correlations. Crucially, this theory provides a remarkably simple test to determine if downstream nonlinear computation decodes all that is encoded.</p><p hwp:id="p-57">Alternative methods to estimate whether animals use their information efficiently rely upon comparing behavioral performance to performance of an ideal observer that can access the entire population. Even with impressive advances in neurotechnology, this challenge remains out of reach for large populations. In contrast, our proposed method to test for optimal decoding has a vastly lower experimental burden. It requires only that a few cells be recorded simultaneously while an animal performs a fine estimation or discrimination task.</p><p hwp:id="p-58">On the other hand, this simple test does not offer a complete description of neural transformations.</p><p hwp:id="p-59">It instead tests one important hypothesis about their functional role — that the brain performs optimal de-coding. The theory also provides a practical way of estimating decoding efficiency. The brain may not be optimal, but instead may be satisfied by a more modest decoding efficiency. In this case, more work is needed to understand what suboptimalities the brain tolerates for satisfactory performance.</p><sec id="s3a" hwp:id="sec-13"><label>3.1</label><title hwp:id="title-13">Which nonlinearities should we test?</title><p hwp:id="p-60">If all neural signals are decoded optimally, then all choice correlations for any function of those signals should also be consistent with optimal decoding, since they contain the same information. Yet for the wrong or incomplete nonlinearities that do not disentangle the task-relevant variables from the nuisance variables, the test may be inconclusive, just as it was for linear decod-ing of a nonlinear code (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-2" hwp:rel-id="F4">Figure 4</xref>): the chosen nonlinear functions may not extract linearly decodable information nor have any choice correlation.</p><p hwp:id="p-61">The optimal nonlinearities would be those that collectively extract the sufficient statistics about the relevant stimulus, which will depend on both the task and the nuisance variables. In complex tasks, like recognizing object from images with many nuisance variables, most of the relevant information lives in higher-order statistics, and therefore require more complex nonlinearities to extract. In such high-dimensional cases, our proposed test is unlikely to be useful. This is because our method expresses stimulus estimates as sums of nonlinear functions, and while that is universal in principle [<xref rid="c51" ref-type="bibr" hwp:id="xref-ref-51-1" hwp:rel-id="ref-51">51</xref>], that is not a compact way to express the complex nonlinearities of deep networks. Alternatively, with good guidance from trained neural network models our method could potentially judge whether those nonlinearities provide a good description of neural decoding. This decoding perspective would complementing studies that argue for a good match between encoding by convolutional neural networks [<xref rid="c6" ref-type="bibr" hwp:id="xref-ref-6-3" hwp:rel-id="ref-6">6</xref>].</p><p hwp:id="p-62">The best condition to apply our optimality test is in tasks of modest complexity but still possessing fundamentally nonlinear structure. Some interesting examples where our test could have practical relevance include motion detection using photoreceptors [<xref rid="c52" ref-type="bibr" hwp:id="xref-ref-52-1" hwp:rel-id="ref-52">52</xref>], visual search with distractors (XOR-type tasks) [<xref rid="c31" ref-type="bibr" hwp:id="xref-ref-31-2" hwp:rel-id="ref-31">31</xref>, <xref rid="c53" ref-type="bibr" hwp:id="xref-ref-53-1" hwp:rel-id="ref-53">53</xref>], sound localization in early auditory processing before the inferior colliculus [<xref rid="c54" ref-type="bibr" hwp:id="xref-ref-54-1" hwp:rel-id="ref-54">54</xref>], or context switching in higher-level cortex [<xref rid="c55" ref-type="bibr" hwp:id="xref-ref-55-1" hwp:rel-id="ref-55">55</xref>].</p><p hwp:id="p-63">Our test for optimal nonlinear decoding really amounts to testing for optimal linear decoding of non-linear functions of recorded neural data. If we had access to some putative downstream neurons that computed these nonlinear functions, we could just test whether the brain linearly decoded those neurons optimally. Yet that would circumvent the most interesting and crucial nonlinear aspects of neural computation. Alternatively, if we could record from neurons at different levels of the processing chain, we could try to characterize that nonlinear recoding between them directly, without reference to a behavioral choice. But this would not easily relate these computations to their functional role. The method proposed here allows us to skip these intermediate steps and directly test the optimality of all accumulated downstream nonlinearities.</p></sec><sec id="s3b" hwp:id="sec-14"><label>3.2</label><title hwp:id="title-14">Nonlinear decoding or switched linear decoding?</title><p hwp:id="p-64">Could the brain avoid nonlinear decoding just by switching between different linear decoders depending on the current nuisance variable <bold><italic toggle="yes">n</italic></bold>, so that <inline-formula hwp:id="inline-formula-11"><alternatives hwp:id="alternatives-20"><inline-graphic xlink:href="332353_inline9.gif" hwp:id="inline-graphic-11"/></alternatives></inline-formula> The switching variable itself would have to be inferred from sensory data, which requires marginalizing over the task variable; this takes us back to the original problem, but with task and nuisance variables reversed. Even so, switched linear decoding would actually be equivalent to nonlinear decoding whenever <inline-formula hwp:id="inline-formula-12"><alternatives hwp:id="alternatives-21"><inline-graphic xlink:href="332353_inline10.gif" hwp:id="inline-graphic-12"/></alternatives></inline-formula> is estimated from neural responses: <inline-formula hwp:id="inline-formula-13"><alternatives hwp:id="alternatives-22"><inline-graphic xlink:href="332353_inline11.gif" hwp:id="inline-graphic-13"/></alternatives></inline-formula>. A discrimination task with a changing class bound ary [<xref rid="c12" ref-type="bibr" hwp:id="xref-ref-12-2" hwp:rel-id="ref-12">12</xref>, <xref rid="c56" ref-type="bibr" hwp:id="xref-ref-56-1" hwp:rel-id="ref-56">56</xref>, <xref rid="c57" ref-type="bibr" hwp:id="xref-ref-57-1" hwp:rel-id="ref-57">57</xref>] is, in principle, a nonlinear task. But if the class boundary is changed too slowly, perhaps changing only on different days, then the brain may well re-learn its weights rather than performing some nonlinear decoding of recent activity. A better experi-mental design for revealing nonlinear computation for task context would be randomly changing the tasks, either cued [<xref rid="c58" ref-type="bibr" hwp:id="xref-ref-58-1" hwp:rel-id="ref-58">58</xref>] or even uncued [<xref rid="c55" ref-type="bibr" hwp:id="xref-ref-55-2" hwp:rel-id="ref-55">55</xref>], on a short enough time scale that the recent neural activity affects the class boundary.</p></sec><sec id="s3c" hwp:id="sec-15"><label>3.3</label><title hwp:id="title-15">Limitations of the approach</title><p hwp:id="p-65">For efficient decoding in a learned task, the optimality test (7) is necessary but not sufficient. If the brain neglects some of informative sufficient statistics, and we don’t test these neglected statistics either, then we could find the brain is consistent with our optimal de-coding test, yet still be suboptimal. Only if the test is passed for <italic toggle="yes">all</italic> statistics will the test be conclusive. For an extreme example, a single neuron might pass the test, but if other neurons don’t, then the brain is not using its information well. On a broader scale, one might find that all individual responses <italic toggle="yes">r</italic><sub><italic toggle="yes">k</italic></sub> pass the optimality test, while products of responses <italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">k</italic></sub> fail. This would be consistent with linear information being used well while distinct quadratic information is present but unused; on the other hand this outcome would not be consistent with quadratic statistics that are uninformative but decoded anyway, since that would increase the output variance beyond that expected from the linear information. In future work we will demonstrate how we can use nonlinear choice correlations to identify properties of suboptimal decoders [<xref rid="c59" ref-type="bibr" hwp:id="xref-ref-59-1" hwp:rel-id="ref-59">59</xref>].</p><p hwp:id="p-66">Our approach is currently limited to feedforward processing, which unquestionably oversimplifies cortical processing. Nonetheless, feedforward models do a fair job of capturing the representational structure of the brain [<xref rid="c6" ref-type="bibr" hwp:id="xref-ref-6-4" hwp:rel-id="ref-6">6</xref>].</p><p hwp:id="p-67">Feedback could also cause suboptimal networks to exhibit choice correlations that seem to resemble the optimal prediction. If the feedback is noisy and projects into the same direction that encodes the stimulus, such as from a dynamic bias [<xref rid="c60" ref-type="bibr" hwp:id="xref-ref-60-1" hwp:rel-id="ref-60">60</xref>], then this could appear as information-limiting correlations, enhancing the match with <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-6" hwp:rel-id="disp-formula-7">Eq 7</xref>. This situation could be disambiguated by measuring the internal noise source providing the feedback, and of course this would require more simultaneous measurements.</p></sec><sec id="s3d" hwp:id="sec-16"><label>3.4</label><title hwp:id="title-16">Comparing choice correlations from in-ternal and external noise</title><p hwp:id="p-68">Since many stimulus-dependent response correlations are induced by external nuisance variation, not internal noise, we might not find informative stimulus-dependent noise correlations upon repeated presentations of a fixed stimulus. Those correlations may only be informative about a stimulus in the presence of natural nuisance variation. For example, if a picture of a face is shown repeatedly without changing its pose, then small expression changes can readily be identified by linear operations; if the pose can vary then the stimulus is only reflected in higher-order correlations [<xref rid="c5" ref-type="bibr" hwp:id="xref-ref-5-3" hwp:rel-id="ref-5">5</xref>].</p><p hwp:id="p-69">In contrast, we <italic toggle="yes">should</italic> see some nonlinear choice correlations even when nuisance variables are fixed. This is because neural circuitry must combine responses nonlinearly to eliminate natural nuisance variation, and any internal noise passing through those same channels will thereby influence the choice (although they may be smaller and more difficult to detect than the fluctuations caused by the nuisance variation). This influence will manifest as nonlinear choice correlations. In other words, stimulus-dependent noise correlations need not predict a fixed stimulus, but they may predict the choice (Supplementary Information S8).</p><p hwp:id="p-70">For optimal decoding, the choice correlations measured using fixed nuisance variables will differ from <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-7" hwp:rel-id="disp-formula-7">Eq 7</xref>, which should strictly hold only when there is natural nuisance variation. This is implicit in <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-8" hwp:rel-id="disp-formula-7">Eq 7</xref>, since the relevant quantities are conditioned only on the relevant stimulus <italic toggle="yes">s</italic> while averaging over the nuisance variations <bold><italic toggle="yes">n</italic></bold>. However, under some conditions, a related prediction for nonlinear choice correlations holds even with-out averaging over nuisance variables (Supplementary Information S8).</p></sec><sec id="s3e" hwp:id="sec-17"><label>3.5</label><title hwp:id="title-17">Conclusion</title><p hwp:id="p-71">Despite the clear importance of computation that is both nonlinear and distributed, and evidence for nonlinear coding in the cortex [<xref rid="c31" ref-type="bibr" hwp:id="xref-ref-31-3" hwp:rel-id="ref-31">31</xref>, <xref rid="c33" ref-type="bibr" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">33</xref>–<xref rid="c35" ref-type="bibr" hwp:id="xref-ref-35-1" hwp:rel-id="ref-35">35</xref>], most neuroscience applications of population coding concepts have assumed linear codes and linear readouts [<xref rid="c6" ref-type="bibr" hwp:id="xref-ref-6-5" hwp:rel-id="ref-6">6</xref>, <xref rid="c28" ref-type="bibr" hwp:id="xref-ref-28-7" hwp:rel-id="ref-28">28</xref>, <xref rid="c39" ref-type="bibr" hwp:id="xref-ref-39-2" hwp:rel-id="ref-39">39</xref>, <xref rid="c61" ref-type="bibr" hwp:id="xref-ref-61-1" hwp:rel-id="ref-61">61</xref>, <xref rid="c62" ref-type="bibr" hwp:id="xref-ref-62-1" hwp:rel-id="ref-62">62</xref>]. The few that directly address nonlinear popu-lation codes either have an impossibly large amount of encoded information [<xref rid="c16" ref-type="bibr" hwp:id="xref-ref-16-5" hwp:rel-id="ref-16">16</xref>, <xref rid="c30" ref-type="bibr" hwp:id="xref-ref-30-5" hwp:rel-id="ref-30">30</xref>], or investigate abstract properties unrelated to structured tasks [<xref rid="c63" ref-type="bibr" hwp:id="xref-ref-63-1" hwp:rel-id="ref-63">63</xref>]. Some ex-perimental studies have been able to extract additional information from recorded populations using nonlinear decoders [<xref rid="c31" ref-type="bibr" hwp:id="xref-ref-31-4" hwp:rel-id="ref-31">31</xref>, <xref rid="c64" ref-type="bibr" hwp:id="xref-ref-64-1" hwp:rel-id="ref-64">64</xref>], but the inferred properties of such decoders are based on recordings being a representative sample that can be extrapolated to larger populations. Unknown correlations and redundancy prevents that from being a reliable method [<xref rid="c23" ref-type="bibr" hwp:id="xref-ref-23-3" hwp:rel-id="ref-23">23</xref>, <xref rid="c65" ref-type="bibr" hwp:id="xref-ref-65-1" hwp:rel-id="ref-65">65</xref>].</p><p hwp:id="p-72">Our method to understand nonlinear neural decod-ing requires neural recordings in a behaving animal. The task must be hard enough that it makes some errors, so that there are behavioral fluctuations to explain. Finally, there should be a modest number of nonlinearly entangled nuisance variables. Unfortu-nately, many neuroscience experiments are designed without explicit use of nuisance variables. Although this simplifies the analysis, this simplification comes at a great cost, which is that the neural circuits are being engaged far from their natural operating point, and far from their purpose: there is little hope of understanding neural computation without challenging the neural systems with nonlinear tasks for which they are required.</p><p hwp:id="p-73">Our statistical perspective on feedforward nonlinear coding in the presence of nuisance variables provides a useful framework for thinking about neural compu-tation. Furthermore, choice-related activity provides guidance for designing interesting experiments to mea-sure not only how information is encoded in the brain, but how it is decoded to generate behavior. In future work we aim to apply this theory to experimental data to test whether real brains decode neural information optimally in any nonlinear tasks.</p></sec></sec><sec id="s4" hwp:id="sec-18"><label>4</label><title hwp:id="title-18">Methods</title><sec id="s4a" hwp:id="sec-19"><label>4.1</label><title hwp:id="title-19">Encoding models</title><sec id="s4a1" hwp:id="sec-20"><label>4.1.1</label><title hwp:id="title-20">Orientation estimation with varying spatial phase</title><p hwp:id="p-74"><xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-4" hwp:rel-id="F1">Figure 1</xref> illustrates how nuisance variation can eliminate a neuron’s mean tuning to relevant stimulus variables, relegating the neural tuning to higher-order statistics like covariances. In this example, the subject estimates the orientation of a Gabor image, <italic toggle="yes">G</italic>(<bold><italic toggle="yes">x</italic></bold><italic toggle="yes">|s, n</italic>), where <bold><italic toggle="yes">x</italic></bold> is spatial position in the image, and <italic toggle="yes">s</italic> and <italic toggle="yes">n</italic> are the orientation and spatial phase of the image, respectively (Supplemental Material S2). The model visual neurons are linear Gabor filters like idealized simple cells in primary visual cortex, corrupted by additive white Gaussian noise. Their responses are thus distributed as <bold><italic toggle="yes">r</italic></bold> <italic toggle="yes">∼ P</italic> (<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s, n</italic>) = <italic toggle="yes">N</italic> (<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|</italic><bold><italic toggle="yes">f</italic></bold> (<italic toggle="yes">s, n</italic>), <italic toggle="yes">ϵI</italic>), where <italic toggle="yes">ϵ</italic> is the noise variance and the mean <bold><italic toggle="yes">f</italic></bold> (<italic toggle="yes">s, n</italic>) = ⟨<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s, n</italic>⟩ =Σ<bold><italic toggle="yes">r r</italic></bold> <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s, n</italic>) is determined by the overlap between the image and the receptive field.</p><p hwp:id="p-75">When the spatial phase <italic toggle="yes">n</italic> is known, the mean neural response contains all the information about orientation <italic toggle="yes">s</italic>. The brain can decode responses linearly to estimate orientation near a reference <italic toggle="yes">s</italic>0.</p><p hwp:id="p-76">When the spatial phase varies, however, the each mean response to a fixed orientation will be combine across different phases: <bold><italic toggle="yes">f</italic></bold> (<italic toggle="yes">s</italic>) = ⟨<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic> ⟩ = Σ<bold><italic toggle="yes">r r</italic></bold> <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>) =∫ <italic toggle="yes">dn Σ</italic><bold><italic toggle="yes">r r</italic></bold> <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s, n</italic>)<italic toggle="yes">p</italic>(<italic toggle="yes">n</italic>). Since each spatial phase can be paired with another phase <italic toggle="yes">π</italic> radians away that inverts the linear response, the phase-averaged mean is <bold><italic toggle="yes">f</italic></bold> (<italic toggle="yes">s</italic>) = 0. Thus the brain cannot estimate orientation by decoding these neurons linearly; nonlinear computation is necessary.</p><p hwp:id="p-77">The covariance provides one such tuned statistic. We define Cov<sub><italic toggle="yes">ij</italic></sub> (<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s, n</italic>) as the neural covariance for a fixed input image (noise correlations), and Cov<sub><italic toggle="yes">ij</italic></sub> (<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>) as the neural covariance when the nuisance varies (nuisance correlations). According to the law of total covariance,
<disp-formula id="eqn10" hwp:id="disp-formula-10">
<alternatives hwp:id="alternatives-23"><graphic xlink:href="332353_eqn10.gif" position="float" orientation="portrait" hwp:id="graphic-16"/></alternatives>
</disp-formula>
where <italic toggle="yes">δf</italic><sub><italic toggle="yes">i</italic></sub>(<italic toggle="yes">s, n</italic>) = <italic toggle="yes">f</italic><sub><italic toggle="yes">i</italic></sub>(<italic toggle="yes">s, n</italic>) <italic toggle="yes">-</italic>⟨<italic toggle="yes">f</italic><sub><italic toggle="yes">i</italic></sub>(<italic toggle="yes">s, n</italic>) ⟨<italic toggle="yes">n</italic>. Supplementary Information S2 shows in detail how Cov<sub><italic toggle="yes">ij</italic></sub> (<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>) is tuned to <italic toggle="yes">s</italic>.</p></sec><sec id="s4a2" hwp:id="sec-21"><label>4.1.2</label><title hwp:id="title-21">Exponential family distribution and sufficient statistics</title><p hwp:id="p-78">We assume the response distribution conditioned on the relevant stimulus (but not on nuisance variables) is approximately a mem-ber of the exponential family with nonlinear sufficient statistics,
<disp-formula id="eqn11" hwp:id="disp-formula-11">
<alternatives hwp:id="alternatives-24"><graphic xlink:href="332353_eqn11.gif" position="float" orientation="portrait" hwp:id="graphic-17"/></alternatives>
</disp-formula>
where <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) is a vector of sufficient statistics for the natural pa-rameter <bold><italic toggle="yes">H</italic></bold>(<italic toggle="yes">s</italic>), <italic toggle="yes">b</italic>(<bold><italic toggle="yes">r</italic></bold>) is the base measure, and <italic toggle="yes">A</italic>(<italic toggle="yes">s</italic>) is the log-partition function. The sufficient statistics contain all of the in-formation in the population response, and all other tuned statis-tics may be derived from them.</p><p hwp:id="p-79">Estimation and inference are closely connected in the expo-nential family. In Supplemental Material S1.2, we show that the optimal local estimation can be achieved by linearly decoding the nonlinear sufficient statistics, <inline-formula hwp:id="inline-formula-14"><alternatives hwp:id="alternatives-25"><inline-graphic xlink:href="332353_inline12.gif" hwp:id="inline-graphic-14"/></alternatives></inline-formula>. The decoding weights minimize the variance of an unbiased decoder,
<disp-formula id="eqn12" hwp:id="disp-formula-12">
<alternatives hwp:id="alternatives-26"><graphic xlink:href="332353_eqn12.gif" position="float" orientation="portrait" hwp:id="graphic-18"/></alternatives>
</disp-formula>
where <bold><italic toggle="yes">F</italic></bold> ′= <italic toggle="yes">∂ (</italic><bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>)<italic toggle="yes">|s) /∂s</italic> is the sensitivity of the statistics to changing inputs, and Γ = Cov(<bold><italic toggle="yes">R</italic></bold><italic toggle="yes">|s</italic>) is the stimulus-conditioned response covariance which generally includes nuisance correlations (<xref rid="s2b" ref-type="sec" hwp:id="xref-sec-4-2" hwp:rel-id="sec-4">Section 2.2</xref>).</p><p hwp:id="p-80">The variance of this unbiased local estimator from the neural responses is lower-bounded by the inverse Fisher information. For exponential family distributions with nonlinear sufficient statistics <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>), the Fisher information is [<xref rid="c23" ref-type="bibr" hwp:id="xref-ref-23-4" hwp:rel-id="ref-23">23</xref>] (Supplemental Material S1.1)
<disp-formula id="eqn13" hwp:id="disp-formula-13" hwp:rev-id="xref-disp-formula-13-1 xref-disp-formula-13-2 xref-disp-formula-13-3 xref-disp-formula-13-4">
<alternatives hwp:id="alternatives-27"><graphic xlink:href="332353_eqn13.gif" position="float" orientation="portrait" hwp:id="graphic-19"/></alternatives>
</disp-formula>
</p></sec><sec id="s4a3" hwp:id="sec-22"><label>4.1.3</label><title hwp:id="title-22">Quadratic encoding</title><p hwp:id="p-81">In a quadratic coding model, the distribution of neural responses is described by the exponential family with up to quadratic sufficient statistics, <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) = {<italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub> } for <italic toggle="yes">i, j ∈ {</italic>1, <italic toggle="yes">…, N }</italic>. A familiar example is the Gaussian distribution with stimulus-dependent covariance Σ(<italic toggle="yes">s</italic>). In order to demonstrate the coding properties of a purely nonlinear neural code, here we assume that the mean tuning curve <italic toggle="yes">f</italic> (<italic toggle="yes">s</italic>) and the stimulus-conditional covariances Σ<sub><italic toggle="yes">ij</italic></sub> (<italic toggle="yes">s</italic>) depend smoothly on the stimulus. We can quantify the informa-tion content of the neural population using <xref ref-type="disp-formula" rid="eqn13" hwp:id="xref-disp-formula-13-1" hwp:rel-id="disp-formula-13">Equation 13</xref>.</p></sec><sec id="s4a4" hwp:id="sec-23"><label>4.1.4</label><title hwp:id="title-23">Cubic encoding</title><p hwp:id="p-82">In our cubic coding model, the distribution of neural responses is described by the exponential family with up to cubic sufficient statistics, <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) = {<italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub>, <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">k</italic></sub>} for <italic toggle="yes">i, j, k ∈</italic> {1, <italic toggle="yes">…, N</italic> }.</p><p hwp:id="p-83">We approximate a three-neuron cubic code first using purely cubic components, and we then apply a stimulus-dependent affine transformation to include linear and quadratic statistics. The pure cubic code is used for a vector <bold><italic toggle="yes">z</italic></bold> with sufficient statistics <italic toggle="yes">z</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">z</italic><sub><italic toggle="yes">j</italic></sub><italic toggle="yes">z</italic><sub><italic toggle="yes">k</italic></sub> (and a base measure <inline-formula hwp:id="inline-formula-15"><alternatives hwp:id="alternatives-28"><inline-graphic xlink:href="332353_inline13.gif" hwp:id="inline-graphic-15"/></alternatives></inline-formula> to ensure the distribution is bounded and normalizable).
<disp-formula id="eqn14" hwp:id="disp-formula-14">
<alternatives hwp:id="alternatives-29"><graphic xlink:href="332353_eqn14.gif" position="float" orientation="portrait" hwp:id="graphic-20"/></alternatives>
</disp-formula>
</p><p hwp:id="p-84">We approximate this distribution by a mixture of four Gaussians. The mixture is chosen to reproduce the tetrahedral symmetry of the cubic distribution (Supplementary Figure 6), which allows the cubic statistics of responses to be stimulus dependent, leaving stimulus-independent quadratic and linear statistics.</p><fig id="fig6" position="float" fig-type="figure" orientation="portrait" hwp:id="F6" hwp:rev-id="xref-fig-6-1 xref-fig-6-2 xref-fig-6-3 xref-fig-6-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;332353v1/FIG6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">fig6</object-id><label>Figure 6:</label><caption hwp:id="caption-7"><p hwp:id="p-85">Multivariate skewed distributions. (<bold>A</bold>) Isoprobability contour of an exponential family distribution with cubic statistics in three dimensions, drawn from <italic toggle="yes">p</italic>(<bold><italic toggle="yes">z</italic></bold><italic toggle="yes">|s</italic>) <italic toggle="yes">∝</italic> exp (<italic toggle="yes">sz</italic><sub>1</sub><italic toggle="yes">z</italic><sub>2</sub><italic toggle="yes">z</italic><sub>3</sub> <italic toggle="yes">-</italic>‖ <bold><italic toggle="yes">z</italic></bold> ‖ 4). (<bold>B</bold>) Isoprobability contour for a mixture of four gaussians (<xref ref-type="disp-formula" rid="eqn78" hwp:id="xref-disp-formula-78-1" hwp:rel-id="disp-formula-78">Eq 78</xref>). (<bold>C,D</bold>) Samples drawn from the mixture form, with <italic toggle="yes">s</italic> = 1, 2.</p></caption><graphic xlink:href="332353_fig6" position="float" orientation="portrait" hwp:id="graphic-21"/></fig><p hwp:id="p-86">To generate larger multivariate cubic codes for Figure (6), for simplicity we assume the pure cubic terms only couple disjoint triplets of variables, and sample independently from an approximately cubic distribution for each triplet. To convert this purely cubic distribution to a distribution with linear and quadratic in-formation, we shift and scale these cubic samples <bold><italic toggle="yes">z</italic></bold> in a manner dependent on <italic toggle="yes">s</italic>:
<disp-formula id="eqn15" hwp:id="disp-formula-15">
<alternatives hwp:id="alternatives-30"><graphic xlink:href="332353_eqn15.gif" position="float" orientation="portrait" hwp:id="graphic-22"/></alternatives>
</disp-formula>
where <bold><italic toggle="yes">f</italic></bold> (<italic toggle="yes">s</italic>) and Σ(<italic toggle="yes">s</italic>) describes the desired signal-dependent mean and covariance (see Supplemental Material S4).</p></sec></sec><sec id="s4b" hwp:id="sec-24"><label>4.2</label><title hwp:id="title-24">Nonlinear choice correlations</title><sec id="s4b1" hwp:id="sec-25"><label>4.2.1</label><title hwp:id="title-25">Estimating choice correlation</title><p hwp:id="p-87">The nonlinear choice correlation between the stimulus estimate <inline-formula hwp:id="inline-formula-16"><alternatives hwp:id="alternatives-31"><inline-graphic xlink:href="332353_inline14.gif" hwp:id="inline-graphic-16"/></alternatives></inline-formula> and one nonlinear function <italic toggle="yes">R</italic><sub><italic toggle="yes">k</italic></sub> (the <italic toggle="yes">k</italic>th element of the vector <bold><italic toggle="yes">R</italic></bold>) of recorded neural activity <bold><italic toggle="yes">r</italic></bold> is
<disp-formula id="eqn16" hwp:id="disp-formula-16">
<alternatives hwp:id="alternatives-32"><graphic xlink:href="332353_eqn16.gif" position="float" orientation="portrait" hwp:id="graphic-23"/></alternatives>
</disp-formula>
where <bold><italic toggle="yes"><inline-formula hwp:id="inline-formula-17"><alternatives hwp:id="alternatives-33"><inline-graphic xlink:href="332353_inline15.gif" hwp:id="inline-graphic-17"/></alternatives></inline-formula></italic></bold> is the estimator variance.</p><p hwp:id="p-88">To compute this quantity from neural responses to stimuli, we need to condition neural responses and behavior data on the same signal <italic toggle="yes">s</italic>, or on the same total input (<italic toggle="yes">s,</italic> <bold><italic toggle="yes">n</italic></bold>) if we want to isolate the contribution of purely internal noise rather than nuisance variation (Supplemental Material S8). We combine choice correlations calculated under different stimulus conditions by balanced <italic toggle="yes">z</italic>-scoring [<xref rid="c66" ref-type="bibr" hwp:id="xref-ref-66-1" hwp:rel-id="ref-66">66</xref>].</p></sec><sec id="s4b2" hwp:id="sec-26"><label>4.2.2</label><title hwp:id="title-26">Optimality test</title><p hwp:id="p-89">Locally optimal linear estimator weights for decoding statistics <bold><italic toggle="yes">R</italic></bold> are given by linear regression as <bold><italic toggle="yes">w</italic></bold> <italic toggle="yes">∝</italic> Γ<sup>-1</sup><bold><italic toggle="yes">F</italic></bold> ′. Substituting these weights into (16), the optimal nonlinear choice correlation becomes
<disp-formula id="eqn17" hwp:id="disp-formula-17">
<alternatives hwp:id="alternatives-34"><graphic xlink:href="332353_eqn17.gif" position="float" orientation="portrait" hwp:id="graphic-24"/></alternatives>
</disp-formula>
where <inline-formula hwp:id="inline-formula-18"><alternatives hwp:id="alternatives-35"><inline-graphic xlink:href="332353_inline16.gif" hwp:id="inline-graphic-18"/></alternatives></inline-formula> is the linear Fisher Information in <italic toggle="yes">R</italic><sub><italic toggle="yes">k</italic></sub>(<bold><italic toggle="yes">r</italic></bold>)</p><p hwp:id="p-90">For fine-scale discriminations, optimal choice correlations can be written in many equivalent ways:
<disp-formula id="eqn18" hwp:id="disp-formula-18">
<alternatives hwp:id="alternatives-36"><graphic xlink:href="332353_eqn18.gif" position="float" orientation="portrait" hwp:id="graphic-25"/></alternatives>
</disp-formula>
where <italic toggle="yes"><inline-formula hwp:id="inline-formula-19"><alternatives hwp:id="alternatives-37"><inline-graphic xlink:href="332353_inline17.gif" hwp:id="inline-graphic-19"/></alternatives></inline-formula></italic> is the discriminability. These ways reflect the simple relationships between four quantities often used to represent information: <italic toggle="yes">d</italic>-prime is prop<italic toggle="yes">v</italic>o<underline>r</underline>tional to the square root of the Fisher information <italic toggle="yes"><inline-formula hwp:id="inline-formula-20"><alternatives hwp:id="alternatives-38"><inline-graphic xlink:href="332353_inline18.gif" hwp:id="inline-graphic-20"/></alternatives></inline-formula></italic> [<xref rid="c67" ref-type="bibr" hwp:id="xref-ref-67-1" hwp:rel-id="ref-67">67</xref>]; estimator standard deviation is bounded by the inverse square root of the Fisher in-formation, <inline-formula hwp:id="inline-formula-21"><alternatives hwp:id="alternatives-39"><inline-graphic xlink:href="332353_inline19.gif" hwp:id="inline-graphic-21"/></alternatives></inline-formula>, discrimination threshold is proportional to the estimator standard deviation,<inline-formula hwp:id="inline-formula-22"><alternatives hwp:id="alternatives-40"><inline-graphic xlink:href="332353_inline20.gif" hwp:id="inline-graphic-22"/></alternatives></inline-formula> In different experiments (binary discrimination, continuous estimation), it can be most natural to express this relationship in different measured quantities.</p><p hwp:id="p-91">In our simulations with binary choices for fine discrimination, we calculate the optimal nonlinear choice correlation using <italic toggle="yes">d</italic>-prime [<xref rid="c68" ref-type="bibr" hwp:id="xref-ref-68-1" hwp:rel-id="ref-68">68</xref>]. <italic toggle="yes"><inline-formula hwp:id="inline-formula-23"><alternatives hwp:id="alternatives-41"><inline-graphic xlink:href="332353_inline21.gif" hwp:id="inline-graphic-23"/></alternatives></inline-formula></italic> is estimated from neural responses generated by stimuli <italic toggle="yes">s±</italic> = <italic toggle="yes">s</italic>0 <italic toggle="yes">±</italic> Δ<italic toggle="yes">s/</italic>2 near a reference stimulus <italic toggle="yes">s</italic>0:
<disp-formula id="eqn19" hwp:id="disp-formula-19">
<alternatives hwp:id="alternatives-42"><graphic xlink:href="332353_eqn19.gif" position="float" orientation="portrait" hwp:id="graphic-26"/></alternatives>
</disp-formula>
</p><p hwp:id="p-92">The discriminability for an decoded neural population is estimated from the unbiased decoder output’s standard deviation, <italic toggle="yes"><inline-formula hwp:id="inline-formula-24"><alternatives hwp:id="alternatives-43"><inline-graphic xlink:href="332353_inline22.gif" hwp:id="inline-graphic-24"/></alternatives></inline-formula></italic></p></sec><sec id="s4b3" hwp:id="sec-27"><label>4.2.3</label><title hwp:id="title-27">Nonlinear choice correlation to analyze an unknown nonlinearity</title><p hwp:id="p-93">In <xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-3" hwp:rel-id="F4">Figure 4</xref>, we generated neural responses given sufficient statistics that are polynomials up to third order, <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) = {<italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub>, <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">k</italic></sub>} (Methods 4.1.4). In contrast, our model brain decodes the stimulus using a cascade of linear-nonlinear transformations, with Rectified Linear Units (ReLU(<italic toggle="yes">x</italic>) = max(0, <italic toggle="yes">x</italic>)) for the nonlinear activation functions. We used a fully-connected ReLU network with two hidden layers and 30 units per hidden layer,
<disp-formula id="eqn20" hwp:id="disp-formula-20">
<alternatives hwp:id="alternatives-44"><graphic xlink:href="332353_eqn20.gif" position="float" orientation="portrait" hwp:id="graphic-27"/></alternatives>
</disp-formula>
<disp-formula id="eqn21" hwp:id="disp-formula-21">
<alternatives hwp:id="alternatives-45"><graphic xlink:href="332353_eqn21.gif" position="float" orientation="portrait" hwp:id="graphic-28"/></alternatives>
</disp-formula>
<disp-formula id="eqn22" hwp:id="disp-formula-22">
<alternatives hwp:id="alternatives-46"><graphic xlink:href="332353_eqn22.gif" position="float" orientation="portrait" hwp:id="graphic-29"/></alternatives>
</disp-formula>
<disp-formula id="eqn23" hwp:id="disp-formula-23">
<alternatives hwp:id="alternatives-47"><graphic xlink:href="332353_eqn23.gif" position="float" orientation="portrait" hwp:id="graphic-30"/></alternatives>
</disp-formula>
</p><p hwp:id="p-94">We trained the network weights and biases with backpropagation to estimate stimuli near a reference <italic toggle="yes">s</italic><sub>0</sub> based on 20000 training pairs (<bold><italic toggle="yes">r</italic></bold>, <italic toggle="yes">s</italic>) generated by the cubic encoding model. This trained neural network extracted 91% of the information available to an optimal decoder.</p></sec></sec><sec id="s4c" hwp:id="sec-28"><label>4.3</label><title hwp:id="title-28">Information-limiting correlations</title><p hwp:id="p-95">Only specific correlated fluctuations limit the information con-tent of large neural populations [<xref rid="c27" ref-type="bibr" hwp:id="xref-ref-27-4" hwp:rel-id="ref-27">27</xref>]. These fluctuations can ul-timately be referred back to the stimulus as <bold><italic toggle="yes">r</italic></bold> <italic toggle="yes">∼ p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic> + <italic toggle="yes">ds</italic>), where <italic toggle="yes">ds</italic> is zero mean noise, whose variance 1<italic toggle="yes">/J<sub>∞</sub></italic> determines the asymptotic variance of any stimulus estimator. These information-limiting correlations for nonlinear computation can be characterized by the covariance of the sufficient statistics, Γ = Cov(<bold><italic toggle="yes">R</italic></bold><italic toggle="yes">|s</italic>) conditioned on <italic toggle="yes">s</italic>; the information-limiting component arises specifically from the signal covariance Cov(<bold><italic toggle="yes">F</italic></bold> (<italic toggle="yes">s</italic>)<italic toggle="yes">|s</italic>). Since the signal for local estimation of stimuli near a reference <italic toggle="yes">s</italic>0 is <bold><italic toggle="yes"><inline-formula hwp:id="inline-formula-25"><alternatives hwp:id="alternatives-48"><inline-graphic xlink:href="332353_inline23.gif" hwp:id="inline-graphic-25"/></alternatives></inline-formula></italic></bold>, the information-limiting component of the covariance is proportional to <bold><italic toggle="yes">F F</italic></bold>:
<disp-formula id="eqn24" hwp:id="disp-formula-24">
<alternatives hwp:id="alternatives-49"><graphic xlink:href="332353_eqn24.gif" position="float" orientation="portrait" hwp:id="graphic-31"/></alternatives>
</disp-formula></p><p hwp:id="p-96">Here Γ<sub>0</sub> is any covariance of <bold><italic toggle="yes">R</italic></bold> that does <italic toggle="yes">not</italic> limit information in large populations. Substituting this expression into (13) for the nonlinear Fisher Information, we obtain
<disp-formula id="eqn25" hwp:id="disp-formula-25">
<alternatives hwp:id="alternatives-50"><graphic xlink:href="332353_eqn25.gif" position="float" orientation="portrait" hwp:id="graphic-32"/></alternatives>
</disp-formula>
where <italic toggle="yes"><inline-formula hwp:id="inline-formula-26"><alternatives hwp:id="alternatives-51"><inline-graphic xlink:href="332353_inline25.gif" hwp:id="inline-graphic-26"/></alternatives></inline-formula></italic> is the nonlinear Fisher Information allowed by Γ0. When the population size grows, the extensive information term <italic toggle="yes">J</italic>0 grows proportionally, so the output information will asymptote to <italic toggle="yes">J∞</italic>.</p></sec></sec><sec id="s5" hwp:id="sec-29"><title hwp:id="title-29">Author contributions</title><p hwp:id="p-97">XP conceived the theoretical framework. XP and QY performed the theoretical analyses. QY performed the simulations. QY and XP wrote the manuscript.</p></sec></body><back><ack hwp:id="ack-1"><title hwp:id="title-30">Acknowledgements</title><p hwp:id="p-98">The authors thank Jeff Beck, Valentin Dragoi, Arun Parajuli, Andreas S. Tolias, Edgar Walker, R. James Cotton and Alex Pouget for helpful conversations. This work was supported by NSF CAREER grant 1552868 and NeuroNex grant 1707400 to XP.</p></ack><ref-list hwp:id="ref-list-1"><title hwp:id="title-31">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1 xref-ref-1-2"><label>[1]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Adelson EH"><surname>Adelson</surname> <given-names>EH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bergen JR"><surname>Bergen</surname> <given-names>JR</given-names></string-name> (<year>1985</year>) <article-title hwp:id="article-title-2">Spatiotemporal en- ergy models for the perception of motion</article-title>. <source hwp:id="source-1">Josa a</source> <volume>2</volume>: <fpage>284</fpage>–<lpage>299</lpage>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1 xref-ref-2-2 xref-ref-2-3"><label>[2]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="DiCarlo JJ"><surname>DiCarlo</surname> <given-names>JJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cox DD"><surname>Cox</surname> <given-names>DD</given-names></string-name> (<year>2007</year>) <article-title hwp:id="article-title-3">Untangling invariant object recognition</article-title>. <source hwp:id="source-2">Trends in cognitive sciences</source> <volume>11</volume>: <fpage>333</fpage>–<lpage>341</lpage>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><label>[3]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Rust NC"><surname>Rust</surname> <given-names>NC</given-names></string-name>, <string-name name-style="western" hwp:sortable="DiCarlo JJ"><surname>DiCarlo</surname> <given-names>JJ</given-names></string-name> (<year>2010</year>) <article-title hwp:id="article-title-4">Selectivity and toler- ance (invariance) both increase as visual informa- tion propagates from cortical area v4 to it</article-title>. <source hwp:id="source-3">Journal of Neuroscience</source> <volume>30</volume>: <fpage>12978</fpage>–<lpage>12995</lpage>.</citation></ref><ref id="c4" hwp:id="ref-4"><label>[4]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Pagan M"><surname>Pagan</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Urban LS"><surname>Urban</surname> <given-names>LS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wohl MP"><surname>Wohl</surname> <given-names>MP</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rust NC"><surname>Rust</surname> <given-names>NC</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-5">Signals in inferotemporal and perirhinal cortex suggest an untangling of visual target information</article-title>. <source hwp:id="source-4">Nature neuroscience</source> <volume>16</volume>: <fpage>1132</fpage>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1 xref-ref-5-2 xref-ref-5-3"><label>[5]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Meyers EM"><surname>Meyers</surname> <given-names>EM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Borzello M"><surname>Borzello</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Freiwald WA"><surname>Freiwald</surname> <given-names>WA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tsao D"><surname>Tsao</surname> <given-names>D</given-names></string-name> (<year>2015</year>) <article-title hwp:id="article-title-6">Intelligent information loss: the coding of facial identity, head pose, and non-face informa- tion in the macaque face patch system</article-title>. <source hwp:id="source-5">Journal of Neuroscience</source> <volume>35</volume>: <fpage>7069</fpage>–<lpage>7081</lpage>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2 xref-ref-6-3 xref-ref-6-4 xref-ref-6-5"><label>[6]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Yamins DL"><surname>Yamins</surname> <given-names>DL</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hong H"><surname>Hong</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cadieu CF"><surname>Cadieu</surname> <given-names>CF</given-names></string-name>, <string-name name-style="western" hwp:sortable="Solomon EA"><surname>Solomon</surname> <given-names>EA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Seibert D"><surname>Seibert</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="DiCarlo JJ"><surname>DiCarlo</surname> <given-names>JJ</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-7">Performance- optimized hierarchical models predict neural re- sponses in higher visual cortex</article-title>. <source hwp:id="source-6">Proceedings of the National Academy of Sciences</source> <volume>111</volume>: <fpage>8619</fpage>–<lpage>8624</lpage>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1"><label>[7]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Ecker AS"><surname>Ecker</surname> <given-names>AS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Berens P"><surname>Berens</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Keliris GA"><surname>Keliris</surname> <given-names>GA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bethge M"><surname>Bethge</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Logothetis NK"><surname>Logothetis</surname> <given-names>NK</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tolias AS"><surname>Tolias</surname> <given-names>AS</given-names></string-name> (<year>2010</year>) <article-title hwp:id="article-title-8">Decorrelated neuronal firing in cortical microcircuits</article-title>. <source hwp:id="source-7">science</source> <volume>327</volume>: <fpage>584</fpage>–<lpage>587</lpage>.</citation></ref><ref id="c8" hwp:id="ref-8"><label>[8]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Ecker AS"><surname>Ecker</surname> <given-names>AS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Berens P"><surname>Berens</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cotton RJ"><surname>Cotton</surname> <given-names>RJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Subramaniyan M"><surname>Subramaniyan</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Denfield GH"><surname>Denfield</surname> <given-names>GH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cadwell CR"><surname>Cadwell</surname> <given-names>CR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Smirnakis SM"><surname>Smirnakis</surname> <given-names>SM</given-names></string-name>, <etal>et al.</etal> (<year>2014</year>) <article-title hwp:id="article-title-9">State dependence of noise correlations in macaque primary visual cortex</article-title>. <source hwp:id="source-8">Neuron</source> <volume>82</volume>: <fpage>235</fpage>–<lpage>248</lpage>.</citation></ref><ref id="c9" hwp:id="ref-9"><label>[9]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.9" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Denfield GH"><surname>Denfield</surname> <given-names>GH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ecker AS"><surname>Ecker</surname> <given-names>AS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shinn TJ"><surname>Shinn</surname> <given-names>TJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bethge M"><surname>Bethge</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tolias AS"><surname>Tolias</surname> <given-names>AS</given-names></string-name> (<year>2017</year>) <article-title hwp:id="article-title-10">Attentional fluctuations induce shared variability in macaque primary visual cortex</article-title>. <source hwp:id="source-9">bioRxiv</source>: <fpage>189282</fpage>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><label>[10]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Ecker AS"><surname>Ecker</surname> <given-names>AS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Denfield GH"><surname>Denfield</surname> <given-names>GH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bethge M"><surname>Bethge</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tolias AS"><surname>Tolias</surname> <given-names>AS</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-11">On the structure of neuronal population activity under fluctuations in attentional state</article-title>. <source hwp:id="source-10">Journal of Neuroscience</source> <volume>36</volume>: <fpage>1775</fpage>–<lpage>1789</lpage>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><label>[11]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Jazayeri M"><surname>Jazayeri</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Movshon JA"><surname>Movshon</surname> <given-names>JA</given-names></string-name> (<year>2006</year>) <article-title hwp:id="article-title-12">Optimal repre- sentation of sensory information by neural popu- lations</article-title>. <source hwp:id="source-11">Nature neuroscience</source> <volume>9</volume>: <fpage>690</fpage>–<lpage>696</lpage>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1 xref-ref-12-2"><label>[12]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.12" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Bondy AG"><surname>Bondy</surname> <given-names>AG</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cumming BG"><surname>Cumming</surname> <given-names>BG</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-13">Feedback dy- namics determine the structure of spike-count cor- relation in visual cortex</article-title>. <source hwp:id="source-12">bioRxiv: 086256</source>.</citation></ref><ref id="c13" hwp:id="ref-13"><label>[13]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Averbeck BB"><surname>Averbeck</surname> <given-names>BB</given-names></string-name>, <string-name name-style="western" hwp:sortable="Latham PE"><surname>Latham</surname> <given-names>PE</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pouget A"><surname>Pouget</surname> <given-names>A</given-names></string-name> (<year>2006</year>) <article-title hwp:id="article-title-14">Neural correlations, population coding and computation</article-title>. <source hwp:id="source-13">Nature reviews neuroscience</source> <volume>7</volume>: <fpage>358</fpage>.</citation></ref><ref id="c14" hwp:id="ref-14"><label>[14]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Cohen MR"><surname>Cohen</surname> <given-names>MR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kohn A"><surname>Kohn</surname> <given-names>A</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-15">Measuring and interpreting neuronal correlations</article-title>. <source hwp:id="source-14">Nature neuroscience</source> <volume>14</volume>: <fpage>811</fpage>.</citation></ref><ref id="c15" hwp:id="ref-15"><label>[15]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.15" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Kohn A"><surname>Kohn</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Coen-Cagli R"><surname>Coen-Cagli</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kanitscheider I"><surname>Kanitscheider</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pouget A"><surname>Pouget</surname> <given-names>A</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-16">Correlations and neuronal population in- formation</article-title>. <source hwp:id="source-15">Annual review of neuroscience</source> <volume>39</volume>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1 xref-ref-16-2 xref-ref-16-3 xref-ref-16-4 xref-ref-16-5 xref-ref-16-6 xref-ref-16-7"><label>[16]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Ecker AS"><surname>Ecker</surname> <given-names>AS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Berens P"><surname>Berens</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tolias AS"><surname>Tolias</surname> <given-names>AS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bethge M"><surname>Bethge</surname> <given-names>M</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-17">The effect of noise correlations in populations of diversely tuned neurons</article-title>. <source hwp:id="source-16">Journal of Neuroscience</source> <volume>31</volume>: <fpage>14272</fpage>–<lpage>14283</lpage>.</citation></ref><ref id="c17" hwp:id="ref-17"><label>[17]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Abbott LF"><surname>Abbott</surname> <given-names>LF</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dayan P"><surname>Dayan</surname> <given-names>P</given-names></string-name> (<year>1999</year>) <article-title hwp:id="article-title-18">The effect of correlated variability on the accuracy of a population code</article-title>. <source hwp:id="source-17">Neural computation</source> <volume>11</volume>: <fpage>91</fpage>–<lpage>101</lpage>.</citation></ref><ref id="c18" hwp:id="ref-18"><label>[18]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Cohen MR"><surname>Cohen</surname> <given-names>MR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Maunsell JH"><surname>Maunsell</surname> <given-names>JH</given-names></string-name> (<year>2009</year>) <article-title hwp:id="article-title-19">Attention improves performance primarily by reducing interneuronal correlations</article-title>. <source hwp:id="source-18">Nature neuroscience</source> <volume>12</volume>: <fpage>1594</fpage>.</citation></ref><ref id="c19" hwp:id="ref-19"><label>[19]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Cohen MR"><surname>Cohen</surname> <given-names>MR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newsome WT"><surname>Newsome</surname> <given-names>WT</given-names></string-name> (<year>2009</year>) <article-title hwp:id="article-title-20">Estimates of the contribution of single neurons to perception de- pend on timescale and noise correlation</article-title>. <source hwp:id="source-19">Journal of Neuroscience</source> <volume>29</volume>: <fpage>6635</fpage>–<lpage>6648</lpage>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><label>[20]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Gawne TJ"><surname>Gawne</surname> <given-names>TJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Richmond BJ"><surname>Richmond</surname> <given-names>BJ</given-names></string-name> (<year>1993</year>) <article-title hwp:id="article-title-21">How independent are the messages carried by adjacent inferior tem- poral cortical neurons?</article-title> <source hwp:id="source-20">Journal of Neuroscience</source> <volume>13</volume>: <fpage>2758</fpage>–<lpage>2771</lpage>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1"><label>[21]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.21" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Ralf H"><surname>Ralf</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bethge M"><surname>Bethge</surname> <given-names>M</given-names></string-name> (<year>2010</year>) <article-title hwp:id="article-title-22">Evaluating neuronal codes for inference using fisher information</article-title>. In: <source hwp:id="source-21">Advances in neural information processing systems</source>. pp. <fpage>1993</fpage>–<lpage>2001</lpage>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1 xref-ref-22-2"><label>[22]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Burge J"><surname>Burge</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jaini P"><surname>Jaini</surname> <given-names>P</given-names></string-name> (<year>2017</year>) <article-title hwp:id="article-title-23">Accuracy maximization analysis for sensory-perceptual tasks: Computa- tional improvements, filter robustness, and coding advantages for scaled additive noise</article-title>. <source hwp:id="source-22">PLoS computational biology</source> <volume>13</volume>: <fpage>e1005281</fpage>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1 xref-ref-23-2 xref-ref-23-3 xref-ref-23-4 xref-ref-23-5"><label>[23]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Beck J"><surname>Beck</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bejjanki VR"><surname>Bejjanki</surname> <given-names>VR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pouget A"><surname>Pouget</surname> <given-names>A</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-24">Insights from a simple expression for linear fisher informa- tion in a recurrently connected population of spik- ing neurons</article-title>. <source hwp:id="source-23">Neural computation</source> <volume>23</volume>: <fpage>1484</fpage>–<lpage>1502</lpage>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1 xref-ref-24-2"><label>[24]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Paradiso M"><surname>Paradiso</surname> <given-names>M</given-names></string-name> (<year>1988</year>) <article-title hwp:id="article-title-25">A theory for the use of visual orientation information which exploits the colum- nar structure of striate cortex</article-title>. <source hwp:id="source-24">Biological cybernetics</source> <volume>58</volume>: <fpage>35</fpage>–<lpage>49</lpage>.</citation></ref><ref id="c25" hwp:id="ref-25"><label>[25]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Zohary E"><surname>Zohary</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shadlen MN"><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newsome WT"><surname>Newsome</surname> <given-names>WT</given-names></string-name> (<year>1994</year>) <article-title hwp:id="article-title-26">Correlated neuronal discharge rate and its implica- tions for psychophysical performance</article-title>. <source hwp:id="source-25">Nature</source> <volume>370</volume>: <fpage>140</fpage>–<lpage>143</lpage>.</citation></ref><ref id="c26" hwp:id="ref-26"><label>[26]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.26" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Sompolinsky H"><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Yoon H"><surname>Yoon</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kang K"><surname>Kang</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shamir M"><surname>Shamir</surname> <given-names>M</given-names></string-name> (<year>2001</year>) <article-title hwp:id="article-title-27">Population coding in neuronal systems with correlated noise</article-title>. <source hwp:id="source-26">Physical Review E</source> <volume>64</volume>: <fpage>051904</fpage>.</citation></ref><ref id="c27" hwp:id="ref-27" hwp:rev-id="xref-ref-27-1 xref-ref-27-2 xref-ref-27-3 xref-ref-27-4 xref-ref-27-5"><label>[27]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.27" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Moreno-Bote R"><surname>Moreno-Bote</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Beck J"><surname>Beck</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kanitscheider I"><surname>Kanitscheider</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pitkow X"><surname>Pitkow</surname> <given-names>X</given-names></string-name>, <string-name name-style="western" hwp:sortable="Latham P"><surname>Latham</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pouget A"><surname>Pouget</surname> <given-names>A</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-28">Information- limiting correlations</article-title>. <source hwp:id="source-27">Nature neuroscience</source> <volume>17</volume>: <fpage>1410</fpage>–<lpage>1417</lpage>.</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1 xref-ref-28-2 xref-ref-28-3 xref-ref-28-4 xref-ref-28-5 xref-ref-28-6 xref-ref-28-7 xref-ref-28-8"><label>[28]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.28" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Pitkow X"><surname>Pitkow</surname> <given-names>X</given-names></string-name>, <string-name name-style="western" hwp:sortable="Liu S"><surname>Liu</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Angelaki DE"><surname>Angelaki</surname> <given-names>DE</given-names></string-name>, <string-name name-style="western" hwp:sortable="DeAngelis GC"><surname>DeAngelis</surname> <given-names>GC</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pouget A"><surname>Pouget</surname> <given-names>A</given-names></string-name> (<year>2015</year>) <article-title hwp:id="article-title-29">How can single sensory neurons predict behavior?</article-title> <source hwp:id="source-28">Neuron</source> <volume>87</volume>: <fpage>411</fpage>–<lpage>423</lpage>.</citation></ref><ref id="c29" hwp:id="ref-29" hwp:rev-id="xref-ref-29-1 xref-ref-29-2 xref-ref-29-3"><label>[29]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.29" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="Shamir M"><surname>Shamir</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sompolinsky H"><surname>Sompolinsky</surname> <given-names>H</given-names></string-name> (<year>2004</year>) <article-title hwp:id="article-title-30">Nonlinear population codes</article-title>. <source hwp:id="source-29">Neural computation</source> <volume>16</volume>: <fpage>1105</fpage>–<lpage>1136</lpage>.</citation></ref><ref id="c30" hwp:id="ref-30" hwp:rev-id="xref-ref-30-1 xref-ref-30-2 xref-ref-30-3 xref-ref-30-4 xref-ref-30-5"><label>[30]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.30" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="Shamir M"><surname>Shamir</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sompolinsky H"><surname>Sompolinsky</surname> <given-names>H</given-names></string-name> (<year>2006</year>) <article-title hwp:id="article-title-31">Implications of neuronal diversity on population coding</article-title>. <source hwp:id="source-30">Neural Computation</source> <volume>18</volume>: <fpage>1951</fpage>–<lpage>1986</lpage>.</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1 xref-ref-31-2 xref-ref-31-3 xref-ref-31-4"><label>[31]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="Pagan M"><surname>Pagan</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Simoncelli EP"><surname>Simoncelli</surname> <given-names>EP</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rust NC"><surname>Rust</surname> <given-names>NC</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-32">Neural quadratic discriminant analysis: Nonlinear decod- ing with v1-like computation</article-title>. <source hwp:id="source-31">Neural computation</source> <volume>28</volume>: <fpage>2291</fpage>–<lpage>2319</lpage>.</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1"><label>[32]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.32" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="Gutnisky DA"><surname>Gutnisky</surname> <given-names>DA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dragoi V"><surname>Dragoi</surname> <given-names>V</given-names></string-name> (<year>2008</year>) <article-title hwp:id="article-title-33">Adaptive coding of visual information in neural populations</article-title>. <source hwp:id="source-32">Nature</source> <volume>452</volume>: <fpage>220</fpage>.</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1"><label>[33]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.33" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Kohn A"><surname>Kohn</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Smith MA"><surname>Smith</surname> <given-names>MA</given-names></string-name> (<year>2005</year>) <article-title hwp:id="article-title-34">Stimulus dependence of neuronal correlation in primary visual cortex of the macaque</article-title>. <source hwp:id="source-33">The Journal of neuroscience</source> <volume>25</volume>: <fpage>3661</fpage>–<lpage>3673</lpage>.</citation></ref><ref id="c34" hwp:id="ref-34"><label>[34]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.34" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Averbeck BB"><surname>Averbeck</surname> <given-names>BB</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lee D"><surname>Lee</surname> <given-names>D</given-names></string-name> (<year>2006</year>) <article-title hwp:id="article-title-35">Effects of noise correlations on information encoding and decoding</article-title>. <source hwp:id="source-34">Journal of Neurophysiology</source> <volume>95</volume>: <fpage>3633</fpage>–<lpage>3644</lpage>.</citation></ref><ref id="c35" hwp:id="ref-35" hwp:rev-id="xref-ref-35-1"><label>[35]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.35" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Ohiorhenuan IE"><surname>Ohiorhenuan</surname> <given-names>IE</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mechler F"><surname>Mechler</surname> <given-names>F</given-names></string-name>, <string-name name-style="western" hwp:sortable="Purpura KP"><surname>Purpura</surname> <given-names>KP</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schmid AM"><surname>Schmid</surname> <given-names>AM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hu Q"><surname>Hu</surname> <given-names>Q</given-names></string-name>, <string-name name-style="western" hwp:sortable="Victor JD"><surname>Victor</surname> <given-names>JD</given-names></string-name> (<year>2010</year>) <article-title hwp:id="article-title-36">Sparse coding and high-order correlations in fine-scale cortical networks</article-title>. <source hwp:id="source-35">Nature</source> <volume>466</volume>: <fpage>617</fpage>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1"><label>[36]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.36" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Ponce-Alvarez A"><surname>Ponce-Alvarez</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Thiele A"><surname>Thiele</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Albright TD"><surname>Albright</surname> <given-names>TD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Stoner GR"><surname>Stoner</surname> <given-names>GR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Deco G"><surname>Deco</surname> <given-names>G</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-37">Stimulus-dependent variability and noise correlations in cortical mt neurons</article-title>. <source hwp:id="source-36">Proceedings of the National Academy of Sciences</source> <volume>110</volume>: <fpage>13162</fpage>–<lpage>13167</lpage>.</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1"><label>[37]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.37" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Rigotti M"><surname>Rigotti</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Barak O"><surname>Barak</surname> <given-names>O</given-names></string-name>, <string-name name-style="western" hwp:sortable="Warden MR"><surname>Warden</surname> <given-names>MR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wang XJ"><surname>Wang</surname> <given-names>XJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Daw ND"><surname>Daw</surname> <given-names>ND</given-names></string-name>, <string-name name-style="western" hwp:sortable="Miller EK"><surname>Miller</surname> <given-names>EK</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fusi S"><surname>Fusi</surname> <given-names>S</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-38">The importance of mixed selectivity in complex cognitive tasks</article-title>. <source hwp:id="source-37">Nature</source> <volume>497</volume>: <fpage>585</fpage>–<lpage>590</lpage>.</citation></ref><ref id="c38" hwp:id="ref-38" hwp:rev-id="xref-ref-38-1"><label>[38]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.38" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-38"><string-name name-style="western" hwp:sortable="Pagan M"><surname>Pagan</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rust NC"><surname>Rust</surname> <given-names>NC</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-39">Dynamic target match signals in perirhinal cortex can be explained by instantaneous computations that act on dynamic input from inferotemporal cortex</article-title>. <source hwp:id="source-38">The Journal of Neuroscience</source> <volume>34</volume>: <fpage>11067</fpage>–<lpage>11084</lpage>.</citation></ref><ref id="c39" hwp:id="ref-39" hwp:rev-id="xref-ref-39-1 xref-ref-39-2"><label>[39]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.39" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-39"><string-name name-style="western" hwp:sortable="Britten KH"><surname>Britten</surname> <given-names>KH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newsome WT"><surname>Newsome</surname> <given-names>WT</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shadlen MN"><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Celebrini S"><surname>Celebrini</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Movshon JA"><surname>Movshon</surname> <given-names>JA</given-names></string-name> (<year>1996</year>) <article-title hwp:id="article-title-40">A relationship between behavioral choice and the visual responses of neurons in macaque mt</article-title>. <source hwp:id="source-39">Visual neuroscience</source> <volume>13</volume>: <fpage>87</fpage>–<lpage>100</lpage>.</citation></ref><ref id="c40" hwp:id="ref-40"><label>[40]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.40" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-40"><string-name name-style="western" hwp:sortable="Shadlen MN"><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Britten KH"><surname>Britten</surname> <given-names>KH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newsome WT"><surname>Newsome</surname> <given-names>WT</given-names></string-name>, <string-name name-style="western" hwp:sortable="Movshon JA"><surname>Movshon</surname> <given-names>JA</given-names></string-name> (<year>1996</year>) <article-title hwp:id="article-title-41">A computational analysis of the relationship between neuronal and behavioral responses to visual motion</article-title>. <source hwp:id="source-40">Journal of Neuroscience</source> <volume>16</volume>: <fpage>1486</fpage>–<lpage>1510</lpage>.</citation></ref><ref id="c41" hwp:id="ref-41"><label>[41]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.41" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-41"><string-name name-style="western" hwp:sortable="Dodd JV"><surname>Dodd</surname> <given-names>JV</given-names></string-name>, <string-name name-style="western" hwp:sortable="Krug K"><surname>Krug</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cumming BG"><surname>Cumming</surname> <given-names>BG</given-names></string-name>, <string-name name-style="western" hwp:sortable="Parker AJ"><surname>Parker</surname> <given-names>AJ</given-names></string-name> (<year>2001</year>) <article-title hwp:id="article-title-42">Perceptually bistable three-dimensional figures evoke high choice probabilities in cortical area mt</article-title>. <source hwp:id="source-41">Journal of Neuroscience</source> <volume>21</volume>: <fpage>4809</fpage>–<lpage>4821</lpage>.</citation></ref><ref id="c42" hwp:id="ref-42"><label>[42]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.42" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-42"><string-name name-style="western" hwp:sortable="Krajbich I"><surname>Krajbich</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Armel C"><surname>Armel</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rangel A"><surname>Rangel</surname> <given-names>A</given-names></string-name> (<year>2010</year>) <article-title hwp:id="article-title-43">Visual fixations and the computation and comparison of value in simple choice</article-title>. <source hwp:id="source-42">Nature neuroscience</source> <volume>13</volume>: <fpage>1292</fpage>.</citation></ref><ref id="c43" hwp:id="ref-43"><label>[43]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.43" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-43"><string-name name-style="western" hwp:sortable="de Lafuente V"><surname>de Lafuente</surname> <given-names>V</given-names></string-name>, <string-name name-style="western" hwp:sortable="Romo R"><surname>Romo</surname> <given-names>R</given-names></string-name> (<year>2005</year>) <article-title hwp:id="article-title-44">Neuronal correlates of subjective sensory experience</article-title>. <source hwp:id="source-43">Nature neuroscience</source> <volume>8</volume>: <fpage>1698</fpage>.</citation></ref><ref id="c44" hwp:id="ref-44"><label>[44]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.44" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-44"><string-name name-style="western" hwp:sortable="Treue S"><surname>Treue</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Trujillo JCM"><surname>Trujillo</surname> <given-names>JCM</given-names></string-name> (<year>1999</year>) <article-title hwp:id="article-title-45">Feature-based attention influences motion processing gain in macaque visual cortex</article-title>. <source hwp:id="source-44">Nature</source> <volume>399</volume>: <fpage>575</fpage>.</citation></ref><ref id="c45" hwp:id="ref-45"><label>[45]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.45" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-45"><string-name name-style="western" hwp:sortable="Roitman JD"><surname>Roitman</surname> <given-names>JD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shadlen MN"><surname>Shadlen</surname> <given-names>MN</given-names></string-name> (<year>2002</year>) <article-title hwp:id="article-title-46">Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task</article-title>. <source hwp:id="source-45">Journal of neuroscience</source> <volume>22</volume>: <fpage>9475</fpage>–<lpage>9489</lpage>.</citation></ref><ref id="c46" hwp:id="ref-46"><label>[46]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.46" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-46"><string-name name-style="western" hwp:sortable="Gu Y"><surname>Gu</surname> <given-names>Y</given-names></string-name>, <string-name name-style="western" hwp:sortable="Angelaki DE"><surname>Angelaki</surname> <given-names>DE</given-names></string-name>, <string-name name-style="western" hwp:sortable="DeAngelis GC"><surname>DeAngelis</surname> <given-names>GC</given-names></string-name> (<year>2008</year>) <article-title hwp:id="article-title-47">Neural correlates of multisensory cue integration in macaque mstd</article-title>. <source hwp:id="source-46">Nature neuroscience</source> <volume>11</volume>: <fpage>1201</fpage>.</citation></ref><ref id="c47" hwp:id="ref-47" hwp:rev-id="xref-ref-47-1"><label>[47]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.47" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-47"><string-name name-style="western" hwp:sortable="Purushothaman G"><surname>Purushothaman</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bradley DC"><surname>Bradley</surname> <given-names>DC</given-names></string-name> (<year>2005</year>) <article-title hwp:id="article-title-48">Neural population code for fine perceptual decisions in area mt</article-title>. <source hwp:id="source-47">Nature neuroscience</source> <volume>8</volume>: <fpage>99</fpage>.</citation></ref><ref id="c48" hwp:id="ref-48" hwp:rev-id="xref-ref-48-1 xref-ref-48-2"><label>[48]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.48" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-48"><string-name name-style="western" hwp:sortable="Haefner RM"><surname>Haefner</surname> <given-names>RM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gerwinn S"><surname>Gerwinn</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Macke JH"><surname>Macke</surname> <given-names>JH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bethge M"><surname>Bethge</surname> <given-names>M</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-49">Inferring decoding strategies from choice probabilities in the presence of correlated variability</article-title>. <source hwp:id="source-48">Nature neuroscience</source> <volume>16</volume>: <fpage>235</fpage>–<lpage>242</lpage>.</citation></ref><ref id="c49" hwp:id="ref-49" hwp:rev-id="xref-ref-49-1"><label>[49]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.49" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-49"><string-name name-style="western" hwp:sortable="Britten KH"><surname>Britten</surname> <given-names>KH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newsome WT"><surname>Newsome</surname> <given-names>WT</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shadlen MN"><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Celebrini S"><surname>Celebrini</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Movshon JA"><surname>Movshon</surname> <given-names>JA</given-names></string-name> (<year>1996</year>) <article-title hwp:id="article-title-50">A relationship between behavioral choice and the visual responses of neurons in macaque mt</article-title>. <source hwp:id="source-49">Visual Neuroscience</source> <volume>13</volume>: <fpage>87</fpage>–<lpage>100</lpage>.</citation></ref><ref id="c50" hwp:id="ref-50" hwp:rev-id="xref-ref-50-1"><label>[50]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.50" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-50"><string-name name-style="western" hwp:sortable="Nienborg H"><surname>Nienborg</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cumming BG"><surname>Cumming</surname> <given-names>BG</given-names></string-name> (<year>2007</year>) <article-title hwp:id="article-title-51">Psychophysically measured task strategy for disparity discrimination is reflected in v2 neurons</article-title>. <source hwp:id="source-50">Nature neuroscience</source> <volume>10</volume>: <fpage>1608</fpage>.</citation></ref><ref id="c51" hwp:id="ref-51" hwp:rev-id="xref-ref-51-1"><label>[51]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.51" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-51"><string-name name-style="western" hwp:sortable="Hornik K"><surname>Hornik</surname> <given-names>K</given-names></string-name> (<year>1991</year>) <article-title hwp:id="article-title-52">Approximation capabilities of multilayer feedforward networks</article-title>. <source hwp:id="source-51">Neural networks</source> <volume>4</volume>: <fpage>251</fpage>–<lpage>257</lpage>.</citation></ref><ref id="c52" hwp:id="ref-52" hwp:rev-id="xref-ref-52-1"><label>[52]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.52" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-52"><string-name name-style="western" hwp:sortable="Poggio T"><surname>Poggio</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Koch C"><surname>Koch</surname> <given-names>C</given-names></string-name> (<year>1987</year>) <article-title hwp:id="article-title-53">Synapses that compute motion</article-title>. <source hwp:id="source-52">Scientific American</source> <volume>256</volume>: <fpage>46</fpage>–<lpage>53</lpage>.</citation></ref><ref id="c53" hwp:id="ref-53" hwp:rev-id="xref-ref-53-1"><label>[53]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.53" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-53"><string-name name-style="western" hwp:sortable="Ma WJ"><surname>Ma</surname> <given-names>WJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Navalpakkam V"><surname>Navalpakkam</surname> <given-names>V</given-names></string-name>, <string-name name-style="western" hwp:sortable="Beck JM"><surname>Beck</surname> <given-names>JM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Van Den Berg R"><surname>Van Den Berg</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pouget A"><surname>Pouget</surname> <given-names>A</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-54">Behavior and neural basis of near-optimal visual search</article-title>. <source hwp:id="source-53">Nature neuroscience</source> <volume>14</volume>: <fpage>783</fpage>.</citation></ref><ref id="c54" hwp:id="ref-54" hwp:rev-id="xref-ref-54-1"><label>[54]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.54" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-54"><string-name name-style="western" hwp:sortable="Davis KA"><surname>Davis</surname> <given-names>KA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ramachandran R"><surname>Ramachandran</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="May BJ"><surname>May</surname> <given-names>BJ</given-names></string-name> (<year>2003</year>) <article-title hwp:id="article-title-55">Auditory processing of spectral cues for sound localization in the inferior colliculus</article-title>. <source hwp:id="source-54">Journal of the Association for Research in Otolaryngology</source> <volume>4</volume>: <fpage>148</fpage>–<lpage>163</lpage>.</citation></ref><ref id="c55" hwp:id="ref-55" hwp:rev-id="xref-ref-55-1 xref-ref-55-2"><label>[55]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.55" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-55"><string-name name-style="western" hwp:sortable="Saez A"><surname>Saez</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rigotti M"><surname>Rigotti</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ostojic S"><surname>Ostojic</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fusi S"><surname>Fusi</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Salzman C"><surname>Salzman</surname> <given-names>C</given-names></string-name> (<year>2015</year>) <article-title hwp:id="article-title-56">Abstract context representations in primate amygdala and prefrontal cortex</article-title>. <source hwp:id="source-55">Neuron</source> <volume>87</volume>: <fpage>869</fpage>–<lpage>881</lpage>.</citation></ref><ref id="c56" hwp:id="ref-56" hwp:rev-id="xref-ref-56-1"><label>[56]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.56" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-56"><string-name name-style="western" hwp:sortable="Cohen MR"><surname>Cohen</surname> <given-names>MR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newsome WT"><surname>Newsome</surname> <given-names>WT</given-names></string-name> (<year>2008</year>) <article-title hwp:id="article-title-57">Contextdependent changes in functional circuitry in visual area mt</article-title>. <source hwp:id="source-56">Neuron</source> <volume>60</volume>: <fpage>162</fpage>–<lpage>173</lpage>.</citation></ref><ref id="c57" hwp:id="ref-57" hwp:rev-id="xref-ref-57-1"><label>[57]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.57" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-57"><string-name name-style="western" hwp:sortable="Lange RD"><surname>Lange</surname> <given-names>RD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haefner RM"><surname>Haefner</surname> <given-names>RM</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-58">Inferring the brain9s internal model from sensory responses in a probabilistic inference framework</article-title>. <source hwp:id="source-57">bioRxiv</source>: <volume>081661</volume>.</citation></ref><ref id="c58" hwp:id="ref-58" hwp:rev-id="xref-ref-58-1"><label>[58]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.58" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-58"><string-name name-style="western" hwp:sortable="Mante V"><surname>Mante</surname> <given-names>V</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sussillo D"><surname>Sussillo</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shenoy KV"><surname>Shenoy</surname> <given-names>KV</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newsome WT"><surname>Newsome</surname> <given-names>WT</given-names></string-name> (<year>2013</year>) <article-title hwp:id="article-title-59">Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title>. <source hwp:id="source-58">Nature</source> <volume>503</volume>: <fpage>78</fpage>–<lpage>84</lpage>.</citation></ref><ref id="c59" hwp:id="ref-59" hwp:rev-id="xref-ref-59-1"><label>[59]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.59" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-59"><string-name name-style="western" hwp:sortable="Yang Q"><surname>Yang</surname> <given-names>Q</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pitkow X"><surname>Pitkow</surname> <given-names>X</given-names></string-name> (<year>2015</year>) <article-title hwp:id="article-title-60">Robust nonlinear neural codes</article-title>. <source hwp:id="source-59">Cosyne abstract</source>.</citation></ref><ref id="c60" hwp:id="ref-60" hwp:rev-id="xref-ref-60-1"><label>[60]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.60" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-60"><string-name name-style="western" hwp:sortable="Haefner RM"><surname>Haefner</surname> <given-names>RM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Berkes P"><surname>Berkes</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fiser J"><surname>Fiser</surname> <given-names>J</given-names></string-name> (<year>2016</year>) <article-title hwp:id="article-title-61">Perceptual decision-making as probabilistic inference by neural sampling</article-title>. <source hwp:id="source-60">Neuron</source> <volume>90</volume>: <fpage>649</fpage>–<lpage>660</lpage>.</citation></ref><ref id="c61" hwp:id="ref-61" hwp:rev-id="xref-ref-61-1"><label>[61]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.61" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-61"><string-name name-style="western" hwp:sortable="Ma WJ"><surname>Ma</surname> <given-names>WJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Beck JM"><surname>Beck</surname> <given-names>JM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Latham PE"><surname>Latham</surname> <given-names>PE</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pouget A"><surname>Pouget</surname> <given-names>A</given-names></string-name> (<year>2006</year>) <article-title hwp:id="article-title-62">Bayesian inference with probabilistic population codes</article-title>. <source hwp:id="source-61">Nature neuroscience</source> <volume>9</volume>: <fpage>1432</fpage>.</citation></ref><ref id="c62" hwp:id="ref-62" hwp:rev-id="xref-ref-62-1"><label>[62]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.62" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-62"><string-name name-style="western" hwp:sortable="Graf AB"><surname>Graf</surname> <given-names>AB</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kohn A"><surname>Kohn</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jazayeri M"><surname>Jazayeri</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Movshon JA"><surname>Movshon</surname> <given-names>JA</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-63">Decoding the activity of neuronal populations in macaque primary visual cortex</article-title>. <source hwp:id="source-62">Nature neuroscience</source> <volume>14</volume>: <fpage>239</fpage>.</citation></ref><ref id="c63" hwp:id="ref-63" hwp:rev-id="xref-ref-63-1"><label>[63]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.63" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-63"><string-name name-style="western" hwp:sortable="Babadi B"><surname>Babadi</surname> <given-names>B</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sompolinsky H"><surname>Sompolinsky</surname> <given-names>H</given-names></string-name> (<year>2014</year>) <article-title hwp:id="article-title-64">Sparseness and expansion in sensory representations</article-title>. <source hwp:id="source-63">Neuron</source> <volume>83</volume>: <fpage>1213</fpage>–<lpage>1226</lpage>.</citation></ref><ref id="c64" hwp:id="ref-64" hwp:rev-id="xref-ref-64-1"><label>[64]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.64" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-64"><string-name name-style="western" hwp:sortable="Maynard E"><surname>Maynard</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hatsopoulos N"><surname>Hatsopoulos</surname> <given-names>N</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ojakangas C"><surname>Ojakangas</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Acuna B"><surname>Acuna</surname> <given-names>B</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sanes J"><surname>Sanes</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Normann R"><surname>Normann</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Donoghue J"><surname>Donoghue</surname> <given-names>J</given-names></string-name> (<year>1999</year>) <article-title hwp:id="article-title-65">Neuronal interactions improve cortical population coding of movement direction</article-title>. <source hwp:id="source-64">Journal of Neuroscience</source> <volume>19</volume>: <fpage>8083</fpage>–<lpage>8093</lpage>.</citation></ref><ref id="c65" hwp:id="ref-65" hwp:rev-id="xref-ref-65-1"><label>[65]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.65" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-65"><string-name name-style="western" hwp:sortable="Kanitscheider I"><surname>Kanitscheider</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Coen-Cagli R"><surname>Coen-Cagli</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kohn A"><surname>Kohn</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pouget A"><surname>Pouget</surname> <given-names>A</given-names></string-name> (<year>2015</year>) <article-title hwp:id="article-title-66">Measuring fisher information accurately in correlated neural populations</article-title>. <source hwp:id="source-65">PLoS computational biology</source> <volume>11</volume>: <fpage>e1004218</fpage>.</citation></ref><ref id="c66" hwp:id="ref-66" hwp:rev-id="xref-ref-66-1"><label>[66]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.66" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-66"><string-name name-style="western" hwp:sortable="Kang I"><surname>Kang</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Maunsell JH"><surname>Maunsell</surname> <given-names>JH</given-names></string-name> (<year>2012</year>) <article-title hwp:id="article-title-67">Potential confounds in estimating trial-to-trial correlations between neuronal response and behavior using choice probabilities</article-title>. <source hwp:id="source-66">Journal of neurophysiology</source> <volume>108</volume>: <fpage>3403</fpage>–<lpage>3415</lpage>.</citation></ref><ref id="c67" hwp:id="ref-67" hwp:rev-id="xref-ref-67-1"><label>[67]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.67" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-67"><string-name name-style="western" hwp:sortable="Berens P"><surname>Berens</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ecker AS"><surname>Ecker</surname> <given-names>AS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gerwinn S"><surname>Gerwinn</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tolias AS"><surname>Tolias</surname> <given-names>AS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bethge M"><surname>Bethge</surname> <given-names>M</given-names></string-name> (<year>2011</year>) <article-title hwp:id="article-title-68">Reassessing optimal neural population codes with neurometric functions</article-title>. <source hwp:id="source-67">Proceedings of the National Academy of Sciences</source> <volume>108</volume>: <fpage>4423</fpage>–<lpage>4428</lpage>.</citation></ref><ref id="c68" hwp:id="ref-68" hwp:rev-id="xref-ref-68-1"><label>[68]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.68" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-68"><string-name name-style="western" hwp:sortable="Green DM"><surname>Green</surname> <given-names>DM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Swets JA"><surname>Swets</surname> <given-names>JA</given-names></string-name> (<year>1966</year>) <source hwp:id="source-68">Signal detection theory and psychophysics. John Wiley</source>.</citation></ref><ref id="c69" hwp:id="ref-69" hwp:rev-id="xref-ref-69-1"><label>[69]</label><citation publication-type="journal" citation-type="journal" ref:id="332353v1.69" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-69"><string-name name-style="western" hwp:sortable="Bethge M"><surname>Bethge</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rotermund D"><surname>Rotermund</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pawelzik K"><surname>Pawelzik</surname> <given-names>K</given-names></string-name> (<year>2002</year>) <article-title hwp:id="article-title-69">Optimal short-term population coding: when fisher information fails</article-title>. <source hwp:id="source-69">Neural computation</source> <volume>14</volume>: <fpage>2317</fpage>–<lpage>2351</lpage>.</citation></ref></ref-list><sec id="s6" hwp:id="sec-30"><title hwp:id="title-32">Supplemental material</title><sec id="s6a" hwp:id="sec-31"><title hwp:id="title-33">S1 Exponential family distributions</title><p hwp:id="p-99">For a stimulus <italic toggle="yes">s</italic> and a response <bold><italic toggle="yes">r</italic></bold>, the conditional prob-ability is a member of the exponential family when
<disp-formula id="eqn26" hwp:id="disp-formula-26">
<alternatives hwp:id="alternatives-52"><graphic xlink:href="332353_eqn26.gif" position="float" orientation="portrait" hwp:id="graphic-33"/></alternatives>
</disp-formula>
where <bold><italic toggle="yes">H</italic></bold>(<italic toggle="yes">s</italic>) are the natural parameters, <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) are the sufficient statistics, <italic toggle="yes">A</italic>(<italic toggle="yes">s</italic>) and <italic toggle="yes">b</italic>(<bold><italic toggle="yes">r</italic></bold>) are the log nor-malizer and base measure. The statistics <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) are called sufficient because they contain all the informa-tion needed to estimate the stimulus <italic toggle="yes">s</italic>.
</p><sec id="s6a1" hwp:id="sec-32"><title hwp:id="title-34">S1.1 Fisher information</title><p hwp:id="p-100">One measure of information content that a population response contains about a stimulus is the Fisher infor-mation <italic toggle="yes">J</italic> (<italic toggle="yes">s</italic>) [<xref rid="c16" ref-type="bibr" hwp:id="xref-ref-16-6" hwp:rel-id="ref-16">16</xref>, <xref rid="c24" ref-type="bibr" hwp:id="xref-ref-24-2" hwp:rel-id="ref-24">24</xref>–<xref rid="c27" ref-type="bibr" hwp:id="xref-ref-27-5" hwp:rel-id="ref-27">27</xref>, <xref rid="c29" ref-type="bibr" hwp:id="xref-ref-29-2" hwp:rel-id="ref-29">29</xref>]. The Fisher information is given by
<disp-formula id="eqn27" hwp:id="disp-formula-27">
<alternatives hwp:id="alternatives-53"><graphic xlink:href="332353_eqn27.gif" position="float" orientation="portrait" hwp:id="graphic-34"/></alternatives>
</disp-formula>
<disp-formula id="eqn28" hwp:id="disp-formula-28">
<alternatives hwp:id="alternatives-54"><graphic xlink:href="332353_eqn28.gif" position="float" orientation="portrait" hwp:id="graphic-35"/></alternatives>
</disp-formula>
</p><p hwp:id="p-101">For distributions <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>) in the exponential family with sufficient statistics <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>), we can compute these quantities analytically. We denote the mean of the sufficient statistics as <bold><italic toggle="yes">F</italic></bold> (<italic toggle="yes">s</italic>) = ⟨<bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>)<italic toggle="yes">|s</italic> ⟩ This mean ⟨<bold><italic toggle="yes">R</italic></bold><italic toggle="yes">|s</italic> ⟩ can be obtained by differentiating <italic toggle="yes">A</italic>(<italic toggle="yes">s</italic>) by the natural parameters <bold><italic toggle="yes">H</italic></bold>(<italic toggle="yes">s</italic>),
<disp-formula id="eqn29" hwp:id="disp-formula-29" hwp:rev-id="xref-disp-formula-29-1">
<alternatives hwp:id="alternatives-55"><graphic xlink:href="332353_eqn29.gif" position="float" orientation="portrait" hwp:id="graphic-36"/></alternatives>
</disp-formula>
</p><p hwp:id="p-102"><xref ref-type="disp-formula" rid="eqn29" hwp:id="xref-disp-formula-29-1" hwp:rel-id="disp-formula-29">Equation 29</xref> can give us the first and second derivatives of <italic toggle="yes">A</italic>(<italic toggle="yes">s</italic>) over <italic toggle="yes">s</italic>.
<disp-formula id="eqn30" hwp:id="disp-formula-30">
<alternatives hwp:id="alternatives-56"><graphic xlink:href="332353_eqn30.gif" position="float" orientation="portrait" hwp:id="graphic-37"/></alternatives>
</disp-formula>
<disp-formula id="eqn31" hwp:id="disp-formula-31">
<alternatives hwp:id="alternatives-57"><graphic xlink:href="332353_eqn31.gif" position="float" orientation="portrait" hwp:id="graphic-38"/></alternatives>
</disp-formula>
</p><p hwp:id="p-103">Thus we can compute two definitions of Fisher information.
<disp-formula id="eqn32" hwp:id="disp-formula-32">
<alternatives hwp:id="alternatives-58"><graphic xlink:href="332353_eqn32.gif" position="float" orientation="portrait" hwp:id="graphic-39"/></alternatives>
</disp-formula>
<disp-formula id="eqn33" hwp:id="disp-formula-33">
<alternatives hwp:id="alternatives-59"><graphic xlink:href="332353_eqn33.gif" position="float" orientation="portrait" hwp:id="graphic-40"/></alternatives>
</disp-formula>
<disp-formula id="eqn34" hwp:id="disp-formula-34">
<alternatives hwp:id="alternatives-60"><graphic xlink:href="332353_eqn34.gif" position="float" orientation="portrait" hwp:id="graphic-41"/></alternatives>
</disp-formula>
and
<disp-formula id="eqn35" hwp:id="disp-formula-35">
<alternatives hwp:id="alternatives-61"><graphic xlink:href="332353_eqn35.gif" position="float" orientation="portrait" hwp:id="graphic-42"/></alternatives>
</disp-formula>
<disp-formula id="eqn36" hwp:id="disp-formula-36">
<alternatives hwp:id="alternatives-62"><graphic xlink:href="332353_eqn36.gif" position="float" orientation="portrait" hwp:id="graphic-43"/></alternatives>
</disp-formula>
<disp-formula id="eqn37" hwp:id="disp-formula-37" hwp:rev-id="xref-disp-formula-37-1">
<alternatives hwp:id="alternatives-63"><graphic xlink:href="332353_eqn37.gif" position="float" orientation="portrait" hwp:id="graphic-44"/></alternatives>
</disp-formula>
where Γ = Cov[<bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>)<italic toggle="yes">|s</italic>].</p><p hwp:id="p-104">Since the two definition are equivalent, we have
<disp-formula id="eqn38" hwp:id="disp-formula-38" hwp:rev-id="xref-disp-formula-38-1">
<alternatives hwp:id="alternatives-64"><graphic xlink:href="332353_eqn38.gif" position="float" orientation="portrait" hwp:id="graphic-45"/></alternatives>
</disp-formula>
</p><p hwp:id="p-105">Substituting <xref ref-type="disp-formula" rid="eqn38" hwp:id="xref-disp-formula-38-1" hwp:rel-id="disp-formula-38">Equation 38</xref> into <xref ref-type="disp-formula" rid="eqn37" hwp:id="xref-disp-formula-37-1" hwp:rel-id="disp-formula-37">Equation 37</xref>, we find the Fisher Information for the exponential family [<xref rid="c23" ref-type="bibr" hwp:id="xref-ref-23-5" hwp:rel-id="ref-23">23</xref>]
<disp-formula id="eqn39" hwp:id="disp-formula-39">
<alternatives hwp:id="alternatives-65"><graphic xlink:href="332353_eqn39.gif" position="float" orientation="portrait" hwp:id="graphic-46"/></alternatives>
</disp-formula>
</p></sec></sec><sec id="s6b" hwp:id="sec-33"><title hwp:id="title-35">S1.2 Estimation in the exponential family</title><p hwp:id="p-106">Again assuming responses come from this distribution, we want to compute the maximum likelihood stimulus, <inline-formula hwp:id="inline-formula-27"><alternatives hwp:id="alternatives-66"><inline-graphic xlink:href="332353_inline26.gif" hwp:id="inline-graphic-27"/></alternatives></inline-formula>, near a reference stimulus <italic toggle="yes">s</italic><sub>0</sub>:
<disp-formula id="eqn40" hwp:id="disp-formula-40">
<alternatives hwp:id="alternatives-67"><graphic xlink:href="332353_eqn40.gif" position="float" orientation="portrait" hwp:id="graphic-47"/></alternatives>
</disp-formula>
<disp-formula id="eqn41" hwp:id="disp-formula-41">
<alternatives hwp:id="alternatives-68"><graphic xlink:href="332353_eqn41.gif" position="float" orientation="portrait" hwp:id="graphic-48"/></alternatives>
</disp-formula>
<disp-formula id="eqn42" hwp:id="disp-formula-42">
<alternatives hwp:id="alternatives-69"><graphic xlink:href="332353_eqn42.gif" position="float" orientation="portrait" hwp:id="graphic-49"/></alternatives>
</disp-formula>
</p><p hwp:id="p-107">A Taylor expansion around the reference yields
<disp-formula id="eqn43" hwp:id="disp-formula-43">
<alternatives hwp:id="alternatives-70"><graphic xlink:href="332353_eqn43.gif" position="float" orientation="portrait" hwp:id="graphic-50"/></alternatives>
</disp-formula>
where all functions and derivatives are evaluated at <italic toggle="yes">s</italic><sub>0</sub>. We find the maximum by differentiating with respect to <italic toggle="yes">s</italic> and setting the result equal to zero:
<disp-formula id="eqn44" hwp:id="disp-formula-44">
<alternatives hwp:id="alternatives-71"><graphic xlink:href="332353_eqn44.gif" position="float" orientation="portrait" hwp:id="graphic-51"/></alternatives>
</disp-formula>
</p><p hwp:id="p-108">The solution is
<disp-formula id="eqn45" hwp:id="disp-formula-45">
<alternatives hwp:id="alternatives-72"><graphic xlink:href="332353_eqn45.gif" position="float" orientation="portrait" hwp:id="graphic-52"/></alternatives>
</disp-formula>
</p><p hwp:id="p-109">Since <bold><italic toggle="yes">r</italic></bold> is a random quantity, we can express <bold><italic toggle="yes">R</italic></bold> as a mean and a deviation away from that mean: <bold><italic toggle="yes">R</italic></bold> = ⟨<bold><italic toggle="yes">R</italic></bold><italic toggle="yes">|s</italic><sub>0</sub> ⟩ + <italic toggle="yes">δ</italic><bold><italic toggle="yes">R</italic></bold> = <bold><italic toggle="yes">F</italic></bold> + <italic toggle="yes">δ</italic><bold><italic toggle="yes">R</italic></bold>. In this case, <bold><italic toggle="yes">H</italic></bold><sup><italic toggle="yes">″T</italic></sup><bold><italic toggle="yes">R</italic></bold> <italic toggle="yes">-A</italic><sup><italic toggle="yes">″</italic></sup> = <bold><italic toggle="yes">H</italic></bold><sup><italic toggle="yes">″T</italic></sup><bold><italic toggle="yes">F</italic></bold> <italic toggle="yes">-A</italic><sup><italic toggle="yes">″</italic></sup>+<bold><italic toggle="yes">H</italic></bold><sup><italic toggle="yes">″T</italic></sup><italic toggle="yes">δ</italic><bold><italic toggle="yes">R</italic></bold>, where the mean term is precisely the negative Fisher Information <italic toggle="yes">-J</italic> (<italic toggle="yes">s</italic><sub>0</sub>). If the trial-to-trial fluctuations in the uncertainty are small relative to the average uncertainty then this Fisher term will dominate. Then we have
<disp-formula id="eqn46" hwp:id="disp-formula-46" hwp:rev-id="xref-disp-formula-46-1">
<alternatives hwp:id="alternatives-73"><graphic xlink:href="332353_eqn46.gif" position="float" orientation="portrait" hwp:id="graphic-53"/></alternatives>
</disp-formula>
</p><p hwp:id="p-110">Where
<disp-formula id="eqn47" hwp:id="disp-formula-47">
<alternatives hwp:id="alternatives-74"><graphic xlink:href="332353_eqn47.gif" position="float" orientation="portrait" hwp:id="graphic-54"/></alternatives>
</disp-formula>
and where we used the results from <xref ref-type="disp-formula" rid="eqn13" hwp:id="xref-disp-formula-13-2" hwp:rel-id="disp-formula-13">Equations 13</xref> and 38, with Γ = Cov(<bold><italic toggle="yes">R</italic></bold><italic toggle="yes">|s</italic><sub>0</sub>) and <bold><italic toggle="yes">F</italic></bold> = ⟨<bold><italic toggle="yes">R</italic></bold><italic toggle="yes">|s</italic><sub>0</sub> ⟩. Thus, in this limit, the optimal estimator for <italic toggle="yes">s</italic> is a linear decoding of the sufficient statistics <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>).</p></sec></sec><sec id="s7" hwp:id="sec-34"><title hwp:id="title-36">S2 Orientation estimation task with varying spatial phase</title><p hwp:id="p-111">In <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-4" hwp:rel-id="F2">Figure 2B</xref>, the subject’s task is to estimate orientation <italic toggle="yes">s</italic> near a reference <italic toggle="yes">s</italic><sub>0</sub>, based on images <italic toggle="yes">G</italic> of Gabor patterns given by
<disp-formula id="eqn48" hwp:id="disp-formula-48">
<alternatives hwp:id="alternatives-75"><graphic xlink:href="332353_eqn48.gif" position="float" orientation="portrait" hwp:id="graphic-55"/></alternatives>
</disp-formula>
where <bold><italic toggle="yes">k</italic></bold> = <italic toggle="yes">κ</italic>(cos <italic toggle="yes">s,</italic> sin <italic toggle="yes">s</italic>). Here the target <italic toggle="yes">s</italic> is the orientation of the pattern, <bold><italic toggle="yes">n</italic></bold> is a nuisance variable reflecting the spatial phase, <bold><italic toggle="yes">x</italic></bold> is the pixel location in the image, and <bold><italic toggle="yes">k</italic></bold> is a spatial frequency vector with amplitude <italic toggle="yes">κ</italic> = ∥<bold><italic toggle="yes">k</italic></bold>.∥ We assume the spatial receptive field of simple cell <italic toggle="yes">j</italic> in primary visual cortex is also described by a Gabor function
<disp-formula id="eqn49" hwp:id="disp-formula-49">
<alternatives hwp:id="alternatives-76"><graphic xlink:href="332353_eqn49.gif" position="float" orientation="portrait" hwp:id="graphic-56"/></alternatives>
</disp-formula>
<disp-formula id="eqn50" hwp:id="disp-formula-50">
<alternatives hwp:id="alternatives-77"><graphic xlink:href="332353_eqn50.gif" position="float" orientation="portrait" hwp:id="graphic-57"/></alternatives>
</disp-formula>
where each neuron has a preferred orientation <italic toggle="yes">s</italic><sub><italic toggle="yes">j</italic></sub>, spa-tial phase <italic toggle="yes">n</italic><sub><italic toggle="yes">j</italic></sub>, and spatial frequency <bold><italic toggle="yes">k</italic></bold><sub><italic toggle="yes">j</italic></sub>. Here for sim-plicity we assume that all neurons’ preferred spatial frequencies have the same amplitude <italic toggle="yes">κ</italic> that matches the input image.</p><p hwp:id="p-112">We model the mean neuronal responses by the over-lap between the image and their linear receptive field. This overlap determines the tuning curve of each neuron:
<disp-formula id="eqn51" hwp:id="disp-formula-51">
<alternatives hwp:id="alternatives-78"><graphic xlink:href="332353_eqn51.gif" position="float" orientation="portrait" hwp:id="graphic-58"/></alternatives>
</disp-formula>
</p><p hwp:id="p-113">This expression can be written in the form:
<disp-formula id="eqn52" hwp:id="disp-formula-52" hwp:rev-id="xref-disp-formula-52-1">
<alternatives hwp:id="alternatives-79"><graphic xlink:href="332353_eqn52.gif" position="float" orientation="portrait" hwp:id="graphic-59"/></alternatives>
</disp-formula>
using the stimulus-dependent response amplitude
<disp-formula id="eqn53" hwp:id="disp-formula-53">
<alternatives hwp:id="alternatives-80"><graphic xlink:href="332353_eqn53.gif" position="float" orientation="portrait" hwp:id="graphic-60"/></alternatives>
</disp-formula>
and phase
<disp-formula id="eqn54" hwp:id="disp-formula-54">
<alternatives hwp:id="alternatives-81"><graphic xlink:href="332353_eqn54.gif" position="float" orientation="portrait" hwp:id="graphic-61"/></alternatives>
</disp-formula>
where we define the cotants
<disp-formula id="eqn55" hwp:id="disp-formula-55">
<alternatives hwp:id="alternatives-82"><graphic xlink:href="332353_eqn55.gif" position="float" orientation="portrait" hwp:id="graphic-62"/></alternatives>
</disp-formula>
<disp-formula id="eqn56" hwp:id="disp-formula-56">
<alternatives hwp:id="alternatives-83"><graphic xlink:href="332353_eqn56.gif" position="float" orientation="portrait" hwp:id="graphic-63"/></alternatives>
</disp-formula>
<disp-formula id="eqn57" hwp:id="disp-formula-57">
<alternatives hwp:id="alternatives-84"><graphic xlink:href="332353_eqn57.gif" position="float" orientation="portrait" hwp:id="graphic-64"/></alternatives>
</disp-formula>
</p><p hwp:id="p-114"><xref ref-type="disp-formula" rid="eqn52" hwp:id="xref-disp-formula-52-1" hwp:rel-id="disp-formula-52">Equation 52</xref> reveals that the mean response of each neuron traces out a sinusoidal oscillation in <italic toggle="yes">n</italic>, where the amplitude and phase depend on <italic toggle="yes">s</italic> and the specific neuron <italic toggle="yes">j</italic>. The mean tuning for each pair of neurons therefore traces out an ellipse as a function of the nuisance variable, the input’s spatial phase. When we <italic toggle="yes">average</italic> over the ellipse generated by the nuisance variable <italic toggle="yes">n</italic>, the mean tuning to <italic toggle="yes">s</italic> is abolished — but the response <italic toggle="yes">covariances</italic> (nuisance correlations) re-main tuned to <italic toggle="yes">s</italic>.</p><p hwp:id="p-115">Assuming each neuron’s response variability is drawn independently from a standard Gaussian <italic toggle="yes">N</italic> (0, 1), we can write the response distribution as
<disp-formula id="eqn58" hwp:id="disp-formula-58">
<alternatives hwp:id="alternatives-85"><graphic xlink:href="332353_eqn58.gif" position="float" orientation="portrait" hwp:id="graphic-65"/></alternatives>
</disp-formula>
</p><p hwp:id="p-116">If the spatial phase <italic toggle="yes">n</italic> were fixed and known, the brain could estimate the orientation just from the mean tuning of the neural responses. However, if the spatial phase is unknown and varies between stimulus presen-tations uniformly from 0 to 2<italic toggle="yes">π</italic>, the mean tuning <bold><italic toggle="yes">f</italic></bold> (<italic toggle="yes">s</italic>) can be expressed as
<disp-formula id="eqn59" hwp:id="disp-formula-59">
<alternatives hwp:id="alternatives-86"><graphic xlink:href="332353_eqn59.gif" position="float" orientation="portrait" hwp:id="graphic-66"/></alternatives>
</disp-formula>
<disp-formula id="eqn60" hwp:id="disp-formula-60">
<alternatives hwp:id="alternatives-87"><graphic xlink:href="332353_eqn60.gif" position="float" orientation="portrait" hwp:id="graphic-67"/></alternatives>
</disp-formula>
<disp-formula id="eqn61" hwp:id="disp-formula-61">
<alternatives hwp:id="alternatives-88"><graphic xlink:href="332353_eqn61.gif" position="float" orientation="portrait" hwp:id="graphic-68"/></alternatives>
</disp-formula>
<disp-formula id="eqn62" hwp:id="disp-formula-62">
<alternatives hwp:id="alternatives-89"><graphic xlink:href="332353_eqn62.gif" position="float" orientation="portrait" hwp:id="graphic-69"/></alternatives>
</disp-formula>
<disp-formula id="eqn63" hwp:id="disp-formula-63">
<alternatives hwp:id="alternatives-90"><graphic xlink:href="332353_eqn63.gif" position="float" orientation="portrait" hwp:id="graphic-70"/></alternatives>
</disp-formula>
</p><p hwp:id="p-117">This shows that there is no signal in the mean responses.</p><p hwp:id="p-118">However, the brain can perform quadratic computations to eliminate the nuisance variable. We can de-fine Cov<sub><italic toggle="yes">ij</italic></sub>[<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s, n</italic>] as the neural covariance (noise correlations) when everything in the image is fixed, and Cov<sub><italic toggle="yes">ij</italic></sub>[<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>] as the neural covariance when the nuisance is unknown and free to vary (nuisance correlations). Then Cov<sub><italic toggle="yes">ij</italic></sub>[<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>] is
<disp-formula id="eqn64" hwp:id="disp-formula-64">
<alternatives hwp:id="alternatives-91"><graphic xlink:href="332353_eqn64.gif" position="float" orientation="portrait" hwp:id="graphic-71"/></alternatives>
</disp-formula>
<disp-formula id="eqn65" hwp:id="disp-formula-65">
<alternatives hwp:id="alternatives-92"><graphic xlink:href="332353_eqn65.gif" position="float" orientation="portrait" hwp:id="graphic-72"/></alternatives>
</disp-formula>
<disp-formula id="eqn66" hwp:id="disp-formula-66">
<alternatives hwp:id="alternatives-93"><graphic xlink:href="332353_eqn66.gif" position="float" orientation="portrait" hwp:id="graphic-73"/></alternatives>
</disp-formula>
<disp-formula id="eqn67" hwp:id="disp-formula-67">
<alternatives hwp:id="alternatives-94"><graphic xlink:href="332353_eqn67.gif" position="float" orientation="portrait" hwp:id="graphic-74"/></alternatives>
</disp-formula>
<disp-formula id="eqn68" hwp:id="disp-formula-68">
<alternatives hwp:id="alternatives-95"><graphic xlink:href="332353_eqn68.gif" position="float" orientation="portrait" hwp:id="graphic-75"/></alternatives>
</disp-formula>
<disp-formula id="eqn69" hwp:id="disp-formula-69">
<alternatives hwp:id="alternatives-96"><graphic xlink:href="332353_eqn69.gif" position="float" orientation="portrait" hwp:id="graphic-76"/></alternatives>
</disp-formula>
<disp-formula id="eqn70" hwp:id="disp-formula-70">
<alternatives hwp:id="alternatives-97"><graphic xlink:href="332353_eqn70.gif" position="float" orientation="portrait" hwp:id="graphic-77"/></alternatives>
</disp-formula>
where <italic toggle="yes">D</italic><sub><italic toggle="yes">ij</italic></sub>(s) is given by
<disp-formula id="eqn71" hwp:id="disp-formula-71" hwp:rev-id="xref-disp-formula-71-1">
<alternatives hwp:id="alternatives-98"><graphic xlink:href="332353_eqn71.gif" position="float" orientation="portrait" hwp:id="graphic-78"/></alternatives>
</disp-formula>
</p><p hwp:id="p-119">Here when we compute <xref ref-type="disp-formula" rid="eqn71" hwp:id="xref-disp-formula-71-1" hwp:rel-id="disp-formula-71">Equation 71</xref>, we used the trigonometric identity: 2 cos(<italic toggle="yes">x</italic>) cos(<italic toggle="yes">y</italic>) = cos(<italic toggle="yes">x</italic> + <italic toggle="yes">y</italic>) + cos(<italic toggle="yes">x -y</italic>), and cos(2<italic toggle="yes">n</italic> + <italic toggle="yes">ψ</italic><sub><italic toggle="yes">i</italic></sub> + <italic toggle="yes">ψ</italic><sub><italic toggle="yes">j</italic></sub>)<italic toggle="yes">dn</italic> = 0.</p><p hwp:id="p-120">This demonstrates that the neural covariance Cov<sub><italic toggle="yes">ij</italic></sub>[<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>] depends on the orientation <italic toggle="yes">s</italic>. While lin-ear computation is useless for estimating orientation since the mean responses are untuned (59), quadratic (or higher-order) nonlinear computations can be used to estimate the orientation.</p></sec><sec id="s8" hwp:id="sec-35"><title hwp:id="title-37">S3 Quadratic coding model</title><p hwp:id="p-121">In a purely quadratic coding model (no linear infor-mation), the distribution of neural responses is de-scribed by the exponential family with quadratic sufficient statistics, <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>) <italic toggle="yes">∼</italic> exp [<bold><italic toggle="yes">H</italic></bold>(<italic toggle="yes">s</italic>)<sup><italic toggle="yes">T</italic></sup><bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>)] where <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) = (<italic toggle="yes">…, r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub>, <italic toggle="yes">…</italic>). A familiar example is a Gaussian distribution with stimulus-dependent covariance: <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>) = <italic toggle="yes">N</italic> (<bold><italic toggle="yes">f</italic></bold>, Σ(<italic toggle="yes">s</italic>)).</p><p hwp:id="p-122">As a concrete example we construct a covariance that rotates with stimulus <italic toggle="yes">s</italic>. Any covariance matrix needs to be positive semidefinite. We build Σ(<italic toggle="yes">s</italic>) by setting the eigenvalues to be positive and <italic toggle="yes">s</italic>-independent and eigenvectors to form an orthogonal basis that rotates with <italic toggle="yes">s</italic>:
<disp-formula id="eqn72" hwp:id="disp-formula-72" hwp:rev-id="xref-disp-formula-72-1">
<alternatives hwp:id="alternatives-99"><graphic xlink:href="332353_eqn72.gif" position="float" orientation="portrait" hwp:id="graphic-79"/></alternatives>
</disp-formula>
where <italic toggle="yes">V</italic> (<italic toggle="yes">s</italic>) = exp <italic toggle="yes">As</italic> is a rotation matrix in which <italic toggle="yes">A</italic> = <italic toggle="yes">-A</italic><sup><italic toggle="yes">T</italic></sup>is a real antisymmetric matrix with pure imaginary eigenvalues, and Λ is a diagonal matrix com posed of all positive eigenvalues.</p><p hwp:id="p-123">To calculate the Fisher Information (<xref ref-type="disp-formula" rid="eqn13" hwp:id="xref-disp-formula-13-3" hwp:rel-id="disp-formula-13">Equation 13</xref>), we need to first calculate the derivative of the mean <inline-formula hwp:id="inline-formula-28"><alternatives hwp:id="alternatives-100"><inline-graphic xlink:href="332353_inline27.gif" hwp:id="inline-graphic-28"/></alternatives></inline-formula> and covariance Γ = Cov[<bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>)<italic toggle="yes">|s</italic>] of the quadratic sufficient statistics.</p><p hwp:id="p-124">Because the mean of <bold><italic toggle="yes">r</italic></bold> is not dependent on the stim-ulus in this example, we can compute <italic toggle="yes"><inline-formula hwp:id="inline-formula-29"><alternatives hwp:id="alternatives-101"><inline-graphic xlink:href="332353_inline28.gif" hwp:id="inline-graphic-29"/></alternatives></inline-formula></italic> <inline-formula hwp:id="inline-formula-30"><alternatives hwp:id="alternatives-102"><inline-graphic xlink:href="332353_inline28a.gif" hwp:id="inline-graphic-30"/></alternatives></inline-formula>, where <inline-formula hwp:id="inline-formula-31"><alternatives hwp:id="alternatives-103"><inline-graphic xlink:href="332353_inline29.gif" hwp:id="inline-graphic-31"/></alternatives></inline-formula> is the derivative of the covariance of <bold><italic toggle="yes">r</italic></bold>,
<disp-formula id="eqn73" hwp:id="disp-formula-73">
<alternatives hwp:id="alternatives-104"><graphic xlink:href="332353_eqn73.gif" position="float" orientation="portrait" hwp:id="graphic-80"/></alternatives>
</disp-formula>
</p><p hwp:id="p-125">Here Ω is a diagonal matrix of eigenvalues for <italic toggle="yes">A, U</italic> is an orthogonal matrix of the eigenvectors of <italic toggle="yes">A</italic>, and <italic toggle="yes">X</italic> = <italic toggle="yes">U</italic> <sup><italic toggle="yes">T</italic></sup>Λ<italic toggle="yes">U</italic>.</p><p hwp:id="p-126">The elements in Γ can be expressed as Γ<sub><italic toggle="yes">ij,kn</italic></sub> = <italic toggle="yes">⟨ r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">k</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">n</italic></sub><italic toggle="yes">|s ⟩ -⟨ r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub><italic toggle="yes">|s ⟩ ⟨ r</italic><sub><italic toggle="yes">k</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">n</italic></sub><italic toggle="yes">|s ⟩</italic>. We can use the following identity for a Gaussian to compute this fourth-order quantity:
<disp-formula id="eqn74" hwp:id="disp-formula-74" hwp:rev-id="xref-disp-formula-74-1">
<alternatives hwp:id="alternatives-105"><graphic xlink:href="332353_eqn74.gif" position="float" orientation="portrait" hwp:id="graphic-81"/></alternatives>
</disp-formula>
</p><p hwp:id="p-127">Where
<disp-formula id="eqn75" hwp:id="disp-formula-75">
<alternatives hwp:id="alternatives-106"><graphic xlink:href="332353_eqn75.gif" position="float" orientation="portrait" hwp:id="graphic-82"/></alternatives>
</disp-formula>
</p><p hwp:id="p-128">Substitution of the response covariance (<xref ref-type="disp-formula" rid="eqn72" hwp:id="xref-disp-formula-72-1" hwp:rel-id="disp-formula-72">Equation 72</xref>) into <xref ref-type="disp-formula" rid="eqn74" hwp:id="xref-disp-formula-74-1" hwp:rel-id="disp-formula-74">Equation 74</xref> allows us to calculate the covariance Γ of the quadratic sufficient statistics, and thereby to estimate the stimulus and Fisher information for this quadratic code.</p></sec><sec id="s9" hwp:id="sec-36"><title hwp:id="title-38">S4 Cubic codes</title><p hwp:id="p-129">In <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Figure 6</xref> we assume the brain encodes the stimulus using a cubic code. A simple cubic code in <bold><italic toggle="yes">z</italic></bold> = (<italic toggle="yes">z</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">z</italic><sub><italic toggle="yes">j</italic></sub>, <italic toggle="yes">z</italic><sub><italic toggle="yes">k</italic></sub>) <italic toggle="yes">∈</italic> ℝ 3 can be written as
<disp-formula id="eqn76" hwp:id="disp-formula-76" hwp:rev-id="xref-disp-formula-76-1">
<alternatives hwp:id="alternatives-107"><graphic xlink:href="332353_eqn76.gif" position="float" orientation="portrait" hwp:id="graphic-83"/></alternatives>
</disp-formula>
where we include the base measure <inline-formula hwp:id="inline-formula-32"><alternatives hwp:id="alternatives-108"><inline-graphic xlink:href="332353_inline30.gif" hwp:id="inline-graphic-32"/></alternatives></inline-formula> to ensure normalizability (<xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-2" hwp:rel-id="F6">Figure 6A</xref>).</p><p hwp:id="p-130">For mathematical convenience, we approximate this code by a mixture of Gaussians.
<disp-formula id="eqn77" hwp:id="disp-formula-77">
<alternatives hwp:id="alternatives-109"><graphic xlink:href="332353_eqn77.gif" position="float" orientation="portrait" hwp:id="graphic-84"/></alternatives>
</disp-formula>
<disp-formula id="eqn78" hwp:id="disp-formula-78" hwp:rev-id="xref-disp-formula-78-1">
<alternatives hwp:id="alternatives-110"><graphic xlink:href="332353_eqn78.gif" position="float" orientation="portrait" hwp:id="graphic-85"/></alternatives>
</disp-formula>
</p><p hwp:id="p-131">Where
<disp-formula id="eqn79" hwp:id="disp-formula-79">
<alternatives hwp:id="alternatives-111"><graphic xlink:href="332353_eqn79.gif" position="float" orientation="portrait" hwp:id="graphic-86"/></alternatives>
</disp-formula>
</p><p hwp:id="p-132">And
<disp-formula id="eqn80" hwp:id="disp-formula-80">
<alternatives hwp:id="alternatives-112"><graphic xlink:href="332353_eqn80.gif" position="float" orientation="portrait" hwp:id="graphic-87"/></alternatives>
</disp-formula>
</p><p hwp:id="p-133">The vectors <bold><italic toggle="yes">v</italic></bold><sub><italic toggle="yes">a</italic></sub> reflect the four corners of the tetrahedron, <italic toggle="yes">v</italic><sub><italic toggle="yes">a,i</italic></sub> = <italic toggle="yes">±</italic>1, to match the tetrahedral symmetry of the pure cubic code (<xref ref-type="disp-formula" rid="eqn76" hwp:id="xref-disp-formula-76-1" hwp:rel-id="disp-formula-76">Equation 76</xref>, <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-3" hwp:rel-id="F6">Figure 6</xref>). To sample from this distribution, we randomly choose a compo-nent <italic toggle="yes">a</italic> and then sample from the gaussian <italic toggle="yes">N</italic> (<bold><italic toggle="yes">z</italic></bold><italic toggle="yes">|µ</italic><sub><italic toggle="yes">a</italic></sub>, Σ<sub><italic toggle="yes">a</italic></sub>) conditioned on that component.</p><p hwp:id="p-134">This distribution has zero mean and identity covariance but a nontrivial skewness tensor, and qualitatively matches the corresponding distribution for the true exponential family distribution with cubic sufficient statistics (<xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-4" hwp:rel-id="F6">Figure 6</xref>).</p><p hwp:id="p-135">For simplicity, we consider pure cubic codes with non-overlapping cliques of three variables.
<disp-formula id="eqn81" hwp:id="disp-formula-81">
<alternatives hwp:id="alternatives-113"><graphic xlink:href="332353_eqn81.gif" position="float" orientation="portrait" hwp:id="graphic-88"/></alternatives>
</disp-formula>
</p><p hwp:id="p-136">To convert this purely cubic distribution into a distribution with linear and quadratic information as well, we simply shift and scale the distribution in a manner dependent on <italic toggle="yes">s</italic>:
<disp-formula id="eqn82" hwp:id="disp-formula-82">
<alternatives hwp:id="alternatives-114"><graphic xlink:href="332353_eqn82.gif" position="float" orientation="portrait" hwp:id="graphic-89"/></alternatives>
</disp-formula>
<disp-formula id="eqn83" hwp:id="disp-formula-83">
<alternatives hwp:id="alternatives-115"><graphic xlink:href="332353_eqn83.gif" position="float" orientation="portrait" hwp:id="graphic-90"/></alternatives>
</disp-formula>
</p><p hwp:id="p-137">These affine transformations can be incorporated directly into each component of the mixture of gaussians,
<disp-formula id="eqn84" hwp:id="disp-formula-84">
<alternatives hwp:id="alternatives-116"><graphic xlink:href="332353_eqn84.gif" position="float" orientation="portrait" hwp:id="graphic-91"/></alternatives>
</disp-formula>
</p><p hwp:id="p-138">Note that the linear and quadratic information terms are independent of the component <bold><italic toggle="yes">a</italic></bold>.</p></sec><sec id="s10" hwp:id="sec-37"><title hwp:id="title-39">S5 Using nonlinear choice correlation to analyze unknown nonlinearities</title><p hwp:id="p-139">The true nonlinearity that the brain uses to estimate the stimulus is unknown. Thus a crucial question in our decoding analysis is, which nonlinearities to consider? One reasonable set is polynomials in <bold><italic toggle="yes">r</italic></bold>, <italic toggle="yes">i.e.</italic> a Taylor series expansion of the neural nonlinearities, <bold>Ψ</bold>(<bold><italic toggle="yes">r</italic></bold>) = (<italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub>, <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">k</italic></sub>, <italic toggle="yes">…</italic>).</p><p hwp:id="p-140">The locally optimal decoder is a weighted sum of the sufficient statistics <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) (<xref ref-type="disp-formula" rid="eqn46" hwp:id="xref-disp-formula-46-1" hwp:rel-id="disp-formula-46">Equation 46</xref>):
<disp-formula id="eqn85" hwp:id="disp-formula-85">
<alternatives hwp:id="alternatives-117"><graphic xlink:href="332353_eqn85.gif" position="float" orientation="portrait" hwp:id="graphic-92"/></alternatives>
</disp-formula>
</p><p hwp:id="p-141">However, the brain might choose a different nonlinear basis <bold><italic toggle="yes">g</italic></bold>(<bold><italic toggle="yes">r</italic></bold>):
<disp-formula id="eqn86" hwp:id="disp-formula-86">
<alternatives hwp:id="alternatives-118"><graphic xlink:href="332353_eqn86.gif" position="float" orientation="portrait" hwp:id="graphic-93"/></alternatives>
</disp-formula>
</p><p hwp:id="p-142">As long as the brain’s nonlinear function spans the same function basis as the sufficient statistics, we can still get all of the information about stimulus from neural population. This allows us to use choice correlation between brain’s estimate <inline-formula hwp:id="inline-formula-33"><alternatives hwp:id="alternatives-119"><inline-graphic xlink:href="332353_inline31.gif" hwp:id="inline-graphic-33"/></alternatives></inline-formula> and our analysis non-linearity Ψ(<bold><italic toggle="yes">r</italic></bold>) to check the optimality condition (<xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-9" hwp:rel-id="disp-formula-7">Equation 7</xref>).</p><p hwp:id="p-143">In <xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-4" hwp:rel-id="F4">Figure 4</xref>, we assumed that the optimal nonlinear basis function <bold><italic toggle="yes">R</italic></bold> is polynomial nonlinearity up to third order, <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) = (<italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub>, <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub>, <italic toggle="yes">r</italic><sub><italic toggle="yes">i</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">j</italic></sub><italic toggle="yes">r</italic><sub><italic toggle="yes">k</italic></sub>, <italic toggle="yes">…</italic>). We used cubic codes described in Methods 4.1.4 to generate neural responses for which <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) are sufficient statistics for the stimulus. In this simulation, 18 neuronal responses (six cliques of size 3) were generated using cubic codes.</p><p hwp:id="p-144">Our model brain decodes the stimulus using a cascade of linear-nonlinear transformations, with Rectified Linear Units (ReLU(<italic toggle="yes">x</italic>) = max(0, <italic toggle="yes">x</italic>)) for the nonlinear activation functions. We used a fully-connected ReLU network with two hidden layers and 30 units per hidden layer,
<disp-formula id="eqn87" hwp:id="disp-formula-87">
<alternatives hwp:id="alternatives-120"><graphic xlink:href="332353_eqn87.gif" position="float" orientation="portrait" hwp:id="graphic-94"/></alternatives>
</disp-formula>
<disp-formula id="eqn88" hwp:id="disp-formula-88">
<alternatives hwp:id="alternatives-121"><graphic xlink:href="332353_eqn88.gif" position="float" orientation="portrait" hwp:id="graphic-95"/></alternatives>
</disp-formula>
<disp-formula id="eqn89" hwp:id="disp-formula-89">
<alternatives hwp:id="alternatives-122"><graphic xlink:href="332353_eqn89.gif" position="float" orientation="portrait" hwp:id="graphic-96"/></alternatives>
</disp-formula>
<disp-formula id="eqn90" hwp:id="disp-formula-90">
<alternatives hwp:id="alternatives-123"><graphic xlink:href="332353_eqn90.gif" position="float" orientation="portrait" hwp:id="graphic-97"/></alternatives>
</disp-formula>
</p><p hwp:id="p-145">We trained the neural network with 20000 response samples generated from a cubic code driven by stimuli near the reference <italic toggle="yes">s</italic><sub>0</sub>. We optimized the estimation performance for the neural network using backpropagation to find weights {<bold><italic toggle="yes">W</italic></bold> <sup>(<italic toggle="yes">&#x01d4c1;</italic>)</sup>}, biases <italic toggle="yes">{</italic><bold><italic toggle="yes">b</italic></bold><sup>(<italic toggle="yes">&#x01d4c1;</italic>)</sup><italic toggle="yes">}</italic>, and read-out vector <bold><italic toggle="yes">v</italic></bold> that minimized the mean squared error. Our trained neural network performed near-optimally, extracting 91% of the Fisher information compared to optimal decoding based on the true sufficient statistics.</p><p hwp:id="p-146">Feigning ignorance of our simulated brain’s true decoder, we used mononomial nonlinearities Ψ(<bold><italic toggle="yes">r</italic></bold>) in our the nonlinear choice correlation test (<xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-10" hwp:rel-id="disp-formula-7">Equation 7</xref>). The simulated choice correlations were calculated by <xref ref-type="disp-formula" rid="eqn5" hwp:id="xref-disp-formula-5-1" hwp:rel-id="disp-formula-5">Equation 5</xref>, where <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) = Ψ(<bold><italic toggle="yes">r</italic></bold>) based on neural responses driven by the reference stimulus <italic toggle="yes">s</italic><sub>0</sub>, and the stimulus estimate was <inline-formula hwp:id="inline-formula-34"><alternatives hwp:id="alternatives-124"><inline-graphic xlink:href="332353_inline31a.gif" hwp:id="inline-graphic-34"/></alternatives></inline-formula><sub>brain</sub>. The optimal choice correlation is computed using <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-11" hwp:rel-id="disp-formula-7">Equation 7</xref>, where <inline-formula hwp:id="inline-formula-35"><alternatives hwp:id="alternatives-125"><inline-graphic xlink:href="332353_inline32.gif" hwp:id="inline-graphic-35"/></alternatives></inline-formula> <inline-formula hwp:id="inline-formula-36"><alternatives hwp:id="alternatives-126"><inline-graphic xlink:href="332353_inline32a.gif" hwp:id="inline-graphic-36"/></alternatives></inline-formula> We computed Δ<bold><italic toggle="yes">F</italic></bold> <sub>Ψ</sub> based on neural population responses <bold><italic toggle="yes">r</italic></bold><sub>+</sub> and <bold><italic toggle="yes">r</italic></bold><sub><italic toggle="yes">-</italic></sub> driven by stimuli <italic toggle="yes">s</italic><sub>+</sub> = <italic toggle="yes">s</italic><sub>0</sub> <italic toggle="yes">±</italic> Δ<italic toggle="yes">s/</italic>2. The change in mean was Δ<bold><italic toggle="yes">F</italic></bold> <sub>Ψ</sub> = <italic toggle="yes">⟨</italic>Ψ(<bold><italic toggle="yes">r</italic></bold><sub>+</sub>) <italic toggle="yes">⟩ -⟨</italic>Ψ(<bold><italic toggle="yes">r</italic></bold><sub><italic toggle="yes">-</italic></sub>)<italic toggle="yes">⟩</italic>, and the average standard deviation was <inline-formula hwp:id="inline-formula-37"><alternatives hwp:id="alternatives-127"><inline-graphic xlink:href="332353_inline33.gif" hwp:id="inline-graphic-37"/></alternatives></inline-formula>. <inline-formula hwp:id="inline-formula-38"><alternatives hwp:id="alternatives-128"><inline-graphic xlink:href="332353_inline34.gif" hwp:id="inline-graphic-38"/></alternatives></inline-formula> is the variance of estimate of reference stimulus <italic toggle="yes">s</italic><sub>0</sub> using the trained neural network. Based on these quantities, <xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-5" hwp:rel-id="F4">Figure 4</xref> shows that we can success-fully identify that the brain is near-optimal.</p></sec><sec id="s11" hwp:id="sec-38"><title hwp:id="title-40">S6 Information-limiting correlations</title><p hwp:id="p-147">Information-limiting correlations can ultimately be referred back to the stimulus, to appear as <bold><italic toggle="yes">r</italic></bold> <italic toggle="yes">∼ p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic> + <italic toggle="yes">ds</italic>), where <italic toggle="yes">ds</italic> is zero mean noise with variance 1<italic toggle="yes">/J</italic><sub><italic toggle="yes">∞</italic></sub>which determines the uncertainty of stimulus. Applying the law of total covariance, we can decompose the covariance of nonlinear statistics <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) conditioned on the stimulus into two parts:
<disp-formula id="eqn91" hwp:id="disp-formula-91" hwp:rev-id="xref-disp-formula-91-1">
<alternatives hwp:id="alternatives-129"><graphic xlink:href="332353_eqn91.gif" position="float" orientation="portrait" hwp:id="graphic-98"/></alternatives>
</disp-formula>
where <italic toggle="yes">⟨·⟩</italic><sub><italic toggle="yes">p</italic></sub> indicates an expectation value over the distribution <italic toggle="yes">p</italic>. The first term can be computed as follows,
<disp-formula id="eqn92" hwp:id="disp-formula-92">
<alternatives hwp:id="alternatives-130"><graphic xlink:href="332353_eqn92.gif" position="float" orientation="portrait" hwp:id="graphic-99"/></alternatives>
</disp-formula>
<disp-formula id="eqn93" hwp:id="disp-formula-93">
<alternatives hwp:id="alternatives-131"><graphic xlink:href="332353_eqn93.gif" position="float" orientation="portrait" hwp:id="graphic-100"/></alternatives>
</disp-formula>
<disp-formula id="eqn94" hwp:id="disp-formula-94">
<alternatives hwp:id="alternatives-132"><graphic xlink:href="332353_eqn94.gif" position="float" orientation="portrait" hwp:id="graphic-101"/></alternatives>
</disp-formula>
</p><p hwp:id="p-148">Here we denote the covariance of <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) given <italic toggle="yes">s</italic> and <italic toggle="yes">ds</italic> as Γ(<italic toggle="yes">s</italic> + <italic toggle="yes">ds</italic>). The second equality used a Taylor expansion of Γ(<italic toggle="yes">s</italic> + <italic toggle="yes">ds</italic>) around <italic toggle="yes">s</italic>. The third equality used the fact that the mean of <italic toggle="yes">ds</italic> is zero. Γ<sub>0</sub> is the covariance of <bold><italic toggle="yes">R</italic></bold> in the absence of information-limiting correlations. The second term in <xref ref-type="disp-formula" rid="eqn91" hwp:id="xref-disp-formula-91-1" hwp:rel-id="disp-formula-91">Equation 91</xref> can be expressed as
<disp-formula id="eqn95" hwp:id="disp-formula-95">
<alternatives hwp:id="alternatives-133"><graphic xlink:href="332353_eqn95.gif" position="float" orientation="portrait" hwp:id="graphic-102"/></alternatives>
</disp-formula>
<disp-formula id="eqn96" hwp:id="disp-formula-96">
<alternatives hwp:id="alternatives-134"><graphic xlink:href="332353_eqn96.gif" position="float" orientation="portrait" hwp:id="graphic-103"/></alternatives>
</disp-formula>
<disp-formula id="eqn97" hwp:id="disp-formula-97">
<alternatives hwp:id="alternatives-135"><graphic xlink:href="332353_eqn97.gif" position="float" orientation="portrait" hwp:id="graphic-104"/></alternatives>
</disp-formula>
<disp-formula id="eqn98" hwp:id="disp-formula-98">
<alternatives hwp:id="alternatives-136"><graphic xlink:href="332353_eqn98.gif" position="float" orientation="portrait" hwp:id="graphic-105"/></alternatives>
</disp-formula>
</p><p hwp:id="p-149">Here we have written the mean of <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) given <italic toggle="yes">s</italic> and <italic toggle="yes">ds</italic> as <bold><italic toggle="yes">F</italic></bold> (<italic toggle="yes">s</italic> + <italic toggle="yes">ds</italic>). The second equality used a first-order expansion of <bold><italic toggle="yes">F</italic></bold> (<italic toggle="yes">s</italic> + <italic toggle="yes">ds</italic>) around <italic toggle="yes">s</italic>. The third equality used the fact that the variance of <italic toggle="yes">ds</italic> is 1<italic toggle="yes">/J</italic><sub><italic toggle="yes">∞</italic></sub>.
<disp-formula id="eqn99" hwp:id="disp-formula-99">
<alternatives hwp:id="alternatives-137"><graphic xlink:href="332353_eqn99.gif" position="float" orientation="portrait" hwp:id="graphic-106"/></alternatives>
</disp-formula>
which is a rank-one perturbation of the covariance Γ 0</p><p hwp:id="p-150">To compute the nonlinear Fisher Information,<italic toggle="yes">JR</italic>(<bold><italic toggle="yes">r</italic></bold>) = <bold><italic toggle="yes">F</italic></bold><sup><italic toggle="yes">′T</italic></sup>Γ<italic toggle="yes">-</italic>1 <bold><italic toggle="yes">F</italic></bold> ′, we can use the Sherman-Morrison lemma to compute Γ<sup>-1</sup>:
<disp-formula id="eqn100" hwp:id="disp-formula-100">
<alternatives hwp:id="alternatives-138"><graphic xlink:href="332353_eqn100.gif" position="float" orientation="portrait" hwp:id="graphic-107"/></alternatives>
</disp-formula>
</p><p hwp:id="p-151">Substituting these equations into the nonlinear Fisher Information (<xref ref-type="disp-formula" rid="eqn13" hwp:id="xref-disp-formula-13-4" hwp:rel-id="disp-formula-13">Equation 13</xref>) and simplifying, we obtain
<disp-formula id="eqn101" hwp:id="disp-formula-101">
<alternatives hwp:id="alternatives-139"><graphic xlink:href="332353_eqn101.gif" position="float" orientation="portrait" hwp:id="graphic-108"/></alternatives>
</disp-formula>
</p><p hwp:id="p-152">Here <inline-formula hwp:id="inline-formula-39"><alternatives hwp:id="alternatives-140"><inline-graphic xlink:href="332353_inline35.gif" hwp:id="inline-graphic-39"/></alternatives></inline-formula> is the nonlinear Fisher Informa-tion in the absence of information-limiting correlations. When the population size grows, the term <italic toggle="yes">J</italic><sub>0</sub> grows proportionally [<xref rid="c16" ref-type="bibr" hwp:id="xref-ref-16-7" hwp:rel-id="ref-16">16</xref>, <xref rid="c29" ref-type="bibr" hwp:id="xref-ref-29-3" hwp:rel-id="ref-29">29</xref>], so for large populations the out-put information saturates at <italic toggle="yes">J</italic><sub><italic toggle="yes">∞</italic></sub>.</p></sec><sec id="s12" hwp:id="sec-39"><title hwp:id="title-41">S7 Nonlinear choice correlation for suboptimal decoding</title><p hwp:id="p-153">A decoder that would be suboptimal for one population code could be near-optimal in the presence of information-limiting noise. In this case, nonlinear choice correlations can be decomposed into a sum of two terms, one from the information-limiting component and the other from the rest of the noise [<xref rid="c28" ref-type="bibr" hwp:id="xref-ref-28-8" hwp:rel-id="ref-28">28</xref>]:
<disp-formula id="eqn102" hwp:id="disp-formula-102">
<alternatives hwp:id="alternatives-141"><graphic xlink:href="332353_eqn102.gif" position="float" orientation="portrait" hwp:id="graphic-109"/></alternatives>
</disp-formula>
</p><p hwp:id="p-154">For unbiased decoding, <bold><italic toggle="yes">w</italic></bold><sup><italic toggle="yes">T</italic></sup><bold><italic toggle="yes">F</italic></bold> = 1 Some manipulation gives
<disp-formula id="eqn103" hwp:id="disp-formula-103" hwp:rev-id="xref-disp-formula-103-1">
<alternatives hwp:id="alternatives-142"><graphic xlink:href="332353_eqn103.gif" position="float" orientation="portrait" hwp:id="graphic-110"/></alternatives>
</disp-formula>
where Γ<sub>0<italic toggle="yes">k</italic></sub> = (Γ<sub>0</sub>)<sub><italic toggle="yes">kk</italic></sub> <italic toggle="yes">≈</italic> Γ<sub><italic toggle="yes">kk</italic></sub> for small information-limiting noise variance 1<italic toggle="yes">/J</italic><sub><italic toggle="yes">∞</italic></sub> <italic toggle="yes">«</italic> Γ<sub>0<italic toggle="yes">k</italic></sub> (which nonetheless can have a large effect on information despite the small variance), and where <italic toggle="yes">Σ</italic><sub>0<italic toggle="yes">s</italic><inline-formula hwp:id="inline-formula-40"><alternatives hwp:id="alternatives-143"><inline-graphic xlink:href="332353_inline36.gif" hwp:id="inline-graphic-40"/></alternatives></inline-formula></sub> is the standard deviation of the estimate produced by the same suboptimal decoder <bold><italic toggle="yes">w</italic></bold> in the absence of information-limiting correlations, <italic toggle="yes">i.e.</italic> when the covariance of the sufficient statistics is Γ<sub>0</sub>. The variance of <inline-formula hwp:id="inline-formula-41"><alternatives hwp:id="alternatives-144"><inline-graphic xlink:href="332353_inline37a.gif" hwp:id="inline-graphic-41"/></alternatives></inline-formula> can itself be decomposed into two terms as well:
<disp-formula id="eqn104" hwp:id="disp-formula-104">
<alternatives hwp:id="alternatives-145"><graphic xlink:href="332353_eqn104.gif" position="float" orientation="portrait" hwp:id="graphic-111"/></alternatives>
</disp-formula>
where we assume unbiased decoding, which implies <bold><italic toggle="yes">w</italic></bold><sup><italic toggle="yes">T</italic></sup><bold><italic toggle="yes">F</italic></bold> <sup><italic toggle="yes">l</italic></sup> = 1. This expression allows us to represent the ratio <italic toggle="yes"><inline-formula hwp:id="inline-formula-42"><alternatives hwp:id="alternatives-146"><inline-graphic xlink:href="332353_inline37.gif" hwp:id="inline-graphic-42"/></alternatives></inline-formula></italic> as
<disp-formula id="eqn105" hwp:id="disp-formula-105">
<alternatives hwp:id="alternatives-147"><graphic xlink:href="332353_eqn105.gif" position="float" orientation="portrait" hwp:id="graphic-112"/></alternatives>
</disp-formula>
</p><p hwp:id="p-155"><sub><italic toggle="yes">s</italic></sub>With <inline-formula hwp:id="inline-formula-43"><alternatives hwp:id="alternatives-148"><inline-graphic xlink:href="332353_inline38.gif" hwp:id="inline-graphic-43"/></alternatives></inline-formula> Substituting these into (<xref ref-type="disp-formula" rid="eqn103" hwp:id="xref-disp-formula-103-1" hwp:rel-id="disp-formula-103">Eq 103</xref>) we find that the choice correlation for a suboptimal decoder in the presence of information-limiting correlations is a weighted sum of the choice correlations for optimal and suboptimal decoding:
<disp-formula id="eqn106" hwp:id="disp-formula-106">
<alternatives hwp:id="alternatives-149"><graphic xlink:href="332353_eqn106.gif" position="float" orientation="portrait" hwp:id="graphic-113"/></alternatives>
</disp-formula>
</p><p hwp:id="p-156">Here <italic toggle="yes"><inline-formula hwp:id="inline-formula-44"><alternatives hwp:id="alternatives-150"><inline-graphic xlink:href="332353_inline39.gif" hwp:id="inline-graphic-44"/></alternatives></inline-formula></italic> and <italic toggle="yes"><inline-formula hwp:id="inline-formula-45"><alternatives hwp:id="alternatives-151"><inline-graphic xlink:href="332353_inline40.gif" hwp:id="inline-graphic-45"/></alternatives></inline-formula></italic> are, respectively, the choice corre lations for suboptimal decoding without information-limiting noise (so Γ = Γ<sub>0</sub>), and choice correlations for optimal decoding.</p><p hwp:id="p-157">The slope <italic toggle="yes">α</italic> between choice correlations and those predicted from optimal decoding is equal to the fraction of estimator variance explained by information-limiting noise. This slope therefore provides an estimate of the efficiency of the brain’s decoding.</p></sec><sec id="s13" hwp:id="sec-40"><title hwp:id="title-42">S8 Comparing choice correlations from internal or external noise</title><p hwp:id="p-158">The response covariance that drives fluctuations in choices could arise from internal or external (nuisance) variability, or both. Choice correlations predicted for optimal decoding differ depending on whether we condition on the nuisance variables or not. In the main text, we described optimal choice correlations under the distribution <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold><italic toggle="yes">|s</italic>). This includes variations caused by external nuisance variables, which is sensible since this is what the brain’s decoder must handle. However, it is also potentially informative to examine how purely internal variability correlates with choice, as this is of-ten how choice correlations are assessed. In this section, we derive the choice correlations driven by purely internal noise, for a decoder that learned to remove external nuisance variation as well.</p><p hwp:id="p-159">For simplicity we assume that the nonlinear sufficient statistics <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) are linearly tuned to both the stimulus <italic toggle="yes">s</italic> and a scalar nuisance variable <italic toggle="yes">n</italic>,
<disp-formula id="eqn107" hwp:id="disp-formula-107">
<alternatives hwp:id="alternatives-152"><graphic xlink:href="332353_eqn107.gif" position="float" orientation="portrait" hwp:id="graphic-114"/></alternatives>
</disp-formula>
where <bold><italic toggle="yes">F</italic></bold> ′ and <bold><italic toggle="yes">G</italic></bold>′ characterize the sensitivity of <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) to stimulus <italic toggle="yes">s</italic> and nuisance <italic toggle="yes">n</italic>, and an internal noise source <bold><italic toggle="yes">η</italic></bold> has zero mean with covariance <italic toggle="yes">H</italic>. We assume the brain has a prior over the nuisance variation, <italic toggle="yes">p</italic>(<italic toggle="yes">n</italic>), with zero mean and variance <italic toggle="yes">ξ</italic>. The total covariance for internal and external fluctuations is then
<disp-formula id="eqn108" hwp:id="disp-formula-108">
<alternatives hwp:id="alternatives-153"><graphic xlink:href="332353_eqn108.gif" position="float" orientation="portrait" hwp:id="graphic-115"/></alternatives>
</disp-formula>
</p><p hwp:id="p-160">When we measure choice correlations while fixing the nuisance variables in the experiment, we assume the brain retains its decoding strategy accounting for both internal noise and unknown nuisance variation, and not the optimal decoding strategy when the nuisance is fixed and known. These decoding weights are
<disp-formula id="eqn109" hwp:id="disp-formula-109" hwp:rev-id="xref-disp-formula-109-1">
<alternatives hwp:id="alternatives-154"><graphic xlink:href="332353_eqn109.gif" position="float" orientation="portrait" hwp:id="graphic-116"/></alternatives>
</disp-formula>
where the denominator <italic toggle="yes">J</italic><sub>1</sub> = <bold><italic toggle="yes">F</italic></bold> <sup><italic toggle="yes">′T</italic></sup>Γ<sup>-1</sup><bold><italic toggle="yes">F</italic></bold> ′ is the Fisher information about <italic toggle="yes">s</italic> when there is natural nuisance variation following <italic toggle="yes">p</italic>(<italic toggle="yes">n</italic>). For distributions in the exponential family, this information saturates the Cramer-Rao bound on an estimator’s variance, so that <italic toggle="yes"><inline-formula hwp:id="inline-formula-46"><alternatives hwp:id="alternatives-155"><inline-graphic xlink:href="332353_inline41.gif" hwp:id="inline-graphic-46"/></alternatives></inline-formula> <inline-formula hwp:id="inline-formula-47"><alternatives hwp:id="alternatives-156"><inline-graphic xlink:href="332353_inline41a.gif" hwp:id="inline-graphic-47"/></alternatives></inline-formula></italic>. [<xref rid="c69" ref-type="bibr" hwp:id="xref-ref-69-1" hwp:rel-id="ref-69">69</xref>] The normalization by <italic toggle="yes">J</italic><sub>1</sub> ensures the decoding is locally unbiased. These weights are used to estimate the stimulus according to
<disp-formula id="eqn110" hwp:id="disp-formula-110" hwp:rev-id="xref-disp-formula-110-1">
<alternatives hwp:id="alternatives-157"><graphic xlink:href="332353_eqn110.gif" position="float" orientation="portrait" hwp:id="graphic-117"/></alternatives>
</disp-formula>
</p><p hwp:id="p-161">Choice correlations in this fixed-nuisance experiment will be denoted by a lowercase <italic toggle="yes">c</italic>:
<disp-formula id="eqn111" hwp:id="disp-formula-111" hwp:rev-id="xref-disp-formula-111-1">
<alternatives hwp:id="alternatives-158"><graphic xlink:href="332353_eqn111.gif" position="float" orientation="portrait" hwp:id="graphic-118"/></alternatives>
</disp-formula>
</p><p hwp:id="p-162">We include the superscript <italic toggle="yes">c</italic> sub as a reminder that these choice correlations do not follow the optimal pat-tern when the decoder is not matched to only the purely internal variability, as here.</p><p hwp:id="p-163">We can express these choice correlations as:
<disp-formula id="eqn112" hwp:id="disp-formula-112" hwp:rev-id="xref-disp-formula-112-1 xref-disp-formula-112-2">
<alternatives hwp:id="alternatives-159"><graphic xlink:href="332353_eqn112.gif" position="float" orientation="portrait" hwp:id="graphic-119"/></alternatives>
</disp-formula>
</p><p hwp:id="p-164">The covariance between <inline-formula hwp:id="inline-formula-48"><alternatives hwp:id="alternatives-160"><inline-graphic xlink:href="332353_inline42.gif" hwp:id="inline-graphic-48"/></alternatives></inline-formula> and <bold><italic toggle="yes">R</italic></bold> is
<disp-formula id="eqn113" hwp:id="disp-formula-113" hwp:rev-id="xref-disp-formula-113-1">
<alternatives hwp:id="alternatives-161"><graphic xlink:href="332353_eqn113.gif" position="float" orientation="portrait" hwp:id="graphic-120"/></alternatives>
</disp-formula>
<disp-formula id="eqn114" hwp:id="disp-formula-114">
<alternatives hwp:id="alternatives-162"><graphic xlink:href="332353_eqn114.gif" position="float" orientation="portrait" hwp:id="graphic-121"/></alternatives>
</disp-formula>
<disp-formula id="eqn115" hwp:id="disp-formula-115">
<alternatives hwp:id="alternatives-163"><graphic xlink:href="332353_eqn115.gif" position="float" orientation="portrait" hwp:id="graphic-122"/></alternatives>
</disp-formula>
</p><p hwp:id="p-165">For the scalar nuisance variable we assume here, we can use the Sherman-Morrison lemma to decompose the inverse of the total covariance into a rank-one perturbation of the internal noise inverse covariance:
<disp-formula id="eqn116" hwp:id="disp-formula-116">
<alternatives hwp:id="alternatives-164"><graphic xlink:href="332353_eqn116.gif" position="float" orientation="portrait" hwp:id="graphic-123"/></alternatives>
</disp-formula>
<disp-formula id="eqn117" hwp:id="disp-formula-117">
<alternatives hwp:id="alternatives-165"><graphic xlink:href="332353_eqn117.gif" position="float" orientation="portrait" hwp:id="graphic-124"/></alternatives>
</disp-formula>
</p><p hwp:id="p-166">Substituting this inverse covariance into <xref ref-type="disp-formula" rid="eqn113" hwp:id="xref-disp-formula-113-1" hwp:rel-id="disp-formula-113">Equation 113</xref>, we obtain
<disp-formula id="eqn118" hwp:id="disp-formula-118">
<alternatives hwp:id="alternatives-166"><graphic xlink:href="332353_eqn118.gif" position="float" orientation="portrait" hwp:id="graphic-125"/></alternatives>
</disp-formula>
<disp-formula id="eqn119" hwp:id="disp-formula-119">
<alternatives hwp:id="alternatives-167"><graphic xlink:href="332353_eqn119.gif" position="float" orientation="portrait" hwp:id="graphic-126"/></alternatives>
</disp-formula>
<disp-formula id="eqn120" hwp:id="disp-formula-120">
<alternatives hwp:id="alternatives-168"><graphic xlink:href="332353_eqn120.gif" position="float" orientation="portrait" hwp:id="graphic-127"/></alternatives>
</disp-formula>
</p><p hwp:id="p-167">This last expression can be rewritten using elements of the Fisher information matrix, whose inverse bounds the covariance of any joint estimator of the signal and nuisance variables, <inline-formula hwp:id="inline-formula-49"><alternatives hwp:id="alternatives-169"><inline-graphic xlink:href="332353_inline43.gif" hwp:id="inline-graphic-49"/></alternatives></inline-formula>:
<disp-formula id="eqn121" hwp:id="disp-formula-121">
<alternatives hwp:id="alternatives-170"><graphic xlink:href="332353_eqn121.gif" position="float" orientation="portrait" hwp:id="graphic-128"/></alternatives>
</disp-formula>
</p><p hwp:id="p-168">With these substitutions, we have
<disp-formula id="eqn122" hwp:id="disp-formula-122" hwp:rev-id="xref-disp-formula-122-1">
<alternatives hwp:id="alternatives-171"><graphic xlink:href="332353_eqn122.gif" position="float" orientation="portrait" hwp:id="graphic-129"/></alternatives>
</disp-formula>
</p><p hwp:id="p-169">The denominator of <xref ref-type="disp-formula" rid="eqn112" hwp:id="xref-disp-formula-112-1" hwp:rel-id="disp-formula-112">Equation 112</xref> involves the variance of the sufficient statistics,
<disp-formula id="eqn123" hwp:id="disp-formula-123">
<alternatives hwp:id="alternatives-172"><graphic xlink:href="332353_eqn123.gif" position="float" orientation="portrait" hwp:id="graphic-130"/></alternatives>
</disp-formula>
and the variance of the brain’s decoder,
<disp-formula id="eqn124" hwp:id="disp-formula-124">
<alternatives hwp:id="alternatives-173"><graphic xlink:href="332353_eqn124.gif" position="float" orientation="portrait" hwp:id="graphic-131"/></alternatives>
</disp-formula>
<disp-formula id="eqn125" hwp:id="disp-formula-125">
<alternatives hwp:id="alternatives-174"><graphic xlink:href="332353_eqn125.gif" position="float" orientation="portrait" hwp:id="graphic-132"/></alternatives>
</disp-formula>
<disp-formula id="eqn126" hwp:id="disp-formula-126">
<alternatives hwp:id="alternatives-175"><graphic xlink:href="332353_eqn126.gif" position="float" orientation="portrait" hwp:id="graphic-133"/></alternatives>
</disp-formula>
where we used the following results:
<disp-formula id="eqn127" hwp:id="disp-formula-127">
<alternatives hwp:id="alternatives-176"><graphic xlink:href="332353_eqn127.gif" position="float" orientation="portrait" hwp:id="graphic-134"/></alternatives>
</disp-formula>
<disp-formula id="eqn128" hwp:id="disp-formula-128">
<alternatives hwp:id="alternatives-177"><graphic xlink:href="332353_eqn128.gif" position="float" orientation="portrait" hwp:id="graphic-135"/></alternatives>
</disp-formula>
<disp-formula id="eqn129" hwp:id="disp-formula-129">
<alternatives hwp:id="alternatives-178"><graphic xlink:href="332353_eqn129.gif" position="float" orientation="portrait" hwp:id="graphic-136"/></alternatives>
</disp-formula>
<disp-formula id="eqn130" hwp:id="disp-formula-130">
<alternatives hwp:id="alternatives-179"><graphic xlink:href="332353_eqn130.gif" position="float" orientation="portrait" hwp:id="graphic-137"/></alternatives>
</disp-formula>
</p><p hwp:id="p-170">Combining the results from <xref ref-type="disp-formula" rid="eqn122" hwp:id="xref-disp-formula-122-1" hwp:rel-id="disp-formula-122">Equation 122</xref>, 126 and 123, we can compute <xref ref-type="disp-formula" rid="eqn112" hwp:id="xref-disp-formula-112-2" hwp:rel-id="disp-formula-112">Equation 112</xref>
<disp-formula id="eqn131" hwp:id="disp-formula-131">
<alternatives hwp:id="alternatives-180"><graphic xlink:href="332353_eqn131.gif" position="float" orientation="portrait" hwp:id="graphic-138"/></alternatives>
</disp-formula>
<disp-formula id="eqn132" hwp:id="disp-formula-132">
<alternatives hwp:id="alternatives-181"><graphic xlink:href="332353_eqn132.gif" position="float" orientation="portrait" hwp:id="graphic-139"/></alternatives>
</disp-formula>
<disp-formula id="eqn133" hwp:id="disp-formula-133">
<alternatives hwp:id="alternatives-182"><graphic xlink:href="332353_eqn133.gif" position="float" orientation="portrait" hwp:id="graphic-140"/></alternatives>
</disp-formula>
</p><p hwp:id="p-171">The optimal choice correlation when there is natural nuisance variation (<xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-12" hwp:rel-id="disp-formula-7">Eq 7</xref>) is given by
<disp-formula id="eqn134" hwp:id="disp-formula-134" hwp:rev-id="xref-disp-formula-134-1">
<alternatives hwp:id="alternatives-183"><graphic xlink:href="332353_eqn134.gif" position="float" orientation="portrait" hwp:id="graphic-141"/></alternatives>
</disp-formula>
where <italic toggle="yes"><inline-formula hwp:id="inline-formula-50"><alternatives hwp:id="alternatives-184"><inline-graphic xlink:href="332353_inline44.gif" hwp:id="inline-graphic-50"/></alternatives></inline-formula></italic> is the Fisher Information in <italic toggle="yes">R</italic><sub><italic toggle="yes">k</italic></sub> about <italic toggle="yes">s</italic> when there is natural nuisance variation, and <italic toggle="yes"><inline-formula hwp:id="inline-formula-51"><alternatives hwp:id="alternatives-185"><inline-graphic xlink:href="332353_inline45.gif" hwp:id="inline-graphic-51"/></alternatives></inline-formula></italic> is the standard deviation of the statistic <italic toggle="yes">R</italic><sub><italic toggle="yes">k</italic></sub>, again when there is natural nuisance variation.</p><p hwp:id="p-172">The choice correlations for the same decoder differ under experimental conditions with and without nuisance variation: <italic toggle="yes"><inline-formula hwp:id="inline-formula-52"><alternatives hwp:id="alternatives-186"><inline-graphic xlink:href="332353_inline46.gif" hwp:id="inline-graphic-52"/></alternatives></inline-formula></italic> and <italic toggle="yes"><inline-formula hwp:id="inline-formula-53"><alternatives hwp:id="alternatives-187"><inline-graphic xlink:href="332353_inline47.gif" hwp:id="inline-graphic-53"/></alternatives></inline-formula></italic>. We find that the nuisance-conditioned choice correlations <italic toggle="yes"><inline-formula hwp:id="inline-formula-54"><alternatives hwp:id="alternatives-188"><inline-graphic xlink:href="332353_inline48.gif" hwp:id="inline-graphic-54"/></alternatives></inline-formula></italic> relate to the optimal nuisance-averaged choice correlations <italic toggle="yes"><inline-formula hwp:id="inline-formula-55"><alternatives hwp:id="alternatives-189"><inline-graphic xlink:href="332353_inline49.gif" hwp:id="inline-graphic-55"/></alternatives></inline-formula></italic>; according to
<disp-formula id="eqn135" hwp:id="disp-formula-135" hwp:rev-id="xref-disp-formula-135-1">
<alternatives hwp:id="alternatives-190"><graphic xlink:href="332353_eqn135.gif" position="float" orientation="portrait" hwp:id="graphic-142"/></alternatives>
</disp-formula>
where we have defined the following constants:
<disp-formula id="eqn136" hwp:id="disp-formula-136">
<alternatives hwp:id="alternatives-191"><graphic xlink:href="332353_eqn136.gif" position="float" orientation="portrait" hwp:id="graphic-143"/></alternatives>
</disp-formula>
<disp-formula id="eqn137" hwp:id="disp-formula-137">
<alternatives hwp:id="alternatives-192"><graphic xlink:href="332353_eqn137.gif" position="float" orientation="portrait" hwp:id="graphic-144"/></alternatives>
</disp-formula>
<disp-formula id="eqn138" hwp:id="disp-formula-138">
<alternatives hwp:id="alternatives-193"><graphic xlink:href="332353_eqn138.gif" position="float" orientation="portrait" hwp:id="graphic-145"/></alternatives>
</disp-formula>
and
<disp-formula id="eqn139" hwp:id="disp-formula-139">
<alternatives hwp:id="alternatives-194"><graphic xlink:href="332353_eqn139.gif" position="float" orientation="portrait" hwp:id="graphic-146"/></alternatives>
</disp-formula>
</p><p hwp:id="p-173">The slope <italic toggle="yes">β</italic><sub><italic toggle="yes">k</italic></sub> and offset <italic toggle="yes">Γ</italic><sub><italic toggle="yes">k</italic></sub> of the relationship be-tween these two types of choice correlations (<xref ref-type="disp-formula" rid="eqn135" hwp:id="xref-disp-formula-135-1" hwp:rel-id="disp-formula-135">Equation 135</xref>) depends on the amount of nuisance variation compared to internal noise and the suboptimality of the brain’s decoding strategy. When the signal and nui-sance can be disentangled, that is, estimated nearly independently using the statistics <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>), then <italic toggle="yes">J</italic><sub>12</sub> is small and the choice correlations driven purely by internal fluctuations closely match the optimal choice correlations in the presence of nuisance variation (<xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-1" hwp:rel-id="F7">Figure 7A</xref>). In contrast, when nuisance variations remain partialy confused with the signal, then <italic toggle="yes">J</italic><sub>12</sub> is large and the choice correlations for fixed nuisance variables may differ from the optimal pattern seen when allowing nuisance variables to change from trial to trial (<xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-2" hwp:rel-id="F7">Figure 7B</xref>). For the simulations in <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-3" hwp:rel-id="F7">Figure 7</xref>, we set the sufficient statistics to be linear <bold><italic toggle="yes">R</italic></bold>(<bold><italic toggle="yes">r</italic></bold>) = <bold><italic toggle="yes">r</italic></bold> for simplicity. Neu-ral responses were generated from a Gaussian distri-bution with a stimulus-dependent mean and identity covariance <italic toggle="yes">H</italic> = <italic toggle="yes">I</italic>: <italic toggle="yes">p</italic>(<bold><italic toggle="yes">r</italic></bold> <italic toggle="yes">|s, n</italic>) = <italic toggle="yes">N</italic> (<bold><italic toggle="yes">F</italic></bold> ′<italic toggle="yes">s</italic> + <bold><italic toggle="yes">G</italic></bold>′<italic toggle="yes">n, I</italic>). In <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-4" hwp:rel-id="F7">Figure 7A</xref>, <bold><italic toggle="yes">F</italic></bold> ′ and <bold><italic toggle="yes">G</italic></bold>′ are set to be orthogonal to en-sure <italic toggle="yes">J</italic><sub>12</sub> = <bold><italic toggle="yes">F</italic></bold> <sup><italic toggle="yes">′T</italic></sup><italic toggle="yes">H</italic><sup>-1</sup><bold><italic toggle="yes">G</italic></bold>′ = 0. They are picked from the eigenvector of a symmetric matrix <italic toggle="yes">A</italic><sup><italic toggle="yes">T</italic></sup><italic toggle="yes">A</italic>, where <italic toggle="yes">A</italic> is a matrix whose elements are generated from uniform dis-tribution bounded by 0 and 1. In <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-5" hwp:rel-id="F7">Figure 7B</xref>, each element in <bold><italic toggle="yes">F</italic></bold> ′ and <bold><italic toggle="yes">G</italic></bold>′ is drawn from a uniform distribution over the interval [0, 1]. We simulate 10000 responses of a population with <italic toggle="yes">N</italic> = 50 neurons. The stimulus is set to 0 and the nuisance is fixed to be 1. The brain’s decoder assumes a Gaussian prior over the nuisance variation with zero mean and variance <italic toggle="yes">ξ</italic> = 2. The decoding weights follow <xref ref-type="disp-formula" rid="eqn109" hwp:id="xref-disp-formula-109-1" hwp:rel-id="disp-formula-109">Equation 109</xref>, and the stimulus is estimated using <xref ref-type="disp-formula" rid="eqn110" hwp:id="xref-disp-formula-110-1" hwp:rel-id="disp-formula-110">Equation 110</xref>. Choice correlations in this fixed-nuisance experiment are computed by <xref ref-type="disp-formula" rid="eqn111" hwp:id="xref-disp-formula-111-1" hwp:rel-id="disp-formula-111">Equation 111</xref> (vertical axis in <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-6" hwp:rel-id="F7">Figure 7</xref>). The predicted optimal choice correlation is computed by <xref ref-type="disp-formula" rid="eqn134" hwp:id="xref-disp-formula-134-1" hwp:rel-id="disp-formula-134">Equation 134</xref> (horizontal axis in <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-7" hwp:rel-id="F7">Figure 7</xref>). In this setting, <italic toggle="yes">β</italic><sub><italic toggle="yes">k</italic></sub> <italic toggle="yes">≈</italic> 1 when <italic toggle="yes">J</italic><sub>12</sub> = 0.</p><fig id="fig7" position="float" fig-type="figure" orientation="portrait" hwp:id="F7" hwp:rev-id="xref-fig-7-1 xref-fig-7-2 xref-fig-7-3 xref-fig-7-4 xref-fig-7-5 xref-fig-7-6 xref-fig-7-7"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;332353v1/FIG7</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F7</object-id><object-id pub-id-type="publisher-id">fig7</object-id><label>Figure 7:</label><caption hwp:id="caption-8"><p hwp:id="p-174">Comparing choice correlations caused by internal and external noise. (<bold>A</bold>) When estimates of nuisance variables are independent of estimates of task-relevant signals, the optimal choice correlations driven by internal noise, <italic toggle="yes"><inline-formula hwp:id="inline-formula-56"><alternatives hwp:id="alternatives-195"><inline-graphic xlink:href="332353_inline50.gif" hwp:id="inline-graphic-56"/></alternatives></inline-formula></italic>;, match the optimal pattern <italic toggle="yes"><inline-formula hwp:id="inline-formula-57"><alternatives hwp:id="alternatives-196"><inline-graphic xlink:href="332353_inline51.gif" hwp:id="inline-graphic-57"/></alternatives></inline-formula> ;</italic>expected for optimal decoding under natural nuisance variation (<xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-13" hwp:rel-id="disp-formula-7">Equation 7</xref>). (<bold>B</bold>) When the signal and nuisance variables remain confounded by an estimator and decoding is evaluated under different conditions than those for which it was optimized, then the choice correlations need not match this optimal prediction.</p></caption><graphic xlink:href="332353_fig7" position="float" orientation="portrait" hwp:id="graphic-147"/></fig><p hwp:id="p-175">In this context, it is especially noteworthy that a mismatch between choice correlations and the optimal pattern might not indicate that the brain is suboptimal, but instead that the experimental task may not match the natural tasks for which the brain could have been optimized.</p></sec></back></article>
