<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/483263</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;483263v2</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;483263</article-id><article-id pub-id-type="other" hwp:sub-type="slug">483263</article-id><article-id pub-id-type="other" hwp:sub-type="atom-slug">483263</article-id><article-id pub-id-type="other" hwp:sub-type="tag">483263</article-id><article-version>1.2</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Bioinformatics" hwp:journal="biorxiv"><subject>Bioinformatics</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">A learned embedding for efficient joint analysis of millions of mass spectra</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1"><label>∗</label>Corresponding author: <email hwp:id="email-1">william-noble@uw.edu</email></corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-3105-1359</contrib-id><name name-style="western" hwp:sortable="Bittremieux Wout"><surname>Bittremieux</surname><given-names>Wout</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-3105-1359"/></contrib><contrib contrib-type="author" hwp:id="contrib-2"><name name-style="western" hwp:sortable="May Damon H."><surname>May</surname><given-names>Damon H.</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref></contrib><contrib contrib-type="author" hwp:id="contrib-3"><name name-style="western" hwp:sortable="Bilmes Jeffrey"><surname>Bilmes</surname><given-names>Jeffrey</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-2" hwp:rel-id="aff-2">2</xref><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-1" hwp:rel-id="aff-3">3</xref></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-4"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-7283-4715</contrib-id><name name-style="western" hwp:sortable="Noble William Stafford"><surname>Noble</surname><given-names>William Stafford</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-3" hwp:rel-id="aff-2">2</xref><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-2" hwp:rel-id="aff-3">3</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">∗</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0001-7283-4715"/></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1"><label>1</label><institution hwp:id="institution-1">Skaggs School of Pharmacy and Pharmaceutical Science, University of California San Diego</institution>, La Jolla, CA 92093, <country>USA</country></aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1 xref-aff-2-2 xref-aff-2-3"><label>2</label><institution hwp:id="institution-2">Department of Genome Sciences, University of Washington</institution>, Seattle, WA 98195, <country>USA</country></aff><aff id="a3" hwp:id="aff-3" hwp:rev-id="xref-aff-3-1 xref-aff-3-2"><label>3</label><institution hwp:id="institution-3">Paul G. Allen School of Computer Science and Engineering, University of Washington</institution>, Seattle, WA 98195, <country>USA</country></aff></contrib-group><pub-date pub-type="epub-original" date-type="pub" publication-format="electronic" hwp:start="2021"><year>2021</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2018-11-29T16:51:10-08:00">
    <day>29</day><month>11</month><year>2018</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2021-09-23T04:51:18-07:00">
    <day>23</day><month>9</month><year>2021</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2018-11-29T16:57:02-08:00">
    <day>29</day><month>11</month><year>2018</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2021-09-23T04:57:22-07:00">
    <day>23</day><month>9</month><year>2021</year>
  </pub-date><elocation-id>483263</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2018-11-29"><day>29</day><month>11</month><year>2018</year></date>
<date date-type="rev-recd" hwp:start="2021-09-22"><day>22</day><month>9</month><year>2021</year></date>
<date date-type="accepted" hwp:start="2021-09-23"><day>23</day><month>9</month><year>2021</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2021</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/" hwp:id="license-1"><p hwp:id="p-1">This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by/4.0/</ext-link></p></license></permissions><self-uri xlink:href="483263.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/change-list" xlink:role="change-list" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/external-links" xlink:role="external-links" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2021/pdf/483263v2.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="483263.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2021/abstracts/483263v2/483263v2.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2021/fulltext/483263v2/483263v2.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-2">Despite the rapidly increasing amount of data in public mass spectrometry repositories, peptide mass spectra are usually analyzed by each laboratory in isolation, treating each experiment as if it has no relationship to any others. This approach fails to exploit the wealth of existing, previously analyzed mass spectrometry data. Alternatively, although large spectral data can be jointly analyzed using spectrum clustering methods, this unsupervised approach does not utilize information from peptide identifications. Here, we propose to train a deep neural network in a supervised fashion based on previous assignments of peptides to spectra. The network, called “GLEAMS,” learns to embed spectra into a low-dimensional space in which spectra generated by the same peptide are close to one another. We empirically demonstrate the utility of this learned embedding by propagating annotations from labeled to unlabeled spectra. We further use GLEAMS as the basis for a large-scale spectral clustering, detecting groups of unidentified, proximal spectra representing the same peptide, and we show how to use these clusters to explore the dark proteome of repeatedly observed yet consistently unidentified mass spectra. We provide a software implementation of our approach, along with a tool to quickly embed additional spectra using a pre-trained model, to facilitate large-scale analyses.</p></abstract><kwd-group kwd-group-type="author" hwp:id="kwd-group-1"><title hwp:id="title-2">Keywords</title><kwd hwp:id="kwd-1">mass spectrometry</kwd><kwd hwp:id="kwd-2">proteomics</kwd><kwd hwp:id="kwd-3">machine learning</kwd><kwd hwp:id="kwd-4">deep learning</kwd></kwd-group><counts><page-count count="23"/></counts><custom-meta-wrap><custom-meta hwp:id="custom-meta-1"><meta-name>special-property</meta-name><meta-value>contains-inline-supplementary-material</meta-value></custom-meta></custom-meta-wrap><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-2">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta><notes hwp:id="notes-1"><notes notes-type="competing-interest-statement" hwp:id="notes-2"><title hwp:id="title-3">Competing Interest Statement</title><p hwp:id="p-3">The authors have declared no competing interest.</p></notes><fn-group content-type="summary-of-updates" hwp:id="fn-group-1"><title hwp:id="title-4">Summary of Updates:</title><fn fn-type="update" hwp:id="fn-1"><p hwp:id="p-4">We have completely rewritten GLEAMS from the ground up to enable eﬀicient scaling to repository-scale data.
We have replaced our custom clustering algorithm with a standard large-scale clustering algorithm, DB-SCAN. This change appropriately places the emphasis of our manuscript on the quality of our learned embedding, showing that these embeddings work well with a standard clustering tool.
We have run our analysis on a massive dataset comprised of 669 million spectra. This is a pre-analyzed compendium of peptide-spectrum matches (PSMs) previously generated to produce a community knowledge base of the discoverable human proteome.</p></fn></fn-group><fn-group content-type="external-links" hwp:id="fn-group-2"><fn fn-type="dataset" hwp:id="fn-2"><p hwp:id="p-5">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/bittremieux/GLEAMS" ext-link-type="uri" xlink:href="https://github.com/bittremieux/GLEAMS" hwp:id="ext-link-2">https://github.com/bittremieux/GLEAMS</ext-link>
</p></fn></fn-group></notes></front><body><sec id="s1" hwp:id="sec-1"><label>1</label><title hwp:id="title-5">Introduction</title><p hwp:id="p-6">Since the publication of the SEQUEST search algorithm in 1994,<sup><xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">1</xref></sup> the dominant approach to assigning peptide sequences to tandem mass spectrometry (MS/MS) data has been to derive a list of candidates for each spectrum from a database, generate a theoretical spectrum for each candidate, and then score each putative peptide-spectrum match (PSM) based on the similarity between the observed and theoretical spectrum fragments. Major advances have been made in search algorithm development and various downstream analyses,<sup><xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">2</xref></sup> but an individual lab searching their spectra against a sequence database remains the dominant paradigm for MS/MS spectrum identification.</p><p hwp:id="p-7">Over the last decade, public proteomics repositories such as the PRoteomics IDEntifications (PRIDE) database<sup><xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">3</xref></sup> and MassIVE have grown to include billions of MS/MS spectra from tens of thousands of assays. As these repositories have become more comprehensive, efforts have been undertaken to make the spectra useful to researchers analyzing new datasets. Some approaches, such as PeptideAtlas,<sup><xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">4</xref></sup> the Global Proteome Machine Database,<sup><xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">5</xref></sup> and MassIVE,<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">6</xref></sup> involve re-searching the spectra using a common workflow. Typically, the output of the analysis is a spectral library, in which sets of spectra corresponding to the same peptide sequence are condensed into a single spectrum either by averaging or selecting a single, representative spectrum per peptide. The spectral library can then be used to analyze new datasets using a search algorithm. A drawback to any method that relies on standard database searching, however, is that prior to false discovery rate (FDR) estimation each spectrum is treated as an independent observation. By failing to jointly consider all of the spectra together during the assignment of peptides to spectra, these pipelines miss out on the opportunity to exploit valuable structure in the data.</p><p hwp:id="p-8">An alternative to simple re-searching of the data is to employ clustering algorithms, several of which have been developed specifically for clustering mass spectra, including MS-Cluster,<sup><xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">7</xref></sup> spectra-cluster,<sup><xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">8</xref>,<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">9</xref></sup> MaRaCluster,<sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">10</xref></sup> msCRUSH,<sup><xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">11</xref></sup> and falcon.<sup><xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">12</xref></sup> Although spectra-cluster and MS-Cluster have been used to process hundreds of millions of spectra from PRIDE<sup><xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-2" hwp:rel-id="ref-8">8</xref>,<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-2" hwp:rel-id="ref-9">9</xref></sup> and MassIVE,<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">6</xref></sup> respectively, in practice, however, it remains challenging to apply these methods on the repository scale. Furthermore, clustering approaches are limited in their ability to incorporate new data sets. Although new spectra that correspond to previously detected peptides can easily be added to the corresponding clusters, and some greedy clustering methods can use newly acquired spectra to create new clusters by merging existing ones,<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-3" hwp:rel-id="ref-6">6</xref></sup> running an entire clustering algorithm from scratch is an extremely expensive operation that becomes progressively more expensive as the repository grows.</p><p hwp:id="p-9">More fundamentally, clustering is problematic because it is an <italic toggle="yes">unsupervised</italic> approach. The input to a clustering algorithm is an unlabeled set of spectra. In practice, the labels (i.e. the associated peptide sequences) are used only in a <italic toggle="yes">post hoc</italic> fashion, to choose how many clusters to produce or to split up large clusters associated with multiple peptides. In recent years, a revolution has occurred in machine learning, with deep neural networks proving to have applicability across a wide array of problems.<sup><xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">13</xref></sup> Accordingly, within the field of proteomics, deep neural networks have recently been applied to several problems, including <italic toggle="yes">de novo</italic> peptide sequencing<sup><xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">14</xref>,<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">15</xref></sup> and simulating MS/MS spectra.<sup><xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">16</xref>,<xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">17</xref></sup> However, to our knowledge no one has yet applied deep neural networks to the problem of making public repository data contribute to the analysis of new mass spectrometry experiments. We hypothesize that we can obtain more accurate and useful information about a large collection of spectra by using a supervised deep learning method that directly exploits peptide–spectrum assignments during joint analysis. Specifically, we posit that peptide labels can be used during training of a large-scale learned model of MS/MS spectra to achieve a robust, efficient, and accurate model.</p><p hwp:id="p-10">Accordingly, we propose GLEAMS (GLEAMS is a Learned Embedding for Annotating Mass Spectra), which is a deep neural network that has been trained to embed MS/MS spectra into a 32-dimensional space in such a way that spectra generated by the same peptide, with the same post-translational modifications (PTMs) and charge, are close together. Our work builds upon methods that have been used successfully to embed various types of data, including text documents<sup><xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">18</xref></sup> and images.<sup><xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">19</xref></sup> The learned spectral embedding offers the advantage that new spectra can efficiently be mapped to the embedded space without requiring re-training. Our approach is fundamentally different from previous (unsupervised) spectrum clustering applications, in the sense that it uses peptide assignments generated from standard database search methods as labels in a supervised learning setting.</p><p hwp:id="p-11">We validate the embedding by demonstrating its ability to place spectra assigned the same label by database search close together, and we describe a method for using this embedding to assign peptide labels to new spectra. We also demonstrate how to use GLEAMS in conjunction with the DBSCAN algorithm<sup><xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">20</xref></sup> to induce a repository-scale clustering of spectra in the MassIVE database. We use these clusters to help characterize the so-called “dark matter” of proteomics. We provide an open-source software implementation of our method, as well as a pre-trained model that can be used to efficiently embed spectra for joint analysis (<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/bittremieux/GLEAMS" ext-link-type="uri" xlink:href="https://github.com/bittremieux/GLEAMS" hwp:id="ext-link-3">https://github.com/bittremieux/GLEAMS</ext-link>).</p></sec><sec id="s2" hwp:id="sec-2"><label>2</label><title hwp:id="title-6">Results</title><sec id="s2a" hwp:id="sec-3"><label>2.1</label><title hwp:id="title-7">A deep neural network learns to embed spectra into a common latent space</title><p hwp:id="p-12">The learned model consists of a “Siamese network,”<sup><xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">21</xref></sup> in which two copies of an embedding network operate side by side (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1A</xref>). During training, the network is provided with pairs of spectra <italic toggle="yes">S</italic><sub>1</sub> and <italic toggle="yes">S</italic><sub>2</sub> and an associated label <italic toggle="yes">Y</italic>, where <italic toggle="yes">Y</italic> = 1 indicates that the spectra were generated by the same peptide, and <italic toggle="yes">Y</italic> = 0 indicates that they were generated from different peptides. Each embedder transforms a spectrum <italic toggle="yes">S</italic><sub><italic toggle="yes">i</italic></sub> into its embedded representation <italic toggle="yes">G</italic><sub><italic toggle="yes">W</italic></sub>(<italic toggle="yes">S</italic><sub><italic toggle="yes">i</italic></sub>), where <italic toggle="yes">W</italic> represents the learned network weights. The key to the learning process is the contrastive loss function adapted from Hadsell et al. [21] defined as
<disp-formula id="ueqn1" hwp:id="disp-formula-1">
<alternatives hwp:id="alternatives-1"><graphic xlink:href="483263v2_ueqn1.gif" position="float" orientation="portrait" hwp:id="graphic-1"/></alternatives>
</disp-formula></p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2 xref-fig-1-3 xref-fig-1-4 xref-fig-1-5 xref-fig-1-6"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;483263v2/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1:</label><caption hwp:id="caption-1"><p hwp:id="p-13"><bold>(A)</bold> Two spectra, <italic toggle="yes">S</italic><sub>1</sub> and <italic toggle="yes">S</italic><sub>2</sub>, are encoded to vectors and passed as input to two instances of the embedder network with tied weights. The Euclidean distance between the two resulting embeddings, <italic toggle="yes">G</italic><sub><italic toggle="yes">W</italic></sub> (<italic toggle="yes">S</italic><sub>1</sub>) and <italic toggle="yes">G</italic><sub><italic toggle="yes">W</italic></sub> (<italic toggle="yes">S</italic><sub>2</sub>), is passed to a contrastive loss function that penalizes dissimilar embeddings that correspond to the same peptide and similar embeddings that correspond to different peptides, up to a margin of 1. <bold>(B)</bold> The embedder network separately receives each of three feature types as input. Precursor features are processed through a fully-connected network with two layers of sizes 32 and 5. Binned fragment intensities are processed through five blocks of one-dimensional convolutional layers and max pooling layers. Reference spectra features are processed through a fully-connected network with two layers of sizes 750 and 250. The output of the three subnetworks is concatenated and passed to a final fully-connected layer of size 32. <bold>(C)</bold> UMAP projection of 685 337 embeddings from frequently occurring peptides in 10 million randomly selected identified spectra from the test dataset. As indicated by the coloration, precursor <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> has a large influence on the location of spectra in the embedded space.</p></caption><graphic xlink:href="483263v2_fig1" position="float" orientation="portrait" hwp:id="graphic-2"/></fig><p hwp:id="p-14">Intuitively, this loss function pulls the two spectra together if they are associated with the same peptide (<italic toggle="yes">Y</italic> = 1) and pushes them apart if they are associated with different peptides (<italic toggle="yes">Y</italic> = 0). Backpropagation from this loss function is used to update the weights in the network.</p><p hwp:id="p-15">The heart of the model itself is the embedder network (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Figure 1B</xref>) which takes as input a spectrum and embeds it into a 32-dimensional space. The model contains two copies of the embedder, with weights tied so that updates to one embedder are always reflected in the other. For input to the embedder, each spectrum is encoded using three sets of features representing, respectively, attributes of the precursor ion, binned fragments, and similarities to an invariant set of reference spectra. Each of the different feature types is processed through a separate deep neural subnetwork, after which the outputs of the three networks are concatenated and passed to a final, fully-connected layer to produce vector embeddings with dimension 32.</p><p hwp:id="p-16">GLEAMS was trained using a set of 30 million high-quality PSMs derived from the MassIVE knowledge base (MassIVE-KB).<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-4" hwp:rel-id="ref-6">6</xref></sup> Importantly, peptide sequence information is only required during initial supervised training of the Siamese network. Subsequent processing using an individual embedder instance is agnostic to the peptide label and can be performed on identified and unidentified spectra in a similar fashion. After training, the embedder model was used to process 669 million spectra from 227 public human proteomics datasets included in MassIVE-KB. As an initial evaluation of the learned embeddings, these spectra were further projected down to two dimensions using UMAP<sup><xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">22</xref></sup> for visual inspection (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-3" hwp:rel-id="F1">Figure 1C</xref>). The visualizations suggest that precursor mass (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-4" hwp:rel-id="F1">Figure 1C</xref>) and precursor charge (Supplementary Figure 1) strongly influence the structure of the embedded space, and that similar spectra are indeed located close to each other. Additionally, several of the individual embedding dimensions show a correlation with the precursor mass, peptide sequence length, or whether the peptides have an arginine or lysine terminus (Supplementary Table 1). This indicates that the GLEAMS embeddings capture latent characteristics of the spectra. Interestingly, although some of these properties were provided as input to the neural network, such as precursor mass, other properties were derived from the data without explicitly encoding them.</p></sec><sec id="s2b" hwp:id="sec-4"><label>2.2</label><title hwp:id="title-8">Clustering of spectrum embeddings to explore spectral similarity</title><p hwp:id="p-17">If our training worked well, then spectra generated by the same peptide should lie close together, according to a Euclidean metric, in the embedded space. Accordingly, we investigated, for 10 million randomly chosen embedded spectra, the relationship between neighbor distance and the proportion of labeled neighbors that have the same peptide label. The results show that neighbors at small distances overwhelmingly represent the same peptide (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2A</xref>). Furthermore, the few different-peptide labels at very small distances almost entirely represent virtually indistinguishable spectra that have identical peptide labels but differ in ambiguous modification localizations. We also investigated the false negative rate, for 10 million randomly chosen embedding pairs, to understand the extent to which embeddings that correspond to the same peptide are distant in the embedded space (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2B</xref>). This analysis shows an excellent separation between same-labeled embeddings and embeddings corresponding to different peptides, with a very small false negative rate of only 1% at a distance threshold corresponding to 1% FDR. Furthermore, the embeddings are robust to different types of mass spectrometry data. Phosphorylation modifications were not included in the MassIVE-KB dataset, and GLEAMS thus did not see any phosphorylated spectra during its training. Nonetheless, GLEAMS was able to embed spectra from a phosphoproteomics study with high accuracy (Supplementary Figure 2).<sup><xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">23</xref></sup></p><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3 xref-fig-2-4 xref-fig-2-5 xref-fig-2-6 xref-fig-2-7"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;483263v2/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2:</label><caption hwp:id="caption-2"><p hwp:id="p-18"><bold>(A)</bold> Proportion of neighbors that have the same peptide label as a function of the distance threshold for 186 865 330 pairwise distances between 10 million randomly selected embeddings from the test dataset (on average 18.7 neighbors per embedding). Embeddings at small distances represent the same peptide (“Original”), while the majority of close neighbors with different peptide labels correspond to peptides with ambiguously localized modifications (“Unmodified”). <bold>(B)</bold> The false negative rate between positive and negative embedding pairs, for 10 million randomly selected pairs from the test dataset, at distance threshold 0.5455 (grey line), corresponding to 1% FDR, is only 1%, indicating excellent separation between positive and negative pairs. <bold>(C+D)</bold> Average clustering performance over three random folds of the test dataset containing 28 million MS/MS spectra each. <bold>(C)</bold> The number of clustered spectra versus the number of incorrectly clustered spectra per clustering algorithm. GLEAMS and MaRaCluster succeed in clustering the highest number of spectra at low rates of incorrectly clustered spectra, whereas MS-Cluster and spectra-cluster are unable to produce highly pure clusters. <bold>(D)</bold> Cluster completeness versus the number of incorrectly clustered spectra per clustering algorithm. GLEAMS produces the most complete clustering result at different levels of incorrectly clustered spectra. This indicates that GLEAMS achieves a greater data reduction than alternative clustering tools, without sacrificing the cluster quality. <bold>(E+F)</bold> Clustering result characteristics at approximately 1% incorrectly clustered spectra over three random folds of the test dataset (Supplementary Table 2). <bold>(E)</bold> Complementary empirical cumulative distribution of the cluster sizes. GLEAMS produces larger clusters than alternative clustering tools, grouping similar spectra into a single cluster rather than splitting them over multiple related clusters. <bold>(F)</bold> The number of datasets that spectra in the test dataset originate from per cluster (24 datasets total). GLEAMS successfully groups related spectra from heterogeneous datasets into single clusters.</p></caption><graphic xlink:href="483263v2_fig2" position="float" orientation="portrait" hwp:id="graphic-3"/></fig><p hwp:id="p-19">To further investigate the utility of the GLEAMS embedding, we performed DBSCAN clustering<sup><xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-2" hwp:rel-id="ref-20">20</xref></sup> in the embedded space to find dense clusters of spectra, and we compared the performance to that of the commonly used spectrum clustering tools MaRaCluster,<sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-2" hwp:rel-id="ref-10">10</xref></sup> MS-Cluster,<sup><xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-2" hwp:rel-id="ref-7">7</xref></sup> and spectra-cluster.<sup><xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-3" hwp:rel-id="ref-8">8</xref>,<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-3" hwp:rel-id="ref-9">9</xref></sup> The comparison indicates that clustering in the GLEAMS embedded space is of a similar or higher quality than clusterings produced by state-of-the-art tools, especially at low rates of incorrectly clustered spectra (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Figure 2C–D</xref>). Notably, even with the most stringent hyperparameters, MS-Cluster and spectra-cluster struggled to produce pure clustering results (i.e. low numbers of incorrectly clustered spectra), whereas specifying a low Euclidean distance threshold for GLEAMS clustering succeeds in producing highly pure clusters (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-4" hwp:rel-id="F2">Figure 2C</xref>). Additionally, GLEAMS generates the most “complete” clustering result (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-5" hwp:rel-id="F2">Figure 2D</xref>). Completeness measures the extent to which multiple spectra corresponding to the same peptide are concentrated in few clusters. By minimizing the extent to which spectra generated from the same peptide are assigned to different clusters, GLEAMS achieves improved data reduction from spectrum clustering compared to alternative clustering tools. This property is especially relevant when performing spectrum clustering at the repository scale, to maximally reduce the data volume for efficient downstream processing of the clustered data.</p><p hwp:id="p-20">To further understand the clustering performance of GLEAMS, we investigated clusters produced by the different tools at a low rate (∼1%) of incorrectly clustered spectra (Supplementary Table 2). These results indicate that GLEAMS and MaRaCluster succeed in clustering the highest number of spectra while minimizing the number of incorrectly clustered spectra. Furthermore, although GLEAMS and MaRaCluster cluster a similar total number of spectra, MaRaCluster groups these spectra into twice as many distinct clusters as GLEAMS. Overall, compared to alternative clustering tools, GLEAMS clearly produces the largest clusters (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-6" hwp:rel-id="F2">Figure 2E</xref>). In contrast, MaRaCluster and spectra-cluster predominantly generate clusters containing fewer than 100 spectra. We hypothesize that GLEAMS’ supervised training allows the model to focus on relevant spectrum features while ignoring confounding features (for example, peaks corresponding to a ubiquitous contaminant within a single study, boosting intra-study spectrum similarity). This hypothesis is supported by the observation that GLEAMS produces clusters with data drawn from more diverse studies, compared to clusters produced by the other tools (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-7" hwp:rel-id="F2">Figure 2F</xref>).</p></sec><sec id="s2c" hwp:id="sec-5"><label>2.3</label><title hwp:id="title-9">Elucidating the “dark proteome” of unidentified spectra</title><p hwp:id="p-21">A key outstanding question in protein mass spectrometry analysis concerns the source of spectral “dark matter,” i.e. spectra that are observed repeatedly across many experiments but consistently remain unidentified. Frank et al. [25] have previously used MS-Cluster to identify 4 million unknown spectra included in “spectral archives,” and Griss et al. [9] have used spectra-cluster to obtain identifications for 9 million previously unannotated spectra in the PRIDE repository.</p><p hwp:id="p-22">The original MassIVE-KB results<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-5" hwp:rel-id="ref-6">6</xref></sup> include identifications for 185 million PSMs out of 669 million MS/MS spectra (1% FDR), leaving a vast amount of spectral data unexplored. To characterize the unidentified spectra, we performed GLEAMS clustering (1% incorrectly clustered spectra) to group 193 million spectra in 17 million clusters. Among the clustered spectra, 86 million spectra were assigned a peptide label by MassIVE-KB, while 107 million spectra remained unidentified. The enrichment in identified spectra (45% of clustered spectra versus 28% of all spectra) indicates that, even though clustering is agnostic to peptide labels, it helps to extract repeatedly occurring, high-quality spectra that can be successfully identified.</p><p hwp:id="p-23">We used a combination of strategies to process the unidentified spectra and explore the dark proteome (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure 3A</xref>). First, peptide identifications were propagated within clusters. For clusters that consist of a mix of identified and unidentified spectra, the unidentified spectra were assigned the same peptide label as their identified cluster neighbors. In this fashion, 23 million PSMs could be identified.</p><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;483263v2/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3:</label><caption hwp:id="caption-3"><p hwp:id="p-24">Exploration of the dark proteome using GLEAMS to process previously unidentified spectra. <bold>(A)</bold> GLEAMS succeeded in identifying 31% additional PSMs compared to the original MassIVE-KB results by performing targeted open modification searching of cluster medoid spectra and propagating peptide labels within clusters. <bold>(B)</bold> Precursor delta masses observed from open modification searching. Some of the most frequent delta masses are annotated with their likely modifications, sourced from Unimod.<sup><xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">24</xref></sup></p></caption><graphic xlink:href="483263v2_fig3" position="float" orientation="portrait" hwp:id="graphic-4"/></fig><p hwp:id="p-25">Second, open modification searching (OMS) was used to investigate the remaining unidentified spectra. By using a large precursor mass window, spectra corresponding to peptides carrying any type of modification can be identified without explicitly having to specify the modifications of interest. However, this is a very computationally intensive task, due to the large increase in search space by opening up the precursor mass window. Therefore, only medoids of fully unidentified clusters were used, instead of having to perform OMS using all spectra. For 84 million clustered and unidentified spectra, 11 million medoid spectra were extracted and searched using the ANN-SoLo open modification spectral library search engine.<sup><xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">26</xref>,<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-1" hwp:rel-id="ref-27">27</xref></sup> This search resulted in 3.7 million newly identified PSMs (1% FDR) corresponding to modified peptides. Finally, peptide labels of the identified medoid spectra were propagated to other cluster members, resulting in 30 million additional PSMs.</p><p hwp:id="p-26">In total, these combined strategies succeeded in assigning peptides to 56 million previously unidentified PSMs, increasing the number of identified spectra by 31% (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Figure 3A</xref>). Additionally, the OMS results provide information on the presence of PTMs in the human proteome (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Figure 3B</xref>). Several of the observed precursor mass differences correspond to single amino acid substitutions, and modifications that were not considered in the original search settings were recovered. Besides abundant modifications that can be artificially introduced during sample processing, such as carbamidomethylation and oxidation, biologically relevant modifications from enrichment studies, such as phosphorylation, were frequently observed.</p><p hwp:id="p-27">Importantly, given its large computational requirements, performing an open search at a repository scale is a highly challenging endeavor. However, using GLEAMS embedding and clustering, we succeeded in efficiently boosting the identification rate by up to a third. Notably, while propagating peptide labels from 86 million original MassIVE-KB PSMs resulted in an increase of 23 million PSMs, similarly propagating peptide labels obtained using OMS from only 3.7 million high-quality spectra filtered using GLEAMS achieved an increase of 30 million PSMs. Additionally, there are 51 million clustered spectra that remained unidentified. Because these spectra are repeatedly observed and expected to be high-quality, they likely correspond to true signals. Consequently, this is an extremely important collection of spectra to investigate using newly developed computational methods to further explore the dark proteome. Overall, these results demonstrate how GLEAMS efficiently enables in-depth analysis at a repository scale.</p></sec></sec><sec id="s3" hwp:id="sec-6"><label>3</label><title hwp:id="title-10">Discussion</title><p hwp:id="p-28">We have demonstrated the utility of the 32-dimensional embedding learned by GLEAMS. By mapping spectra from diverse experiments into a common latent space, we can efficiently add an additional 31% to the identifications derived from database search. A key factor in GLEAMS’ strong performance is its ability to efficiently operate on hundreds of millions to billions of spectra, corresponding to the size of an entire proteomics repository. Once the embedder is trained, new spectra representing previously unobserved peptides can be embedded and used for analysis without performing any expensive operations as long as they have sufficiently similar characteristics to the distribution of training spectra. Because the computational power required to find the nearest neighbors of a given spectrum in the embedded space increases only sub-linearly with the size of the repository, this task can smoothly scale to billions of vectors. Additionally, specialized hardware, such as graphics processing units, can be used to speed up nearest neighbor searching.<sup><xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">28</xref></sup> This makes it possible in principle to assign new spectra to spectrum clusters nearly instantaneously upon submission to a repository, giving researchers the immediate benefit of the combined analysis efforts of the entire proteomics community.</p><p hwp:id="p-29">One caveat to the GLEAMS approach is that training the embedder relies upon the availability of peptide labels. A public repository typically contains datasets of varying quality and with varying types of analyses applied to them. The latter may even include invalid labels or labels not subjected to FDR control. Accordingly, we have exploited labels derived from systematic, repository-wide processing of the MassIVE database<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-6" hwp:rel-id="ref-6">6</xref></sup> to attempt to alleviate variability due to differences in analysis. This type of processing is expensive, but is hidden from the typical end user of GLEAMS, who will interact primarily with a pre-trained embedding network.</p><p hwp:id="p-30">We hypothesize that the learned embedding can have potential utility beyond simply transferring identifications among nearby spectra. For example, it may be that semantic relationships among spectra generated by related molecular species can be derived from the latent space, in analogy to semantic relationships encoded by neural word embeddings.<sup><xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-2" hwp:rel-id="ref-18">18</xref></sup> If such relationships could be mapped, then it might be possible to, for instance, predict where in the embedded space a spectrum generated by a peptide with a particular PTM would be found, based on the known location of the unmodified species. It may also be possible to develop a joint embedding of peptide sequences and spectra, allowing arbitrary peptide sequences to be embedded. The embedded space could then be used like a search engine, assigning peptide identifications to spectra based on closeness to an embedded peptide sequence.</p><p hwp:id="p-31">The embedding also opens up possibilities for transfer learning. For example, it may be possible to train a separate neural network to predict a spectrum’s quality, or potential for being identified, from its location in embedded space, or to classify spectra as “chimeric” (generated by more than one peptide) or not. Furthermore, the GLEAMS embedding may have potential for applications at the level of the mass spectrometry runs or entire experiments, using each experiment’s embedded spectra to predict its tissue of origin or, in the case of metaproteomics experiments, taxonomic makeup.</p><p hwp:id="p-32">A clear direction for future work is the development of statistical confidence estimation procedures suitable for this type of learned embedding. On the one hand, propagating peptide annotations between proximal pairs of spectra may risk introducing false positive assignments. On the other hand, when multiple identified spectra lie close to an unidentified spectrum, our confidence in such a propagation should intuitively increase relative to propagation with respect to a single spectrum–spectrum pair. Target-decoy methods for confidence estimation are widely used and provably correct under reasonable assumptions about the database search procedure,<sup><xref ref-type="bibr" rid="c29" hwp:id="xref-ref-29-1" hwp:rel-id="ref-29">29</xref></sup> but these methods do not generalize in a straightforward fashion to a method based on propagation in the GLEAMS embedded space.</p><p hwp:id="p-33">Furthermore, the training procedure might be augmented by the inclusion of additional features as input to the embedder network. For example, retention time is a valuable feature to validate spectrum identifications. Similarly, it is sometimes used as a filter to minimize the number of incorrect spectrum groupings during clustering. Currently, we did not include this information because the training data originated from a wide diversity of experimental set-ups, including varied chromatography conditions. However, an exploration of retention time-related features to use during training of the GLEAMS neural network could prove a fruitful avenue of research to further boost its performance.</p></sec><sec id="s4" hwp:id="sec-7"><label>4</label><title hwp:id="title-11">Methods</title><sec id="s4a" hwp:id="sec-8"><label>4.1</label><title hwp:id="title-12">Encoding mass spectra for network input</title><p hwp:id="p-34">Each spectrum is encoded as a vector of 3010 features of three types: precursor attributes, binned fragment intensities, and dot product similarities with a set of reference spectra.</p><p hwp:id="p-35">Precursor mass, <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic>, and charge are encoded as a combined 61 features. Precursor mass and <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> are each extremely important values for which precision is critical, and so they are poorly suited for encoding as single input features for a neural network. Accordingly, we experimented with several binary encodings of precursor mass and <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic>, each of which gave superior performance on validation data than a real-value encoding, and settled on the encoding that gave moderately better performance than the others: a 27-bit “Gray code” binary encoding, in which successive values differ by only a single bit, preserving locality and eliminating thresholds at which many bits are flipped at once. Precursor values may span the range 400 Da to 6000 Da, so the Gray code encoding has a resolution of 4 × 10<sup>−5</sup> Da. Fragment values may span the range 50.5 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> to 2500 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic>, so the Gray code encoding has a resolution of 2 × 10<sup>−5</sup> <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic>. Spectrum charge is one-hot encoded: seven features represent charge states 1–7, all of which are set to 0 except the charge corresponding to the spectrum (spectra with charge 8 or higher are encoded as charge 7).</p><p hwp:id="p-36">Fragment peaks are encoded as 2449 features. Fragment intensities are square-root transformed and then normalized by dividing by the sum of the square-root intensities. Fragments outside the range 50.5 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> to 2500 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> are discarded, and the remaining fragments are binned into 2449 bins at 1.000 507 9 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic>, corresponding to the distance between the centers of two adjacent clusters of physically possible peptide masses,<sup><xref ref-type="bibr" rid="c30" hwp:id="xref-ref-30-1" hwp:rel-id="ref-30">30</xref></sup> with bins offset by half a mass cluster separation width so that bin boundaries fall between peaks. This bin size was chosen in order to accommodate data acquired using various instruments and protocols, and in deference to practical constraints on the number of input features for the deep learning approach. Consequently, it is unrelated to the optimal fragment mass tolerance for database search for a given run.</p><p hwp:id="p-37">Similarities of each spectrum to an invariant set of reference spectra are encoded as 500 features. Each such feature is the normalized dot product between the given spectrum and one of an invariant set of 500 reference spectra chosen randomly from the training dataset. This can be considered as an “empirical kernel map”,<sup><xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">31</xref></sup> allowing GLEAMS to represent the similarity between two spectra <italic toggle="yes">A</italic> and <italic toggle="yes">B</italic> by “paths” of similarities through each one of the reference spectra <italic toggle="yes">R</italic> via the transitive property; i.e., <italic toggle="yes">A</italic> is similar to <italic toggle="yes">B</italic> if <italic toggle="yes">A</italic> is similar to <italic toggle="yes">R</italic> and <italic toggle="yes">R</italic> is similar to <italic toggle="yes">B</italic>. In contrast to the fragment binning strategy described previously, similarities to the reference spectra are computed at native resolution. The 500 reference MS/MS spectra were selected from the training data by using submodular selection, as implemented in the apricot Python package (version 0.4.1).<sup><xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">32</xref></sup> First, 1000 peak files were randomly selected from the training data, containing 22 million MS/MS spectra that were downsampled to 200 000 MS/MS spectra. These spectra were used to compute a pairwise similarity matrix (normalized dot product with fragment <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> tolerance 0.05 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic>) that was used to perform submodular selection using the facility location function to select 500 representative reference spectra (Supplementary Figure 3).</p></sec><sec id="s4b" hwp:id="sec-9"><label>4.2</label><title hwp:id="title-13">Repository-scale MS/MS data</title><p hwp:id="p-38">A large-scale, heterogeneous dataset derived from the MassIVE knowledge base (MassIVE-KB; version 2018-06-15)<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-7" hwp:rel-id="ref-6">6</xref></sup> was used to develop GLEAMS. As per Wang et al. [6], the MassIVE-KB dataset consists of 31 TB of human data from 227 public proteomics datasets. In total 28 155 peak files in the mzML<sup><xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">33</xref></sup> or mzXML format were downloaded from MassIVE, containing over 669 million MS/MS spectra.</p><p hwp:id="p-39">All spectra were processed using a uniform identification pipeline during initial compilation of the MassIVE-KB dataset.<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-8" hwp:rel-id="ref-6">6</xref></sup> MSGF+<sup><xref ref-type="bibr" rid="c34" hwp:id="xref-ref-34-1" hwp:rel-id="ref-34">34</xref></sup> was used to search the spectra against the UniProt human reference proteome database (version May 23, 2016).<sup><xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-1" hwp:rel-id="ref-35">35</xref></sup> Cysteine carbamidomethylation was set as a fixed modification, and variable modifications were methionine oxidation, N-terminal acetylation, N-terminal carbamylation, pyroglutamate formation from glutamine, and deamidation of aspargine and glutamine. MSGF+ was configured to allow one <sup><xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-2" hwp:rel-id="ref-13">13</xref></sup>C precursor mass isotope, at most one non-tryptic terminus, and 10 ppm precursor mass tolerance. The searches were individually filtered at 1% PSM-level FDR. A dynamic search space adjustment was performed during processing of the synthetic peptide spectra from the ProteomeTools project<sup><xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">36</xref></sup> and affinity purification mass spectrometry runs from the BioPlex project<sup><xref ref-type="bibr" rid="c37" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">37</xref></sup> to account for differences in sample complexity and spectral characteristics.<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-9" hwp:rel-id="ref-6">6</xref></sup> Next, the MassIVE-KB spectral library was generated using the top 100 PSMs for each unique precursor (i.e. combination of peptide sequence and charge), corresponding to 30 million high-quality PSMs (uniformly 0% PSM-level FDR from the original searches).<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-10" hwp:rel-id="ref-6">6</xref></sup></p><p hwp:id="p-40">The MSGF+ identification results for the full MassIVE-KB dataset were obtained from MassIVE in the mzTab format<sup><xref ref-type="bibr" rid="c38" hwp:id="xref-ref-38-1" hwp:rel-id="ref-38">38</xref></sup> and combined in a single metadata file containing 185 million PSMs. Additionally, information for the 30 million filtered PSMs to create the MassIVE-KB spectral library was independently retrieved.</p></sec><sec id="s4c" hwp:id="sec-10"><label>4.3</label><title hwp:id="title-14">Neural network architecture</title><p hwp:id="p-41">The embedder network (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-5" hwp:rel-id="F1">Figure 1B</xref>) takes each of the three types of inputs separately. The precursor features are processed through a two-layer fully-connected network with layer dimensions 32 and 5. The 2449-dimensional binned fragment intensities are processed through five blocks of one-dimensional convolutional layers and max pooling layers inspired by the VGG architecture.<sup><xref ref-type="bibr" rid="c39" hwp:id="xref-ref-39-1" hwp:rel-id="ref-39">39</xref></sup> The first two blocks consist of two consecutive convolutional layers, followed by a max pooling layer. The third, fourth, and fifth blocks each consist of three consecutive convolutional layers, followed by a max pooling layer. The number of output filters of each of the convolutional layers is 30 for the first block, 60 for the second block, 120 for the third block, and 240 for the fourth and fifth blocks. All blocks use convolutional layers with convolution window length 3 and convolution stride length 1. All max pooling layers consist of pool size 1 and stride length 2. In this fashion the first dimension is halved after every block to ultimately convert the 2449×1 dimensional input tensor to a 71×240 dimensional output tensor. The 500-dimensional reference spectra features are processed through a two-layer fully-connected network with layer dimensions 750 and 250. The output of the three networks is concatenated and passed to a final, L2-regularized, fully-connected layer with dimension 32.</p><p hwp:id="p-42">All network layers use the scaled exponential linear units (SELU) activation function.<sup><xref ref-type="bibr" rid="c40" hwp:id="xref-ref-40-1" hwp:rel-id="ref-40">40</xref></sup> The fully-connected layers are initialized using LeCun normal initialization,<sup><xref ref-type="bibr" rid="c41" hwp:id="xref-ref-41-1" hwp:rel-id="ref-41">41</xref></sup> and the convolutional layers are initialized using the Glorot uniform initialization.<sup><xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-1" hwp:rel-id="ref-42">42</xref></sup></p><p hwp:id="p-43">To train the embedder, we construct a “Siamese network” containing two instances of the embedder with tied weights <italic toggle="yes">W</italic> forming function <italic toggle="yes">G</italic><sub><italic toggle="yes">W</italic></sub> (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-6" hwp:rel-id="F1">Figure 1A</xref>). Pairs of spectra <italic toggle="yes">S</italic><sub>1</sub> and <italic toggle="yes">S</italic><sub>2</sub> are transformed to embeddings <italic toggle="yes">G</italic><sub><italic toggle="yes">W</italic></sub> (<italic toggle="yes">S</italic><sub>1</sub>) and <italic toggle="yes">G</italic><sub><italic toggle="yes">W</italic></sub> (<italic toggle="yes">S</italic><sub>2</sub>) in each instance of the Siamese network, respectively. The output of the Siamese network is the Euclidean distance between the two embeddings: ||<italic toggle="yes">G</italic><sub><italic toggle="yes">W</italic></sub> (<italic toggle="yes">S</italic><sub>1</sub>) − <italic toggle="yes">G</italic><sub><italic toggle="yes">W</italic></sub> (<italic toggle="yes">S</italic><sub>2</sub>)||<sub>2</sub>. The Siamese network is trained to optimize the following contrastive loss function:<sup><xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-2" hwp:rel-id="ref-21">21</xref></sup>
<disp-formula id="ueqn2" hwp:id="disp-formula-2">
<alternatives hwp:id="alternatives-2"><graphic xlink:href="483263v2_ueqn2.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives>
</disp-formula>
where <italic toggle="yes">Y</italic> is the label associated with the pair of spectra <italic toggle="yes">S</italic><sub>1</sub> and <italic toggle="yes">S</italic><sub>2</sub>.</p></sec><sec id="s4d" hwp:id="sec-11"><label>4.4</label><title hwp:id="title-15">Training the embedder</title><p hwp:id="p-44">The GLEAMS model was trained using the 30 million high-quality PSMs used for compilation of the MassIVE-KB spectral library. PSMs were randomly split by their MassIVE dataset identifier so that the training, validation, and test sets consisted of approximately 80%, 10%, and 10% of all PSMs respectively (training set: 24 986 744 PSMs / 554 290 510 MS/MS spectra from 184 datasets; validation set: 2 762 210 PSMs / 30 386 035 MS/MS spectra from 11 datasets; test set: 2 758 019 PSMs / 84 699 214 MS/MS spectra from 24 datasets).</p><p hwp:id="p-45">The Siamese neural network was trained using positive and negative spectra pairs. Positive pairs consist of two spectra with identical precursors, and negative spectra consist of two spectra that correspond to different peptides within a 10 ppm precursor mass tolerance with at most 25% overlap between their theoretical b and y fragments. In total 317 million, 205 million, 43 million, and 5 million positive training pairs were generated for precursor charges 2 to 5, respectively; and 8.347 billion, 3.263 billion, 182 million, and 5 million negative training pairs were generated for precursor charges 2 to 5, respectively.</p><p hwp:id="p-46">The Siamese neural network was trained for 50 iterations using the rectified Adam optimizer<sup><xref ref-type="bibr" rid="c43" hwp:id="xref-ref-43-1" hwp:rel-id="ref-43">43</xref></sup> with learning rate 0.0002. Each iteration consisted of 40 000 steps with batch size 256. The pair generators per precursor charge and label (positive/negative) were separately shuffled and rotated to ensure that each batch consisted of an equal number of positive and negative pairs and balanced precursor charge states. After each iteration the performance of the network was assessed using a fixed validation set consisting of 512 000 spectrum pairs.</p><p hwp:id="p-47">Training and evaluation were performed on a Intel Xeon Gold 6148 processor (2.4 GHz, 40 cores) with 768 GB memory and four NVIDIA GeForce RTX 2080 Ti graphics cards.</p></sec><sec id="s4e" hwp:id="sec-12"><label>4.5</label><title hwp:id="title-16">Phosphoproteomics embedding</title><p hwp:id="p-48">An independent phosphoproteomics dataset by Hijazi et al. [23], generated to study kinase network topology, was used to evaluate the robustness of the GLEAMS embeddings for unseen post-translational modifications. All raw and mzIdentML<sup><xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-1" hwp:rel-id="ref-44">44</xref></sup> files were downloaded from PRIDE (project PXD015943) using ppx (version 1.1.1)<sup><xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-1" hwp:rel-id="ref-45">45</xref></sup> and converted to mzML files<sup><xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-2" hwp:rel-id="ref-33">33</xref></sup> using ThermoRawFileParser (version 1.3.4).<sup><xref ref-type="bibr" rid="c46" hwp:id="xref-ref-46-1" hwp:rel-id="ref-46">46</xref></sup> As per Hijazi et al. [23], the original identifications were obtained by searching with Mascot (version 2.5)<sup><xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-1" hwp:rel-id="ref-47">47</xref></sup> against the SwissProt database (SwissProt_Sep2014_2015_12.fasta), with search settings of up to two tryptic missed cleavages; precursor mass tolerance 10 ppm; fragment mass tolerance 0.025 Da; cysteine carbamidomethylation as a fixed modification; and N-terminal pyroglutamate formation from glutamine, methionine oxidation, and phosphorylation of serine, threonine, and tyrosine as variable modifications. The identification results included 3.7 million PSMs at 1% FDR (of which 98.5% are phosphorylated) for 18.6 million MS/MS spectra. All spectra were embedded with the previously trained GLEAMS model, and 1.185 billion positive pairs consisting of PSMs with identical peptide sequences and 293 million negative pairs consisting of PSMs with different sequences within a 10 ppm precursor mass tolerance were generated.</p></sec><sec id="s4f" hwp:id="sec-13"><label>4.6</label><title hwp:id="title-17">Density-based embedding clustering</title><p hwp:id="p-49">Approximate nearest neighbor indexing and density-based clustering<sup><xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-2" hwp:rel-id="ref-12">12</xref></sup> were used to efficiently cluster the spectrum embeddings at a repository scale. First, the MS/MS spectra were converted to embeddings using the trained GLEAMS model. Next, the embeddings were split per precursor charge and partitioned into 1 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> buckets based on their corresponding precursor mass. The Faiss library was used for efficient similarity searching.<sup><xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-2" hwp:rel-id="ref-28">28</xref></sup> Faiss was used to construct an inverted index per <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> bucket by assigning the embeddings to centroids determined using k-means clustering. Conceptually, this corresponds to a Voronoi diagram, with each embedding assigned to its nearest representative centroid in the inverted index. The number of centroids to form the inverted index was dynamically set based on the number of embeddings in a bucket <italic toggle="yes">N</italic>. For buckets that consisted of up to one million embeddings <inline-formula hwp:id="inline-formula-1"><alternatives hwp:id="alternatives-3"><inline-graphic xlink:href="483263v2_inline1.gif" hwp:id="inline-graphic-1"/></alternatives></inline-formula> centroids were used; for buckets that consisted of up to ten million embeddings 2<sup><xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-2" hwp:rel-id="ref-16">16</xref></sup> centroids were used; and for larger buckets 2<sup><xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-3" hwp:rel-id="ref-18">18</xref></sup> centroids were used.</p><p hwp:id="p-50">Next, the inverted index was used for efficient similarity searching. Instead of having to perform all pairwise embedding comparisons in each bucket to find each embedding’s nearest neighbors, after mapping the embeddings to their Voronoi representatives they only needed to be compared to a limited number of embeddings in the inverted index. A maximum of 1024 lists in the inverted index were explored per query during searching, and for each embedding the Euclidean distances to its 50 nearest embeddings within a 10 ppm precursor mass window were stored in a sparse pairwise distance matrix.</p><p hwp:id="p-51">This pairwise distance matrix was used to cluster the data using the DBSCAN algorithm.<sup><xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-3" hwp:rel-id="ref-20">20</xref></sup> Briefly, if a given number of embeddings are close to each other and form a dense data subspace, with closeness defined relative to a user-specified Euclidean distance threshold, then they are grouped in clusters. However, some clusters produced by DBSCAN violated the 10 ppm precursor mass tolerance because embeddings within a cluster can be connected through other embeddings with intermediate precursor mass. To avoid such false positives, the clusters reported by DBSCAN were postprocessed by hierarchical clustering with maximum linkage of the cluster members’ precursor masses. In this fashion, some clusters are split into smaller, coherent clusters so that none of the embeddings in a single cluster have a pairwise precursor mass difference that exceeds the precursor mass tolerance.</p><p hwp:id="p-52">An important advantage of this clustering approach is that the number of clusters is not required to be known in advance. Instead, DBSCAN is able to find clusters in dense regions, whereas embeddings in low-density regions, without a sufficient number of close neighbors, are marked as noise. Additionally, the approach is scalable: using the sparse pairwise distance matrix it was possible to efficiently process hundreds of millions of data points simultaneously.</p></sec><sec id="s4g" hwp:id="sec-14"><label>4.7</label><title hwp:id="title-18">Cluster evaluation</title><p hwp:id="p-53">Four clustering algorithms—GLEAMS clustering, MaRaCluster,<sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-3" hwp:rel-id="ref-10">10</xref></sup> MS-Cluster,<sup><xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-3" hwp:rel-id="ref-7">7</xref></sup> and spectra-cluster<sup><xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-4" hwp:rel-id="ref-8">8</xref>,<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-4" hwp:rel-id="ref-9">9</xref></sup>—were run using a variety of parameter settings for each. For GLEAMS clustering Euclidean distance thresholds of 0.005, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, and 0.10 were used. MaRaCluster (version 1.01)<sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-4" hwp:rel-id="ref-10">10</xref></sup> was run with a precursor mass tolerance of 10 ppm, and with identical P-value and clustering thresholds −3.0, −5.0, −10.0, −15.0, −20.0, −25.0, −30.0, or −50.0. Other options were kept at their default values. MS-Cluster (version 2.00)<sup><xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-4" hwp:rel-id="ref-7">7</xref></sup> was run using its “LTQ_TRYP” model for three rounds of clustering with mixture probability 0.000 01, 0.0001, 0.001, 0.005, 0.01, 0.05, or 0.1. The fragment mass tolerance and precursor mass tolerance were 0.05 Da and 10 ppm, respectively, and precursor charges were read from the input files. Other options were kept at their default values. spectra-cluster (version 1.1.2)<sup><xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-5" hwp:rel-id="ref-8">8</xref>,<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-5" hwp:rel-id="ref-9">9</xref></sup> was run in its “fast mode” for three rounds of clustering with the final clustering threshold 0.999 99, 0.9999, 0.999, 0.99, 0.95, 0.9, or 0.8. The fragment mass tolerance and precursor mass tolerance were 0.05 Da and 10 ppm, respectively. Other options were kept at their default values.</p><p hwp:id="p-54">The clustering tools were evaluated using 85 million MS/MS spectra originating from 24 datasets in the test set. The spectra were split in three randomly generated folds, containing approximately 28 million MS/MS spectra each, and exported to MGF files for processing using the different clustering tools. To evaluate cluster quality, the mean performance over the three folds was used. Valid clusters were required to consist of minimum five spectra, and smaller clusters (including singleton clusters) were considered as noise.</p><p hwp:id="p-55">The following evaluation measures were used to assess cluster quality:</p><sec id="s4g1" hwp:id="sec-15"><title hwp:id="title-19">Clustered spectra</title><p hwp:id="p-56">The number of spectra in non-noise clusters divided by the total number of spectra.</p></sec><sec id="s4g2" hwp:id="sec-16"><title hwp:id="title-20">Incorrectly clustered spectra</title><p hwp:id="p-57">The number of incorrectly clustered spectra in non-noise clusters divided by the total number of identified spectra in non-noise clusters. Spectra are considered incorrectly clustered if their peptide labels deviate from the most frequent peptide label in their clusters, with unidentified spectra not considered.</p></sec><sec id="s4g3" hwp:id="sec-17"><title hwp:id="title-21">Completeness</title><p hwp:id="p-58">Completeness measures the fragmentation of spectra corresponding to the same peptide across multiple clusters and is based on the notion of <italic toggle="yes">entropy</italic> in information theory. A clustering result that perfectly satisfies the completeness criterium (value “1”) assigns all PSMs with an identical peptide label to a single cluster. Completeness is computed as one minus the conditional entropy of the cluster distribution given the peptide assignments divided by the maximum reduction in entropy the peptide assignments could provide.<sup><xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-1" hwp:rel-id="ref-48">48</xref></sup></p></sec></sec><sec id="s4h" hwp:id="sec-18"><label>4.8</label><title hwp:id="title-22">Clustering peptide annotation</title><p hwp:id="p-59">GLEAMS was used to embed all 669 million spectra in the MassIVE-KB dataset and cluster the embeddings using DBSCAN. The Euclidean distance threshold was 0.013, clustering 193 million spectra (29%) with 0.97% incorrectly clustered spectra and 0.821 completeness.</p><p hwp:id="p-60">To assign peptide labels to previously unidentified spectra, first peptide annotations were propagated within pure clusters. For 17 million clusters that contained a mixture of unidentified spectra and PSMs with identical peptide labels, the unidentified spectra were assigned the same label, resulting in 23 million new PSMs.</p><p hwp:id="p-61">Second, open modification searching was used to process the unidentified spectra. Medoid spectra were extracted from clusters consisting of only unidentified spectra by selecting the spectra with minimum embedded distances to all other cluster members. This resulted in 11 million medoid spectra representing 84 million clustered spectra. The medoid spectra were split into two groups based on cluster size —size two and size greater than two— and exported to two MGF files.</p><p hwp:id="p-62">Next, the ANN-SoLo<sup><xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-2" hwp:rel-id="ref-26">26</xref>,<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-2" hwp:rel-id="ref-27">27</xref></sup> (version 0.3.3) spectral library search engine was used for open modification searching.</p><p hwp:id="p-63">Search settings included preprocessing the spectra by removing peaks outside the 101 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> to 1500 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> range and peaks within a 1.5 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic> window around the precursor <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic>, precursor mass tolerance 10 ppm for the standard searching step of ANN-SoLo’s built-in cascade search and 500 Da for the open searching step, and fragment mass tolerance 0.05 <italic toggle="yes">m</italic>/<italic toggle="yes">z</italic>. Other settings were kept at their default values. As reference spectral library the MassIVE-KB spectral library was used. Duplicates were removed using SpectraST<sup><xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-1" hwp:rel-id="ref-49">49</xref></sup> (version 5.0 as part of the Trans-Proteomic Pipeline version 5.1.0<sup><xref ref-type="bibr" rid="c50" hwp:id="xref-ref-50-1" hwp:rel-id="ref-50">50</xref></sup>) by retaining only the best replicate spectrum for each individual peptide ion, and decoy spectra were added in a 1:1 ratio using the shuffle-and-reposition method.<sup><xref ref-type="bibr" rid="c51" hwp:id="xref-ref-51-1" hwp:rel-id="ref-51">51</xref></sup> PSMs were filtered at 1% FDR by ANN-SoLo’s built-in subgroup FDR procedure.<sup><xref ref-type="bibr" rid="c52" hwp:id="xref-ref-52-1" hwp:rel-id="ref-52">52</xref></sup></p><p hwp:id="p-64">ANN-SoLo managed to identify 3.7 million PSMs (32% of previously unidentified cluster medoid spectra). Finally, peptide labels from the ANN-SoLo PSMs were propagated to other cluster members, resulting in 30 million additional PSMs.</p></sec><sec id="s4i" hwp:id="sec-19"><label>4.9</label><title hwp:id="title-23">Code availability</title><p hwp:id="p-65">GLEAMS was implemented in Python 3.8. Pyteomics (version 4.3.2)<sup><xref ref-type="bibr" rid="c53" hwp:id="xref-ref-53-1" hwp:rel-id="ref-53">53</xref></sup> was used to read MS/MS spectra in the mzML,<sup><xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-3" hwp:rel-id="ref-33">33</xref></sup> mzXML, and MGF formats. spectrum_utils (version 0.3.4)<sup><xref ref-type="bibr" rid="c54" hwp:id="xref-ref-54-1" hwp:rel-id="ref-54">54</xref></sup> was used for spectrum preprocessing. Submodular selection was performed using apricot (version 0.4.1).<sup><xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-2" hwp:rel-id="ref-32">32</xref></sup> The neural network code was implemented using the Tensorflow/Keras framework (version 2.2.0).<sup><xref ref-type="bibr" rid="c55" hwp:id="xref-ref-55-1" hwp:rel-id="ref-55">55</xref></sup> Faiss (version 1.6.3)<sup><xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-3" hwp:rel-id="ref-28">28</xref></sup> was used for efficient similarity searching. Scikit-Learn (version 0.23.1)<sup><xref ref-type="bibr" rid="c56" hwp:id="xref-ref-56-1" hwp:rel-id="ref-56">56</xref></sup> was used for DBSCAN clustering, and fastcluster (version 1.1.28)<sup><xref ref-type="bibr" rid="c57" hwp:id="xref-ref-57-1" hwp:rel-id="ref-57">57</xref></sup> was used for hierarchical clustering. Additional scientific computing was done using NumPy (version 1.19.0),<sup><xref ref-type="bibr" rid="c58" hwp:id="xref-ref-58-1" hwp:rel-id="ref-58">58</xref></sup> SciPy (version 1.5.0),<sup><xref ref-type="bibr" rid="c59" hwp:id="xref-ref-59-1" hwp:rel-id="ref-59">59</xref></sup> Numba (version 0.50.1),<sup><xref ref-type="bibr" rid="c60" hwp:id="xref-ref-60-1" hwp:rel-id="ref-60">60</xref></sup> and Pandas (version 1.0.5).<sup><xref ref-type="bibr" rid="c61" hwp:id="xref-ref-61-1" hwp:rel-id="ref-61">61</xref></sup> Data analysis and visualization were performed using Jupyter Notebooks,<sup><xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-1" hwp:rel-id="ref-62">62</xref></sup> matplotlib (version 3.3.0),<sup><xref ref-type="bibr" rid="c63" hwp:id="xref-ref-63-1" hwp:rel-id="ref-63">63</xref></sup> Seaborn (version 0.11.0),<sup><xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-1" hwp:rel-id="ref-64">64</xref></sup> and UMAP (version 0.4.6).<sup><xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-2" hwp:rel-id="ref-22">22</xref></sup></p><p hwp:id="p-66">All code is available as open source under the permissive BSD license at <ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/bittremieux/GLEAMS" ext-link-type="uri" xlink:href="https://github.com/bittremieux/GLEAMS" hwp:id="ext-link-4">https://github.com/bittremieux/GLEAMS</ext-link>. Code used to analyze the data and to generate the figures presented here is available on GitHub (<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/bittremieux/GLEAMS_notebooks" ext-link-type="uri" xlink:href="https://github.com/bittremieux/GLEAMS_notebooks" hwp:id="ext-link-5">https://github.com/bittremieux/GLEAMS_notebooks</ext-link>).</p></sec></sec><sec sec-type="supplementary-material" hwp:id="sec-20"><title hwp:id="title-24">Supporting information</title><supplementary-material position="float" orientation="portrait" hwp:id="DC1"><object-id pub-id-type="other" hwp:sub-type="slug">DC1</object-id><label>Supplementary figures and tables</label><media xlink:href="supplements/483263_file02.pdf" position="float" orientation="portrait" hwp:id="media-1"/></supplementary-material></sec></body><back><ref-list hwp:id="ref-list-1"><title hwp:id="title-25">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1"><label>(1)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Eng J. K."><surname>Eng</surname>, <given-names>J. K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="McCormack A. L."><surname>McCormack</surname>, <given-names>A. L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Yates J. R. I."><surname>Yates</surname>, <given-names>J. R. I.</given-names></string-name> <article-title hwp:id="article-title-2">An Approach to Correlate Tandem Mass Spectral Data of Peptides with Amino Acid Sequences in a Protein Database</article-title>. <source hwp:id="source-1">Journal of the American Society for Mass Spectrometry</source> <year>1994</year>, <volume>5</volume>, <fpage>976</fpage>–<lpage>989</lpage>, DOI: <pub-id pub-id-type="doi">10.1016/1044-0305(94)80016-2</pub-id>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1"><label>(2)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Tabb D. L."><surname>Tabb</surname>, <given-names>D. L.</given-names></string-name> <article-title hwp:id="article-title-3">The SEQUEST Family Tree</article-title>. <source hwp:id="source-2">Journal of the American Society for Mass Spectrometry</source> <year>2015</year>, <volume>26</volume>, <fpage>1814</fpage>–<lpage>1819</lpage>, DOI: <pub-id pub-id-type="doi">10.1007/s13361-015-1201-3</pub-id>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><label>(3)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Perez-Riverol Y."><surname>Perez-Riverol</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Csordas A."><surname>Csordas</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bai J."><surname>Bai</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bernal-Llinares M."><surname>Bernal-Llinares</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-4">The PRIDE Database and Related Tools and Resources in 2019: Improving Support for Quantification Data</article-title>. <source hwp:id="source-3">Nucleic Acids Research</source> <year>2019</year>, <volume>47</volume>, <fpage>D442</fpage>–<lpage>D450</lpage>, DOI: <pub-id pub-id-type="doi">10.1093/nar/gky1106</pub-id>.</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1"><label>(4)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Deutsch E. W."><surname>Deutsch</surname>, <given-names>E. W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lam H."><surname>Lam</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Aebersold R."><surname>Aebersold</surname>, <given-names>R.</given-names></string-name> <article-title hwp:id="article-title-5">PeptideAtlas: A Resource for Target Selection for Emerging Targeted Proteomics Workflows</article-title>. <source hwp:id="source-4">EMBO reports</source> <year>2008</year>, <volume>9</volume>, <fpage>429</fpage>–<lpage>434</lpage>, DOI: <pub-id pub-id-type="doi">10.1038/embor.2008.56</pub-id>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1"><label>(5)</label><citation publication-type="book" citation-type="book" ref:id="483263v2.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Fenyö D."><surname>Fenyö</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Eriksson J."><surname>Eriksson</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Beavis R."><surname>Beavis</surname>, <given-names>R.</given-names></string-name> <chapter-title>In Computational Biology</chapter-title>, <person-group person-group-type="editor" hwp:id="person-group-1"><string-name name-style="western" hwp:sortable="Fenyö D."><surname>Fenyö</surname>, <given-names>D.</given-names></string-name></person-group>, Ed.; <source hwp:id="source-5">Methods in Molecular Biology</source>, Vol. <volume>673</volume>; <publisher-name>Humana Press</publisher-name>: <publisher-loc>Totowa, NJ</publisher-loc>, <year>2010</year>, pp <fpage>189</fpage>–<lpage>202</lpage>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2 xref-ref-6-3 xref-ref-6-4 xref-ref-6-5 xref-ref-6-6 xref-ref-6-7 xref-ref-6-8 xref-ref-6-9 xref-ref-6-10"><label>(6)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Wang M."><surname>Wang</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wang J."><surname>Wang</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Carver J."><surname>Carver</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pullman B. S."><surname>Pullman</surname>, <given-names>B. S.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-6">Assembling the Community-Scale Discoverable Human Proteome</article-title>. <source hwp:id="source-6">Cell Systems</source> <year>2018</year>, <volume>7</volume>, <fpage>412</fpage>–<lpage>421</lpage>.e5, DOI: <pub-id pub-id-type="doi">10.1016/j.cels.2018.08.004</pub-id>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1 xref-ref-7-2 xref-ref-7-3 xref-ref-7-4"><label>(7)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Frank A. M."><surname>Frank</surname>, <given-names>A. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bandeira N."><surname>Bandeira</surname>, <given-names>N.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shen Z."><surname>Shen</surname>, <given-names>Z.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tanner S."><surname>Tanner</surname>, <given-names>S.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-7">Clustering Millions of Tandem Mass Spectra</article-title>. <source hwp:id="source-7">Journal of Proteome Research</source> <year>2008</year>, <volume>7</volume>, <fpage>113</fpage>–<lpage>122</lpage>, DOI: <pub-id pub-id-type="doi">10.1021/pr070361e</pub-id>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1 xref-ref-8-2 xref-ref-8-3 xref-ref-8-4 xref-ref-8-5"><label>(8)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Griss J."><surname>Griss</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Foster J. M."><surname>Foster</surname>, <given-names>J. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hermjakob H."><surname>Hermjakob</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Vizcaíno J. A."><surname>Vizcaíno</surname>, <given-names>J. A.</given-names></string-name> <article-title hwp:id="article-title-8">PRIDE Cluster: Building a Consensus of Proteomics Data</article-title>. <source hwp:id="source-8">Nature Methods</source> <year>2013</year>, <volume>10</volume>, <fpage>95</fpage>–<lpage>96</lpage>, DOI: <pub-id pub-id-type="doi">10.1038/nmeth.2343</pub-id>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1 xref-ref-9-2 xref-ref-9-3 xref-ref-9-4 xref-ref-9-5"><label>(9)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Griss J."><surname>Griss</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Perez-Riverol Y."><surname>Perez-Riverol</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lewis S."><surname>Lewis</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tabb D. L."><surname>Tabb</surname>, <given-names>D. L.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-9">Recognizing Millions of Consistently Unidentified Spectra across Hundreds of Shotgun Proteomics Datasets</article-title>. <source hwp:id="source-9">Nature Methods</source> <year>2016</year>, <volume>13</volume>, <fpage>651</fpage>–<lpage>656</lpage>, DOI: <pub-id pub-id-type="doi">10.1038/nmeth.3902</pub-id>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1 xref-ref-10-2 xref-ref-10-3 xref-ref-10-4"><label>(10)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="The M."><surname>The</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Käll L."><surname>Käll</surname>, <given-names>L.</given-names></string-name> <article-title hwp:id="article-title-10">MaRaCluster: A Fragment Rarity Metric for Clustering Fragment Spectra in Shotgun Proteomics</article-title>. <source hwp:id="source-10">Journal of Proteome Research</source> <year>2016</year>, <volume>15</volume>, <fpage>713</fpage>–<lpage>720</lpage>, DOI: <pub-id pub-id-type="doi">10.1021/acs.jproteome.5b00749</pub-id>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><label>(11)</label><citation publication-type="other" citation-type="journal" ref:id="483263v2.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Wang L."><surname>Wang</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Li S."><surname>Li</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tang H."><surname>Tang</surname>, <given-names>H.</given-names></string-name> <article-title hwp:id="article-title-11">msCRUSH: Fast Tandem Mass Spectral Clustering Using Locality Sensitive Hashing</article-title>. <source hwp:id="source-11">Journal of Proteome Research</source> <year>2019</year>, DOI: <pub-id pub-id-type="doi">10.1021/acs.jproteome.8b00448</pub-id>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1 xref-ref-12-2"><label>(12)</label><citation publication-type="other" citation-type="journal" ref:id="483263v2.12" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Bittremieux W."><surname>Bittremieux</surname>, <given-names>W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Laukens K."><surname>Laukens</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Noble W. S."><surname>Noble</surname>, <given-names>W. S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dorrestein P. C."><surname>Dorrestein</surname>, <given-names>P. C.</given-names></string-name> <article-title hwp:id="article-title-12">Large-Scale Tandem Mass Spectrum Clustering Using Fast Nearest Neighbor Searching</article-title>. <source hwp:id="source-12">Rapid Communications in Mass Spectrometry</source> <year>2021</year>, <fpage>e9153</fpage>, DOI: <pub-id pub-id-type="doi">10.1002/rcm.9153</pub-id>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1 xref-ref-13-2"><label>(13)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="LeCun Y."><surname>LeCun</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bengio Y."><surname>Bengio</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hinton G."><surname>Hinton</surname>, <given-names>G.</given-names></string-name> <article-title hwp:id="article-title-13">Deep Learning</article-title>. <source hwp:id="source-13">Nature</source> <year>2015</year>, <volume>521</volume>, <fpage>436</fpage>–<lpage>444</lpage>, DOI: <pub-id pub-id-type="doi">10.1038/nature14539</pub-id>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><label>(14)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Tran N. H."><surname>Tran</surname>, <given-names>N. H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zhang X."><surname>Zhang</surname>, <given-names>X.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Xin L."><surname>Xin</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shan B."><surname>Shan</surname>, <given-names>B.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-14">De Novo Peptide Sequencing by Deep Learning</article-title>. <source hwp:id="source-14">Proceedings of the National Academy of Sciences</source> <year>2017</year>, <volume>114</volume>, <fpage>8247</fpage>–<lpage>8252</lpage>, DOI: <pub-id pub-id-type="doi">10.1073/pnas.1705691114</pub-id>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><label>(15)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.15" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Tran N. H."><surname>Tran</surname>, <given-names>N. H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Qiao R."><surname>Qiao</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Xin L."><surname>Xin</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chen X."><surname>Chen</surname>, <given-names>X.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-15">Deep Learning Enables de Novo Peptide Sequencing from Data-Independent-Acquisition Mass Spectrometry</article-title>. <source hwp:id="source-15">Nature Methods</source> <year>2018</year>, <volume>16</volume>, <fpage>63</fpage>–<lpage>66</lpage>, DOI: <pub-id pub-id-type="doi">10.1038/s41592-018-0260-3</pub-id>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1 xref-ref-16-2"><label>(16)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Gessulat S."><surname>Gessulat</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schmidt T."><surname>Schmidt</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zolg D. P."><surname>Zolg</surname>, <given-names>D. P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Samaras P."><surname>Samaras</surname>, <given-names>P.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-16">Prosit: Proteome-Wide Prediction of Peptide Tandem Mass Spectra by Deep Learning</article-title>. <source hwp:id="source-16">Nature Methods</source> <year>2019</year>, <volume>16</volume>, <fpage>509</fpage>–<lpage>518</lpage>, DOI: <pub-id pub-id-type="doi">10.1038/s41592-019-0426-7</pub-id>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><label>(17)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Tiwary S."><surname>Tiwary</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Levy R."><surname>Levy</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gutenbrunner P."><surname>Gutenbrunner</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Salinas Soto F."><surname>Salinas Soto</surname>, <given-names>F.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-17">High-Quality MS/MS Spectrum Prediction for Data-Dependent and Data-Independent Acquisition Data Analysis</article-title>. <source hwp:id="source-17">Nature Methods</source> <year>2019</year>, <volume>16</volume>, <fpage>519</fpage>–<lpage>525</lpage>, DOI: <pub-id pub-id-type="doi">10.1038/s41592-019-0427-6</pub-id>.</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1 xref-ref-18-2 xref-ref-18-3"><label>(18)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.18" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Mikolov T."><surname>Mikolov</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chen K."><surname>Chen</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Corrado G."><surname>Corrado</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dean J."><surname>Dean</surname>, <given-names>J.</given-names></string-name> <source hwp:id="source-18">Efficient Estimation of Word Representations in Vector Space</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="https://arxiv.org/abs/1301.3781v3" ext-link-type="uri" xlink:href="https://arxiv.org/abs/1301.3781v3" hwp:id="ext-link-6">https://arxiv.org/abs/1301.3781v3</ext-link>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><label>(19)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.19" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Chen T."><surname>Chen</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kornblith S."><surname>Kornblith</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Norouzi M."><surname>Norouzi</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hinton G."><surname>Hinton</surname>, <given-names>G.</given-names></string-name> <source hwp:id="source-19">A Simple Framework for Contrastive Learning of Visual Representations</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="http://arxiv.org/abs/2002.05709" ext-link-type="uri" xlink:href="http://arxiv.org/abs/2002.05709" hwp:id="ext-link-7">http://arxiv.org/abs/2002.05709</ext-link>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1 xref-ref-20-2 xref-ref-20-3"><label>(20)</label><citation publication-type="book" citation-type="book" ref:id="483263v2.20" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Ester M."><surname>Ester</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kriegel H.-P."><surname>Kriegel</surname>, <given-names>H.-P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sander J."><surname>Sander</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Xu X."><surname>Xu</surname>, <given-names>X.</given-names></string-name> <source hwp:id="source-20">In Proceedings of the Second International Conference on Knowledge Discovery and Data Mining - KDD’96</source>, <publisher-name>AAAI Press</publisher-name>: <publisher-loc>Portland, OR, USA</publisher-loc>, <year>1996</year>, pp <fpage>226</fpage>–<lpage>231</lpage>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1 xref-ref-21-2"><label>(21)</label><citation publication-type="book" citation-type="book" ref:id="483263v2.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Hadsell R."><surname>Hadsell</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chopra S."><surname>Chopra</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="LeCun Y."><surname>LeCun</surname>, <given-names>Y.</given-names></string-name> <source hwp:id="source-21">In Proceedings of the 2006 IEEE Computer Society Conference on Computer Vision and Pattern Recognition - CVPR ‘06</source>, <publisher-name>IEEE</publisher-name>: <publisher-loc>New York, NY, USA</publisher-loc>, <year>2006</year>; Vol. <volume>2</volume>, pp <fpage>1735</fpage>–<lpage>1742</lpage>, DOI: <pub-id pub-id-type="doi">10.1109/CVPR.2006.100</pub-id>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1 xref-ref-22-2"><label>(22)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.22" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="McInnes L."><surname>McInnes</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Healy J."><surname>Healy</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Melville J."><surname>Melville</surname>, <given-names>J.</given-names></string-name> <source hwp:id="source-22">UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="http://arxiv.org/abs/1802.03426" ext-link-type="uri" xlink:href="http://arxiv.org/abs/1802.03426" hwp:id="ext-link-8">http://arxiv.org/abs/1802.03426</ext-link>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1"><label>(23)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Hijazi M."><surname>Hijazi</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Smith R."><surname>Smith</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rajeeve V."><surname>Rajeeve</surname>, <given-names>V.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bessant C."><surname>Bessant</surname>, <given-names>C.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-18">Reconstructing Kinase Network Topologies from Phosphoproteomics Data Reveals Cancer-Associated Rewiring</article-title>. <source hwp:id="source-23">Nature Biotechnology</source> <year>2020</year>, <volume>38</volume>, <fpage>493</fpage>–<lpage>502</lpage>, DOI: <pub-id pub-id-type="doi">10.1038/s41587-019-0391-9</pub-id>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1"><label>(24)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Creasy D. M."><surname>Creasy</surname>, <given-names>D. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cottrell J. S."><surname>Cottrell</surname>, <given-names>J. S.</given-names></string-name> <article-title hwp:id="article-title-19">Unimod: Protein Modifications for Mass Spectrometry</article-title>. <source hwp:id="source-24">PROTEOMICS</source> <year>2004</year>, <volume>4</volume>, <fpage>1534</fpage>–<lpage>1536</lpage>, DOI: <pub-id pub-id-type="doi">10.1002/pmic.200300744</pub-id>.</citation></ref><ref id="c25" hwp:id="ref-25"><label>(25)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Frank A. M."><surname>Frank</surname>, <given-names>A. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Monroe M. E."><surname>Monroe</surname>, <given-names>M. E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shah A. R."><surname>Shah</surname>, <given-names>A. R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Carver J. J."><surname>Carver</surname>, <given-names>J. J.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-20">Spectral Archives: Extending Spectral Libraries to Analyze Both Identified and Unidentified Spectra</article-title>. <source hwp:id="source-25">Nature Methods</source> <year>2011</year>, <volume>8</volume>, <fpage>587</fpage>–<lpage>591</lpage>, DOI: <pub-id pub-id-type="doi">10.1038/nmeth.1609</pub-id>.</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1 xref-ref-26-2"><label>(26)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.26" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Bittremieux W."><surname>Bittremieux</surname>, <given-names>W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Meysman P."><surname>Meysman</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Noble W. S."><surname>Noble</surname>, <given-names>W. S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Laukens K."><surname>Laukens</surname>, <given-names>K.</given-names></string-name> <article-title hwp:id="article-title-21">Fast Open Modification Spectral Library Searching through Approximate Nearest Neighbor Indexing</article-title>. <source hwp:id="source-26">Journal of Proteome Research</source> <year>2018</year>, <volume>17</volume>, <fpage>3463</fpage>–<lpage>3474</lpage>, DOI: <pub-id pub-id-type="doi">10.1021/acs.jproteome.8b00359</pub-id>.</citation></ref><ref id="c27" hwp:id="ref-27" hwp:rev-id="xref-ref-27-1 xref-ref-27-2"><label>(27)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.27" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Bittremieux W."><surname>Bittremieux</surname>, <given-names>W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Laukens K."><surname>Laukens</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Noble W. S."><surname>Noble</surname>, <given-names>W. S.</given-names></string-name> <article-title hwp:id="article-title-22">Extremely Fast and Accurate Open Modification Spectral Library Searching of High-Resolution Mass Spectra Using Feature Hashing and Graphics Processing Units</article-title>. <source hwp:id="source-27">Journal of Proteome Research</source> <year>2019</year>, <volume>18</volume>, <fpage>3792</fpage>–<lpage>3799</lpage>, DOI: <pub-id pub-id-type="doi">10.1021/acs.jproteome.9b00291</pub-id>.</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1 xref-ref-28-2 xref-ref-28-3"><label>(28)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.28" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Johnson J."><surname>Johnson</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Douze M."><surname>Douze</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jégou H."><surname>Jégou</surname>, <given-names>H.</given-names></string-name> <source hwp:id="source-28">Billion-Scale Similarity Search with GPUs</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="http://arxiv.org/abs/1702.08734" ext-link-type="uri" xlink:href="http://arxiv.org/abs/1702.08734" hwp:id="ext-link-9">http://arxiv.org/abs/1702.08734</ext-link>.</citation></ref><ref id="c29" hwp:id="ref-29" hwp:rev-id="xref-ref-29-1"><label>(29)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.29" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="He K."><surname>He</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fu Y."><surname>Fu</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zeng W.-F."><surname>Zeng</surname>, <given-names>W.-F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Luo L."><surname>Luo</surname>, <given-names>L.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-23">A theoretical foundation of the target-decoy search strategy for false discovery rate control in proteomics</article-title>. <source hwp:id="source-29">arXiv</source> <year>2015</year>, <ext-link l:rel="related" l:ref-type="uri" l:ref="https://arxiv.org/abs/1501.00537" ext-link-type="uri" xlink:href="https://arxiv.org/abs/1501.00537" hwp:id="ext-link-10">https://arxiv.org/abs/1501.00537</ext-link>.</citation></ref><ref id="c30" hwp:id="ref-30" hwp:rev-id="xref-ref-30-1"><label>(30)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.30" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="Wolski W. E."><surname>Wolski</surname>, <given-names>W. E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Farrow M."><surname>Farrow</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Emde A.-K."><surname>Emde</surname>, <given-names>A.-K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lehrach H."><surname>Lehrach</surname>, <given-names>H.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-24">Analytical Model of Peptide Mass Cluster Centres with Applications</article-title>. <source hwp:id="source-30">Proteome Science</source> <year>2006</year>, <volume>4</volume>, <fpage>18</fpage>, DOI: <pub-id pub-id-type="doi">10.1186/1477-5956-4-18</pub-id>.</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1"><label>(31)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="Hofmann T."><surname>Hofmann</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schölkopf B."><surname>Schölkopf</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Smola A. J."><surname>Smola</surname>, <given-names>A. J.</given-names></string-name> <article-title hwp:id="article-title-25">Kernel Methods in Machine Learning</article-title>. <source hwp:id="source-31">The Annals of Statistics</source> <year>2008</year>, <volume>36</volume>, <fpage>1171</fpage>–<lpage>1220</lpage>, DOI: <pub-id pub-id-type="doi">10.1214/009053607000000677</pub-id>.</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1 xref-ref-32-2"><label>(32)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.32" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="Schreiber J."><surname>Schreiber</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bilmes J."><surname>Bilmes</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Noble W. S."><surname>Noble</surname>, <given-names>W. S.</given-names></string-name> <source hwp:id="source-32">Apricot: Submodular Selection for Data Summarization in Python</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="http://arxiv.org/abs/1906.03543" ext-link-type="uri" xlink:href="http://arxiv.org/abs/1906.03543" hwp:id="ext-link-11">http://arxiv.org/abs/1906.03543</ext-link>.</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1 xref-ref-33-2 xref-ref-33-3"><label>(33)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.33" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Martens L."><surname>Martens</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chambers M."><surname>Chambers</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sturm M."><surname>Sturm</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kessner D."><surname>Kessner</surname>, <given-names>D.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-26">mzML—a Community Standard for Mass Spectrometry Data</article-title>. <source hwp:id="source-33">Molecular &amp; Cellular Proteomics</source> <year>2011</year>, <volume>10</volume>, R110.000133–R110.000133, DOI: <pub-id pub-id-type="doi">10.1074/mcp.R110.000133</pub-id>.</citation></ref><ref id="c34" hwp:id="ref-34" hwp:rev-id="xref-ref-34-1"><label>(34)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.34" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Kim S."><surname>Kim</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pevzner P. A."><surname>Pevzner</surname>, <given-names>P. A.</given-names></string-name> <article-title hwp:id="article-title-27">MS-GF+ Makes Progress towards a Universal Database Search Tool for Proteomics</article-title>. <source hwp:id="source-34">Nature Communications</source> <year>2014</year>, <volume>5</volume>, <fpage>5277</fpage>, DOI: <pub-id pub-id-type="doi">10.1038/ncomms6277</pub-id>.</citation></ref><ref id="c35" hwp:id="ref-35" hwp:rev-id="xref-ref-35-1"><label>(35)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.35" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Breuza L."><surname>Breuza</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Poux S."><surname>Poux</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Estreicher A."><surname>Estreicher</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Famiglietti M. L."><surname>Famiglietti</surname>, <given-names>M. L.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-28">The UniProtKB Guide to the Human Proteome</article-title>. <source hwp:id="source-35">Database</source> <year>2016</year>, <volume>2016</volume>, <fpage>bav120</fpage>, DOI: <pub-id pub-id-type="doi">10.1093/database/bav120</pub-id>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1"><label>(36)</label><citation publication-type="other" citation-type="journal" ref:id="483263v2.36" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Zolg D. P."><surname>Zolg</surname>, <given-names>D. P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wilhelm M."><surname>Wilhelm</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schnatbaum K."><surname>Schnatbaum</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zerweck J."><surname>Zerweck</surname>, <given-names>J.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-29">Building ProteomeTools Based on a Complete Synthetic Human Proteome</article-title>. <source hwp:id="source-36">Nature Methods</source> <year>2017</year>, DOI: <pub-id pub-id-type="doi">10.1038/nmeth.4153</pub-id>.</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1"><label>(37)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.37" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Huttlin E. L."><surname>Huttlin</surname>, <given-names>E. L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ting L."><surname>Ting</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bruckner R. J."><surname>Bruckner</surname>, <given-names>R. J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gebreab F."><surname>Gebreab</surname>, <given-names>F.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-30">The BioPlex Network: A Systematic Exploration of the Human Interactome</article-title>. <source hwp:id="source-37">Cell</source> <year>2015</year>, <volume>162</volume>, <fpage>425</fpage>–<lpage>440</lpage>, DOI: <pub-id pub-id-type="doi">10.1016/j.cell.2015.06.043</pub-id>.</citation></ref><ref id="c38" hwp:id="ref-38" hwp:rev-id="xref-ref-38-1"><label>(38)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.38" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-38"><string-name name-style="western" hwp:sortable="Griss J."><surname>Griss</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jones A. R."><surname>Jones</surname>, <given-names>A. R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sachsenberg T."><surname>Sachsenberg</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Walzer M."><surname>Walzer</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-31">The mzTab Data Exchange Format: Communicating Mass-Spectrometry-Based Proteomics and Metabolomics Experimental Results to a Wider Audience</article-title>. <source hwp:id="source-38">Molecular &amp; Cellular Proteomics</source> <year>2014</year>, <volume>13</volume>, <fpage>2765</fpage>–<lpage>2775</lpage>, DOI: <pub-id pub-id-type="doi">10.1074/mcp.O113.036681</pub-id>.</citation></ref><ref id="c39" hwp:id="ref-39" hwp:rev-id="xref-ref-39-1"><label>(39)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.39" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-39"><string-name name-style="western" hwp:sortable="Simonyan K."><surname>Simonyan</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zisserman A."><surname>Zisserman</surname>, <given-names>A.</given-names></string-name> <source hwp:id="source-39">Very Deep Convolutional Networks for Large-Scale Image Recognition</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="http://arxiv.org/abs/1409.1556" ext-link-type="uri" xlink:href="http://arxiv.org/abs/1409.1556" hwp:id="ext-link-12">http://arxiv.org/abs/1409.1556</ext-link>.</citation></ref><ref id="c40" hwp:id="ref-40" hwp:rev-id="xref-ref-40-1"><label>(40)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.40" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-40"><string-name name-style="western" hwp:sortable="Klambauer G."><surname>Klambauer</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Unterthiner T."><surname>Unterthiner</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mayr A."><surname>Mayr</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hochreiter S."><surname>Hochreiter</surname>, <given-names>S.</given-names></string-name> <source hwp:id="source-40">Self-Normalizing Neural Networks</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="http://arxiv.org/abs/1706.02515" ext-link-type="uri" xlink:href="http://arxiv.org/abs/1706.02515" hwp:id="ext-link-13">http://arxiv.org/abs/1706.02515</ext-link>.</citation></ref><ref id="c41" hwp:id="ref-41" hwp:rev-id="xref-ref-41-1"><label>(41)</label><citation publication-type="book" citation-type="book" ref:id="483263v2.41" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-41"><string-name name-style="western" hwp:sortable="LeCun Y. A."><surname>LeCun</surname>, <given-names>Y. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bottou L."><surname>Bottou</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Orr G. B."><surname>Orr</surname>, <given-names>G. B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Müller K.-R."><surname>Müller</surname>, <given-names>K.-R.</given-names></string-name> <chapter-title>In Neural Networks: Tricks of the Trade</chapter-title>, <person-group person-group-type="editor" hwp:id="person-group-2"><string-name name-style="western" hwp:sortable="Montavon G."><surname>Montavon</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Orr G. B."><surname>Orr</surname>, <given-names>G. B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Müller K.-R."><surname>Müller</surname>, <given-names>K.-R.</given-names></string-name></person-group>, Eds.; <source hwp:id="source-41">Lecture Notes in Computer Science</source>, Vol. <volume>7700</volume>; <publisher-name>Springer Berlin Heidelberg</publisher-name>: <publisher-loc>Berlin, Heidelberg</publisher-loc>, <year>2012</year>, pp <fpage>9</fpage>–<lpage>48</lpage>.</citation></ref><ref id="c42" hwp:id="ref-42" hwp:rev-id="xref-ref-42-1"><label>(42)</label><citation publication-type="book" citation-type="book" ref:id="483263v2.42" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-42"><string-name name-style="western" hwp:sortable="Glorot X."><surname>Glorot</surname>, <given-names>X.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bengio Y."><surname>Bengio</surname>, <given-names>Y.</given-names></string-name> <chapter-title>In Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics, ed. by</chapter-title> <person-group person-group-type="editor" hwp:id="person-group-3"><string-name name-style="western" hwp:sortable="Teh Y. W."><surname>Teh</surname>, <given-names>Y. W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Titterington M."><surname>Titterington</surname>, <given-names>M.</given-names></string-name></person-group>, <source hwp:id="source-42">JMLR Workshop and Conference Proceedings: Chia Laguna Resort</source>, <publisher-loc>Sardinia, Italy</publisher-loc>, <year>2010</year>; Vol. <volume>9</volume>, pp <fpage>249</fpage>–<lpage>256</lpage>.</citation></ref><ref id="c43" hwp:id="ref-43" hwp:rev-id="xref-ref-43-1"><label>(43)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.43" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-43"><string-name name-style="western" hwp:sortable="Liu L."><surname>Liu</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jiang H."><surname>Jiang</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="He P."><surname>He</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chen W."><surname>Chen</surname>, <given-names>W.</given-names></string-name>, <etal>et al.</etal> <source hwp:id="source-43">On the Variance of the Adaptive Learning Rate and Beyond</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="http://arxiv.org/abs/1908.03265" ext-link-type="uri" xlink:href="http://arxiv.org/abs/1908.03265" hwp:id="ext-link-14">http://arxiv.org/abs/1908.03265</ext-link>.</citation></ref><ref id="c44" hwp:id="ref-44" hwp:rev-id="xref-ref-44-1"><label>(44)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.44" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-44"><string-name name-style="western" hwp:sortable="Jones A. R."><surname>Jones</surname>, <given-names>A. R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Eisenacher M."><surname>Eisenacher</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mayer G."><surname>Mayer</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kohlbacher O."><surname>Kohlbacher</surname>, <given-names>O.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-32">The mzIdentML Data Standard for Mass Spectrometry-Based Proteomics Results</article-title>. <source hwp:id="source-44">Molecular &amp; Cellular Proteomics</source> <year>2012</year>, <volume>11</volume>, M111.014381– M111.014381, DOI: <pub-id pub-id-type="doi">10.1074/mcp.M111.014381</pub-id>.</citation></ref><ref id="c45" hwp:id="ref-45" hwp:rev-id="xref-ref-45-1"><label>(45)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.45" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-45"><string-name name-style="western" hwp:sortable="Fondrie W. E."><surname>Fondrie</surname>, <given-names>W. E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bittremieux W."><surname>Bittremieux</surname>, <given-names>W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Noble W. S."><surname>Noble</surname>, <given-names>W. S.</given-names></string-name> <article-title hwp:id="article-title-33">ppx: Programmatic Access to Proteomics Data Repositories</article-title>. <source hwp:id="source-45">Journal of Proteome Research</source> <year>2021</year>, <volume>20</volume>, <fpage>4621</fpage>–<lpage>4624</lpage>, DOI: <pub-id pub-id-type="doi">10.1021/acs.jproteome.1c00454</pub-id>.</citation></ref><ref id="c46" hwp:id="ref-46" hwp:rev-id="xref-ref-46-1"><label>(46)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.46" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-46"><string-name name-style="western" hwp:sortable="Hulstaert N."><surname>Hulstaert</surname>, <given-names>N.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shofstahl J."><surname>Shofstahl</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sachsenberg T."><surname>Sachsenberg</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Walzer M."><surname>Walzer</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-34">ThermoRawFileParser: Modular, Scalable, and Cross-Platform RAW File Conversion</article-title>. <source hwp:id="source-46">Journal of Proteome Research</source> <year>2020</year>, <volume>19</volume>, <fpage>537</fpage>–<lpage>542</lpage>, DOI: <pub-id pub-id-type="doi">10.1021/acs.jproteome.9b00328</pub-id>.</citation></ref><ref id="c47" hwp:id="ref-47" hwp:rev-id="xref-ref-47-1"><label>(47)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.47" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-47"><string-name name-style="western" hwp:sortable="Perkins D. N."><surname>Perkins</surname>, <given-names>D. N.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pappin D. J. C."><surname>Pappin</surname>, <given-names>D. J. C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Creasy D. M."><surname>Creasy</surname>, <given-names>D. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cottrell J. S."><surname>Cottrell</surname>, <given-names>J. S.</given-names></string-name> <article-title hwp:id="article-title-35">Probability-Based Protein Identification by Searching Sequence Databases Using Mass Spectrometry Data</article-title>. <source hwp:id="source-47">Electrophoresis</source> <year>1999</year>, <volume>20</volume>, <fpage>3551</fpage>–<lpage>3567</lpage>, DOI: <pub-id pub-id-type="doi">10.1002/(SICI)1522-2683(19991201)20:18&lt;3551::AID-ELPS3551&gt;3.0.CO;2-2</pub-id>.</citation></ref><ref id="c48" hwp:id="ref-48" hwp:rev-id="xref-ref-48-1"><label>(48)</label><citation publication-type="book" citation-type="book" ref:id="483263v2.48" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-48"><string-name name-style="western" hwp:sortable="Rosenberg A."><surname>Rosenberg</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hirschberg J."><surname>Hirschberg</surname>, <given-names>J.</given-names></string-name> <source hwp:id="source-48">In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL) - CoNLL-EMNLP 2007</source>, <publisher-name>Association for Computational Linguistics</publisher-name>: <publisher-loc>Prague, Czech Republic</publisher-loc>, <year>2007</year>, pp <fpage>410</fpage>–<lpage>420</lpage>.</citation></ref><ref id="c49" hwp:id="ref-49" hwp:rev-id="xref-ref-49-1"><label>(49)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.49" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-49"><string-name name-style="western" hwp:sortable="Lam H."><surname>Lam</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Deutsch E. W."><surname>Deutsch</surname>, <given-names>E. W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Eddes J. S."><surname>Eddes</surname>, <given-names>J. S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Eng J. K."><surname>Eng</surname>, <given-names>J. K.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-36">Development and Validation of a Spectral Library Searching Method for Peptide Identification from MS/MS</article-title>. <source hwp:id="source-49">PROTEOMICS</source> <year>2007</year>, <volume>7</volume>, <fpage>655</fpage>–<lpage>667</lpage>, DOI: <pub-id pub-id-type="doi">10.1002/pmic.200600625</pub-id>.</citation></ref><ref id="c50" hwp:id="ref-50" hwp:rev-id="xref-ref-50-1"><label>(50)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.50" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-50"><string-name name-style="western" hwp:sortable="Deutsch E. W."><surname>Deutsch</surname>, <given-names>E. W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mendoza L."><surname>Mendoza</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shteynberg D."><surname>Shteynberg</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Farrah T."><surname>Farrah</surname>, <given-names>T.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-37">A Guided Tour of the Trans-Proteomic Pipeline</article-title>. <source hwp:id="source-50">PROTEOMICS</source> <year>2010</year>, <volume>10</volume>, <fpage>1150</fpage>–<lpage>1159</lpage>, DOI: <pub-id pub-id-type="doi">10.1002/pmic.200900375</pub-id>.</citation></ref><ref id="c51" hwp:id="ref-51" hwp:rev-id="xref-ref-51-1"><label>(51)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.51" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-51"><string-name name-style="western" hwp:sortable="Lam H."><surname>Lam</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Deutsch E. W."><surname>Deutsch</surname>, <given-names>E. W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Aebersold R."><surname>Aebersold</surname>, <given-names>R.</given-names></string-name> <article-title hwp:id="article-title-38">Artificial Decoy Spectral Libraries for False Discovery Rate Estimation in Spectral Library Searching in Proteomics</article-title>. <source hwp:id="source-51">Journal of Proteome Research</source> <year>2010</year>, <volume>9</volume>, <fpage>605</fpage>–<lpage>610</lpage>, DOI: <pub-id pub-id-type="doi">10.1021/pr900947u</pub-id>.</citation></ref><ref id="c52" hwp:id="ref-52" hwp:rev-id="xref-ref-52-1"><label>(52)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.52" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-52"><string-name name-style="western" hwp:sortable="Fu Y."><surname>Fu</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Qian X."><surname>Qian</surname>, <given-names>X.</given-names></string-name> <article-title hwp:id="article-title-39">Transferred Subgroup False Discovery Rate for Rare Post-Translational Modifications Detected by Mass Spectrometry</article-title>. <source hwp:id="source-52">Molecular &amp; Cellular Proteomics</source> <year>2014</year>, <volume>13</volume>, <fpage>1359</fpage>–<lpage>1368</lpage>, DOI: <pub-id pub-id-type="doi">10.1074/mcp.O113.030189</pub-id>.</citation></ref><ref id="c53" hwp:id="ref-53" hwp:rev-id="xref-ref-53-1"><label>(53)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.53" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-53"><string-name name-style="western" hwp:sortable="Levitsky L. I."><surname>Levitsky</surname>, <given-names>L. I.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Klein J. A."><surname>Klein</surname>, <given-names>J. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ivanov M. V."><surname>Ivanov</surname>, <given-names>M. V.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gorshkov M."><surname>Gorshkov</surname>, <given-names>M.</given-names></string-name> <article-title hwp:id="article-title-40">Pyteomics 4.0: Five Years of Development of a Python Proteomics Framework</article-title>. <source hwp:id="source-53">Journal of Proteome Research</source> <year>2019</year>, <volume>18</volume>, <fpage>709</fpage>–<lpage>714</lpage>, DOI: <pub-id pub-id-type="doi">10.1021/acs.jproteome.8b00717</pub-id>.</citation></ref><ref id="c54" hwp:id="ref-54" hwp:rev-id="xref-ref-54-1"><label>(54)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.54" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-54"><string-name name-style="western" hwp:sortable="Bittremieux W."><surname>Bittremieux</surname>, <given-names>W.</given-names></string-name> <article-title hwp:id="article-title-41">spectrum_utils: A Python Package for Mass Spectrometry Data Processing and Visualization</article-title>. <source hwp:id="source-54">Analytical Chemistry</source> <year>2020</year>, <volume>92</volume>, <fpage>659</fpage>–<lpage>661</lpage>, DOI: <pub-id pub-id-type="doi">10.1021/acs.analchem.9b04884</pub-id>.</citation></ref><ref id="c55" hwp:id="ref-55" hwp:rev-id="xref-ref-55-1"><label>(55)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.55" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-55"><string-name name-style="western" hwp:sortable="Abadi Martín"><given-names>Martín</given-names> <surname>Abadi</surname></string-name>, <string-name name-style="western" hwp:sortable="Agarwal Ashish"><given-names>Ashish</given-names> <surname>Agarwal</surname></string-name>, <string-name name-style="western" hwp:sortable="Barham Paul"><given-names>Paul</given-names> <surname>Barham</surname></string-name>, <string-name name-style="western" hwp:sortable="Brevdo Eugene"><given-names>Eugene</given-names> <surname>Brevdo</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-42">TensorFlow: Large-Scale Machine Learning on Heterogeneous Systems</article-title>, <source hwp:id="source-55">Software</source> available from <ext-link l:rel="related" l:ref-type="uri" l:ref="http://tensorflow.org" ext-link-type="uri" xlink:href="http://tensorflow.org" hwp:id="ext-link-15">tensorflow.org</ext-link>, <year>2015</year>.</citation></ref><ref id="c56" hwp:id="ref-56" hwp:rev-id="xref-ref-56-1"><label>(56)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.56" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-56"><string-name name-style="western" hwp:sortable="Pedregosa F."><surname>Pedregosa</surname>, <given-names>F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Varoquaux G."><surname>Varoquaux</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gramfort A."><surname>Gramfort</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Michel V."><surname>Michel</surname>, <given-names>V.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-43">Scikit-Learn: Machine Learning in Python</article-title>. <source hwp:id="source-56">Journal of Machine Learning Research</source> <year>2011</year>, <volume>12</volume>, <fpage>2825</fpage>–<lpage>2830</lpage>.</citation></ref><ref id="c57" hwp:id="ref-57" hwp:rev-id="xref-ref-57-1"><label>(57)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.57" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-57"><string-name name-style="western" hwp:sortable="Müllner D."><surname>Müllner</surname>, <given-names>D.</given-names></string-name> <article-title hwp:id="article-title-44">Fastcluster: Fast Hierarchical, Agglomerative Clustering Routines for R and Python</article-title>. <source hwp:id="source-57">Journal of Statistical Software</source> <year>2013</year>, <volume>53</volume>, DOI: <pub-id pub-id-type="doi">10.18637/jss.v053.i09</pub-id>.</citation></ref><ref id="c58" hwp:id="ref-58" hwp:rev-id="xref-ref-58-1"><label>(58)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.58" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-58"><string-name name-style="western" hwp:sortable="Harris C. R."><surname>Harris</surname>, <given-names>C. R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Millman K. J."><surname>Millman</surname>, <given-names>K. J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="van der Walt S. J."><surname>van der Walt</surname>, <given-names>S. J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gommers R."><surname>Gommers</surname>, <given-names>R.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-45">Array Programming with NumPy</article-title>. <source hwp:id="source-58">Nature</source> <year>2020</year>, <volume>585</volume>, <fpage>357</fpage>–<lpage>362</lpage>, DOI: <pub-id pub-id-type="doi">10.1038/s41586-020-2649-2</pub-id>.</citation></ref><ref id="c59" hwp:id="ref-59" hwp:rev-id="xref-ref-59-1"><label>(59)</label><citation publication-type="other" citation-type="journal" ref:id="483263v2.59" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-59"><collab hwp:id="collab-1">SciPy 1.0 Contributors</collab>, <string-name name-style="western" hwp:sortable="Virtanen P."><surname>Virtanen</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gommers R."><surname>Gommers</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Oliphant T. E."><surname>Oliphant</surname>, <given-names>T. E.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-46">SciPy 1.0: Fundamental Algorithms for Scientific Computing in Python</article-title>. <source hwp:id="source-59">Nature Methods</source> <year>2020</year>, DOI: <pub-id pub-id-type="doi">10.1038/s41592-019-0686-2</pub-id>.</citation></ref><ref id="c60" hwp:id="ref-60" hwp:rev-id="xref-ref-60-1"><label>(60)</label><citation publication-type="book" citation-type="book" ref:id="483263v2.60" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-60"><string-name name-style="western" hwp:sortable="Lam S. K."><surname>Lam</surname>, <given-names>S. K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pitrou A."><surname>Pitrou</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Seibert S."><surname>Seibert</surname>, <given-names>S.</given-names></string-name> <source hwp:id="source-60">In Proceedings of the Second Workshop on the LLVM Compiler Infrastructure in HPC - LLVM ‘15</source>, <publisher-name>ACM Press</publisher-name>: <publisher-loc>Austin, TX, USA</publisher-loc>, <year>2015</year>, pp <fpage>1</fpage>–<lpage>6</lpage>, DOI: <pub-id pub-id-type="doi">10.1145/2833157.2833162</pub-id>.</citation></ref><ref id="c61" hwp:id="ref-61" hwp:rev-id="xref-ref-61-1"><label>(61)</label><citation publication-type="book" citation-type="book" ref:id="483263v2.61" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-61"><string-name name-style="western" hwp:sortable="McKinney W."><surname>McKinney</surname>, <given-names>W.</given-names></string-name> <source hwp:id="source-61">In Proceedings of the 9th Python in Science Conference</source>, ed. by <person-group person-group-type="editor" hwp:id="person-group-4"><string-name name-style="western" hwp:sortable="rfvan der Walt S."><surname>rfvan der Walt</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Millman J."><surname>Millman</surname>, <given-names>J.</given-names></string-name></person-group>, <publisher-name>Austin</publisher-name>, <publisher-loc>Texas, USA</publisher-loc>, <year>2010</year>, pp <fpage>51</fpage>–<lpage>56</lpage>.</citation></ref><ref id="c62" hwp:id="ref-62" hwp:rev-id="xref-ref-62-1"><label>(62)</label><citation publication-type="book" citation-type="book" ref:id="483263v2.62" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-62"><string-name name-style="western" hwp:sortable="Thomas K."><surname>Thomas</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Benjamin R.-K."><surname>Benjamin</surname>, <given-names>R.-K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fernando P."><surname>Fernando</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Brian G."><surname>Brian</surname>, <given-names>G.</given-names></string-name>, <etal>et al.</etal> <chapter-title>In Positioning and Power in Academic Publishing: Players</chapter-title>, <source hwp:id="source-62">Agents and Agendas</source>; <publisher-name>IOS Press</publisher-name>: <year>2016</year>, pp <fpage>87</fpage>–<lpage>90</lpage>.</citation></ref><ref id="c63" hwp:id="ref-63" hwp:rev-id="xref-ref-63-1"><label>(63)</label><citation publication-type="journal" citation-type="journal" ref:id="483263v2.63" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-63"><string-name name-style="western" hwp:sortable="Hunter J. D."><surname>Hunter</surname>, <given-names>J. D.</given-names></string-name> <article-title hwp:id="article-title-47">Matplotlib: A 2D Graphics Environment</article-title>. <source hwp:id="source-63">Computing in Science &amp; Engineering</source> <year>2007</year>, <volume>9</volume>, <fpage>90</fpage>–<lpage>95</lpage>, DOI: <pub-id pub-id-type="doi">10.1109/MCSE.2007.55</pub-id>.</citation></ref><ref id="c64" hwp:id="ref-64" hwp:rev-id="xref-ref-64-1"><label>(64)</label><citation publication-type="website" citation-type="web" ref:id="483263v2.64" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-64"><string-name name-style="western" hwp:sortable="Waskom M."><surname>Waskom</surname>, <given-names>M.</given-names></string-name>, <source hwp:id="source-64">the seaborn development team mwaskom/seaborn</source>, <ext-link l:rel="related" l:ref-type="uri" l:ref="https://doi.org/10.5281/zenodo.592845" ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.592845" hwp:id="ext-link-16">https://doi.org/10.5281/zenodo.592845</ext-link>, version latest, <year>2020</year>, DOI: <pub-id pub-id-type="doi">10.5281/zenodo.592845</pub-id>.</citation></ref></ref-list></back></article>
