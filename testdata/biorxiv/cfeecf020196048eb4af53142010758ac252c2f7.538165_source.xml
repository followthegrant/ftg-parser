<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/538165</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;538165</article-id><article-id pub-id-type="other" hwp:sub-type="slug">538165</article-id><article-id pub-id-type="other" hwp:sub-type="atom-slug">538165</article-id><article-id pub-id-type="other" hwp:sub-type="tag">538165</article-id><article-version>1.2</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Plant Biology" hwp:journal="biorxiv"><subject>Plant Biology</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">A Stomata Classification and Detection System in Microscope Images of Maize Cultivars</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1"><label>*</label>Corresponding author: Tel.: +55 (12) 3309-9500; fax: +55 (12) 3921-8857; <italic toggle="yes">Email address</italic>: <email hwp:id="email-1">ffaria@unifesp.br</email> (Fabio Augusto Faria)</corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-4871-6625</contrib-id><name name-style="western" hwp:sortable="Aono Alexandre Hild"><surname>Aono</surname><given-names>Alexandre Hild</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">a</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-4871-6625"/></contrib><contrib contrib-type="author" hwp:id="contrib-2"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-7655-7206</contrib-id><name name-style="western" hwp:sortable="Nagai James Shiniti"><surname>Nagai</surname><given-names>James Shiniti</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">a</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-7655-7206"/></contrib><contrib contrib-type="author" hwp:id="contrib-3"><name name-style="western" hwp:sortable="Mendonça Dickel Gabriella da Silva"><surname>Mendonça Dickel</surname><given-names>Gabriella da Silva</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">b</xref></contrib><contrib contrib-type="author" hwp:id="contrib-4"><name name-style="western" hwp:sortable="Marinho Rafaela Cabral"><surname>Marinho</surname><given-names>Rafaela Cabral</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-2" hwp:rel-id="aff-2">b</xref></contrib><contrib contrib-type="author" hwp:id="contrib-5"><name name-style="western" hwp:sortable="Macedo de Oliveira Paulo Eugênio Alves"><surname>Macedo de Oliveira</surname><given-names>Paulo Eugênio Alves</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-3" hwp:rel-id="aff-2">b</xref></contrib><contrib contrib-type="author" hwp:id="contrib-6"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6494-7514</contrib-id><name name-style="western" hwp:sortable="Papa João Paulo"><surname>Papa</surname><given-names>João Paulo</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-1" hwp:rel-id="aff-3">c</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-6494-7514"/></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-7"><name name-style="western" hwp:sortable="Faria Fabio Augusto"><surname>Faria</surname><given-names>Fabio Augusto</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-3" hwp:rel-id="aff-1">a</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*</xref></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2 xref-aff-1-3"><label>a</label><institution hwp:id="institution-1">Instituto de Ciência e Tecnologia, Universidade Federal de São Paulo – UNIFESP</institution>, 12247-014, São José dos Campos, SP – <country>Brazil</country></aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1 xref-aff-2-2 xref-aff-2-3"><label>b</label><institution hwp:id="institution-2">Instituto de Biologia, Universidade Federal de Uberlândia</institution>, Uberlândia, MG, <country>Brazil</country></aff><aff id="a3" hwp:id="aff-3" hwp:rev-id="xref-aff-3-1"><label>c</label><institution hwp:id="institution-3">Sao Paulo State University</institution>, Bauru, SP, <country>Brazil</country></aff></contrib-group><pub-date pub-type="epub-original" date-type="pub" publication-format="electronic" hwp:start="2021"><year>2021</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2019-02-01T19:21:11-08:00">
    <day>1</day><month>2</month><year>2019</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2021-01-16T13:21:13-08:00">
    <day>16</day><month>1</month><year>2021</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2019-02-01T19:27:10-08:00">
    <day>1</day><month>2</month><year>2019</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2021-01-16T13:24:14-08:00">
    <day>16</day><month>1</month><year>2021</year>
  </pub-date><elocation-id>538165</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2019-02-01"><day>01</day><month>2</month><year>2019</year></date>
<date date-type="rev-recd" hwp:start="2021-01-16"><day>16</day><month>1</month><year>2021</year></date>
<date date-type="accepted" hwp:start="2021-01-16"><day>16</day><month>1</month><year>2021</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2021</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="license-1"><p hwp:id="p-1">This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by-nc-nd/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></p></license></permissions><self-uri xlink:href="538165.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/change-list" xlink:role="change-list" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2021/pdf/538165v2.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="538165.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2021/abstracts/538165v2/538165v2.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2021/fulltext/538165v2/538165v2.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-2">Research on stomata, i.e., morphological structures of plants, has increased in popularity in the last years. These structures (pores) are in charge of the interaction between the internal plant system and the environment, working on different processes such as photosynthesis and transpiration stream. Besides, a better understanding of the pore mechanism plays a significant role when exploring the evolution process, as well as the behavior of plants. Although the study of stomata in dicots species of plants has advanced considerably in the past years, there is little information about stomata of cereal grasses. Also, automated detection of these structures have been considered in the literature, but some gaps are still uncovered. This fact is motivated by high morphological variation of stomata and the presence of noise from the image acquisition step. In this work, we propose a new methodology for automatic stomata classification and a new detection system in microscope images for maize cultivars. We have achieved an approximated accuracy of 97.1% in the identification of stomata regions using classifiers based on deep learning features, which figures out as a nearly perfect classification system.</p></abstract><kwd-group kwd-group-type="author" hwp:id="kwd-group-1"><title hwp:id="title-2">Keywords</title><kwd hwp:id="kwd-1">deep learning</kwd><kwd hwp:id="kwd-2">image classification</kwd><kwd hwp:id="kwd-3">pattern recognition</kwd></kwd-group><counts><page-count count="15"/></counts><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-1">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta><notes hwp:id="notes-1"><notes notes-type="competing-interest-statement" hwp:id="notes-2"><title hwp:id="title-3">Competing Interest Statement</title><p hwp:id="p-3">The authors have declared no competing interest.</p></notes><fn-group content-type="summary-of-updates" hwp:id="fn-group-1"><title hwp:id="title-4">Summary of Updates:</title><fn fn-type="update" hwp:id="fn-1"><p hwp:id="p-4">Content modifications.</p></fn></fn-group></notes></front><body><sec id="s1" hwp:id="sec-1"><label>1.</label><title hwp:id="title-5">Introduction</title><p hwp:id="p-5">Stomata have probably received more attention than any other single vegetative structure in plants [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">1</xref>]. Regulating gas exchange between the plant and the environment[<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">2</xref>], these structures stand for small pores on the surfaces of leaves, stems and parts of angiosperm flowers and fruits [<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">3</xref>, <xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">4</xref>], and they are formed by a pair of specialized epidermal cells (guarder cells) that are located in the surface of aerial parts of most higher plants [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-2" hwp:rel-id="ref-1">1</xref>]. Due to the controlling of the exchange of water vapor and CO<sup>2</sup> between the interior of the leaf and the atmosphere [<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-2" hwp:rel-id="ref-3">3</xref>], the photosynthesis, transpiration stream, nutrition and the metabolism of land plants are in different ways related to the opening and closing movements of the stomata [<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-2" hwp:rel-id="ref-4">4</xref>, <xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-3" hwp:rel-id="ref-1">1</xref>]. Furthermore, Hetherington and Woodward [<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-3" hwp:rel-id="ref-3">3</xref>] pointed out that the acquisition of stomata and an impervious leaf cuticle are considered the key elements in the evolution of advanced terrestrial plants, allowing the plant to inhabit a range of different, often fluctuating, environments but still control water content.</p><p hwp:id="p-6">The stomatal movements distinguish such structures from other pores found in plant organs, e.g., pneumathodes, hydathodes, lenticels, and the breathing pores found in the thalli of liverworts [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-4" hwp:rel-id="ref-1">1</xref>]. The control of stomatal aperture requires the coordinated control of multiple cellular processes [<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-4" hwp:rel-id="ref-3">3</xref>] and its morphogenesis is affected by several environmental stimuli, such as relative humidity, temperature, the concentration of atmospheric carbon dioxide, light intensity, and endogenous plant hormones [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-2" hwp:rel-id="ref-2">2</xref>, <xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-5" hwp:rel-id="ref-3">3</xref>, <xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-5" hwp:rel-id="ref-1">1</xref>]. Global warming, for example, could increase leaf transpiration and soil evaporation, and as consequence leaf stomata movements can control plant water loss and carbon gain under this water stress condition [<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">5</xref>]. Stomatal aperture might also represent an initial response to both plants and human pathogenic bacteria [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-3" hwp:rel-id="ref-2">2</xref>]. In plants, it has been reported that microscopic surface openings serve as passive ports of bacterial entry during infection and the stomatal closure is part of a plant innate immune response to restrict bacterial invasion [<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">6</xref>].</p><p hwp:id="p-7">The number of pores per unit area varies not only between species but also within species because of the influence of environmental factors during growth, leaf morphology and genetic composition [<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-3" hwp:rel-id="ref-4">4</xref>, <xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-6" hwp:rel-id="ref-1">1</xref>]. In general, it happens due to the influence on cell size [<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-4" hwp:rel-id="ref-4">4</xref>], e.g., smaller guarder cells are usually associated with higher stomatal frequencies [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-7" hwp:rel-id="ref-1">1</xref>]. Besides stomata differentiation is a process that occurs together with the development of plant organs and, therefore, counts of stomata per unit area carried out at different stages in leaf development will differ [<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-5" hwp:rel-id="ref-4">4</xref>]. Another characteristic with great variation concerns the spacing of stomata, which may be relatively evenly spaced throughout a leaf, located in regular rows along the length of a leaf, or they may be clustered in patches [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-8" hwp:rel-id="ref-1">1</xref>].</p><p hwp:id="p-8">Since the types of stomatal configuration are profoundly different, the study and identification of these pores are vital points to understand several mechanisms of plants. Haworth et al. [<xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">7</xref>] also stated that it might be reasonable to assume that stomatal structures have played a significant role in plant evolution over the last 400 million years. Nevertheless, the examination of stomata from microscope images involves manual measurement and is highly dependent on biologists with expert knowledge to correctly identify and measure stomatal morphology [<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">8</xref>].</p><p hwp:id="p-9">Even with the apparent relevance of these structures, a recent study [<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">9</xref>]indicated that, surprisingly, we still know little about stomata of cereal grasses. These grasses are extremely important since they provide the majority of calories consumed by humans either directly through the consumption of grains or indirectly through animals fed a diet of grains and forage[<xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">10</xref>]. Hepworth et al. [<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-2" hwp:rel-id="ref-9">9</xref>] highlighted that the stomatal complexes in grasses differ of the dicots in many ways, e.g., the guard cells of dicots are kidney-shaped and form stomata that are scattered throughout the epidermis in a less orderly pattern, while stomatal configuration of grasses develop in parallel rows within defined and specific epidermal cell files [<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-3" hwp:rel-id="ref-9">9</xref>].</p><p hwp:id="p-10">In this scenario, in order to assist the biological community to perform stomata studies, we proposed an automated strategy for stomata detection and classification in microscope images using machine learning techniques. Our work is seminal in a sense it is less time-consuming when examining stomatal behavior, thus enabling biologists to use more information from the images and study a broader range of stomata. In this work, we employed microscope images of maize, which represent the most produced and consumed cultivars in the world. As far as we are concerned, we have not observed any similar work concerning maize cultivars.</p><p hwp:id="p-11">The remainder of this work is organized as follows. Section 2 and 3 present the related works and the proposed approach, respectively. Section 4 discusses the methodology, while Section 4 presents the experiments. Finally, Section 6 states conclusions and future works.</p></sec><sec id="s2" hwp:id="sec-2"><label>2.</label><title hwp:id="title-6">Related Works</title><p hwp:id="p-12">The research of stomata image processing started in the 80’s. Recognized as possible pioneers, Omasa and Onoe [<xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">11</xref>] proposed a technique for measuring stomata characteristics in grayscale images using Fourier Transform and threshold filters for image processing and segmenting [<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-2" hwp:rel-id="ref-8">8</xref>]. More recently, Sanyal et al. [<xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">12</xref>] compared tomato cultivars using several morphological characteristics, including stomata measures. Microscope images of different varieties were obtained using a scanning electron microscope, and the segmentation was performed using a watershed algorithm resulting in one stomata per image, followed by morphological operations (e.g., erosion and dilation) and Sobel kernel filters to remove noise and obtain stomatal boundaries. Using 100 images of tomato cultivars and a multilayer perceptron algorithm, the proposed approach achieved 96.6% of accuracy.</p><p hwp:id="p-13">Jian et al. [<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">13</xref>] aimed at estimating stomata density using three different regions of <italic toggle="yes">Populus Euphratica</italic> leaves. For image processing purposes, an object-oriented classification method was used with parameters such as scale, compactness, and shape. Such an approach presented high accuracy when compared to human-based count, showing advantages over the traditional method to extract the stoma information. Aiming the constant growth and development of stomata image processing studies, Higaki et al. [<xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">14</xref>] published the “Live Images of Plant Stomata LIPS” database. In other work, Higaki and Takumi [<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">15</xref>] presented a semi-automatic stomata region detection approach using ImageJ software [<xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">16</xref>] and a Clustering-Aided Rapid Training Agent-based algorithm [<xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">17</xref>].</p><p hwp:id="p-14">Oliveira et al. [<xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">18</xref>] proposed an approach solely based on morphological operations. Initially, a Gaussian low-pass filter was employed to preprocess the images and remove noise. Further, reconstruction operations (e.g., opening and closing) were applied to highlight stomata regions, which were counted based on background intensity differences. As a result, the work reported recognition rates of around 94.3%.</p><p hwp:id="p-15">Laga et al. [<xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">19</xref>] introduced a supervised method for stomata detection based on morphological and structural features. To fulfill such purpose, 24 microscope images were obtained and filtered by normalization together with a Gaussian filter. The images were manually segmented and the width and height parameters extracted. The authors reported results close to a manual counting approach. Later on, a patent for stomata measurement using Gaussian filtering and morphological operations was registered by Awwad et al. [<xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">20</xref>].</p><p hwp:id="p-16">Duarte et. al.[<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">21</xref>] proposed a method to count stomata in microscope images automatically. Initially, the images were converted from RGB to CieLAB to select the best channel for analysis. Wavelet Spot Detection and morphological operations performed the stomata detection step, with results nearly to 90.6% of recognition accuracy.</p><p hwp:id="p-17">Jayakody et al. [<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-3" hwp:rel-id="ref-8">8</xref>] proposed an automated stomata detection and pore measurement system for grapevines. The approach employed a Cascade Object Detection (COD) algorithm with two main steps: (i) first, the COD classifiers are trained using stoma and non-stoma images, and then (ii) a sliding window over the microscope images was used to identify stomata inside it. After its detection, the pore measurement step was performed using binary segmentation and skeletonization with ellipse fitting, for further estimating pore measurements. The authors reported 91.6% of recognition rate.</p></sec><sec id="s3" hwp:id="sec-3"><label>3.</label><title hwp:id="title-7">Proposed System</title><p hwp:id="p-18">This section introduces the approach for stomata classification and detection employed in the work.</p><sec id="s3a" hwp:id="sec-4"><label>3.1.</label><title hwp:id="title-8">Overview</title><p hwp:id="p-19">The proposed approach is composed of two different process: (i) stomata detection and further (ii) classification. <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1</xref> depicts an overview of the proposed approach.</p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1:</label><caption hwp:id="caption-1"><p hwp:id="p-20">An overview of the proposed stomata classification and detection system.</p></caption><graphic xlink:href="538165v2_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-21">In the stomata classification process, the first step is to manually collect and label a subset of stomata and non-stomata regions from the microscope images dataset, creating two disjoint sets of subimages, i.e., <italic toggle="yes">train</italic> and <italic toggle="yes">test</italic>. Such sets are subjected to an image descriptor that encodes the visual properties of the subimages into feature vectors (i.e., <italic toggle="yes">F</italic><sub><italic toggle="yes">train</italic></sub> and <italic toggle="yes">F</italic><sub><italic toggle="yes">test</italic></sub> for the <italic toggle="yes">train</italic> and <italic toggle="yes">test</italic> sets, respectively). Further, the feature vectors <italic toggle="yes">F</italic><sub><italic toggle="yes">train</italic></sub> are used as input for a learning method, thus creating a learned model for stomata classification purposes. Finally, each feature vector <italic toggle="yes">F</italic><sub><italic toggle="yes">test</italic></sub> is then classified by this learned model. In the classification process, different image descriptors and learning methods are evaluated through a <italic toggle="yes">k</italic>-fold cross-validation protocol, and the best model is adopted to detect stomata regions on the next step.</p><p hwp:id="p-22">Regarding the stomata detection process, a sliding window is used on each microscope image from the entire dataset to create a set of regions of interest (<italic toggle="yes">ROI</italic>), which are subjected to an image descriptor resulting in the feature vectors (<italic toggle="yes">F</italic><sub><italic toggle="yes">ROI</italic></sub>). Finally, each <italic toggle="yes">F</italic><sub><italic toggle="yes">ROI</italic></sub> is classified by the best model, i.e., a tuple (learning method + image descriptor) computed in the classification process.</p></sec><sec id="s3b" hwp:id="sec-5"><label>3.2.</label><title hwp:id="title-9">Stomata Classification Process</title><p hwp:id="p-23">The first step for identifying stomata structures is the manual selection of a set of subimages containing stomata or other plant structures, labeled as non-stomata. Due to the differences between stomata size in distinct microscope images, we adopted a region/window of dimension 151 × 258 pixels. We observed that such size is enough to include all stomata regions from the dataset images. Therefore, a total of 1, 000 subimages of each class (i.e., stomata and non-stomata) were selected to compose the new dataset.</p><p hwp:id="p-24">Once the dataset has been created, the next step is to extract visual properties from the subimages using image descriptors. In this work, we evaluated eleven different image descriptors, as described below:</p><sec id="s3b1" hwp:id="sec-6"><label>3.2.1.</label><title hwp:id="title-10">DAISY</title><p hwp:id="p-25">the descriptor relies on gradient orientation histograms. For an input image, orientation maps are calculated based on quantized directions using Gaussian kernels. The final descriptor concerns the values from these convolved maps located on concentric circles centered on a location. The amount of Gaussian smoothing is proportional to the radius of the circles [<xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">22</xref>].</p></sec><sec id="s3b2" hwp:id="sec-7"><label>3.2.2.</label><title hwp:id="title-11">Histogram of Oriented Gradients (HOG)</title><p hwp:id="p-26">feature descriptor based on the creation of histograms with gradient orientation using their magnitude in specific portions of an image [<xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">23</xref>]. The local shape information is described by the distribution of gradients in different orientations [<xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">24</xref>].</p></sec><sec id="s3b3" hwp:id="sec-8"><label>3.2.3.</label><title hwp:id="title-12">GIST</title><p hwp:id="p-27">the descriptor focuses on the shape of the scene itself, i.e., on the relationship between the outlines of the surfaces and their properties, ignoring the local objects in the scene and their relationships [<xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">25</xref>]. The approach does not require any form of segmentation and is based on a set of perceptual dimensions (naturalness, openness, roughness, expansion, ruggedness) [<xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-2" hwp:rel-id="ref-24">24</xref>].</p></sec><sec id="s3b4" hwp:id="sec-9"><label>3.2.4.</label><title hwp:id="title-13">Haralick Texture Features</title><p hwp:id="p-28">at first, a gray-level co-occurrence matrix is computed considering the relation of each voxel with its neighborhood. Using different statistical measures (e.g., entropy, energy, variance, and correlation), texture properties are encoded from the image into feature vectors [<xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">26</xref>].</p></sec><sec id="s3b5" hwp:id="sec-10"><label>3.2.5.</label><title hwp:id="title-14">Local Binary Patterns (LBP)</title><p hwp:id="p-29">it computes a local representation of texture based on the comparison of each pixel with its neighborhood. A threshold for such comparison is defined and an output image is produced with the binary to decimal values conversion. Further, a histogram is created as the final descriptor [<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-1" hwp:rel-id="ref-27">27</xref>].</p></sec><sec id="s3b6" hwp:id="sec-11"><label>3.2.6.</label><title hwp:id="title-15">Deep Convolutional Neural Network</title><p hwp:id="p-30">a typical convolutional network is a fully-connected network where each hidden activation is computed by multiplying the entire input by weights in a given layer [<xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">28</xref>]. In this technique, a connection between traditional optimization-based schemes and a neural network architecture is considered, where a separable structure is introduced as a reliable support for robust deconvolution against artifacts [<xref ref-type="bibr" rid="c29" hwp:id="xref-ref-29-1" hwp:rel-id="ref-29">29</xref>]. Once we do not have available a large scale of images to train a deep learning architecture from scratch, a good alternative is to use the transfer learning [<xref ref-type="bibr" rid="c30" hwp:id="xref-ref-30-1" hwp:rel-id="ref-30">30</xref>]. Usually, the networks are pre-trained over ImageNet dataset [<xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">31</xref>], for further adding other layers according to the target application. The last layer can be used for feature extraction purposes (image descriptor). In this work, we adopted six different architectures: (i) DenseNet121 [<xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">32</xref>], (ii) InceptionResNetV2 [<xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">33</xref>], (iii) InceptionV3 [<xref ref-type="bibr" rid="c34" hwp:id="xref-ref-34-1" hwp:rel-id="ref-34">34</xref>], (iv) ModbileNet [<xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-1" hwp:rel-id="ref-35">35</xref>], (v) NasNet [<xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">36</xref>], and (vi) VGG16 [<xref ref-type="bibr" rid="c37" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">37</xref>].</p><p hwp:id="p-31">Concerning the machine learning techniques, we used three different approaches: (i) Support Vector Machine [<xref ref-type="bibr" rid="c38" hwp:id="xref-ref-38-1" hwp:rel-id="ref-38">38</xref>] (SVM), (ii) Multilayer Perceptron [<xref ref-type="bibr" rid="c39" hwp:id="xref-ref-39-1" hwp:rel-id="ref-39">39</xref>] (MLP), and (iii) Adaboost [<xref ref-type="bibr" rid="c40" hwp:id="xref-ref-40-1" hwp:rel-id="ref-40">40</xref>]. The best tuple (i.e., learning method + image descriptor) will be then employed to label the new stomata regions on the next process. <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2</xref> shows the steps of the stomata classification process proposed in this work.</p><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2:</label><caption hwp:id="caption-2"><p hwp:id="p-32">In-depth explanation of the stomata classification process.</p></caption><graphic xlink:href="538165v2_fig2" position="float" orientation="portrait" hwp:id="graphic-2"/></fig></sec></sec><sec id="s3c" hwp:id="sec-12"><label>3.3.</label><title hwp:id="title-16">Stomata Detection Process</title><p hwp:id="p-33"><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Figure 4</xref> depicts the methodology for stomata detection, which is divided into the following steps:</p><sec id="s3c1" hwp:id="sec-13"><label>3.3.1.</label><title hwp:id="title-17">Dataset</title><p hwp:id="p-34">A dataset with stoma and non-stoma subimages (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure 3</xref>) was created through a manual selection task from microscope images.</p><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3:</label><caption hwp:id="caption-3"><p hwp:id="p-35">Examples of: (a) stoma and (b) non-stoma subimages/regions, which were manually selected and labeled in this work.</p></caption><graphic xlink:href="538165v2_fig3" position="float" orientation="portrait" hwp:id="graphic-3"/></fig><fig id="fig4" position="float" fig-type="figure" orientation="portrait" hwp:id="F4" hwp:rev-id="xref-fig-4-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4:</label><caption hwp:id="caption-4"><p hwp:id="p-36">In-depth explanation of the stomata identification process.</p></caption><graphic xlink:href="538165v2_fig4" position="float" orientation="portrait" hwp:id="graphic-4"/></fig></sec><sec id="s3c2" hwp:id="sec-14"><label>3.3.2.</label><title hwp:id="title-18">Feature extraction</title><p hwp:id="p-37">Once the best descriptor has been found on the stomata classification process, the features of the new dataset are generated and stored into a table with the labels of each category (stoma or non-stoma).</p></sec><sec id="s3c3" hwp:id="sec-15"><label>3.3.3.</label><title hwp:id="title-19">Creation of the learned model</title><p hwp:id="p-38">The descriptors were evaluated using three different learning methods: SVM, MLP, and Adaboost. Based on the best effective results achieved by each learned model (i.e., a tuple composed of a aescriptor + the learning method), the most appropriate learned model is then selected to label the subimage in next step.</p></sec><sec id="s3c4" hwp:id="sec-16"><label>3.3.4.</label><title hwp:id="title-20">Sliding window iteration</title><p hwp:id="p-39">Using a window of 151 × 258 pixels, an iteration over the microscope images is performed, and for each generated subimage, a label (stoma or non-stoma) is obtained using the best-learned model. Due to the possible separation of stoma structures, the windows were created with a stride of 100 pixels in both columns and rows.</p></sec><sec id="s3f5" hwp:id="sec-17"><label>3.3.5.</label><title hwp:id="title-21">Selection of positive regions</title><p hwp:id="p-40">Based on the previous classification, an auxiliary matrix is filled in order to enable the posterior identification of stoma regions. Pixels with a positive occurrence for stoma are separated from the rest of the image, for the further analyzes of such regions.</p></sec></sec></sec><sec id="s4" hwp:id="sec-18"><label>4.</label><title hwp:id="title-22">Experimental Setup</title><p hwp:id="p-41">This section describes the dataset design, the technologies, and evaluation protocol used in this work.</p><sec id="s4a" hwp:id="sec-19"><label>4.1.</label><title hwp:id="title-23">Image Dataset</title><p hwp:id="p-42">Regarding optical microscope investigation, it has been necessary to separate the epidermis from the remainder of the leaf itself to get a clear view of the cell walls and the shape of the stomata [<xref ref-type="bibr" rid="c41" hwp:id="xref-ref-41-1" hwp:rel-id="ref-41">41</xref>]. Herein cyanoacrylate glue was applied to the microscope slide in order to obtain an impression of the sheet surface to be captured using a camera attached to a microscope. Leaves were sampled from 20 <italic toggle="yes">Zea mays</italic> cultivars (maize) granted by Nidera Sementes company (Uberlândia-MG), producing a total of 200 microscope images with different dimensions such as 2, 565 × 3, 583, 2, 675 × 3, 737, and 2, 748 × 3, 840.</p><p hwp:id="p-43">The selected species then were treated with colchicine [<xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-1" hwp:rel-id="ref-42">42</xref>] to change their ploidy and cell morphology for further studies. Due to the plant ploidy specificity, different images might have different stomata sizes and width. Besides, as previously mentioned, stomata differentiation is a process that occurs together with the development of plant organs, and herein plants with different ages were used, and a clear distinction of the images and plant morphologies can be visualized in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Figure 5</xref>. In these microscope images, different types of noise and artifacts can be observed as well, as depicted in <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Figure 6</xref>, thus highlighting the challenges faced in this work.</p><fig id="fig5" position="float" fig-type="figure" orientation="portrait" hwp:id="F5" hwp:rev-id="xref-fig-5-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/FIG5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">fig5</object-id><label>Figure 5:</label><caption hwp:id="caption-5"><p hwp:id="p-44">Samples from the microscope images of Maize Cultivars used in this work.</p></caption><graphic xlink:href="538165v2_fig5" position="float" orientation="portrait" hwp:id="graphic-5"/></fig><fig id="fig6" position="float" fig-type="figure" orientation="portrait" hwp:id="F6" hwp:rev-id="xref-fig-6-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/FIG6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">fig6</object-id><label>Figure 6:</label><caption hwp:id="caption-6"><p hwp:id="p-45">Different types of noise present in the microscopic images: (a) the usage of cyanoacrylate glue can generate air bubbles; (b) the microscope might capture leaves residuals; (c) the leaves might bend and create grooves in the image; (d) degraded stomata due to biological factors; and (e) low image quality due to equipment limitations.</p></caption><graphic xlink:href="538165v2_fig6" position="float" orientation="portrait" hwp:id="graphic-6"/></fig><p hwp:id="p-46">In the experiments, the dataset with 200 microscope images was submitted to the 5-fold cross-validation protocol, i.e., four parts of the dataset compose the training set (160 images), and one part belongs to the test set (40 images). This process is repeated five times. Therefore, in the <italic toggle="yes">stomata classification task</italic>, for each microscope image, 5 stoma and 5 non-stoma regions/sub-images have been manually select to compose training and test sets in an overall of 2, 000 sub-images.</p><p hwp:id="p-47">Concerning the <italic toggle="yes">stomata detection task</italic>, respecting the separation of the disjoint sets of the 5-fold cross-validation protocol, each training set created in the stomata classification task is maintained with 1, 600 sub-images. However, the test sets are generated by a sliding window operation. Hence, for each one of the 40 test images, between 876 and 963 regions/sub-images were selected by a sliding window iteration, resulting in approximately 44, 000 sub-images per test set, in an overall of 217, 866 sub-images for the five runs.</p></sec><sec id="s4b" hwp:id="sec-20"><label>4.2.</label><title hwp:id="title-24">Programming Environment and Libraries</title><p hwp:id="p-48">All approaches considered in this paper were executed on a personal computer with 2.7GHz Intel Core i7-7500U 2.7GHz Intel Core i7-7500U with 16GB of RAM and NVIDIA GeForce 940MX 4GB graphic card. Similarly, the programming language used in this work was Python2 with the following libraries: scikit-learn [<xref ref-type="bibr" rid="c43" hwp:id="xref-ref-43-1" hwp:rel-id="ref-43">43</xref>], pyleargist, scikit-image[<xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-1" hwp:rel-id="ref-44">44</xref>], opencv [<xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-1" hwp:rel-id="ref-45">45</xref>], keras[<xref ref-type="bibr" rid="c46" hwp:id="xref-ref-46-1" hwp:rel-id="ref-46">46</xref>] and tensorflow[<xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-1" hwp:rel-id="ref-47">47</xref>]. A considerable part of the libraries was mostly used for feature extraction and deep learning methods purposes.</p></sec><sec id="s4c" hwp:id="sec-21"><label>4.3.</label><title hwp:id="title-25">Evaluation Protocol</title><p hwp:id="p-49">To assess the accuracy of the proposed approach for classifying and identifying stomata regions, we employed a <italic toggle="yes">k</italic>-fold cross-validation with <italic toggle="yes">k</italic> = 5. The classified images represent the test set and the sub-images used to create the learned model were extracted from the training set. A manual count was also performed for each image to evaluate the final results using all windows generated, including the overlapped regions.</p></sec></sec><sec id="s5" hwp:id="sec-22"><label>5.</label><title hwp:id="title-26">Results and Discussion</title><p hwp:id="p-50">This section discusses the experiments performed to validate the proposed approach.</p><sec id="s5a" hwp:id="sec-23"><label>5.1.</label><title hwp:id="title-27">Stomata Classification Task</title><p hwp:id="p-51">In this first experiment, we performed a comparative analysis among five image descriptors (HOG, GIST, DAISY, LBP, and Haralick) and three learning methods (Adaboost, MLP, and SVM) for the stomata classification task. The effectiveness is measured in terms of the mean accuracy considering the 5-fold cross-validation protocol.</p><p hwp:id="p-52">As one can observe in <xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-1" hwp:rel-id="T1">Table 1</xref>, the best results were achieved by descriptors purely based on gradient information (HOG and DAISY)<sup><xref ref-type="fn" rid="fn1" hwp:id="xref-fn-2-1" hwp:rel-id="fn-2">1</xref></sup>. HOG descriptor with MLP (HOG+MLP) and DAISY descriptor with Adaboost (DAISY+Adaboost) achieved 96.0% of mean accuracy. In a comprehensive comparison among all image descriptors, HOG descriptor was the most effective with a mean accuracy of 94.7%, which can be justified by the specific shape of the stoma when compared to other parts. Therefore, this fact can show us that shape is perhaps the most essential visual property for the target application. Although GIST is a shape descriptor, its way of dealing with visual properties globally (holistic) may explain its poor performance in such images.</p><table-wrap id="tbl1" orientation="portrait" position="float" hwp:id="T1" hwp:rev-id="xref-table-wrap-1-1 xref-table-wrap-1-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/TBL1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">tbl1</object-id><label>Table 1:</label><caption hwp:id="caption-7"><p hwp:id="p-53">Mean Accuracy of the classifiers based on image descriptor features for the stomata classification task.</p></caption><graphic xlink:href="538165v2_tbl1" position="float" orientation="portrait" hwp:id="graphic-7"/></table-wrap><p hwp:id="p-54">Since deep learning techniques are on the spotlight due to their outstanding results in a number of applications, we also considered them in this work. <xref rid="tbl2" ref-type="table" hwp:id="xref-table-wrap-2-1" hwp:rel-id="T2">Table 2</xref> presents the effectiveness results of six different deep learning architectures (DenseNet121 – DenseNet, Inception-ResNetV2 – IResNet, InceptionV3 – Inception, MobileNet, NasNet, and VGG16) using three learning methods (Adaboost, MLP, and SVM) concerning the stomata classification task.</p><table-wrap id="tbl2" orientation="portrait" position="float" hwp:id="T2" hwp:rev-id="xref-table-wrap-2-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/TBL2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T2</object-id><object-id pub-id-type="publisher-id">tbl2</object-id><label>Table 2:</label><caption hwp:id="caption-8"><p hwp:id="p-55">Mean Accuracy of the experiments based on deep learning features for the stomata classification task.</p></caption><graphic xlink:href="538165v2_tbl2" position="float" orientation="portrait" hwp:id="graphic-8"/></table-wrap><p hwp:id="p-56">As one can observe, information based on deep learning features outperformed the handcrafted ones (<xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-2" hwp:rel-id="T1">Table 1</xref>), except for HOG descriptor. In this experiment, the classifiers using VGG16 features achieved the best results with 100% of mean accuracy for almost all three learning techniques considered in this work for the stomata classification task.</p></sec><sec id="s5b" hwp:id="sec-24"><label>5.2.</label><title hwp:id="title-28">Stomata Detection Task</title><p hwp:id="p-57">In this experiment, the classifier based on VGG16 features with Support Vector Machines (SVM+VGG16) was adopted for the stomata detection task since it obtained the best results in the stomata classification task. Using the sliding window approach to generate possible stomata regions, we have created between 876 and 963 regions/sub-images for each microscope image (overall of 217, 866 sub-images) for the further application of a 5-fold cross-validation protocol.</p><p hwp:id="p-58"><xref rid="tbl3" ref-type="table" hwp:id="xref-table-wrap-3-1" hwp:rel-id="T3">Table 3</xref> summarizes the effectiveness results considering the classifier SVM+VGG16. The number of detected stoma regions are compatible with the manual counting, which shows a good performance of the proposed approach. Besides, all folds presented similar effectiveness with around 97.1% of detected stoma regions, i.e., 11, 388 stomata out of the 11, 734 ones present in the dataset. It is also important to clarify that the results achieved in this paper are better than the ones recently reported by Jayakody et al. [<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-4" hwp:rel-id="ref-8">8</xref>], which obtained an overall accuracy of 91.6% of detected regions.</p><table-wrap id="tbl3" orientation="portrait" position="float" hwp:id="T3" hwp:rev-id="xref-table-wrap-3-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/TBL3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T3</object-id><object-id pub-id-type="publisher-id">tbl3</object-id><label>Table 3:</label><caption hwp:id="caption-9"><p hwp:id="p-59">Effectiveness results of the classifier (SVM+VGG16) for sliding window classification.</p></caption><graphic xlink:href="538165v2_tbl3" position="float" orientation="portrait" hwp:id="graphic-9"/></table-wrap><p hwp:id="p-60">Once the stomata region candidates have been detected in a microscope image (<xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-1" hwp:rel-id="F7">Figure 7</xref>(a)), an auxiliary matrix was created to encode the stomata region occurrence (<xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-2" hwp:rel-id="F7">Figure 7</xref>(b)), and then a merging between microscope image and auxiliary matrix was performed (<xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-3" hwp:rel-id="F7">Figure 7</xref>(c)). Finally, all stomata are identified in the microscope image, as depicted in <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-4" hwp:rel-id="F7">Figure 7</xref>(d).</p><fig id="fig7" position="float" fig-type="figure" orientation="portrait" hwp:id="F7" hwp:rev-id="xref-fig-7-1 xref-fig-7-2 xref-fig-7-3 xref-fig-7-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/FIG7</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F7</object-id><object-id pub-id-type="publisher-id">fig7</object-id><label>Figure 7:</label><caption hwp:id="caption-10"><p hwp:id="p-61">Pos-processing of a microscope image.</p></caption><graphic xlink:href="538165v2_fig7" position="float" orientation="portrait" hwp:id="graphic-10"/></fig><p hwp:id="p-62">We have also analyzed the quality of the effectiveness results. <xref rid="fig8" ref-type="fig" hwp:id="xref-fig-8-1" hwp:rel-id="F8">Figure 8</xref> shows the hit and miss-classification results achieved by the proposed system. It is essential to observe that regions/sub-images with low quality have also been correctly classified as containing stoma, as depicted in <xref rid="fig8" ref-type="fig" hwp:id="xref-fig-8-2" hwp:rel-id="F8">Figure 8</xref>(a). This fact corroborates the usage of the VGG16 features for the stomata detection task. Miss classified regions can be visualized in <xref rid="fig8" ref-type="fig" hwp:id="xref-fig-8-3" hwp:rel-id="F8">Figure 8</xref>(b). Most of these regions/sub-images represent plant structures that are similar to stomata.</p><fig id="fig8" position="float" fig-type="figure" orientation="portrait" hwp:id="F8" hwp:rev-id="xref-fig-8-1 xref-fig-8-2 xref-fig-8-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;538165v2/FIG8</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F8</object-id><object-id pub-id-type="publisher-id">fig8</object-id><label>Figure 8:</label><caption hwp:id="caption-11"><p hwp:id="p-63">Examples of the stomata classification results: (a) true positive sub-images and (b) false positive sub-images.</p></caption><graphic xlink:href="538165v2_fig8" position="float" orientation="portrait" hwp:id="graphic-11"/></fig></sec></sec><sec id="s6" hwp:id="sec-25"><label>6.</label><title hwp:id="title-29">Conclusions</title><p hwp:id="p-64">Leaves microscope images contain relevant information about plant morphology and can be used for studying specific characteristics of metabolic pathways and different biological processes. A vegetative structure that has received considerable attention concerns the so-called stoma (in the plural, stomata), which stands for small pores on the surfaces of aerial parts of most higher plants (e.g., leaves, stems and pieces of angiosperm flowers and fruits). Stomata are responsible by many functionalities such as (i) exchange of water vapor and CO<sup>2</sup> between the interior of the leaf and the atmosphere; (ii) photosynthesis; (iii) transpiration stream; (iv) nutrition; and (v) metabolism of land plants. Therefore, the understanding of the stomata is of great importance in the exploration of the evolution and behavior of plants.</p><p hwp:id="p-65">In this work, we proposed a stomata classification and identification approach in microscope images of maize cultivars. Herein we have evaluated different extraction techniques (image descriptor and deep learning) and learning methods (Adaboost, MLP, and SVM) concerning the task of correctly classifying stomata regions. In the experiments, the proposed approach achieved a mean accuracy of 96% using HOG+MLP, and a mean accuracy of 100% with VGG16 features using Support Vector Machines (VGG16+SVM).</p><p hwp:id="p-66">Regarding the stomata detection task with a sliding window approach for generating all possible regions/sub-images from the microscope images, the proposed approach detected 97.1% of the stomata regions in 200 microscopes. This fact could show us that the proposed approach using deep learning features might be an appropriate solution for the target application.</p><p hwp:id="p-67">As future work, we intend to develop a computational toolkit to support the specialists in the biology area in their research.</p></sec></body><back><ack hwp:id="ack-1"><title hwp:id="title-30">Acknowledgements</title><p hwp:id="p-68">The authors thanks the support of the Brazilian scientific funding agency CNPq through projects #408919/2016-7 and #307066/2017-7, São Paulo Research Foundation FAPESP grants #2016/19403-6, #2014/12236-1, and #2013/07375-0, as well as the support of NVIDIA Corporation for the donation of the GPUs used for this research.</p></ack><ref-list hwp:id="ref-list-1"><title hwp:id="title-31">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1 xref-ref-1-2 xref-ref-1-3 xref-ref-1-4 xref-ref-1-5 xref-ref-1-6 xref-ref-1-7 xref-ref-1-8"><label>[1]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.1" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Willmer C."><given-names>C.</given-names> <surname>Willmer</surname></string-name> and <string-name name-style="western" hwp:sortable="Fricker M."><given-names>M.</given-names> <surname>Fricker</surname></string-name>, <source hwp:id="source-1">Stomata. Springer Science &amp; Business Media</source>, <year>1996</year>, vol. <volume>2</volume>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1 xref-ref-2-2 xref-ref-2-3"><label>[2]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Melotto M."><given-names>M.</given-names> <surname>Melotto</surname></string-name>, <string-name name-style="western" hwp:sortable="Underwood W."><given-names>W.</given-names> <surname>Underwood</surname></string-name>, and <string-name name-style="western" hwp:sortable="He S. Y."><given-names>S. Y.</given-names> <surname>He</surname></string-name>, “<article-title hwp:id="article-title-2">Role of stomata in plant innate immunity and foliar bacterial diseases</article-title>,” <source hwp:id="source-2">Annu. Rev. Phytopathol</source>., vol. <volume>46</volume>, pp. <fpage>101</fpage>–<lpage>122</lpage>, <year>2008</year>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1 xref-ref-3-2 xref-ref-3-3 xref-ref-3-4 xref-ref-3-5"><label>[3]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Hetherington A. M."><given-names>A. M.</given-names> <surname>Hetherington</surname></string-name> and <string-name name-style="western" hwp:sortable="Woodward F. I."><given-names>F. I.</given-names> <surname>Woodward</surname></string-name>, “<article-title hwp:id="article-title-3">The role of stomata in sensing and driving environmental change</article-title>,” <source hwp:id="source-3">Nature</source>, vol. <volume>424</volume>, no. <issue>6951</issue>, p. <fpage>901</fpage>, <year>2003</year>.</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1 xref-ref-4-2 xref-ref-4-3 xref-ref-4-4 xref-ref-4-5"><label>[4]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.4" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Meidner H."><given-names>H.</given-names> <surname>Meidner</surname></string-name> and <string-name name-style="western" hwp:sortable="Mansfield T. A."><given-names>T. A.</given-names> <surname>Mansfield</surname></string-name>, <source hwp:id="source-4">Physiology of stomata. Tata Mcgraw-Hill Publishing Company Limited; Bombay</source>, <year>1968</year>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1"><label>[5]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Wu G."><given-names>G.</given-names> <surname>Wu</surname></string-name>, <string-name name-style="western" hwp:sortable="Liu H."><given-names>H.</given-names> <surname>Liu</surname></string-name>, <string-name name-style="western" hwp:sortable="Hua L."><given-names>L.</given-names> <surname>Hua</surname></string-name>, <string-name name-style="western" hwp:sortable="Luo Q."><given-names>Q.</given-names> <surname>Luo</surname></string-name>, <string-name name-style="western" hwp:sortable="Lin Y."><given-names>Y.</given-names> <surname>Lin</surname></string-name>, <string-name name-style="western" hwp:sortable="He P."><given-names>P.</given-names> <surname>He</surname></string-name>, <string-name name-style="western" hwp:sortable="Feng S."><given-names>S.</given-names> <surname>Feng</surname></string-name>, <string-name name-style="western" hwp:sortable="Liu J."><given-names>J.</given-names> <surname>Liu</surname></string-name>, and <string-name name-style="western" hwp:sortable="Ye Q."><given-names>Q.</given-names> <surname>Ye</surname></string-name>, “<article-title hwp:id="article-title-4">Differential responses of stomata and photosynthesis to elevated temperature in two co-occurring subtropical forest tree species</article-title>,” <source hwp:id="source-5">Frontiers in plant science</source>, vol. <volume>9</volume>, p. <fpage>467</fpage>, <year>2018</year>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1"><label>[6]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Melotto M."><given-names>M.</given-names> <surname>Melotto</surname></string-name>, <string-name name-style="western" hwp:sortable="Underwood W."><given-names>W.</given-names> <surname>Underwood</surname></string-name>, <string-name name-style="western" hwp:sortable="Koczan J."><given-names>J.</given-names> <surname>Koczan</surname></string-name>, <string-name name-style="western" hwp:sortable="Nomura K."><given-names>K.</given-names> <surname>Nomura</surname></string-name>, and <string-name name-style="western" hwp:sortable="He S. Y."><given-names>S. Y.</given-names> <surname>He</surname></string-name>, “<article-title hwp:id="article-title-5">Plant stomata function in innate immunity against bacterial invasion</article-title>,” <source hwp:id="source-6">Cell</source>, vol. <volume>126</volume>, no. <issue>5</issue>, pp. <fpage>969</fpage>–<lpage>980</lpage>, <year>2006</year>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1"><label>[7]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Haworth M."><given-names>M.</given-names> <surname>Haworth</surname></string-name>, <string-name name-style="western" hwp:sortable="Elliott-Kingston C."><given-names>C.</given-names> <surname>Elliott-Kingston</surname></string-name>, and <string-name name-style="western" hwp:sortable="McElwain J. C."><given-names>J. C.</given-names> <surname>McElwain</surname></string-name>, “<article-title hwp:id="article-title-6">Stomatal control as a driver of plant evolution</article-title>,” <source hwp:id="source-7">Journal of Experimental Botany</source>, vol. <volume>62</volume>, no. <issue>8</issue>, pp. <fpage>2419</fpage>–<lpage>2423</lpage>, <year>2011</year>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1 xref-ref-8-2 xref-ref-8-3 xref-ref-8-4"><label>[8]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Jayakody H."><given-names>H.</given-names> <surname>Jayakody</surname></string-name>, <string-name name-style="western" hwp:sortable="Liu S."><given-names>S.</given-names> <surname>Liu</surname></string-name>, <string-name name-style="western" hwp:sortable="Whitty M."><given-names>M.</given-names> <surname>Whitty</surname></string-name>, and <string-name name-style="western" hwp:sortable="Petrie P."><given-names>P.</given-names> <surname>Petrie</surname></string-name>, “<article-title hwp:id="article-title-7">Microscope image based fully automated stomata detection and pore measurement method for grapevines</article-title>,” <source hwp:id="source-8">Plant Methods</source>, vol. <volume>13</volume>, no. <issue>1</issue>, p. <fpage>94</fpage>, <year>2017</year>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1 xref-ref-9-2 xref-ref-9-3"><label>[9]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Hepworth C."><given-names>C.</given-names> <surname>Hepworth</surname></string-name>, <string-name name-style="western" hwp:sortable="Caine R. S."><given-names>R. S.</given-names> <surname>Caine</surname></string-name>, <string-name name-style="western" hwp:sortable="Harrison E. L."><given-names>E. L.</given-names> <surname>Harrison</surname></string-name>, <string-name name-style="western" hwp:sortable="Sloan J."><given-names>J.</given-names> <surname>Sloan</surname></string-name>, and <string-name name-style="western" hwp:sortable="Gray J. E."><given-names>J. E.</given-names> <surname>Gray</surname></string-name>, “<article-title hwp:id="article-title-8">Stomatal development: focusing on the grasses</article-title>,” <source hwp:id="source-9">Current opinion in plant biology</source>, vol. <volume>41</volume>, pp. <fpage>1</fpage>–<lpage>7</lpage>, <year>2018</year>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><label>[10]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Vogel J."><given-names>J.</given-names> <surname>Vogel</surname></string-name>, “<article-title hwp:id="article-title-9">Unique aspects of the grass cell wall</article-title>,” <source hwp:id="source-10">Current opinion in plant biology</source>, vol. <volume>11</volume>, no. <issue>3</issue>, pp. <fpage>301</fpage>–<lpage>307</lpage>, <year>2008</year>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><label>[11]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Omasa K."><given-names>K.</given-names> <surname>Omasa</surname></string-name> and <string-name name-style="western" hwp:sortable="Onoe M."><given-names>M.</given-names> <surname>Onoe</surname></string-name>, “<article-title hwp:id="article-title-10">Measurement of stomatal aperture by digital image processing</article-title>,” <source hwp:id="source-11">Plant and cell physiology</source>, vol. <volume>25</volume>, no. <issue>8</issue>, pp. <fpage>1379</fpage>–<lpage>1388</lpage>, <year>1984</year>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1"><label>[12]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.12" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Sanyal P."><given-names>P.</given-names> <surname>Sanyal</surname></string-name>, <string-name name-style="western" hwp:sortable="Bhattacharya U."><given-names>U.</given-names> <surname>Bhattacharya</surname></string-name>, and <string-name name-style="western" hwp:sortable="Bandyopadhyay S. K."><given-names>S. K.</given-names> <surname>Bandyopadhyay</surname></string-name>, <article-title hwp:id="article-title-11">“Analysis of sem images of stomata of different tomato cultivars based on morphological features,” in Modeling &amp; Simulation</article-title>, <year>2008</year>. AICMS 08. Second Asia International Conference on&gt;. <source hwp:id="source-12">IEEE</source>, <volume>2008</volume>, pp. <fpage>890</fpage>–<lpage>894</lpage>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1"><label>[13]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.13" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Jian S."><given-names>S.</given-names> <surname>Jian</surname></string-name>, <string-name name-style="western" hwp:sortable="Zhao C."><given-names>C.</given-names> <surname>Zhao</surname></string-name>, and <string-name name-style="western" hwp:sortable="Zhao Y."><given-names>Y.</given-names> <surname>Zhao</surname></string-name>, <article-title hwp:id="article-title-12">“Based on remote sensing processing technology estimating leaves stomatal density of populus euphratica,” in Geoscience and Remote Sensing Symposium (IGARSS), 2011 IEEE International</article-title>. <source hwp:id="source-13">IEEE</source>, <year>2011</year>, pp. <fpage>547</fpage>–<lpage>550</lpage>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><label>[14]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Higaki T."><given-names>T.</given-names> <surname>Higaki</surname></string-name>, <string-name name-style="western" hwp:sortable="Kutsuna N."><given-names>N.</given-names> <surname>Kutsuna</surname></string-name>, and <string-name name-style="western" hwp:sortable="Hasezawa S."><given-names>S.</given-names> <surname>Hasezawa</surname></string-name>, “<article-title hwp:id="article-title-13">Lips database with lipservice: a microscopic image database of intracellular structures in arabidopsis guard cells</article-title>,” <source hwp:id="source-14">BMC plant biology</source>, vol. <volume>13</volume>, no. <issue>1</issue>, p. <fpage>81</fpage>, <year>2013</year>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><label>[15]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.15" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Takumi K. N. H. S. Higaki"><given-names>K. N. H. S. Higaki</given-names>, <surname>Takumi</surname></string-name>, “<article-title hwp:id="article-title-14">Carta-based semi-automatic detection of stomatal regions on an arabidopsis cotyledon surface</article-title>,” <source hwp:id="source-15">PLANT MORPHOLOGY</source>, vol. <volume>26</volume>, no. <issue>1</issue>, pp. <fpage>9</fpage>–<lpage>12</lpage>, <year>2014</year>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1"><label>[16]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.16" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Rasband W. S."><given-names>W. S.</given-names> <surname>Rasband</surname></string-name>, <source hwp:id="source-16">“Imagej, us national institutes of health, bethesda, maryland, usa,”</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="http://imagej.nih.gov/ij/" ext-link-type="uri" xlink:href="http://imagej.nih.gov/ij/" hwp:id="ext-link-2">http://imagej.nih.gov/ij/</ext-link>, <year>2011</year>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><label>[17]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Kutsuna N."><given-names>N.</given-names> <surname>Kutsuna</surname></string-name>, <string-name name-style="western" hwp:sortable="Higaki T."><given-names>T.</given-names> <surname>Higaki</surname></string-name>, <string-name name-style="western" hwp:sortable="Matsunaga S."><given-names>S.</given-names> <surname>Matsunaga</surname></string-name>, <string-name name-style="western" hwp:sortable="Otsuki T."><given-names>T.</given-names> <surname>Otsuki</surname></string-name>, <string-name name-style="western" hwp:sortable="Yamaguchi M."><given-names>M.</given-names> <surname>Yamaguchi</surname></string-name>, <string-name name-style="western" hwp:sortable="Fujii H."><given-names>H.</given-names> <surname>Fujii</surname></string-name>, and <string-name name-style="western" hwp:sortable="Hasezawa S."><given-names>S.</given-names> <surname>Hasezawa</surname></string-name>, “<article-title hwp:id="article-title-15">Active learning framework with iterative clustering for bioimage classification</article-title>,” <source hwp:id="source-17">Nature communications</source>, vol. <volume>3</volume>, p. <fpage>1032</fpage>, <year>2012</year>.</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1"><label>[18]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.18" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Oliveira M. W. da Silva"><given-names>M. W. da Silva</given-names> <surname>Oliveira</surname></string-name>, <string-name name-style="western" hwp:sortable="da Silva N. R."><given-names>N. R.</given-names> <surname>da Silva</surname></string-name>, <string-name name-style="western" hwp:sortable="Casanova D."><given-names>D.</given-names> <surname>Casanova</surname></string-name>, <string-name name-style="western" hwp:sortable="Pinheiro L. F. S."><given-names>L. F. S.</given-names> <surname>Pinheiro</surname></string-name>, <string-name name-style="western" hwp:sortable="Kolb R. M."><given-names>R. M.</given-names> <surname>Kolb</surname></string-name>, and <string-name name-style="western" hwp:sortable="Bruno O. M."><given-names>O. M.</given-names> <surname>Bruno</surname></string-name>, <source hwp:id="source-18">“Automatic counting of stomata in epidermis microscopic images,”</source> <year>2014</year>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><label>[19]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.19" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Laga H."><given-names>H.</given-names> <surname>Laga</surname></string-name>, <string-name name-style="western" hwp:sortable="Shahinnia F."><given-names>F.</given-names> <surname>Shahinnia</surname></string-name>, and <string-name name-style="western" hwp:sortable="Fleury D."><given-names>D.</given-names> <surname>Fleury</surname></string-name>, <article-title hwp:id="article-title-16">“Image-based plant stornata phenotyping,” in Control Automation Robotics &amp; Vision (ICARCV), 2014 13th International Conference on</article-title>. <source hwp:id="source-19">IEEE</source>, <year>2014</year>, pp. <fpage>217</fpage>–<lpage>222</lpage>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><label>[20]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.20" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Awwad F."><given-names>F.</given-names> <surname>Awwad</surname></string-name>, <string-name name-style="western" hwp:sortable="Abuqamar S."><given-names>S.</given-names> <surname>Abuqamar</surname></string-name>, <string-name name-style="western" hwp:sortable="Ksiksi T."><given-names>T.</given-names> <surname>Ksiksi</surname></string-name>, <string-name name-style="western" hwp:sortable="Thaker S."><given-names>S.</given-names> <surname>Thaker</surname></string-name>, and <string-name name-style="western" hwp:sortable="Rabee A. A. R."><given-names>A. A. R.</given-names> <surname>Rabee</surname></string-name>, <source hwp:id="source-20">“Process and device for direct measurements of plant stomata,”</source> <month>Jun</month>. 15 <year>2017</year>, uS Patent App. 14/968,954.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1"><label>[21]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.21" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Duarte K. T."><given-names>K. T.</given-names> <surname>Duarte</surname></string-name>, <string-name name-style="western" hwp:sortable="de Carvalho M. A. G."><given-names>M. A. G.</given-names> <surname>de Carvalho</surname></string-name>, and <string-name name-style="western" hwp:sortable="Martins P. S."><given-names>P. S.</given-names> <surname>Martins</surname></string-name>, “<article-title hwp:id="article-title-17">Segmenting high-quality digital images of stomata using the wavelet spot detection and the watershed transform</article-title>.” in <source hwp:id="source-21">VISIGRAPP (4: VISAPP)</source>, <year>2017</year>, pp. <fpage>540</fpage>–<lpage>547</lpage>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><label>[22]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Tola E."><given-names>E.</given-names> <surname>Tola</surname></string-name>, <string-name name-style="western" hwp:sortable="Lepetit V."><given-names>V.</given-names> <surname>Lepetit</surname></string-name>, and <string-name name-style="western" hwp:sortable="Fua P."><given-names>P.</given-names> <surname>Fua</surname></string-name>, “<article-title hwp:id="article-title-18">Daisy: An efficient dense descriptor applied to wide-baseline stereo</article-title>,” <source hwp:id="source-22">IEEE transactions on pattern analysis and machine intelligence</source>, vol. <volume>32</volume>, no. <issue>5</issue>, pp. <fpage>815</fpage>–<lpage>830</lpage>, <year>2010</year>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1"><label>[23]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.23" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="McConnell R. K."><given-names>R. K.</given-names> <surname>McConnell</surname></string-name>, <source hwp:id="source-23">“Method of and apparatus for pattern recognition,”</source> <month>Jan</month>. 28 <year>1986</year>, uS Patent 4,567,610.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1 xref-ref-24-2"><label>[24]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.24" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Douze M."><given-names>M.</given-names> <surname>Douze</surname></string-name>, <string-name name-style="western" hwp:sortable="Jégou H."><given-names>H.</given-names> <surname>Jégou</surname></string-name>, <string-name name-style="western" hwp:sortable="Sandhawalia H."><given-names>H.</given-names> <surname>Sandhawalia</surname></string-name>, <string-name name-style="western" hwp:sortable="Amsaleg L."><given-names>L.</given-names> <surname>Amsaleg</surname></string-name>, and <string-name name-style="western" hwp:sortable="Schmid C."><given-names>C.</given-names> <surname>Schmid</surname></string-name>, “<article-title hwp:id="article-title-19">Evaluation of gist descriptors for web-scale image search</article-title>,” in <source hwp:id="source-24">Proceedings of the ACM International Conference on Image and Video Retrieval. ACM</source>, <year>2009</year>, p. <fpage>19</fpage>.</citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1"><label>[25]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Oliva A."><given-names>A.</given-names> <surname>Oliva</surname></string-name> and <string-name name-style="western" hwp:sortable="Torralba A."><given-names>A.</given-names> <surname>Torralba</surname></string-name>, “<article-title hwp:id="article-title-20">Modeling the shape of the scene: A holistic representation of the spatial envelope</article-title>,” <source hwp:id="source-25">International journal of computer vision</source>, vol. <volume>42</volume>, no. <issue>3</issue>, pp. <fpage>145</fpage>–<lpage>175</lpage>, <year>2001</year>.</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1"><label>[26]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.26" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Haralick R. M."><given-names>R. M.</given-names> <surname>Haralick</surname></string-name>, <string-name name-style="western" hwp:sortable="Shanmugam K."><given-names>K.</given-names> <surname>Shanmugam</surname></string-name> <etal>et al.</etal>, “<article-title hwp:id="article-title-21">Textural features for image classification</article-title>,” <source hwp:id="source-26">IEEE Transactions on systems, man, and cybernetics</source>, no. <issue>6</issue>, pp. <fpage>610</fpage>–<lpage>621</lpage>, <year>1973</year>.</citation></ref><ref id="c27" hwp:id="ref-27" hwp:rev-id="xref-ref-27-1"><label>[27]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.27" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Ojala T."><given-names>T.</given-names> <surname>Ojala</surname></string-name>, <string-name name-style="western" hwp:sortable="Pietikäinen M."><given-names>M.</given-names> <surname>Pietikäinen</surname></string-name>, and <string-name name-style="western" hwp:sortable="Harwood D."><given-names>D.</given-names> <surname>Harwood</surname></string-name>, “<article-title hwp:id="article-title-22">A comparative study of texture measures with classification based on featured distributions</article-title>,” <source hwp:id="source-27">Pattern recognition</source>, vol. <volume>29</volume>, no. <issue>1</issue>, pp. <fpage>51</fpage>–<lpage>59</lpage>, <year>1996</year>.</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1"><label>[28]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.28" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Sainath T. N."><given-names>T. N.</given-names> <surname>Sainath</surname></string-name>, <string-name name-style="western" hwp:sortable="Mohamed A.-r."><given-names>A.-r.</given-names> <surname>Mohamed</surname></string-name>, <string-name name-style="western" hwp:sortable="Kingsbury B."><given-names>B.</given-names> <surname>Kingsbury</surname></string-name>, and <string-name name-style="western" hwp:sortable="Ramabhadran B."><given-names>B.</given-names> <surname>Ramabhadran</surname></string-name>, “<article-title hwp:id="article-title-23">Deep convolutional neural networks for lvcsr</article-title>,” in <source hwp:id="source-28">Acoustics, speech and signal processing (ICASSP), 2013 IEEE international conference on. IEEE</source>, <year>2013</year>, pp. <fpage>8614</fpage>–<lpage>8618</lpage>.</citation></ref><ref id="c29" hwp:id="ref-29" hwp:rev-id="xref-ref-29-1"><label>[29]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.29" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="Xu L."><given-names>L.</given-names> <surname>Xu</surname></string-name>, <string-name name-style="western" hwp:sortable="Ren J. S."><given-names>J. S.</given-names> <surname>Ren</surname></string-name>, <string-name name-style="western" hwp:sortable="Liu C."><given-names>C.</given-names> <surname>Liu</surname></string-name>, and <string-name name-style="western" hwp:sortable="Jia J."><given-names>J.</given-names> <surname>Jia</surname></string-name>, <source hwp:id="source-29">“Deep convolutional neural network for image deconvolution,” in Advances in Neural Information Processing Systems</source>, <year>2014</year>, pp. <fpage>1790</fpage>–<lpage>1798</lpage>.</citation></ref><ref id="c30" hwp:id="ref-30" hwp:rev-id="xref-ref-30-1"><label>[30]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.30" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="Pan S. J."><given-names>S. J.</given-names> <surname>Pan</surname></string-name> and <string-name name-style="western" hwp:sortable="Yang Q."><given-names>Q.</given-names> <surname>Yang</surname></string-name>, “<article-title hwp:id="article-title-24">A survey on transfer learning</article-title>,” <source hwp:id="source-30">IEEE Trans. on Knowl. and Data Eng</source>., vol. <volume>22</volume>, no. <issue>10</issue>, pp. <fpage>1345</fpage>–<lpage>1359</lpage>, <month>Oct</month>. <year>2010</year>.</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1"><label>[31]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="Russakovsky O."><given-names>O.</given-names> <surname>Russakovsky</surname></string-name>, <string-name name-style="western" hwp:sortable="Deng J."><given-names>J.</given-names> <surname>Deng</surname></string-name>, <string-name name-style="western" hwp:sortable="Su H."><given-names>H.</given-names> <surname>Su</surname></string-name>, <string-name name-style="western" hwp:sortable="Krause J."><given-names>J.</given-names> <surname>Krause</surname></string-name>, <string-name name-style="western" hwp:sortable="Satheesh S."><given-names>S.</given-names> <surname>Satheesh</surname></string-name>, <string-name name-style="western" hwp:sortable="Ma S."><given-names>S.</given-names> <surname>Ma</surname></string-name>, <string-name name-style="western" hwp:sortable="Huang Z."><given-names>Z.</given-names> <surname>Huang</surname></string-name>, <string-name name-style="western" hwp:sortable="Karpathy A."><given-names>A.</given-names> <surname>Karpathy</surname></string-name>, <string-name name-style="western" hwp:sortable="Khosla A."><given-names>A.</given-names> <surname>Khosla</surname></string-name>, <string-name name-style="western" hwp:sortable="Bernstein M."><given-names>M.</given-names> <surname>Bernstein</surname></string-name>, <string-name name-style="western" hwp:sortable="Berg A. C."><given-names>A. C.</given-names> <surname>Berg</surname></string-name>, and <string-name name-style="western" hwp:sortable="Fei-Fei L."><given-names>L.</given-names> <surname>Fei-Fei</surname></string-name>, “<article-title hwp:id="article-title-25">ImageNet Large Scale Visual Recognition Challenge</article-title>,” <source hwp:id="source-31">International Journal of Computer Vision (IJCV)</source>, vol. <volume>115</volume>, no. <issue>3</issue>, pp. <fpage>211</fpage>–<lpage>252</lpage>, <year>2015</year>.</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1"><label>[32]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.32" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="Huang G."><given-names>G.</given-names> <surname>Huang</surname></string-name>, <string-name name-style="western" hwp:sortable="Liu Z."><given-names>Z.</given-names> <surname>Liu</surname></string-name>, and <string-name name-style="western" hwp:sortable="Weinberger K. Q."><given-names>K. Q.</given-names> <surname>Weinberger</surname></string-name>, “<article-title hwp:id="article-title-26">Densely connected convolutional networks</article-title>,” <source hwp:id="source-32">CoRR, vol. abs/1608.06993</source>, <year>2016</year>.</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1"><label>[33]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.33" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Szegedy C."><given-names>C.</given-names> <surname>Szegedy</surname></string-name>, <string-name name-style="western" hwp:sortable="Ioffe S."><given-names>S.</given-names> <surname>Ioffe</surname></string-name>, and <string-name name-style="western" hwp:sortable="Vanhoucke V."><given-names>V.</given-names> <surname>Vanhoucke</surname></string-name>, “<article-title hwp:id="article-title-27">Inception-v4, inception-resnet and the impact of residual connections on learning</article-title>,” <source hwp:id="source-33">CoRR</source>, vol. abs/1602.07261, <year>2016</year>.</citation></ref><ref id="c34" hwp:id="ref-34" hwp:rev-id="xref-ref-34-1"><label>[34]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.34" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Szegedy C."><given-names>C.</given-names> <surname>Szegedy</surname></string-name>, <string-name name-style="western" hwp:sortable="Vanhoucke V."><given-names>V.</given-names> <surname>Vanhoucke</surname></string-name>, <string-name name-style="western" hwp:sortable="Ioffe S."><given-names>S.</given-names> <surname>Ioffe</surname></string-name>, <string-name name-style="western" hwp:sortable="Shlens J."><given-names>J.</given-names> <surname>Shlens</surname></string-name>, and <string-name name-style="western" hwp:sortable="Wojna Z."><given-names>Z.</given-names> <surname>Wojna</surname></string-name>, “<article-title hwp:id="article-title-28">Rethinking the inception architecture for computer vision</article-title>,” <source hwp:id="source-34">CoRR</source>, vol. abs/1512.00567, <year>2015</year>.</citation></ref><ref id="c35" hwp:id="ref-35" hwp:rev-id="xref-ref-35-1"><label>[35]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.35" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Howard A. G."><given-names>A. G.</given-names> <surname>Howard</surname></string-name>, <string-name name-style="western" hwp:sortable="Zhu M."><given-names>M.</given-names> <surname>Zhu</surname></string-name>, <string-name name-style="western" hwp:sortable="Chen B."><given-names>B.</given-names> <surname>Chen</surname></string-name>, <string-name name-style="western" hwp:sortable="Kalenichenko D."><given-names>D.</given-names> <surname>Kalenichenko</surname></string-name>, <string-name name-style="western" hwp:sortable="Wang W."><given-names>W.</given-names> <surname>Wang</surname></string-name>, <string-name name-style="western" hwp:sortable="Weyand T."><given-names>T.</given-names> <surname>Weyand</surname></string-name>, <string-name name-style="western" hwp:sortable="Andreetto M."><given-names>M.</given-names> <surname>Andreetto</surname></string-name>, and <string-name name-style="western" hwp:sortable="Adam H."><given-names>H.</given-names> <surname>Adam</surname></string-name>, “<article-title hwp:id="article-title-29">Mobilenets: Efficient convolutional neural networks for mobile vision applications</article-title>,” <source hwp:id="source-35">arXiv preprint</source> arXiv:<pub-id pub-id-type="arxiv">1704.04861</pub-id>, <year>2017</year>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1"><label>[36]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.36" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Zoph B."><given-names>B.</given-names> <surname>Zoph</surname></string-name>, <string-name name-style="western" hwp:sortable="Vasudevan V."><given-names>V.</given-names> <surname>Vasudevan</surname></string-name>, <string-name name-style="western" hwp:sortable="Shlens J."><given-names>J.</given-names> <surname>Shlens</surname></string-name>, and <string-name name-style="western" hwp:sortable="Le Q. V."><given-names>Q. V.</given-names> <surname>Le</surname></string-name>, “<article-title hwp:id="article-title-30">Learning transferable architectures for scalable image recognition</article-title>,” <source hwp:id="source-36">CoRR</source>, vol. abs/1707.07012, <year>2017</year>.</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1"><label>[37]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.37" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Simonyan K."><given-names>K.</given-names> <surname>Simonyan</surname></string-name> and <string-name name-style="western" hwp:sortable="Zisserman A."><given-names>A.</given-names> <surname>Zisserman</surname></string-name>, “<article-title hwp:id="article-title-31">Very deep convolutional networks for large-scale image recognition</article-title>,” in <source hwp:id="source-37">International Conference on Learning Representations</source>, <year>2015</year>.</citation></ref><ref id="c38" hwp:id="ref-38" hwp:rev-id="xref-ref-38-1"><label>[38]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.38" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-38"><string-name name-style="western" hwp:sortable="Boser B. E."><given-names>B. E.</given-names> <surname>Boser</surname></string-name>, <string-name name-style="western" hwp:sortable="Guyon I. M."><given-names>I. M.</given-names> <surname>Guyon</surname></string-name>, and <string-name name-style="western" hwp:sortable="Vapnik V. N."><given-names>V. N.</given-names> <surname>Vapnik</surname></string-name>, “<article-title hwp:id="article-title-32">A training algorithm for optimal margin classifiers</article-title>,” in <source hwp:id="source-38">Workshop on Computational Learning Theory, ser. COLT ’92</source>, <year>1992</year>, pp. <fpage>144</fpage>–<lpage>152</lpage>.</citation></ref><ref id="c39" hwp:id="ref-39" hwp:rev-id="xref-ref-39-1"><label>[39]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.39" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-39"><string-name name-style="western" hwp:sortable="Hornik K."><given-names>K.</given-names> <surname>Hornik</surname></string-name>, <string-name name-style="western" hwp:sortable="Stinchcombe M."><given-names>M.</given-names> <surname>Stinchcombe</surname></string-name>, and <string-name name-style="western" hwp:sortable="White H."><given-names>H.</given-names> <surname>White</surname></string-name>, “<article-title hwp:id="article-title-33">Multilayer feedforward networks are universal approximators</article-title>,” <source hwp:id="source-39">Neural Netw</source>., vol. <volume>2</volume>, no. <issue>5</issue>, pp. <fpage>359</fpage>–<lpage>366</lpage>, <month>Jul</month>. <year>1989</year>.</citation></ref><ref id="c40" hwp:id="ref-40" hwp:rev-id="xref-ref-40-1"><label>[40]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.40" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-40"><string-name name-style="western" hwp:sortable="Schapire R. E."><given-names>R. E.</given-names> <surname>Schapire</surname></string-name>, “<article-title hwp:id="article-title-34">A brief introduction to boosting</article-title>,” in <source hwp:id="source-40">Proceedings of the 16th International Joint Conference on Artificial Intelligence - Volume 2, ser. IJCAI’99, San Francisco, CA, USA</source>, <year>1999</year>, pp. <fpage>1401</fpage>–<lpage>1406</lpage>.</citation></ref><ref id="c41" hwp:id="ref-41" hwp:rev-id="xref-ref-41-1"><label>[41]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.41" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-41"><string-name name-style="western" hwp:sortable="Castilloa J. J."><given-names>J. J.</given-names> <surname>Castilloa</surname></string-name> and <string-name name-style="western" hwp:sortable="Ferrarotto M."><given-names>M.</given-names> <surname>Ferrarotto</surname></string-name>, “<article-title hwp:id="article-title-35">Evaluation of cyanoacrylate glues for making attached living-leaves epidermis replicas and its scanning electron microscopy observations (evaluación de pegamentos de cianoacrilato para hacer réplicas epidérmicas en hojas vivas adheridas y su observación al meb)</article-title>,” <source hwp:id="source-41">Scanning</source>, vol. <volume>20</volume>, no. <issue>8</issue>, pp. <fpage>557</fpage>–<lpage>563</lpage>, <year>1998</year>.</citation></ref><ref id="c42" hwp:id="ref-42" hwp:rev-id="xref-ref-42-1"><label>[42]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.42" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-42"><string-name name-style="western" hwp:sortable="Doležel J."><given-names>J.</given-names> <surname>Doležel</surname></string-name> and <string-name name-style="western" hwp:sortable="Binarová P."><given-names>P.</given-names> <surname>Binarová</surname></string-name>, “<article-title hwp:id="article-title-36">The effects of colchicine on ploidy level, morphology and embryogenic capacity of alfalfa suspension cultures</article-title>,” <source hwp:id="source-42">Plant Science</source>, vol. <volume>64</volume>, no. <issue>2</issue>, pp. <fpage>213</fpage>–<lpage>219</lpage>, <year>1989</year>.</citation></ref><ref id="c43" hwp:id="ref-43" hwp:rev-id="xref-ref-43-1"><label>[43]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.43" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-43"><string-name name-style="western" hwp:sortable="Pedregosa F."><given-names>F.</given-names> <surname>Pedregosa</surname></string-name>, <string-name name-style="western" hwp:sortable="Varoquaux G."><given-names>G.</given-names> <surname>Varoquaux</surname></string-name>, <string-name name-style="western" hwp:sortable="Gramfort A."><given-names>A.</given-names> <surname>Gramfort</surname></string-name>, <string-name name-style="western" hwp:sortable="Michel V."><given-names>V.</given-names> <surname>Michel</surname></string-name>, <string-name name-style="western" hwp:sortable="Thirion B."><given-names>B.</given-names> <surname>Thirion</surname></string-name>, <string-name name-style="western" hwp:sortable="Grisel O."><given-names>O.</given-names> <surname>Grisel</surname></string-name>, <string-name name-style="western" hwp:sortable="Blondel M."><given-names>M.</given-names> <surname>Blondel</surname></string-name>, <string-name name-style="western" hwp:sortable="Prettenhofer P."><given-names>P.</given-names> <surname>Prettenhofer</surname></string-name>, <string-name name-style="western" hwp:sortable="Weiss R."><given-names>R.</given-names> <surname>Weiss</surname></string-name>, <string-name name-style="western" hwp:sortable="Dubourg V."><given-names>V.</given-names> <surname>Dubourg</surname></string-name>, <string-name name-style="western" hwp:sortable="Vanderplas J."><given-names>J.</given-names> <surname>Vanderplas</surname></string-name>, <string-name name-style="western" hwp:sortable="Passos A."><given-names>A.</given-names> <surname>Passos</surname></string-name>, <string-name name-style="western" hwp:sortable="Cournapeau D."><given-names>D.</given-names> <surname>Cournapeau</surname></string-name>, <string-name name-style="western" hwp:sortable="Brucher M."><given-names>M.</given-names> <surname>Brucher</surname></string-name>, <string-name name-style="western" hwp:sortable="Perrot M."><given-names>M.</given-names> <surname>Perrot</surname></string-name>, and <string-name name-style="western" hwp:sortable="Duchesnay E."><given-names>E.</given-names> <surname>Duchesnay</surname></string-name>, “<article-title hwp:id="article-title-37">Scikit-learn: Machine learning in Python</article-title>,” <source hwp:id="source-43">Journal of Machine Learning Research</source>, vol. <volume>12</volume>, pp. <fpage>2825</fpage>–<lpage>2830</lpage>, <year>2011</year>.</citation></ref><ref id="c44" hwp:id="ref-44" hwp:rev-id="xref-ref-44-1"><label>[44]</label><citation publication-type="journal" citation-type="journal" ref:id="538165v2.44" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-44"><string-name name-style="western" hwp:sortable="van der Walt S."><given-names>S.</given-names> <surname>van der Walt</surname></string-name>, <string-name name-style="western" hwp:sortable="Schönberger J. L."><given-names>J. L.</given-names> <surname>Schönberger</surname></string-name>, <string-name name-style="western" hwp:sortable="Nunez-Iglesias J."><given-names>J.</given-names> <surname>Nunez-Iglesias</surname></string-name>, <string-name name-style="western" hwp:sortable="Boulogne F."><given-names>F.</given-names> <surname>Boulogne</surname></string-name>, <string-name name-style="western" hwp:sortable="Warner J. D."><given-names>J. D.</given-names> <surname>Warner</surname></string-name>, <string-name name-style="western" hwp:sortable="Yager N."><given-names>N.</given-names> <surname>Yager</surname></string-name>, <string-name name-style="western" hwp:sortable="Gouillart E."><given-names>E.</given-names> <surname>Gouillart</surname></string-name>, <string-name name-style="western" hwp:sortable="Yu T."><given-names>T.</given-names> <surname>Yu</surname></string-name>, and <collab hwp:id="collab-1">the scikit-image contributors</collab>, “<article-title hwp:id="article-title-38">scikit-image: image processing in Python</article-title>,” <source hwp:id="source-44">PeerJ</source>, vol. <volume>2</volume>, p. <fpage>e453</fpage>, 6 <year>2014</year>.</citation></ref><ref id="c45" hwp:id="ref-45" hwp:rev-id="xref-ref-45-1"><label>[45]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.45" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-45"><string-name name-style="western" hwp:sortable="Bradski G."><given-names>G.</given-names> <surname>Bradski</surname></string-name>, “<article-title hwp:id="article-title-39">The OpenCV Library</article-title>,” <source hwp:id="source-45">Dr. Dobb’s Journal of Software Tools</source>, <year>2000</year>.</citation></ref><ref id="c46" hwp:id="ref-46" hwp:rev-id="xref-ref-46-1"><label>[46]</label><citation publication-type="website" citation-type="web" ref:id="538165v2.46" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-46"><string-name name-style="western" hwp:sortable="Chollet F."><given-names>F.</given-names> <surname>Chollet</surname></string-name> <etal>et al.</etal>, <source hwp:id="source-46">“Keras,”</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="https://keras.io" ext-link-type="uri" xlink:href="https://keras.io" hwp:id="ext-link-3">https://keras.io</ext-link>, <year>2015</year>.</citation></ref><ref id="c47" hwp:id="ref-47" hwp:rev-id="xref-ref-47-1"><label>[47]</label><citation publication-type="other" citation-type="journal" ref:id="538165v2.47" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-47"><collab hwp:id="collab-2">M. A</collab>. <etal>et. al.</etal>, <source hwp:id="source-47">“TensorFlow: Large-scale machine learning on heterogeneous systems,” 2015, software available from tensorflow.org. [Online]</source>. Available: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://www.tensorflow.org/" ext-link-type="uri" xlink:href="https://www.tensorflow.org/" hwp:id="ext-link-4">https://www.tensorflow.org/</ext-link></citation></ref></ref-list><fn-group hwp:id="fn-group-2"><fn id="fn1" hwp:id="fn-2" hwp:rev-id="xref-fn-2-1"><label><sup>1</sup></label><p hwp:id="p-69">The values in bold stand for the best descriptor per classifier. Symbol ‘⋆’ denotes the best overall result.</p></fn></fn-group></back></article>
