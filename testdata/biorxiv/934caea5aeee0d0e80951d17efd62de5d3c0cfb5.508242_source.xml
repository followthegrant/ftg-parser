<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/508242</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;508242v3</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;508242</article-id><article-id pub-id-type="other" hwp:sub-type="slug">508242</article-id><article-id pub-id-type="other" hwp:sub-type="atom-slug">508242</article-id><article-id pub-id-type="other" hwp:sub-type="tag">508242</article-id><article-version>1.3</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Bioinformatics" hwp:journal="biorxiv"><subject>Bioinformatics</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">Identifying complex sequence patterns with a variable-convolutional layer effectively and efficiently</article-title></title-group><author-notes hwp:id="author-notes-1"><fn id="n1" fn-type="equal" hwp:id="fn-1" hwp:rev-id="xref-fn-1-1 xref-fn-1-2"><label>#</label><p hwp:id="p-1">These authors contributed equally to this work.</p></fn><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1 xref-corresp-1-2"><label>*</label>To whom correspondence should be addressed. Email: <email hwp:id="email-1">gaog@mail.cbi.pku.edu.cn</email>, and mail could also be sent to <email hwp:id="email-2">dingy@mail.cbi.pku.edu.cn</email></corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" hwp:id="contrib-1"><name name-style="western" hwp:sortable="Li Jing-Yi"><surname>Li</surname><given-names>Jing-Yi</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref><xref ref-type="fn" rid="n1" hwp:id="xref-fn-1-1" hwp:rel-id="fn-1">#</xref></contrib><contrib contrib-type="author" hwp:id="contrib-2"><name name-style="western" hwp:sortable="Jin Shen"><surname>Jin</surname><given-names>Shen</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref><xref ref-type="fn" rid="n1" hwp:id="xref-fn-1-2" hwp:rel-id="fn-1">#</xref></contrib><contrib contrib-type="author" hwp:id="contrib-3"><name name-style="western" hwp:sortable="Tu Xin-Ming"><surname>Tu</surname><given-names>Xin-Ming</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">1</xref></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-4"><name name-style="western" hwp:sortable="Ding Yang"><surname>Ding</surname><given-names>Yang</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-3" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-1" hwp:rel-id="aff-3">3</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*</xref></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-5"><name name-style="western" hwp:sortable="Gao Ge"><surname>Gao</surname><given-names>Ge</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-4" hwp:rel-id="aff-1">1</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-2" hwp:rel-id="corresp-1">*</xref></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2 xref-aff-1-3 xref-aff-1-4"><label>1</label><institution hwp:id="institution-1">Biomedical Pioneering Innovation Center (BIOPIC) &amp; Beijing Advanced Innovation Center for Genomics (ICG), Center for Bioinformatics (CBI), and State Key Laboratory of Protein and Plant Gene Research at School of Life Sciences, Peking University</institution>, Beijing, 100871, <country>China</country></aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1"><label>2</label><institution hwp:id="institution-2">Computational Biology Department, Carnegie Mellon University</institution>, Pittsburgh, Pennsylvania, 15213</aff><aff id="a3" hwp:id="aff-3" hwp:rev-id="xref-aff-3-1"><label>3</label><institution hwp:id="institution-3">Beijing Institute of Radiation Medicine</institution>, Beijing, 100850, <country>China</country></aff></contrib-group><pub-date pub-type="epub-original" date-type="pub" publication-format="electronic" hwp:start="2021"><year>2021</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2018-12-31T11:06:10-08:00">
    <day>31</day><month>12</month><year>2018</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2021-01-25T19:57:15-08:00">
    <day>25</day><month>1</month><year>2021</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2018-12-31T11:11:58-08:00">
    <day>31</day><month>12</month><year>2018</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2021-01-25T20:00:24-08:00">
    <day>25</day><month>1</month><year>2021</year>
  </pub-date><elocation-id>508242</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2018-12-29"><day>29</day><month>12</month><year>2018</year></date>
<date date-type="rev-recd" hwp:start="2021-01-25"><day>25</day><month>1</month><year>2021</year></date>
<date date-type="accepted" hwp:start="2021-01-25"><day>25</day><month>1</month><year>2021</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2021</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/" hwp:id="license-1"><p hwp:id="p-2">This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by-nc/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by-nc/4.0/</ext-link></p></license></permissions><self-uri xlink:href="508242.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/external-links" xlink:role="external-links" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2021/pdf/508242v3.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="508242.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2021/abstracts/508242v3/508242v3.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2021/fulltext/508242v3/508242v3.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-3">Motif identification is among the most canonical and essential computational tasks for bioinformatics and genomics. Here we proposed a simple and scalable novel convolution-based layer, Variable Convolutional neural layer (vConv), for effective motif identification in high-throughput omics data by learning kernel length on-the-fly. Empirical evaluations on DNA-protein binding and DNase footprinting cases well demonstrated that vConv-based networks have superior performance to their convolutional counterparts regardless of model complexity. All source codes are freely available on GitHub (<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/gao-lab/vConv" ext-link-type="uri" xlink:href="https://github.com/gao-lab/vConv" hwp:id="ext-link-2">https://github.com/gao-lab/vConv</ext-link>) for academic usage.</p></abstract><counts><page-count count="23"/></counts><custom-meta-wrap><custom-meta hwp:id="custom-meta-1"><meta-name>special-property</meta-name><meta-value>contains-inline-supplementary-material</meta-value></custom-meta></custom-meta-wrap><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-2">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta><notes hwp:id="notes-1"><notes notes-type="competing-interest-statement" hwp:id="notes-2"><title hwp:id="title-2">Competing Interest Statement</title><p hwp:id="p-4">The authors have declared no competing interest.</p></notes><fn-group content-type="external-links" hwp:id="fn-group-1"><fn fn-type="dataset" hwp:id="fn-2"><p hwp:id="p-5">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/gao-lab/vConv" ext-link-type="uri" xlink:href="https://github.com/gao-lab/vConv" hwp:id="ext-link-3">https://github.com/gao-lab/vConv</ext-link>
</p></fn></fn-group></notes></front><body><sec id="s1" hwp:id="sec-1"><title hwp:id="title-3">Introduction</title><p hwp:id="p-6">Recurring sequence motifs (<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">Achar and Sætrom, 2015</xref>; <xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">Kulakovskiy and Makeev, 2013</xref>) have been well demonstrated to exert or regulate important biological functions, such as protein binding (<xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">Stormo, 2015</xref>), transcription initiation (<xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">Kadonaga, 2012</xref>), alternative splicing (<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">Blencowe, 2000</xref>), subcellular localization (<xref ref-type="bibr" rid="c46" hwp:id="xref-ref-46-1" hwp:rel-id="ref-46">Zhang, et al., 2014</xref>), translation control (<xref ref-type="bibr" rid="c50" hwp:id="xref-ref-50-1" hwp:rel-id="ref-50">Zucchelli, et al., 2015</xref>), and microRNA targeting (<xref ref-type="bibr" rid="c38" hwp:id="xref-ref-38-1" hwp:rel-id="ref-38">Thomson and Dinger, 2016</xref>). Effectively and efficiently identifying these motifs in massive omics data is a critical first step for follow-up investigations.</p><p hwp:id="p-7">Various computational tools have been developed to identify sequence motifs via word-based and profile-based models (<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">Das and Dai, 2007</xref>; <xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-1" hwp:rel-id="ref-27">Lihu and Holban, 2015</xref>; <xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">Liu, et al., 2018</xref>; <xref ref-type="bibr" rid="c39" hwp:id="xref-ref-39-1" hwp:rel-id="ref-39">Tran and Huang, 2014</xref>; <xref ref-type="bibr" rid="c43" hwp:id="xref-ref-43-1" hwp:rel-id="ref-43">Zambelli, et al., 2013</xref>). Word-based tools start with a fixed-length and conservative segment and then perform a global scanning; such tools include DREME (<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">Bailey, 2011</xref>), Fmotif (<xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">Jia, et al., 2014</xref>), RSAT peak-motifs (<xref ref-type="bibr" rid="c37" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">Thomas-Chollier, et al., 2012</xref>), SIOMICS (<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">Ding, et al., 2015</xref>; <xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">Ding, et al., 2014</xref>), and Discover (<xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">Maaskola and Rajewsky, 2014</xref>). While these tools can theoretically obtain the globally optimal solution, they suffer from high computational complexity when applied to data with complex motifs or large-scale datasets (<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-2" hwp:rel-id="ref-8">Das and Dai, 2007</xref>). Profile-based tools attempt to find representative motifs by heuristically fine-tuning a series of possible motifs, either generated from a subset of input data or randomly chosen (<xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">Ikebata and Yoshida, 2015</xref>; <xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">Kulakovskiy, et al., 2010</xref>; <xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-1" hwp:rel-id="ref-35">Sharov and Ko, 2009</xref>) (<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">Bailey, et al., 2006</xref>; <xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">Machanick and Bailey, 2011</xref>), leading to a faster (but probably sub-optimal) motif calling (<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-2" hwp:rel-id="ref-27">Lihu and Holban, 2015</xref>).</p><p hwp:id="p-8">Several convolutional neural network (CNN)-based tools have been proposed recently as a more scalable approach for identifying motifs. Alipanahi et al. developed DeepBind to identify protein binding motifs from large-scale ChIP-Seq datasets (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">Alipanahi, et al., 2015</xref>) by treating each convolutional kernel as an individual motif scanner and discriminating motif-containing sequences from others based on the output of all kernels. Along with this line, several convolution-based networks have been proposed to effectively handle large amount of data in various settings (<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">Angermueller, et al., 2017</xref>; <xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">Kelley, et al., 2018</xref>; <xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">Koo and Eddy, 2019</xref>; <xref ref-type="bibr" rid="c41" hwp:id="xref-ref-41-1" hwp:rel-id="ref-41">Wang, et al., 2018</xref>; <xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-1" hwp:rel-id="ref-47">Zhang, et al., 2018</xref>; <xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-1" hwp:rel-id="ref-49">Zhou, et al., 2018</xref>). Meanwhile, however, the inherent fixed-kernel design of canonical convolutional networks could hinder effective identification (<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">Han, et al., 2018</xref>; <xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-1" hwp:rel-id="ref-42">Yin and Schütze, 2016</xref>; <xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-2" hwp:rel-id="ref-42">Yin and Schütze, 2016</xref>; <xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-2" hwp:rel-id="ref-47">Zhang, et al., 2018</xref>) of <italic toggle="yes">bona fide</italic> sequence patterns, which are usually of various lengths and unknown <italic toggle="yes">a priori</italic> and often function combinatorically (<xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">Lambert, et al., 2018</xref>; <xref ref-type="bibr" rid="c34" hwp:id="xref-ref-34-1" hwp:rel-id="ref-34">Reiter, et al., 2017</xref>). One possible workaround is to build these representations in a hierarchical manner (<xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-2" hwp:rel-id="ref-20">Kelley, et al., 2018</xref>; <xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-2" hwp:rel-id="ref-23">Koo and Eddy, 2019</xref>), yet the deeper structure itself would demand additional time/space cost for network training and hyper-parameter search (also see Supplementary Notes 1).</p><p hwp:id="p-9">Here, we proposed a novel neural layer architecture called Variable Convolutional neural layer (vConv), which learns the kernel length directly from the data. Evaluations based on both simulations and real-world datasets showed that vConv-based networks outperformed canonical convolution-based networks, making it an ideal option for the <italic toggle="yes">ab initio</italic> discovery of motifs from high-throughput datasets. Further inspection also suggested the vConv layer being robust for various hyper-parameter setups. All source codes are publicly available on GitHub (<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/gao-lab/vConv" ext-link-type="uri" xlink:href="https://github.com/gao-lab/vConv" hwp:id="ext-link-4">https://github.com/gao-lab/vConv</ext-link>).</p></sec><sec id="s2" hwp:id="sec-2"><title hwp:id="title-4">Methods</title><sec id="s2a" hwp:id="sec-3"><title hwp:id="title-5">Design and implementation of vConv</title><p hwp:id="p-10">Without loss of generality, we focus on nucleotide sequences where each nucleotide can take only one of four alphabets (A, C, G, and T (for DNA) or U (for RNA)). vConv (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Fig. 1</xref>) is designed to be a convolutional layer equipped with a trainable “mask” to adaptively tune the effective length of the kernel during training. Specifically, for the <italic toggle="yes">z</italic>-th kernel <italic toggle="yes">w<sup>z</sup></italic> of length <italic toggle="yes">L<sub>k</sub>,z</italic> ∈ {1,…,<italic toggle="yes">n</italic>}, the “mask” <inline-formula hwp:id="inline-formula-1"><alternatives hwp:id="alternatives-1"><inline-graphic xlink:href="508242v3_inline1.gif" hwp:id="inline-graphic-1"/></alternatives></inline-formula> is a matrix with the same shape as this kernel (i.e., <italic toggle="yes">L<sub>k</sub></italic> × 4) and most elements close to either 0 or 1 (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Fig. 1A</xref>). Multiplying this mask and the original kernel by the Hadamard product <inline-formula hwp:id="inline-formula-2"><alternatives hwp:id="alternatives-2"><inline-graphic xlink:href="508242v3_inline2.gif" hwp:id="inline-graphic-2"/></alternatives></inline-formula> thus effectively masks the original kernel with the corresponding close-to-0 elements and gives the masked kernel (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-3" hwp:rel-id="F1">Fig. 1B</xref>), which can then be used as an ordinary kernel in a canonical convolutional layer (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-4" hwp:rel-id="F1">Fig. 1C</xref>).</p><fig id="fig1" position="float" orientation="portrait" fig-type="figure" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2 xref-fig-1-3 xref-fig-1-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;508242v3/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Fig. 1.</label><caption hwp:id="caption-1"><p hwp:id="p-11">The design of vConv. Firstly, a mask matrix is constructed from two sigmoid functions (A). Then vConv “masks” this mask matrix onto the kernel using the Hadamard product (B), and treats the masked kernel as an ordinary kernel to convolve the input sequence (C).</p></caption><graphic xlink:href="508242v3_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-12">Mathematically, this mask is parameterized by two sigmoid functions of opposite orientation with two scalars <inline-formula hwp:id="inline-formula-3"><alternatives hwp:id="alternatives-3"><inline-graphic xlink:href="508242v3_inline3.gif" hwp:id="inline-graphic-3"/></alternatives></inline-formula> and <inline-formula hwp:id="inline-formula-4"><alternatives hwp:id="alternatives-4"><inline-graphic xlink:href="508242v3_inline4.gif" hwp:id="inline-graphic-4"/></alternatives></inline-formula> representing the left- and right-boundaries, respectively:
<disp-formula id="eqn5" hwp:id="disp-formula-1">
<alternatives hwp:id="alternatives-5"><graphic xlink:href="508242v3_eqn5.gif" position="float" orientation="portrait" hwp:id="graphic-2"/></alternatives>
</disp-formula>
</p><p hwp:id="p-13">As the above equation implies, all <italic toggle="yes">i</italic>’s falling outside the boundaries (i.e., <inline-formula hwp:id="inline-formula-5"><alternatives hwp:id="alternatives-6"><inline-graphic xlink:href="508242v3_inline5.gif" hwp:id="inline-graphic-5"/></alternatives></inline-formula> or <inline-formula hwp:id="inline-formula-6"><alternatives hwp:id="alternatives-7"><inline-graphic xlink:href="508242v3_inline5a.gif" hwp:id="inline-graphic-6"/></alternatives></inline-formula>) have their (masking) elements <inline-formula hwp:id="inline-formula-7"><alternatives hwp:id="alternatives-8"><inline-graphic xlink:href="508242v3_inline6.gif" hwp:id="inline-graphic-7"/></alternatives></inline-formula> [<italic toggle="yes">i,j</italic>] close to zero, and all <italic toggle="yes">i</italic>’s within the boundaries have their elements close to 1; those <italic toggle="yes">i</italic>’s around the boundaries have their elements around 0.5, thus ‘soft’-masking boundary kernel elements.</p><p hwp:id="p-14">To make <inline-formula hwp:id="inline-formula-8"><alternatives hwp:id="alternatives-9"><inline-graphic xlink:href="508242v3_inline7.gif" hwp:id="inline-graphic-8"/></alternatives></inline-formula> and <inline-formula hwp:id="inline-formula-9"><alternatives hwp:id="alternatives-10"><inline-graphic xlink:href="508242v3_inline8.gif" hwp:id="inline-graphic-9"/></alternatives></inline-formula> converge faster during training, we combine the binary cross-entropy (BCE) loss with a sum of masked Shannon losses (MSLs) from each kernel mask. Mathematically, we have the following total loss <italic toggle="yes">L</italic>:
<disp-formula id="eqn6" hwp:id="disp-formula-2">
<alternatives hwp:id="alternatives-11"><graphic xlink:href="508242v3_eqn6.gif" position="float" orientation="portrait" hwp:id="graphic-3"/></alternatives>
</disp-formula>
</p><p hwp:id="p-15">Where <inline-formula hwp:id="inline-formula-10"><alternatives hwp:id="alternatives-12"><inline-graphic xlink:href="508242v3_inline9.gif" hwp:id="inline-graphic-10"/></alternatives></inline-formula> is the sum of the Shannon entropy across all nucleotide positions of <italic toggle="yes">P<sub>z</sub></italic>, the position weight matrix (PWM) learned by the <italic toggle="yes">z</italic>-th kernel. For precision, we set <italic toggle="yes">P<sub>z</sub></italic> = <italic toggle="yes">P</italic>(<italic toggle="yes">w<sup>z</sup>, b</italic> = 2) following the exact kernel-to-PWM transformation specified by Ding et al. (<xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">Ding, et al., 2018</xref>). One can then immediately deduce the formula for updating the left boundary <inline-formula hwp:id="inline-formula-11"><alternatives hwp:id="alternatives-13"><inline-graphic xlink:href="508242v3_inline10.gif" hwp:id="inline-graphic-11"/></alternatives></inline-formula> at time step <italic toggle="yes">t</italic> via gradient descent with learning rate <italic toggle="yes">r</italic> (<italic toggle="yes">r</italic>&gt;0):
<disp-formula hwp:id="disp-formula-3">
<alternatives hwp:id="alternatives-14"><graphic xlink:href="508242v3_ueqn1.gif" position="float" orientation="portrait" hwp:id="graphic-4"/></alternatives>
</disp-formula>
</p><p hwp:id="p-16">Similarly, for updating the right boundary <inline-formula hwp:id="inline-formula-12"><alternatives hwp:id="alternatives-15"><inline-graphic xlink:href="508242v3_inline11.gif" hwp:id="inline-graphic-12"/></alternatives></inline-formula>, we have:
<disp-formula hwp:id="disp-formula-4">
<alternatives hwp:id="alternatives-16"><graphic xlink:href="508242v3_ueqn2.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives>
</disp-formula>
</p><p hwp:id="p-17">The Shannon entropies of all kernel positions far from the mask boundaries <inline-formula hwp:id="inline-formula-13"><alternatives hwp:id="alternatives-17"><inline-graphic xlink:href="508242v3_inline12.gif" hwp:id="inline-graphic-13"/></alternatives></inline-formula> contribute little to the final derivatives. Therefore, if most boundary-flanking kernel positions have a low Shannon entropy (i.e., a high information content; defined by <italic toggle="yes">H</italic>(<italic toggle="yes">P</italic>(<italic toggle="yes">w<sup>z</sup></italic>, 2))<italic toggle="yes"><sub>i</sub></italic> — <italic toggle="yes">threshold</italic> &lt; 0), then the masked Shannon loss (MSL) will help push the boundaries outwards (i.e., <inline-formula hwp:id="inline-formula-14"><alternatives hwp:id="alternatives-18"><inline-graphic xlink:href="508242v3_inline13.gif" hwp:id="inline-graphic-14"/></alternatives></inline-formula> and <inline-formula hwp:id="inline-formula-15"><alternatives hwp:id="alternatives-19"><inline-graphic xlink:href="508242v3_inline14.gif" hwp:id="inline-graphic-15"/></alternatives></inline-formula>) during gradient descent, just as if the current mask is too narrow to span all informative positions. Likewise, if most boundary-flanking kernel positions have a high Shannon entropy (i.e. a low information content; defined by <italic toggle="yes">H</italic>(<italic toggle="yes">P</italic>(<italic toggle="yes">w<sup>z</sup></italic>, 2))<italic toggle="yes"><sub>i</sub></italic> — <italic toggle="yes">threshold</italic> &gt; 0), then the MSL will help push the boundaries inwards (i.e., <inline-formula hwp:id="inline-formula-16"><alternatives hwp:id="alternatives-20"><inline-graphic xlink:href="508242v3_inline15.gif" hwp:id="inline-graphic-16"/></alternatives></inline-formula> and <inline-formula hwp:id="inline-formula-17"><alternatives hwp:id="alternatives-21"><inline-graphic xlink:href="508242v3_inline16.gif" hwp:id="inline-graphic-17"/></alternatives></inline-formula>), just as if the current mask is too broad to exclude some positions with low information content.</p><p hwp:id="p-18">To speed up computation in practice, we approximate the sum by ignoring most small, outside-mask kernel positions and retaining only those terms with <inline-formula hwp:id="inline-formula-18"><alternatives hwp:id="alternatives-22"><inline-graphic xlink:href="508242v3_inline17.gif" hwp:id="inline-graphic-18"/></alternatives></inline-formula>.</p><p hwp:id="p-19">Finally, when introducing a vConv layer into a model, values of <inline-formula hwp:id="inline-formula-19"><alternatives hwp:id="alternatives-23"><inline-graphic xlink:href="508242v3_inline18.gif" hwp:id="inline-graphic-19"/></alternatives></inline-formula>, <italic toggle="yes">λ</italic>, and <italic toggle="yes">threshold</italic> in MSL are of user’s choice. In all subsequent benchmarking on vConv-based networks, unless otherwise specified, we set for each vConv layer the <inline-formula hwp:id="inline-formula-20"><alternatives hwp:id="alternatives-24"><inline-graphic xlink:href="508242v3_inline19.gif" hwp:id="inline-graphic-20"/></alternatives></inline-formula> as <inline-formula hwp:id="inline-formula-21"><alternatives hwp:id="alternatives-25"><inline-graphic xlink:href="508242v3_inline20.gif" hwp:id="inline-graphic-21"/></alternatives></inline-formula> for an unmasked kernel length of <italic toggle="yes">l</italic>, the <italic toggle="yes">λ</italic> as 0.0025, and the <italic toggle="yes">threshold</italic> in MSL as <inline-formula hwp:id="inline-formula-22"><alternatives hwp:id="alternatives-26"><inline-graphic xlink:href="508242v3_inline21.gif" hwp:id="inline-graphic-22"/></alternatives></inline-formula> for a kernel with <italic toggle="yes">c</italic> channels. This value of <italic toggle="yes">threshold</italic> is the Shannon entropy for the (discrete) distribution whose highest probability is 0.7, and all others <italic toggle="yes">c</italic>-1’s are equally divided. When processing the nucleic acid sequence, there are totally <italic toggle="yes">c</italic>=4 different probability values, so the probability of the remaining 3 items equally divided is (1-0.7)/3; on the other hand, in Basenji-based Basset networks, the <italic toggle="yes">c</italic> for deeper convolutional layers is not necessarily 4.</p></sec><sec id="s2b" hwp:id="sec-4"><title hwp:id="title-6">Benchmark vConv-based networks on simulated sequence classification</title><p hwp:id="p-20">We simulated for each motif case 6,000 sequences (with 3,000 positive and 3,000 negative) of length 1,000, picked 600 as the test dataset randomly, and split the rest into 4,860 training and 540 validation sequences by setting “validation_split=0.1” in model.fit of Keras Model API (version 2.2.4)(<xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">Chollet, 2015</xref>); in this way, for each motif case, the same collection of training, validation, and test datasets was used for all hyper-parameter settings tested (see below). The ratio of counts of positive to negative sequences in the test dataset was within [0.8, 1.2] for all 7 motif cases. Each positive sequence is a random sequence with a “signal sequence” inserted at a random location, and each negative sequence is a fully random sequence. The “signal sequence” is a sequence fragment generated from one of the motifs associated with the case in question (<xref ref-type="table" rid="tbl2" hwp:id="xref-table-wrap-2-1" hwp:rel-id="T2">Table 2</xref>). For the cases of 2, 4, 6 and 8 motifs, new motifs were introduced incrementally (i.e., all motifs in “2 motifs” were also included in “4 motifs”, all motifs in “4 motifs” were also included in “6 motifs”, and all motifs in “6 motifs” were also included in “8 motifs”).</p><p hwp:id="p-21">In each iteration of benchmarking a certain case, we (1) picked a hyper-parameter setting from <xref ref-type="table" rid="tbl1" hwp:id="xref-table-wrap-1-1" hwp:rel-id="T1">Table 1</xref>; (2) used the training and validation datasets to train first a vConv-based network (see Supplementary Fig. 1 for its structure) with this hyper-parameter setting and then a canonical convolution-based network with a model structure identical to that of the vConv-based network, except that the vConv layer was replaced with a canonical convolutional layer with the same kernel number and (unmasked) kernel length; and (3) obtained the AUROC values of these two networks on the test dataset. Iterating over all possible hyper-parameter settings yielded a series of AUROC values for both the vConv-based network and the convolution-based network for the case at hand.</p><table-wrap id="tbl1" orientation="portrait" position="float" hwp:id="T1" hwp:rev-id="xref-table-wrap-1-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;508242v3/TBL1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">tbl1</object-id><label>Table 1.</label><caption hwp:id="caption-2"><p hwp:id="p-22">Hyper-parameter space for the comparison between vConv-based networks and convolution-based networks on simulation datasets.</p></caption><graphic xlink:href="508242v3_tbl1" position="float" orientation="portrait" hwp:id="graphic-6"/></table-wrap><table-wrap id="tbl2" orientation="portrait" position="float" hwp:id="T2" hwp:rev-id="xref-table-wrap-2-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;508242v3/TBL2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T2</object-id><object-id pub-id-type="publisher-id">tbl2</object-id><label>Table 2.</label><caption hwp:id="caption-3"><p hwp:id="p-23">Motifs used to generate each dataset. All motifs were derived from JASPAR (<xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">Khan, et al., 2017</xref>).</p></caption><graphic xlink:href="508242v3_tbl2" position="float" orientation="portrait" hwp:id="graphic-7"/></table-wrap><p hwp:id="p-24">We used AdaDelta (<xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-1" hwp:rel-id="ref-44">Zeiler, 2012</xref>) with learning rate 1 as the optimizer. All parameters except for vConv-exclusive ones were initialized by the Glorot uniform initializer (<xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">Glorot and Bengio, 2010</xref>); vConv-exclusive parameters were initialized as specified in the subsection “Design and implementation of vConv”. Both convolution-based and vConv-based networks were trained with early stopping on validation loss with patience set to 50. vConv-based networks with <italic toggle="yes">n</italic> kernels were first trained without updating <inline-formula hwp:id="inline-formula-23"><alternatives hwp:id="alternatives-27"><inline-graphic xlink:href="508242v3_inline22.gif" hwp:id="inline-graphic-23"/></alternatives></inline-formula> for 10 epochs and then trained with updating <inline-formula hwp:id="inline-formula-24"><alternatives hwp:id="alternatives-28"><inline-graphic xlink:href="508242v3_inline23.gif" hwp:id="inline-graphic-24"/></alternatives></inline-formula>.</p></sec><sec id="s2c" hwp:id="sec-5"><title hwp:id="title-7">Benchmark vConv-based networks on real-world sequence classification</title><p hwp:id="p-25">To further demonstrate the performance of vConv-based networks in the real world, we examined whether replacing convolutional layers with vConv helps to improve the performance for motif identification in real-world ChIP-Seq data, against three published convolution-based networks: DeepBind (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-2" hwp:rel-id="ref-2">Alipanahi, et al., 2015</xref>), Zeng et al.’s convolution-based networks (<xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-1" hwp:rel-id="ref-45">Zeng, et al., 2016</xref>), and Basset (<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">Kelley, et al., 2016</xref>).</p><p hwp:id="p-26">For the first comparison, we downloaded DeepBind’s original training (with positively sequences only) and test datasets from <ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/jisraeli/DeepBind/tree/master/data/encode" ext-link-type="uri" xlink:href="https://github.com/jisraeli/DeepBind/tree/master/data/encode" hwp:id="ext-link-5">https://github.com/jisraeli/DeepBind/tree/master/data/encode</ext-link>, and generated negative training dataset by shuffling positive sequences with matching dinucleotide composition as specified by DeepBind (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-3" hwp:rel-id="ref-2">Alipanahi, et al., 2015</xref>). We then trained vConv-based networks (see below for the model structure and training details) and compared their AUROC on test datasets with those of three sets of DeepBind performances from Supplementary Table 5 of DeepBind’s original paper (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-4" hwp:rel-id="ref-2">Alipanahi, et al., 2015</xref>): (1) the DeepBind* networks, which were trained by using all the training dataset; (2) the DeepBind networks, whose positive training sequences consist of those from the top 500 odd-numbered peaks only; and (3) the DeepBindbest networks, the one of DeepBind and DeepBind* with larger AUROC for each test dataset. During comparison, we found that there are two datasets with different AUROC values yet sharing the same model name in their original dataset (REST_HepG2_NRSF_HudsonAlpha and REST_SK-N-SH_NRSF_HudsonAlpha), which makes us unable to determine their true AUROC values, so we excluded them from the comparison.</p><p hwp:id="p-27">For the second comparison between vConv-based networks and Zeng et al.’s (<xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-2" hwp:rel-id="ref-45">Zeng, et al., 2016</xref>) convolution-based networks, we downloaded 690 ENCODE ChIP-Seq-based training and test datasets representing the DNA binding profile of various transcription factors and other DNA-binding proteins from <ext-link l:rel="related" l:ref-type="uri" l:ref="http://cnn.csail.mit.edu/motif_discovery/" ext-link-type="uri" xlink:href="http://cnn.csail.mit.edu/motif_discovery/" hwp:id="ext-link-6">http://cnn.csail.mit.edu/motif_discovery/</ext-link>. We then trained vConv-based networks (see below for the model structure and training details) and compared its AUROC value on test datasets with the AUROC values of Zeng et al.’s networks from <ext-link l:rel="related" l:ref-type="uri" l:ref="http://cnn.csail.mit.edu/motif_discovery_pred/" ext-link-type="uri" xlink:href="http://cnn.csail.mit.edu/motif_discovery_pred/" hwp:id="ext-link-7">http://cnn.csail.mit.edu/motif_discovery_pred/</ext-link>.</p><p hwp:id="p-28">The first two comparisons used the same model structure (Supplementary Fig. 1) and hyper-parameter space (Supplementary Table 1). For direct comparison between vConv-based networks and convolution-based networks for DeepBind and Zeng et al.’s cases (<xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-3" hwp:rel-id="ref-45">Zeng, et al., 2016</xref>), the vConv-based network was implemented by replacing the convolutional layer of each network considered for comparison with a vConv layer (with exactly the same hyper-parameters for the number of kernels and the initial (unmasked) kernel length). The hyper-parameter space is listed in the Supplementary Table 1. The remaining details of parameter initialization followed those of the corresponding convolution-based networks (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-5" hwp:rel-id="ref-2">Alipanahi, et al., 2015</xref>; <xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-4" hwp:rel-id="ref-45">Zeng, et al., 2016</xref>), and all these networks used the training strategy described in the simulation case.</p><p hwp:id="p-29">Finally, for the third comparison with the Basset network (<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-2" hwp:rel-id="ref-21">Kelley, et al., 2016</xref>), we used the Basenji reimplementation of Basset (<xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-3" hwp:rel-id="ref-20">Kelley, et al., 2018</xref>) (<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/calico/basenji/tree/master/manuscripts/basset" ext-link-type="uri" xlink:href="https://github.com/calico/basenji/tree/master/manuscripts/basset" hwp:id="ext-link-8">https://github.com/calico/basenji/tree/master/manuscripts/basset</ext-link>) made and recommended by the original author of Basset (D.Kelley, personal communications); this reimplementation is a deep CNN with nine convolutional layers (see Supplementary Fig. 2 for the full details). We (1) generated the datasets by running “make_data.sh” under “manuscripts/basset/” (of this repository), (2) re-trained the original Basset networks by running “python basenji_train.py-k-o train_basset params_basset.json data_basset” under “manuscripts/basset/” (of this repository) to obtain their AUROC values, (3) replaced either the first (‘Single vConv-based’; left figure in Supplementary Fig. 3) or all nine (‘Completed vConv-based’; right figure in Supplementary Fig. 3) convolutional layers in the Basset network with vConv layer(s) and retrained it to obtain the AUROC value of the vConv-based Basset network, and finally (4) compared the AUROC values between the two types of networks. The details of parameter initialization (except for the vConv-exclusive parameters) and stochastic gradient descent-based optimization (with learning rate 0.005) were exactly the same between the vConv-based and the original Basset networks (Supplementary Fig. 2 and 3).</p></sec><sec id="s2d" hwp:id="sec-6"><title hwp:id="title-8">Benchmark vConv-based networks on real-world motif discovery</title><p hwp:id="p-30">Finally, we compared vConv-based networks with the canonical methods on the motif discovery problem. We followed the protocol proposed by Zhang et al. (Zhang, et al., 2015) to assess the accuracy of the extracted representative motifs based on the ENCODE CTCF ChIP-Seq datasets (<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">ENCODE Project Consortium, 2012</xref>). In brief, for each motif discovery tool and each ChIP-Seq dataset, we located the motif-containing sequence fragments for candidate motifs discovered by this tool, checked whether they overlapped with the ChIP-Seq peaks with CisFinder, and reported the largest per-motif ratio of overlapping fragments to all fragments across all candidate motifs as the final accuracy of this tool on this dataset (see Supplementary Fig. 4 for more details). For the sake of demonstrating the advantage of vConv-based networks, here the model structure of the vConv-based network was chosen to be the one used in simulation (Supplementary Fig. 1).</p></sec></sec><sec id="s3" hwp:id="sec-7"><title hwp:id="title-9">Results</title><sec id="s3a" hwp:id="sec-8"><title hwp:id="title-10">vConv-based networks identify motifs more effectively than convolution-based networks</title><p hwp:id="p-31">We first present direct comparisons between vConv-based and convolution-based networks based on multiple simulated datasets (see the Methods for more details). vConv-based networks performed statistically significantly better (with all Wilcoxon rank sum test’s p-values &lt; 1e-18 for the null hypothesis that the AUROC of the vConv-based network is equal to or smaller than that of the convolution-based network), and this improvement became larger when more motifs are introduced (2 motifs to 8 motifs in <xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Fig. 2A</xref>) and with increased heterogeneity of the motif length (2 motifs v.s. TwoDiffMotif1/2/3 in <xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Fig. 2A</xref>); notably, this superior performance gain of vConv-based networks applies to most datasets (Supplementary Fig. 5). In addition, vConv-based networks showed a smaller mean standard error of the AUROC than convolution-based networks across different hyper-parameter settings (Levene’s test, p-value &lt; 0.001 for all datasets; see Supplementary Table 2), suggesting that vConv-based networks also have a better robustness to hyper-parameters than convolution-based networks (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Fig. 2B</xref>).</p><fig id="fig2" position="float" orientation="portrait" fig-type="figure" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;508242v3/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Fig. 2.</label><caption hwp:id="caption-4"><p hwp:id="p-32">vConv-based networks outperformed canonical convolution-based networks for motifs of different lengths on simulation datasets. (A) shows the comparison of overall AUROC distribution for each case between the vConv-based and the convolution-based networks. (B) shows the mean and standard error of per-hyper-parameter-setting AUROC difference between the vConv-based network and the convolution-based network.</p></caption><graphic xlink:href="508242v3_fig2" position="float" orientation="portrait" hwp:id="graphic-8"/></fig><p hwp:id="p-33">We further visualized the first layer of trained vConv-based and convolution-based networks on the most complex dataset (8 motifs), and found that vConv-based networks accurately recovered the underlying real motif from sequences and converge to the real length well (Supplementary Fig. 10). Of note, we found that the vConv-based networks successfully learned a motif (MA0234.1) which was missed by canonical convolution-based networks (Supplementary Fig. 10, second row).</p><p hwp:id="p-34">These findings further compelled us to suspect that vConv-based networks will perform better than convolution-based networks on real-world cases possibly with combinatorial regulation. To test this hypothesis, we examined whether replacing convolutional layer(s) with vConv would improve performance of the following convolution-based networks: (1) DeepBind (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-6" hwp:rel-id="ref-2">Alipanahi, et al., 2015</xref>), a series of DNA-protein-binding classifiers trained for each of 504 ENCODE ChIP-Seq datasets; (2) Zeng et al.’s convolution-based networks (<xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-5" hwp:rel-id="ref-45">Zeng, et al., 2016</xref>), a series of structurally optimized variants of DeepBind models for each of 690 ChIP-Seq datasets; and (3) Basset (<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-3" hwp:rel-id="ref-21">Kelley, et al., 2016</xref>), a complex DNase footprint predictor with nine convolutional layers (see Methods for more details). As expected, vConv-based networks showed a statistically significantly improved performance compared to their convolution-based network counterparts for all these three cases (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Fig. 3</xref> and Supplementary Fig. 6), with a few exceptions some of which can be attributed to small sample size of the input dataset (Supplementary Fig. 7A-B) and disappeared upon additional grid-search on kernel length (Supplementary Fig. 7C). Of note, stacking vConv layers for a complex convolution-based network like Basset can statistically significantly improve the performance with respect to both the original Basset network and the single vConv-based network (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Fig. 3C</xref>), well demonstrating its combined power with the popular hierarchical representation learning strategy in CNN application.</p><fig id="fig3" position="float" orientation="portrait" fig-type="figure" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;508242v3/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Fig. 3.</label><caption hwp:id="caption-5"><p hwp:id="p-35">vConv-based networks outperformed convolution-based networks on real-world cases. (A), comparison of AUROC between vConv-based networks and DeepBindbest networks for DeepBind (see also Supplementary Fig. 6 for comparison with other DeepBind networks). (B), comparison of AUROC between vConv-based networks and networks from Zeng et al.. (C), comparison of AUROC between vConv-based networks with ‘Completed vConv-based’, the vConv-based network with all convolutional layers of Basset network replaced by vConv (right figure in Supplementary Fig. 3; see Methods for more details) and networks from Basset. All p-values shown are from Wilcoxon rank sum test, single-tailed, with the null hypothesis that the AUROC of the vConv-based network is equal to or smaller than that of the convolution-based network. See Methods for more details of each specific network.</p></caption><graphic xlink:href="508242v3_fig3" position="float" orientation="portrait" hwp:id="graphic-9"/></fig></sec><sec id="s3b" hwp:id="sec-9"><title hwp:id="title-11">vConv-based networks discover motifs from real-world sequences more accurately and faster than canonical tools</title><p hwp:id="p-36">We further evaluated vConv-based networks’ performance for <italic toggle="yes">ab initio</italic> motif discovery. In brief, for a particular trained vConv-based network, we first selected kernels with corresponding dense layer weights higher than a predetermined baseline (defined as mean (all dense layer weights) - standard deviation (all dense layer weights)) and then extracted and aligned these kernels’ corresponding segments to compute the representative PWM (<xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Fig. 4A</xref>). We then compared the accuracy of recovering ChIP-Seq peaks by the vConv-based motif discovery and other motif discovery tools across all these ChIP-Seq datasets (<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-2" hwp:rel-id="ref-13">ENCODE Project Consortium, 2012</xref>) (see the Methods for details).</p><fig id="fig4" position="float" orientation="portrait" fig-type="figure" hwp:id="F4" hwp:rev-id="xref-fig-4-1 xref-fig-4-2 xref-fig-4-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;508242v3/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Fig. 4.</label><caption hwp:id="caption-6"><p hwp:id="p-37">vConv-based networks discover motifs more accurately and faster. (A) shows the process of calling a representative motif from a trained vConv-based network. (B) shows the difference in accuracy, defined as the accuracy of vConv-based motif discovery minus the accuracy of the motif discovery algorithm shown on the x-axis on the same dataset. MEME (<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-2" hwp:rel-id="ref-5">Bailey, et al., 2006</xref>) failed to complete the discovery within a reasonable time (~50% datasets remained unfinished even after running for 1.5 weeks with 2,000 cores, amounting to 504,000 CPU hours) for these datasets, and its results were thus not listed here. (C) shows the time cost of each motif discovery algorithm as a function of millions of base pairs in the dataset tested.</p></caption><graphic xlink:href="508242v3_fig4" position="float" orientation="portrait" hwp:id="graphic-10"/></fig><p hwp:id="p-38">Out of all 100 CTCF datasets, the vConv-based network outperformed DREME (<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-2" hwp:rel-id="ref-4">Bailey, 2011</xref>) on all datasets, CisFinder (<xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-2" hwp:rel-id="ref-35">Sharov and Ko, 2009</xref>) on 95 datasets and MEME-ChIP (<xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-2" hwp:rel-id="ref-32">Machanick and Bailey, 2011</xref>) on 87 datasets (<xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-2" hwp:rel-id="F4">Fig. 4B</xref>). In addition, the vConv-based network ran much faster than DREME and MEME-ChIP on large datasets (more than 17 million base pairs finished in less than 30 minutes compared to hours by DREME and MEME-ChIP’s; see <xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-3" hwp:rel-id="F4">Fig. 4C</xref>).</p></sec></sec><sec id="s4" hwp:id="sec-10"><title hwp:id="title-12">Discussion</title><p hwp:id="p-39">Inspired by the theoretical model (Supplementary Notes 1) for analyzing the influence of the kernel size in the convolutional layer, we designed and implemented a novel convolutional layer, vConv, which adaptively tunes the kernel lengths at run time. vConv could be readily integrated into multi-layer neural networks, as an “in-place replacement” of canonical convolutional layer. To facilitate its application in various fields, we have implemented vConv as a new type of convolutional layer in Keras (<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/gao-lab/vConv" ext-link-type="uri" xlink:href="https://github.com/gao-lab/vConv" hwp:id="ext-link-9">https://github.com/gao-lab/vConv</ext-link>).</p><p hwp:id="p-40">In theory, a regular fixed-length convolution kernel with size larger than that of the <italic toggle="yes">bona fide</italic> motif, may be able to converge to a solution where the kernel captures the motif faithfully with zero padding everywhere else, just as what the vConv kernel does. Nevertheless, preliminary empirical evaluations suggest that such “perfect” solution could be very rare in reality with a general training strategy: none of the convolution-based network kernels similar to the ground truth motifs in the 8 motifs case (as determined by Tomtom; see Supplementary Fig. 10) contains more than 1 position whose sum of absolute elements are one order of magnitude more closer to 0 than other positions.</p><p hwp:id="p-41">vConv is scalable considering the fact that its current design only adds a <italic toggle="yes">O</italic>(<italic toggle="yes">ncl</italic>) per <italic toggle="yes">n</italic>-kernel-convolutional layer (with kernel length <italic toggle="yes">l</italic> and number of channels <italic toggle="yes">c</italic>) replaced to the overall time complexity than of the canonical fixed-kernel convolutional layer, and that preliminary empirical evaluations suggest no evidence of convergence slowdown (as benchmarked in Supplementary Fig. 8 for the simulation case). While we notice that the current variable-length kernel strategy implemented by vConv could, in theory, be approximated by combing multiple fixed-length-kernel networks, we’d argue that such approximation would lead to serious inflation for the number of trainable parameters, and higher time cost for training and optimization. For example, to approximate a simple network with one vConv layer of <italic toggle="yes">n</italic> unmasked kernels with average length <italic toggle="yes">l</italic> (which needs <italic toggle="yes">n</italic>*(4*<italic toggle="yes">l</italic>+2)+<italic toggle="yes">n</italic> = <italic toggle="yes">n</italic>*(4*<italic toggle="yes">l</italic>+3) parameters), the ensemble of <italic toggle="yes">m</italic> convolution-based networks would take <italic toggle="yes">m</italic>*(<italic toggle="yes">n</italic>*(4*<italic toggle="yes">l</italic>)+<italic toggle="yes">n</italic>) = <italic toggle="yes">m</italic>*(<italic toggle="yes">n</italic>*(4*<italic toggle="yes">l</italic>+1)) parameters, far larger than <italic toggle="yes">n</italic>*(4*<italic toggle="yes">l</italic>+3) when <italic toggle="yes">m</italic> is of tens or hundreds - a popular choice in ensemble learning.</p><p hwp:id="p-42">vConv-based networks show robustness with various hyper-parameters and initialization setups (Supplementary Table 2). We believe that the major vConv-exclusive components, Shannon loss (MSL) and boundary parameters, contribute to the increased robustness. Intutively, such components could regularize the parameters to learn, making the overall objective function simpler (i.e., having fewer suboptima) and thus more robust. Consistently, we found out that the vConv-based network -- when equipped with MSL -- had a smaller variance of AUROC that is statistically significantly different from that of the vConv-based network without MSL in 3 out of all 7 simulation cases (Levene’s test, p&lt;0.001; Supplementary Table 3), suggesting that MSL does contribute to this increased robustness in certain conditions. Of interest, equipping MSL also improved the AUROC of the vConv-based network (Supplementary Fig. 9).</p><sec id="s4a" hwp:id="sec-11"><title hwp:id="title-13">Further work</title><p hwp:id="p-43">We note that the current theoretical analysis (see details in Supplementary Notes 1) reported above relies on prior knowledge of the real motif <inline-formula hwp:id="inline-formula-25"><alternatives hwp:id="alternatives-29"><inline-graphic xlink:href="508242v3_inline24.gif" hwp:id="inline-graphic-25"/></alternatives></inline-formula>, which may not be feasible to obtain for real-world datasets. A possible workaround is to estimate the empirical null distribution of <italic toggle="yes">P<sub>real</sub></italic> over a set of randomly initialized PWMs and kernels and then derive the expectation of <italic toggle="yes">P<sub>real</sub></italic> over the given dataset. Such theoretical distribution, once established, could serve as a general background distribution for further development of motif scanners.</p><p hwp:id="p-44">Moreover, although current motifs in convolution-based networks are automatically represented by PWMs, this might be an oversimplified representation of the genuine motifs, which may allow insertions and deletions within motifs (e.g., the HMM motifs from Pfam (<xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">El-Gebali, et al., 2018</xref>) and Rfam (<xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">Kalvari, et al., 2017</xref>)). While recurrent neural networks have been expected to be able to learn such motifs (<xref ref-type="bibr" rid="c29" hwp:id="xref-ref-29-1" hwp:rel-id="ref-29">Liu, 2017</xref>; <xref ref-type="bibr" rid="c30" hwp:id="xref-ref-30-1" hwp:rel-id="ref-30">Liza and Grzes, 2019</xref>; <xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">Min, et al., 2019</xref>; <xref ref-type="bibr" rid="c40" hwp:id="xref-ref-40-1" hwp:rel-id="ref-40">Vazhayil and KP, 2018</xref>), the interpretation of such models is still challenging. A promising alternative would be to use the CNN framework to learn complex motifs directly, as demonstrated by a recently developed CNN model HOCNNLB (<xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-1" hwp:rel-id="ref-48">Zhang, et al., 2019</xref>) which can learn first-order Markov models by re-encoding input sequences. Combining the variable-length nature of vConv and such complex-motif-capturing models might be much more useful for mining biological motifs.</p></sec></sec><sec sec-type="supplementary-material" hwp:id="sec-12"><title hwp:id="title-14">Supporting information</title><supplementary-material position="float" orientation="portrait" hwp:id="DC1"><object-id pub-id-type="other" hwp:sub-type="slug">DC1</object-id><label>supplementary files</label><media xlink:href="supplements/508242_file02.pdf" position="float" orientation="portrait" hwp:id="media-1"/></supplementary-material></sec></body><back><sec hwp:id="sec-13"><title hwp:id="title-15">Funding</title><p hwp:id="p-45">This work was supported by funds from the National Key Research and Development Program (2016YFC0901603), the China 863 Program (2015AA020108), as well as the State Key Laboratory of Protein and Plant Gene Research and the Beijing Advanced Innovation Center for Genomics (ICG) at Peking University. The research of G.G. was supported in part by the National Program for the Support of Top-notch Young Professionals.</p></sec><ack hwp:id="ack-1"><title hwp:id="title-16">Acknowledgments</title><p hwp:id="p-46">The authors would like to thank Drs. Cheng Li, Letian Tao, Minghua Deng, Zemin Zhang, Jian Lu and Liping Wei at Peking University for their helpful comments and suggestions during the study. The analysis was supported by the High-performance Computing Platform of Peking University, and we thank Dr. Chun Fan and Yin-Ping Ma for their assistance during the analysis.</p></ack><ref-list hwp:id="ref-list-1"><title hwp:id="title-17">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Achar A."><surname>Achar</surname>, <given-names>A.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Sætrom P."><surname>Sætrom</surname>, <given-names>P.</given-names></string-name> <article-title hwp:id="article-title-2">RNA motif discovery: a computational overview</article-title>. <source hwp:id="source-1">Biology direct</source> <year>2015</year>;<volume>10</volume>(<issue>1</issue>):<fpage>61</fpage>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1 xref-ref-2-2 xref-ref-2-3 xref-ref-2-4 xref-ref-2-5 xref-ref-2-6"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Alipanahi B."><surname>Alipanahi</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Delong A."><surname>Delong</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Weirauch M.T."><surname>Weirauch</surname>, <given-names>M.T.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Frey B.J."><surname>Frey</surname>, <given-names>B.J.</given-names></string-name> <article-title hwp:id="article-title-3">Predicting the sequence specificities of DNA-and RNA-binding proteins by deep learning</article-title>. <source hwp:id="source-2">Nature biotechnology</source> <year>2015</year>;<volume>33</volume>(<issue>8</issue>):<fpage>831</fpage>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Angermueller C."><surname>Angermueller</surname>, <given-names>C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lee H.J."><surname>Lee</surname>, <given-names>H.J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Reik W."><surname>Reik</surname>, <given-names>W.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Stegle O."><surname>Stegle</surname>, <given-names>O.</given-names></string-name> <article-title hwp:id="article-title-4">DeepCpG: accurate prediction of single-cell DNA methylation states using deep learning</article-title>. <source hwp:id="source-3">Genome biology</source> <year>2017</year>;<volume>18</volume>(<issue>1</issue>):<fpage>67</fpage>.</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1 xref-ref-4-2"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Bailey T.L."><surname>Bailey</surname>, <given-names>T.L.</given-names></string-name> <article-title hwp:id="article-title-5">DREME: motif discovery in transcription factor ChIP-seq data</article-title>. <source hwp:id="source-4">Bioinformatics</source> <year>2011</year>;<volume>27</volume>(<issue>12</issue>):<fpage>1653</fpage>–<lpage>1659</lpage>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1 xref-ref-5-2"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Bailey T.L."><surname>Bailey</surname>, <given-names>T.L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Williams N."><surname>Williams</surname>, <given-names>N.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Misleh C."><surname>Misleh</surname>, <given-names>C.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Li W.W."><surname>Li</surname>, <given-names>W.W.</given-names></string-name> <article-title hwp:id="article-title-6">MEME: discovering and analyzing DNA and protein sequence motifs</article-title>. <source hwp:id="source-5">Nucleic acids research</source> <year>2006</year>;<volume>34</volume>(<issue>suppl_2</issue>):<fpage>W369</fpage>–<lpage>W373</lpage>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Blencowe B.J."><surname>Blencowe</surname>, <given-names>B.J.</given-names></string-name> <article-title hwp:id="article-title-7">Exonic splicing enhancers: mechanism of action, diversity and role in human genetic diseases</article-title>. <source hwp:id="source-6">Trends in biochemical sciences</source> <year>2000</year>;<volume>25</volume>(<issue>3</issue>):<fpage>106</fpage>–<lpage>110</lpage>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1"><citation publication-type="other" citation-type="journal" ref:id="508242v3.7" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Chollet F."><surname>Chollet</surname>, <given-names>F.</given-names></string-name>, others. <source hwp:id="source-7">Keras</source>. <year>2015</year>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1 xref-ref-8-2"><citation publication-type="book" citation-type="book" ref:id="508242v3.8" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Das M.K."><surname>Das</surname>, <given-names>M.K.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Dai H.-K."><surname>Dai</surname>, <given-names>H.-K.</given-names></string-name> <chapter-title>A survey of DNA motif finding algorithms</chapter-title>. In, <source hwp:id="source-8">BMC bioinformatics</source>. <publisher-name>Springer</publisher-name>; <year>2007</year>. p. <fpage>S21</fpage>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Ding J."><surname>Ding</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dhillon V."><surname>Dhillon</surname>, <given-names>V.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Li X."><surname>Li</surname>, <given-names>X.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Hu H."><surname>Hu</surname>, <given-names>H.</given-names></string-name> <article-title hwp:id="article-title-8">Systematic discovery of cofactor motifs from ChIP-seq data by SIOMICS</article-title>. <source hwp:id="source-9">Methods</source> <year>2015</year>;<volume>79</volume>:<fpage>47</fpage>–<lpage>51</lpage>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Ding J."><surname>Ding</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hu H."><surname>Hu</surname>, <given-names>H.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Li X."><surname>Li</surname>, <given-names>X.</given-names></string-name> <article-title hwp:id="article-title-9">SIOMICS: a novel approach for systematic identification of motifs in ChIP-seq data</article-title>. <source hwp:id="source-10">Nucleic acids research</source> <year>2014</year>;<volume>42</volume>(<issue>5</issue>):<fpage>e35</fpage>–<lpage>e35</lpage>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><citation publication-type="other" citation-type="journal" ref:id="508242v3.11" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Ding Y."><surname>Ding</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Li J.-Y."><surname>Li</surname>, <given-names>J.-Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wang M."><surname>Wang</surname>, <given-names>M.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Gao G."><surname>Gao</surname>, <given-names>G.</given-names></string-name> <article-title hwp:id="article-title-10">An exact transformation of convolutional kernels enables accurate identification of sequence motifs</article-title>. <source hwp:id="source-11">bioRxiv</source> <year>2018</year>:<fpage>163220</fpage>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.12" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="El-Gebali S."><surname>El-Gebali</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mistry J."><surname>Mistry</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bateman A."><surname>Bateman</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Eddy S.R."><surname>Eddy</surname>, <given-names>S.R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Luciani A."><surname>Luciani</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Potter S.C."><surname>Potter</surname>, <given-names>S.C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Qureshi M."><surname>Qureshi</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Richardson L.J."><surname>Richardson</surname>, <given-names>L.J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Salazar G.A."><surname>Salazar</surname>, <given-names>G.A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Smart A."><surname>Smart</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sonnhammer E.L L."><surname>Sonnhammer</surname>, <given-names>E.L L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hirsh L."><surname>Hirsh</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Paladin L."><surname>Paladin</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Piovesan D."><surname>Piovesan</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tosatto S."><surname>Tosatto</surname>, <given-names>S.</given-names></string-name>C E. and <string-name name-style="western" hwp:sortable="Finn R.D."><surname>Finn</surname>, <given-names>R.D.</given-names></string-name> <article-title hwp:id="article-title-11">The Pfam protein families database in 2019</article-title>. <source hwp:id="source-12">Nucleic Acids Research</source> <year>2018</year>;<volume>47</volume>(<issue>D1</issue>):<fpage>D427</fpage>–<lpage>D432</lpage>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1 xref-ref-13-2"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><collab hwp:id="collab-1">ENCODE Project Consortium</collab>. <article-title hwp:id="article-title-12">An integrated encyclopedia of DNA elements in the human genome</article-title>. <source hwp:id="source-13">Nature</source> <year>2012</year>;<volume>489</volume>(<issue>7414</issue>):<fpage>57</fpage>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><citation publication-type="confproc" citation-type="confproc" ref:id="508242v3.14" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Glorot X."><surname>Glorot</surname>, <given-names>X.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Bengio Y."><surname>Bengio</surname>, <given-names>Y.</given-names></string-name> <article-title hwp:id="article-title-13">Understanding the difficulty of training deep feedforward neural networks</article-title>. In: <person-group person-group-type="editor" hwp:id="person-group-1"><string-name name-style="western" hwp:sortable="Yee Whye T."><surname>Yee Whye</surname>, <given-names>T.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Mike T."><surname>Mike</surname>, <given-names>T.</given-names></string-name></person-group>, editors, <conf-name>Proceedings of the Thirteenth International Conference on Artificial Intelligence and Statistics</conf-name>. <source hwp:id="source-14">Proceedings of Machine Learning Research: PMLR</source>; <year>2010</year>. p. <fpage>249</fpage>–<lpage>256</lpage>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><citation publication-type="confproc" citation-type="confproc" ref:id="508242v3.15" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Han S."><surname>Han</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Meng Z."><surname>Meng</surname>, <given-names>Z.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Li Z."><surname>Li</surname>, <given-names>Z.</given-names></string-name>, <string-name name-style="western" hwp:sortable="O’Reilly J."><surname>O’Reilly</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cai J."><surname>Cai</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wang X."><surname>Wang</surname>, <given-names>X.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Tong Y."><surname>Tong</surname>, <given-names>Y.</given-names></string-name> <article-title hwp:id="article-title-14">Optimizing filter size in convolutional neural networks for facial action unit recognition</article-title>. In, <conf-name>Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition</conf-name>. <year>2018</year>. p. <fpage>5070</fpage>–<lpage>5078</lpage>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Ikebata H."><surname>Ikebata</surname>, <given-names>H.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Yoshida R."><surname>Yoshida</surname>, <given-names>R.</given-names></string-name> <article-title hwp:id="article-title-15">Repulsive parallel MCMC algorithm for discovering diverse motifs from large sequence sets</article-title>. <source hwp:id="source-15">Bioinformatics</source> <year>2015</year>;<volume>31</volume>(<issue>10</issue>):<fpage>1561</fpage>–<lpage>1568</lpage>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.17" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Jia C."><surname>Jia</surname>, <given-names>C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Carson M.B."><surname>Carson</surname>, <given-names>M.B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wang Y."><surname>Wang</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lin Y."><surname>Lin</surname>, <given-names>Y.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Lu H."><surname>Lu</surname>, <given-names>H.</given-names></string-name> <article-title hwp:id="article-title-16">A new exhaustive method and strategy for finding motifs in ChIP-enriched regions</article-title>. <source hwp:id="source-16">PLoS One</source> <year>2014</year>;<volume>9</volume>(<issue>1</issue>).</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Kadonaga J.T."><surname>Kadonaga</surname>, <given-names>J.T.</given-names></string-name> <article-title hwp:id="article-title-17">Perspectives on the RNA polymerase II core promoter</article-title>. <source hwp:id="source-17">Wiley Interdisciplinary Reviews: Developmental Biology</source> <year>2012</year>;<volume>1</volume>(<issue>1</issue>):<fpage>40</fpage>–<lpage>51</lpage>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Kalvari I."><surname>Kalvari</surname>, <given-names>I.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Argasinska J."><surname>Argasinska</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Quinones-Olvera N."><surname>Quinones-Olvera</surname>, <given-names>N.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Nawrocki E.P."><surname>Nawrocki</surname>, <given-names>E.P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rivas E."><surname>Rivas</surname>, <given-names>E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Eddy S.R."><surname>Eddy</surname>, <given-names>S.R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bateman A."><surname>Bateman</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Finn R.D."><surname>Finn</surname>, <given-names>R.D.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Petrov A.I."><surname>Petrov</surname>, <given-names>A.I.</given-names></string-name> <article-title hwp:id="article-title-18">Rfam 13.0: shifting to a genome-centric resource for non-coding RNA families</article-title>. <source hwp:id="source-18">Nucleic Acids Research</source> <year>2017</year>;<volume>46</volume>(<issue>D1</issue>):<fpage>D335</fpage>–<lpage>D342</lpage>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1 xref-ref-20-2 xref-ref-20-3"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Kelley D.R."><surname>Kelley</surname>, <given-names>D.R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Reshef Y.A."><surname>Reshef</surname>, <given-names>Y.A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bileschi M."><surname>Bileschi</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Belanger D."><surname>Belanger</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="McLean C.Y."><surname>McLean</surname>, <given-names>C.Y.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Snoek J."><surname>Snoek</surname>, <given-names>J.</given-names></string-name> <article-title hwp:id="article-title-19">Sequential regulatory activity prediction across chromosomes with convolutional neural networks</article-title>. <source hwp:id="source-19">Genome research</source> <year>2018</year>;<volume>28</volume>(<issue>5</issue>):<fpage>739</fpage>–<lpage>750</lpage>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1 xref-ref-21-2 xref-ref-21-3"><citation publication-type="other" citation-type="journal" ref:id="508242v3.21" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Kelley D.R."><surname>Kelley</surname>, <given-names>D.R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Snoek J."><surname>Snoek</surname>, <given-names>J.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Rinn J.L."><surname>Rinn</surname>, <given-names>J.L.</given-names></string-name> <article-title hwp:id="article-title-20">Basset: learning the regulatory code of the accessible genome with deep convolutional neural networks</article-title>. <source hwp:id="source-20">Genome research</source> <year>2016</year>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Khan A."><surname>Khan</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fornes O."><surname>Fornes</surname>, <given-names>O.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Stigliani A."><surname>Stigliani</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gheorghe M."><surname>Gheorghe</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Castro-Mondragon J.A."><surname>Castro-Mondragon</surname>, <given-names>J.A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="van der Lee R."><surname>van der Lee</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bessy A."><surname>Bessy</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cheneby J."><surname>Cheneby</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kulkarni S.R."><surname>Kulkarni</surname>, <given-names>S.R.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Tan G."><surname>Tan</surname>, <given-names>G.</given-names></string-name> <article-title hwp:id="article-title-21">JASPAR 2018: update of the open-access database of transcription factor binding profiles and its web framework</article-title>. <source hwp:id="source-21">Nucleic acids research</source> <year>2017</year>;<volume>46</volume>(<issue>D1</issue>):<fpage>D260</fpage>–<lpage>D266</lpage>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1 xref-ref-23-2"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Koo P.K."><surname>Koo</surname>, <given-names>P.K.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Eddy S.R."><surname>Eddy</surname>, <given-names>S.R.</given-names></string-name> <article-title hwp:id="article-title-22">Representation learning of genomic sequence motifs with convolutional neural networks</article-title>. <source hwp:id="source-22">PLoS computational biology</source> <year>2019</year>;<volume>15</volume>(<issue>12</issue>):<fpage>e1007560</fpage>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Kulakovskiy I.V."><surname>Kulakovskiy</surname>, <given-names>I.V.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Boeva V."><surname>Boeva</surname>, <given-names>V.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Favorov A.V."><surname>Favorov</surname>, <given-names>A.V.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Makeev V.J."><surname>Makeev</surname>, <given-names>V.J.</given-names></string-name> <article-title hwp:id="article-title-23">Deep and wide digging for binding motifs in ChIP-Seq data</article-title>. <source hwp:id="source-23">Bioinformatics</source> <year>2010</year>;<volume>26</volume>(<issue>20</issue>):<fpage>2622</fpage>–<lpage>2623</lpage>.</citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1"><citation publication-type="book" citation-type="book" ref:id="508242v3.25" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Kulakovskiy I.V."><surname>Kulakovskiy</surname>, <given-names>I.V.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Makeev V.J."><surname>Makeev</surname>, <given-names>V.J.</given-names></string-name> <chapter-title>DNA sequence motif: a jack of all trades for ChIP-Seq data</chapter-title>. In, <source hwp:id="source-24">Advances in protein chemistry and structural biology</source>. <publisher-name>Elsevier</publisher-name>; <year>2013</year>. p. <fpage>135</fpage>–<lpage>171</lpage>.</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.26" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Lambert S.A."><surname>Lambert</surname>, <given-names>S.A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jolma A."><surname>Jolma</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Campitelli L.F."><surname>Campitelli</surname>, <given-names>L.F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Das P.K."><surname>Das</surname>, <given-names>P.K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Yin Y."><surname>Yin</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Albu M."><surname>Albu</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chen X."><surname>Chen</surname>, <given-names>X.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Taipale J."><surname>Taipale</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hughes T.R."><surname>Hughes</surname>, <given-names>T.R.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Weirauch M.T.J.C."><surname>Weirauch</surname>, <given-names>M.T.J.C.</given-names></string-name> <source hwp:id="source-25">The human transcription factors</source>. <year>2018</year>;<volume>172</volume>(<issue>4</issue>):<fpage>650</fpage>–<lpage>665</lpage>.</citation></ref><ref id="c27" hwp:id="ref-27" hwp:rev-id="xref-ref-27-1 xref-ref-27-2"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.27" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Lihu A."><surname>Lihu</surname>, <given-names>A.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Holban Ş."><surname>Holban</surname>, <given-names>Ş.</given-names></string-name> <article-title hwp:id="article-title-24">A review of ensemble methods for de novo motif discovery in ChIP-Seq data</article-title>. <source hwp:id="source-26">Briefings in bioinformatics</source> <year>2015</year>;<volume>16</volume>(<issue>6</issue>):<fpage>964</fpage>–<lpage>973</lpage>.</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.28" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Liu B."><surname>Liu</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Yang J."><surname>Yang</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Li Y."><surname>Li</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="McDermaid A."><surname>McDermaid</surname>, <given-names>A.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Ma Q."><surname>Ma</surname>, <given-names>Q.</given-names></string-name> <article-title hwp:id="article-title-25">An algorithmic perspective of de novo cis-regulatory motif finding based on ChIP-seq data</article-title>. <source hwp:id="source-27">Briefings in bioinformatics</source> <year>2018</year>;<volume>19</volume>(<issue>5</issue>):<fpage>1069</fpage>–<lpage>1081</lpage>.</citation></ref><ref id="c29" hwp:id="ref-29" hwp:rev-id="xref-ref-29-1"><citation publication-type="other" citation-type="journal" ref:id="508242v3.29" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="Liu X."><surname>Liu</surname>, <given-names>X.</given-names></string-name> <article-title hwp:id="article-title-26">Deep recurrent neural network for protein function prediction from sequence</article-title>. <source hwp:id="source-28">arXiv preprint</source> arXiv:<pub-id pub-id-type="arxiv">1701.08318</pub-id> <year>2017</year>.</citation></ref><ref id="c30" hwp:id="ref-30" hwp:rev-id="xref-ref-30-1"><citation publication-type="other" citation-type="journal" ref:id="508242v3.30" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="Liza F.F."><surname>Liza</surname>, <given-names>F.F.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Grzes M."><surname>Grzes</surname>, <given-names>M.</given-names></string-name> <article-title hwp:id="article-title-27">Relating RNN layers with the spectral WFA ranks in sequence modelling</article-title>. <source hwp:id="source-29">Association for Computational Linguistics</source> <year>2019</year>.</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="Maaskola J."><surname>Maaskola</surname>, <given-names>J.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Rajewsky N."><surname>Rajewsky</surname>, <given-names>N.</given-names></string-name> <article-title hwp:id="article-title-28">Binding site discovery from nucleic acid sequences by discriminative learning of hidden Markov models</article-title>. <source hwp:id="source-30">Nucleic acids research</source> <year>2014</year>;<volume>42</volume>(<issue>21</issue>):<fpage>12995</fpage>–<lpage>13011</lpage>.</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1 xref-ref-32-2"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.32" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="Machanick P."><surname>Machanick</surname>, <given-names>P.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Bailey T.L."><surname>Bailey</surname>, <given-names>T.L.</given-names></string-name> <article-title hwp:id="article-title-29">MEME-ChIP: motif analysis of large DNA datasets</article-title>. <source hwp:id="source-31">Bioinformatics</source> <year>2011</year>;<volume>27</volume>(<issue>12</issue>):<fpage>1696</fpage>–<lpage>1697</lpage>.</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1"><citation publication-type="other" citation-type="journal" ref:id="508242v3.33" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Min S."><surname>Min</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Park S."><surname>Park</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kim S."><surname>Kim</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Choi H.-S."><surname>Choi</surname>, <given-names>H.-S.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Yoon S."><surname>Yoon</surname>, <given-names>S.</given-names></string-name> <article-title hwp:id="article-title-30">Pre-Training of Deep Bidirectional Protein Sequence Representations with Structural Information</article-title>. <source hwp:id="source-32">arXiv preprint</source> arXiv:<pub-id pub-id-type="arxiv">1912.05625</pub-id> <year>2019</year>.</citation></ref><ref id="c34" hwp:id="ref-34" hwp:rev-id="xref-ref-34-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.34" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Reiter F."><surname>Reiter</surname>, <given-names>F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wienerroither S."><surname>Wienerroither</surname>, <given-names>S.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Stark A."><surname>Stark</surname>, <given-names>A.</given-names></string-name> <article-title hwp:id="article-title-31">Combinatorial function of transcription factors and cofactors</article-title>. <source hwp:id="source-33">Curr Opin Genet Dev</source> <year>2017</year>;<volume>43</volume>:<fpage>73</fpage>–<lpage>81</lpage>.</citation></ref><ref id="c35" hwp:id="ref-35" hwp:rev-id="xref-ref-35-1 xref-ref-35-2"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.35" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Sharov A.A."><surname>Sharov</surname>, <given-names>A.A.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Ko M.S."><surname>Ko</surname>, <given-names>M.S.</given-names></string-name> <article-title hwp:id="article-title-32">Exhaustive search for over-represented DNA sequence motifs with CisFinder</article-title>. <source hwp:id="source-34">DNA research</source> <year>2009</year>;<volume>16</volume>(<issue>5</issue>):<fpage>261</fpage>–<lpage>273</lpage>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.36" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Stormo G.D."><surname>Stormo</surname>, <given-names>G.D.</given-names></string-name> <article-title hwp:id="article-title-33">DNA motif databases and their uses</article-title>. <source hwp:id="source-35">Current protocols in bioinformatics</source> <year>2015</year>;<volume>51</volume>(<issue>1</issue>):<fpage>2.15. 11</fpage>–<lpage>12.15. 16</lpage>.</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.37" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Thomas-Chollier M."><surname>Thomas-Chollier</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Herrmann C."><surname>Herrmann</surname>, <given-names>C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Defrance M."><surname>Defrance</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sand O."><surname>Sand</surname>, <given-names>O.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Thieffry D."><surname>Thieffry</surname>, <given-names>D.</given-names></string-name> and <string-name name-style="western" hwp:sortable="van Helden J."><surname>van Helden</surname>, <given-names>J.</given-names></string-name> <article-title hwp:id="article-title-34">RSAT peak-motifs: motif analysis in full-size ChIP-seq datasets</article-title>. <source hwp:id="source-36">Nucleic acids research</source> <year>2012</year>;<volume>40</volume>(<issue>4</issue>):<fpage>e31</fpage>–<lpage>e31</lpage>.</citation></ref><ref id="c38" hwp:id="ref-38" hwp:rev-id="xref-ref-38-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.38" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-38"><string-name name-style="western" hwp:sortable="Thomson D.W."><surname>Thomson</surname>, <given-names>D.W.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Dinger M.E."><surname>Dinger</surname>, <given-names>M.E.</given-names></string-name> <article-title hwp:id="article-title-35">Endogenous microRNA sponges: evidence and controversy</article-title>. <source hwp:id="source-37">Nature Reviews Genetics</source> <year>2016</year>;<volume>17</volume>(<issue>5</issue>):<fpage>272</fpage>.</citation></ref><ref id="c39" hwp:id="ref-39" hwp:rev-id="xref-ref-39-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.39" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-39"><string-name name-style="western" hwp:sortable="Tran N.T.L."><surname>Tran</surname>, <given-names>N.T.L.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Huang C.-H."><surname>Huang</surname>, <given-names>C.-H.</given-names></string-name> <article-title hwp:id="article-title-36">A survey of motif finding Web tools for detecting binding site motifs in ChIP-Seq data</article-title>. <source hwp:id="source-38">Biology direct</source> <year>2014</year>;<volume>9</volume>(<issue>1</issue>):<fpage>4</fpage>.</citation></ref><ref id="c40" hwp:id="ref-40" hwp:rev-id="xref-ref-40-1"><citation publication-type="other" citation-type="journal" ref:id="508242v3.40" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-40"><string-name name-style="western" hwp:sortable="Vazhayil A."><surname>Vazhayil</surname>, <given-names>A.</given-names></string-name> and <string-name name-style="western" hwp:sortable="kp S."><surname>kp</surname>, <given-names>S.</given-names></string-name> <article-title hwp:id="article-title-37">DeepProteomics: Protein family classification using Shallow and Deep Networks</article-title>. <source hwp:id="source-39">arXiv preprint</source> arXiv:<pub-id pub-id-type="arxiv">1809.04461</pub-id> <year>2018</year>.</citation></ref><ref id="c41" hwp:id="ref-41" hwp:rev-id="xref-ref-41-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.41" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-41"><string-name name-style="western" hwp:sortable="Wang M."><surname>Wang</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tai C."><surname>Tai</surname>, <given-names>C.</given-names></string-name>, E, W. and <string-name name-style="western" hwp:sortable="Wei L."><surname>Wei</surname>, <given-names>L.</given-names></string-name> <article-title hwp:id="article-title-38">DeFine: deep convolutional neural networks accurately quantify intensities of transcription factor-DNA binding and facilitate evaluation of functional non-coding variants</article-title>. <source hwp:id="source-40">Nucleic acids research</source> <year>2018</year>;<volume>46</volume>(<issue>11</issue>):<fpage>e69</fpage>–<lpage>e69</lpage>.</citation></ref><ref id="c42" hwp:id="ref-42" hwp:rev-id="xref-ref-42-1 xref-ref-42-2"><citation publication-type="other" citation-type="journal" ref:id="508242v3.42" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-42"><string-name name-style="western" hwp:sortable="Yin W."><surname>Yin</surname>, <given-names>W.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Schütze H."><surname>Schütze</surname>, <given-names>H.</given-names></string-name> <article-title hwp:id="article-title-39">Multichannel variable-size convolution for sentence classification</article-title>. <source hwp:id="source-41">arXiv preprint</source> arXiv:<pub-id pub-id-type="arxiv">1603.04513</pub-id> <year>2016</year>.</citation></ref><ref id="c43" hwp:id="ref-43" hwp:rev-id="xref-ref-43-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.43" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-43"><string-name name-style="western" hwp:sortable="Zambelli F."><surname>Zambelli</surname>, <given-names>F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pesole G."><surname>Pesole</surname>, <given-names>G.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Pavesi G."><surname>Pavesi</surname>, <given-names>G.</given-names></string-name> <article-title hwp:id="article-title-40">Motif discovery and transcription factor binding sites before and after the next-generation sequencing era</article-title>. <source hwp:id="source-42">Briefings in bioinformatics</source> <year>2013</year>;<volume>14</volume>(<issue>2</issue>):<fpage>225</fpage>–<lpage>237</lpage>.</citation></ref><ref id="c44" hwp:id="ref-44" hwp:rev-id="xref-ref-44-1"><citation publication-type="other" citation-type="journal" ref:id="508242v3.44" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-44"><string-name name-style="western" hwp:sortable="Zeiler M.D."><surname>Zeiler</surname>, <given-names>M.D.</given-names></string-name> <article-title hwp:id="article-title-41">Adadelta: an adaptive learning rate method</article-title>. <source hwp:id="source-43">arXiv preprint</source> arXiv:<pub-id pub-id-type="arxiv">1212.5701</pub-id> <year>2012</year>.</citation></ref><ref id="c45" hwp:id="ref-45" hwp:rev-id="xref-ref-45-1 xref-ref-45-2 xref-ref-45-3 xref-ref-45-4 xref-ref-45-5"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.45" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-45"><string-name name-style="western" hwp:sortable="Zeng H."><surname>Zeng</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Edwards M.D."><surname>Edwards</surname>, <given-names>M.D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Liu G."><surname>Liu</surname>, <given-names>G.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Gifford D.K."><surname>Gifford</surname>, <given-names>D.K.</given-names></string-name> <article-title hwp:id="article-title-42">Convolutional neural network architectures for predicting DNA–protein binding</article-title>. <source hwp:id="source-44">Bioinformatics</source> <year>2016</year>;<volume>32</volume>(<issue>12</issue>):<fpage>i121</fpage>–<lpage>i127</lpage>.</citation></ref><ref id="c46" hwp:id="ref-46" hwp:rev-id="xref-ref-46-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.46" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-46"><string-name name-style="western" hwp:sortable="Zhang B."><surname>Zhang</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gunawardane L."><surname>Gunawardane</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Niazi F."><surname>Niazi</surname>, <given-names>F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jahanbani F."><surname>Jahanbani</surname>, <given-names>F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chen X."><surname>Chen</surname>, <given-names>X.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Valadkhan S."><surname>Valadkhan</surname>, <given-names>S.</given-names></string-name> <article-title hwp:id="article-title-43">A novel RNA motif mediates the strict nuclear localization of a long noncoding RNA</article-title>. <source hwp:id="source-45">Molecular and cellular biology</source> <year>2014</year>;<volume>34</volume>(<issue>12</issue>):<fpage>2318</fpage>–<lpage>2329</lpage>.</citation></ref><ref id="c47" hwp:id="ref-47" hwp:rev-id="xref-ref-47-1 xref-ref-47-2"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.47" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-47"><string-name name-style="western" hwp:sortable="Zhang J."><surname>Zhang</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Peng W."><surname>Peng</surname>, <given-names>W.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Wang L."><surname>Wang</surname>, <given-names>L.</given-names></string-name> <article-title hwp:id="article-title-44">LeNup: learning nucleosome positioning from DNA sequences with improved convolutional neural networks</article-title>. <source hwp:id="source-46">Bioinformatics</source> <year>2018</year>;<volume>34</volume>(<issue>10</issue>):<fpage>1705</fpage>–<lpage>1712</lpage>.</citation></ref><ref id="c48" hwp:id="ref-48" hwp:rev-id="xref-ref-48-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.48" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-48"><string-name name-style="western" hwp:sortable="Zhang Q."><surname>Zhang</surname>, <given-names>Q.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zhu L."><surname>Zhu</surname>, <given-names>L.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Huang D.S."><surname>Huang</surname>, <given-names>D.S.</given-names></string-name> <article-title hwp:id="article-title-45">High-Order Convolutional Neural Network Architecture for Predicting DNA-Protein Binding Sites</article-title>. <source hwp:id="source-47">IEEE/ACM Trans Comput Biol Bioinform</source> <year>2019</year>;<volume>16</volume>(<issue>4</issue>):<fpage>1184</fpage>–<lpage>1192</lpage>.</citation></ref><ref id="c49" hwp:id="ref-49" hwp:rev-id="xref-ref-49-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.49" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-49"><string-name name-style="western" hwp:sortable="Zhou J."><surname>Zhou</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Theesfeld C.L."><surname>Theesfeld</surname>, <given-names>C.L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Yao K."><surname>Yao</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chen K.M."><surname>Chen</surname>, <given-names>K.M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wong A.K."><surname>Wong</surname>, <given-names>A.K.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Troyanskaya O.G."><surname>Troyanskaya</surname>, <given-names>O.G.</given-names></string-name> <article-title hwp:id="article-title-46">Deep learning sequence-based ab initio prediction of variant effects on expression and disease risk</article-title>. <source hwp:id="source-48">Nature genetics</source> <year>2018</year>;<volume>50</volume>(<issue>8</issue>):<fpage>1171</fpage>.</citation></ref><ref id="c50" hwp:id="ref-50" hwp:rev-id="xref-ref-50-1"><citation publication-type="journal" citation-type="journal" ref:id="508242v3.50" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-50"><string-name name-style="western" hwp:sortable="Zucchelli S."><surname>Zucchelli</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cotella D."><surname>Cotella</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Takahashi H."><surname>Takahashi</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Carrieri C."><surname>Carrieri</surname>, <given-names>C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cimatti L."><surname>Cimatti</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fasolo F."><surname>Fasolo</surname>, <given-names>F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jones M."><surname>Jones</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sblattero D."><surname>Sblattero</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sanges R."><surname>Sanges</surname>, <given-names>R.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Santoro C."><surname>Santoro</surname>, <given-names>C.</given-names></string-name> <article-title hwp:id="article-title-47">SINEUPs: A new class of natural and synthetic antisense long non-coding RNAs that activate translation</article-title>. <source hwp:id="source-49">RNA biology</source> <year>2015</year>;<volume>12</volume>(<issue>8</issue>):<fpage>771</fpage>–<lpage>779</lpage>.</citation></ref></ref-list></back></article>
