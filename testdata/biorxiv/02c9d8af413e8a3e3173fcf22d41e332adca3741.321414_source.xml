<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/321414</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;321414</article-id><article-id pub-id-type="other" hwp:sub-type="slug">321414</article-id><article-id pub-id-type="other" hwp:sub-type="tag">321414</article-id><article-version>1.1</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Animal Behavior and Cognition" hwp:journal="biorxiv"><subject>Animal Behavior and Cognition</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">Acoustic Calibration in an Echoic Environment</article-title></title-group><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6230-6457</contrib-id><name name-style="western" hwp:sortable="Kazakov Alexander"><surname>Kazakov</surname><given-names>Alexander</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-6230-6457"/></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-2"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6645-107X</contrib-id><name name-style="western" hwp:sortable="Israel Nelken"><surname>Israel</surname><given-names>Nelken</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-6645-107X"/></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2"><label>1</label><institution hwp:id="institution-1">Edmond and Lily Safra Center for Brain Sciences, The Hebrew University of Jerusalem</institution>, <country>Israel</country></aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1"><label>2</label><institution hwp:id="institution-2">Dept. of Neurobiology, The Alexander Silberman Inst. of Life Sciences Hebrew University of Jerusalem</institution>, <country>Israel</country></aff></contrib-group><pub-date pub-type="epub-original" hwp:start="2018"><year>2018</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2018-05-22T13:09:10-07:00">
    <day>22</day><month>5</month><year>2018</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2018-05-22T13:09:10-07:00">
    <day>22</day><month>5</month><year>2018</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2018-05-22T13:16:02-07:00">
    <day>22</day><month>5</month><year>2018</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2018-05-22T13:16:02-07:00">
    <day>22</day><month>5</month><year>2018</year>
  </pub-date><elocation-id>321414</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2018-05-22"><day>22</day><month>5</month><year>2018</year></date>
<date date-type="rev-recd" hwp:start="2018-05-22"><day>22</day><month>5</month><year>2018</year></date>
<date date-type="accepted" hwp:start="2018-05-22"><day>22</day><month>5</month><year>2018</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2018</copyright-year><license hwp:id="license-1"><p hwp:id="p-1">The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.</p></license></permissions><self-uri xlink:href="321414.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2019/pdf/321414v1.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="321414.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2019/abstracts/321414v1/321414v1.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2019/fulltext/321414v1/321414v1.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">ABSTRACT</title><p hwp:id="p-2"><italic toggle="yes">Background</italic>: The sound fed to a loudspeaker may significantly differ from that reaching the ear of the listener. The transformation from one to the other consists of spectral distortions with strong dependence on the relative locations of the speaker and the listener as well as on the geometry of the environment. With the increased importance of research in awake, freely-moving animals in large arenas, it becomes important to understand how animal location influences the corresponding spectral distortions.</p><p hwp:id="p-3"><italic toggle="yes">New Method</italic>: We describe a full calibration pipeline that includes spatial sampling and estimation of the spectral distortions. We estimated the impulse responses of the environment using Golay complementary sequences.</p><p hwp:id="p-4">Using those sequences, we also describe an acoustic 3D localization method for freely moving animals.</p><p hwp:id="p-5"><italic toggle="yes">Results</italic>: In our arena, the impulse responses are dominated by a small number of strong reflections. We use this understanding to provide guidelines for designing the geometry of the environment as well as the presented sounds, in order to provide more uniform sound levels throughout the environment. Our 3D localization method achieves a 1 cm precision through the utilization of sound cues only.</p><p hwp:id="p-6"><italic toggle="yes">Comparison with Existing Methods</italic>: To our knowledge, this is the first description of a large-scale acoustic calibration pipeline with acoustic localization for neuroscience studies.</p><p hwp:id="p-7"><italic toggle="yes">Conclusions</italic>: Principled sampling of large arena allows for better design and control of the acoustic information provided to freely-moving animals.</p></abstract><kwd-group kwd-group-type="author" hwp:id="kwd-group-1"><title hwp:id="title-2">KEYWORDS</title><kwd hwp:id="kwd-1">Acoustic calibration</kwd><kwd hwp:id="kwd-2">sound distortions</kwd><kwd hwp:id="kwd-3">Golay complementary sequences</kwd><kwd hwp:id="kwd-4">echoic environments</kwd><kwd hwp:id="kwd-5">freely moving animals</kwd><kwd hwp:id="kwd-6">3D localization</kwd><kwd hwp:id="kwd-7">volumetric tracking</kwd></kwd-group><counts><page-count count="24"/></counts></article-meta></front><body><sec id="s1" hwp:id="sec-1"><label>1.</label><title hwp:id="title-3">INTRODUCTION</title><p hwp:id="p-8">A growing number of studies in brain sciences use freely moving animals, a process that is driven by technological advances such as the possibility to perform extracellular recordings with large electrode arrays using telemetry<sup><xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">1</xref>,<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">2</xref></sup>. However, less constrained behavior comes with a cost in terms of stimulus control. In audition, for example, sounds reproduced by loudspeaker are distorted as they propagate through the environment, so that the sound reaching the ear is different from that initially produced by the loudspeaker (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Fig. 1a</xref>.). These distortions are usually estimated through acoustic calibration – the comparison between the sound at the input to the loudspeaker with that actually reaching the ears. For freely-moving animals, the need to calibrate sounds in multiple locations is an especially hard task.</p><p hwp:id="p-9">Acoustic distortions are fully characterized by measuring the responses to an impulse (the ‘impulse response’). Evaluation of the acoustic properties using an impulse response is called ‘Impulse response analysis’, and its evolution is thoroughly described by Warren (2014)<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3"><sup>3</sup></xref>. In short, the straightforward method to measure the impulse response is to record the responses to a single, ideal impulse. However, practical implementations of ideal impulses have low acoustic power because of their short duration, leading to low signal to noise ratio (SNR) in the resulting estimates. Instead of a single impulse, it is possible to use a pseudo-random noise, which is later cross-correlated with the recorded response, resulting in the impulse response of the system. For this to work well, the test signal has to have an autocorrelation consisting of a single peak at zero delay and zero correlation at all other delays. To maximize the quality of the estimates the test signal should also be of maximal power. For example, the use of maximal length sequences has been proposed by Schroeder (1979)<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4"><sup>4</sup></xref>. Maximal length sequences, however, are not exactly white and thus can’t be used for estimating a perfect impulse response. To solve this problem, Golay complementary sequences were proposed<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5"><sup>5</sup></xref> and later applied for acoustic measurement in a number of studies of the auditory system<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">6</xref>–<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">8</xref></sup>. Even though Golay complementary sequences require playback and recording of two different sequences, the test signal is shorter than its pseudo-random equivalents, resulting in faster estimation of the impulse response<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-2" hwp:rel-id="ref-5"><sup>5</sup></xref>. We therefore used Golay complementary sequences to achieve a high throughput calibration pipeline.</p><fig id="fig1" position="float" orientation="portrait" fig-type="figure" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2 xref-fig-1-3 xref-fig-1-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Fig 1.</label><caption hwp:id="caption-1"><title hwp:id="title-4">The echoic environment and the sound sampling robot.</title><p hwp:id="p-10">A. Simplified model of the arena, depicting the twelve speakers arranged in pairs (blue points along the circumferential wall). The arena is designed for experiments with freely behaving rats, driven by auditory stimuli (solid orange lines). Acoustic calibration compares the sound at the rat’s location to that transduced by the computer, and reflects both the speaker and the arena effects on the sound. B. An image of the arena. C. The acoustic calibration was performed in hundreds of locations along the arena, using a robot.</p></caption><graphic xlink:href="321414_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-11">In this paper, we describe an automated pipeline for high throughput sound calibration in a large arena used in our own research. We demonstrate the use of acoustic calibration for understanding the geometrical origin of the resulting acoustic distortions, and illustrate some approaches to alleviate them. We then suggest a second use for the estimated impulse responses: we exploit them for rapid 3D localization of the animal. Fast and accurate localization of freely moving animals is an open challenge. Although many generic approaches have been proposed for object tracking, only few are applicable for studies of freely moving rodents. Tracking an animal in three dimensions (3D, volumetric tracking) is even harder. Camera based approaches require line of sight with the animal and installation of multiple cameras<sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">9</xref>,<xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">10</xref></sup>. Solutions based on magnetic tracking require installation of dedicated sensors and may not provide sufficient spatial resolution<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-2" hwp:rel-id="ref-1"><sup>1</sup></xref>. Here, the same hardware used for acoustic calibration (multiple loudspeakers with a microphone on the head of the animal) is used also for high-resolution, fast 3D tracking.</p></sec><sec id="s2" hwp:id="sec-2"><label>2.</label><title hwp:id="title-5">MATERIALS AND METHODS</title><sec id="s2a" hwp:id="sec-3"><label>2.1</label><title hwp:id="title-6">The arena</title><p hwp:id="p-12">The arena is roughly circular (the circle is approximated by 18 straight segments, with diameter of 160 cm and wall height of 50 cm, see <xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Fig. 1a-b</xref>). Six pairs of speakers (MF1, TDT) are evenly spread around the upper rim of the wall, with distance of 17 cm between speakers of each pair and central angle spread of 60º between successive pairs of speaker. All speakers are tilted by 35º below the horizontal axis such that their acoustic axes are pointed towards the center of the arena (<xref ref-type="fig" rid="figS1" hwp:id="xref-fig-8-1" hwp:rel-id="F8">Supp. Fig. 1</xref>).</p><fig id="figS1" position="float" orientation="portrait" fig-type="figure" hwp:id="F8" hwp:rev-id="xref-fig-8-1 xref-fig-8-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F8</object-id><object-id pub-id-type="publisher-id">figS1</object-id><label>Supp. fig 1:</label><caption hwp:id="caption-8"><title hwp:id="title-31">Control for the precision of acoustically evaluated distances.</title><p hwp:id="p-73">A side view of the environment (speaker – orange rectangle, microphone – orange circle). The manually measured distances: <italic toggle="yes">R<sub>arena</sub></italic> is the radius of the arena. <italic toggle="yes">X<sub>sp</sub></italic> is the distance of the speaker’s membrane from the wall, due to the 35° tilt. <italic toggle="yes">X<sub>sp↔mic</sub></italic> is the horizontal distance of the microphone from the loudspeaker. <italic toggle="yes">h<sub>sp</sub></italic> is the height of the speaker’s membrane center. <italic toggle="yes">h<sub>mic</sub></italic> is the height of the microphone. <italic toggle="yes">h<sub>sp↔mic</sub></italic> is its vertical distance of the microphone from the speaker. Using the Pythagorean theorem we calculate <inline-formula hwp:id="inline-formula-10"><alternatives hwp:id="alternatives-12"><inline-graphic xlink:href="321414_inline10.gif" hwp:id="inline-graphic-10"/></alternatives></inline-formula>, the distance between the speaker’s membrane and the microphone, based on the manual measurements. <inline-formula hwp:id="inline-formula-11"><alternatives hwp:id="alternatives-13"><inline-graphic xlink:href="321414_inline11.gif" hwp:id="inline-graphic-11"/></alternatives></inline-formula> is the acoustically evaluated distance (89.8 cm), deviating 0.2 cm (0.22%) from the manually measured one (90 cm).</p></caption><graphic xlink:href="321414_figS1" position="float" orientation="portrait" hwp:id="graphic-10"/></fig></sec><sec id="s2b" hwp:id="sec-4"><label>2.2</label><title hwp:id="title-7">Acoustic modeling of the arena</title><p hwp:id="p-13">We idealize the acoustics of the arena as a linear, time-invariant system. The system is therefore fully specified by the impulse responses (IRs) from each speaker to each point in the arena. While the linearity assumption is very good at the sound levels considered here, the time invariance is clearly an approximation, since the presence of an animal in the arena modifies the acoustic properties in a way that depends on animal location. Nevertheless, the structure of the impulse responses is primarily determined by geometric factors that are independent of animal location. This point is further addressed in the Results.</p><p hwp:id="p-14">The main challenge here is the need to sample the impulse response from multiple speakers to densely spaced points in the arena. Full reconstruction of the pressure field at all relevant frequencies requires the distance between spatially sampled points to be a fraction of the wavelength at the highest frequency of interest. However, this is practically impossible: rats hear up to 75 kHz, where the wavelength is 4 mm, requiring a sampling density of about 1 mm<xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11"><sup>11</sup></xref>. In practice, we sampled the IRs with spatial resolution of about 1 cm, using a custom built robot (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-3" hwp:rel-id="F1">Fig. 1c</xref>). While this resolution limits the ability to fully reconstruct the resulting pressure field to frequencies below 10 kHz, we will show that useful information can nevertheless be extracted at higher frequencies as well.</p><p hwp:id="p-15">The Fourier transform of the IR (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Fig. 2a</xref>) is called the transfer function (TF, <xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Fig. 2b</xref>). The transfer function describes the steady-state amplitude gain and phase shift of sinusoidal signals as a function of frequency. Here we were primarily interested in spectral distortions, and therefore TFs are invariably represented by their amplitudes only. The TFs varied with the relative location of the microphone and the speaker that produced the IRs. We demonstrated this both by repositioning the microphone inside the arena, while estimating the IRs from a single speaker (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Fig. 2c</xref>), or by measuring the IRs from different speakers at a microphone in a fixed location (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-4" hwp:rel-id="F2">Fig. 2d</xref>). The frequency-dependent variations are not produced by the noise in the measurement, since these were highly reproducible for a fixed location (<xref ref-type="fig" rid="figS2" hwp:id="xref-fig-9-1" hwp:rel-id="F9">Supp. Fig. 2</xref>).</p><fig id="figS2" position="float" orientation="portrait" fig-type="figure" hwp:id="F9" hwp:rev-id="xref-fig-9-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F9</object-id><object-id pub-id-type="publisher-id">figS2</object-id><label>Supp. fig 2:</label><caption hwp:id="caption-9"><title hwp:id="title-32">TFs are highly variable between different locations of the arena, but is highly reproducible at each location</title><p hwp:id="p-74">TFs were measured in five different locations along a radius connecting the speaker and the center of the arena (d=80 cm). At each location three measurements were made. Each line represents TF, with the shaded area representing the standard deviation of the 3 measurements. The variability between measurements in the same location is hardly visible when compared with the between-location variability.</p></caption><graphic xlink:href="321414_figS2" position="float" orientation="portrait" hwp:id="graphic-11"/></fig></sec><sec id="s2c" hwp:id="sec-5"><label>2.3</label><title hwp:id="title-8">Impulse Response measurements using Golay sequences</title><p hwp:id="p-16">The IRs were measured by playing two complementary Golay sequences, as suggested by Zhou (1992)<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6"><sup>6</sup></xref> and illustrated in <xref ref-type="fig" rid="figS3" hwp:id="xref-fig-10-1" hwp:rel-id="F10">Supp. Fig. 3</xref>. Starting from <italic toggle="yes">a</italic><sub>1</sub> = [1 1] and <italic toggle="yes">b</italic><sub>1</sub> = [1 − 1], Golay sequences of length 2<sup><italic toggle="yes">i</italic>+1</sup> were constructed from Golay sequences of length 2<sup>i</sup> following a recursive concatenation:</p><fig id="figS3" position="float" orientation="portrait" fig-type="figure" hwp:id="F10" hwp:rev-id="xref-fig-10-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F10</object-id><object-id pub-id-type="publisher-id">figS3</object-id><label>Supp. fig 3:</label><caption hwp:id="caption-10"><title hwp:id="title-33">Computing an impulse response from the responses to a pair of Golay complementary sequences.</title><p hwp:id="p-75"><bold>A</bold>. An example of two complementary Golay sequences of length 2<sup>5</sup> = 32 <italic toggle="yes">bits</italic>. <bold>B</bold>. The two auto-correlations of Golay codes (bottom two lines) sum to an impulse at the origin. <bold>C</bold>. Sound recording of one Golay sequence. <bold>D</bold>. The responses to each Golay sequence is cross-correlated with its original Golay sequence, producing a single cross-correlation. The two cross correlations are shown by bottom plots. When summed, they form an impulse response (the upper dark line).</p></caption><graphic xlink:href="321414_figS3" position="float" orientation="portrait" hwp:id="graphic-12"/></fig><fig id="fig2" position="float" orientation="portrait" fig-type="figure" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3 xref-fig-2-4 xref-fig-2-5 xref-fig-2-6 xref-fig-2-7 xref-fig-2-8 xref-fig-2-9 xref-fig-2-10"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Fig 2.</label><caption hwp:id="caption-2"><title hwp:id="title-9">The acoustic properties of the arena were assessed by the impulse response analysis. The impulse response depends on the relative location of the microphone and the speaker that produces the impulse.</title><p hwp:id="p-17"><bold>A</bold>. An impulse response (IR) measured in the arena (black) and an ideal impulse response of a system with no distortions (red). <bold>B</bold>. The transfer function (TF) is the Fourier transform of the impulse response. Black and red lines show the TFs of IRs from A. <bold>C</bold>. Examples of TFs measured at 3 locations. <bold>D</bold>. Examples of TFs measured at a single location of the arena, for 3 different speakers.</p></caption><graphic xlink:href="321414_fig2" position="float" orientation="portrait" hwp:id="graphic-2"/></fig><p hwp:id="p-18"><italic toggle="yes">a</italic><sub><italic toggle="yes">i</italic>+1</sub>=(<italic toggle="yes">a</italic><sub><italic toggle="yes">i</italic></sub>|<italic toggle="yes">b</italic><sub><italic toggle="yes">i</italic></sub>), <italic toggle="yes">b</italic><sub><italic toggle="yes">i</italic>+1</sub>=(<italic toggle="yes">a</italic><sub><italic toggle="yes">i</italic></sub>|−<italic toggle="yes">b</italic><sub><italic toggle="yes">i</italic></sub>) where (· | ·) denotes concatenation and (−) denotes elementwise negation.</p><p hwp:id="p-19">These two sequences were played with a time interval of 0.2 s between them, to let most of the echoes decay (this interval is referred to below as the ‘silence buffer’). The sounds were generated by a single multichannel sound card (RME M16AD) and fed through programmable attenuators (PA5, TDT). Sounds were presented through TDT MF1 speakers. These speakers have a nominal frequency response range of 1–65 kHz with differences of up to ± 13 dB in sound level<xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12"><sup>12</sup></xref>. The speakers were driven by power amplifiers (SA1, TDT). Except for online tracking of rats, the sound was recorded by a calibrated microphone (Brüel &amp; Kjær model 4939) at 192 kHz. The IR was recovered by cross-correlating the recorded sounds with the played sequences and summing the results obtained for the two sequences.</p><p hwp:id="p-20">To ensure precise temporal synchronization of the playback and the microphone recordings, a square pulse was produced by the sound card on a separate channel and recorded on a separate channel of the sound recorder. Later this trigger was used to locate precisely the onset of the test sound, in order to estimate the length of the direct path of the sound from the loudspeaker to the microphone (<xref ref-type="fig" rid="figS4" hwp:id="xref-fig-11-1" hwp:rel-id="F11"><xref ref-type="fig" rid="figS4" hwp:id="xref-fig-11-2" hwp:rel-id="F11">Supp. Fig. 4</xref></xref>).</p><fig id="figS4" position="float" orientation="portrait" fig-type="figure" hwp:id="F11" hwp:rev-id="xref-fig-11-1 xref-fig-11-2 xref-fig-11-3 xref-fig-11-4 xref-fig-11-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F11</object-id><object-id pub-id-type="publisher-id">figS4</object-id><label>Supp. fig 4:</label><caption hwp:id="caption-11"><title hwp:id="title-34">Impulse response encodes the distance of the speaker to the microphone.</title><p hwp:id="p-76">An impulse response was recorded at the center of the arena (gray line). Black point represents sound onset, black empty circle is the estimated sound onset at the microphone’s location. Time difference of these two points is called time-of-arrival of the sound, in this case it is 2.62 ms. It can be converted to distance by multiplication with the speed of sound: 0.00262 ⋅ 343 = 89.8 <italic toggle="yes">cm</italic>;.</p></caption><graphic xlink:href="321414_figS4" position="float" orientation="portrait" hwp:id="graphic-13"/></fig></sec><sec id="s2d" hwp:id="sec-6"><label>2.4</label><title hwp:id="title-10">Spatial sampling</title><p hwp:id="p-21">Spatial sampling was automated using a custom-built robot, based on model RB-Rbo-33 by RobotShop (<ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.robotshop.com/" ext-link-type="uri" xlink:href="http://www.robotshop.com/" hwp:id="ext-link-1">http://www.robotshop.com</ext-link>). The microphone was fixed to an extension arm in front of the robot, pointing perpendicularly towards the floor (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-4" hwp:rel-id="F1">Fig. 1c</xref>). A high-precision geared motor (Cytron Technologies, MO-SPG-30E-60K) was used to set the elevation of the microphone arm and was operated by an encoder (H bridge motor driver SN754410, Texas Instruments Inc.) connected to the Arduino board on the robot (<xref ref-type="fig" rid="figS5" hwp:id="xref-fig-12-1" hwp:rel-id="F12"><xref ref-type="fig" rid="figS5" hwp:id="xref-fig-12-2" hwp:rel-id="F12">Supp. Fig. 5</xref></xref>). A custom MATLAB program controlled the automated sampling sequence: it positioned the robot in a predefined location and elevated the microphone to the desired height. It then played the test sound through each speaker in turn and recorded the microphone signals. The whole process repeated at the next location. As a rule, sampling at all microphone elevations occurred before moving the robot to a new location. In the data shown here, the spatial positions were selected in order to study particular features of the impulse response. For example, studying the floor echo was performed using 10 locations at varying heights at two horizontal locations (See results). When these measurements were performed, the robot was placed at the center of the arena and its arm was lowered such that the microphone was 1 cm above the floor. The arm was elevated 1 cm between each of the 10 vertical sampling locations, then the robot moved horizontally 40 centimeters (half the radius of the arena) and continued to sample the other 10 vertical locations, from the highest to the lowest one. The whole sequence was performed autonomously under control of a MATLAB routine.</p><fig id="figS5" position="float" orientation="portrait" fig-type="figure" hwp:id="F12" hwp:rev-id="xref-fig-12-1 xref-fig-12-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F12</object-id><object-id pub-id-type="publisher-id">figS5</object-id><label>Supp. fig 5:</label><caption hwp:id="caption-12"><title hwp:id="title-35">Electrical circuitry that enables the vertical movement of the microphone.</title><p hwp:id="p-77">The bottom part of the robot was assembled from the kit <underline>Rover V2 (RobotShop)</underline>. A geared motor (<underline>MO-SPG-30E-60K</underline>) was installed on top of it, fixed inside a custom made frame. The motor controlled the elevation of the extension arm, that held the microphone. An Arduino-compatible board (part of the RobotShop kit) controlled the robot’s tracks and the geared motor. The later was connected to the board using a custom made PCB circuit, utilizing an H bridge driver.</p></caption><graphic xlink:href="321414_figS5" position="float" orientation="portrait" hwp:id="graphic-14"/></fig><p hwp:id="p-22">The precision of the robot’s movements was evaluated and pre-calibrated to deliver sub millimeter accuracy per single movement. Nevertheless, positional error accumulated over a long measurement sequence, leading to potential errors on the order of 1 cm, and therefore limiting the length of recording trajectories. This error was partially eliminated, when needed, by breaking the recording session into a shorter sequence of autonomous sessions, with manual correction of the robot location between sessions. We didn’t integrate a camera feedback to correct the robot location since we expected its own error to be too large for that purpose (more than one cm).</p></sec><sec id="s2e" hwp:id="sec-7"><label>2.5</label><title hwp:id="title-11">Localization of a freely moving animal</title><p hwp:id="p-23">The IRs were used to determine the time of arrival of the first waveform from each loudspeaker to the microphone, and transformed into an estimate of the distance between the microphone and the speaker (<xref ref-type="fig" rid="figS4" hwp:id="xref-fig-11-3" hwp:rel-id="F11"><xref ref-type="fig" rid="figS4" hwp:id="xref-fig-11-4" hwp:rel-id="F11">Supp. Fig. 4</xref></xref>). The estimated distance constrains the speaker location to a sphere around the speaker. In order to narrow down the possible locations to a single point in space, distances to at least two other speakers are required (See <xref ref-type="fig" rid="figS6" hwp:id="xref-fig-13-1" hwp:rel-id="F13">Supp. Fig. 6</xref>; In general, if three spheres intersect, they would do so in 2 points, but in our case one point can be discarded since the microphone location is always below the plane defined by the speakers). The distance-based localization that relies on intersection of spheres is called trilateration (or multi-lateration for more than 3 distances). If the distances are exact, the relevant intersection point can be analytically found. In the presence of noise, the location of the microphone can be still numerically approximated. We used the MATLAB minimizer ‘fmincon’ with the loss function described by (1) to estimate the point <italic toggle="yes">p</italic><sub><italic toggle="yes">loc</italic></sub>, where <italic toggle="yes">p</italic><sub><italic toggle="yes">i</italic></sub> is the location of speaker <italic toggle="yes">i</italic>, <italic toggle="yes">d</italic><sub><italic toggle="yes">i</italic></sub> are the calculated distances between the head stage and speaker <italic toggle="yes">i</italic>, and <italic toggle="yes">p</italic><sup>*</sup> is the estimated microphone location.</p><fig id="figS6" position="float" orientation="portrait" fig-type="figure" hwp:id="F13" hwp:rev-id="xref-fig-13-1 xref-fig-13-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F13</object-id><object-id pub-id-type="publisher-id">figS6</object-id><label>Supp. fig 6:</label><caption hwp:id="caption-13"><title hwp:id="title-36">The trilateration for microphone localization in 3D.</title><p hwp:id="p-78">Trilateration is distance-based localization that relies on intersection of spheres (or circles, for 2D). For acoustic localization, the point of interest is the microphone (black point, p*). The locations of the loudspeakers are known (colored dots, i.e. p<sub>1</sub>) and distances to the microphone are evaluated using the time-or-arrival of the direct sound, estimated from the IRs (i.e. d<sub>1</sub>). The three circles don’t intersect in a single point due to measurement noise, and the location of the microphone is approximated through minimization of distances to the three circles (i.e. ɛ<sub>1</sub>).</p></caption><graphic xlink:href="321414_figS6" position="float" orientation="portrait" hwp:id="graphic-15"/></fig><disp-formula id="eqn1" hwp:id="disp-formula-1">
<alternatives hwp:id="alternatives-1"><graphic xlink:href="321414_eqn1.gif" position="float" orientation="portrait" hwp:id="graphic-3"/></alternatives>
</disp-formula><p hwp:id="p-24">The animals used for localization were SABRA-R albino female rats. The animals used here had sufficient body mass (250–300 g) for carrying the headstage that included an integrated microphone and weighed 15 gram. The headstage was head fixed as described in Polterovich et. al. (In Press). The microphone was located 5 cm above the head, it sampled sound at 44 kHz and transmitted it online using a telemetry system to a data logging computer.</p><p hwp:id="p-25">In addition to the acoustic localization, the arena was photographed at 30 Hz using a wide-field digital video camera that was placed above its center, such that each acoustic localization test could be later associated to a photograph of the rat in the RIFF taken at approximately the same time (see Supp. Movies 1–4). These images were later used to manually annotate the location of the microphone so that the localization error, defined as the distance between the position determined by acoustic localization and the manually annotated one, could be evaluated. The image of the rat was obtained through a fisheye lens, so that the height coordinate causes a shift outward from the vertical axis of the camera. In order to compare the manually annotated location of the headstage and the point estimated by the acoustic localization, the estimated location was shifted in the same way (Supp. Movies 1–4; The yellow point is the manual annotation of the microphone location, the red dot show the acoustically-determined position, corrected for the shift due to the elevation of the microphone. The red line displays the projection on the arena floor).</p></sec><sec id="s2f" hwp:id="sec-8"><label>2.6</label><title hwp:id="title-12">Additional Test Sounds</title><p hwp:id="p-26"><underline>Frequency sweeps.</underline> Frequency sweeps covering 0.5 kHz extent in 10 seconds were used to directly measure the amplitude of the transfer functions over restricted frequency ranges. The ranges tested were 1–1.5 kHz, 10–10.5 kHz and 34–34.5 kHz.</p><p hwp:id="p-27"><underline>Narrow band sweeps.</underline> Narrow band (NB) sweeps were created as a superposition of 101 pure tone sweeps. Each spanned the same range (0.5 kHz) but had a varying starting frequency and phase. For example, to produce NB sweep over the range of 10–10.5 kHz, we summed 101 frequency sweeps such that the first covered the range 9.95–10.45 kHz, the second covered 9.96–10.46 kHz, and so on, each starting with a random phase.</p><p hwp:id="p-28"><underline>Test sounds for spatial localization.</underline> A variety of Golay codes of various lengths were tested for localization. The sequences were always sampled at 192 kHz. Since the microphone on the headstage could sample only at 44 kHz, the sequence was lowpass filtered at 20 kHz. To reduce measurement time, a shorter silent buffer of only 10 ms was inserted between the two Golay complementary codes. For a Golay code of length 2<sup>12</sup> for example, this resulted in a total duration of sound presentation of <inline-formula hwp:id="inline-formula-1"><alternatives hwp:id="alternatives-2"><inline-graphic xlink:href="321414_inline1.gif" hwp:id="inline-graphic-1"/></alternatives></inline-formula> ms = 53 ms. Each speaker played these sounds and produced a single estimate of distance. Varying sets of 3 to 12 distances were used for estimating rat position. The total time for estimating three distances was <inline-formula hwp:id="inline-formula-2"><alternatives hwp:id="alternatives-3"><inline-graphic xlink:href="321414_inline2.gif" hwp:id="inline-graphic-2"/></alternatives></inline-formula> ms and for 12 distances (using all speakers) was <inline-formula hwp:id="inline-formula-3"><alternatives hwp:id="alternatives-4"><inline-graphic xlink:href="321414_inline3.gif" hwp:id="inline-graphic-3"/></alternatives></inline-formula> ms.</p></sec><sec id="s3g" hwp:id="sec-9"><label>2.7</label><title hwp:id="title-13">Data analysis</title><p hwp:id="p-29">The signal processing and data analysis were performed using custom written MATLAB functions.</p></sec></sec><sec id="s3" hwp:id="sec-10"><label>3.</label><title hwp:id="title-14">Results</title><sec id="s3a" hwp:id="sec-11"><label>3.1</label><title hwp:id="title-15">Impulse response and transfer function encode local acoustic features</title><p hwp:id="p-30">Perfect sound reproduction occurs only when the impulse response (IR) represents a pure delay; in that case the transfer function (TF) has an amplitude gain which is constant as a function of frequency, and a phase shift which is a linear function of frequency (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-5" hwp:rel-id="F2">Fig. 2a-b</xref>, red lines). Deviations from these ideal conditions cause the IR to deviate from a pure delay, and the TF typically has frequency-dependent amplitude gain (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-6" hwp:rel-id="F2">Fig. 2a-b</xref>, black lines).</p><p hwp:id="p-31">One concern about these measurements is the potential role of the robot itself in shaping the IRs, since its body could produce its own share of acoustic distortions. To check this, we recorded IRs from the microphone at the same location while the robot rotated around it, showing only minor differences in the TFs and mostly at frequencies above 15 kHz: In a control experiment, the robot was rotated twelve times by 90º clockwise, keeping the microphone in the same position. When comparing the average IR produced by the speakers obscured by the robot (red plots, <xref ref-type="fig" rid="figS7" hwp:id="xref-fig-14-1" hwp:rel-id="F14">Supp. Fig. 7a</xref>.) with the IR of the speakers that had line of sight with the microphone (same figure, blue plots) it is evident that the crucial temporal features are preserved: The sound onset was unchanged (t = 3.1 ms), and the main features of the impulse response, the two amplitude deflections at t = 3.2 and t = 3.4 ms, are intact. The two TFs (<xref ref-type="fig" rid="figS7" hwp:id="xref-fig-14-2" hwp:rel-id="F14">Supp. Fig. 7b</xref>.) largely overlap up to 25 kHz. The recorded TFs from all locations shared many features (as can be seen on an illustrative TF in <xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-7" hwp:rel-id="F2">Fig. 2b</xref>): the TFs were invariably lowpass and the energy above 45 kHz was reduced by about 40 dB relative to low frequencies. This is most probably due to the frequency response of the loudspeakers<xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-2" hwp:rel-id="ref-12"><sup>12</sup></xref>. Another feature is the slow oscillations with a period of a few kHz, easily observable between 20 and 40 kHz in <xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-8" hwp:rel-id="F2">Fig. 2b</xref>. In addition to the slow oscillations, there were fast fluctuations of the TF. For example, in the TF shown at <xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-9" hwp:rel-id="F2">Fig. 2b</xref>, sound level has a local minima near 13, 15 and 23 kHz, where the sound level decreased by 30 dB and then increased again within a frequency interval as narrow as 40 Hz, forming so-called spectral notches. Finally, TFs exhibited stronger attenuation of high frequencies when the microphone was located far from the acoustic axis of a loudspeaker.</p><fig id="figS7" position="float" orientation="portrait" fig-type="figure" hwp:id="F14" hwp:rev-id="xref-fig-14-1 xref-fig-14-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS7</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F14</object-id><object-id pub-id-type="publisher-id">figS7</object-id><label>Supp. fig 7:</label><caption hwp:id="caption-14"><title hwp:id="title-37">The IR and TF are affected by the robot’s body.</title><p hwp:id="p-79">The rover was rotated 12 times around the microphone (the location of which was kept constant), each time by 90° clockwise (completing three full circles). After a single rotation, the IR was sampled from all the 12 speakers, out of which two speakers had no line of sight with the microphone because of the robot’s body. <bold>A</bold>. The average IR for all speakers from all body positions that allowed a line of sight with the microphone (blue) and the average IR for the speakers obscured by the robot (orange). Solid line is the mean, shaded areas are the standard deviations across all corresponding robot body locations). <bold>B</bold>. TFs of the impulse responses from A.</p></caption><graphic xlink:href="321414_figS7" position="float" orientation="portrait" hwp:id="graphic-16"/></fig><p hwp:id="p-32">We will show that the periodic patterns in the TFs (both slow and fast) are due to strong reflections from the floor and walls of the arena (<xref ref-type="sec" rid="s4b" hwp:id="xref-sec-18-1" hwp:rel-id="sec-18">Section 4.2</xref>), while the attenuation off the acoustic axis at high frequencies is the consequence of the frequency-dependent directivity of the speakers (<xref ref-type="sec" rid="s4c" hwp:id="xref-sec-19-1" hwp:rel-id="sec-19">Section 4.3</xref>). We then develop strategies to at least partially compensate for these distortions (Section 4.4).</p></sec><sec id="s3b" hwp:id="sec-12"><label>3.2</label><title hwp:id="title-16">Echoes from the floor and walls shape the IRs</title><p hwp:id="p-33">The IRs tend to have a relatively simple structure, consisting of the direct sound reaching the microphone (indicated by red arrows in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Fig. 3a</xref>) followed by a first prominent reflection (yellow arrow) and a few longer-latency reflections (the green and blue arrows mark the first two).</p><p hwp:id="p-34">In order to verify the origin of each of these reflections, we converted the timing of arrival (ToA) of a reflection into traveling distance of the sound wave (distance = ToA × speed of sound at 20º C, considered as 343 m/s. For an example, see <xref ref-type="fig" rid="figS4" hwp:id="xref-fig-11-5" hwp:rel-id="F11">Supp. Fig. 4</xref>). The precision of the acoustically determined distances was tested in a separate control experiment, and the error was within the 0.3 cm uncertainty of manual measurements: The precision of the acoustically determined distances was tested by measuring the delay of the direct sound from all 12 speakers to the microphone at the center of the arena, comparing them to manually measured distances (<xref ref-type="fig" rid="figS1" hwp:id="xref-fig-8-2" hwp:rel-id="F8">Supp. Fig. 1</xref> depicts geometric modeling of the arena). The measured ToA of the sound was 2.62 ms, corresponding to a traveling distance of 89.8 cm. The empirical distance was 90 cm, within less than 1% of the value determined from the ToA. Because of the speaker’s shape the empirical distance was determined with a spatial precision of 0.3 cm. All acoustically-determined distances fell within this error range.</p><fig id="fig3" position="float" orientation="portrait" fig-type="figure" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3 xref-fig-3-4 xref-fig-3-5 xref-fig-3-6 xref-fig-3-7 xref-fig-3-8 xref-fig-3-9 xref-fig-3-10 xref-fig-3-11 xref-fig-3-12 xref-fig-3-13 xref-fig-3-14 xref-fig-3-15 xref-fig-3-16 xref-fig-3-17 xref-fig-3-18 xref-fig-3-19 xref-fig-3-20 xref-fig-3-21 xref-fig-3-22 xref-fig-3-23 xref-fig-3-24"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Fig 3.</label><caption hwp:id="caption-3"><title hwp:id="title-17">Impulse responses are largely shaped by echoes from the floor and walls.</title><p hwp:id="p-35"><bold>A</bold>. Schematic view of the echoes inside the arena. Colored arrows represent possible propagation paths of the sound emitted by the speaker and recorded by the microphone (black stem in the middle). <bold>B</bold>. Discrete events, marked by colored arrows, are identifiable in the IR. Red bar at the beginning marks the moment when the impulse would be produced by the speaker. <bold>C</bold>. Impulse responses as a function of height above the floor. Each row represents one IR, colored by amplitude. The microphone was raised 10 times in steps of 1 cm, starting from a height of 1 cm. The colored arrows correspond to the discrete events from B. <bold>D</bold>. Impulse responses as a function of distance along the radius from the center of the arena (bottom) to the wall, just underneath the speaker (top). All IRs were measured at constant height of 10 cm. <bold>E</bold>. An example IR (blue line) was windowed to remove echoes (windows displayed as grey trapezoids). The red version includes only the floor echo, and the yellow version includes only the direct sound. <bold>F</bold>. TFs of the IRs in C. <bold>G</bold>. Approximating the IR as a sequence of four impulses, corresponding to the direct sound and the three echoes. Same conventions as in E. <bold>H</bold>. TFs of IRs from G.</p></caption><graphic xlink:href="321414_fig3" position="float" orientation="portrait" hwp:id="graphic-4"/></fig><p hwp:id="p-36">For the IR shown in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Fig. 3b</xref>, the path length of the direct sound was 0.95 m (red arrow), and the first reflection had a path length of 1.07 m (yellow arrow). This is the expected path length of a reflection from the floor. To illustrate this claim, IRs from one speaker location (speaker no. 5) were measured as a function of the height of the microphone, above a fixed floor location. The difference between the path lengths of the direct sound and the floor reflection increases with microphone elevation (see the geometrical analysis in <xref ref-type="fig" rid="figS8" hwp:id="xref-fig-15-1" hwp:rel-id="F15">Supp. Fig. 8</xref>). <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Figure 3c</xref> shows 10 IRs measured at a fixed floor location as a function of elevation, stacked from closest to the floor (lowest IR) and to the highest (upper IR). Indeed, increasing microphone’s height decreased the ToA of the direct sound (red arrow, because it decreased the distance between the loudspeaker and the microphone), but increased the delay to the first reflection (yellow arrow). We conclude that the first echo is most likely a reflection from the floor.</p><fig id="figS8" position="float" orientation="portrait" fig-type="figure" hwp:id="F15" hwp:rev-id="xref-fig-15-1 xref-fig-15-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS8</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F15</object-id><object-id pub-id-type="publisher-id">figS8</object-id><label>Supp. fig 8:</label><caption hwp:id="caption-15"><title hwp:id="title-38">Computing path differences for the direct sound and the floor emitted echo, at the lowest and highest sampled points (<italic toggle="yes">h<sub>mic</sub></italic>=1 cm, <italic toggle="yes">h<sub>mic</sub></italic> =11 cm).</title><p hwp:id="p-80"><bold>A</bold>. The upper diagram shows a side view of the arena. Orange rectangle represents the loudspeaker, orange circle is the microphone that was placed 11 cm above the ground. The floor reflection was computed under the assumption that the incidence and reflection angles are equal. The bottom diagram is a geometric problem arising from the upper diagram. Distances are converted to time through the relation <inline-formula hwp:id="inline-formula-12"><alternatives hwp:id="alternatives-14"><inline-graphic xlink:href="321414_inline12.gif" hwp:id="inline-graphic-12"/></alternatives></inline-formula> The path difference was found to be 12.53 cm, corresponding to an expected 0.4 ms delay of the echo after the direct sound onset.</p><p hwp:id="p-81"><bold>B</bold>. Same as A for a microphone placed at a height of 1 cm. Here the path difference decreases to 1.22 cm and the delay to 0.05 ms. These predictions are consistent with the experiment of <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-24" hwp:rel-id="F3">Fig. 3c</xref>.</p></caption><graphic xlink:href="321414_figS8" position="float" orientation="portrait" hwp:id="graphic-17"/></fig><p hwp:id="p-37">The origin of the later two reflections (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-4" hwp:rel-id="F3">Fig. 3b</xref>, green and blue arrows) was determined using the same approach. Their path lengths in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-5" hwp:rel-id="F3">Fig. 3b</xref> were 2.39 and 3.98 m, corresponding to 1.5 and 2.5 times the diameter of the arena. These distances are compatible with one or two reflections from the walls (see <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-6" hwp:rel-id="F3">Fig. 3a</xref> for the geometry). In order to verify our hypothesis, we recorded IRs in different locations along the radius of the arena, starting at the center of the arena and moving towards the speaker (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-7" hwp:rel-id="F3">Fig. 3d</xref>). Both first and late echoes are easily observed in this experiment, and marked on <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-8" hwp:rel-id="F3">fig. 3d</xref> by the yellow, green and blue arrows. The second echo (corresponding to a single wall reflection, green arrow) shows longer delays for microphone positions close to the speaker (when the distance from the far, reflecting wall is the longest) and shorter delays in microphone positions close to the center of the arena. The third echo shows the reverse dependence (blue arrow), also as expected.</p><p hwp:id="p-38">Since the IRs are dominated by discrete echoes whose geometrical origin could be clearly determined, we investigated the effect of such discrete echoes on the TF. Generally, a discrete echo causes oscillations in the amplitude of the TF. The relationship between echo delay and rate of fluctuations of the TF can be analytically demonstrated for model TFs composed of only two pure-delay echoes. In that case, a simple calculation shows that the amplitude fluctuations of the TF occur at a rate of 1/Δt, where Δt is the echo delay. These effects are illustrated in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-9" hwp:rel-id="F3">Fig. 3e-f</xref>. <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-10" hwp:rel-id="F3">Figure 3e</xref> (blue line) replots the IRs in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-11" hwp:rel-id="F3">Fig. 3b</xref>. We approximated this IR by a sequence of four delta functions, positioned at the onsets of the direct sound and of the three echoes we considered (the floor and the two wall reflections, <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-12" hwp:rel-id="F3">Fig. 3g</xref>, blue). The Fourier transform exhibits a similar profile to the measured one (Compare the blue plots in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-13" hwp:rel-id="F3">Fig. 3f, h</xref>), with both fast and slow oscillations.</p><p hwp:id="p-39">The TF shows slow oscillations with a period of about 2.5 kHz, and rapid ones with a period of about 150 Hz. We isolated the effect of the delay to the first echo on the periodic structure of the TF by windowing the IR to remove the later echoes and observing the effect on its TF. The red plot in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-14" hwp:rel-id="F3">Fig. 3e</xref> depicts the original IR after all echoes were removed except the first one (originated by the floor), while the red plot in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-15" hwp:rel-id="F3">Fig. 3g</xref> depicts the corresponding approximation by two impulses. The corresponding TFs (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-16" hwp:rel-id="F3">Figs. 3f</xref> and <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-17" hwp:rel-id="F3">3h</xref>, red lines) preserved only slow oscillations. The yellow plots in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-18" hwp:rel-id="F3">Figs. 3e-h</xref> depict the IR after all echoes were windowed, resulting in a TF that had neither the slow oscillations nor the fast ones.</p><p hwp:id="p-40"><xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Figure 4</xref> quantifies these relationships in a different way. TFs recorded at higher positions above ground had faster oscillations than those recorded close to the ground (<xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-2" hwp:rel-id="F4">Fig. 4</xref>). This periodicity can be quantified by computing the cepstrum – the Fourier transform of the log amplitude of the TF. This analysis was performed on a frequency range of 3–40 kHz (<xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-3" hwp:rel-id="F4">Fig. 4a</xref>), within the frequency range of the speakers. <xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-4" hwp:rel-id="F4">Figure 4 b,d,f</xref> displays the TFs recorded at heights 1, 6, 11 cm, respectively, with the corresponding cepstra displayed in <xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-5" hwp:rel-id="F4">Figs. 4c,e,g</xref>. These plots clearly show the correlation between microphone’s height above the floor and the periodicity of the TF. Indeed, the time of the peak cepstrum corresponded well with the delay between the direct sound and the floor reflection (0.05 and 0.4 ms, as in <xref ref-type="fig" rid="figS8" hwp:id="xref-fig-15-2" hwp:rel-id="F15">Supp. Fig. 8</xref> and <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-19" hwp:rel-id="F3">Fig. 3c</xref>).</p><fig id="fig4" position="float" orientation="portrait" fig-type="figure" hwp:id="F4" hwp:rev-id="xref-fig-4-1 xref-fig-4-2 xref-fig-4-3 xref-fig-4-4 xref-fig-4-5 xref-fig-4-6 xref-fig-4-7"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Fig 4.</label><caption hwp:id="caption-4"><title hwp:id="title-18">Quefrency (frequency of the oscillations in the TF) increases with height above the floor.</title><p hwp:id="p-41"><bold>A</bold>. TF was calculated at microphone elevation of 1 cm above the floor. <bold>B</bold>. A frequency region of 0–40 kHz was cropped out and high-pass filtered. <bold>C</bold>. The power cepstrum of B., calculated as |<italic toggle="yes">IFFT</italic>(<italic toggle="yes">log</italic>(<italic toggle="yes">FFT</italic>|(<italic toggle="yes">S</italic>)|<sup>2</sup>))|<sup>2</sup>. The black arrow indicates the measured time delay between the direct sound and the first echo <bold>D</bold>. and <bold>E</bold>. Same as B and C, for a height of 6 cm. <bold>F</bold>. and <bold>G</bold>. Same as B and C, for a height of 11 cm.</p></caption><graphic xlink:href="321414_fig4" position="float" orientation="portrait" hwp:id="graphic-5"/></fig><p hwp:id="p-42">We conclude that the first echo in our arena introduces the slow oscillations while the later echoes are responsible for the fast ones. Although the slow oscillations were observable along most of the relevant frequency range (0–60 kHz), their amplitude didn’t exceed 10 dB. The fast oscillations, on the other hand, had much larger magnitude, sometimes spanning almost 60 dB within a few 10s of Hz.</p></sec><sec id="s3c" hwp:id="sec-13"><label>3.3</label><title hwp:id="title-19">Effect of speaker directivity on the TFs</title><p hwp:id="p-43">Speakers radiate sounds non-uniformly in space<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13"><sup>13</sup></xref>. Although the TF on the main axis of the speaker may have roughly constant amplitude (as in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-20" hwp:rel-id="F3">Fig. 3b</xref>), off-axis low frequencies tend to have higher amplitudes than high frequencies. A freely moving rodent is always located off the main axis of at least 10 speakers, making the directivity a factor that is to be considered in the acoustic calibration process.</p><p hwp:id="p-44">More formally, typical directivity patterns depend on the size of the speaker through the combination <italic toggle="yes">k</italic> ⋅ <italic toggle="yes">a</italic>, where <italic toggle="yes">k</italic> = <inline-formula hwp:id="inline-formula-4"><alternatives hwp:id="alternatives-5"><inline-graphic xlink:href="321414_inline4.gif" hwp:id="inline-graphic-4"/></alternatives></inline-formula>, with <italic toggle="yes">f</italic> the frequency, <italic toggle="yes">c</italic> the speed of sound and <italic toggle="yes">a</italic> the radius of the speaker. For <italic toggle="yes">k</italic> ⋅ <italic toggle="yes">a</italic> ≪ 1, the speaker is omnidirectional. For <italic toggle="yes">k</italic> ⋅ <italic toggle="yes">a</italic> &gt; 1, the radiation pattern has a typical shape of <inline-formula hwp:id="inline-formula-5"><alternatives hwp:id="alternatives-6"><inline-graphic xlink:href="321414_inline5.gif" hwp:id="inline-graphic-5"/></alternatives></inline-formula> for a <italic toggle="yes">g</italic> which is overall decreasing as a function of frequency, but may show a significant oscillatory behavior as well. Near the axis of the speaker, θ is small and the dependence on frequency is therefore weak. Farther away from the axis, the directivity pattern causes a frequency dependence which becomes stronger as the angle θ increases, and whose details depend on the exact function <italic toggle="yes">g</italic>.</p><p hwp:id="p-45">These directivity properties are thoroughly explained by Müller &amp; Möser (2013)<xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14"><sup>14</sup></xref> and Geddes (2009)<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15"><sup>15</sup></xref>. To evaluate the directivity of our speakers (since directivity specifications were not supplied by the manufacturer) we measured TFs for different angles θ relative to speaker’s main axis (<xref ref-type="fig" rid="fig5" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Fig. 5</xref>). The TFs were measured at 23 locations along a 50 cm circle around the speaker location. These 23 locations spanned a central angle of 120º around the speaker, one point on the principal axis and 11 on each side.</p><p hwp:id="p-46">We subtracted the TF at the point that coincides with the principal axis of the speaker from all other TFs to create relative TF profiles, shown in <xref ref-type="fig" rid="fig5" hwp:id="xref-fig-5-2" hwp:rel-id="F5">Fig. 5a</xref>. This measure preserves the relative attenuations along the different angles while removing location-independent distortions created by the imperfect audio equipment (loudspeaker and microphone). We compared these measurements with the expected directivity pattern of a disk vibrating in free space (<xref ref-type="disp-formula" rid="eqn2" hwp:id="xref-disp-formula-2-1" hwp:rel-id="disp-formula-2">Eq. 2</xref>, <xref ref-type="fig" rid="fig5" hwp:id="xref-fig-5-3" hwp:rel-id="F5">Fig. 5b</xref>), where the function g is known to be <italic toggle="yes">J</italic><sub>1,</sub> the Bessel function of the first kind (up to a numerical factor). <italic toggle="yes">c</italic> was the speed of sound at 20 C°, 343 m/s, and <italic toggle="yes">a</italic> the effective speaker radius (1.8 cm):</p><disp-formula id="eqn2" hwp:id="disp-formula-2" hwp:rev-id="xref-disp-formula-2-1">
<alternatives hwp:id="alternatives-7"><graphic xlink:href="321414_eqn2.gif" position="float" orientation="portrait" hwp:id="graphic-6"/></alternatives>
</disp-formula><p hwp:id="p-47">These plots display the sound power as a function of both the frequency and the angle from the speaker’s main axis. For the range of angles that we measured, frequencies below 15 kHz had an almost constant power. This is further visualized in <xref ref-type="fig" rid="fig5" hwp:id="xref-fig-5-4" hwp:rel-id="F5">Fig. 5c</xref>, where all the positions of the microphone are displayed, colored by the sound power. At higher frequencies, however, the sound is more attenuated off-axis than on-axis (<xref ref-type="fig" rid="fig5" hwp:id="xref-fig-5-5" hwp:rel-id="F5">Figs. 5d,e</xref>). We conclude that to avoid acoustic variability at high frequencies, the speaker should be selected so that the rat is as close as possible to its acoustic axis.</p></sec><sec id="s3d" hwp:id="sec-14"><label>3.4</label><title hwp:id="title-20">Narrow-band noise stimuli reduce the effects of fast fluctuations in TF amplitude</title><p hwp:id="p-48">The most problematic feature of the TFs identified above consists of the fast fluctuations in amplitude, which may be very large (dozens of dBs). We identified them as the consequence of the wall reflections, of which the earliest would occur at a delay on the order of the travel time along a diameter of the arena, which is about 5 ms. Thus, the slowest of the fast fluctuations occur over bandwidths of <inline-formula hwp:id="inline-formula-6"><alternatives hwp:id="alternatives-8"><inline-graphic xlink:href="321414_inline6.gif" hwp:id="inline-graphic-6"/></alternatives></inline-formula> 200 Hz. Longer delays would result in faster amplitude fluctuations.</p><p hwp:id="p-49">We show here how to reduce the effects of the fast fluctuations on sound amplitude through the use of narrow band stimuli instead of pure tones. Pure tones are widely used in auditory studies due to their simplicity, but in echoic environment their amplitude varies substantially from place to place as well as for different frequencies because of the fast fluctuations in the TFs. We generated narrow band stimuli as combinations of a large number of closely-spaced pure tones, superimposed at random phase. We reasoned that this superposition would average out the rapid fluctuations in the TFs, making sound level much less position- and frequency-dependent: at any location in the arena, some of the pure tone components would be strongly attenuated and other won’t, so that the overall power of the narrow band stimulus should be less variable than that of the individual pure tones composing it. The extent of this averaging can be controlled by the frequency span of the narrow band noise, which we set to 0.5 kHz (2.5 times the width of the typical fluctuation).</p><fig id="fig5" position="float" orientation="portrait" fig-type="figure" hwp:id="F5" hwp:rev-id="xref-fig-5-1 xref-fig-5-2 xref-fig-5-3 xref-fig-5-4 xref-fig-5-5 xref-fig-5-6"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIG5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">fig5</object-id><label>Fig 5.</label><caption hwp:id="caption-5"><title hwp:id="title-21">Speaker directivity.</title><p hwp:id="p-50"><bold>A</bold>. TFs were sampled at 23 locations, 11 at each side of the main speaker’s axis. All samples maintained a constant distance to the speaker (No.5). All TFs were stacked together and colored the sound power, then the TF at the central point was subtracted from each of them to produce the relative TF profile. <bold>B</bold>. Expected directivity for an oscillating round piston with the same radius as the speaker. <bold>C</bold>. Relative power at 5 kHz at all sampled locations. <bold>D</bold>. Same as C., at 25 kHz. <bold>E</bold>. Same as C, for 35 kHz.</p></caption><graphic xlink:href="321414_fig5" position="float" orientation="portrait" hwp:id="graphic-7"/></fig><p hwp:id="p-51">To assess the efficiency of the proposed method, we first recorded responses to a 10 s long frequency sweep spanning the range of 1 – 1.5 kHz, and verified that the amplitude fluctuations of the recorded signal (over a range of about 20 dB) were essentially equivalent to the power fluctuations of the TF measured using the Golay codes (<xref ref-type="fig" rid="figS9" hwp:id="xref-fig-16-1" hwp:rel-id="F16">Supp. Fig. 9</xref>). We then compared the envelope fluctuations of a slow pure tone frequency sweep and of a slow harrow band noise frequency sweep (see Methods for the details of the stimuli; <xref ref-type="fig" rid="fig6" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Fig. 6</xref>). The envelope of the pure tone sweep significantly fluctuated as the frequency changed over a 500 Hz range, due to the fast amplitude fluctuations in the TF. The pattern of the fluctuations varied as a function of the location (<xref ref-type="fig" rid="fig6" hwp:id="xref-fig-6-2" hwp:rel-id="F6">Figs. 6a</xref> and <xref ref-type="fig" rid="fig6" hwp:id="xref-fig-6-3" hwp:rel-id="F6">6b</xref> illustrate recordings at two locations 20 cm apart) and the frequency band (upper plots represent frequency sweep at 0.5–1 kHz, bottom represent 10–10.5 kHz, where the fast fluctuations are less apparent). As expected, narrow band stimuli had substantially lower amplitude fluctuations compared to pure tone sweep.</p><fig id="figS9" position="float" orientation="portrait" fig-type="figure" hwp:id="F16" hwp:rev-id="xref-fig-16-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS9</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F16</object-id><object-id pub-id-type="publisher-id">figS9</object-id><label>Supp. fig 9:</label><caption hwp:id="caption-16"><title hwp:id="title-39">Comparison of the amplitude fluctuations of a frequency sweep with those of the TF measured using the Golay codes</title><p hwp:id="p-82"><bold>A</bold>. A Frequency sweep (starting from 1 kHz and ending at 1.5 kHz, duration 10 s) was recorded by a statically located microphone at r=50cm, z=6cm. Bold black line represents the amplitude envelope of the signal <bold>B</bold>. A transfer function was calculated at the same location, using Golay of length 2<sup>14</sup>. The range 1–1.5 kHz (grayed area) is magnified on the right. <bold>C</bold>. The envelope of the sound is compared to the TF, that was converted to dB units using: Power=20·log<sub>10</sub>(Amplitude).</p></caption><graphic xlink:href="321414_figS9" position="float" orientation="portrait" hwp:id="graphic-18"/></fig><fig id="fig6" position="float" orientation="portrait" fig-type="figure" hwp:id="F6" hwp:rev-id="xref-fig-6-1 xref-fig-6-2 xref-fig-6-3 xref-fig-6-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIG6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">fig6</object-id><label>Fig 6.</label><caption hwp:id="caption-6"><title hwp:id="title-22">Narrow-band noise has lower amplitude variability than pure tones.</title><p hwp:id="p-52"><bold>A</bold>. Amplitude fluctuations as a function of time during a slow sweep of a tone (light grey) and a narrow noise band (dark grey and black). Both stimuli covered the same frequency range (1–1.5 and 10–10.5 kHz for the upper and bottom plots, respectively), played by same speaker, and recorded at the same location. <bold>B</bold>. Same as A, at a different location.</p></caption><graphic xlink:href="321414_fig6" position="float" orientation="portrait" hwp:id="graphic-8"/></fig><p hwp:id="p-53">Unfortunately, the same approach cannot work for the slow fluctuations in the TFs, caused by the floor reflections. These fluctuations are much slower – the notches vary in their periodicity, from two periods between 0–60 kHz when the microphone is 1 cm above the floor up to dozens of periods when the microphone is 10 cm above the floor (<xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-6" hwp:rel-id="F4">Fig. 4</xref>). One approach for minimizing the amplitude modulations across the arena, consists of using an average TF from many different locations and speakers as a guide for a robust stimulus generation. To demonstrate this approach, we averaged 4680 TFs that were sampled from all 12 loudspeakers at 390 locations (<xref ref-type="fig" rid="figS10" hwp:id="xref-fig-17-1" hwp:rel-id="F17">Supp. Fig. 10a</xref>), and looked for a wide range of frequencies that had minimal power span. <xref ref-type="fig" rid="figS10" hwp:id="xref-fig-17-2" hwp:rel-id="F17">Supp. Fig. 10b</xref> depicts this process and shows the resulting five narrow band stimuli picked at 7.5 kHz steps along a range of 30 kHz. The recorded amplitudes of these stimuli spanned only 10 dB range.</p><fig id="figS10" position="float" orientation="portrait" fig-type="figure" hwp:id="F17" hwp:rev-id="xref-fig-17-1 xref-fig-17-2 xref-fig-17-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS10</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F17</object-id><object-id pub-id-type="publisher-id">figS10</object-id><label>Supp. fig 10:</label><caption hwp:id="caption-17"><title hwp:id="title-40">Average TF of 390 location across the arena guides the creation of stable acoustic stimuli.</title><p hwp:id="p-83">A. Schematic of the 390 recording locations. All 12 speakers were sampled at each location, producing 4680 TFs. <bold>B</bold>. The TFs from A. were averaged (black line is the mean, grey area is the standard deviation). The average TF guides the creation of a stimulus set with minimal power variance (stimuli denoted by black dots). In this example, narrow-band sounds of [12.5 20 27.5 35 42.5] kHz span the frequency range of 30 kHz with power modulation of only 10 dB on average across all the recorded locations.</p></caption><graphic xlink:href="321414_figS10" position="float" orientation="portrait" hwp:id="graphic-19"/></fig></sec><sec id="s3e" hwp:id="sec-15"><label>3.5</label><title hwp:id="title-23">Acoustic localization of freely moving animal in 3D</title><p hwp:id="p-54">The traveling distance of the direct sound can be evaluated with precision of up to 0.3 cm (Results section B.). Given 3 distances from loudspeakers to the microphone, the later can be localized by numerical solution of the multi-lateration problem (see Methods and <xref ref-type="fig" rid="figS6" hwp:id="xref-fig-13-2" hwp:rel-id="F13">Supp. Fig. 6</xref>). If the microphone is carried by an animal, it can be used for 3D tracking as the animal freely moves through the environment. We tested this approach with freely moving rats that were carrying a headstage containing a microphone.</p><p hwp:id="p-55">Implementing this method requires solving two problems: First, the acoustic quality of the headstage microphone (denoted by HS) was inferior to the calibrated B&amp;K microphone (BK) we used for measuring the TFs. Second, the rat may move while the calibration sounds are presented, introducing inconsistencies in the distances used for multi-lateration. Both these factors reduce the localization accuracy. We therefore tested the accuracy of the method, varying the duration of the Golay pair (and therefore the SNR of the estimated IR) as well as the number of loudspeakers used for estimating the animal location. We performed these measurements on a static microphone as well as on a freely-moving rat carrying a headstage containing a microphone, verifying the localization of the rat using a concurrently collected video movie.</p><p hwp:id="p-56">The precision of the trilateration solution was assessed for statically placed microphones. First the acoustic localization was compared to manually determined location of the microphone, showing that the acoustic 3D localization is consistent with the true location of the microphone (<xref ref-type="fig" rid="fig7" hwp:id="xref-fig-7-1" hwp:rel-id="F7">Fig. 7a-b</xref>). Then ten repeats of the localization process were performed, each based on distances to all 12 loudspeakers (<xref ref-type="fig" rid="figS11" hwp:id="xref-fig-18-1" hwp:rel-id="F18">Supp. Fig. 11a</xref>, blue dots). The localization error was evaluated as the distance of the solution point from the cluster center, indicating the cluster volumetric spread. The mean errors were 0.061 cm and 0.099 cm for the BK and HS microphones respectively.</p><fig id="figS11" position="float" orientation="portrait" fig-type="figure" hwp:id="F18" hwp:rev-id="xref-fig-18-1 xref-fig-18-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS11</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F18</object-id><object-id pub-id-type="publisher-id">figS11</object-id><label>Supp. fig 11:</label><caption hwp:id="caption-18"><title hwp:id="title-41">3D Localization of a static microphone achieves sub cm precision, independent on microphone, Golay length or speaker number.</title><p hwp:id="p-84">A. The 3D localization was tested on a statically placed microphones (B&amp;K in left plots, Headstage in right ones). The localization was obtained based on distances to all 12 speakers. Two different stimulus configurations were tested: Golay of length 2<sup>12</sup> with silence buffer of 0.1 sec (blue dots) or Golay of length 2<sup>14</sup> with silence buffer of 0.2 sec (yellow dots). The localization was repeated 10 times for each condition to assess the variance. Axis represent spatial location relative to the center of the arena, in centimeters. B. Same experiment was repeated for localizations based on 3 speakers.</p></caption><graphic xlink:href="321414_figS11" position="float" orientation="portrait" hwp:id="graphic-20"/></fig><fig id="fig7" position="float" orientation="portrait" fig-type="figure" hwp:id="F7" hwp:rev-id="xref-fig-7-1 xref-fig-7-2 xref-fig-7-3 xref-fig-7-4 xref-fig-7-5 xref-fig-7-6"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIG7</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F7</object-id><object-id pub-id-type="publisher-id">fig7</object-id><label>Fig 7.</label><caption hwp:id="caption-7"><title hwp:id="title-24">Acoustic 3D localization of a freely moving animal</title><p hwp:id="p-57"><bold>A</bold>. A statically placed microphone was acoustically localized using the delays to the direct sounds emitted by 12 speakers (Golay codes of length 2<sup>16</sup> bits, 10 independent localizations marked by blue stems). The location of the microphone was manually evaluated with uncertainty error of 0.3 cm (projected to the three 2D planes as concentric circles). The mean spread of the localizations was 0.085 cm from the cluster center (black stem with red circle). <bold>B</bold>. Same as A. but for acoustic localization using 3 speakers, resulting in mean error of 0.12 cm. <bold>C</bold>. A pair of Golay codes (10<sup>12</sup> bits) are played by 3 different speakers (marked by colored dots) with 10 ms silence buffer in between. This sequence is recorded by the microphone as a continuous sound (blue plot) and is used to locate it in 3D. <bold>D</bold>. The precision of the localization depends on the sound to noise ratio of the IR, that is controlled by length of the Golay and the silence buffer. When both are long enough, the SNR is high (upper plot). Bottom plot displays an example of an IR with low SNR. <bold>E</bold>. Frames from Supp. Movie No.2 (Golay of length 10<sup>12</sup> bits, silence buffer 10 ms). The green dot is the centroid of the rat as registered by the camera, the yellow circle is the manual annotation of the location of the microphone and the red stem is the location of the microphone estimated acoustically, projected to the 2D image. <bold>F</bold>. Mean localization error of Supp. Movie No.2 is 1.5 cm (based on 50 measurements). The error is defined as a distance between the acoustic localization of the microphone, projected to the 2D image (the red point in E.) and the manual annotation (yellow circle).</p></caption><graphic xlink:href="321414_fig7" position="float" orientation="portrait" hwp:id="graphic-9"/></fig><p hwp:id="p-58">The superior precision of BK can be explained by the higher sampling rate we used for these measurements. Sampling at 192 kHz provided a resolution of <inline-formula hwp:id="inline-formula-7"><alternatives hwp:id="alternatives-9"><inline-graphic xlink:href="321414_inline7.gif" hwp:id="inline-graphic-7"/></alternatives></inline-formula>0.18 cm, while the sampling rate of the HS was limited by hardware constraints to 44 kHz, resulting in a resolution of <inline-formula hwp:id="inline-formula-8"><alternatives hwp:id="alternatives-10"><inline-graphic xlink:href="321414_inline8.gif" hwp:id="inline-graphic-8"/></alternatives></inline-formula> Another reason could be the inferior recording quality of HS, as shown in the strongly filtered TFs that were recorded by HS (TFs recorded at the same location of the arena are compared in <xref ref-type="fig" rid="figS12" hwp:id="xref-fig-19-1" hwp:rel-id="F19">Supp. Fig 12b</xref>). In consequence, the IRs estimated from HS had slower rise of the IR, as illustrated in <xref ref-type="fig" rid="figS12" hwp:id="xref-fig-19-2" hwp:rel-id="F19">Supp. Fig. 12a</xref> around 0.7 ms, complicating the detection of the onset latency and reducing localization accuracy. For both BK and HS, the 3D localization error was a few times smaller than the distance resolution. We believe this decrease is the result of combining the twelve distances during the multi-lateration process.</p><fig id="figS12" position="float" orientation="portrait" fig-type="figure" hwp:id="F19" hwp:rev-id="xref-fig-19-1 xref-fig-19-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS12</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F19</object-id><object-id pub-id-type="publisher-id">figS12</object-id><label>Supp. fig 12:</label><caption hwp:id="caption-19"><title hwp:id="title-42">Comparison of the B&amp;K and the HeadStage (HS) microphones TFs.</title><p hwp:id="p-85">Both microphones were placed 5 cm from the speaker and the IR and TF were measured using Golay of length 2<sup>16</sup>. The measurement was repeated 5 times (solid line indicates the average, the shaded area is standard deviation). Blue color shows the B&amp;K results, orange for HS. <bold>A</bold>. IRs. <bold>B</bold>. TFs.</p></caption><graphic xlink:href="321414_figS12" position="float" orientation="portrait" hwp:id="graphic-21"/></fig><p hwp:id="p-59">We studied the precision of the localization as a function of the parameters of the sound presentation protocol. A localization protocol consisted of selecting the speakers from which the sounds would be presented, as well as the durations of the Golay code and of the silence buffer. For example, <xref ref-type="fig" rid="fig7" hwp:id="xref-fig-7-2" hwp:rel-id="F7">Fig. 7c</xref> shows the sound recorded during a localization protocol consisting of 3 speakers, each playing a pair of Golay codes. Each Golay code was 2<sup>12</sup> bits long (sampled at 192 kHz, thus lasting <inline-formula hwp:id="inline-formula-9"><alternatives hwp:id="alternatives-11"><inline-graphic xlink:href="321414_inline9.gif" hwp:id="inline-graphic-9"/></alternatives></inline-formula>, with a silence buffer of 10 ms in between. As already mentioned, the precision of the determination of the speaker-microphone distance depends on the precision of the IR onset. The precision of the IR onset mainly depends on two factors: The power of the calibration sound (regulated by the Golay code length, in bits) and the duration of the silence buffer between successive Golay sequences (within and across pairs): this duration determines the perturbation caused by one Golay sequence on the next one. Thus, there is a tradeoff between the SNR of an IR and the length of the localization cue. For example, using Golay sequences of length 2<sup>16</sup> bits and silence buffer of 0.2 sec resulted in clear IR onset (<xref ref-type="fig" rid="fig7" hwp:id="xref-fig-7-3" hwp:rel-id="F7">Fig. 7d</xref>, top) while using Golay sequences of length 2<sup>10</sup> bits and silence buffer of 0.01 sec resulted in substantial fluctuations around the IR onset, masking the exact onset (<xref ref-type="fig" rid="fig7" hwp:id="xref-fig-7-4" hwp:rel-id="F7">Fig. 7d</xref>, bottom; <xref ref-type="fig" rid="figS13" hwp:id="xref-fig-20-1" hwp:rel-id="F20">Supp. Fig. 13</xref>).</p><fig id="figS13" position="float" orientation="portrait" fig-type="figure" hwp:id="F20" hwp:rev-id="xref-fig-20-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS13</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F20</object-id><object-id pub-id-type="publisher-id">figS13</object-id><label>Supp. fig 13:</label><caption hwp:id="caption-20"><title hwp:id="title-43">Both Golay and silence buffer length affect the SNR of the impulse response.</title><p hwp:id="p-86">Impulse response was calculated for Golay cues of varying length (from 2<sup>16</sup> in upper row down to 2<sup>10</sup> in the bottom row) and for varying silence buffers (from 200 ms in the left column down to 10 ms in the right column) and rescaled to their individual maximum. The plots represent the first 10 ms of the impulse response, focusing on the direct sound onset at the microphone location. Sounds played and sampled at 192 kHz by B&amp;K microphone.</p></caption><graphic xlink:href="321414_figS13" position="float" orientation="portrait" hwp:id="graphic-22"/></fig><p hwp:id="p-60">The duration of the localization process can be furthermore shortened by reducing the number of speakers. While three speakers are enough to define a trilateration problem, adding more speakers would improve the precision. However, each additional speaker prolongs the localization process. For example, trilateration based on 3 speakers requires only 3 pairs of Golay codes to be played while trilateration based on 12 speakers is more than 4 times longer (<xref ref-type="fig" rid="figS14" hwp:id="xref-fig-21-1" hwp:rel-id="F21">Supp. Fig. 14</xref>). We tested the effect of the speakers set size on microphones at a fixed position, by using only 3 speakers for the localization of a static microphone (<xref ref-type="fig" rid="figS11" hwp:id="xref-fig-18-2" hwp:rel-id="F18">Supp. Fig. 11b</xref>). The localization error grew to 0.21 cm and 0.44 cm for BK and HS as expected, but maintained sub-centimeter precision. We concluded that three speakers are enough for precise localization.</p><fig id="figS14" position="float" orientation="portrait" fig-type="figure" hwp:id="F21" hwp:rev-id="xref-fig-21-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS14</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F21</object-id><object-id pub-id-type="publisher-id">figS14</object-id><label>Supp. fig 14:</label><caption hwp:id="caption-21"><title hwp:id="title-44">Localization cue length (ms) as a function of Golay length, silence buffer length and number of speakers that were used during the localization.</title><p hwp:id="p-87">An acoustic localization of the microphone is obtained by playing a localization sound. This sound is comprised of a Golay pairs being played by at least 3 speakers, one at a time, with silence buffers in between. Denote number of speakers by <italic toggle="yes">N</italic>, Golay code length (bits) by <italic toggle="yes">G</italic> and silence buffers (ms) by <italic toggle="yes">t<sub>b</sub></italic>. The sound duration (in ms) is calculated as follows (sampled as 192 kHz): <inline-formula hwp:id="inline-formula-13"><alternatives hwp:id="alternatives-15"><inline-graphic xlink:href="321414_inline13.gif" hwp:id="inline-graphic-13"/></alternatives></inline-formula> Orange shading stands for localization cues that are too short to successfully localize the microphone (due to low SNR). Green shading is the shortest localization cue that can be used for the localization task.</p></caption><graphic xlink:href="321414_figS14" position="float" orientation="portrait" hwp:id="graphic-23"/></fig><p hwp:id="p-61">Lastly, we tested the acoustic localization on a freely moving rat. We tried four localization protocols that differed in Golay and silence buffer lengths, as well as the number of speakers (listed in <xref ref-type="fig" rid="figS15" hwp:id="xref-fig-22-1" hwp:rel-id="F22">Supp. Fig. 15</xref> with the corresponding localization precision). Each protocol was comprised of 50 localization trials, played once every 2 s, and the signal recorded by HS was stored for offline analysis. Additionally, a visual localization was performed using a camera. The acoustic localization error was determined as the distance from the acoustically reconstructed location of the microphone (Red dot in <xref ref-type="fig" rid="fig7" hwp:id="xref-fig-7-5" hwp:rel-id="F7">Fig. 7e</xref>., Supp. movies 1–4) to the manually annotated location of the headstage (empty yellow circle; see Methods). The highest accuracy was obtained for a protocol using 3 speakers, a Golay code length of 2<sup>12</sup> bits, and silence buffers of 0.01 s, resulting in a mean error of 1.5 cm even for fast movement bursts (<xref ref-type="fig" rid="fig7" hwp:id="xref-fig-7-6" hwp:rel-id="F7">Fig. 7e,f</xref> and Supp. Movie 2). Shorter Golay codes (of 2<sup>11</sup> bits) led to increased mean error, reaching 4 cm on average (<xref ref-type="fig" rid="figS15" hwp:id="xref-fig-22-2" hwp:rel-id="F22">Supp Fig. 15a</xref>.), significantly worse than similar localization cue with Golay of length 2<sup>12</sup> (<xref ref-type="fig" rid="figS15" hwp:id="xref-fig-22-3" hwp:rel-id="F22">Supp. Fig. 15b</xref>). Similarly, using more than 3 speakers led to decreased precision (<xref ref-type="fig" rid="figS15" hwp:id="xref-fig-22-4" hwp:rel-id="F22">Supp. Fig. 15c, d</xref>), presumably due to prolonged localization protocols.</p><fig id="figS15" position="float" orientation="portrait" fig-type="figure" hwp:id="F22" hwp:rev-id="xref-fig-22-1 xref-fig-22-2 xref-fig-22-3 xref-fig-22-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;321414v1/FIGS15</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F22</object-id><object-id pub-id-type="publisher-id">figS15</object-id><label>Supp. fig 15:</label><caption hwp:id="caption-22"><title hwp:id="title-45">Measured localization error of a freely moving animal as a function of Golay length, buffer length and number of speakers.</title><p hwp:id="p-88">Four sound configurations were tested for freely moving rat localization. The error was measured as the distance between the acoustical localization and the manual annotation of the microphone location. <bold>A</bold>. Golay of length 2<sup>11</sup> samples, silence buffer length of 0.01 sec and localization based on 3 speakers, denoted as G11B0.01S3. The test can be viewed in Supp. Movie 1. <bold>B</bold>. Golay = 2<sup>12</sup>, silence buffer = 0.01 sec, 3 speakers. See Supp. movie 2 <bold>C</bold>. Golay = 2<sup>12</sup>, silence buffer = 0.02 sec, 4 speakers. See Supp. movie 3 <bold>D</bold>. Golay = 2<sup>12</sup>, silence buffer = 0.03 sec, 4 speakers. See Supp. movie 4.</p></caption><graphic xlink:href="321414_figS15" position="float" orientation="portrait" hwp:id="graphic-24"/></fig></sec></sec><sec id="s4" hwp:id="sec-16"><label>4</label><title hwp:id="title-25">DISCUSSION</title><p hwp:id="p-62">We used Golay complementary sequences to estimate impulse response (IR) of the arena<sup><xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-3" hwp:rel-id="ref-5">5</xref>,<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-3" hwp:rel-id="ref-6">6</xref></sup>. We demonstrate a principled analysis of the IRs, identifying the geometric basis for their structure, the resulting distortions in the frequency domain, and suggesting approaches for minimizing the acoustic inhomogeneities as a function of frequency and spatial location. We then demonstrate a viable, high precision localization of the animal using the same hardware used to calibrate the arena.</p><sec id="s4a" hwp:id="sec-17"><label>4.1</label><title hwp:id="title-26">Automated calibration pipeline</title><p hwp:id="p-63">This study introduces a pipeline for acoustic calibration of echoic environments, which was successfully applied to our own setup. The initial step of the sound sampling is a laborious task, if performed manually: Sound samples are to be collected at high spatial resolution along few meter-wide environment, due to high variability of perturbations between two adjacent locations. Moreover, the IR has to be calculated individually for each speaker, increasing the recordings count to hundreds. Clearly, a fully automated sampling system is the only way to address this challenge. We achieved it using a programmable robot that performed the sound sampling routine, autonomously operating for hours over hundreds of predefined recording locations.</p></sec><sec id="s4b" hwp:id="sec-18" hwp:rev-id="xref-sec-18-1"><label>4.2</label><title hwp:id="title-27">Characterizing the acoustic properties of the arena</title><p hwp:id="p-64">The IRs had relatively simple structure, consisting of a direct sound, a short-delay floor reflection, and longer delay wall reflections (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-10" hwp:rel-id="F2">Figs. 2</xref>, <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-21" hwp:rel-id="F3">3</xref>). We showed that both floor and the wall echoes were clearly visible on the IR, across most locations and speakers, and that these reflections determined much of the spectral distortions in the TFs. Importantly, we did not detect echoes from sources outside the arena, including the ceiling. The ceiling is located 2.1 meter above the arena’s floor, reflecting echoes with approximate traveling path of 4.2 m, corresponding to ToA of 12–13 ms. Perturbations are indeed visible on the IR at about 12 ms (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-22" hwp:rel-id="F3">Fig. 3b</xref>, blue arrow), but we identified them with the second wall reflection, which also had ToA of 12 ms. The absence of a ceiling reflection could be due to the directivity of the loudspeakers: the ceiling was approximately located at 125 degrees off the acoustic axis, and the amplitude of the sound could be substantially lower at the direction even at the lowest frequencies of interest. This observation supports the simplifying assumption that the acoustic effects of external objects are negligible, and the arena can be modeled as an environment with only two sources of echo – the floor and the wall.</p><p hwp:id="p-65">Approximating the IR as a sequence of echoes made it easy to understand the structure of the spectral distortions: echoes cause periodic fluctuations in the amplitude of the TFs, with the time intervals between echoes determining the rate of these fluctuations. Short time intervals resulted in slow fluctuations, while long time intervals resulted in rapid fluctuations in the TF (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-23" hwp:rel-id="F3">Fig. 3e-h</xref>).</p><p hwp:id="p-66">We believe that one reason for the relatively simple structure of the IRs is the use of a large, circular arena. This caused a clear separation in time between the floor and wall reflections. Since we showed that the effects of the wall reflections can be largely neutralized through the use of narrowband stimuli, further optimization of the arena for acoustic purposes would consist of reducing the floor reflections. This can be achieved by using absorbing or dispersing materials on the floor, although this would complicate the maintenance of the arena.</p><p hwp:id="p-67">An effective way of minimizing the distortions is a guided design of the auditory stimuli. It is advisable to use mostly frequencies below about 15 kHz to avoid the influence of speaker directivity (<xref ref-type="fig" rid="fig5" hwp:id="xref-fig-5-6" hwp:rel-id="F5">Fig. 5</xref>), to use narrow band stimuli instead of pure tones (<xref ref-type="fig" rid="fig6" hwp:id="xref-fig-6-4" hwp:rel-id="F6">Fig. 6</xref>) to reduce the effects of wall reflections, and to be guided by an average TF profile as in <xref ref-type="fig" rid="figS10" hwp:id="xref-fig-17-3" hwp:rel-id="F17">Supp. Fig. 10</xref>.</p><p hwp:id="p-68">The calibration pipeline may be extended for generating narrowband stimuli, based on the following steps: Record IRs across the arena and compute their TFs, calculate the frequency of the fast spectral notches (the quefrency peak, as in <xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-7" hwp:rel-id="F4">fig. 4</xref>), generate the narrow band stimuli and measure their amplitude as a function of center frequency in order to evaluate their performance. These stimuli can provide best fitting acoustic cues for the unique geometry of the specific setup.</p></sec><sec id="s4c" hwp:id="sec-19" hwp:rev-id="xref-sec-19-1"><label>4.3</label><title hwp:id="title-28">Application of the acoustic localization of freely moving animals</title><p hwp:id="p-69">We developed a 3D acoustic localization technique that provides a spatial resolution of about 1.5 centimeter in 160 cm wide environment. Hardware pre-requisites of the acoustic localization are three speakers, a microphone, and synchronized clocks of the sound reproducing and recording equipment. It is worth noting that the presented method particularly fits experimental setups that possess integrated microphones on the head stages or body harnesses of the animals.</p><p hwp:id="p-70">There are a number of advantages of the method over alternatives: Its hardware pre-requisites are relatively modest, especially beneficial for those setups that already utilize acoustic equipment; The localization is performed in a fraction of a second in a closed room, due to the small time interval that is required for sounds to cross a few meter environment; It has no footprint on the electrophysiological recordings, since no electro-magnetic disturbance is introduces; and it acquires all three volumetric coordinates (X, Y, Z).</p><p hwp:id="p-71">The main disadvantage of 3D acoustic localization is the need to use audible sounds that may interfere with the acoustic paradigm of the scheduled experiment, or may generally stress the animal. It also has a relatively low temporal resolution, limited by the durations of the Golay code and the silence buffer. The temporal resolution achieved here is limited to about 5 Hz.</p></sec></sec></body><back><ack hwp:id="ack-1"><label>5</label><title hwp:id="title-29">ACKNOWLEDGEMENTS</title><p hwp:id="p-72">The authors thank Dr. Maciej M. Jankowski and Ana Polterovich for awake rat recordings. This work was supported by a European Research Council (ERC) advanced grant GA-340063 (project RATLAND), by F.I.R.S.T. grant no. 1075/2013 from the Israel Science Foundation to IN, and by a grant from the Gatsby Charitable Foundation.</p></ack><ref-list hwp:id="ref-list-1"><label>6</label><title hwp:id="title-30">BIBLIOGRAPHY</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1 xref-ref-1-2"><label>1.</label><citation publication-type="journal" citation-type="journal" ref:id="321414v1.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Jow U. M."><surname>Jow</surname>, <given-names>U. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kiani M."><surname>Kiani</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Huo X."><surname>Huo</surname>, <given-names>X.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Ghovanloo M."><surname>Ghovanloo</surname>, <given-names>M.</given-names></string-name> <article-title hwp:id="article-title-2">Towards a smart experimental arena for long-term electrophysiology experiments</article-title>. <source hwp:id="source-1">IEEE Trans. Biomed. Circuits Syst</source>. <volume>6</volume>, <fpage>414</fpage>–<lpage>423</lpage> (<year>2012</year>).</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1"><label>2.</label><citation publication-type="journal" citation-type="journal" ref:id="321414v1.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Fan D."><surname>Fan</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-3">A Wireless Multi-Channel Recording System for Freely Behaving Mice and Rats</article-title>. <source hwp:id="source-2">PLoS One</source> <volume>6</volume>, <fpage>e22033</fpage> (<year>2011</year>).</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><label>3.</label><citation publication-type="thesis" citation-type="thesis" ref:id="321414v1.3" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Warren C."><surname>Warren</surname>, <given-names>C.</given-names></string-name> <article-title hwp:id="article-title-4">Impulse response measurement using complementary sequences</article-title>. PhD thesis (<publisher-loc>University of California at San Diego</publisher-loc>, <year>2014</year>).</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1"><label>4.</label><citation publication-type="journal" citation-type="journal" ref:id="321414v1.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Schroeder M. R."><surname>Schroeder</surname>, <given-names>M. R.</given-names></string-name> <article-title hwp:id="article-title-5">Integrated-impulse method measuring sound decay without using impulses</article-title>. <source hwp:id="source-3">J. Acoust. Soc. Am</source>. <volume>66</volume>, <fpage>497</fpage>–<lpage>500</lpage> (<year>1979</year>).</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1 xref-ref-5-2 xref-ref-5-3"><label>5.</label><citation publication-type="journal" citation-type="journal" ref:id="321414v1.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Foster S."><surname>Foster</surname>, <given-names>S.</given-names></string-name> <article-title hwp:id="article-title-6">Impulse response measurement using Golay codes</article-title>. in <source hwp:id="source-4">ICASSP ‘86. IEEE International Conference on Acoustics, Speech, and Signal Processing</source> <volume>11</volume>, <fpage>929</fpage>–<lpage>932</lpage> (Institute of Electrical and Electronics Engineers, <year>1986</year>).</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2 xref-ref-6-3"><label>6.</label><citation publication-type="journal" citation-type="journal" ref:id="321414v1.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Zhou B."><surname>Zhou</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Green D. M."><surname>Green</surname>, <given-names>D. M.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Middlebrooks J. C."><surname>Middlebrooks</surname>, <given-names>J. C.</given-names></string-name> <article-title hwp:id="article-title-7">Characterization of external ear impulse responses using Golay codes</article-title>. <source hwp:id="source-5">J. Acoust. Soc. Am</source>. <volume>92</volume>, <fpage>1169</fpage>–<lpage>1171</lpage> (<year>1992</year>).</citation></ref><ref id="c7" hwp:id="ref-7"><label>7.</label><citation publication-type="journal" citation-type="journal" ref:id="321414v1.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Jacobson G."><surname>Jacobson</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Poganiatz I."><surname>Poganiatz</surname>, <given-names>I.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Nelken I."><surname>Nelken</surname>, <given-names>I.</given-names></string-name> <article-title hwp:id="article-title-8">Synthesizing spatially complex sound in virtual space: an accurate offline algorithm</article-title>. <source hwp:id="source-6">J. Neurosci. Methods</source> <volume>106</volume>, <fpage>29</fpage>–<lpage>38</lpage> (<year>2001</year>).</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><label>8.</label><citation publication-type="journal" citation-type="journal" ref:id="321414v1.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Mrsic-flogel T. D."><surname>Mrsic-flogel</surname>, <given-names>T. D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="King A. J."><surname>King</surname>, <given-names>A. J.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Schnupp J. W. H."><surname>Schnupp</surname>, <given-names>J. W. H.</given-names></string-name> <article-title hwp:id="article-title-9">Encoding of Virtual Acoustic Space Stimuli</article-title> by <source hwp:id="source-7">Neurons in Ferret Primary Auditory Cortex</source>. (<year>2005</year>). doi:<pub-id pub-id-type="doi">10.1152/jn.00748.2004</pub-id></citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1"><label>9.</label><citation publication-type="journal" citation-type="journal" ref:id="321414v1.9" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Lai P."><surname>Lai</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Basso D."><surname>Basso</surname>, <given-names>D.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Fisher L."><surname>Fisher</surname>, <given-names>L.</given-names></string-name> <article-title hwp:id="article-title-10">3D Tracking of Mouse Locomotion Using Shape-From-Silhouette Techniques</article-title>. <source hwp:id="source-8">Icpv</source> <fpage>18</fpage>–<lpage>21</lpage> (<year>2011</year>).</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><label>10.</label><citation publication-type="journal" citation-type="journal" ref:id="321414v1.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Yovel Y."><surname>Yovel</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Falk B."><surname>Falk</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Moss C. F."><surname>Moss</surname>, <given-names>C. F.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Ulanovsky N."><surname>Ulanovsky</surname>, <given-names>N.</given-names></string-name> <article-title hwp:id="article-title-11">Optimal Localization by Pointing Off Axis</article-title>. <source hwp:id="source-9">Science (80-.)</source>. <fpage>701</fpage>–<lpage>705</lpage> (<year>2010</year>). doi:<pub-id pub-id-type="doi">10.1126/science.1183310</pub-id></citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><label>11.</label><citation publication-type="journal" citation-type="journal" ref:id="321414v1.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Kelly J. B."><surname>Kelly</surname>, <given-names>J. B.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Masterton B."><surname>Masterton</surname>, <given-names>B.</given-names></string-name> <article-title hwp:id="article-title-12">Auditory sensitivity of the albino rat</article-title>. <source hwp:id="source-10">J. Comp. Physiol. Psychol</source>. <volume>91</volume>, <fpage>930</fpage>–<lpage>936</lpage> (<year>1977</year>).</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1 xref-ref-12-2"><label>12.</label><citation publication-type="others" citation-type="journal" ref:id="321414v1.12" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-12"><collab hwp:id="collab-1">TUCKER-DAVIS TECHNOLOGIES. MF1 Multi-Field Magnetic Speakers Specification</collab>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.tdt.com/files/manuals/Sys3Manual/MF1.pdf" ext-link-type="uri" xlink:href="http://www.tdt.com/files/manuals/Sys3Manual/MF1.pdf" hwp:id="ext-link-2">http://www.tdt.com/files/manuals/Sys3Manual/MF1.pdf</ext-link></citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1"><label>13.</label><citation publication-type="others" citation-type="journal" ref:id="321414v1.13" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Frontiers A."><surname>Frontiers</surname>, <given-names>A.</given-names></string-name> <collab hwp:id="collab-2">inc. Speaker Directivity</collab>. (<year>2013</year>). Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.acousticfrontiers.com/20131129controlled-directivity-speakers-open-up-your-acoustic-treatment-options/" ext-link-type="uri" xlink:href="http://www.acousticfrontiers.com/20131129controlled-directivity-speakers-open-up-your-acoustic-treatment-options/" hwp:id="ext-link-3">http://www.acousticfrontiers.com/20131129controlled-directivity-speakers-open-up-your-acoustic-treatment-options/</ext-link>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><label>14.</label><citation publication-type="book" citation-type="book" ref:id="321414v1.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Möser M."><surname>Möser</surname>, <given-names>M.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Müller G."><surname>Müller</surname>, <given-names>G.</given-names></string-name> <chapter-title>Handbook of Engineering Acoustics</chapter-title>. (<publisher-name>Springer</publisher-name> <publisher-loc>Berlin Heidelberg</publisher-loc>, <year>2013</year>). doi:<pub-id pub-id-type="doi">10.1007/978-3-540-69460-1</pub-id></citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><label>15.</label><citation publication-type="other" citation-type="journal" ref:id="321414v1.15" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Geddes E."><surname>Geddes</surname>, <given-names>E.</given-names></string-name> <article-title hwp:id="article-title-13">Directivity in Loudspeaker Systems</article-title>. <fpage>1</fpage>–<lpage>14</lpage> (<year>2009</year>).</citation></ref></ref-list></back></article>
