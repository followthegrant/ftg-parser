<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/013227</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;013227v1</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;013227</article-id><article-id pub-id-type="other" hwp:sub-type="slug">013227</article-id><article-id pub-id-type="other" hwp:sub-type="tag">013227</article-id><article-version>1.1</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Genetics" hwp:journal="biorxiv"><subject>Genetics</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">Scaling probabilistic models of genetic variation to millions of humans</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1 xref-corresp-1-2">
<label>*</label>Address for correspondence: <email hwp:id="email-1">david.blei@columbia.edu</email>, <email hwp:id="email-2">jstorey@princeton.edu</email></corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" hwp:id="contrib-1"><name name-style="western" hwp:sortable="Gopalan Prem"><surname>Gopalan</surname><given-names>Prem</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref></contrib><contrib contrib-type="author" hwp:id="contrib-2"><name name-style="western" hwp:sortable="Hao Wei"><surname>Hao</surname><given-names>Wei</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-3"><name name-style="western" hwp:sortable="Blei David M."><surname>Blei</surname><given-names>David M.</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-1" hwp:rel-id="aff-3">3</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*</xref></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-4"><name name-style="western" hwp:sortable="Storey John D."><surname>Storey</surname><given-names>John D.</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-2" hwp:rel-id="aff-2">2</xref><xref ref-type="aff" rid="a4" hwp:id="xref-aff-4-1" hwp:rel-id="aff-4">4</xref><xref ref-type="aff" rid="a5" hwp:id="xref-aff-5-1" hwp:rel-id="aff-5">5</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-2" hwp:rel-id="corresp-1">*</xref></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1">
<label>1</label>
<institution hwp:id="institution-1">Department of Computer Science, Princeton University</institution>, Princeton NJ 08544 <country>USA</country>
</aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1 xref-aff-2-2">
<label>2</label>
<institution hwp:id="institution-2">Lewis-Sigler Institute for Integrative Genomics, Princeton University</institution>, Princeton NJ 08544 <country>USA</country>
</aff><aff id="a3" hwp:id="aff-3" hwp:rev-id="xref-aff-3-1">
<label>3</label>
<institution hwp:id="institution-3">Departments of Statistics and Computer Science, Columbia University</institution>, New York NY 10027 <country>USA</country>
</aff><aff id="a4" hwp:id="aff-4" hwp:rev-id="xref-aff-4-1">
<label>4</label>
<institution hwp:id="institution-4">Center for Statistics and Machine Learning, Princeton University</institution>, Princeton NJ 08544 <country>USA</country>
</aff><aff id="a5" hwp:id="aff-5" hwp:rev-id="xref-aff-5-1">
<label>5</label>
<institution hwp:id="institution-5">Department of Molecular Biology, Princeton University</institution>, Princeton NJ 08544 <country>USA</country>
</aff></contrib-group><pub-date pub-type="epub-original" hwp:start="2014"><year>2014</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2014-12-24T11:21:12-08:00">
    <day>24</day><month>12</month><year>2014</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2014-12-24T11:21:12-08:00">
    <day>24</day><month>12</month><year>2014</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2014-12-24T11:45:17-08:00">
    <day>24</day><month>12</month><year>2014</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2014-12-24T11:45:17-08:00">
    <day>24</day><month>12</month><year>2014</year>
  </pub-date><elocation-id>013227</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2014-12-24"><day>24</day><month>12</month><year>2014</year></date>
<date date-type="accepted" hwp:start="2014-12-24"><day>24</day><month>12</month><year>2014</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2014, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2014</copyright-year><license hwp:id="license-1"><p hwp:id="p-1">The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.</p></license></permissions><self-uri xlink:href="013227.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2019/pdf/013227v1.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="013227.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2019/abstracts/013227v1/013227v1.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2019/fulltext/013227v1/013227v1.htslp"/><abstract hwp:id="abstract-1"><p hwp:id="p-2">A major goal of population genetics is to quantitatively understand variation of genetic polymorphisms among individuals. Researchers have developed sophisticated statistical methods to capture the complex population structure that underlies observed genotypes in humans. The number of humans that have been densely genotyped across the genome has grown sig-nificantly in recent years. In aggregate about 1M individuals have been densely genotyped to date, and if we could analyze this data then we would have a nearly complete picture of human genetic variation. Existing state-of-the-art methods, however, cannot scale to data of this size. To this end, we have developed TeraStructure. TeraStructure is a new algorithm to fit Bayesian models of genetic variation in human populations on tera-sample-sized data sets (10<sup>12</sup> observed genotypes, e.g., 1M individuals at 1M SNPs). It is a principled approach to approximate Bayesian inference that iterates between subsampling locations of the genome and updating an estimate of the latent population structure. On real and simulated data sets of up to 10K individuals, TeraStructure is twice as fast as existing methods and recovers the latent population structure with equal accuracy. On genomic data simulated at the tera-sample-size scales, TeraStructure continues to be accurate and is the only method that can complete its analysis.</p><sec hwp:id="sec-1"><title hwp:id="title-1">Software</title><p hwp:id="p-3">T<sc>era</sc>S<sc>tructure</sc> is available for download at <ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/premgopalan/terastructure" ext-link-type="uri" xlink:href="https://github.com/premgopalan/terastructure" hwp:id="ext-link-1">https://github.com/premgopalan/terastructure</ext-link>.</p></sec><sec hwp:id="sec-2"><title hwp:id="title-2">Funding</title><p hwp:id="p-4">This research was supported in part by NIH grant R01 HG006448 and ONR grant N00014-12-1-0764.</p></sec></abstract><kwd-group kwd-group-type="author" hwp:id="kwd-group-1"><kwd hwp:id="kwd-1">Keywords</kwd><kwd hwp:id="kwd-2">admixture</kwd><kwd hwp:id="kwd-3">population structure</kwd><kwd hwp:id="kwd-4">scalable data analysis</kwd><kwd hwp:id="kwd-5">stochastic optimization</kwd><kwd hwp:id="kwd-6">variational inference</kwd></kwd-group><counts><page-count count="30"/></counts><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-1">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta></front><body><sec id="s1" hwp:id="sec-3"><title hwp:id="title-3">INTRODUCTION</title><p hwp:id="p-5">The quantitative characterization of genetic polymorphisms in human populations plays a key role in understanding evolution, migration, and trait variation. Genetic variation of humans is highly structured in that frequencies of genetic polymorphisms depend strongly on ancestry and evolutionary forces that vary among individuals. Therefore, to comprehensively understand human genetic variation, we must also understand the underlying structure of human populations.</p><p hwp:id="p-6">Over the last fifteen years, scientists have successfully used genome-wide Bayesian models of genetic polymorphisms to infer the latent structure embedded in an observed population. The probabilistic model of Pritchard, Stephens and Donnelly <xref rid="c1" ref-type="bibr" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">[1]</xref>, which we will refer to as the “PSD model”, has become a standard tool both for exploring hypotheses about human genetic variation and for taking latent structure into account in downstream analyses. The basic idea behind the PSD model is that each individual’s ancestry is composed of a mixture of ancestral populations, and an individual’s genotype can thus be modeled as a random process that mixes the frequencies of genetic variants from among these ancestral populations.</p><p hwp:id="p-7">The PSD model turns the problem of estimating ancestral population structure into one of posterior inference, i.e., estimating a conditional distribution. The assumed genomic structure—the population proportions for each individual and the allele frequencies for each population—are hidden random variables in the model; the collection of individuals at a collection of SNPs <italic toggle="yes">x={x<sub>i,ℓ</sub>}</italic> are observed random variables. The main computational problem for the PSD model is to estimate the posterior distribution of the hidden population structure given the data, <italic toggle="yes">p(β, θ | x)</italic>. With this posterior, or posterior means of the hidden variables, population geneticists can explore the latent structure of their data and correct for ancestry in downstream analyses. Like many modern Bayesian models, this posterior is not tractable to compute: the original algorithm for using the PSD model <xref rid="c1" ref-type="bibr" hwp:id="xref-ref-1-2" hwp:rel-id="ref-1">[1]</xref> and subsequent innovations <xref rid="c2" ref-type="bibr" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">[2]</xref> <xref rid="c3" ref-type="bibr" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">[3]</xref> are all methods for approximating it.</p><p hwp:id="p-8">Modern genetics, however, cannot take full advantage of the PSD model and related probabilistic models. The reason is that the existing solutions to the core computational problem—the problem of estimating the latent ancestral structure given a collection of observed genetic data—cannot handle the scale of modern datasets. They require repeatedly iterating through the entire data set to form its approximation. With massive data sets, this is not a practical methodology.</p><p hwp:id="p-9">The sample sizes of genome-wide association studies now routinely involve tens of thousands of people. Public and private initiatives have managed to measure genome-wide genetic variation on hundreds of thousands of individuals. For example, a recent study by the company 23andme used genotypes from 162,721 individuals <xref rid="c4" ref-type="bibr" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">[4]</xref>. Taken together, we now have dense genome-wide genotype data on the order of a million individuals. Fitting probabilistic models on these data would provide an unprecedented characterization of genetic variation and the structure of human populations. But, as we show in our study, this analysis is not possible with the current state of the art.</p><p hwp:id="p-10">To this end, we have developed TeraStructure, an algorithm for analyzing data sets of up to 10<sup>12</sup> genotypes. It is based on “variational inference” <xref rid="c5" ref-type="bibr" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">[5]</xref> <xref rid="c6" ref-type="bibr" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">[6]</xref>, a general strategy for Bayesian computation that we can scale to massive data sets <xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">[7]</xref>. TeraStructure’s computational flow iterates between subsampling observed single nucleotide polymorphism (SNP) genotypes, analyzing the subsam-ple, and updating its estimate of the hidden ancestral populations.</p></sec><sec id="s2" hwp:id="sec-4"><title hwp:id="title-4">RESULTS</title><p hwp:id="p-11">TeraStructure provides a statistical estimate of the PSD model, capturing the heterogenous mixtures of ancestral populations that are inherent in a data set of observed human genomes. Formally, the PSD model assumes that there are <italic toggle="yes">K</italic> ancestral populations, each characterized by its minor allele frequencies <italic toggle="yes">β<sub>k</sub></italic> for each of the SNPs. Further, it assumes that each individual in the sample exhibits those populations with different proportions <italic toggle="yes">θ<sub>i</sub></italic>. Finally, it assumes that each SNP genotypeℓ in each individual <italic toggle="yes">i</italic>, denoted by <italic toggle="yes">x<sub>i, ℓ</sub></italic> is drawn from an ancestral population that itself is drawn from the individual-specific proportions. If we code each SNP genotype as a 0, 1, or 2 (to denote the three possible genotypes), then it models <italic toggle="yes">x<sub>i, ℓ</sub></italic> ∼ Binomial <italic toggle="yes">(2, p<sub>i, ℓ</sub>)</italic> where <italic toggle="yes">p<sub>i, ℓ</sub> = ∑<sub>k</sub> θ<sub>i, k</sub> β<sub>k, ℓ</sub></italic>.</p><p hwp:id="p-12">TeraStructure has a significantly different computational structure, which is illustrated in <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1</xref>. At each iteration, it maintains an estimate of the population proportions for each person and the allele frequencies for each population<xref rid="fn1" ref-type="fn" hwp:id="xref-fn-1-1" hwp:rel-id="fn-1"><sup>1</sup></xref>. It repeatedly iterates between the following steps: (a) sample a SNP from the data, <italic toggle="yes">x, <sub>ℓ</sub></italic>, the measured genotypes at a single site in the genome across all people, analyze how the current estimates of the ancestral populations explain the genotypes at that SNP, and update the estimates of the latent structure—both the ancestral allele frequencies and per-individual population proportions.</p><fig id="fig1" position="float" orientation="portrait" fig-type="figure" hwp:id="F1" hwp:rev-id="xref-fig-1-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;013227v1/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1:</label><caption hwp:id="caption-1"><p hwp:id="p-13">A schematic diagram of stochastic variational inference for the Pritchard-Stephens-Donnelly (PSD) model. The algorithm maintains an estimate of the latent population proportions for each individual. At each iteration it samples SNP measurements from the large database, infers the per-population frequencies for that SNP, and updates its idea of the population proportions. This is much more efficient than algorithms that must iterate across all SNPs at each iteration.</p></caption><graphic xlink:href="013227_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-14">It is the subsampling step of the inner loop that allows TeraStrucure to scale to massive genetic data. Rather than scan the entire population at each iteration, it iteratively subsamples a SNP, analyzes the subsample, and updates its estimate. On small data sets, this leads to faster estimates that are as good as those obtained by the slower procedures. More importantly, it lets us scale the PSD model up to sample sizes that are orders of magnitude greater than what the current state of the art can handle. We further emphasize that the technical approach behind TeraStructure—one that repeatedly subsamples from a massive data set and then updates an estimate of its hidden structure—can be adapted to many Bayesian models that are used in modern genetics research, such as HMMs, phylogenetic trees, and others.</p><p hwp:id="p-15">TeraStructure is built on variational inference, a method from the statistical machine learning literature that adapts ideas in statistical physics to solve a variety of approximate Bayesian inference problems. The main idea behind variational inference is as follows. We first parameterize individual distributions for each latent variable in the model, i.e., a distribution for each set of per-population allele frequencies <italic toggle="yes">q</italic>(<italic toggle="yes">β<sub>k</sub></italic>) and a distribution for each individual’s population proportions <italic toggle="yes">q</italic>(<italic toggle="yes">θ<sub>i</sub></italic>). We then fit these distributions so that their product is close to the true posterior, where closeness is measured by Kullback-Leibler divergence. (Kullback-Leibler is an information-theoretic quantity that asymmetrically measures the distance between two distributions.) Thus we do Bayesian inference by solving the following optimization problem, <disp-formula id="ueqn1" hwp:id="disp-formula-1">
<alternatives hwp:id="alternatives-1"><graphic xlink:href="013227_ueqn1.gif" position="float" orientation="portrait" hwp:id="graphic-2"/></alternatives></disp-formula></p><p hwp:id="p-16">The key idea in TeraStructure is to solve this optimization problem with <italic toggle="yes">stochastic variational inference</italic> <xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-2" hwp:rel-id="ref-7">[7]</xref>, an adaptation of the classical stochastic optimization algorithm <xref rid="c8" ref-type="bibr" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">[8]</xref> to variational inference. Specifically, we optimize the KL divergence by following noisy realizations of its derivatives, where the noise emerges from our subsampling the data at each iteration. The noisy derivatives are much cheaper to compute than the true derivatives, which require iterating over the entire data set. See Methods for the mathematical details that outline the variational objective function and how subsampling the data leads to noisy derivatives.</p><p hwp:id="p-17">We applied TeraStructure to both real and simulated data sets to study and demonstrate its good performance. We compared it to ADMIXTURE <xref rid="c2" ref-type="bibr" hwp:id="xref-ref-2-2" hwp:rel-id="ref-2">[2]</xref> and FASTSTRUCTURE <xref rid="c3" ref-type="bibr" hwp:id="xref-ref-3-2" hwp:rel-id="ref-3">[3]</xref>, the two algorithms for estimating the PSD model that work on modestly sized data. In our comparisons, wetimed all the algorithms under equivalent computational conditions. On simulated data, where the truth is known, we measured the quality of the resulting fits by computing the KL divergence between the estimated models and the truth. On the real data sets, where the truth is not known, we measured model fitness by predictive log likelihood of held-out measurements (Methods). The smaller the KL divergence and the larger the predictive likelihood, the better a method performs.</p><p hwp:id="p-18">We first analyzed two real data sets: the Human Genome Diversity Panel (HGDP) data set <xref rid="c9" ref-type="bibr" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">[9]</xref>, <xref rid="c10" ref-type="bibr" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">[10]</xref> and the 1000 Genomes Project (TGP) <xref rid="c11" ref-type="bibr" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">[11]</xref>. After preprocessing, HGDP consisted of 940 individuals at 642,951 SNPs for a total of 604 million observed genotypes and TGP consisted of 1,718 people at 1,854,622 SNPs for a total of 3.2 billion observed genotypes. In previous work, ADMIXTURE and FASTSTRUCTURE have been shown to perform reasonably well on data sets of this size <xref rid="c2" ref-type="bibr" hwp:id="xref-ref-2-3" hwp:rel-id="ref-2">[2]</xref>, <xref rid="c3" ref-type="bibr" hwp:id="xref-ref-3-3" hwp:rel-id="ref-3">[3]</xref>. In applying all three algorithms to these data, we found that TeraStructure achieved the highest predictive log likelihood of held-out measurements by a modest margin (<xref rid="tblS1" ref-type="table" hwp:id="xref-table-wrap-2-1" hwp:rel-id="T2">Table S1</xref>) and it also completed its estimation in a comparable period of time (<xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-1" hwp:rel-id="T1">Table 1</xref>).</p><table-wrap id="tblS1" position="float" orientation="portrait" hwp:id="T2" hwp:rev-id="xref-table-wrap-2-1 xref-table-wrap-2-2 xref-table-wrap-2-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;013227v1/TBLS1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T2</object-id><object-id pub-id-type="publisher-id">tblS1</object-id><label>Table S1:</label><caption hwp:id="caption-7"><p hwp:id="p-102">The predictive accuracy of TERASTRUCTURE is comparable to the ADMIXTURE [<xref rid="c2" ref-type="bibr" hwp:id="xref-ref-2-5" hwp:rel-id="ref-2">2</xref>] and the FASTSTRUCTURE [<xref rid="c3" ref-type="bibr" hwp:id="xref-ref-3-8" hwp:rel-id="ref-3">3</xref>] algorithms, implying a similar model fit. The mean test log likelihood under the model fits is shown. We generated 5 test sets at random and computed the mean over these heldout sets. N is the number of individuals in the data set. The number of ancestral populations is set to <italic toggle="yes">K</italic> = 10 for HGDP and <italic toggle="yes">K</italic> = 8 for TGP.</p></caption><graphic xlink:href="013227_tblS1" position="float" orientation="portrait" hwp:id="graphic-19"/></table-wrap><table-wrap id="tbl1" position="float" orientation="portrait" hwp:id="T1" hwp:rev-id="xref-table-wrap-1-1 xref-table-wrap-1-2 xref-table-wrap-1-3 xref-table-wrap-1-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;013227v1/TBL1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">tbl1</object-id><label>Table 1:</label><caption hwp:id="caption-2"><p hwp:id="p-19">The running time of all algorithms on both real and synthetic data. T<sc>era</sc>S<sc>tructure</sc> is the only algorithm that can scale beyond <italic toggle="yes">N</italic> = 10; 000 individuals to the synthetic data sets with= 100; 000 individuals and <italic toggle="yes">N</italic> = 1; 000; 000 individuals. <italic toggle="yes">S</italic> is the fraction of SNP locations sub-sampled, with repetition, during training; <italic toggle="yes">L</italic> is the number of SNP locations. <italic toggle="yes">S</italic> * <italic toggle="yes">L</italic> also equals the number of training iterations of the outer loop in the algorithm of <xref rid="figS1" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure S1</xref> prior to convergence, since we subsample one SNP location in each iteration. The T<sc>era</sc>S<sc>tructure</sc> and ADMIXTURE algorithms were run with ten parallel threads, while FASTSTRUCTURE, which does not have a threading option, was run with a single thread. Even under the best-case assumption of ten times speedup due to parallel computation, the TeraStructure algorithm is twice as fast as both ADMIXTURE and FASTSTRUCTURE algorithms on the data set with <italic toggle="yes">N</italic> = 10; 000 individuals. On the real data sets, T<sc>era</sc>S<sc>tructure</sc> is faster than the other algorithms. In contrast to other methods, T<sc>era</sc>S<sc>tructure</sc> iterated over the SNP locations at most once on all data sets. Supplementary Figures and Tables</p></caption><graphic xlink:href="013227_tbl1" position="float" orientation="portrait" hwp:id="graphic-3"/></table-wrap><fig id="figS1" position="float" orientation="portrait" fig-type="figure" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3 xref-fig-3-4 xref-fig-3-5 xref-fig-3-6 xref-fig-3-7 xref-fig-3-8"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;013227v1/FIGS1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">figS1</object-id><label>Figure S1:</label><caption hwp:id="caption-4"><p hwp:id="p-99">T<sc>era</sc>S<sc>tructure</sc> Algorithm-Stochastic variational inference for the PSD model.</p></caption><graphic xlink:href="013227_figS1" position="float" orientation="portrait" hwp:id="graphic-16"/></fig><p hwp:id="p-20">We then studied the algorithms on synthetic data. We designed these data sets be similar to real genetic data sets, but at sizes that push the limits of what is available today (Methods). We simulated data sets consisting of 10,000 individuals, 100,000 individuals, and 1M individuals, each with 1M SNP genotypes per individual. On these data we know the true individual proportions, and we can visualize how well each algorithm reconstructs them (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2</xref>). We found that ADMIXTURE and FASTSTRUCTURE were only able to analyze the 10,000-individual set, on which TeraStructure was both 2−3 times faster and more accurate (<xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-2" hwp:rel-id="T1">Tables 1</xref> and <xref rid="tblS2" ref-type="table" hwp:id="xref-table-wrap-3-1" hwp:rel-id="T3">S2</xref>). More importantly, TeraStructure was the only algorithm that was able to analyze the larger data sets of 100,000 individuals and 1M individuals, and again with high accuracy (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2</xref> and <xref rid="tblS2" ref-type="table" hwp:id="xref-table-wrap-3-2" hwp:rel-id="T3">Table S2</xref>).</p><table-wrap id="tblS2" position="float" orientation="portrait" hwp:id="T3" hwp:rev-id="xref-table-wrap-3-1 xref-table-wrap-3-2 xref-table-wrap-3-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;013227v1/TBLS2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T3</object-id><object-id pub-id-type="publisher-id">tblS2</object-id><label>Table S2:</label><caption hwp:id="caption-8"><p hwp:id="p-103">The accuracy of the algorithms on synthetic data. T<sc>era</sc>S<sc>tructure</sc> is the only algorithm that was able to complete its analysis on the synthetic data sets with <italic toggle="yes">N</italic> = 100; 000 individuals and <italic toggle="yes">N</italic> = 1; 000; 000 individuals. On these massive data sets, T<sc>era</sc>S<sc>tructure</sc> found a highly accurate fit to the data (see also <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Figure 2</xref>). On smaller synthetic data, T<sc>era</sc>S<sc>tructure</sc> finds a fit to the data that is closer to the ground truth than either of the other methods. The number of ancestral populations is set to the number of ground truth ancestral populations: <italic toggle="yes">K</italic>=6.</p></caption><graphic xlink:href="013227_tblS2" position="float" orientation="portrait" hwp:id="graphic-20"/></table-wrap><fig id="fig2" position="float" orientation="portrait" fig-type="figure" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;013227v1/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2:</label><caption hwp:id="caption-3"><p hwp:id="p-21">T<sc>era</sc>S<sc>tructure</sc> recovers the ground truth per-individual population proportions on the synthetic data sets with high accuracy. Each panel shows a visualization of the ground truth θ<sup>*</sup> <sub>i</sub> and the inferred E[<sub>ii</sub>] for all individuals in a data set. The current state-of-the-art algorithms cannot complete their analyses of 100,000 and 1,000,000 individuals. TeraStructure is able to analyze data of this size and gives highly accurate estimates.</p></caption><graphic xlink:href="013227_fig2" position="float" orientation="portrait" hwp:id="graphic-4"/></fig><p hwp:id="p-22">TeraStructure uses a convergence criterion to decide when to stop iterating (Methods). This lets us gauge how many SNPs were necessary to sample before the algorithm had learned the structure of the population. On the HGDP and TGP data, we found that TeraStructure needed to sample ∼90% and ∼50% of the SNPs, respectively, before converging (<xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-3" hwp:rel-id="T1">Table 1</xref>). On the tera-sample-sized data set of 1M individuals by 1M SNPs, TeraStructure sampled ∼50% of the SNPs before converging.</p><p hwp:id="p-23">When analyzing data with the PSD model, we must choose the number of ancestral populations <italic toggle="yes">K</italic>. For real data, TeraStructure addressed this model selection problem using a predictive approach <xref rid="c12" ref-type="bibr" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">[12]</xref>. We held out a set of genome SNP locations for each individual and computed the average predictive log likelihood under the model for varying numbers of ancestral populations.</p><p hwp:id="p-24">The best choice of <italic toggle="yes">K</italic> is the one that assigns the highest probability to the held-out set. Our sensitivity analysis revealed that <italic toggle="yes">K</italic> = 8 had the highest validation likelihood on the TGP data, while <italic toggle="yes">K</italic> = 10 had the highest likelihood on the HGDP data (<xref rid="figS3" ref-type="fig" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Figure S3</xref>). On the real data sets, we fixed the number of populations <italic toggle="yes">K</italic> for each data set to the <italic toggle="yes">K</italic> with the highest validation likelihood (<xref rid="tblS1" ref-type="table" hwp:id="xref-table-wrap-2-2" hwp:rel-id="T2">Table S1</xref>); on simulated data sets, we set <italic toggle="yes">K</italic> to the number of ground truth ancestral populations (<xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-4" hwp:rel-id="T1">Table 1</xref>).</p></sec><sec id="s3" hwp:id="sec-5"><title hwp:id="title-5">DISCUSSION</title><p hwp:id="p-25">We have developed TeraStructure, a novel algorithm that repeatedly takes strategic subsamples of genotyping data to uncover the underlying structure of human populations. We have demonstrated the effectiveness of TeraStructure by applying it to large and globally sampled human SNP genotype data and comparing our predictive likelihood to existing algorithms. Further, we used a comprehensive simulation study to show that TeraStructure can accurately fit a standard probabilistic model of population genetic structure on data sets with a million individuals and 10<sup>12</sup> observed genotypes. This is orders of magnitude beyond the capabilities of current state-of-the-art algorithms. We note that our results are from computation on a modest computing platform. On advanced computing architectures, TeraStructure can analyze even larger data sets, and holds promise of characterizing the structure of world-scale human populations.</p><p hwp:id="p-26">Fitting probabilistic models of population structure such as the PSD model is an important part of analyzing genotyping data. Genomic studies are growing and it is vital that our statistical algorithms can scale to millions of individuals and trillions or more genotype observations. Such analyses are not possible with the current state-of-the-art algorithms as they require multiple iterations over the entire data. TeraStructure overcomes this limitation with a different computational structure—one that iterates between subsampling from a population, analyzing the sample, and updating an estimate of hidden structure. Using TeraStructure to analyze tera-sample-size data sets will provide the most comprehensive analyses to date of the global population genetics of humans.</p></sec><sec id="s4" hwp:id="sec-6"><title hwp:id="title-6">METHODS</title><sec id="s4a" hwp:id="sec-7"><title hwp:id="title-7">Real data sets</title><p hwp:id="p-27">We used genotyping data from the Human Genome Diversity Project (HGDP) and 1000 Gnomes Project (TGP), which are the two largest publicly available datasets that sampled individuals globally. To help insure the quality of the data, we filtered the individuals for 95% genotyping completeness and we removed the SNPs with lower than 1% minor allele frequency. The HGDP dataset is the complete Stanford HGDP SNP Genotyping data. We filtered the individuals by removing those not in the “H952” set <xref rid="c13" ref-type="bibr" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">[13]</xref>, which leaves us with only the individuals without first or second degree relatives in the data. The final dimensions are 642,951 SNPs by 940 individuals, and a total of 603 million observations (0.08% missing data). The TGP data set was 2012-01-31 Omni Platform Genotypes and is accessible from the NCBI ftp site. We removed related individuals using the sample information provided by the 1000 Genomes Project. The final dimensions are 1,854,622 SNPs by 1,718 individuals, and a total of 3.1 billion observations (0.3% missing data).</p></sec><sec id="s4b" hwp:id="sec-8"><title hwp:id="title-8">Simulated data sets</title><p hwp:id="p-28">The goal of our study on synthetic data sets is to demonstrate scalability to tera-sized data sets— one million observed genotypes from one million individuals—while maintaining high accuracy in recovering ground truth per-individual population proportions <italic toggle="yes">θ<sub>i</sub></italic> and per-population allele frequencies <italic toggle="yes">β<sub>k</sub></italic>. To this end, we generated synthetic genotype data using the Pritchard-Stephens-Donnelly (PSD) model <xref rid="c1" ref-type="bibr" hwp:id="xref-ref-1-3" hwp:rel-id="ref-1">[1]</xref>. A specification of the the per-individual population proportions and the population allele frequencies is our “ground truth”. To generate realistic synthetic data, we made the individual <italic toggle="yes">θ<sub>i</sub></italic>’s visually similar to the proportions obtained from fitting our model to the TGP data set. We modeled allele frequencies <italic toggle="yes">β<sub>1:K,l</sub></italic> from real data.</p><p hwp:id="p-29">In our simulation, the process of drawing an individual <italic toggle="yes">i’s</italic> proportions <italic toggle="yes">θ<sub>i</sub></italic> has two levels. At the first level, we drew <italic toggle="yes">S</italic> points in the <italic toggle="yes">K</italic>-simplex from a symmetric Dirichlet distribution, <italic toggle="yes">q<sub>s</sub>∼</italic> Dirichlet(α). Each of the <italic toggle="yes">S</italic> points represents a “region” of individuals, and each individual was assigned to one of the regions such that the regions are equally sized. Then, we drew the population proportions of each individual, <italic toggle="yes">θ<sub>i</sub></italic>∼ Dirichlet (<italic toggle="yes">γq<sub>s,1</sub>,…,γ q<sub>s,K</sub></italic>). Thus, each region has a fixed <italic toggle="yes">q<sub>s</sub></italic> and the proportion of individuals from that region are governed by the same scaled <italic toggle="yes">q<sub>s</sub></italic> parameter. The parameter <italic toggle="yes">q<sub>s</sub></italic> controls the sparsity of the <italic toggle="yes">θ<sub>i</sub></italic>, while the parameter γ controls how similar admixture proportions are within each group. For all simulations, we set <italic toggle="yes">S</italic> = 50, <italic toggle="yes">α</italic> = 02, and <italic toggle="yes">γ= 50</italic>.</p><p hwp:id="p-30">Each <italic toggle="yes">β<sub>1: K,l</sub></italic> at a SNP location <italic toggle="yes">l</italic>, consists of <italic toggle="yes">K</italic> independent draws from a Beta distribution with parameters following that of the Balding-Nichols Model <xref rid="c14" ref-type="bibr" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">[14]</xref>, i.e. <inline-formula hwp:id="inline-formula-1"><alternatives hwp:id="alternatives-2"><inline-graphic xlink:href="013227_inline1.gif" hwp:id="inline-graphic-1"/></alternatives></inline-formula> where <italic toggle="yes">p<sub>l</sub></italic> is the marginal allele frequency and <italic toggle="yes">F<sub>l</sub></italic> is the Wright’s <italic toggle="yes">F<sub>ST</sub></italic> at location <italic toggle="yes">l</italic>. The paired parameters <italic toggle="yes">p<sub>l</sub></italic> and <italic toggle="yes">F<sub>l</sub></italic> were estimated from the HGDP data set described earlier. For each pair, we chose a random complete SNP from the HGDP data and set the allele frequency <italic toggle="yes">p<sub>l</sub></italic> to the observed frequency. The Wright’s <italic toggle="yes">F<sub>ST</sub> F<sub>l</sub></italic> was set to the Weir &amp; Cockerham F<sub>ST</sub> estimate <xref rid="c15" ref-type="bibr" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">[15]</xref> with 5 discrete subpopulations, following analysis of the HGDP study in <xref rid="c16" ref-type="bibr" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">[16]</xref>. We simulated data with 1,000,000 SNPs and three different scales of individuals: 10,000, 100,000 and 1,000,000. With 1 million individuals and 1 million SNPS, the number of observations is tera-sample-sized, i.e., 10<sup>12</sup> observations.</p></sec></sec><sec id="s5" hwp:id="sec-9"><title hwp:id="title-9">The PSD Model</title><p hwp:id="p-31">We present the model and algorithm for unphased genotype data, though it easily generalizes to phased data. (Most massive population genetics data sets are unphased.) In unphased data, each observation <italic toggle="yes">x<sub>i,l</sub></italic>∈{0,1,2} denotes the observed genotype for individual <italic toggle="yes">i</italic> at SNP location <italic toggle="yes">l</italic>. The data are coded for how many major alleles are present: <italic toggle="yes">x<sub>i,l</sub></italic> = 0 indicates two minor alleles; <italic toggle="yes">x<sub>i,l</sub></italic> = 2 indicates two major alleles; and <italic toggle="yes">x<sub>i,l</sub></italic> = 1 indicates one major and one minor allele. In this last case we do not code which allele came from the mother and which from the father. This is what it means for the data to be unphased.</p><p hwp:id="p-32">The PSD model captures the heterogenous patterns of ancestral populations that are inherent in observed human genomes. It posits <italic toggle="yes">K</italic> ancestral populations, each characterized by its allele frequencies across sites, and assumes that each person’s genome exhibits these populations with different proportions. Given a set of observed genomes, the goal of the algorithm is to estimate the proportion of each ancestral population present in a given individual, (ii) the ancestral population allele frequencies for each SNP, (iii) the effective allele frequency for each individual/SNP combination. Given observed data, we uncover its population structure by estimating the conditional distribution of the allele frequencies and the per-individual population proportions.</p><p hwp:id="p-33">Formally, each population <italic toggle="yes">k</italic> is characterized by an array of per-location distributions over major and minor alleles <italic toggle="yes">β<sub>k,l</sub></italic> ∈(0, 1). Each individual i is characterized by its per-population proportions <italic toggle="yes">θ<sub>i,k</sub>&gt;0</italic>, where <italic toggle="yes">∑<sub>j</sub> θ<sub>i,j</sub> = 1</italic>. The observation for individual <italic toggle="yes">i</italic> at location <italic toggle="yes">l</italic> is assumed drawn from a binomial. Its parameter is a mixture of the population parameters for that location <italic toggle="yes">β<sub>1:K;l</sub></italic>, where the mixture proportions are defined by the individual <italic toggle="yes">θ<sub>i</sub></italic>. Thus, across individuals, the basic population distributions are shared at each location but they are exhibited with different individualized proportions.</p><p hwp:id="p-34">Placing priors on the hidden variables, the data are assumed drawn from the following model:</p><p hwp:id="p-35"><italic toggle="yes">β<sub>k,l</sub></italic> ~ Beta(<italic toggle="yes">a, b</italic>)</p><p hwp:id="p-36"><italic toggle="yes">θ<sub>i</sub></italic> ~ Dirichlet(<italic toggle="yes">c</italic>)</p><p hwp:id="p-37"><italic toggle="yes">x<sub>i,l</sub></italic> ~ Binomial(2, ∑<italic toggle="yes"><sub>k</sub></italic>, <italic toggle="yes">θ<sub>i,k</sub></italic>, <italic toggle="yes">β<sub>k,l</sub></italic>)</p><p hwp:id="p-38">This is the model for unphased data in <xref rid="c1" ref-type="bibr" hwp:id="xref-ref-1-4" hwp:rel-id="ref-1">[1]</xref>.</p></sec><sec id="s5b" hwp:id="sec-10"><title hwp:id="title-10">Scalable Computation for the PSD Model</title><p hwp:id="p-39">How do we use the PSD model? We are given a set of measured genotypes from <italic toggle="yes">N</italic> individuals at <italic toggle="yes">L</italic> locations <italic toggle="yes">x = x<sub>1:N,1:L</sub></italic>. Given this data, we compute the posterior distribution of the basic population parameters <italic toggle="yes">β= β<sub>1:K,1:L</sub></italic> and individual population proportions <italic toggle="yes">θ= θ<sub>1:N,1:K</sub></italic>. From the posterior we can compute estimates of the latent population structure.</p><p hwp:id="p-40">For example, <xref rid="figS2" ref-type="fig" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Figure S2</xref> illustrates the posterior expected population proportions, computed from our algorithm, for the 1718 individuals of the 1000-Genomes data set. <xref rid="figS2" ref-type="fig" hwp:id="xref-fig-4-2" hwp:rel-id="F4">Figure S2</xref> illustrates these posterior estimates at three values of the latent number of populations <italic toggle="yes">K</italic>, at <italic toggle="yes">K</italic> = 7, <italic toggle="yes">K</italic> = 8 and <italic toggle="yes">K</italic> = 9. This data set contains over 3 billion observations. Though the model is not aware of the country-of-origin for each individual, our algorithm uncovered population structure consistent with the major geographical regions. Some of the groups of individuals identify a specific region (e.g., red for Africa) while others represent admixture between regions (e.g., green for Europeans and Central/South Americans).</p><fig id="figS2" position="float" orientation="portrait" fig-type="figure" hwp:id="F4" hwp:rev-id="xref-fig-4-1 xref-fig-4-2 xref-fig-4-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;013227v1/FIGS2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">figS2</object-id><label>Figure S2:</label><caption hwp:id="caption-5"><p hwp:id="p-100">Population structure inferred from the TGP data set using the TERASTRUCTURE algorithm at three settings for the number of populations K. The visualization of the <italic toggle="yes">θ</italic>’s in the Figure shows patterns consistent with the major geographical regions. Some of the clusters identify a specific region (e.g. red for Africa) while others represent admixture between regions (e.g. green for Europeans and Central/South Americans). The presence of clusters that are shared between different regions demonstrates the more continuous nature of the structure. The new cluster from <italic toggle="yes">K</italic> = 7 to <italic toggle="yes">K</italic> = 8 matches structure differentiating between American groups. For <italic toggle="yes">K</italic> = 9, the new cluster is unpopulated.</p></caption><graphic xlink:href="013227_figS2" position="float" orientation="portrait" hwp:id="graphic-17"/></fig><p hwp:id="p-41">Specifically, we develop a stochastic variational inference algorithm <xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-3" hwp:rel-id="ref-7">[7]</xref> for the PSD model, a strategy whose computational structure is intrinsically efficient. At each iteration, we first subsample a set of observed genotypes from the data set, a step which involves sampling a location and including the observations for all individuals at that location. We then analyze only those observations at the subsampled location. Finally, we update our estimates of the population-wide hidden structure based on the analysis of the subsample. In each iteration we obtain a new subsample corresponding to a new location and repeat the process.</p><p hwp:id="p-42">This is in contrast to previous algorithms for approximate inference in the PSD model, like the MCMC algorithm of <xref rid="c1" ref-type="bibr" hwp:id="xref-ref-1-5" hwp:rel-id="ref-1">[1]</xref> or the variational inference algorithm of <xref rid="c3" ref-type="bibr" hwp:id="xref-ref-3-4" hwp:rel-id="ref-3">[3]</xref>. These algorithms form an approximate posterior through repeated iterations over the entire data set; such methods are slow for massive data sets. Our method subsamples a SNP location at each iteration, and provides a valid approximation of the admixture posterior that scales to population-size genomic data.</p></sec><sec id="s5c" hwp:id="sec-11"><title hwp:id="title-11">Variational Inference for the PSD Model</title><p hwp:id="p-43">The admixture posterior is proportional to the joint distribution</p><disp-formula id="eqn1" hwp:id="disp-formula-2">
<alternatives hwp:id="alternatives-3"><graphic xlink:href="013227_eqn1.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives></disp-formula><p hwp:id="p-44">This distribution is difficult to compute because of the normalizing constant, the marginal probability of the observed genotypes. The central computational problem for the PSD model is how to approximate the posterior.</p><p hwp:id="p-45">Variational inference is a class of methods for approximate posterior inference that adapts earlier ideas in statistical physics <xref rid="c17" ref-type="bibr" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">[17]</xref> to probabilistic models <xref rid="c5" ref-type="bibr" hwp:id="xref-ref-5-2" hwp:rel-id="ref-5">[5]</xref>, <xref rid="c6" ref-type="bibr" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">[6]</xref>. Broadly, we define a family of distributions over the hidden variables <italic toggle="yes">q</italic>(·) indexed by a set of free parameters <italic toggle="yes">ν</italic>. We then fit <italic toggle="yes">ν</italic> to find the member of the family that is close to the posterior, where closeness is measured with KL divergence,</p><disp-formula id="eqn2" hwp:id="disp-formula-3" hwp:rev-id="xref-disp-formula-3-1 xref-disp-formula-3-2 xref-disp-formula-3-3">
<alternatives hwp:id="alternatives-4"><graphic xlink:href="013227_eqn2.gif" position="float" orientation="portrait" hwp:id="graphic-6"/></alternatives></disp-formula><p hwp:id="p-46">The objective function of <xref rid="eqn2" ref-type="disp-formula" hwp:id="xref-disp-formula-3-1" hwp:rel-id="disp-formula-3">Equation 2</xref> is not computable. (It is not computable for the same reason that exact Bayesian inference is intractable—it requires computing the marginal probability of the data.) Thus variational inference optimizes an alternative objective that is equal to the negative KL up to an unknown additive constant,</p><p hwp:id="p-47"><disp-formula id="eqn3" hwp:id="disp-formula-4" hwp:rev-id="xref-disp-formula-4-1 xref-disp-formula-4-2 xref-disp-formula-4-3 xref-disp-formula-4-4 xref-disp-formula-4-5 xref-disp-formula-4-6">
<alternatives hwp:id="alternatives-5"><graphic xlink:href="013227_eqn3.gif" position="float" orientation="portrait" hwp:id="graphic-7"/></alternatives></disp-formula></p><p hwp:id="p-48">This objective is a function of the variational parameters <italic toggle="yes">ν</italic> because each term is an expectation with respect to <inline-formula hwp:id="inline-formula-2"><alternatives hwp:id="alternatives-6"><inline-graphic xlink:href="013227_inline2.gif" hwp:id="inline-graphic-2"/></alternatives></inline-formula>. Further, though the additive constant is unknown, maximizing <xref rid="eqn3" ref-type="disp-formula" hwp:id="xref-disp-formula-4-1" hwp:rel-id="disp-formula-4">Equation 3</xref> with respect to <inline-formula hwp:id="inline-formula-3"><alternatives hwp:id="alternatives-7"><inline-graphic xlink:href="013227_inline3.gif" hwp:id="inline-graphic-3"/></alternatives></inline-formula> is equivalent to minimizing the KL divergence in <xref rid="eqn2" ref-type="disp-formula" hwp:id="xref-disp-formula-3-2" hwp:rel-id="disp-formula-3">Equation 2</xref>. Intuitively, the first term encourages that <italic toggle="yes">q</italic>(·) place mass on configurations of the latent variables that best explain the data; the second term, which is the entropy of the variational distribution, encourages that <italic toggle="yes">q</italic>(·) be diffuse.</p><p hwp:id="p-49">To finish specifying the objective, we must set the form of <italic toggle="yes">q</italic>(·). A key idea behind variational inference is that the form of the variational distribution is set to make the problem tractable, that is, for the objective of <xref rid="eqn2" ref-type="disp-formula" hwp:id="xref-disp-formula-3-3" hwp:rel-id="disp-formula-3">Equation 2</xref> to be computable (as well as its gradients). As for most applications of variational inference, we choose <italic toggle="yes">q</italic>(·) to be the <italic toggle="yes">mean-field family</italic>, the family where each variable is independent and governed by its own parametric distribution,</p><disp-formula id="eqn4" hwp:id="disp-formula-5" hwp:rev-id="xref-disp-formula-5-1 xref-disp-formula-5-2">
<alternatives hwp:id="alternatives-8"><graphic xlink:href="013227_eqn4.gif" position="float" orientation="portrait" hwp:id="graphic-8"/></alternatives></disp-formula><p hwp:id="p-50">Our notation is that <inline-formula hwp:id="inline-formula-4"><alternatives hwp:id="alternatives-9"><inline-graphic xlink:href="013227_inline4.gif" hwp:id="inline-graphic-4"/></alternatives></inline-formula> is the variational parameter for the <italic toggle="yes">i</italic>th individual’s population proportions <italic toggle="yes">θ<sub>i</sub></italic> and is the variational parameter for the distribution of genotypes in population <italic toggle="yes">k</italic> at location <italic toggle="yes">l</italic>. Further, we set the form of each factor to be the same form as the prior. Thus <inline-formula hwp:id="inline-formula-5"><alternatives hwp:id="alternatives-10"><inline-graphic xlink:href="013227_inline42.gif" hwp:id="inline-graphic-5"/></alternatives></inline-formula> are Dirichlet distributions and <inline-formula hwp:id="inline-formula-6"><alternatives hwp:id="alternatives-11"><inline-graphic xlink:href="013227_inline43.gif" hwp:id="inline-graphic-6"/></alternatives></inline-formula> are Beta distributions. These decisions come from the general theory around mean-field variational inference in exponential families <xref rid="c18" ref-type="bibr" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">[18]</xref>, <xref rid="c19" ref-type="bibr" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">[19]</xref>. (See also <xref rid="eqn7" ref-type="disp-formula" hwp:id="xref-disp-formula-8-1" hwp:rel-id="disp-formula-8">Equation 7</xref> and <xref rid="eqn9" ref-type="disp-formula" hwp:id="xref-disp-formula-10-1" hwp:rel-id="disp-formula-10">Equation 9</xref>).</p><p hwp:id="p-51">We emphasize that in the variational family each hidden variable is endowed with its own variational distribution. While the model assumes each individual’s proportions come from the same shared prior, the variational family provides a different parameter for each. This gives the variational family the flexibility it needs to represent different individuals with different population proportions. For example, to create <xref rid="figS2" ref-type="fig" hwp:id="xref-fig-4-3" hwp:rel-id="F4">Figure S2</xref> we plotted the variational expectation of each individuals population parameters distribution <inline-formula hwp:id="inline-formula-7"><alternatives hwp:id="alternatives-12"><inline-graphic xlink:href="013227_inline5.gif" hwp:id="inline-graphic-7"/></alternatives></inline-formula>
</p><p hwp:id="p-52">With these components—the objective of <xref rid="eqn3" ref-type="disp-formula" hwp:id="xref-disp-formula-4-2" hwp:rel-id="disp-formula-4">Equation 3</xref> and the variational family of <xref rid="eqn4" ref-type="disp-formula" hwp:id="xref-disp-formula-5-1" hwp:rel-id="disp-formula-5">Equation 4</xref>— we have turned the inference problem for the PSD model into an optimization problem.</p><sec id="s5d" hwp:id="sec-12"><title hwp:id="title-12">Stochastic Variational Inference for the PSD Model</title><p hwp:id="p-53">Traditional variational inference iterates over all the variational parameters. For example, the authors of <xref rid="c3" ref-type="bibr" hwp:id="xref-ref-3-5" hwp:rel-id="ref-3">[3]</xref> approximate the admixture posterior by updating each variational parameter in turn while holding the others fixed. This <italic toggle="yes">batch</italic> strategy is more efficient than MCMC but cannot scale to tera-sized data sets, where the number of individuals <italic toggle="yes">N</italic> is in the hundreds of thousands or millions and the number of locations <italic toggle="yes">L</italic> is in the millions.</p><p hwp:id="p-54">To solve this problem, we use stochastic optimization <xref rid="c8" ref-type="bibr" hwp:id="xref-ref-8-2" hwp:rel-id="ref-8">[8]</xref> applied to the variational objective [<xref rid="c20" ref-type="bibr" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">20</xref>; <xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-4" hwp:rel-id="ref-7">7</xref>]. Our algorithm follows easy-to-compute noisy estimates of the gradient to more quickly make progress in the variational objective. The noise and computability of the gradient stem from repeated subsampling from the data.</p><p hwp:id="p-55">Our algorithm is called TERASTRUCTURE. It maintains a variational estimate of each individuals population proportions <inline-formula hwp:id="inline-formula-8"><alternatives hwp:id="alternatives-13"><inline-graphic xlink:href="013227_inline6.gif" hwp:id="inline-graphic-8"/></alternatives></inline-formula> and the allele frequencies of each basic population <inline-formula hwp:id="inline-formula-9"><alternatives hwp:id="alternatives-14"><inline-graphic xlink:href="013227_inline7.gif" hwp:id="inline-graphic-9"/></alternatives></inline-formula> It repeatedly cycles through the following steps:
<list list-type="order" hwp:id="list-1"><list-item hwp:id="list-item-1"><p hwp:id="p-56">Sample an observation from SNP location <italic toggle="yes">l</italic> from all individuals.</p></list-item><list-item hwp:id="list-item-2"><p hwp:id="p-57">Estimate how each individual expresses the basic populations, only using the measured location <italic toggle="yes">l</italic>. Use these estimates to update the ancestral allele frequencies parameter <inline-formula hwp:id="inline-formula-10"><alternatives hwp:id="alternatives-15"><inline-graphic xlink:href="013227_inline8.gif" hwp:id="inline-graphic-10"/></alternatives></inline-formula> local to <italic toggle="yes">l</italic>.</p></list-item><list-item hwp:id="list-item-3"><p hwp:id="p-58">Use these estimates to update the population proportions parameter of all individuals <inline-formula hwp:id="inline-formula-11"><alternatives hwp:id="alternatives-16"><inline-graphic xlink:href="013227_inline9.gif" hwp:id="inline-graphic-11"/></alternatives></inline-formula>
</p></list-item></list></p><p hwp:id="p-59">The stochastic algorithm above can quickly make progress. After one iteration, which involved processing observations at only one of the <italic toggle="yes">L</italic> possible locations, we have an estimate of the population proportions of all individuals. Given the estimate of the population proportions, an estimate of the ancestral allele frequencies can be computed for any location. In comparison, the batch algorithm of <xref rid="c3" ref-type="bibr" hwp:id="xref-ref-3-6" hwp:rel-id="ref-3">[3]</xref> needs to iterate over the entire data set at least once, to make any progress.</p><sec id="s5d1" hwp:id="sec-13"><title hwp:id="title-13">Global and local parameters</title><p hwp:id="p-60">Before we develop our algorithm, we use the conditional dependencies in our graphical model to divide our variational parameters into <italic toggle="yes">local</italic> and <italic toggle="yes">global</italic> parameters <xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-5" hwp:rel-id="ref-7">[7]</xref>.</p><p hwp:id="p-61">In each iteration we subsample genotype measurements for all individuals at a SNP location <italic toggle="yes">l</italic>. Our sampled observations are <italic toggle="yes">x<sub>1:N,l</sub></italic>. Under the PSD model, given individual proportions <italic toggle="yes">θ<sub>1:N</sub></italic>, the sample <italic toggle="yes">x<sub>1:N,l</sub></italic> and the ancestral allele frequencies <italic toggle="yes">β<sub>1:K,l</sub></italic> are conditionally independent of all other observations and allele frequencies <italic toggle="yes">β<sub>1:K,−l</sub></italic>. Thus, the allele frequencies <italic toggle="yes">β<sub>1:K,l</sub></italic> are local to the observations <italic toggle="yes">x<sub>1:N,l</sub></italic>. The population proportions <italic toggle="yes">θ<sub>1:N</sub></italic>, with the local variables, govern the distribution of observations at any sampled SNP location. Therefore, the <italic toggle="yes">θ<sub>1:N</sub></italic> are global variables. Following <xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-6" hwp:rel-id="ref-7">[7]</xref>, we extend this notion of global and local sets to the variational parameters. Given observations <italic toggle="yes">x<sub>l;1:N</sub></italic> at the location <italic toggle="yes">l</italic>, the <inline-formula hwp:id="inline-formula-12"><alternatives hwp:id="alternatives-17"><inline-graphic xlink:href="013227_inline10.gif" hwp:id="inline-graphic-12"/></alternatives></inline-formula> are the global variational parameters; the <inline-formula hwp:id="inline-formula-13"><alternatives hwp:id="alternatives-18"><inline-graphic xlink:href="013227_inline11.gif" hwp:id="inline-graphic-13"/></alternatives></inline-formula> are the local variational parameters.</p><p hwp:id="p-62">In stochastic variational inference <xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-7" hwp:rel-id="ref-7">[7]</xref>, we iteratively update local and global parameters. In each iteration, we first subsample a SNP location <italic toggle="yes">l</italic> and compute optimal local parameters for the sample, given the current settings of the global parameters. We then update the global parameters using a stochastic natural gradient <xref rid="c21" ref-type="bibr" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">[21]</xref> of the variational objective computed from the subsampled data and the local parameters.</p><p hwp:id="p-63">We will now develop our algorithm by first obtaining closed form updates for our local and global variational parameters. For the local parameters, we will derive optimal coordinate updates; for the global parameters, we will derive the stochastic natural gradient update.</p></sec><sec id="s5d2" hwp:id="sec-14"><title hwp:id="title-14">Computing the optimal local parameters</title><p hwp:id="p-64">Given the global parameters <inline-formula hwp:id="inline-formula-14"><alternatives hwp:id="alternatives-19"><inline-graphic xlink:href="013227_inline12.gif" hwp:id="inline-graphic-14"/></alternatives></inline-formula> we can optimize local parameters <inline-formula hwp:id="inline-formula-15"><alternatives hwp:id="alternatives-20"><inline-graphic xlink:href="013227_inline13.gif" hwp:id="inline-graphic-15"/></alternatives></inline-formula> in closed form under certain assumptions. These assumptions involve the <italic toggle="yes">complete conditionals</italic> of the hidden variables in the model, and the variational family. A complete conditional is the conditional distribution of a latent variable given the observations and the other latent variables in the model [18]. If the complete conditional of a variable is in the same family as its prior, and the corresponding variational distribution is in the same family, then we can optimize its variational parameter by setting it to the expected natural parameter (under <italic toggle="yes">q</italic>) of the complete conditional.</p><p hwp:id="p-65">If the complete conditional of each latent variable is in the same exponential family as its prior distribution, then the model is <italic toggle="yes">conditionally conjugate</italic>.</p><p hwp:id="p-66">The complete conditionals for the <italic toggle="yes">β<sub>k,l</sub></italic> at a sampled location <italic toggle="yes">l</italic> are</p><disp-formula id="eqn5" hwp:id="disp-formula-6" hwp:rev-id="xref-disp-formula-6-1 xref-disp-formula-6-2 xref-disp-formula-6-3">
<alternatives hwp:id="alternatives-21"><graphic xlink:href="013227_eqn5.gif" position="float" orientation="portrait" hwp:id="graphic-9"/></alternatives></disp-formula><p hwp:id="p-67">The complete conditional in <xref rid="eqn5" ref-type="disp-formula" hwp:id="xref-disp-formula-6-1" hwp:rel-id="disp-formula-6">Equation 5</xref> is not in the exponential family because the expectation of the second and third log-of-summation terms, with respect to the variational family <italic toggle="yes">q</italic>, are intractable. Therefore, the PSD model is not conditionally conjugate.</p><p hwp:id="p-68">To overcome the nonconjugacy in the model, we introduce multinomial approximations using the zeroth order delta method for moments [<xref rid="c22" ref-type="bibr" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">22</xref>; <xref rid="c23" ref-type="bibr" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">23</xref>]. These approximations provide a lower bound to these intractable terms in the variational objective of <xref rid="eqn3" ref-type="disp-formula" hwp:id="xref-disp-formula-4-3" hwp:rel-id="disp-formula-4">Equation 3</xref>. In particular, we introduce auxiliary <italic toggle="yes">K</italic>-multinomial distributions <italic toggle="yes">q(ϕ<sub>il</sub></italic>) and <italic toggle="yes">q(ξ<sub>il</sub></italic>),</p><disp-formula id="eqn6" hwp:id="disp-formula-7" hwp:rev-id="xref-disp-formula-7-1 xref-disp-formula-7-2 xref-disp-formula-7-3">
<alternatives hwp:id="alternatives-22"><graphic xlink:href="013227_eqn6.gif" position="float" orientation="portrait" hwp:id="graphic-10"/></alternatives></disp-formula><p hwp:id="p-69">These distributions <italic toggle="yes">q(ϕ<sub>il</sub></italic>) and <italic toggle="yes">q(ξ<sub>il</sub></italic>) approximate only the conditionals of the allele frequencies local to the sampled location <italic toggle="yes">l</italic> and the individual <italic toggle="yes">i</italic>; the parameters to these distributions are local.</p><p hwp:id="p-70">Substituting the lower bounds from <xref rid="eqn6" ref-type="disp-formula" hwp:id="xref-disp-formula-7-1" hwp:rel-id="disp-formula-7">Equation 6</xref> in <xref rid="eqn5" ref-type="disp-formula" hwp:id="xref-disp-formula-6-2" hwp:rel-id="disp-formula-6">Equation 5</xref>, the complete conditional is</p><disp-formula id="eqn7" hwp:id="disp-formula-8" hwp:rev-id="xref-disp-formula-8-1 xref-disp-formula-8-2">
<alternatives hwp:id="alternatives-23"><graphic xlink:href="013227_eqn7.gif" position="float" orientation="portrait" hwp:id="graphic-11"/></alternatives></disp-formula><p hwp:id="p-71">Our approximation has effectively placed the complete conditional of allele frequency <italic toggle="yes">β<sub>k,l</sub></italic> in the exponential family. By choosing the variational distribution <inline-formula hwp:id="inline-formula-16"><alternatives hwp:id="alternatives-24"><inline-graphic xlink:href="013227_inline44.gif" hwp:id="inline-graphic-16"/></alternatives></inline-formula> from <xref rid="eqn4" ref-type="disp-formula" hwp:id="xref-disp-formula-5-2" hwp:rel-id="disp-formula-5">Equation 4</xref> to be the Beta distribution, the same family as the prior distribution, we satisfy the conditions for a closed form coordinate update for the local parameters <inline-formula hwp:id="inline-formula-17"><alternatives hwp:id="alternatives-25"><inline-graphic xlink:href="013227_inline14.gif" hwp:id="inline-graphic-17"/></alternatives></inline-formula> The optimal <inline-formula hwp:id="inline-formula-18"><alternatives hwp:id="alternatives-26"><inline-graphic xlink:href="013227_inline15.gif" hwp:id="inline-graphic-18"/></alternatives></inline-formula> is the expected natural parameter (under <italic toggle="yes">q</italic>) of the complete conditional in <xref rid="eqn7" ref-type="disp-formula" hwp:id="xref-disp-formula-8-2" hwp:rel-id="disp-formula-8">Equation 7</xref> [<xref rid="c18" ref-type="bibr" hwp:id="xref-ref-18-2" hwp:rel-id="ref-18">18</xref>].</p><p hwp:id="p-72">Another perspective on the approximations in <xref rid="eqn6" ref-type="disp-formula" hwp:id="xref-disp-formula-7-2" hwp:rel-id="disp-formula-7">Equation 6</xref> is they lead to a computationally efficient lower bound on the objective of <xref rid="eqn3" ref-type="disp-formula" hwp:id="xref-disp-formula-4-4" hwp:rel-id="disp-formula-4">Equation 3</xref>.</p></sec><sec id="s5d3" hwp:id="sec-15"><title hwp:id="title-15">Computing the optimal local parameters</title><p hwp:id="p-73">Computing stochastic gradient updates for the global parameters. We now turn to the stochastic optimization of the population proportions parameter <inline-formula hwp:id="inline-formula-19"><alternatives hwp:id="alternatives-27"><inline-graphic xlink:href="013227_inline16.gif" hwp:id="inline-graphic-19"/></alternatives></inline-formula> using the subsampled observations <italic toggle="yes">x<sub>1:N,l</sub></italic> at location <italic toggle="yes">l</italic>. We compute noisy estimates of the natural gradient [<xref rid="c21" ref-type="bibr" hwp:id="xref-ref-21-2" hwp:rel-id="ref-21">21</xref>] of the variational objective with respect to <inline-formula hwp:id="inline-formula-20"><alternatives hwp:id="alternatives-28"><inline-graphic xlink:href="013227_inline17.gif" hwp:id="inline-graphic-20"/></alternatives></inline-formula> and we follow these estimates with a decreasing step-size. Following <xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-8" hwp:rel-id="ref-7">[7]</xref>, we can compute the natural gradient of <xref rid="eqn3" ref-type="disp-formula" hwp:id="xref-disp-formula-4-5" hwp:rel-id="disp-formula-4">Equation 3</xref> with respect to the global variational parameter <inline-formula hwp:id="inline-formula-21"><alternatives hwp:id="alternatives-29"><inline-graphic xlink:href="013227_inline18.gif" hwp:id="inline-graphic-21"/></alternatives></inline-formula> by first computing the coordinate update for <inline-formula hwp:id="inline-formula-22"><alternatives hwp:id="alternatives-30"><inline-graphic xlink:href="013227_inline19.gif" hwp:id="inline-graphic-22"/></alternatives></inline-formula> and then subtracting its current setting.</p><p hwp:id="p-74">To compute the coordinate update for <inline-formula hwp:id="inline-formula-23"><alternatives hwp:id="alternatives-31"><inline-graphic xlink:href="013227_inline45.gif" hwp:id="inline-graphic-23"/></alternatives></inline-formula>, we write down the complete conditional of the population proportions <italic toggle="yes">θ<sub>i</sub></italic>:</p><disp-formula id="eqn8" hwp:id="disp-formula-9" hwp:rev-id="xref-disp-formula-9-1">
<alternatives hwp:id="alternatives-32"><graphic xlink:href="013227_eqn8.gif" position="float" orientation="portrait" hwp:id="graphic-12"/></alternatives></disp-formula><p hwp:id="p-75">Similar to the complete conditionals of the local variables in <xref rid="eqn5" ref-type="disp-formula" hwp:id="xref-disp-formula-6-3" hwp:rel-id="disp-formula-6">Equation 5</xref>, the complete conditional in <xref rid="eqn8" ref-type="disp-formula" hwp:id="xref-disp-formula-9-1" hwp:rel-id="disp-formula-9">Equation 8</xref> is not in the exponential family. We use the multinomial approximations in <xref rid="eqn6" ref-type="disp-formula" hwp:id="xref-disp-formula-7-3" hwp:rel-id="disp-formula-7">Equation 6</xref> to bring the complete conditional into the exponential family, and in the same family as the prior distribution over the population proportions:</p><disp-formula id="eqn9" hwp:id="disp-formula-10" hwp:rev-id="xref-disp-formula-10-1 xref-disp-formula-10-2">
<alternatives hwp:id="alternatives-33"><graphic xlink:href="013227_eqn9.gif" position="float" orientation="portrait" hwp:id="graphic-13"/></alternatives></disp-formula><p hwp:id="p-76">Following <xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-9" hwp:rel-id="ref-7">[7]</xref>, the stochastic natural gradient of the variational objective with respect to the global parameter <inline-formula hwp:id="inline-formula-24"><alternatives hwp:id="alternatives-34"><inline-graphic xlink:href="013227_inline20.gif" hwp:id="inline-graphic-24"/></alternatives></inline-formula> using <italic toggle="yes">L</italic> replicates of <italic toggle="yes">x<sub>i,l</sub></italic> is</p><disp-formula id="eqn10" hwp:id="disp-formula-11" hwp:rev-id="xref-disp-formula-11-1 xref-disp-formula-11-2 xref-disp-formula-11-3 xref-disp-formula-11-4">
<alternatives hwp:id="alternatives-35"><graphic xlink:href="013227_eqn10.gif" position="float" orientation="portrait" hwp:id="graphic-14"/></alternatives></disp-formula><p hwp:id="p-77">Notice we have used the expected natural parameter from the complete conditional in <xref rid="eqn9" ref-type="disp-formula" hwp:id="xref-disp-formula-10-2" hwp:rel-id="disp-formula-10">Equation 9</xref> in <xref rid="eqn10" ref-type="disp-formula" hwp:id="xref-disp-formula-11-1" hwp:rel-id="disp-formula-11">Equation 10</xref>. We arrive at this form of the natural gradient by premultipling the gradient by the inverse Fisher information, and replacing the summation over all SNP locations in <xref rid="eqn10" ref-type="disp-formula" hwp:id="xref-disp-formula-11-2" hwp:rel-id="disp-formula-11">Equation 10</xref> with a summation over <italic toggle="yes">L</italic> replications from the sampled location. <xref rid="eqn10" ref-type="disp-formula" hwp:id="xref-disp-formula-11-3" hwp:rel-id="disp-formula-11">Equation 10</xref> is a noisy natural gradient of a lower bound on the variational objective of <xref rid="eqn3" ref-type="disp-formula" hwp:id="xref-disp-formula-4-6" hwp:rel-id="disp-formula-4">Equation 3</xref>.</p><p hwp:id="p-78">To optimize the variational objective with respect to the population proportions <inline-formula hwp:id="inline-formula-25"><alternatives hwp:id="alternatives-36"><inline-graphic xlink:href="013227_inline21.gif" hwp:id="inline-graphic-25"/></alternatives></inline-formula> we use the natural gradients in <xref rid="eqn10" ref-type="disp-formula" hwp:id="xref-disp-formula-11-4" hwp:rel-id="disp-formula-11">Equation 10</xref> in a Robbins-Monro algorithm <xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-10" hwp:rel-id="ref-7">[7]</xref>. At each iteration we update the global variational parameters with a noisy gradient computed from the SNP observations at location <italic toggle="yes">l</italic>. The step-size at iteration <italic toggle="yes">t</italic> is <inline-formula hwp:id="inline-formula-26"><alternatives hwp:id="alternatives-37"><inline-graphic xlink:href="013227_inline22.gif" hwp:id="inline-graphic-26"/></alternatives></inline-formula> and is set using the schedule <disp-formula id="eqn11" hwp:id="disp-formula-12">
<alternatives hwp:id="alternatives-38"><graphic xlink:href="013227_eqn11.gif" position="float" orientation="portrait" hwp:id="graphic-15"/></alternatives></disp-formula></p><p hwp:id="p-79">This satisfies the Robbins-Monro conditions on the step-size, and guarantees convergence to a local optimum of the variational objective <xref rid="c8" ref-type="bibr" hwp:id="xref-ref-8-3" hwp:rel-id="ref-8">[8]</xref>.</p></sec><sec id="s5d4" hwp:id="sec-16"><title hwp:id="title-16">The stochastic algorithm</title><p hwp:id="p-80">The full algorithm is shown in <xref rid="figS1" ref-type="fig" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Figure S1</xref>. For each iteration, we first subsample a SNP location <italic toggle="yes">l</italic> and compute optimal local parameters <inline-formula hwp:id="inline-formula-27"><alternatives hwp:id="alternatives-39"><inline-graphic xlink:href="013227_inline23.gif" hwp:id="inline-graphic-27"/></alternatives></inline-formula> for the sample, given the current settings of the global parameters <inline-formula hwp:id="inline-formula-28"><alternatives hwp:id="alternatives-40"><inline-graphic xlink:href="013227_inline24.gif" hwp:id="inline-graphic-28"/></alternatives></inline-formula> We then update the global parameter <inline-formula hwp:id="inline-formula-29"><alternatives hwp:id="alternatives-41"><inline-graphic xlink:href="013227_inline25.gif" hwp:id="inline-graphic-29"/></alternatives></inline-formula> of each individual <italic toggle="yes">i</italic> using the stochastic natural gradient of the variational objective, with respect to <inline-formula hwp:id="inline-formula-30"><alternatives hwp:id="alternatives-42"><inline-graphic xlink:href="013227_inline26.gif" hwp:id="inline-graphic-30"/></alternatives></inline-formula> computed from the subsampled data and local parameters.</p></sec><sec id="s5d5" hwp:id="sec-17"><title hwp:id="title-17">Memory efficient computation</title><p hwp:id="p-81">During training, the stochastic variational inference algorithm is only required to keep the variational population proportions <inline-formula hwp:id="inline-formula-31"><alternatives hwp:id="alternatives-43"><inline-graphic xlink:href="013227_inline27.gif" hwp:id="inline-graphic-31"/></alternatives></inline-formula> for all individuals <italic toggle="yes">i ∈ 1, … N</italic> in memory. For a given location, the optimal local parameters <inline-formula hwp:id="inline-formula-32"><alternatives hwp:id="alternatives-44"><inline-graphic xlink:href="013227_inline28.gif" hwp:id="inline-graphic-32"/></alternatives></inline-formula> can be computed using the local optimization steps—steps 6 to 9—in <xref rid="figS1" ref-type="fig" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Figure S1</xref>. The local parameters need not be kept around beyond the corresponding sampling step. This drastically cuts the memory needed. The memory requirement is therefore <italic toggle="yes">O(NK)</italic> where <italic toggle="yes">N</italic> is the number of individuals and <italic toggle="yes">K</italic> is the number of latent ancestral populations. Further, this results in a small fitted model state: the fitted <inline-formula hwp:id="inline-formula-33"><alternatives hwp:id="alternatives-45"><inline-graphic xlink:href="013227_inline29.gif" hwp:id="inline-graphic-33"/></alternatives></inline-formula> Given the <inline-formula hwp:id="inline-formula-34"><alternatives hwp:id="alternatives-46"><inline-graphic xlink:href="013227_inline30.gif" hwp:id="inline-graphic-34"/></alternatives></inline-formula> the allele frequencies <inline-formula hwp:id="inline-formula-35"><alternatives hwp:id="alternatives-47"><inline-graphic xlink:href="013227_inline31.gif" hwp:id="inline-graphic-35"/></alternatives></inline-formula> can be optimized for any given location <italic toggle="yes">l</italic>, using the local step.</p></sec><sec id="s5d6" hwp:id="sec-18"><title hwp:id="title-18">Linear scaling in the number of threads</title><p hwp:id="p-82">We can compute the local steps and the global steps in parallel across <italic toggle="yes">T</italic> threads. First, we “map” the individuals into <italic toggle="yes">T</italic> disjoint sets, and each thread is responsible for computation on one of these sets of individuals. Notice that each thread can independently compute the local parameters <inline-formula hwp:id="inline-formula-36"><alternatives hwp:id="alternatives-48"><inline-graphic xlink:href="013227_inline32.gif" hwp:id="inline-graphic-36"/></alternatives></inline-formula> for any individual <italic toggle="yes">n</italic> that it owns. This corresponds to step 6 of the algorithm in <xref rid="figS1" ref-type="fig" hwp:id="xref-fig-3-4" hwp:rel-id="F3">Figure S1</xref>. Further, the sums required in step 7 of the algorithm in <xref rid="figS1" ref-type="fig" hwp:id="xref-fig-3-5" hwp:rel-id="F3">Figure S1</xref> can also be computed in parallel. The “reduce” step consists of aggregating the per-thread sums in step 7, and estimating the new Beta parameters. This is an <italic toggle="yes">O(T + K)</italic> operation, where <italic toggle="yes">T</italic> is the number of threads and <italic toggle="yes">K</italic> is the number of ancestral populations. Since and <italic toggle="yes">K</italic> are small constants, our reduce step is inexpensive. The global step in step 9 can also be computed in parallel.</p><p hwp:id="p-83">Given <italic toggle="yes">T</italic> threads, the computational complexity of the stochastic algorithm is <inline-formula hwp:id="inline-formula-37"><alternatives hwp:id="alternatives-49"><inline-graphic xlink:href="013227_inline33.gif" hwp:id="inline-graphic-37"/></alternatives></inline-formula> The algorithm is dominated by the parallel computation in steps 6 and 9, which scale linearly in the number of threads <italic toggle="yes">T</italic>. By increasing <italic toggle="yes">T</italic>, we scale our algorithm linearly in the number of threads.</p></sec><sec id="s5d7" hwp:id="sec-19"><title hwp:id="title-19">Initializing variational parameters</title><p hwp:id="p-84">We initialize the population proportions randomly using <italic toggle="yes">θ<sub>ik</sub></italic> ~ Gamma(100; 0:01). Within each local step, we initialize <inline-formula hwp:id="inline-formula-38"><alternatives hwp:id="alternatives-50"><inline-graphic xlink:href="013227_inline34.gif" hwp:id="inline-graphic-38"/></alternatives></inline-formula> at location l to the prior parameters <italic toggle="yes">(a, b)</italic>. We use the same initialization procedure on all data sets.</p></sec><sec id="s5d8" hwp:id="sec-20"><title hwp:id="title-20">Assessing convergence using a validation set</title><p hwp:id="p-85">We hold out a <italic toggle="yes">validation</italic> set of genotype observations, and evaluate the predictive accuracy on that set to assess convergence of the stochastic algorithm in <xref rid="figS1" ref-type="fig" hwp:id="xref-fig-3-6" hwp:rel-id="F3">Figure S1</xref> <xref rid="c12" ref-type="bibr" hwp:id="xref-ref-12-2" hwp:rel-id="ref-12">[12]</xref>. These observations are treated as missing during training.</p><p hwp:id="p-86">The validation set is chosen with computational efficiency in mind. We will periodically evaluate the heldout log likelihood on this set (the <italic toggle="yes">validation log likelihood</italic>) to determine convergence of the algorithm in <xref rid="figS1" ref-type="fig" hwp:id="xref-fig-3-7" hwp:rel-id="F3">Figure S1</xref>. By choosing individuals from a small fraction of total locations <italic toggle="yes">L</italic>, we ensure that this periodic computation is only required to recompute the optimal <inline-formula hwp:id="inline-formula-39"><alternatives hwp:id="alternatives-51"><inline-graphic xlink:href="013227_inline35.gif" hwp:id="inline-graphic-39"/></alternatives></inline-formula> for those locations.</p><p hwp:id="p-87">The TERASTRUCTURE algorithm stops when the change in validation log likelihood is less than 0.0001%. We measure this change over 100; 000 iterations.</p><p hwp:id="p-88">For the validation set, we uniformly sample at random 0:5% of the <italic toggle="yes">L</italic> locations, and at each location we uniformly sample at random and keep aside observed genotypes for <italic toggle="yes">r</italic> individuals. The number of per-location held out individuals <italic toggle="yes">r</italic> is set to <italic toggle="yes">N</italic>/100 for large <italic toggle="yes">N</italic> (<italic toggle="yes">N</italic> &gt; 2000) and otherwise to <italic toggle="yes">N/10</italic>. This allows for a reasonably small fraction of individuals to be held out from each location. Further, <italic toggle="yes">r</italic> is limited to a maximum of 1000 individuals for any <italic toggle="yes">N</italic>.</p></sec><sec id="s5d9" hwp:id="sec-21"><title hwp:id="title-21">Choosing the number of ancestral populations</title><p hwp:id="p-89">In our experiments on the real data sets (see <xref rid="tblS1" ref-type="table" hwp:id="xref-table-wrap-2-3" hwp:rel-id="T2">Table S1</xref>), we fixed the number of populations <italic toggle="yes">K</italic> to the optimal values based on validation log likelihoods. Our sensitivity analysis (see <xref rid="figS3" ref-type="fig" hwp:id="xref-fig-5-2" hwp:rel-id="F5">Figure S3</xref>) revealed that <italic toggle="yes">K = 8</italic> had the optimal validation likelihood on the TGP data, while <italic toggle="yes">K = 10</italic> was the optimal for the HGDP data set. In our experiments on simulated data sets (see <xref rid="tblS2" ref-type="table" hwp:id="xref-table-wrap-3-3" hwp:rel-id="T3">Table S2</xref>), we set <italic toggle="yes">K</italic> to the number of ground truth ancestral populations: <italic toggle="yes">K = 6</italic>.</p><fig id="figS3" position="float" orientation="portrait" fig-type="figure" hwp:id="F5" hwp:rev-id="xref-fig-5-1 xref-fig-5-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;013227v1/FIGS3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">figS3</object-id><label>Figure S3:</label><caption hwp:id="caption-6"><p hwp:id="p-101">Predictive log likelihood as a function of the number of ancestral populations on the Human Genome Diversity Panel (HGDP) and 1000 Genomes Project (TGP) data sets. The HGDP data peaks at 10 population, and the TGP data peaks at 8 populations.</p></caption><graphic xlink:href="013227_figS3" position="float" orientation="portrait" hwp:id="graphic-18"/></fig></sec></sec><sec id="s5e" hwp:id="sec-22"><title hwp:id="title-22">Experimental setup for the study</title><p hwp:id="p-90">The goal of our empirical study is to assess the accuracy and scalability of the stochastic variational inference algorithm of <xref rid="figS1" ref-type="fig" hwp:id="xref-fig-3-8" hwp:rel-id="F3">Figure S1</xref> and compare to leading scalable methods in the research literature. In this section, we present the details of our experimental setup. We refer the reader to the main article for the results.</p><p hwp:id="p-91">We compared our algorithm to the best existing algorithms for discovering population structure: the FASTSTRUCTURE algorithm <xref rid="c3" ref-type="bibr" hwp:id="xref-ref-3-7" hwp:rel-id="ref-3">[3]</xref> and the ADMIXTURE algorithm <xref rid="c2" ref-type="bibr" hwp:id="xref-ref-2-4" hwp:rel-id="ref-2">[2]</xref>. We fit these algorithms to the largest real-world genotyping data publicly available—the HGDP [<xref rid="c9" ref-type="bibr" hwp:id="xref-ref-9-2" hwp:rel-id="ref-9">9</xref>; <xref rid="c10" ref-type="bibr" hwp:id="xref-ref-10-2" hwp:rel-id="ref-10">10</xref>] and the TGP <xref rid="c11" ref-type="bibr" hwp:id="xref-ref-11-2" hwp:rel-id="ref-11">[11]</xref> data sets. We also studied fits to massive synthetic data sets. Our synthetic data sets have up to <italic toggle="yes">N</italic> = 1,000,000 individuals and <italic toggle="yes">L</italic> = 1,000,000 SNP locations, for a total of 10<sup>12</sup> genotype observations.</p><p hwp:id="p-92">On the synthetic data sets, we studied the accuracy of these algorithms in retrieving the ground truth population structure, the run time of these algorithms, and the ability of these algorithms to scale to massive data sets. On the real data sets, we used the predictive approach to evaluating model fitness <xref rid="c12" ref-type="bibr" hwp:id="xref-ref-12-3" hwp:rel-id="ref-12">[12]</xref>.</p><sec id="s5e1" hwp:id="sec-23"><title hwp:id="title-23">Metrics</title><p hwp:id="p-93">On real data sets, we computed the predictive accuracy on a test set of observed genotypes by computing the held-out log likelihood under the PSD model. The test set is chosen to enable a fair comparison to other algorithms. We hold out genotypes for 0:5% of the N individuals from each location <italic toggle="yes">l ∈ 1, … L</italic>. A better predictive accuracy corresponds to a better fit to the data <xref rid="c12" ref-type="bibr" hwp:id="xref-ref-12-4" hwp:rel-id="ref-12">[12]</xref>. We approximate the predictive distribution of a heldout SNP using variational posterior estimates of <italic toggle="yes">θ</italic> and <italic toggle="yes">β</italic>.</p><p hwp:id="p-94">On synthetic data sets, we measured the accuracy in recovering the ground truth population proportions. We computed the Kullback Leibler divergence <xref rid="c24" ref-type="bibr" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">[24]</xref> of the variational posterior estimate <inline-formula hwp:id="inline-formula-40"><alternatives hwp:id="alternatives-52"><inline-graphic xlink:href="013227_inline36.gif" hwp:id="inline-graphic-40"/></alternatives></inline-formula> to the true population proportions <inline-formula hwp:id="inline-formula-41"><alternatives hwp:id="alternatives-53"><inline-graphic xlink:href="013227_inline37.gif" hwp:id="inline-graphic-41"/></alternatives></inline-formula> for each individual <italic toggle="yes">i</italic>. We then compared the median KL divergence across all individuals.</p></sec><sec id="s5e2" hwp:id="sec-24"><title hwp:id="title-24">Hyperparameters</title><p hwp:id="p-95">We set the Dirichlet parameter <italic toggle="yes">c</italic> to <inline-formula hwp:id="inline-formula-42"><alternatives hwp:id="alternatives-54"><inline-graphic xlink:href="013227_inline38.gif" hwp:id="inline-graphic-42"/></alternatives></inline-formula> to enforce a sparse prior on the per-individual population proportions. We set the learning rate parameters, <italic toggle="yes">τ<sub>0</sub></italic> to 1 and <inline-formula hwp:id="inline-formula-43"><alternatives hwp:id="alternatives-55"><inline-graphic xlink:href="013227_inline39.gif" hwp:id="inline-graphic-43"/></alternatives></inline-formula> to 0.5, to allow rapid learning in the early iterations. Finally, we set the hyperparameters <italic toggle="yes">a</italic> and <italic toggle="yes">b</italic> to 1 to enforce a uniform prior on the population parameters <italic toggle="yes">β<sub>1:K,1:L</sub></italic>. We used the same hyperparameter settings and initialization in all of our experiments.</p></sec><sec id="s5e3" hwp:id="sec-25"><title hwp:id="title-25">Open-source software</title><p hwp:id="p-96">Our software is implemented in C++ and has 5400 lines of code. It uses the POSIX Threading library for multi-threaded computation. It inputs genotype data in text or PLINK format <xref rid="c25" ref-type="bibr" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">[25]</xref> and outputs the population proportions <inline-formula hwp:id="inline-formula-44"><alternatives hwp:id="alternatives-56"><inline-graphic xlink:href="013227_inline40.gif" hwp:id="inline-graphic-44"/></alternatives></inline-formula> An option to the software tool computes the expected allele frequency Beta parameters local to a list of locations, given the global individual population proportions <inline-formula hwp:id="inline-formula-45"><alternatives hwp:id="alternatives-57"><inline-graphic xlink:href="013227_inline41.gif" hwp:id="inline-graphic-45"/></alternatives></inline-formula> and a list of SNP locations. Our software is available at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://github.com/premgopalan/terastructure" ext-link-type="uri" xlink:href="http://github.com/premgopalan/terastructure" hwp:id="ext-link-2">http://github.com/premgopalan/terastructure</ext-link>.</p></sec><sec id="s5e4" hwp:id="sec-26"><title hwp:id="title-26">Computing hardware</title><p hwp:id="p-97">All experiments were run on a single multicore machine with two Intel Xeon E5-2680v2 processors, with 10 cores each and running at 2.8 GHz. The maximum RAM required for our experiments is 10 GB.</p></sec></sec></sec></body><back><fn-group hwp:id="fn-group-1"><fn id="fn1" hwp:id="fn-1" hwp:rev-id="xref-fn-1-1"><label><sup>1</sup></label><p hwp:id="p-98">We describe and illustrate these quantities as though they are estimates. More technically, the algorithm stores parameterized approximate posteriors to them.</p></fn></fn-group><ref-list hwp:id="ref-list-1"><title hwp:id="title-27">REFERENCES</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1 xref-ref-1-2 xref-ref-1-3 xref-ref-1-4 xref-ref-1-5"><label>[1]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Pritchard J."><surname>Pritchard</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Stephens M."><surname>Stephens</surname>, <given-names>M.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Donnelly P."><surname>Donnelly</surname>, <given-names>P.</given-names></string-name> <article-title hwp:id="article-title-2">Inference of population structure using multilo-cus genotype data</article-title>. <source hwp:id="source-1">Genetics</source> <volume>155</volume>, <fpage>945</fpage>–<lpage>959</lpage>, <month>June</month> (<year>2000</year>).</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1 xref-ref-2-2 xref-ref-2-3 xref-ref-2-4 xref-ref-2-5"><label>[2]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Alexander D. H."><surname>Alexander</surname>, <given-names>D. H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Novembre J."><surname>Novembre</surname>, <given-names>J.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Lange K."><surname>Lange</surname>, <given-names>K.</given-names></string-name> <article-title hwp:id="article-title-3">Fast model-based estimation of ancestry in unrelated individuals</article-title>. <source hwp:id="source-2">Genome research</source> <volume>19</volume>(<issue>9</issue>), <fpage>1655</fpage>–<lpage>1664</lpage> (<year>2009</year>).</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1 xref-ref-3-2 xref-ref-3-3 xref-ref-3-4 xref-ref-3-5 xref-ref-3-6 xref-ref-3-7 xref-ref-3-8"><label>[3]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Raj A."><surname>Raj</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Stephens M."><surname>Stephens</surname>, <given-names>M.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Pritchard J."><surname>Pritchard</surname>, <given-names>J.</given-names></string-name> <article-title hwp:id="article-title-4">Variational inference of population structure in large SNP datasets</article-title>. <source hwp:id="source-3">Genetics</source> <volume>197</volume>, <fpage>573</fpage>–<lpage>589</lpage> (<year>2014</year>).</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1"><label>[4]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.4" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Bryc K."><surname>Bryc</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Durand E."><surname>Durand</surname>, <given-names>E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Macpherson J. M."><surname>Macpherson</surname>, <given-names>J. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Reich D."><surname>Reich</surname>, <given-names>D.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Mountain J."><surname>Mountain</surname>, <given-names>J.</given-names></string-name> <article-title hwp:id="article-title-5">The genetic ancestry of african, latino, and european americans across the united states</article-title>. <source hwp:id="source-4">bioRxiv</source> <ext-link l:rel="related" l:ref-type="uri" l:ref="http://dx.doi.org/10.1101/009340" ext-link-type="uri" xlink:href="http://dx.doi.org/10.1101/009340" hwp:id="ext-link-3">http://dx.doi.org/10.1101/009340</ext-link> (<year>2014</year>).</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1 xref-ref-5-2"><label>[5]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Jordan M."><surname>Jordan</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ghahramani Z."><surname>Ghahramani</surname>, <given-names>Z.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jaakkola T."><surname>Jaakkola</surname>, <given-names>T.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Saul L."><surname>Saul</surname>, <given-names>L.</given-names></string-name> <article-title hwp:id="article-title-6">Introduction to variational methods for graphical models</article-title>. <source hwp:id="source-5">Machine Learning</source> <volume>37</volume>, <fpage>183</fpage>–<lpage>233</lpage> (<year>1999</year>).</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2"><label>[6]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Wainwright M."><surname>Wainwright</surname>, <given-names>M.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Jordan M."><surname>Jordan</surname>, <given-names>M.</given-names></string-name> <article-title hwp:id="article-title-7">Graphical models, exponential families, and variational inference</article-title>. <source hwp:id="source-6">Foundations and Trends in Machine Learning</source> <volume>1</volume>(<issue>1–2</issue>), <fpage>1</fpage>–<lpage>305</lpage> (<year>2008</year>).</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1 xref-ref-7-2 xref-ref-7-3 xref-ref-7-4 xref-ref-7-5 xref-ref-7-6 xref-ref-7-7 xref-ref-7-8 xref-ref-7-9 xref-ref-7-10"><label>[7]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Hoffman M."><surname>Hoffman</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Blei D."><surname>Blei</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wang C."><surname>Wang</surname>, <given-names>C.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Paisley J."><surname>Paisley</surname>, <given-names>J.</given-names></string-name> <article-title hwp:id="article-title-8">Stochastic variational inference</article-title>. <source hwp:id="source-7">Journal of Machine Learning Research</source> <volume>14</volume>, <fpage>1303</fpage>–<lpage>1347</lpage> (<year>2013</year>).</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1 xref-ref-8-2 xref-ref-8-3"><label>[8]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Robbins H."><surname>Robbins</surname>, <given-names>H.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Monro S."><surname>Monro</surname>, <given-names>S.</given-names></string-name> <article-title hwp:id="article-title-9">A stochastic approximation method</article-title>. <source hwp:id="source-8">The Annals of Mathematical Statistics</source> <volume>22</volume>(<issue>3</issue>), <fpage>400</fpage>–<lpage>407</lpage> (<year>1951</year>).</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1 xref-ref-9-2"><label>[9]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Cann H. M."><surname>Cann</surname>, <given-names>H. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="de Toma C."><surname>de Toma</surname>, <given-names>C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cazes L."><surname>Cazes</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Legrand M. F."><surname>Legrand</surname>, <given-names>M. F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Morel V."><surname>Morel</surname>, <given-names>V.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Piouffre L."><surname>Piouffre</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bodmer J."><surname>Bodmer</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bodmer W. F."><surname>Bodmer</surname>, <given-names>W. F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bonne-Tamir B."><surname>Bonne-Tamir</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cambon-Thomsen A."><surname>Cambon-Thomsen</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chen Z."><surname>Chen</surname>, <given-names>Z.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chu J."><surname>Chu</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Carcassi C."><surname>Carcassi</surname>, <given-names>C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Contu L."><surname>Contu</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Du R."><surname>Du</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Excoffier L."><surname>Excoffier</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ferrara G. B."><surname>Ferrara</surname>, <given-names>G. B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Friedlaender J. S."><surname>Friedlaender</surname>, <given-names>J. S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Groot H."><surname>Groot</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Gurwitz D."><surname>Gurwitz</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jenkins T."><surname>Jenkins</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Herrera R. J."><surname>Herrera</surname>, <given-names>R. J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Huang X."><surname>Huang</surname>, <given-names>X.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kidd J."><surname>Kidd</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kidd K. K."><surname>Kidd</surname>, <given-names>K. K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Langaney A."><surname>Langaney</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lin A. A."><surname>Lin</surname>, <given-names>A. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mehdi S. Q."><surname>Mehdi</surname>, <given-names>S. Q.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Parham P."><surname>Parham</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Piazza A."><surname>Piazza</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pistillo M. P."><surname>Pistillo</surname>, <given-names>M. P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Qian Y."><surname>Qian</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shu Q."><surname>Shu</surname>, <given-names>Q.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Xu J."><surname>Xu</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zhu S."><surname>Zhu</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Weber J. L."><surname>Weber</surname>, <given-names>J. L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Greely H. T."><surname>Greely</surname>, <given-names>H. T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Feldman M. W."><surname>Feldman</surname>, <given-names>M. W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Thomas G."><surname>Thomas</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dausset J."><surname>Dausset</surname>, <given-names>J.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Cavalli-Sforza L. L."><surname>Cavalli-Sforza</surname>, <given-names>L. L.</given-names></string-name> <article-title hwp:id="article-title-10">A human genome diversity cell line panel</article-title>. <source hwp:id="source-9">Science</source> <volume>296</volume>(<issue>5566</issue>), <fpage>261</fpage>–<lpage>262</lpage>, <month>Apr</month> (<year>2002</year>).</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1 xref-ref-10-2"><label>[10]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Cavalli-Sforza L. L."><surname>Cavalli-Sforza</surname>, <given-names>L. L.</given-names></string-name> <article-title hwp:id="article-title-11">The Human Genome Diversity Project: past, present and future</article-title>. <source hwp:id="source-10">Nat. Rev. Genet</source>. <volume>6</volume>(<issue>4</issue>), <fpage>333</fpage>–<lpage>340</lpage>, <month>Apr</month> (<year>2005</year>).</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1 xref-ref-11-2"><label>[11]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><collab hwp:id="collab-1">1000 Genomes Project Consortium</collab>. <article-title hwp:id="article-title-12">An integrated map of genetic variation from 1,092 human genomes</article-title>. <source hwp:id="source-11">Nature</source> <volume>491</volume>(<issue>7422</issue>), <fpage>56</fpage>–<lpage>65</lpage>, <month>Nov</month> (<year>2012</year>).</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1 xref-ref-12-2 xref-ref-12-3 xref-ref-12-4"><label>[12]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.12" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Geisser S."><surname>Geisser</surname>, <given-names>S.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Eddy W."><surname>Eddy</surname>, <given-names>W.</given-names></string-name> <article-title hwp:id="article-title-13">A predictive approach to model selection</article-title>. <source hwp:id="source-12">Journal of the American Statistical Association</source> <volume>74</volume>, <fpage>153</fpage>–<lpage>160</lpage> (<year>1979</year>).</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1"><label>[13]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Rosenberg N. A."><surname>Rosenberg</surname>, <given-names>N. A.</given-names></string-name> <article-title hwp:id="article-title-14">Standardized subsets of the hgdp-ceph human genome diversity cell line panel, accounting for atypical and duplicated samples and pairs of close relatives</article-title>. <source hwp:id="source-13">Annals of Human Genetics</source> <volume>70</volume>(<issue>6</issue>), <fpage>841</fpage>–<lpage>847</lpage> (<year>2006</year>).</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><label>[14]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Balding D."><surname>Balding</surname>, <given-names>D.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Nichols R."><surname>Nichols</surname>, <given-names>R.</given-names></string-name> <article-title hwp:id="article-title-15">A method for quantifying differentiation between populations at multi-allelic loci and its implications for investigating identity and paternity</article-title>. <source hwp:id="source-14">Genetica</source> <volume>96</volume>(<issue>1–2</issue>), <fpage>3</fpage>–<lpage>12</lpage> (<year>1995</year>).</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><label>[15]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.15" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Weir B. S."><surname>Weir</surname>, <given-names>B. S.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Cockerham C. C."><surname>Cockerham</surname>, <given-names>C. C.</given-names></string-name> <article-title hwp:id="article-title-16">Estimating f-statistics for the analysis of population structure</article-title>. <source hwp:id="source-15">Evolution</source> <volume>38</volume>, <fpage>1358</fpage>–<lpage>1370</lpage> (<year>1984</year>).</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1"><label>[16]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Rosenberg N. A."><surname>Rosenberg</surname>, <given-names>N. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pritchard J. K."><surname>Pritchard</surname>, <given-names>J. K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Weber J. L."><surname>Weber</surname>, <given-names>J. L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cann H. M."><surname>Cann</surname>, <given-names>H. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kidd K. K."><surname>Kidd</surname>, <given-names>K. K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zhivotovsky L. A."><surname>Zhivotovsky</surname>, <given-names>L. A.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Feldman M. W."><surname>Feldman</surname>, <given-names>M. W.</given-names></string-name> <article-title hwp:id="article-title-17">Genetic structure of human populations</article-title>. <source hwp:id="source-16">Science</source> <volume>298</volume>, <fpage>2381</fpage>–<lpage>2385</lpage> (<year>2002</year>).</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><label>[17]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Peterson C."><surname>Peterson</surname>, <given-names>C.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Anderson J."><surname>Anderson</surname>, <given-names>J.</given-names></string-name> <article-title hwp:id="article-title-18">A mean field theory learning algorithm for neural networks</article-title>. <source hwp:id="source-17">Complex Systems</source> <volume>1</volume>(<issue>5</issue>), <fpage>995</fpage>–<lpage>1019</lpage> (<year>1987</year>).</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1 xref-ref-18-2"><label>[18]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.18" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Ghahramani Z."><surname>Ghahramani</surname>, <given-names>Z.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Beal M."><surname>Beal</surname>, <given-names>M.</given-names></string-name> <article-title hwp:id="article-title-19">Propagation algorithms for variational Bayesian learning</article-title>. <source hwp:id="source-18">In Neural Information Processing Systems</source>, <fpage>507</fpage>–<lpage>513</lpage>, (<year>2001</year>).</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><label>[19]</label><citation publication-type="book" citation-type="book" ref:id="013227v1.19" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Bishop C."><surname>Bishop</surname>, <given-names>C.</given-names></string-name> <source hwp:id="source-19">Pattern Recognition and Machine Learning</source>. <publisher-name>Springer New York</publisher-name>, (<year>2006</year>).</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><label>[20]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Sato M."><surname>Sato</surname>, <given-names>M.</given-names></string-name> <article-title hwp:id="article-title-20">Online model selection based on the variational Bayes</article-title>. <source hwp:id="source-20">Neural Computation</source> <volume>13</volume>(<issue>7</issue>), <fpage>1649</fpage>–<lpage>1681</lpage> (<year>2001</year>).</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1 xref-ref-21-2"><label>[21]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Amari S."><surname>Amari</surname>, <given-names>S.</given-names></string-name> <article-title hwp:id="article-title-21">Information geometry on hierarchy of probability distributions</article-title>. <source specific-use="IEEE" hwp:id="source-21">IEEE Transactions on Information Theory</source> <volume>47</volume>(<issue>5</issue>), <fpage>1701</fpage>–<lpage>1711</lpage> (<year>2001</year>).</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><label>[22]</label><citation publication-type="book" citation-type="book" ref:id="013227v1.22" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Bickel P."><surname>Bickel</surname>, <given-names>P.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Doksum K."><surname>Doksum</surname>, <given-names>K.</given-names></string-name> <source hwp:id="source-22">Mathematical Statistics: Basic Ideas and Selected Topics</source>, volume <volume>1</volume>. <publisher-name>Pearson Prentice Hall</publisher-name>, <publisher-loc>Upper Saddle River, NJ</publisher-loc>, <edition>2nd</edition> edition, (<year>2007</year>).</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1"><label>[23]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Wang C."><surname>Wang</surname>, <given-names>C.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Blei D."><surname>Blei</surname>, <given-names>D.</given-names></string-name> <article-title hwp:id="article-title-22">Variational inference in nonconjugate models</article-title>. <source hwp:id="source-23">Journal of Machine Learning Research</source> <volume>14</volume>, <fpage>1005</fpage>–<lpage>1031</lpage> (<year>2013</year>).</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1"><label>[24]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Kullback S."><surname>Kullback</surname>, <given-names>S.</given-names></string-name> and <string-name name-style="western" hwp:sortable="Leibler R."><surname>Leibler</surname>, <given-names>R.</given-names></string-name> <article-title hwp:id="article-title-23">On information and sufficiency</article-title>. <source hwp:id="source-24">The Annals of Mathematical Statistics</source> <volume>22</volume>(<issue>1</issue>), <fpage>79</fpage>–<lpage>86</lpage> (<year>1951</year>).</citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1"><label>[25]</label><citation publication-type="journal" citation-type="journal" ref:id="013227v1.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Purcell S."><surname>Purcell</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Neale B."><surname>Neale</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Todd-Brown K."><surname>Todd-Brown</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Thomas L."><surname>Thomas</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ferreira M. A."><surname>Ferreira</surname>, <given-names>M. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bender D."><surname>Bender</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Maller J."><surname>Maller</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sklar P."><surname>Sklar</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="De Bakker P. I."><surname>De Bakker</surname>, <given-names>P. I.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Daly M. J."><surname>Daly</surname>, <given-names>M. J.</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-24">Plink: a tool set for whole-genome association and population-based linkage analyses</article-title>. <source hwp:id="source-25">The American Journal of Human Genetics</source> <volume>81</volume>(<issue>3</issue>), <fpage>559</fpage>–<lpage>575</lpage> (<year>2007</year>).</citation></ref></ref-list></back></article>
