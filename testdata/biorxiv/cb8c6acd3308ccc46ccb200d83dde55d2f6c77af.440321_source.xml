<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/440321</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;440321v5</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;440321</article-id><article-id pub-id-type="other" hwp:sub-type="slug">440321</article-id><article-id pub-id-type="other" hwp:sub-type="atom-slug">440321</article-id><article-id pub-id-type="other" hwp:sub-type="tag">440321</article-id><article-version>1.5</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Animal Behavior and Cognition" hwp:journal="biorxiv"><subject>Animal Behavior and Cognition</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">A confirmation bias in perceptual decision-making due to hierarchical approximate inference</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1 xref-corresp-1-2"><label>*</label>Corresponding authors: <email hwp:id="email-1">lange.richard.d@gmail.com</email>, <email hwp:id="email-2">ralf.haefner@rochester.edu</email>.</corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" corresp="yes" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-1429-8333</contrib-id><name name-style="western" hwp:sortable="Lange Richard D."><surname>Lange</surname><given-names>Richard D.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref><xref ref-type="aff" rid="a4" hwp:id="xref-aff-4-1" hwp:rel-id="aff-4">4</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-1429-8333"/></contrib><contrib contrib-type="author" hwp:id="contrib-2"><name name-style="western" hwp:sortable="Chattoraj Ankani"><surname>Chattoraj</surname><given-names>Ankani</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">1</xref></contrib><contrib contrib-type="author" hwp:id="contrib-3"><name name-style="western" hwp:sortable="Beck Jeffrey M."><surname>Beck</surname><given-names>Jeffrey M.</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-1" hwp:rel-id="aff-3">3</xref></contrib><contrib contrib-type="author" hwp:id="contrib-4"><name name-style="western" hwp:sortable="Yates Jacob L."><surname>Yates</surname><given-names>Jacob L.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-3" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a5" hwp:id="xref-aff-5-1" hwp:rel-id="aff-5">5</xref></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-5"><name name-style="western" hwp:sortable="Haefner Ralf M."><surname>Haefner</surname><given-names>Ralf M.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-4" hwp:rel-id="aff-1">1</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-2" hwp:rel-id="corresp-1">*</xref></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2 xref-aff-1-3 xref-aff-1-4"><label>1</label><institution hwp:id="institution-1">Brain and Cognitive Sciences, University of Rochester</institution>, Rochester, NY 14627, <country>USA</country>.</aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1"><label>2</label><institution hwp:id="institution-2">Computer Science, University of Rochester</institution>, Rochester, NY 14627, <country>USA</country>.</aff><aff id="a3" hwp:id="aff-3" hwp:rev-id="xref-aff-3-1"><label>3</label><institution hwp:id="institution-3">Department of Neurobiology, Duke University</institution>, Durham, NC 27708, <country>USA</country>.</aff><aff id="a4" hwp:id="aff-4" hwp:rev-id="xref-aff-4-1"><label>4</label><institution hwp:id="institution-4">Department of Neurobiology, University of Pennsylvania</institution>, Philadelphia, PA 19104</aff><aff id="a5" hwp:id="aff-5" hwp:rev-id="xref-aff-5-1"><label>5</label><institution hwp:id="institution-5">Department of Biology, University of Maryland</institution>, College Park, MD 20742</aff></contrib-group><pub-date pub-type="epub-original" date-type="pub" publication-format="electronic" hwp:start="2021"><year>2021</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2018-10-11T13:03:09-07:00">
    <day>11</day><month>10</month><year>2018</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2021-06-14T19:27:14-07:00">
    <day>14</day><month>6</month><year>2021</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2018-10-11T13:10:14-07:00">
    <day>11</day><month>10</month><year>2018</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2021-06-14T19:31:35-07:00">
    <day>14</day><month>6</month><year>2021</year>
  </pub-date><elocation-id>440321</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2018-10-11"><day>11</day><month>10</month><year>2018</year></date>
<date date-type="rev-recd" hwp:start="2021-06-14"><day>14</day><month>6</month><year>2021</year></date>
<date date-type="accepted" hwp:start="2021-06-14"><day>14</day><month>6</month><year>2021</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2021</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="license-1"><p hwp:id="p-1">This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by-nc-nd/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></p></license></permissions><self-uri xlink:href="440321.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/change-list" xlink:role="change-list" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2021/pdf/440321v5.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="440321.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2021/abstracts/440321v5/440321v5.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2021/fulltext/440321v5/440321v5.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-2">Making good decisions requires updating beliefs according to new evidence. This is a dynamical process that is prone to biases: in some cases, beliefs become entrenched and resistant to new evidence (leading to primacy effects), while in other cases, beliefs fade over time and rely primarily on later evidence (leading to recency effects). How and why either type of bias dominates in a given context is an important open question. Here, we study this question in classic perceptual decision-making tasks, where, puzzlingly, previous empirical studies differ in the kinds of biases they observe, ranging from primacy to recency, despite seemingly equivalent tasks. We present a new model, based on hierarchical approximate inference and derived from normative principles, that not only explains both primacy and recency effects in existing studies, but also predicts how the type of bias should depend on the statistics of stimuli in a given task. We verify this prediction in a novel visual discrimination task with human observers, finding that each observer’s temporal bias changed as the result of changing the key stimulus statistics identified by our model. By fitting an extended drift-diffusion model to our data we rule out an alternative explanation for primacy effects due to bounded integration. Taken together, our results resolve a major discrepancy among existing perceptual decision-making studies, and suggest that a key source of bias in human decision-making is approximate hierarchical inference.</p></abstract><counts><page-count count="30"/></counts><custom-meta-wrap><custom-meta hwp:id="custom-meta-1"><meta-name>special-property</meta-name><meta-value>contains-inline-supplementary-material</meta-value></custom-meta></custom-meta-wrap><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-2">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta><notes hwp:id="notes-1"><notes notes-type="competing-interest-statement" hwp:id="notes-2"><title hwp:id="title-2">Competing Interest Statement</title><p hwp:id="p-3">The authors have declared no competing interest.</p></notes><fn-group content-type="summary-of-updates" hwp:id="fn-group-1"><title hwp:id="title-3">Summary of Updates:</title><fn fn-type="update" hwp:id="fn-1"><p hwp:id="p-4">Major revision to abstract, introduction, and order of results.</p></fn></fn-group></notes></front><body><sec id="s1" hwp:id="sec-1"><title hwp:id="title-4">Introduction</title><p hwp:id="p-5">Human decisions are known to be systematically biased, from high-level planning and reasoning to low-level perceptual decisions [<xref ref-type="bibr" rid="c65" hwp:id="xref-ref-65-1" hwp:rel-id="ref-65">65</xref>, <xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-1" hwp:rel-id="ref-42">42</xref>]. Decisions are especially difficult when they require synthesizing multiple pieces of noisy or ambiguous evidence for or against multiple alternatives [<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">13</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">6</xref>, <xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">26</xref>, <xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">18</xref>]. Perceptual decision-making studies across multiple species and sensory modalities have exposed systematic biases that differ in ways that are not well understood. Here, we focus on temporal biases, which range from over-weighting early evidence (a primacy effect) to over-weighting late evidence (a recency effect) (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1a</xref>) even in situations when an equal weighting of evidence would be optimal. Despite seemingly comparable tasks, existing studies are surprisingly heterogeneous in the biases they find: some report primacy effects [<xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">33</xref>, <xref ref-type="bibr" rid="c43" hwp:id="xref-ref-43-1" hwp:rel-id="ref-43">43</xref>, <xref ref-type="bibr" rid="c72" hwp:id="xref-ref-72-1" hwp:rel-id="ref-72">72</xref>], some find that information is weighted equally over time [<xref ref-type="bibr" rid="c76" hwp:id="xref-ref-76-1" hwp:rel-id="ref-76">76</xref>, <xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">11</xref>, <xref ref-type="bibr" rid="c54" hwp:id="xref-ref-54-1" hwp:rel-id="ref-54">54</xref>], and some find recency effects [<xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">19</xref>] without a clear pattern emerging from the data.</p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2 xref-fig-1-3 xref-fig-1-4 xref-fig-1-5 xref-fig-1-6"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;440321v5/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1:</label><caption hwp:id="caption-1"><title hwp:id="title-5">Differences in “sensory information” and “category information” can explain differences in temporal biases reported by earlier studies.</title><p hwp:id="p-6"><bold>a)</bold> A observer’s “temporal weighting strategy” is an estimate of how their choice is based on a weighted sum of each frame of evidence <italic toggle="yes">e<sub>f</sub></italic> (more precisely, a weighted sum of the log odds at each frame). Three commonly observed motifs are decreasing weights (primacy), constant weights (optimal), or increasing weights (recency). <bold>b)</bold> Information in the stimulus about the category may be decomposed into information in each frame about a sensory variable (“sensory information”) and information about the category given the sensory variable (“category information”). <bold>c)</bold> Category information and sensory information may be manipulated independently, creating a two-dimensional space of possible tasks. Any level of task performance can be the result of different combinations of sensory and category information. A qualitative placement of previous work into this space separates those that find primacy effects in the upper-left (low sensory/high category information or LSHC regime) from those that find recency effects or optimal weights in the lower right (high sensory/low category information or HSLC regime). Numbered references are: [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">1</xref>] Kiani et al. 2008, [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">2</xref>] Nienborg and Cumming 2009, [<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">3</xref>]	Brunton et al. 2013, [<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">4</xref>] Wyart et al. 2012, [<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">5</xref>] Raposo et al. 2014, [<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">6</xref>] Drugowitsch et al. 2016.</p></caption><graphic xlink:href="440321v5_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-7">Existing models propose mechanisms for either primacy [<xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-2" hwp:rel-id="ref-33">33</xref>] or recency [<xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">25</xref>] effects alone, or are flexible enough to account for either type of bias [<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-2" hwp:rel-id="ref-13">13</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-3" hwp:rel-id="ref-6">6</xref>, <xref ref-type="bibr" rid="c75" hwp:id="xref-ref-75-1" hwp:rel-id="ref-75">75</xref>, <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-1" hwp:rel-id="ref-64">64</xref>, <xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-2" hwp:rel-id="ref-11">11</xref>, <xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-2" hwp:rel-id="ref-19">19</xref>], but none identifies or predicts the factors that cause one bias or the other to appear in a given context. All of these models are based on a variant of the classic drift-diffusion model [<xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-2" hwp:rel-id="ref-26">26</xref>]. For example, Kiani et al. proposed that evidence integration stops when an internal bound is reached, even during fixed stimulus duration tasks. Averaged over many trials in which the bound is reached at different times, this leads to a primacy effect. Alternatively, a primacy effect is also expected if evidence integration is implemented by an attractor network [<xref ref-type="bibr" rid="c74" hwp:id="xref-ref-74-1" hwp:rel-id="ref-74">74</xref>, <xref ref-type="bibr" rid="c75" hwp:id="xref-ref-75-2" hwp:rel-id="ref-75">75</xref>, <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-2" hwp:rel-id="ref-64">64</xref>]. However, neither of these mechanisms can account for recency effects. On the other hand, including a “forgetting” term in the updating of the decision-variable leads to a recency effect [<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-3" hwp:rel-id="ref-13">13</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-4" hwp:rel-id="ref-6">6</xref>, <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-3" hwp:rel-id="ref-64">64</xref>, <xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-2" hwp:rel-id="ref-25">25</xref>]. The analysis by Glaze et al. shows that a recency bias is optimal in a volatile environment, but such mechanisms cannot explain primacy effects. Deneve’s normative analysis predicts that primacy and recency should depend on trial-by-trial changes in difficulty, while Prat-Ortega et al. find that primacy and recency can change as a function of the variability of the input to a attractor-based decision-circuit. However, neither account alone, or in combination, can explain the differences found across experiments. It is thus an open question whether the disparate biases observed empirically are due to differences in species, sensory modalities, training, experimental design, or individual observers.</p><p hwp:id="p-8">Here, we propose a new model that not only accounts for the existing findings in the literature, but also predicts which key aspect of the stimulus determines the specific temporal bias shown by an observer. Our model extends classic ideal observer models to the hierarchical case by explicitly including the intermediate sensory representation. This reveals that task difficulty is modulated by two distinct types of information: the information between the stimulus and sensory representation (“sensory information”), and the information between sensory representation and category (“category information”) (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Figure 1b-c</xref>). We show that approximate inference in such a model predicts characteristic temporal biases in a way that can explain prior empirical findings. Furthermore, our model makes a critical prediction: that the temporal bias of an individual observer should change from primacy to recency as the balance in the types of information is changed. We verify this critical prediction of our model using newly collected data from a novel pair of visual discrimination tasks. Finally, we perform a quantitative model comparison demonstrating that inference dynamics, not a finite integration bound, explain our observers’ biases, consistent with our theory.</p></sec><sec id="s2" hwp:id="sec-2"><title hwp:id="title-6">Results</title><sec id="s2a" hwp:id="sec-3"><title hwp:id="title-7">“Sensory Information” vs “Category Information”</title><p hwp:id="p-9">Normative models of decision-making in the brain are typically based on the idea of an ideal observer, who uses Bayes’ rule to infer the most likely category on each trial given the stimulus. On each trial in a typical task, the stimulus consists of multiple “frames” (by “frames” we refer to independent pieces of evidence that are not necessarily visual). If the stimulus or evidence in each frame, <italic toggle="yes">e<sub>f</sub></italic>, is independent, then information about the category <italic toggle="yes">C</italic> can be combined by the well-known process of summing the log odds implied by each piece of evidence [<xref ref-type="bibr" rid="c68" hwp:id="xref-ref-68-1" hwp:rel-id="ref-68">68</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-5" hwp:rel-id="ref-6">6</xref>, <xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-3" hwp:rel-id="ref-26">26</xref>]:
<disp-formula id="eqn1" hwp:id="disp-formula-1">
<alternatives hwp:id="alternatives-1"><graphic xlink:href="440321v5_eqn1.gif" position="float" orientation="portrait" hwp:id="graphic-2"/></alternatives>
</disp-formula></p><p hwp:id="p-10">The ideal observer updates their current belief about the correct category by adding the information provided by the current evidence: LPO<sub><italic toggle="yes">f</italic></sub> = LPO<sub><italic toggle="yes">f</italic>-1</sub> + LLO<sub><italic toggle="yes">f</italic></sub>.</p><p hwp:id="p-11">In the brain, however, a decision-making area cannot base its decision on the externally presented stimulus, <italic toggle="yes">e<sub>f</sub></italic>, directly, but must rely on intermediate sensory features, which we call <italic toggle="yes">x<sub>f</sub></italic> (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-3" hwp:rel-id="F1">Figure 1b</xref>). Accounting for the intervening sensory representation implies that LLO<sub><italic toggle="yes">f</italic></sub> cannot be computed directly, but only in stages. The information between the stimulus and category (<italic toggle="yes">e<sub>f</sub></italic> to <italic toggle="yes">C</italic>) is therefore partitioned into two stages: the information between the stimulus and the sensory features (<italic toggle="yes">e<sub>f</sub></italic> to <italic toggle="yes">x<sub>f</sub></italic>), and the information between sensory features and category (<italic toggle="yes">x<sub>f</sub></italic> to <italic toggle="yes">C</italic>). We call these “sensory information” and “category information,” respectively (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-4" hwp:rel-id="F1">Figure 1b</xref>). These two kinds of information define a two-dimensional space in which a given task is located as a single point (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-5" hwp:rel-id="F1">Figure 1c</xref>). For example, in a visual task, each <italic toggle="yes">e<sub>f</sub></italic> would be the image on the screen while <italic toggle="yes">x<sub>f</sub></italic> could be the instantaneous orientation or motion direction.</p><p hwp:id="p-12">An evidence integration task may be challenging either because each frame is perceptually unclear (low “sensory information”), or because the relationship between sensory features and category is ambiguous in each frame (low “category information”). Consider the classic dot motion task [<xref ref-type="bibr" rid="c41" hwp:id="xref-ref-41-1" hwp:rel-id="ref-41">41</xref>] and the Poisson clicks task [<xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-3" hwp:rel-id="ref-11">11</xref>], which occupy opposite locations in the space. In the classic low-coherence dot motion task, observers view a cloud of moving dots, a small percentage of which move “coherently” in one direction. Here, sensory information is low since the percept of net motion is weak on each frame. Category information, on the other hand, is high, since knowing the true net motion on a single frame would be highly predictive of the correct choice (and of motion on subsequent frames). In the Poisson clicks task, on the other hand, observers hear a random sequence of clicks in each ear and must report the side with the higher rate. Here, sensory information is high since each click is well above sensory thresholds. Category information, however, is low, since knowing the side on which a single click was presented provides only little information about the correct choice for the trial as a whole (and the side of the other clicks). When frames are sequential, another way to think about category information is as “temporal coherence” of the stimulus: the more each frame of evidence is predictive of the correct choice, the more the frames must be predictive of each other, whether a frame consists of visual dots or of auditory clicks. Note that our distinction between sensory and category information is different from the well-studied distinction between internal and external noise; in general, both internal and external noise will reduce the amount of sensory and category information.</p><p hwp:id="p-13">In general, sensory and category information depends on the nature of the sensory features x relative to <italic toggle="yes">e</italic> and <italic toggle="yes">C</italic>, and those relationships depend on the sensory system under consideration. For instance, a high spatial frequency grating may contain high sensory information to a primate, but low sensory information to a species with lower acuity. Similarly, when “frames” are presented quickly, they may be temporally integrated, with the effect of both reducing sensory information and increasing category information.</p><p hwp:id="p-14">Qualitatively placing prior studies in the space spanned by these two kinds of information results in two clusters: the studies that report primacy effects are located in the upper left quadrant (low-sensory/high-category or LSHC) and studies with flat weighting or recency effects are in the lower right quadrant (high-sensory/low-category or HSLC) (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-6" hwp:rel-id="F1">Figure 1c</xref>, see Supplemental Text for justifications of placements). This provides initial empirical evidence that the trade-off between sensory information and category information may underlie differences in temporal weighting seen in previous studies. Unfortunately, since our placement of prior studies is only qualitative this observation only constitutes weak evidence in favor of this hypothesis. However, this hypothesis makes the strong prediction that a simple change in the stimulus statistics corresponding to sensory and category information, while holding everything else constant, should change the temporal weighting found in these previous studies (predictions provided in Supplemental Table S1). Below we will present new data from an experiment in which we did exactly that and found that biases indeed shifted from primacy to optimal/recency as predicted.</p></sec><sec id="s2b" hwp:id="sec-4"><title hwp:id="title-8">Approximate hierarchical inference explains transition from primacy to recency</title><p hwp:id="p-15">If stimuli were processed by the brain in a purely feedforward fashion, then a decision-making area could simply integrate the evidence in sensory features (<italic toggle="yes">x<sub>f</sub></italic>) directly. This is consistent with some theories of inference in the brain in which sensory areas represent a likelihood function over stimuli [<xref ref-type="bibr" rid="c38" hwp:id="xref-ref-38-1" hwp:rel-id="ref-38">38</xref>, <xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-2" hwp:rel-id="ref-3">3</xref>, <xref ref-type="bibr" rid="c51" hwp:id="xref-ref-51-1" hwp:rel-id="ref-51">51</xref>, <xref ref-type="bibr" rid="c69" hwp:id="xref-ref-69-1" hwp:rel-id="ref-69">69</xref>]. However, activity in sensory areas does not rigidly track the stimulus, but is known to be influenced by past stimuli [<xref ref-type="bibr" rid="c77" hwp:id="xref-ref-77-1" hwp:rel-id="ref-77">77</xref>, <xref ref-type="bibr" rid="c37" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">37</xref>], as well as by feedback from the rest of the brain [<xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">24</xref>, <xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">32</xref>]. In fact, the intermediate sensory representation is itself often assumed to be the result of an inference process over latent variables in an internal model of the world [<xref ref-type="bibr" rid="c39" hwp:id="xref-ref-39-1" hwp:rel-id="ref-39">39</xref>, <xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">36</xref>, <xref ref-type="bibr" rid="c78" hwp:id="xref-ref-78-1" hwp:rel-id="ref-78">78</xref>]. This process is naturally formalized as <italic toggle="yes">hierarchical inference</italic> (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2a</xref>) in which feedforward connections communicate the likelihood and feedback communicates the prior or other contextual expectations, and sensory areas combine these to represent a posterior distribution [<xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">20</xref>, <xref ref-type="bibr" rid="c51" hwp:id="xref-ref-51-2" hwp:rel-id="ref-51">51</xref>, <xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">23</xref>, <xref ref-type="bibr" rid="c61" hwp:id="xref-ref-61-1" hwp:rel-id="ref-61">61</xref>, <xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-1" hwp:rel-id="ref-35">35</xref>].</p><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3 xref-fig-2-4 xref-fig-2-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;440321v5/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2:</label><caption hwp:id="caption-2"><title hwp:id="title-9">Information flow during hierarchical inference where categorical beliefs are fed back as a prior on sensory features.</title><p hwp:id="p-16"><bold>a)</bold> Generative model that we assume the brain has learned for a discrimination task, which specifies how sensory observations <italic toggle="yes">e<sub>f</sub></italic> depend on the category for the trial, <italic toggle="yes">C</italic>, in two stages: each sensory observation <italic toggle="yes">e<sub>f</sub></italic> is assumed to be a noisy realization of underlying sensory features, <italic toggle="yes">x<sub>f</sub></italic>, and each frame of sensory features is itself assumed to be selected according to the trial’s category. <bold>b-c)</bold> Integrating evidence about <italic toggle="yes">C</italic> requires updating the current belief about <italic toggle="yes">C</italic> with new information derived from the sensory representation (left-right “integration” and bottom-up “update” arrows). The posterior distribution over <italic toggle="yes">x</italic> combines top-down expectations (diagonal “prior” arrows) with new evidence from the stimulus, <italic toggle="yes">e<sub>f</sub></italic> (bottom-up “likelihood” arrows). Width of arrows indicates average amount of information communicated; red and blue arrows indicate changes in information flow between conditions. Note that when inference is exact, the prior is subtracted from the information in the update during the integration to prevent double-counting early evidence. While the generative model in (a) operates with discrete frames, <italic toggle="yes">f</italic>, inference in the brain happens in continuous time, <italic toggle="yes">t</italic>. <bold>b)</bold> LSHC: Low sensory information means little information in the likelihood about sensory features <italic toggle="yes">x<sub>f</sub></italic>. High category information means that most of this information is also informative about <italic toggle="yes">C</italic>. It also means high information in the prior that is fed back to the sensory representation. <bold>c)</bold> HSLC: High sensory information means high information in the likelihood about sensory features <italic toggle="yes">x<sub>f</sub></italic>. Low category information means that this information is only weakly predictive of <italic toggle="yes">C</italic>. It also means little information in the prior that is being fed back to the sensory representation.</p></caption><graphic xlink:href="440321v5_fig2" position="float" orientation="portrait" hwp:id="graphic-3"/></fig><p hwp:id="p-17">We hypothesize that feedback of “decision-related” information to sensory areas [<xref ref-type="bibr" rid="c46" hwp:id="xref-ref-46-1" hwp:rel-id="ref-46">46</xref>, <xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">16</xref>] implements a prior that reflects current beliefs about the stimulus category [<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-1" hwp:rel-id="ref-27">27</xref>, <xref ref-type="bibr" rid="c60" hwp:id="xref-ref-60-1" hwp:rel-id="ref-60">60</xref>, <xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-2" hwp:rel-id="ref-35">35</xref>]. While such a prior is optimal from the perspective of estimating the sensory features, <italic toggle="yes">x<sub>f</sub></italic>, this complicates evidence accumulation (Methods). When <italic toggle="yes">x<sub>f</sub></italic> is influenced by prior beliefs about the stimulus category, the calculation of the “update” (log likelihood odds or LLO<sub><italic toggle="yes">f</italic></sub>) cannot simply replace p(<italic toggle="yes">e<sub>f</sub></italic>|<italic toggle="yes">C</italic>) by p(<italic toggle="yes">x<sub>f</sub></italic>|<italic toggle="yes">C</italic>); instead, the decision-making area now needs to account for or “divide out” the influence of the top-down prior on the sensory representation (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2b-c</xref>). For an ideal observer performing exact inference, this process would not entail any suboptimalities or biases. However, inference in the brain is necessarily approximate, with the <italic toggle="yes">potential</italic> to induce a bias.</p><p hwp:id="p-18"><italic toggle="yes">Under</italic>-correcting for this prior would lead to earlier frames entering into the update multiple times, giving them a larger weight in the final decision. Over multiple frames, the effect is a positive feedback loop between estimates of sensory features <italic toggle="yes">x<sub>f</sub></italic> and the belief in <italic toggle="yes">C</italic>. This mechanism, which we call a “perceptual confirmation bias,” leads to primacy effects. <italic toggle="yes">Over</italic>-correcting for the prior, on the other hand, would lead to information from earlier frames decaying away, giving earlier frames less influence on the final decision and manifesting as recency effects. Importantly, in either case, the strength of any bias is directly related to the strength of the prior, which in turn is determined by the category information in the task (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Figure 2</xref>).</p><p hwp:id="p-19">We implemented two canonical models, corresponding to each of the two major classes of approximate inference schemes known from statistics and machine learning: sampling-based and variational inference [<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-2" hwp:rel-id="ref-5">5</xref>, <xref ref-type="bibr" rid="c40" hwp:id="xref-ref-40-1" hwp:rel-id="ref-40">40</xref>], and both of which have previously been proposed models for inference in the brain [<xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-2" hwp:rel-id="ref-20">20</xref>, <xref ref-type="bibr" rid="c51" hwp:id="xref-ref-51-3" hwp:rel-id="ref-51">51</xref>, <xref ref-type="bibr" rid="c55" hwp:id="xref-ref-55-1" hwp:rel-id="ref-55">55</xref>, <xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-2" hwp:rel-id="ref-23">23</xref>]. In both cases, we assumed that sensory areas of the brain approximate the posterior, incorporating both the current sensory input <italic toggle="yes">and</italic> expectations based on past frames. Interestingly, both sampling-based and variational inference models behaved similarly in terms of performance and biases, and so here only show the results from the sampling-based model, and provide the corresponding variational results in the SI. The performance of our approximate models (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure 3b</xref>) largely matched that of an exact inference model (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Figure 3a</xref>), with accuracy somewhat reduced for high category information. We computed the temporal biases of the approximate inference models for each combination of sensory information and category information, and found that both models showed a primacy effect whose magnitude decreased with the amount of category information (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Figure 3b-d</xref>). Both hierarchical inference models <italic toggle="yes">under</italic>-corrected for the influence of prior expectations on the sensory representation. Over the course of a trial, this lead to a positive feedback loop between the evidence-integration part of the model and the sensory representation, with the strength of this loop being strong in the LSHC and weak in the HSLC condition (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-4" hwp:rel-id="F2">Figure 2b-c</xref>). Importantly, this bias is a direct consequence of the <italic toggle="yes">approximate</italic> nature of the representation of the posterior distribution; for instance, in the sampling model, the bias disappears as the number of samples gets large (Methods).</p><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3 xref-fig-3-4 xref-fig-3-5 xref-fig-3-6"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;440321v5/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3:</label><caption hwp:id="caption-3"><title hwp:id="title-10">Changes in bias predicted by approximate hierarchical inference models.</title><p hwp:id="p-20"><bold>a)</bold> Performance of an ideal observer reporting <italic toggle="yes">C</italic> given ten frames of evidence. White line shows threshold performance, defined as 70% correct. The ideal observer’s temporal weights are always flat (not shown). <bold>b)</bold> Performance of our sampling-based approximate inference model with no leak (Methods). Colored dots correspond to lines in the next panel. <bold>c)</bold> Temporal weights in the model transition from flat to a strong primacy effect, all at threshold performance, as the stimulus transitions from the HSLC to the LSHC conditions. <bold>d)</bold> Visualization of how temporal biases change across the entire task space. Red corresponds to primacy, and blue to recency. White contour as in (b). Black lines are iso-contours for slopes corresponding to highlighted points in (b). <bold>e-g)</bold> Same as (b-d) but with leaky integration, which lessens primacy effects and produces recency effects when category information is low.</p></caption><graphic xlink:href="440321v5_fig3" position="float" orientation="portrait" hwp:id="graphic-4"/></fig><p hwp:id="p-21">Results for the variational and sampling-based inference models are qualitatively the same (Supplemental Figure S4), as are results from simulating a larger neurally-inspired sampling model (Supplemental Figure S8) [<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-2" hwp:rel-id="ref-27">27</xref>]. This indicates that the observed pattern of biases is not tied to a particular representation scheme – sampling or parametric – but to the <italic toggle="yes">approximate</italic> and <italic toggle="yes">hierarchical</italic> nature of inference.</p><p hwp:id="p-22">Previous studies further suggest that evidence integration in the brain may be “leaky” or “forgetful,” which can be motivated either mechanistically [<xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-3" hwp:rel-id="ref-19">19</xref>, <xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-4" hwp:rel-id="ref-13">13</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-6" hwp:rel-id="ref-6">6</xref>, <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-4" hwp:rel-id="ref-64">64</xref>], or as an adaptation to non-stationary environments in normative models [<xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-3" hwp:rel-id="ref-25">25</xref>]. Including leaky integration, our final approximate inference models contain two competing mechanisms: first, they exhibit a confirmation bias as a consequence of approximate hierarchical inference, which is strongest when category information is high, leading to a primacy effect. Second, they contain leaky integration dynamics, which dampens the primacy effect and results in recency effects when category information is low and confirmation bias dynamics are weak (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-4" hwp:rel-id="F3">Figure 3e-g</xref>). While the exact magnitude of the leak is a free parameter in our model, to be constrained by data, the <italic toggle="yes">change</italic> in bias with changes in category information is a strong prediction, i.e. changing from strong primacy to no bias, or changing from weak primacy to recency, depending on the magnitude of the leak.</p><p hwp:id="p-23">We performed additional simulations to explore the interaction between leaky integration and hierarchical inference. First, we observed that leaky integration can, surprisingly, <italic toggle="yes">improve</italic> performance, since it counteracts the confirmation bias when category information is high (Supplemental Figure S5). We further observed that optimizing the magnitude of the leak for maximum performance, separately for each combination of sensory information and category information, always resulted in flat temporal weights (Supplemental Figure S6).</p><p hwp:id="p-24">Our models make a critical prediction that is not shared by any other model: that the temporal bias of the very same observer should change from primacy to flat or recency in a task in which nothing changes apart from the balance between category and sensory information.</p></sec><sec id="s2c" hwp:id="sec-5"><title hwp:id="title-11">Changing category information in a visual discrimination task</title><p hwp:id="p-25">To test this prediction, we designed an orientation discrimination task with two stimulus conditions that correspond to the two opposite sides of this task space (LSHC and HSLC), while keeping all other aspects of the design the same (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Figure 4a-b</xref>). Importantly, in this experiment, within-observer comparisons between the two task conditions isolate relative changes in sensory information and category information. This overcomes the difficulties in directly quantifying sensory information and category information as “high” or “low” in an isolated task, which requires additional assumptions, as discussed above.</p><fig id="fig4" position="float" fig-type="figure" orientation="portrait" hwp:id="F4" hwp:rev-id="xref-fig-4-1 xref-fig-4-2 xref-fig-4-3 xref-fig-4-4 xref-fig-4-5 xref-fig-4-6"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;440321v5/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4:</label><caption hwp:id="caption-4"><title hwp:id="title-12">Two task conditions that reduce either sensory or category information to threshold level using a staircase.</title><p hwp:id="p-26"><bold>a)</bold> Each trial consisted of a 200ms start cue, followed by 10 stimulus frames presented for 83ms each, followed by a single mask frame of zero-coherence noise. After a 750ms delay, left or right targets appeared and participants pressed a button to categorize the stimulus as “left” or “right.” Stimulus contrast is amplified and spatial frequency reduced in this illustration. <bold>b)</bold> Category information is determined by the expected ratio of frames in which the orientation matches the correct category, and sensory information is determined by a parameter <italic toggle="yes">κ</italic> determining the degree of spatial orientation coherence (Methods). At the start of each block, we reset the staircase to the same point, with category information at 9 : 1 and <italic toggle="yes">κ</italic> at 0.8. We then ran a 2-to-1 staircase either on <italic toggle="yes">κ</italic> or on category information. The <italic toggle="yes">Low-Sensory-High-Category (LSHC)</italic> and <italic toggle="yes">High-Category-Low-Sensory (HSLC)</italic> ovals indicate sub-threshold trials; only these trials were used in the regression to infer observers’ temporal weights. <bold>c)</bold> Visualization of a noisy stimulus in the LSHC condition. All frames are oriented to the left. <bold>d)</bold> Psychometric curves for all observers (thin lines) and averaged (thick line) over the staircase. Shaded gray area indicates the median threshold level across all observers. <bold>e)</bold> Example frames in the HSLC condition. The orientation of each frame is clear, but orientations change from frame to frame. <bold>f)</bold> Psychometric curves over frame ratios, plotted as in (d).</p></caption><graphic xlink:href="440321v5_fig4" position="float" orientation="portrait" hwp:id="graphic-5"/></fig><p hwp:id="p-27">The stimulus in our task consisted of a sequence of ten visual frames (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-2" hwp:rel-id="F4">Figure 4a</xref>). Each frame consisted of band-pass-filtered white noise with excess orientation power either in the 45° or the +45° orientation [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-2" hwp:rel-id="ref-1">1</xref>] (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-3" hwp:rel-id="F4">Figure 4b,d</xref>). On each trial, there was a single true orientation category, but individual frames might differ in their orientation. At the end of each trial, observers reported whether the stimulus was oriented predominantly in the −45° or the +45° orientation (Methods).</p><p hwp:id="p-28">Sensory information in our task is determined by how well each image determines the orientation of that frame (i.e. the amount of “noise” in each frame), and category information is determined by the probability that any given frame’s orientation matches the trial’s category. We used signal detection theory to quantify both sensory information and category information as the area under the receiver-operating-characteristic curve for <italic toggle="yes">e<sub>f</sub></italic> and <italic toggle="yes">x<sub>f</sub></italic> (sensory information), and for <italic toggle="yes">x<sub>f</sub></italic> and <italic toggle="yes">C</italic> (category information). Hence for a ratio of 5 : 5 frames of each orientation, a frame’s orientation does not predict the correct choice and category information is 0.5. For a ratio of 10 : 0, knowledge of the orientation of a single frame is sufficient to determine the correct choice and category information is 1. Quantifying sensory information depends on individual observer’s sensory noise, but likewise ranges from 0.5 to 1 (see Supplemental Text).</p><p hwp:id="p-29">For each observer, we compared two conditions intended to probe the difference between the LSHC and HSLC regimes. Starting with a stimulus containing both high sensory and high category information, we either ran a 2:1 staircase lowering the sensory information while keeping category information high, or we ran a 2:1 staircase lowering category information while keeping sensory information high (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-4" hwp:rel-id="F4">Figure 4b</xref>). Sub-threshold trials in each condition define the LSHC and HSLC regimes, respectively (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-5" hwp:rel-id="F4">Figure 4c,e</xref>). For each condition and each observer, we used logistic regression to infer the influence of each frame onto their choice. observers’ overall performance was matched in the two conditions by setting a performance threshold below which trials were included in the analysis (Methods).</p><p hwp:id="p-30">In agreement with our hypothesis, we find predominantly flat or decreasing temporal weights in the LSHC condition (<xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Figure 5a</xref>), and when the information is partitioned differently – in the HSLC condition – we find flat or increasing weights (<xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-2" hwp:rel-id="F5">Figure 5b</xref>). To quantify this change, we first used cross-validation to select a method for quantifying temporal slopes, and found that constraining weights to be either a linear or exponential function of time worked equally well, and both outperformed logistic regression with a smoothness prior (Supplemental Figure S2d; Methods). A within-observer comparison revealed that the change in slope between the two conditions was as predicted for all observers (<xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-3" hwp:rel-id="F5">Figure 5h</xref>) (<italic toggle="yes">p</italic> &lt; 0.05 for 9 of 12 observers, bootstrap). The effect was also highly significant on a population level (<italic toggle="yes">p</italic> &lt; 0.01, sign test on median slope parameters for each observer). This demonstrates that the trade-off between sensory and category information in a task robustly changes observers’ temporal weighting strategy as we predicted.</p><fig id="fig5" position="float" fig-type="figure" orientation="portrait" hwp:id="F5" hwp:rev-id="xref-fig-5-1 xref-fig-5-2 xref-fig-5-3 xref-fig-5-4 xref-fig-5-5 xref-fig-5-6 xref-fig-5-7 xref-fig-5-8 xref-fig-5-9 xref-fig-5-10"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;440321v5/FIG5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">fig5</object-id><label>Figure 5:</label><caption hwp:id="caption-5"><title hwp:id="title-13">Every observer’s temporal bias consistently changes from primacy to unbiased/recency between conditions as predicted.</title><p hwp:id="p-31"><bold>a-b)</bold> Temporal weights from logistic regression of choices from sub-threshold frames for individual observers. Weights are regularized by a cross-validated smoothness term, and are normalized to have a mean of 1. <bold>c-d)</bold> To summarize temporal biases, we constrained weights to be an exponential function of time and re-fit them to observers’ choices. Exponential weights had higher cross-validated performance than regularized logistic regression, supporting their use to summarize temporal biases (Supplemental Figure S2d; Methods). <bold>e)</bold> The <italic toggle="yes">change</italic> in the temporal bias, quantified as the exponential slope parameter (<italic toggle="yes">β</italic>), between the two task contexts for each observer is consistently positive (combined, <italic toggle="yes">p</italic> &lt; 0.01, sign test on median slope from bootstrapping). This result is individually significant in 9 of 12 observers by bootstrapping (<italic toggle="yes">p</italic> &lt; 0.05, <italic toggle="yes">p</italic> &lt; 0.01, and <italic toggle="yes">p</italic> &lt; 0.001 indicated by *, **, and ** * respectively; non-significant observers plotted with dashed lines). Points are median slope values after bootstrap-resampling each observer’s sub-threshold trials. A slope parameter <italic toggle="yes">β</italic> &gt; 0 corresponds to a recency bias and <italic toggle="yes">β</italic> &lt; 0 to a primacy bias. We found similar results using linear rather than exponential weight functions (Supplemental Figure S3).</p></caption><graphic xlink:href="440321v5_fig5" position="float" orientation="portrait" hwp:id="graphic-6"/></fig></sec><sec id="s2d" hwp:id="sec-6"><title hwp:id="title-14">Confirmation bias, not bounded integration, explains primacy effects</title><p hwp:id="p-32">The primary alternative explanation for primacy effects in fixed-duration integration tasks proposes that observers integrate evidence to an internal <italic toggle="yes">bound</italic>, at which point they cease paying attention to the stimulus [<xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-3" hwp:rel-id="ref-33">33</xref>]. In this scenario, early evidence always enters the decision-making process while evidence late in trial is often ignored. Averaged over many trials, this results in early evidence having a larger effect on the final decision than late evidence, and hence decreasing regression weights (and psychophysical kernels) just as we found in the LSHC condition. Both models reflect very different underlying mechanism: in our approximate hierarchical inference models, a confirmation bias ensures that early evidence has a larger effect on the final decision than late evidence for every single trial. In the integration-to-bound (ITB) model, in a single trial, all evidence is weighed exactly the same before the bound is reached, and not at all afterwards.</p><p hwp:id="p-33">In order to test whether the ITB mechanism or confirmation bias dynamics better explain our data, we used an Extended ITB model that can account for both biased integration dynamics (as during a confirmation bias), and for incomplete evidence accumulation due to a finite bound [<xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">31</xref>]. This model is a simple extension to classic drift diffusion models [<xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-4" hwp:rel-id="ref-26">26</xref>]. Until it hits a bound or the trial ends, the model integrates signals as follows:
<disp-formula id="eqn2" hwp:id="disp-formula-2">
<alternatives hwp:id="alternatives-2"><graphic xlink:href="440321v5_eqn2.gif" position="float" orientation="portrait" hwp:id="graphic-7"/></alternatives>
</disp-formula>
where <italic toggle="yes">∈<sub>f</sub></italic> represents noise in the accumulation process (<xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Figure 6a</xref>, Methods). For <italic toggle="yes">α</italic> = 0, this model weighs evidence equally (optimally) over time. <italic toggle="yes">α</italic> &gt; 0 has previously been proposed to model “forgetful integration” in mechanistic models [<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-5" hwp:rel-id="ref-13">13</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-7" hwp:rel-id="ref-6">6</xref>, <xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-5" hwp:rel-id="ref-26">26</xref>, <xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-4" hwp:rel-id="ref-11">11</xref>], or as reflecting an assumption of non-stationarity in the environment in normative models [<xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-4" hwp:rel-id="ref-25">25</xref>], and leads to a recency effect. Importantly, a negative value for <italic toggle="yes">α</italic> induces “accelerating” integration dynamics, in which already-accumulated evidence is amplified, leading to primacy effects [<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-6" hwp:rel-id="ref-13">13</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-8" hwp:rel-id="ref-6">6</xref>, <xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-2" hwp:rel-id="ref-31">31</xref>].</p><fig id="fig6" position="float" fig-type="figure" orientation="portrait" hwp:id="F6" hwp:rev-id="xref-fig-6-1 xref-fig-6-2 xref-fig-6-3 xref-fig-6-4 xref-fig-6-5 xref-fig-6-6 xref-fig-6-7 xref-fig-6-8 xref-fig-6-9"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;440321v5/FIG6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">fig6</object-id><label>Figure 6:</label><caption hwp:id="caption-6"><title hwp:id="title-15">Fitting an Extended Integration-to-Bound (“Extended ITB”) model to data demonstrates that integration dynamics (negative ff for confirmation bias, positive ff for forgetting), rather than a bound, best accounts for data.</title><p hwp:id="p-34"><bold>a)</bold> Illustration of Extended ITB model. As in classic drift-diffusion models with an absorbing bound, evidence is integrated to an internal bound, after which new evidence is ignored. Compared to perfect integration (<italic toggle="yes">α</italic> = 0), a <italic toggle="yes">positive</italic> leak (<italic toggle="yes">α</italic> &gt; 0) decays information away and results in a recency bias, and a negative leak (<italic toggle="yes">α</italic> &lt; 0) amplifies already integrated information, resulting in a primacy bias. Since <italic toggle="yes">α</italic> &lt; 0 may also result in more bound crossings, both leak and bound together determine the shape of the temporal weights. <bold>b)</bold> Inferred values of the bound and leak parameters in each condition, shown as median±68% credible intervals. The classic ITB explanation of primacy effects corresponds to a non-negative leak and a small bound – illustrated here as a shaded green area. Note that the three observers near the ITB regime are points from the HSLC task – two still exhibit mild recency effects and one exhibits a mild primacy effect as predicted by ITB. <bold>c)</bold> Across both conditions, the temporal slopes (<italic toggle="yes">β</italic>) implied by the full model fits closely match the slopes in the data. <italic toggle="yes">β</italic> &lt; 0 corresponds to primacy, and <italic toggle="yes">β</italic> &gt; 0 to recency. Error bars indicate 68% confidence intervals from bootstrapping trials on <italic toggle="yes">β</italic><sub>data</sub> and from posterior samples on <italic toggle="yes">β</italic><sub>fit</sub>. <bold>d)</bold> Median temporal biases implied by the full model (middle) and by the model with either zero leak (left) or infinite bound (right). Each line corresponds to a single observer. (LSHC condition only – HSLC condition in Supplemental Figure S12). d) Across the population, the negative leak (confirmation bias) accounted for 99% (68%CI=[93%, 106%]), and bounded integration accounted for 18% (68%CI=[13%, 23%]) of the primacy bias captured by the model. (Additional analyses in Supplemental Figure S12).</p></caption><graphic xlink:href="440321v5_fig6" position="float" orientation="portrait" hwp:id="graphic-8"/></fig><p hwp:id="p-35">The Extended ITB model produces three distinct patterns in the data (colored text in <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-2" hwp:rel-id="F6">Figure 6c</xref>). First, when <italic toggle="yes">α</italic> is positive and the bound is large, it produces recency biases. Second, when the bound is small, it produces primacy biases [<xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-4" hwp:rel-id="ref-33">33</xref>], as long as <italic toggle="yes">α</italic> is also small so that it does not prevent the bound from being crossed. Third, when the bound is large and <italic toggle="yes">α</italic> is <italic toggle="yes">negative</italic>, it also produces primacy biases but now due to confirmation-bias-like dynamics rather than due to bounded integration. Crucially, this single model can account for both primacy due to a bound and primacy due to a confirmation bias by different parameter values (recovery of ground-truth mechanisms shown in Supplemental Figures S10, S11). Examining the parameters of this model fit to data therefore allows us to determine the relative contributions of bounded integration and confirmation bias dynamics in cases where observers show primacy effects.</p><p hwp:id="p-36">We fit the Extended ITB model to individual choices on sub-threshold trials, separately for the LSHC and the HSLC conditions. <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-3" hwp:rel-id="F6">Figure 6c</xref> shows the posterior mean and 68% credible interval for the dynamics parameter, ff, and bound parameter inferred for each observer. The model consistently inferred a negative <italic toggle="yes">α</italic> in the LSHC condition and a positive <italic toggle="yes">α</italic> in the HSLC condition for all observers, suggesting that confirmation-bias dynamics are crucial to explain observer’s primacy biases in the LSHC condition, as well as the change in bias from LSHC to HSLC conditions. However, while the inferred bound for every single observer is so high as not to contribute at all <italic toggle="yes">if the leak was zero</italic>, it is possible that bounded integration still contributes to primacy effects, given that a stronger confirmation bias (<italic toggle="yes">α</italic> &lt; 0) will hit a bound more often.</p><p hwp:id="p-37">We therefore performed an ablation analysis to quantify the relative contribution of the leak and bound parameters to the primacy effect in the LSHC condition (Methods). We first asked whether the inferred model parameters reproduced the observed biases. Indeed, <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-4" hwp:rel-id="F6">Figure 6b</xref> shows near-perfect agreement between the temporal biases implied by simulating choices from the fitted models and the biases inferred directly from observers’ choices. Given this, if setting the bound to 1 leaves temporal biases unchanged, then we can conclude that biases were driven by the leak, and conversely, a temporal bias that remains after setting <italic toggle="yes">α</italic> to zero must be due to the bound. <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-5" hwp:rel-id="F6">Figure 6d</xref> shows that primacy effects largely disappear when <italic toggle="yes">α</italic> is ablated, but not when the bound is ablated. To summarize ablation effects across the population, we used a hierarchical regression model to compute a population-level “ablation index” for each parameter, which is 0 if removing the parameter has no effect on temporal slopes, <italic toggle="yes">β</italic>, and is 1 if removing it destroys all temporal biases (Methods). The ablation index can therefore be interpreted as the fraction of the observers’ primacy or recency biases that are attributable to each parameter (but they do not necessarily sum to 1 because the slope is a nonlinear combination of both parameters). In the LSHC condition, the ablation index for the leak term was 0.99 (68% CI=[0.93, 1.06]), and for the bound term it was 0.18 (68% CI=[0.13, 0.23]) (<xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-6" hwp:rel-id="F6">Figure 6e</xref>). This indicates that although both mechanisms are present, primacy effects in our data are dominated by the self-reinforcing dynamics of a negative leak. Results for the HSLC condition are shown in Supplemental Figure S12.</p><p hwp:id="p-38">Interestingly, one observer exhibited a slight primacy effect in the HSLC condition, and our analyses suggest this was primarily due to bounded integration dynamics as proposed by Kiani et al (2008). This outlier observer is marked with a diamond symbol throughout <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-7" hwp:rel-id="F6">Figure 6</xref>, and is further highlighted in Supplemental Figure S12. However, even this observer’s primacy effect in the LSHC condition was driven by a confirmation bias (negative ff), and their change in slope between LSHC and HSLC conditions was in the same direction as the other observers. Importantly, finding a primacy effect due to an internal bound confirms that our model fitting procedure is able to detect such effects when they are, in fact, present. Two additional observers appear to have low bounds in the HSLC condition (<xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-8" hwp:rel-id="F6">Figure 6c</xref>), but are dominated by leaky integration (<italic toggle="yes">α</italic> &gt; 0), resulting in an overall recency bias.</p></sec></sec><sec id="s3" hwp:id="sec-7"><title hwp:id="title-16">Discussion</title><p hwp:id="p-39">Our work makes three main contributions. First, we extended ideal observer models of evidence integration tasks by explicitly accounting for the intermediate sensory representation. We showed that this partitions the information in the stimulus about the category into two parts – “sensory information” and “category information” – defining a novel two-dimensional space of possible tasks. Second, we found that two classes of biologically-plausible approximate inference algorithms en-tailed a confirmation bias whose strength strongly varied across this task space. Interestingly, the location of tasks in existing studies qualitatively predicted the bias they found across species, sensory modalities and task designs. Third, we collected new data and confirmed a critical prediction of our theory, namely that individual observers’ temporal biases should change depending on the balance of sensory information and category information in the stimulus. Finally, by fitting an extended integration to bound (Extended ITB) model to individual observer choices, we confirmed that these changes in biases are due to a change in integration dynamics rather than bounded integration.</p><p hwp:id="p-40">The “confirmation bias” emerges in our hierarchical inference models as the result of three key assumptions. Our first assumption is that inference in evidence integration tasks is in fact hierarchical, and that the brain approximates the posterior distribution over the intermediate sensory variables, <italic toggle="yes">x</italic>. This is in line with converging evidence that populations of sensory neurons encode posterior distributions of corresponding sensory variables [<xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-2" hwp:rel-id="ref-36">36</xref>, <xref ref-type="bibr" rid="c78" hwp:id="xref-ref-78-2" hwp:rel-id="ref-78">78</xref>, <xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-2" hwp:rel-id="ref-4">4</xref>, <xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-2" hwp:rel-id="ref-2">2</xref>] incorporating dynamic prior beliefs via feedback connections [<xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-3" hwp:rel-id="ref-36">36</xref>, <xref ref-type="bibr" rid="c78" hwp:id="xref-ref-78-3" hwp:rel-id="ref-78">78</xref>, <xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-3" hwp:rel-id="ref-2">2</xref>, <xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-1" hwp:rel-id="ref-45">45</xref>, <xref ref-type="bibr" rid="c60" hwp:id="xref-ref-60-2" hwp:rel-id="ref-60">60</xref>, <xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-1" hwp:rel-id="ref-47">47</xref>, <xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-3" hwp:rel-id="ref-27">27</xref>, <xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-3" hwp:rel-id="ref-35">35</xref>]. This is in contrast to other probabilistic theories in which only the likelihood is represented in sensory areas [<xref ref-type="bibr" rid="c38" hwp:id="xref-ref-38-2" hwp:rel-id="ref-38">38</xref>, <xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-3" hwp:rel-id="ref-3">3</xref>, <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-1" hwp:rel-id="ref-48">48</xref>, <xref ref-type="bibr" rid="c69" hwp:id="xref-ref-69-2" hwp:rel-id="ref-69">69</xref>], which would not predict primacy effects due to confirmation bias dynamics.</p><p hwp:id="p-41">Our second key assumption is that evidence is accumulated online. In our models, the belief over <italic toggle="yes">C</italic> is updated based only on the posterior from the previous step and the current posterior over <italic toggle="yes">x</italic>. This can be thought of as an assumption that the brain does not have a mechanism to store and retrieve earlier frames of evidence directly, and is consistent with drift-diffusion models of decision-making [<xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-6" hwp:rel-id="ref-26">26</xref>]. As mentioned in the main text, the assumptions until now – hierarchical inference with online updates – do not entail any temporal biases for an ideal observer. Further, the use of discrete time in our experiment and models is only for mathematical convenience – analogous dynamics emerge in continuous-time, and in fact we implemented our models at a finer time scale than at which evidence frames are presented.</p><p hwp:id="p-42">Third, we assumed that inference in the brain is approximate – a safe assumption due to the intractable nature of exact inference in large models. In the sampling model, we assumed that the brain can draw a limited number of independent samples of <italic toggle="yes">x</italic> per update to <italic toggle="yes">C</italic>, and found that for a finite number of samples the model is inherently unable to account for all of the prior bias of <italic toggle="yes">C</italic> on <italic toggle="yes">x</italic> in its updates to <italic toggle="yes">C</italic>. Existing neural models of sampling typically assume that samples are distributed temporally [<xref ref-type="bibr" rid="c29" hwp:id="xref-ref-29-1" hwp:rel-id="ref-29">29</xref>, <xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-3" hwp:rel-id="ref-20">20</xref>, <xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">12</xref>, <xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-2" hwp:rel-id="ref-47">47</xref>, <xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-4" hwp:rel-id="ref-27">27</xref>], but it has also been proposed that the brain could process multiple sampling “chains” distributed spatially [<xref ref-type="bibr" rid="c56" hwp:id="xref-ref-56-1" hwp:rel-id="ref-56">56</xref>]. The relevant quantity for our model is the number of independent samples that can be tallied per update: the more samples, the smaller the bias. The variational model’s representational capacity was limited by enforcing that the posterior over <italic toggle="yes">x</italic> is unimodal, and that there is no explicit representation of dependencies between <italic toggle="yes">x</italic> and <italic toggle="yes">C</italic>. Importantly, this does not imply that <italic toggle="yes">x</italic> and <italic toggle="yes">C</italic> do not influence each other. Rather, the Variational Bayes algorithm expresses these dependencies in the <italic toggle="yes">dynamics</italic> between the two areas: each update that makes <italic toggle="yes">C</italic> = +1 more likely pushes the distribution over <italic toggle="yes">x</italic> further towards +1, and vice versa. Because the number of dependencies between variables grows exponentially, such approximates are necessary in variational inference with many variables [<xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-4" hwp:rel-id="ref-20">20</xref>]. The Mean Field Variational Bayes algorithm that we use here has been previously proposed as a candidate algorithm for neural inference [<xref ref-type="bibr" rid="c53" hwp:id="xref-ref-53-1" hwp:rel-id="ref-53">53</xref>].</p><p hwp:id="p-43">The assumptions up to now predict a primacy effect but cannot account for the observed recency effects. When we incorporate a forgetting term in our models, they reproduce the observed range of biases from primacy to recency. The existence of such a forgetting term is supported by previous literature [<xref ref-type="bibr" rid="c67" hwp:id="xref-ref-67-1" hwp:rel-id="ref-67">67</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-9" hwp:rel-id="ref-6">6</xref>]. Further, it is normative in our framework in the sense that reducing the bias in the above models improves performance (Supplemental Figures S4-S6). The optimal amount of bias correction depends on the task statistics: for high category information where the confirmation bias is strongest, a stronger forgetting term is needed to correct for it. While it is conceivable that the brain would optimize this term to the task [<xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-5" hwp:rel-id="ref-11">11</xref>, <xref ref-type="bibr" rid="c50" hwp:id="xref-ref-50-1" hwp:rel-id="ref-50">50</xref>], our data suggest it is stable across our LSHC and HSLC conditions, or only adapts slowly.</p><p hwp:id="p-44">It has been proposed that post-decision feedback biases subsequent perceptual estimations [<xref ref-type="bibr" rid="c59" hwp:id="xref-ref-59-1" hwp:rel-id="ref-59">59</xref>, <xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-1" hwp:rel-id="ref-62">62</xref>]. While in spirit similar to our confirmation bias model, there are two conceptual differences between these models and our own: First, the feedback from decision area to sensory area in our model is both continuous and online, rather than conditioned on a single choice after a decision is made. Second, our models are derived from an ideal observer and only incur bias due to algorithmic approximations, while previously proposed “self-consistency” biases are not normative and require separate justification.</p><p hwp:id="p-45">Our analysis decisively shows that accelerating dynamics, rather than reaching a bound before the end of the trial, explains the primacy effect in our data. Prior work has suggested that such accelerating dynamics may arise from two attractor states corresponding to the two choices <italic toggle="yes">within</italic> a decision-area [<xref ref-type="bibr" rid="c70" hwp:id="xref-ref-70-1" hwp:rel-id="ref-70">70</xref>, <xref ref-type="bibr" rid="c74" hwp:id="xref-ref-74-2" hwp:rel-id="ref-74">74</xref>, <xref ref-type="bibr" rid="c75" hwp:id="xref-ref-75-3" hwp:rel-id="ref-75">75</xref>, <xref ref-type="bibr" rid="c71" hwp:id="xref-ref-71-1" hwp:rel-id="ref-71">71</xref>, <xref ref-type="bibr" rid="c73" hwp:id="xref-ref-73-1" hwp:rel-id="ref-73">73</xref>], and that the nature of the temporal bias depends on the volatility of the integrated signal [<xref ref-type="bibr" rid="c52" hwp:id="xref-ref-52-1" hwp:rel-id="ref-52">52</xref>]. Importantly, decision-dynamics alone <italic toggle="yes">cannot</italic> explain our results, since the input to the attractors in such models usually reflects the total information in each frame about the choice, i.e. combining both sensory and category information. In other words, attractor models usually integrate <italic toggle="yes">log odds</italic>, which we kept approximately constant between LSHC and HSLC conditions. The same argument applies to other models that do no distinguish between sensory and category information, whether based on mixing trials of different difficulty [<xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">17</xref>] or differential accumulation of consistent and inconsistent evidence [<xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-2" hwp:rel-id="ref-62">62</xref>, <xref ref-type="bibr" rid="c66" hwp:id="xref-ref-66-1" hwp:rel-id="ref-66">66</xref>, <xref ref-type="bibr" rid="c34" hwp:id="xref-ref-34-1" hwp:rel-id="ref-34">34</xref>, <xref ref-type="bibr" rid="c63" hwp:id="xref-ref-63-1" hwp:rel-id="ref-63">63</xref>].</p><p hwp:id="p-46">In contrast, in our explanation based on approximate hierarchical inference, attractor dynamics arise <italic toggle="yes">across</italic> sensory and decision areas, as the result of cortical inter-area feedback whose strength is monotonically related to category information. Holding the task difficulty (and hence the magnitude of the log odds of each frame) constant, our model nonetheless predicts stronger inter-area attractor dynamics when category information is high. Given recent evidence that noise correlations contain a task-dependent feedback component [<xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">7</xref>], we therefore predict a reduction of task-dependent noise correlations in comparable tasks with lower category information. The confirmation bias mechanism may also account for the recent finding that stronger attractor dynamics are seen in a categorization task than in a comparable estimation task [<xref ref-type="bibr" rid="c61" hwp:id="xref-ref-61-2" hwp:rel-id="ref-61">61</xref>].</p><p hwp:id="p-47">It has also been proposed that primacy effects could be the result of near-perfect integration of an adapting sensory population [<xref ref-type="bibr" rid="c73" hwp:id="xref-ref-73-2" hwp:rel-id="ref-73">73</xref>, <xref ref-type="bibr" rid="c77" hwp:id="xref-ref-77-2" hwp:rel-id="ref-77">77</xref>]. For this mechanism to explain our full results, however, the sensory population would need to become less adapted over the course of a trial in our HSLC condition, while at the same time <italic toggle="yes">more</italic> adapted in the LSHC condition. We are unaware of such an adaptation mechanism in the literature. Further, such stimulus-dependent circuit dynamics would not predict top-down neural effects such as the task-dependence of the dynamics of sensory populations [<xref ref-type="bibr" rid="c61" hwp:id="xref-ref-61-3" hwp:rel-id="ref-61">61</xref>] nor the origin and prevalence of differential correlations [<xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-2" hwp:rel-id="ref-7">7</xref>], both of which are consistent with hierarchical inference [<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-5" hwp:rel-id="ref-27">27</xref>, <xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-4" hwp:rel-id="ref-35">35</xref>].</p><p hwp:id="p-48">While our focus is on the perceptual domain in which observers integrate evidence over a timescale on the order of tens or hundreds of milliseconds, analogous computational principles hold in the cognitive domain over longer timescales. The crucial computational motif underlying our model of the confirmation bias is approximate hierarchical inference over multiple timescales. An agent in such a setting must simultaneously make accurate judgments of current data (based on the current posterior) and track long-term trends (based on all likelihoods). For instance, Zylberberg et al. (2018) identified an analogous challenge when observers must simultaneously make categorical decisions each trial (their “fast” timescale) while tracking the stationary statistics of a block of trials (their “slow” timescale), with trial-by-trial statistics analogous to the frame-by-frame statistics in our LSHC condition. As the authors describe, if observers base model updates on posteriors rather than likelihoods, they will further entrench existing beliefs [<xref ref-type="bibr" rid="c79" hwp:id="xref-ref-79-1" hwp:rel-id="ref-79">79</xref>]. However, the authors did not investigate order effects; our proposed confirmation bias models would predict that observers’ estimates of block statistics is biased towards earlier trials in the block (primacy). Schustek et al. (2018) likewise asked observers to track information across trials in a cognitive task more analogous to our HSLC condition, and report close to flat weighting of evidence across trials [<xref ref-type="bibr" rid="c57" hwp:id="xref-ref-57-1" hwp:rel-id="ref-57">57</xref>] in agreement with our model.</p><p hwp:id="p-49">The strength of the perceptual confirmation bias is directly related to the integration of internal “top-down” beliefs and external “bottom-up” evidence previously implicated in clinical dysfunctions of perception [<xref ref-type="bibr" rid="c30" hwp:id="xref-ref-30-1" hwp:rel-id="ref-30">30</xref>]. Therefore, the differential effect of sensory and category information may be useful in diagnosing clinical conditions that have been hypothesized to be related to abnormal integration of sensory information with internal expectations [<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">21</xref>].</p><p hwp:id="p-50">Hierarchical (approximate) inference on multiple timescales is a common motif across perception, cognition, and machine learning. We suspect that all of these areas will benefit from the insights on the causes of the confirmation bias mechanism that we have described here and how they depend on the statistics of the inputs in a task.</p></sec><sec id="s4" hwp:id="sec-8"><title hwp:id="title-17">Methods</title><sec id="s4a" hwp:id="sec-9"><title hwp:id="title-18">Visual Discrimination Task</title><p hwp:id="p-51">We recruited students at the University of Rochester as observers in our study. All were compensated for their time, and methods were approved by the Research observers Review Board. We found no difference between naive observers and authors, so all main-text analyses are combined, with data points belonging to authors and naive observers indicated in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-4" hwp:rel-id="F5">Figure 5d</xref>.</p><p hwp:id="p-52">Our stimulus consisted of ten frames of band-pass filtered noise [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-3" hwp:rel-id="ref-1">1</xref>, <xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-1" hwp:rel-id="ref-44">44</xref>] masked by a soft-edged annulus, leaving a “hole” in the center for a small cross on which observers fixated. The stimulus subtended 2.6 degrees of visual angle around fixation. Stimuli were presented using Matlab and Psychtoolbox on a 1920×1080px 120 Hz monitor with gamma-corrected luminance [<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">8</xref>]. Observers kept a constant viewing distance of 36 inches using a chin-rest. Each trial began with a 200ms “start” cue consisting of a black ring around the location of the upcoming stimulus. Each frame lasted 83.3ms (12 frames per second). The last frame was followed by a single double-contrast noise mask with no orientation energy. Observers then had a maximum of 1s to respond, or the trial was discarded (Supplemental Figure 4)a. The stimulus was designed to minimize the effects of small fixational eye movements: (i) small eye movements do not provide more information about either orientation, and (ii) each 83ms frame was too fast for observers to make multiple fixations on a single frame.</p><p hwp:id="p-53">The stimulus was constructed from white noise that was then masked by a kernel in the Fourier domain to include energy at a range of orientations and spatial frequencies but random phases [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-4" hwp:rel-id="ref-1">1</xref>, <xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-2" hwp:rel-id="ref-44">44</xref>, <xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-3" hwp:rel-id="ref-7">7</xref>] (a complete description and parameters can be found in the Supplemental Text). We manipulated sensory information by broadening or narrowing the distribution of orientations present in each frame, centered on either +45° or −45° depending on the chosen orientation of each frame. We manipulated category information by changing the proportion of frames that matched the orientation chosen for that trial. The range of spatial frequencies was kept constant for all observers and in all conditions.</p><p hwp:id="p-54">Trials were presented in blocks of 100, with typically 8 blocks per session (about 1 hour). Each session consisted of blocks of only HSLC or only LSHC trials (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-6" hwp:rel-id="F4">Figure 4</xref>). Observers completed between 1500 and 4400 trials in the LSHC condition, and between 1500 and 3200 trials in the HSLC condition. After each block, observers were given an optional break and the staircase was reset to <italic toggle="yes">κ</italic> = 0.8 and <italic toggle="yes">p</italic><sub>match</sub> = 0.9. <italic toggle="yes">p</italic><sub>match</sub> is defined as the probability that a single frame matched the category for a given trial. In each condition, psychometric curves were fit to the concatenation of all trials from all sessions using the Psignifit Matlab package [<xref ref-type="bibr" rid="c58" hwp:id="xref-ref-58-1" hwp:rel-id="ref-58">58</xref>], and temporal weights were fit to all trials below each observer’s threshold.</p></sec><sec id="s4b" hwp:id="sec-10"><title hwp:id="title-19">Low Sensory-, High Category-Information (LSHC) Condition</title><p hwp:id="p-55">In the LSHC condition, a continuous 2-to-1 staircase on <italic toggle="yes">κ</italic> was used to keep observers near threshold (<italic toggle="yes">κ</italic> was incremented after each incorrect response, and decremented after two correct responses in a row). <italic toggle="yes">p</italic><sub>match</sub> was fixed to 0.9. On average, observers had a threshold (defined as 70% correct) of <italic toggle="yes">κ</italic> = 0.17±0.07 (1 standard deviation). Regression of temporal weights was done on all sub-threshold trials, defined per-observer.</p></sec><sec id="s4c" hwp:id="sec-11"><title hwp:id="title-20">High Sensory-, Low Category-Information (HSLC) Condition</title><p hwp:id="p-56">In the HSLC condition, the staircase acted on <italic toggle="yes">p</italic><sub>match</sub> while keeping fixed at 0.8. Although <italic toggle="yes">p</italic><sub>match</sub> is a continuous parameter, observers always saw 10 discrete frames, hence the true ratio of frames ranged from 5:5 to 10:0 on any given trial. Observers were on average 69.5% ± 4.7% (1 standard deviation) correct when the ratio of frame types was 6:4, after adjusting for individual biases in the 5:5 case. Regression of temporal weights was done on all 6:4 and 5:5 ratio trials for all observers, regardless of the underlying <italic toggle="yes">p</italic><sub>match</sub> parameter.</p></sec><sec id="s4d" hwp:id="sec-12"><title hwp:id="title-21">Logistic Regression of Temporal Weights</title><p hwp:id="p-57">We constructed a matrix of per-frame signal strengths S on sub-threshold trials by measuring the empirical signal level in each frame. This was done by taking the dot product of the Fourier-domain energy of each frame as it was displayed on the screen (that is, including the annulus mask applied in pixel space) with a difference of Fourier-domain kernels at +45° and 45° with = 0.16. This gives a scalar value per frame that is positive when the stimulus contained more +45° energy and negative when it contained more −45° energy. Signals were z-scored before performing logistic regression, and weights were normalized to have a mean of 1 after fitting.</p><p hwp:id="p-58">Temporal weights were first fit using (regularized) logistic regression with different types of regularization. The first regularization method consisted of an AR0 (ridge) prior, and an AR2 (curvature penalty) prior. We did not use an AR1 prior to avoid any bias in the slopes, which is central to our analysis.</p><p hwp:id="p-59">To visualize regularized weights in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-5" hwp:rel-id="F5">Figure 5</xref>, the ridge and AR2 hyperparameters were chosen using 10-fold cross-validation for each observer, then averaging the optimal hyperparameters across observers for each task condition. This cross validation procedure was used only for display purposes for individual observers in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-6" hwp:rel-id="F5">Figure 5a-b</xref> of the main text, while the linear and exponential fits (described below) were used for <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-7" hwp:rel-id="F5">Figure 5c-d</xref> and statistical comparisons. Supplemental Figure S1 shows individual observers’ weights for all regression models.</p><p hwp:id="p-60">We used two methods to quantify the shape (or slope) of <bold>w</bold>: by constraining <bold>w</bold> to be either an exponential or linear function of time, but otherwise optimizing the same maximum-likelihood objective as logistic regression. Cross-validation suggests that both of these methods perform similarly to either unregularized or the regularized logistic regression defined above, with insignificant differences (Supplemental Figure S2). The exponential is defined as
<disp-formula id="eqn3" hwp:id="disp-formula-3" hwp:rev-id="xref-disp-formula-3-1 xref-disp-formula-3-2">
<alternatives hwp:id="alternatives-3"><graphic xlink:href="440321v5_eqn3.gif" position="float" orientation="portrait" hwp:id="graphic-9"/></alternatives>
</disp-formula>
where <italic toggle="yes">f</italic> refers to the frame number. <italic toggle="yes">β</italic> gives an estimate of the shape of the weights w over time, while <italic toggle="yes">α</italic> controls the overall magnitude. <italic toggle="yes">β</italic> &gt; 0 corresponds to recency and <italic toggle="yes">β</italic> &lt; 0 to primacy. The <italic toggle="yes">β</italic> parameter is reported for human observers in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-8" hwp:rel-id="F5">Figure 5d</xref>, and for the models in <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-5" hwp:rel-id="F3">Figure 3e,h</xref>.</p><p hwp:id="p-61">The second method to quantify slope was to constrain the weights to be a linear function in time:
<disp-formula id="eqn4" hwp:id="disp-formula-4">
<alternatives hwp:id="alternatives-4"><graphic xlink:href="440321v5_eqn4.gif" position="float" orientation="portrait" hwp:id="graphic-10"/></alternatives>
</disp-formula>
where <italic toggle="yes">slope</italic> &gt; 0 corresponds to recency and <italic toggle="yes">slope</italic> &lt; 0 to primacy.</p><p hwp:id="p-62"><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-9" hwp:rel-id="F5">Figure 5d</xref> shows the median exponential shape parameter (<italic toggle="yes">β</italic>) after bootstrapped resampling of trials 500 times for each observer. Both the exponential and linear weights give comparable results (Supplemental Figure S3).</p><p hwp:id="p-63">Because we are not explicitly interested in the magnitude of <bold>w</bold> but rather its <italic toggle="yes">shape</italic> over stimulus frames, we always plot a “normalized” weight, <bold>w</bold>/mean(<bold>w</bold>), both for our experimental results (<xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-10" hwp:rel-id="F5">Figure 5a-d</xref>) and for the model (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-6" hwp:rel-id="F3">Figure 3c, f</xref>).</p></sec><sec id="s4e" hwp:id="sec-13"><title hwp:id="title-22">Approximate inference models</title><p hwp:id="p-64">We model evidence integration as Bayesian inference in a three-variable generative model (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-5" hwp:rel-id="F2">Figure 2a</xref>) that distills the key features of online evidence integration in a hierarchical model [<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-6" hwp:rel-id="ref-27">27</xref>]. The variables in the model are mapped onto the sensory periphery (<italic toggle="yes">e</italic>), sensory cortex (<italic toggle="yes">x</italic>), and a decision-making area (<italic toggle="yes">C</italic>) in the brain. For simulations, the same model was used both to generate data (<italic toggle="yes">C</italic> → <italic toggle="yes">x<sub>f</sub></italic> → <italic toggle="yes">e<sub>f</sub></italic>), and, in the reverse direction, as a model of inference dynamics (<italic toggle="yes">e<sub>f</sub></italic> → p(<italic toggle="yes">x<sub>f</sub></italic> | …) ↔ p(<italic toggle="yes">C</italic>| …)).</p><p hwp:id="p-65">In the generative direction, on each trial, the binary value of the correct choice <italic toggle="yes">C</italic> ∈ {−1, +1} is drawn from a 50/50 prior. <italic toggle="yes">x<sub>f</sub></italic> is then drawn from a mixture of two Gaussians:
<disp-formula id="eqn5" hwp:id="disp-formula-5" hwp:rev-id="xref-disp-formula-5-1">
<alternatives hwp:id="alternatives-5"><graphic xlink:href="440321v5_eqn5.gif" position="float" orientation="portrait" hwp:id="graphic-11"/></alternatives>
</disp-formula></p><p hwp:id="p-66">Finally, each <italic toggle="yes">e<sub>f</sub></italic> is drawn from a Gaussian around <italic toggle="yes">x<sub>f</sub></italic>:
<disp-formula id="eqn6" hwp:id="disp-formula-6">
<alternatives hwp:id="alternatives-6"><graphic xlink:href="440321v5_eqn6.gif" position="float" orientation="portrait" hwp:id="graphic-12"/></alternatives>
</disp-formula></p><p hwp:id="p-67">In the inference direction, we assume that the observer has learned the correct model parameters (namely the category information, and sensory information or <inline-formula hwp:id="inline-formula-1"><alternatives hwp:id="alternatives-7"><inline-graphic xlink:href="440321v5_inline1.gif" hwp:id="inline-graphic-1"/></alternatives></inline-formula>), even as parameters change between the two different conditions. This is why we ran our observers in blocks of only LSHC or HSLC trials on a given day.</p><p hwp:id="p-68">Category information in this model can be quantified by the probability that <inline-formula hwp:id="inline-formula-2"><alternatives hwp:id="alternatives-8"><inline-graphic xlink:href="440321v5_inline2.gif" hwp:id="inline-graphic-2"/></alternatives></inline-formula> is drawn from the mode that matches <italic toggle="yes">C</italic>, as in <xref rid="eqn5" ref-type="disp-formula" hwp:id="xref-disp-formula-5-1" hwp:rel-id="disp-formula-5">equation (5)</xref>. We quantify sensory information as the probability with which an ideal observer can recover the sign of <italic toggle="yes">x<sub>f</sub></italic> from a single <italic toggle="yes">e<sub>f</sub></italic>. That is, in our model sensory information is equivalent to the area under the ROC curve for two univariate Gaussian distributions separated by a distance of 2, which is given by
<disp-formula id="eqn7" hwp:id="disp-formula-7">
<alternatives hwp:id="alternatives-9"><graphic xlink:href="440321v5_eqn7.gif" position="float" orientation="portrait" hwp:id="graphic-13"/></alternatives>
</disp-formula>
where ϕ is the inverse cumulative normal distribution.</p><p hwp:id="p-69">Optimal inference of <italic toggle="yes">C</italic> requires conditioning on all frames of evidence <italic toggle="yes">e</italic><sub>1</sub>,…, <italic toggle="yes">e<sub>f</sub></italic>, which can be expressed as the Log Posterior Odds (LPO),
<disp-formula id="eqn8" hwp:id="disp-formula-8">
<alternatives hwp:id="alternatives-10"><graphic xlink:href="440321v5_eqn8.gif" position="float" orientation="portrait" hwp:id="graphic-14"/></alternatives>
</disp-formula>
where LLO<sub><italic toggle="yes">f</italic></sub> is the log likelihood odds for frame <italic toggle="yes">f</italic> [<xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-7" hwp:rel-id="ref-26">26</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-10" hwp:rel-id="ref-6">6</xref>]. To reflect the fact that the brain has access to only one frame of evidence at a time, this can be rewritten this as an <italic toggle="yes">online</italic> update rule, summing the previous frame’s log posterior with new evidence gleaned on the current frame:
<disp-formula id="eqn9" hwp:id="disp-formula-9" hwp:rev-id="xref-disp-formula-9-1">
<alternatives hwp:id="alternatives-11"><graphic xlink:href="440321v5_eqn9.gif" position="float" orientation="portrait" hwp:id="graphic-15"/></alternatives>
</disp-formula></p><p hwp:id="p-70">Optimal inference of <italic toggle="yes">x<sub>f</sub></italic> similarly requires accounting for all possible sources of information. Ideally, sensory areas should incorporate prior information based on previous frames to compute p(<italic toggle="yes">x<sub>f</sub></italic> |<italic toggle="yes">e</italic><sub>1</sub>,…, <italic toggle="yes">e<sub>f</sub></italic>). Using p<sub><italic toggle="yes">f</italic>-1</sub>(<italic toggle="yes">C</italic> = <italic toggle="yes">C</italic>) = p(<italic toggle="yes">C</italic> = <italic toggle="yes">c</italic>|<italic toggle="yes">e</italic><sub>1</sub>,…, <italic toggle="yes">e</italic><sub><italic toggle="yes">f</italic>-1</sub>) to denote the brain’s belief that the category is <italic toggle="yes">C</italic> = <italic toggle="yes">c</italic> after the first <italic toggle="yes">f</italic> − 1 frames, the posterior over <italic toggle="yes">x<sub>f</sub></italic> given all frames, p(<italic toggle="yes">x<sub>f</sub></italic>|<italic toggle="yes">e</italic><sub>1</sub>,…, <italic toggle="yes">e<sub>f</sub></italic>), can be written as
<disp-formula id="eqn10" hwp:id="disp-formula-10">
<alternatives hwp:id="alternatives-12"><graphic xlink:href="440321v5_eqn10.gif" position="float" orientation="portrait" hwp:id="graphic-16"/></alternatives>
</disp-formula></p><p hwp:id="p-71">The term p<sub><italic toggle="yes">f</italic></sub> (<italic toggle="yes">x<sub>f</sub></italic>) is a prior on sensory features <italic toggle="yes">x<sub>f</sub></italic> that changes over time depending on the current belief in the category, p<sub><italic toggle="yes">f</italic>-1</sub>(<italic toggle="yes">C</italic>). In other words, sensory areas could dynamically combine instantaneous evidence (p(<italic toggle="yes">e<sub>f</sub></italic>|<italic toggle="yes">x<sub>f</sub></italic>)) with accumulated categorical beliefs (p<sub><italic toggle="yes">f</italic>-1</sub>(<italic toggle="yes">C</italic>)) to arrive at a more precise estimate of present sensory features <italic toggle="yes">x<sub>f</sub></italic>. This is what we mean by feedback of “decision-related information” or of “categorical beliefs.”</p><p hwp:id="p-72">Our approximate inference models, described in detail below, compute a biased estimate of LLO<sub><italic toggle="yes">f</italic></sub>, which we call <inline-formula hwp:id="inline-formula-3"><alternatives hwp:id="alternatives-13"><inline-graphic xlink:href="440321v5_inline3.gif" hwp:id="inline-graphic-3"/></alternatives></inline-formula>. The bias is due to the interaction of approximations with feedback of prior beliefs, such that <inline-formula hwp:id="inline-formula-4"><alternatives hwp:id="alternatives-14"><inline-graphic xlink:href="440321v5_inline4.gif" hwp:id="inline-graphic-4"/></alternatives></inline-formula> is biased towards LPO<sub><italic toggle="yes">f</italic>-1</sub>, resulting in a confirmation bias. Importantly, this bias arises naturally in both the sampling-based and variational approximate inference algorithms that we study here, as a direct consequence the <italic toggle="yes">approximate</italic> nature of the posterior. Given the approximate representation of posteriors over <italic toggle="yes">x<sub>f</sub></italic>, there is no way to exactly divide out the influence of the prior and recover the exact log likelihood odds on a frame-by-frame basis. However, the confirmation bias can be mitigated on average simply by incorporating a leak term, <italic toggle="yes">γ</italic>, in the integration process [<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-7" hwp:rel-id="ref-13">13</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-11" hwp:rel-id="ref-6">6</xref>]:
<disp-formula id="eqn11" hwp:id="disp-formula-11" hwp:rev-id="xref-disp-formula-11-1 xref-disp-formula-11-2">
<alternatives hwp:id="alternatives-15"><graphic xlink:href="440321v5_eqn11.gif" position="float" orientation="portrait" hwp:id="graphic-17"/></alternatives>
</disp-formula></p><p hwp:id="p-73">Due to the bias in <inline-formula hwp:id="inline-formula-5"><alternatives hwp:id="alternatives-16"><inline-graphic xlink:href="440321v5_inline5.gif" hwp:id="inline-graphic-5"/></alternatives></inline-formula>, <italic toggle="yes">γ</italic> can be seen as a kind of approximate <italic toggle="yes">bias correction</italic>, with positive values for <italic toggle="yes">γ</italic> often improving performance (Supplemental Figure S5–S6). Equivalently, one can view the quantity <inline-formula hwp:id="inline-formula-6"><alternatives hwp:id="alternatives-17"><inline-graphic xlink:href="440321v5_inline6.gif" hwp:id="inline-graphic-6"/></alternatives></inline-formula> as a less biased estimate of the true log likelihood odds.</p><p hwp:id="p-74">Because the effective time per update in the brain is likely faster than our 83ms stimulus frames, we included an additional parameter <italic toggle="yes">n</italic><sub>U</sub> for the number of online belief updates per stimulus frame. In the sampling model described below, we amortize the per-frame updates over <italic toggle="yes">n</italic><sub>U</sub> steps, updating <italic toggle="yes">n</italic><sub>U</sub> times per frame using <inline-formula hwp:id="inline-formula-7"><alternatives hwp:id="alternatives-18"><inline-graphic xlink:href="440321v5_inline7.gif" hwp:id="inline-graphic-7"/></alternatives></inline-formula>. In the variational model, we interpret <italic toggle="yes">n</italic><sub>U</sub> as the number of coordinate ascent steps per stimulus frame.</p><p hwp:id="p-75">Simulations of both models were done with 10000 trials per task type and 10 frames per trial. To quantify the evidence-weighting of each model, we used the same logistic regression procedure that was used to analyze human observers’ behavior. In particular, temporal weights in the model are best described by the exponential weights (<xref rid="eqn3" ref-type="disp-formula" hwp:id="xref-disp-formula-3-1" hwp:rel-id="disp-formula-3">equation (3)</xref>), so we use <italic toggle="yes">β</italic> to characterize the model’s biases.</p></sec><sec id="s4f" hwp:id="sec-14"><title hwp:id="title-23">Sampling model</title><p hwp:id="p-76">The sampling model estimates p(<italic toggle="yes">e<sub>f</sub></italic>|<italic toggle="yes">C</italic>) using importance sampling of <italic toggle="yes">x</italic>, where each sample is drawn from a pseudo-posterior using the current running estimate of <italic toggle="yes">p</italic><sub><italic toggle="yes">f</italic>-1</sub>(<italic toggle="yes">C</italic>) ≡ <italic toggle="yes">p</italic>(<italic toggle="yes">C</italic>|<italic toggle="yes">e</italic><sub>1</sub>, .., <italic toggle="yes">e</italic><sub><italic toggle="yes">f</italic>-1</sub>) as a marginal prior:
<disp-formula id="eqn12" hwp:id="disp-formula-12">
<alternatives hwp:id="alternatives-19"><graphic xlink:href="440321v5_eqn12.gif" position="float" orientation="portrait" hwp:id="graphic-18"/></alternatives>
</disp-formula></p><p hwp:id="p-77">Using this distribution, we obtain the following unnormalized importance weights.
<disp-formula id="eqn13" hwp:id="disp-formula-13">
<alternatives hwp:id="alternatives-20"><graphic xlink:href="440321v5_eqn13.gif" position="float" orientation="portrait" hwp:id="graphic-19"/></alternatives>
</disp-formula></p><p hwp:id="p-78">In the self-normalized importance sampling algorithm these weights are then normalized as follows,
<disp-formula id="ueqn1" hwp:id="disp-formula-14">
<alternatives hwp:id="alternatives-21"><graphic xlink:href="440321v5_ueqn1.gif" position="float" orientation="portrait" hwp:id="graphic-20"/></alternatives>
</disp-formula>
though we found that this had no qualitative effect on the model’s ability to reproduce the trends in the data. The above equations yield the following estimate for the log-likelihood ratio needed for the belief update rule in <xref rid="eqn11" ref-type="disp-formula" hwp:id="xref-disp-formula-11-1" hwp:rel-id="disp-formula-11">equation (11)</xref>:
<disp-formula id="eqn14" hwp:id="disp-formula-15">
<alternatives hwp:id="alternatives-22"><graphic xlink:href="440321v5_eqn14.gif" position="float" orientation="portrait" hwp:id="graphic-21"/></alternatives>
</disp-formula></p><p hwp:id="p-79">In the case of infinitely many samples, these importance weights exactly counteract the bias introduced by sampling from the posterior rather than likelihood, thereby avoiding any double-counting of the prior, and hence, any confirmation bias [<xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-1" hwp:rel-id="ref-49">49</xref>]. However, in the case of finite samples, <italic toggle="yes">S</italic>, biased estimates of LLO<sub>f</sub> are unavoidable [<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">15</xref>].</p><p hwp:id="p-80">The full sampling model is given in Supplemental Algorithm S1. Simulations in the main text were done with <italic toggle="yes">S</italic> = 5, <italic toggle="yes">n</italic><sub>U</sub> = 5, normalized importance weights, and <italic toggle="yes">γ</italic> = 0 or <italic toggle="yes">γ</italic> = 0.1.</p></sec><sec id="s4g" hwp:id="sec-15"><title hwp:id="title-24">Variational model</title><p hwp:id="p-81">The following variational model produces qualitatively similar patterns of temporal biases to the IS model (Supplemental Figure S4).</p><p hwp:id="p-82">The core assumption of the variational model is that while a decision area approximates the posterior over <italic toggle="yes">C</italic> and a sensory area approximates the posterior over <italic toggle="yes">x</italic>, no brain area explicitly represents posterior dependencies between them. That is, we assume the brain employs a <italic toggle="yes">mean field approximation</italic> to the joint posterior by factorizing p(<italic toggle="yes">C</italic>, <italic toggle="yes">x</italic><sub>1</sub>,…, <italic toggle="yes">x<sub>F</sub></italic>|<italic toggle="yes">e</italic><sub>1</sub>,…, <italic toggle="yes">e<sub>F</sub></italic>) into a product of approximate marginal distributions <inline-formula hwp:id="inline-formula-8"><alternatives hwp:id="alternatives-23"><inline-graphic xlink:href="440321v5_inline8.gif" hwp:id="inline-graphic-8"/></alternatives></inline-formula> and minimizes the Kullback-Leibler diver-gence between q and p using a process that can be modeled by the Mean-Field Variational Bayes algorithm [<xref ref-type="bibr" rid="c40" hwp:id="xref-ref-40-2" hwp:rel-id="ref-40">40</xref>].</p><p hwp:id="p-83">By restricting the updates to be online (one frame at a time, in order), this model can be seen as an instance of “Streaming Variational Bayes” [<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">9</xref>]. That is, the model computes a sequence of approximate posteriors over <italic toggle="yes">C</italic> using the same update rule for each frame. We thus only need to derive the update rules for a single frame and a given prior over <italic toggle="yes">C</italic>; this is extended to multiple frames by re-using the posterior from frame <italic toggle="yes">f</italic> - 1 as the prior on frame <italic toggle="yes">f</italic>.</p><p hwp:id="p-84">As in the sampling model, this model is unable to completely discount the added prior over <italic toggle="yes">x</italic>. Intuitively, since the mean-field assumption removes explicit correlations between <italic toggle="yes">x</italic> and <italic toggle="yes">C</italic>, the model is forced to commit to a marginal posterior in favor of <italic toggle="yes">C</italic> = +1 or <italic toggle="yes">C</italic> = −1 and <italic toggle="yes">x</italic> &gt; 0 or <italic toggle="yes">x</italic> &lt; 0 after each update, which then biases subsequent judgments of each.</p><p hwp:id="p-85">To keep conditional distributions in the exponential family (which is only a matter of mathematical convenience and has no effect on the ideal observer), we introduce an auxiliary variable <italic toggle="yes">z<sub>f</sub></italic> ∈ {−1, +1} that selects which of the two modes <italic toggle="yes">x<sub>f</sub></italic> is in:
<disp-formula id="eqn15" hwp:id="disp-formula-16">
<alternatives hwp:id="alternatives-24"><graphic xlink:href="440321v5_eqn15.gif" position="float" orientation="portrait" hwp:id="graphic-22"/></alternatives>
</disp-formula>
such that
<disp-formula id="eqn16" hwp:id="disp-formula-17">
<alternatives hwp:id="alternatives-25"><graphic xlink:href="440321v5_eqn16.gif" position="float" orientation="portrait" hwp:id="graphic-23"/></alternatives>
</disp-formula>
We then optimize <inline-formula hwp:id="inline-formula-9"><alternatives hwp:id="alternatives-26"><inline-graphic xlink:href="440321v5_inline9.gif" hwp:id="inline-graphic-9"/></alternatives></inline-formula>.</p><p hwp:id="p-86">Mean-Field Variational Bayes is a coordinate ascent algorithm on the parameters of each approximate marginal distribution. To derive the update equations for each step, we begin with the following [<xref ref-type="bibr" rid="c40" hwp:id="xref-ref-40-3" hwp:rel-id="ref-40">40</xref>]:
<disp-formula id="eqn17" hwp:id="disp-formula-18">
<alternatives hwp:id="alternatives-27"><graphic xlink:href="440321v5_eqn17.gif" position="float" orientation="portrait" hwp:id="graphic-24"/></alternatives>
</disp-formula>
After simplifying, the new q(<italic toggle="yes">x<sub>f</sub></italic>) term is a Gaussian with mean given by <xref rid="eqn18" ref-type="disp-formula" hwp:id="xref-disp-formula-19-1" hwp:rel-id="disp-formula-19">equation (18)</xref> and constant variance
<disp-formula id="eqn18" hwp:id="disp-formula-19" hwp:rev-id="xref-disp-formula-19-1">
<alternatives hwp:id="alternatives-28"><graphic xlink:href="440321v5_eqn18.gif" position="float" orientation="portrait" hwp:id="graphic-25"/></alternatives>
</disp-formula>
where μ<sub>C</sub> and μ<sub>z</sub> are the means of the current estimates of q(C) and q(z).</p><p hwp:id="p-87">For the update to q(<italic toggle="yes">z<sub>f</sub></italic>) in terms of log odds of <italic toggle="yes">z<sub>f</sub></italic> we obtain:
<disp-formula id="eqn19" hwp:id="disp-formula-20">
<alternatives hwp:id="alternatives-29"><graphic xlink:href="440321v5_eqn19.gif" position="float" orientation="portrait" hwp:id="graphic-26"/></alternatives>
</disp-formula></p><p hwp:id="p-88">Similarly, the update to q(C) is given by:
<disp-formula id="eqn20" hwp:id="disp-formula-21" hwp:rev-id="xref-disp-formula-21-1 xref-disp-formula-21-2">
<alternatives hwp:id="alternatives-30"><graphic xlink:href="440321v5_eqn20.gif" position="float" orientation="portrait" hwp:id="graphic-27"/></alternatives>
</disp-formula>
Note that the first term in <xref rid="eqn20" ref-type="disp-formula" hwp:id="xref-disp-formula-21-1" hwp:rel-id="disp-formula-21">equation (20)</xref> – the log prior – will be replaced with the log posterior estimate from the previous frame (see Supplemental Algorithm S2). Comparing <xref rid="eqn20" ref-type="disp-formula" hwp:id="xref-disp-formula-21-2" hwp:rel-id="disp-formula-21">equations (20)</xref> and <xref rid="eqn9" ref-type="disp-formula" hwp:id="xref-disp-formula-9-1" hwp:rel-id="disp-formula-9">(9)</xref>, we see that in the variational model, the log likelihood odds estimate is given by
<disp-formula id="eqn21" hwp:id="disp-formula-22" hwp:rev-id="xref-disp-formula-22-1">
<alternatives hwp:id="alternatives-31"><graphic xlink:href="440321v5_eqn21.gif" position="float" orientation="portrait" hwp:id="graphic-28"/></alternatives>
</disp-formula></p><p hwp:id="p-89">Analogously to the sampling model we assume a number of updates <italic toggle="yes">n<sub>U</sub></italic> reflecting the speed of relevant computations in the brain relative to how quickly stimulus frames are presented. Unlike for the sampling model, naively amortizing the updates implied by <xref rid="eqn21" ref-type="disp-formula" hwp:id="xref-disp-formula-22-1" hwp:rel-id="disp-formula-22">equation (21)</xref> <italic toggle="yes">n<sub>U</sub></italic> times results in a stronger primacy effect than observed in the data, since the Variational Bayes algorithm naturally has attractor dynamics built in. Allowing for an additional parameter η scaling this update (corresponding to the step size in Stochastic Variational Inference [<xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">28</xref>]) seems biologically plausible because it simply corresponds to a coupling strength in the feed-forward direction. Decreasing η both reduces the primacy effect and improves the model’s performance. Here we used η = 0.05 in all simulations based on a qualitative match with the data. The full variational model is given in Algorithm S2.</p></sec><sec id="s4h" hwp:id="sec-16"><title hwp:id="title-25">Fitting the Extended ITB model to data</title><p hwp:id="p-90">To explore alternatives, we implemented an Integration to Bound (ITB) model in our simplified 3-variable hierarchical task model, <italic toggle="yes">C</italic> → <italic toggle="yes">x<sub>f</sub></italic> → <italic toggle="yes">e<sub>f</sub></italic>. The dynamics of the integrator model were nearly identical to <xref rid="eqn11" ref-type="disp-formula" hwp:id="xref-disp-formula-11-2" hwp:rel-id="disp-formula-11">equation (11)</xref>, using the exact log likelihood odds, but with added noise:
<disp-formula id="eqn22" hwp:id="disp-formula-23">
<alternatives hwp:id="alternatives-32"><graphic xlink:href="440321v5_eqn22.gif" position="float" orientation="portrait" hwp:id="graphic-29"/></alternatives>
</disp-formula>
where <italic toggle="yes">ϵ</italic> is zero-mean Gaussian noise with variance <inline-formula hwp:id="inline-formula-10"><alternatives hwp:id="alternatives-33"><inline-graphic xlink:href="440321v5_inline10.gif" hwp:id="inline-graphic-10"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="c74" hwp:id="xref-ref-74-3" hwp:rel-id="ref-74">74</xref>, <xref ref-type="bibr" rid="c67" hwp:id="xref-ref-67-2" hwp:rel-id="ref-67">67</xref>, <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-12" hwp:rel-id="ref-6">6</xref>, <xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-6" hwp:rel-id="ref-11">11</xref>, <xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-4" hwp:rel-id="ref-19">19</xref>]. Although <italic toggle="yes">α</italic> plays a similar role to <italic toggle="yes">γ</italic> from the hierarchical inference models (both <italic toggle="yes">α</italic> and <italic toggle="yes">γ</italic> are referred to as “leak” parameters), we distinguish between them to avoid confusion. Whereas <italic toggle="yes">α</italic> &lt; 0 produces confirmation-bias dynamics in the Extended ITB model, in the hierarchical inference models a confirmation bias occurs when <italic toggle="yes">γ</italic> is small but positive and category information is high (that is, the confirmation bias in hierarchical inference is due to biased estimation of <inline-formula hwp:id="inline-formula-11"><alternatives hwp:id="alternatives-34"><inline-graphic xlink:href="440321v5_inline11.gif" hwp:id="inline-graphic-11"/></alternatives></inline-formula> rather than to <italic toggle="yes">γ</italic>). In the Extended ITB model, whenever LPO<sub><italic toggle="yes">f</italic></sub> crosses the bound at ±<italic toggle="yes">B</italic>, it “sticks” to that bound for the rest of the trial regardless of further evidence. Note that in the unbounded case noise does not affect the shape of the temporal weights (only their magnitude), but noise interacts with the bound to determine the shape as well as overall performance. Supplemental Figure S7 shows the performance and temporal biases of the ITB model for a range of parameter values.</p><p hwp:id="p-91">Per observer per condition, we used Metropolis Hastings (MH) to infer the joint posterior over seven parameters: the category prior (<italic toggle="yes">p<sub>C</sub></italic>), lapse rate (<italic toggle="yes">λ</italic>), decision temperature (<italic toggle="yes">T</italic>), integration noise (<italic toggle="yes">ϵ</italic>), bound (<italic toggle="yes">B</italic>), leak (<italic toggle="yes">α</italic>), and evidence scale (<italic toggle="yes">s</italic>). One challenge for fitting models is that the mapping from signal in the images (<bold>S</bold>) to “log odds” to be integrated (LLO) depends on category information, sensory information, and on unknown properties of each observer’s visual system. The evidence scale parameter, <italic toggle="yes">s</italic>, was introduced because although we can estimate the ground truth category information in each task (0.6 for HSLC and 0.9 for LSHC), the <italic toggle="yes">effective</italic> sensory information depends on each observer’s visual system and will differ between the two tasks. Using logistic regression, we explored plausible nonlinear monotonic mappings between signals <bold>S</bold> and log-odds, but found that none performed better than linear scaling when applied to sub-threshold trials. We therefore used LLO ≈ <italic toggle="yes">g</italic>(<bold>S</bold>/<italic toggle="yes">s</italic>), where <italic toggle="yes">g</italic> is a sigmoidal function that accounts for category information being less than 1, and inferred <italic toggle="yes">s</italic> jointly along with other parameters of the model. The scale s was fixed to 1 when fitting the ground-truth models, as the mapping between evidence and log odds is completely known in those cases.</p><p hwp:id="p-92">Each trial, the Extended ITB model followed the noisy integration dynamics in (22), where <inline-formula hwp:id="inline-formula-12"><alternatives hwp:id="alternatives-35"><inline-graphic xlink:href="440321v5_inline12.gif" hwp:id="inline-graphic-12"/></alternatives></inline-formula> and LLO<sub><italic toggle="yes">f</italic></sub> was computed exactly, as described above. After integration, the decision then incorporated a symmetric lapse rate and temperature:
<disp-formula id="ueqn2" hwp:id="disp-formula-24">
<alternatives hwp:id="alternatives-36"><graphic xlink:href="440321v5_ueqn2.gif" position="float" orientation="portrait" hwp:id="graphic-30"/></alternatives>
</disp-formula>
where σ(<italic toggle="yes">a</italic>) is the sigmoid function, σ(<italic toggle="yes">a</italic>) ≡ (1 + exp(−<italic toggle="yes">a</italic>))<sup>−1</sup>. Note that if the bound is hit, then LPO<sub><italic toggle="yes">F</italic></sub> = ±<italic toggle="yes">B</italic>, but the temperature and lapse still apply. To compute the log likelihood for each set of parameters, we numerically marginalized over the noise, <italic toggle="yes">ϵ</italic>, by discretizing LPO into bins of width at most 0.01 between −<italic toggle="yes">B</italic> and +<italic toggle="yes">B</italic> (clipped at 3 times the largest LPO reached by the ideal observer) and computing the <italic toggle="yes">probability mass</italic> of LPO<sub><italic toggle="yes">f</italic></sub> given LPO<sub><italic toggle="yes">f</italic>-1</sub>, LLO<sub><italic toggle="yes">f</italic></sub>, and <italic toggle="yes">ϵ</italic>. This enabled exact rather than stochastic likelihood evaluations within MH.</p><p hwp:id="p-93">The priors over each parameter were set as follows. p(<italic toggle="yes">p<sub>C</sub></italic>) was set to Beta(2, 2). p(λ) was set to Beta(1, 10). p(<italic toggle="yes">α</italic>) was uniform in [−1, 1]. p(<italic toggle="yes">s</italic>) was set to an exponential distribution with mean 20. p(<italic toggle="yes">ϵ</italic>) was set to an exponential distribution with mean 0.25. p(<italic toggle="yes">T</italic>) was set to an exponential distribution with mean 4. p(<italic toggle="yes">B</italic>) was set to a Gamma distribution with (shape,scale) parameters (2, 3) (mean 6). MH proposal distributions were chosen to minimize the autocorrelation time when sampling each parameter in isolation.</p><p hwp:id="p-94">We ran 12 MCMC chains per observer per condition. The initial point for each chain was selected as the best point among 500 quasi-random samples from the prior. Chains were run for variable durations based on available shared computing resources. Each was initially run for 4 days; all chains were then extended for each model that had not yet converged according to the Gelman-Rubin statistic, <inline-formula hwp:id="inline-formula-13"><alternatives hwp:id="alternatives-37"><inline-graphic xlink:href="440321v5_inline13.gif" hwp:id="inline-graphic-13"/></alternatives></inline-formula> [<xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">22</xref>, <xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">10</xref>]. We discarded burn-in samples separately per chain post-hoc, defining burn-in as the time until the first sample surpassed the median posterior probability for that chain (maximum 20%, median 0.46%, minimum 0.1% of the chain length for all chains). After discarding burn-in, all chains had a minimum of 81k, median 334k, and maximum 999k samples. Standard practice suggests that <inline-formula hwp:id="inline-formula-14"><alternatives hwp:id="alternatives-38"><inline-graphic xlink:href="440321v5_inline14.gif" hwp:id="inline-graphic-14"/></alternatives></inline-formula> indicates good enough convergence. The slowest-mixing parameter was the signal scale (<italic toggle="yes">s</italic>), with <inline-formula hwp:id="inline-formula-15"><alternatives hwp:id="alternatives-39"><inline-graphic xlink:href="440321v5_inline15.gif" hwp:id="inline-graphic-15"/></alternatives></inline-formula> in the worst case. All <inline-formula hwp:id="inline-formula-16"><alternatives hwp:id="alternatives-40"><inline-graphic xlink:href="440321v5_inline16.gif" hwp:id="inline-graphic-16"/></alternatives></inline-formula> values for the parameters relevant to the main analysis − <italic toggle="yes">α</italic>, <italic toggle="yes">B</italic>, and <italic toggle="yes">β</italic> – indicated convergence ([min, median, max] values of <inline-formula hwp:id="inline-formula-17"><alternatives hwp:id="alternatives-41"><inline-graphic xlink:href="440321v5_inline17.gif" hwp:id="inline-graphic-17"/></alternatives></inline-formula> equal to [1, 1.00335, 1.032] for <italic toggle="yes">α</italic>, [1.0005, 1.00555, 1.0425] for <italic toggle="yes">B</italic>, and [1, 1.0014, 1.0178] for all <italic toggle="yes">β</italic> values in ablation analyses.</p></sec><sec id="s4i" hwp:id="sec-17"><title hwp:id="title-26">Estimating temporal slopes and ablation indices implied by model samples</title><p hwp:id="p-95">To estimate the the shape of temporal weights implied by the model fits, we simulated choices from the model once for each posterior sample after thinning to 500 samples per chain for a total of 6k samples per observer and condition. We then fit the slope of the exponential weight function, <italic toggle="yes">β</italic>, to these simulated choices using logistic regression constrained to be an exponential function of time as described earlier (<xref rid="eqn3" ref-type="disp-formula" hwp:id="xref-disp-formula-3-2" hwp:rel-id="disp-formula-3">equation (3)</xref>). This is the <italic toggle="yes">β</italic><sub>fit</sub> plotted on the y-axis of <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-9" hwp:rel-id="F6">Figure 6b</xref>. For the ablation analyses, we again fit <italic toggle="yes">β</italic> to choices simulated once per posterior sample of model parameters, but setting <italic toggle="yes">α</italic> = 0 in one case or (<italic toggle="yes">B</italic> = ∞, <italic toggle="yes">ϵ</italic> = 0) in the other.</p><p hwp:id="p-96">We used a hierarchical regression analysis to compute “ablation indices” per observer and per parameter. The motivation for this analysis is that observers have different magnitudes of primacy and recency effects, but the <italic toggle="yes">relative</italic> impact of the leak or bound and noise parameters appeared fairly consistent throughout the population (Supplemental Figure S12), so a good summary index measures the <italic toggle="yes">fraction</italic> of the bias attributable to each parameter, which directly relates to the slope of a regression line through the origin. To quantify the net effect of each ablated parameter per observer, we regressed a linear model with zero intercept to <italic toggle="yes">β</italic><sub>fit</sub> versus <italic toggle="yes">β</italic><sub>true</sub>. If an ablated parameter has little impact on <italic toggle="yes">β</italic><sub>fit</sub>, then the slope of the regression will be near 1, so we use 1 minus the linear model’s slope as an index of the parameter’s contribution. The regression model accounted for errors in both <italic toggle="yes">x</italic> and <italic toggle="yes">y</italic> but approximated them as Gaussian. Defining <italic toggle="yes">m</italic> to be the regression slope for the population and <italic toggle="yes">m<sub>i</sub></italic> to be the slope for observer <italic toggle="yes">i</italic>, the regression model was defined as
<disp-formula id="eqn23" hwp:id="disp-formula-25" hwp:rev-id="xref-disp-formula-25-1">
<alternatives hwp:id="alternatives-42"><graphic xlink:href="440321v5_eqn23.gif" position="float" orientation="portrait" hwp:id="graphic-31"/></alternatives>
</disp-formula>
<disp-formula id="eqn24" hwp:id="disp-formula-26" hwp:rev-id="xref-disp-formula-26-1">
<alternatives hwp:id="alternatives-43"><graphic xlink:href="440321v5_eqn24.gif" position="float" orientation="portrait" hwp:id="graphic-32"/></alternatives>
</disp-formula>
<disp-formula id="eqn25" hwp:id="disp-formula-27">
<alternatives hwp:id="alternatives-44"><graphic xlink:href="440321v5_eqn25.gif" position="float" orientation="portrait" hwp:id="graphic-33"/></alternatives>
</disp-formula>
<disp-formula id="eqn26" hwp:id="disp-formula-28">
<alternatives hwp:id="alternatives-45"><graphic xlink:href="440321v5_eqn26.gif" position="float" orientation="portrait" hwp:id="graphic-34"/></alternatives>
</disp-formula></p><p hwp:id="p-97">This model was implemented in STAN and fit using NUTS [<xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">14</xref>]. The regression was done separately for each experimental condition and each set of ablated parameters. <xref rid="eqn23" ref-type="disp-formula" hwp:id="xref-disp-formula-25-1" hwp:rel-id="disp-formula-25">Equations (23)</xref> and <xref rid="eqn24" ref-type="disp-formula" hwp:id="xref-disp-formula-26-1" hwp:rel-id="disp-formula-26">(24)</xref> are standard practice in hierarchical regression – they capture the idea that there is variation in the parameter of interest (the slope <italic toggle="yes">m</italic>) across observers which is normally distributed with unknown variance, σ<sub><italic toggle="yes">m</italic></sub>, but that this variance is encouraged to be small if supported by the data. The variable <italic toggle="yes">x<sub>i</sub></italic> is the “true” x location associated with each observer, which is inferred as a latent variable to account for measurement error in both x (25) and y (26) dimensions. Measurement errors in <italic toggle="yes">β</italic><sub>true</sub>, σ<italic toggle="yes"><sub>x,i</sub></italic> were set to the standard deviation in <italic toggle="yes">β</italic> across bootstraps. Measurement errors in <italic toggle="yes">β</italic><sub>fit</sub>, σ<sub><italic toggle="yes">y,i</italic></sub> were set to the standard deviation of the posterior predictive distribution over <italic toggle="yes">β</italic> from simulated choices on each sample of model parameters as described above. We set <italic toggle="yes">x<sub>i</sub></italic> and <italic toggle="yes">y<sub>i</sub></italic> to the median values of <italic toggle="yes">β</italic><sub>true</sub> (across bootstrapped trials) and <italic toggle="yes">β</italic><sub>fit</sub> (across posterior samples), respectively.</p></sec><sec id="s4j" hwp:id="sec-18"><title hwp:id="title-27">Ground-truth models</title><p hwp:id="p-98">Based on observations of the temporal weighting profile alone, the transition between primacy and recency could be explained by bounded integration with a changing leak amount in the LSHC condition and high bound in the HSLC condition (Supplemental Figure S7g-i). To verify that all of the above fitting and ablation procedures could distinguish a confirmation bias from bounded integration, we tested them on two ground-truth models: one where choices were simulated from a hierarchical inference (IS) model, and one where choices were simulated from an ITB model. All ground-truth parameter values are given in Supplemental Table S3, which were chosen to meet two criteria: first, constant performance at 70% in both LSHC and HSLC regimes, and second, matched temporal slopes (a primacy effect with shape <italic toggle="yes">β</italic> ≈ −0.1 in the LSHC condition and a recency effect with shape <italic toggle="yes">β</italic> ≈ 0.1 in the HSLC condition for both models). This analysis confirmed that bounded integration is indeed distinguishable from a confirmation bias (<italic toggle="yes">α</italic> &lt; 0), in terms of the quality of the fit (Supplemental Figures S9), different inferred parameter values (Supplemental Figure S10), and the ablation tests (Supplemental Figure S11).</p></sec></sec><sec sec-type="supplementary-material" hwp:id="sec-19"><title hwp:id="title-28">Supporting information</title><supplementary-material position="float" orientation="portrait" hwp:id="DC1"><object-id pub-id-type="other" hwp:sub-type="slug">DC1</object-id><label>Supplemental text and figures</label><media xlink:href="supplements/440321_file02.pdf" position="float" orientation="portrait" hwp:id="media-1"/></supplementary-material></sec></body><back><ack hwp:id="ack-1"><title hwp:id="title-29">Acknowledgements</title><p hwp:id="p-99">This work was supported by NEI/NIH awards R01 EY028811-01 (RMH) and T32 EY007125 (RDL, JLY), as well as an NSF/NRT graduate training grant NSF-1449828 (RDL).</p></ack><sec sec-type="COI-statement" hwp:id="sec-20"><title hwp:id="title-30">Competing Interests</title><p hwp:id="p-100">The authors declare no competing interests.</p></sec><sec hwp:id="sec-21"><title hwp:id="title-31">Author Contributions</title><p hwp:id="p-101">Author contributions are shown in the following table, where black = significant contribution, gray = partial contribution, and white = zero or minimal contribution.</p><table-wrap id="utbl1" orientation="portrait" position="float" hwp:id="T1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;440321v5/UTBL1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">utbl1</object-id><graphic xlink:href="440321v5_utbl1" position="float" orientation="portrait" hwp:id="graphic-35"/></table-wrap></sec><ref-list hwp:id="ref-list-1"><title hwp:id="title-32">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1 xref-ref-1-2 xref-ref-1-3 xref-ref-1-4"><label>[1]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Beaudot William H A"><given-names>William H A</given-names> <surname>Beaudot</surname></string-name> and <string-name name-style="western" hwp:sortable="Mullen Kathy T."><given-names>Kathy T.</given-names> <surname>Mullen</surname></string-name>. <article-title hwp:id="article-title-2">Orientation discrimination in human vision: Psychophysics and modeling</article-title>. <source hwp:id="source-1">Vision Research</source>, <volume>46</volume>:<fpage>26</fpage>–<lpage>46</lpage>, <year>2006</year>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1 xref-ref-2-2 xref-ref-2-3"><label>[2]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Beck Jeff"><given-names>Jeff</given-names> <surname>Beck</surname></string-name>, <string-name name-style="western" hwp:sortable="Heller Katherine"><given-names>Katherine</given-names> <surname>Heller</surname></string-name>, and <string-name name-style="western" hwp:sortable="Pouget Alexandre"><given-names>Alexandre</given-names> <surname>Pouget</surname></string-name>. <article-title hwp:id="article-title-3">Complex Inference in Neural Circuits with Probabilistic Population Codes and Topic Models</article-title>. <source hwp:id="source-2">Advances in Neural Infromation Processing Systems</source>, <volume>25</volume>:<fpage>3068</fpage>–<lpage>3076</lpage>, <year>2012</year>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1 xref-ref-3-2 xref-ref-3-3"><label>[3]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Beck Jeffrey M."><given-names>Jeffrey M.</given-names> <surname>Beck</surname></string-name>, <string-name name-style="western" hwp:sortable="Ma Wei Ji"><given-names>Wei Ji</given-names> <surname>Ma</surname></string-name>, <string-name name-style="western" hwp:sortable="Kiani Roozbeh"><given-names>Roozbeh</given-names> <surname>Kiani</surname></string-name>, <string-name name-style="western" hwp:sortable="Hanks Tim"><given-names>Tim</given-names> <surname>Hanks</surname></string-name>, <string-name name-style="western" hwp:sortable="Churchland Anne K."><given-names>Anne K.</given-names> <surname>Churchland</surname></string-name>, <string-name name-style="western" hwp:sortable="Roitman Jamie"><given-names>Jamie</given-names> <surname>Roitman</surname></string-name>, <string-name name-style="western" hwp:sortable="Shadlen Michael N."><given-names>Michael N.</given-names> <surname>Shadlen</surname></string-name>, <string-name name-style="western" hwp:sortable="Latham Peter E."><given-names>Peter E.</given-names> <surname>Latham</surname></string-name>, and <string-name name-style="western" hwp:sortable="Pouget Alexandre"><given-names>Alexandre</given-names> <surname>Pouget</surname></string-name>. <article-title hwp:id="article-title-4">Probabilistic Population Codes for Bayesian Decision Making</article-title>. <source hwp:id="source-3">Neuron</source>, <volume>60</volume>(<issue>6</issue>):<fpage>1142</fpage>–<lpage>1152</lpage>, <year>2008</year>.</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1 xref-ref-4-2"><label>[4]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Berkes Pietro"><given-names>Pietro</given-names> <surname>Berkes</surname></string-name>, <string-name name-style="western" hwp:sortable="Orbán Gergo"><given-names>Gergo</given-names> <surname>Orbán</surname></string-name>, <string-name name-style="western" hwp:sortable="Lengyel Máté"><given-names>Máté</given-names> <surname>Lengyel</surname></string-name>, and <string-name name-style="western" hwp:sortable="Fiser Jósef"><given-names>Jósef</given-names> <surname>Fiser</surname></string-name>. <article-title hwp:id="article-title-5">Spontaneous Cortical Activity Reveals Hallmarks of an Optimal Internal Model of the Environment</article-title>. <source hwp:id="source-4">Science</source>, <volume>331</volume>(<issue>January</issue>): <fpage>83</fpage>–<lpage>87</lpage>, <year>2011</year>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1 xref-ref-5-2"><label>[5]</label><citation publication-type="book" citation-type="book" ref:id="440321v5.5" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Bishop C.M."><given-names>C.M.</given-names> <surname>Bishop</surname></string-name>. <chapter-title>Pattern Recognition and Machine Learning</chapter-title>. <source hwp:id="source-5">Information science and statistics</source>. <publisher-name>Springer</publisher-name> <publisher-loc>(New York)</publisher-loc>, <year>2006</year>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2 xref-ref-6-3 xref-ref-6-4 xref-ref-6-5 xref-ref-6-6 xref-ref-6-7 xref-ref-6-8 xref-ref-6-9 xref-ref-6-10 xref-ref-6-11 xref-ref-6-12"><label>[6]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Bogacz Rafal"><given-names>Rafal</given-names> <surname>Bogacz</surname></string-name>, <string-name name-style="western" hwp:sortable="Brown Eric"><given-names>Eric</given-names> <surname>Brown</surname></string-name>, <string-name name-style="western" hwp:sortable="Moehlis Jeff"><given-names>Jeff</given-names> <surname>Moehlis</surname></string-name>, <string-name name-style="western" hwp:sortable="Holmes Philip"><given-names>Philip</given-names> <surname>Holmes</surname></string-name>, and <string-name name-style="western" hwp:sortable="Cohen Jonathan D."><given-names>Jonathan D.</given-names> <surname>Cohen</surname></string-name>. <article-title hwp:id="article-title-6">The physics of optimal decision making: A formal analysis of models of performance in two-alternative forced-choice tasks</article-title>. <source hwp:id="source-6">Psychological Review</source>, <volume>113</volume>(<issue>4</issue>):<fpage>700</fpage>–<lpage>765</lpage>, <year>2006</year>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1 xref-ref-7-2 xref-ref-7-3"><label>[7]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Bondy Adrian G."><given-names>Adrian G.</given-names> <surname>Bondy</surname></string-name>, <string-name name-style="western" hwp:sortable="Haefner Ralf M."><given-names>Ralf M.</given-names> <surname>Haefner</surname></string-name>, and <string-name name-style="western" hwp:sortable="Cumming Bruce G."><given-names>Bruce G.</given-names> <surname>Cumming</surname></string-name>. <article-title hwp:id="article-title-7">Feedback determines the structure of correlated variability in primary visual cortex</article-title>. <source hwp:id="source-7">Nature Neuroscience</source>, <volume>21</volume>(<issue>4</issue>):<fpage>598</fpage>–<lpage>606</lpage>, <year>2018</year>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><label>[8]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Brainard D. H."><given-names>D. H.</given-names> <surname>Brainard</surname></string-name>. <article-title hwp:id="article-title-8">The psychophysics toolbox</article-title>. <source hwp:id="source-8">Spatial Vision</source>, <volume>10</volume>:<fpage>433</fpage>–<lpage>436</lpage>, <year>1997</year>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1"><label>[9]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Broderick Tamara"><given-names>Tamara</given-names> <surname>Broderick</surname></string-name>, <string-name name-style="western" hwp:sortable="Boyd Nicholas"><given-names>Nicholas</given-names> <surname>Boyd</surname></string-name>, <string-name name-style="western" hwp:sortable="Wibisono Andre"><given-names>Andre</given-names> <surname>Wibisono</surname></string-name>, <string-name name-style="western" hwp:sortable="Wilson Ashia C"><given-names>Ashia C</given-names> <surname>Wilson</surname></string-name>, and <string-name name-style="western" hwp:sortable="Jordan Michael I"><given-names>Michael I</given-names> <surname>Jordan</surname></string-name>. <article-title hwp:id="article-title-9">Streaming variational bayes</article-title>. <source hwp:id="source-9">Advances in Neural Information Processing Systems</source>, <volume>26</volume>:<fpage>1727</fpage>–<lpage>1735</lpage>, <year>2013</year>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><label>[10]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Brooks Stephen P."><given-names>Stephen P.</given-names> <surname>Brooks</surname></string-name> and <string-name name-style="western" hwp:sortable="Gelman Andrew"><given-names>Andrew</given-names> <surname>Gelman</surname></string-name>. <article-title hwp:id="article-title-10">General methods for monitoring convergence of iterative simulations</article-title>. <source hwp:id="source-10">Journal of Computational and Graphical Statistics</source>, <volume>7</volume>(<issue>4</issue>):<fpage>434</fpage>–<lpage>455</lpage>, <year>1998</year>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1 xref-ref-11-2 xref-ref-11-3 xref-ref-11-4 xref-ref-11-5 xref-ref-11-6"><label>[11]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Brunton Bingni W"><given-names>Bingni W</given-names> <surname>Brunton</surname></string-name>, <string-name name-style="western" hwp:sortable="Botvinick Matthew M."><given-names>Matthew M.</given-names> <surname>Botvinick</surname></string-name>, and <string-name name-style="western" hwp:sortable="Brody Carlos D"><given-names>Carlos D</given-names> <surname>Brody</surname></string-name>. <article-title hwp:id="article-title-11">Rats and humans can optimally accumulate evidence for decision-making</article-title>. <source hwp:id="source-11">Science</source>, <volume>340</volume>(<issue>6128</issue>):<fpage>95</fpage>–<lpage>8</lpage>, <year>2013</year>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1"><label>[12]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.12" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Buesing Lars"><given-names>Lars</given-names> <surname>Buesing</surname></string-name>, <string-name name-style="western" hwp:sortable="Bill Johannes"><given-names>Johannes</given-names> <surname>Bill</surname></string-name>, <string-name name-style="western" hwp:sortable="Nessler Bernhard"><given-names>Bernhard</given-names> <surname>Nessler</surname></string-name>, and <string-name name-style="western" hwp:sortable="Maass Wolfgang"><given-names>Wolfgang</given-names> <surname>Maass</surname></string-name>. <article-title hwp:id="article-title-12">Neural dynamics as sampling: A model for stochastic computation in recurrent networks of spiking neurons</article-title>. <source hwp:id="source-12">PLoS Computational Biology</source>, <volume>7</volume>(<issue>11</issue>), <year>2011</year>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1 xref-ref-13-2 xref-ref-13-3 xref-ref-13-4 xref-ref-13-5 xref-ref-13-6 xref-ref-13-7"><label>[13]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Busemeyer Jerome R."><given-names>Jerome R.</given-names> <surname>Busemeyer</surname></string-name> and <string-name name-style="western" hwp:sortable="Townsend James T."><given-names>James T.</given-names> <surname>Townsend</surname></string-name>. <article-title hwp:id="article-title-13">Decision field theory: A dynamic-cognitive approach to decision making in an uncertain environment</article-title>. <source hwp:id="source-13">Psychological Review</source>, <volume>100</volume>(<issue>3</issue>):<fpage>432</fpage>–<lpage>459</lpage>, <year>1993</year>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><label>[14]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.14" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Carpenter Bob"><given-names>Bob</given-names> <surname>Carpenter</surname></string-name>, <string-name name-style="western" hwp:sortable="Gelman Andrew"><given-names>Andrew</given-names> <surname>Gelman</surname></string-name>, <string-name name-style="western" hwp:sortable="Hoffman Matthew D."><given-names>Matthew D.</given-names> <surname>Hoffman</surname></string-name>, <string-name name-style="western" hwp:sortable="Lee Daniel"><given-names>Daniel</given-names> <surname>Lee</surname></string-name>, <string-name name-style="western" hwp:sortable="Goodrich Ben"><given-names>Ben</given-names> <surname>Goodrich</surname></string-name>, <string-name name-style="western" hwp:sortable="Betancourt Michael"><given-names>Michael</given-names> <surname>Betancourt</surname></string-name>, <string-name name-style="western" hwp:sortable="Brubaker Marcus A."><given-names>Marcus A.</given-names> <surname>Brubaker</surname></string-name>, <string-name name-style="western" hwp:sortable="Guo Jiqiang"><given-names>Jiqiang</given-names> <surname>Guo</surname></string-name>, <string-name name-style="western" hwp:sortable="Li Peter"><given-names>Peter</given-names> <surname>Li</surname></string-name>, and <string-name name-style="western" hwp:sortable="Riddell Allen"><given-names>Allen</given-names> <surname>Riddell</surname></string-name>. <article-title hwp:id="article-title-14">Stan: A probabilistic programming language</article-title>. <source hwp:id="source-14">Journal of Statistical Software</source>, <volume>76</volume>(<issue>1</issue>), <year>2017</year>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><label>[15]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.15" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Cremer Chris"><given-names>Chris</given-names> <surname>Cremer</surname></string-name>, <string-name name-style="western" hwp:sortable="Morris Quaid"><given-names>Quaid</given-names> <surname>Morris</surname></string-name>, and <string-name name-style="western" hwp:sortable="Duvenaud David"><given-names>David</given-names> <surname>Duvenaud</surname></string-name>. <article-title hwp:id="article-title-15">Reinterpreting Importance-Weighted Autoencoders</article-title>. <source hwp:id="source-15">arXiv</source>, pages <fpage>1</fpage>–<lpage>6</lpage>, <year>2017</year>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1"><label>[16]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Cumming Bruce G."><given-names>Bruce G.</given-names> <surname>Cumming</surname></string-name> and <string-name name-style="western" hwp:sortable="Nienborg Hendrikje"><given-names>Hendrikje</given-names> <surname>Nienborg</surname></string-name>. <article-title hwp:id="article-title-16">Feedforward and feedback sources of choice probability in neural population responses</article-title>. <source hwp:id="source-16">Current Opinion in Neurobiology</source>, <volume>37</volume>:<fpage>126</fpage>–<lpage>132</lpage>, <year>2016</year>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><label>[17]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Deneve Sophie"><given-names>Sophie</given-names> <surname>Deneve</surname></string-name>. <article-title hwp:id="article-title-17">Making Decisions with Unknown Sensory Reliability</article-title>. <source hwp:id="source-17">Frontiers in Neuro-science</source>, <volume>6</volume>(<issue>June</issue>):<fpage>1</fpage>–<lpage>13</lpage>, <year>2012</year>.</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1"><label>[18]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Drugowitsch J."><given-names>J.</given-names> <surname>Drugowitsch</surname></string-name>, <string-name name-style="western" hwp:sortable="Moreno-Bote Rubén"><given-names>Rubén</given-names> <surname>Moreno-Bote</surname></string-name>, <string-name name-style="western" hwp:sortable="Churchland a. K."><given-names>a. K.</given-names> <surname>Churchland</surname></string-name>, <string-name name-style="western" hwp:sortable="Shadlen Michael N."><given-names>Michael N.</given-names> <surname>Shadlen</surname></string-name>, and <string-name name-style="western" hwp:sortable="Pouget a."><given-names>a.</given-names> <surname>Pouget</surname></string-name>. <article-title hwp:id="article-title-18">The Cost of Accumulating Evidence in Perceptual Decision Making</article-title>. <source hwp:id="source-18">Journal of Neuroscience</source>, <volume>32</volume>(<issue>11</issue>):<fpage>3612</fpage>–<lpage>3628</lpage>, <year>2012</year>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1 xref-ref-19-2 xref-ref-19-3 xref-ref-19-4"><label>[19]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Drugowitsch Jan"><given-names>Jan</given-names> <surname>Drugowitsch</surname></string-name>, <string-name name-style="western" hwp:sortable="Wyart Valentin"><given-names>Valentin</given-names> <surname>Wyart</surname></string-name>, <string-name name-style="western" hwp:sortable="Devauchelle Anne-Dominique"><given-names>Anne-Dominique</given-names> <surname>Devauchelle</surname></string-name>, and <string-name name-style="western" hwp:sortable="Koechlin Etienne"><given-names>Etienne</given-names> <surname>Koechlin</surname></string-name>. <article-title hwp:id="article-title-19">Computational Precision of Mental Inference as Critical Source of Human Choice Suboptimality</article-title>. <source hwp:id="source-19">Neuron</source>, <volume>92</volume>(<issue>6</issue>):<fpage>1398</fpage>–<lpage>1411</lpage>, <year>2016</year>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1 xref-ref-20-2 xref-ref-20-3 xref-ref-20-4"><label>[20]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Fiser József Jósef"><given-names>József Jósef</given-names> <surname>Fiser</surname></string-name>, <string-name name-style="western" hwp:sortable="Berkes Pietro"><given-names>Pietro</given-names> <surname>Berkes</surname></string-name>, <string-name name-style="western" hwp:sortable="Orbán Gergo"><given-names>Gergo</given-names> <surname>Orbán</surname></string-name>, and <string-name name-style="western" hwp:sortable="Lengyel Máté"><given-names>Máté</given-names> <surname>Lengyel</surname></string-name>. <article-title hwp:id="article-title-20">Statistically optimal perception and learning: from behavior to neural representations</article-title>. <source hwp:id="source-20">Trends in Cognitive Sciences</source>, <volume>14</volume>(<issue>3</issue>):<fpage>119</fpage>–<lpage>30</lpage>, <year>2010</year>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1"><label>[21]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Fletcher Paul C."><given-names>Paul C.</given-names> <surname>Fletcher</surname></string-name> and <string-name name-style="western" hwp:sortable="Frith Chris D."><given-names>Chris D.</given-names> <surname>Frith</surname></string-name>. <article-title hwp:id="article-title-21">Perceiving is believing: A Bayesian approach to explaining the positive symptoms of schizophrenia</article-title>. <source hwp:id="source-21">Nature Reviews Neuroscience</source>, <volume>10</volume>:<fpage>48</fpage>–<lpage>58</lpage>, <year>2009</year>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><label>[22]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Gelman Andrew"><given-names>Andrew</given-names> <surname>Gelman</surname></string-name> and <string-name name-style="western" hwp:sortable="Rubin Donald B"><given-names>Donald B</given-names> <surname>Rubin</surname></string-name>. <article-title hwp:id="article-title-22">Inference from Iterative Simulation Using Multiple Sequences</article-title>. <source hwp:id="source-22">Statistical Science</source>, <volume>7</volume>(<issue>4</issue>):<fpage>457</fpage> —-<lpage>511</lpage>, <year>1992</year>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1 xref-ref-23-2"><label>[23]</label><citation publication-type="book" citation-type="book" ref:id="440321v5.23" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Gershman Samuel J"><given-names>Samuel J</given-names> <surname>Gershman</surname></string-name> and <string-name name-style="western" hwp:sortable="Beck Jeffrey M."><given-names>Jeffrey M.</given-names> <surname>Beck</surname></string-name>. <chapter-title>Complex Probabilistic Inference: From Cognition to Neural Computation</chapter-title>. In <source hwp:id="source-23">Ahmed Moustafa, editor, Computational Models of Brain and Behavior</source>, chapter Complex Pr, pages <fpage>1</fpage>–<lpage>17</lpage>. <publisher-name>Wiley-Blackwell</publisher-name>, <year>2016</year>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1"><label>[24]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Gilbert Charles D"><given-names>Charles D</given-names> <surname>Gilbert</surname></string-name> and <string-name name-style="western" hwp:sortable="Li Wu"><given-names>Wu</given-names> <surname>Li</surname></string-name>. <source hwp:id="source-24">Top-down influences on visual processing</source>. <volume>14</volume>(<issue>May</issue>):<fpage>350</fpage>–<lpage>363</lpage>, <year>2013</year>.</citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1 xref-ref-25-2 xref-ref-25-3 xref-ref-25-4"><label>[25]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Glaze Christopher M."><given-names>Christopher M.</given-names> <surname>Glaze</surname></string-name>, <string-name name-style="western" hwp:sortable="Kable Joseph W."><given-names>Joseph W.</given-names> <surname>Kable</surname></string-name>, and <string-name name-style="western" hwp:sortable="Gold Joshua I."><given-names>Joshua I.</given-names> <surname>Gold</surname></string-name>. <article-title hwp:id="article-title-23">Normative evidence accumulation in unpredictable environments</article-title>. <source hwp:id="source-25">eLife</source>, <volume>4</volume>:<fpage>1</fpage>–<lpage>27</lpage>, <year>2015</year>.</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1 xref-ref-26-2 xref-ref-26-3 xref-ref-26-4 xref-ref-26-5 xref-ref-26-6 xref-ref-26-7"><label>[26]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.26" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Gold Joshua I"><given-names>Joshua I</given-names> <surname>Gold</surname></string-name> and <string-name name-style="western" hwp:sortable="Shadlen Michael N."><given-names>Michael N.</given-names> <surname>Shadlen</surname></string-name>. <article-title hwp:id="article-title-24">The neural basis of decision making</article-title>. <source hwp:id="source-26">Annual review of neuroscience</source>, <volume>30</volume>(<issue>30</issue>):<fpage>535</fpage>–<lpage>574</lpage>, <year>2007</year>.</citation></ref><ref id="c27" hwp:id="ref-27" hwp:rev-id="xref-ref-27-1 xref-ref-27-2 xref-ref-27-3 xref-ref-27-4 xref-ref-27-5 xref-ref-27-6"><label>[27]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.27" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Haefner Ralf M."><given-names>Ralf M.</given-names> <surname>Haefner</surname></string-name>, <string-name name-style="western" hwp:sortable="Berkes Pietro"><given-names>Pietro</given-names> <surname>Berkes</surname></string-name>, and <string-name name-style="western" hwp:sortable="Fiser Jozsef"><given-names>Jozsef</given-names> <surname>Fiser</surname></string-name>. <article-title hwp:id="article-title-25">Perceptual Decision-Making as Probabilistic Inference by Neural Sampling</article-title>. <source hwp:id="source-27">Neuron</source>, <volume>90</volume>(<issue>3</issue>):<fpage>649</fpage>–<lpage>660</lpage>, <year>2016</year>.</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1"><label>[28]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.28" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Hoffman Matthew D."><given-names>Matthew D.</given-names> <surname>Hoffman</surname></string-name>, <string-name name-style="western" hwp:sortable="Blei David M."><given-names>David M.</given-names> <surname>Blei</surname></string-name>, <string-name name-style="western" hwp:sortable="Wang Chong"><given-names>Chong</given-names> <surname>Wang</surname></string-name>, and <string-name name-style="western" hwp:sortable="Paisley John"><given-names>John</given-names> <surname>Paisley</surname></string-name>. <article-title hwp:id="article-title-26">Stochastic variational inference</article-title>. <source hwp:id="source-28">Journal of Machine Learning Research</source>, <volume>14</volume>:<fpage>1303</fpage>–<lpage>1347</lpage>, <year>2013</year>.</citation></ref><ref id="c29" hwp:id="ref-29" hwp:rev-id="xref-ref-29-1"><label>[29]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.29" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="Hoyer P. O."><given-names>P. O.</given-names> <surname>Hoyer</surname></string-name> and <string-name name-style="western" hwp:sortable="Hyvärinen A."><given-names>A.</given-names> <surname>Hyvärinen</surname></string-name>. <article-title hwp:id="article-title-27">Interpreting neural response variability as monte carlo sampling of the posterior</article-title>. <source hwp:id="source-29">Advances in Neural Information Processing Systems</source>, <volume>17</volume>(<issue>1</issue>):<fpage>293</fpage>–<lpage>300</lpage>, <year>2003</year>.</citation></ref><ref id="c30" hwp:id="ref-30" hwp:rev-id="xref-ref-30-1"><label>[30]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.30" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="Jardri Renaud"><given-names>Renaud</given-names> <surname>Jardri</surname></string-name> and <string-name name-style="western" hwp:sortable="Denéve Sophie"><given-names>Sophie</given-names> <surname>Denéve</surname></string-name>. <article-title hwp:id="article-title-28">Circular inferences in schizophrenia</article-title>. <source hwp:id="source-30">Brain</source>, <volume>136</volume>(<issue>11</issue>):<fpage>3227</fpage>–<lpage>3241</lpage>, <year>2013</year>.</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1 xref-ref-31-2"><label>[31]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="Kawaguchi Katsuhisa"><given-names>Katsuhisa</given-names> <surname>Kawaguchi</surname></string-name>, <string-name name-style="western" hwp:sortable="Clery Stephane"><given-names>Stephane</given-names> <surname>Clery</surname></string-name>, <string-name name-style="western" hwp:sortable="Pourriahi Paria"><given-names>Paria</given-names> <surname>Pourriahi</surname></string-name>, <string-name name-style="western" hwp:sortable="Seillier Lenka"><given-names>Lenka</given-names> <surname>Seillier</surname></string-name>, <string-name name-style="western" hwp:sortable="Haefner Ralf M."><given-names>Ralf M.</given-names> <surname>Haefner</surname></string-name>, and <string-name name-style="western" hwp:sortable="Nienborg Hendrikje"><given-names>Hendrikje</given-names> <surname>Nienborg</surname></string-name>. <article-title hwp:id="article-title-29">Differentiating between models of perceptual decision making using pupil size inferred confidence</article-title>. <source hwp:id="source-31">Journal of Neuroscience</source>, <volume>38</volume>(<issue>41</issue>):<fpage>8874</fpage>–<lpage>8888</lpage>, <year>2018</year>.</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1"><label>[32]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.32" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="Keller Georg B."><given-names>Georg B.</given-names> <surname>Keller</surname></string-name> and <string-name name-style="western" hwp:sortable="Mrsic-Flogel Thomas D."><given-names>Thomas D.</given-names> <surname>Mrsic-Flogel</surname></string-name>. <article-title hwp:id="article-title-30">Predictive Processing: A Canonical Cortical Computation</article-title>. <source hwp:id="source-32">Neuron</source>, <volume>100</volume>(<issue>2</issue>):<fpage>424</fpage>–<lpage>435</lpage>, <year>2018</year>.</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1 xref-ref-33-2 xref-ref-33-3 xref-ref-33-4"><label>[33]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.33" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Kiani Roozbeh"><given-names>Roozbeh</given-names> <surname>Kiani</surname></string-name>, <string-name name-style="western" hwp:sortable="Hanks Timothy D"><given-names>Timothy D</given-names> <surname>Hanks</surname></string-name>, and <string-name name-style="western" hwp:sortable="Shadlen Michael N."><given-names>Michael N.</given-names> <surname>Shadlen</surname></string-name>. <article-title hwp:id="article-title-31">Bounded integration in parietal cortex underlies decisions even when viewing duration is dictated by the environment</article-title>. <source hwp:id="source-33">The Journal of Neuroscience</source>, <volume>28</volume>(<issue>12</issue>):<fpage>3017</fpage>–<lpage>3029</lpage>, <year>2008</year>.</citation></ref><ref id="c34" hwp:id="ref-34" hwp:rev-id="xref-ref-34-1"><label>[34]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.34" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Lak Armin"><given-names>Armin</given-names> <surname>Lak</surname></string-name>, <string-name name-style="western" hwp:sortable="Hueske Emily"><given-names>Emily</given-names> <surname>Hueske</surname></string-name>, <string-name name-style="western" hwp:sortable="Hirokawa Junya"><given-names>Junya</given-names> <surname>Hirokawa</surname></string-name>, <string-name name-style="western" hwp:sortable="Masset Paul"><given-names>Paul</given-names> <surname>Masset</surname></string-name>, <string-name name-style="western" hwp:sortable="Ott Torben"><given-names>Torben</given-names> <surname>Ott</surname></string-name>, <string-name name-style="western" hwp:sortable="Urai Anne E"><given-names>Anne E</given-names> <surname>Urai</surname></string-name>, <string-name name-style="western" hwp:sortable="Donner To-bias H"><given-names>To-bias H</given-names> <surname>Donner</surname></string-name>, <string-name name-style="western" hwp:sortable="Carandini Matteo"><given-names>Matteo</given-names> <surname>Carandini</surname></string-name>, <string-name name-style="western" hwp:sortable="Tonegawa Susumu"><given-names>Susumu</given-names> <surname>Tonegawa</surname></string-name>, <string-name name-style="western" hwp:sortable="Uchida Naoshige"><given-names>Naoshige</given-names> <surname>Uchida</surname></string-name>, and <string-name name-style="western" hwp:sortable="Kepecs Adam"><given-names>Adam</given-names> <surname>Kepecs</surname></string-name>. <article-title hwp:id="article-title-32">Reinforcement biases subsequent perceptual decisions when confidence is low, a widespread behavioral phenomenon</article-title>. <source hwp:id="source-34">eLife</source>, <volume>9</volume>:<fpage>e49834</fpage>, <month>apr</month> <year>2020</year>.</citation></ref><ref id="c35" hwp:id="ref-35" hwp:rev-id="xref-ref-35-1 xref-ref-35-2 xref-ref-35-3 xref-ref-35-4"><label>[35]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.35" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Lange Richard D"><given-names>Richard D</given-names> <surname>Lange</surname></string-name> and <string-name name-style="western" hwp:sortable="Haefner Ralf M"><given-names>Ralf M</given-names> <surname>Haefner</surname></string-name>. <article-title hwp:id="article-title-33">Task-induced neural covariability as a signature of Bayesian learning and inference</article-title>. <source hwp:id="source-35">bioRxiv</source>, <year>2020</year>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1 xref-ref-36-2 xref-ref-36-3"><label>[36]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.36" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Lee Tai Sing"><given-names>Tai Sing</given-names> <surname>Lee</surname></string-name> and <string-name name-style="western" hwp:sortable="Mumford David"><given-names>David</given-names> <surname>Mumford</surname></string-name>. <article-title hwp:id="article-title-34">Hierarchical Bayesian inference in the visual cortex</article-title>. <source hwp:id="source-36">Journal of the Optical Society of America A</source>, <volume>20</volume>(<issue>7</issue>):<fpage>1434</fpage>–<lpage>1448</lpage>, <year>2003</year>.</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1"><label>[37]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.37" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Lueckmann Jan-Matthis"><given-names>Jan-Matthis</given-names> <surname>Lueckmann</surname></string-name>, <string-name name-style="western" hwp:sortable="Macke Jakob H."><given-names>Jakob H.</given-names> <surname>Macke</surname></string-name>, and <string-name name-style="western" hwp:sortable="Nienborg Hendrikje"><given-names>Hendrikje</given-names> <surname>Nienborg</surname></string-name>. <article-title hwp:id="article-title-35">Can serial dependencies in choices and neural activity explain choice probabilities?</article-title> <source hwp:id="source-37">The Journal of Neuroscience</source>, <volume>38</volume> (<issue>14</issue>):<fpage>2225</fpage>–<lpage>17</lpage>, <year>2018</year>.</citation></ref><ref id="c38" hwp:id="ref-38" hwp:rev-id="xref-ref-38-1 xref-ref-38-2"><label>[38]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.38" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-38"><string-name name-style="western" hwp:sortable="Ma Wei Ji"><given-names>Wei Ji</given-names> <surname>Ma</surname></string-name>, <string-name name-style="western" hwp:sortable="Beck Jeffrey M."><given-names>Jeffrey M.</given-names> <surname>Beck</surname></string-name>, <string-name name-style="western" hwp:sortable="Latham Peter E"><given-names>Peter E</given-names> <surname>Latham</surname></string-name>, and <string-name name-style="western" hwp:sortable="Pouget Alexandre"><given-names>Alexandre</given-names> <surname>Pouget</surname></string-name>. <article-title hwp:id="article-title-36">Bayesian inference with probabilistic population codes</article-title>. <source hwp:id="source-38">Nature Neuroscience</source>, <volume>9</volume>(<issue>11</issue>):<fpage>1432</fpage>–<lpage>1438</lpage>, <year>2006</year>.</citation></ref><ref id="c39" hwp:id="ref-39" hwp:rev-id="xref-ref-39-1"><label>[39]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.39" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-39"><string-name name-style="western" hwp:sortable="Mumford David"><given-names>David</given-names> <surname>Mumford</surname></string-name>. <article-title hwp:id="article-title-37">On the computational architecture of the neocortex</article-title>. <source hwp:id="source-39">Biological cybernetics</source>, <volume>251</volume>:<fpage>241</fpage>–<lpage>251</lpage>, <year>1992</year>.</citation></ref><ref id="c40" hwp:id="ref-40" hwp:rev-id="xref-ref-40-1 xref-ref-40-2 xref-ref-40-3"><label>[40]</label><citation publication-type="book" citation-type="book" ref:id="440321v5.40" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-40"><string-name name-style="western" hwp:sortable="Murphy Kevin P."><given-names>Kevin P.</given-names> <surname>Murphy</surname></string-name>. <source hwp:id="source-40">Machine Learning: A Probabilistic Perspective</source>. <publisher-name>The MIT Press</publisher-name>, <year>2012</year>.</citation></ref><ref id="c41" hwp:id="ref-41" hwp:rev-id="xref-ref-41-1"><label>[41]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.41" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-41"><string-name name-style="western" hwp:sortable="Newsome W. T."><given-names>W. T.</given-names> <surname>Newsome</surname></string-name> and <string-name name-style="western" hwp:sortable="Pare E. B."><given-names>E. B.</given-names> <surname>Pare</surname></string-name>. <article-title hwp:id="article-title-38">A selective impairment of motion perception following lesions of the middle temporal visual area (MT)</article-title>. <source hwp:id="source-41">The Journal of Neuroscience</source>, <volume>8</volume>(<issue>6</issue>):<fpage>2201</fpage>–<lpage>2211</lpage>, <year>1988</year>.</citation></ref><ref id="c42" hwp:id="ref-42" hwp:rev-id="xref-ref-42-1"><label>[42]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.42" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-42"><string-name name-style="western" hwp:sortable="Nickerson Rs"><given-names>Rs</given-names> <surname>Nickerson</surname></string-name>. <article-title hwp:id="article-title-39">Confirmation bias: A ubiquitous phenomenon in many guises</article-title>. <source hwp:id="source-42">Review of general psychology</source>, <volume>2</volume>(<issue>2</issue>):<fpage>175</fpage>–<lpage>220</lpage>, <year>1998</year>.</citation></ref><ref id="c43" hwp:id="ref-43" hwp:rev-id="xref-ref-43-1"><label>[43]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.43" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-43"><string-name name-style="western" hwp:sortable="Nienborg Hendrikje"><given-names>Hendrikje</given-names> <surname>Nienborg</surname></string-name> and <string-name name-style="western" hwp:sortable="Cumming Bruce G."><given-names>Bruce G.</given-names> <surname>Cumming</surname></string-name>. <article-title hwp:id="article-title-40">Decision-related activity in sensory neurons reflects more than a neuron’s causal effect</article-title>. <source hwp:id="source-43">Nature</source>, <volume>459</volume>(<issue>7243</issue>):<fpage>89</fpage>–<lpage>92</lpage>, <year>2009</year>.</citation></ref><ref id="c44" hwp:id="ref-44" hwp:rev-id="xref-ref-44-1 xref-ref-44-2"><label>[44]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.44" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-44"><string-name name-style="western" hwp:sortable="Nienborg Hendrikje"><given-names>Hendrikje</given-names> <surname>Nienborg</surname></string-name> and <string-name name-style="western" hwp:sortable="Cumming Bruce G"><given-names>Bruce G</given-names> <surname>Cumming</surname></string-name>. <article-title hwp:id="article-title-41">Decision-related activity in sensory neurons may depend on the columnar architecture of cerebral cortex</article-title>. <source hwp:id="source-44">The Journal of Neuroscience</source>, <volume>34</volume>(<issue>10</issue>): <fpage>3579</fpage>–<lpage>85</lpage>, <year>2014</year>.</citation></ref><ref id="c45" hwp:id="ref-45" hwp:rev-id="xref-ref-45-1"><label>[45]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.45" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-45"><string-name name-style="western" hwp:sortable="Nienborg Hendrikje"><given-names>Hendrikje</given-names> <surname>Nienborg</surname></string-name> and <string-name name-style="western" hwp:sortable="Roelfsema Pieter R."><given-names>Pieter R.</given-names> <surname>Roelfsema</surname></string-name>. <article-title hwp:id="article-title-42">Belief states as a framework to explain extraretinal influences in visual cortex</article-title>. <source hwp:id="source-45">Current opinion in neurobiology</source>, <volume>32</volume>:<fpage>45</fpage>–<lpage>52</lpage>, <year>2015</year>.</citation></ref><ref id="c46" hwp:id="ref-46" hwp:rev-id="xref-ref-46-1"><label>[46]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.46" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-46"><string-name name-style="western" hwp:sortable="Nienborg Hendrikje"><given-names>Hendrikje</given-names> <surname>Nienborg</surname></string-name>, <string-name name-style="western" hwp:sortable="Cohen Marlene R"><given-names>Marlene R</given-names> <surname>Cohen</surname></string-name>, <string-name name-style="western" hwp:sortable="Cumming Bruce G."><given-names>Bruce G.</given-names> <surname>Cumming</surname></string-name>, <string-name name-style="western" hwp:sortable="Cohen Marlene R."><given-names>Marlene R.</given-names> <surname>Cohen</surname></string-name>, and <string-name name-style="western" hwp:sortable="Cumming Bruce G."><given-names>Bruce G.</given-names> <surname>Cumming</surname></string-name>. <article-title hwp:id="article-title-43">Decision-related activity in sensory neurons: correlations among neurons and with behavior</article-title>. <source hwp:id="source-46">Annual review of neuroscience</source>, <volume>35</volume>(<issue>1</issue>):<fpage>463</fpage>–<lpage>483</lpage>, <month>jan</month> <year>2012</year>.</citation></ref><ref id="c47" hwp:id="ref-47" hwp:rev-id="xref-ref-47-1 xref-ref-47-2"><label>[47]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.47" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-47"><string-name name-style="western" hwp:sortable="Orbán Gergó"><given-names>Gergó</given-names> <surname>Orbán</surname></string-name>, <string-name name-style="western" hwp:sortable="Berkes Pietro"><given-names>Pietro</given-names> <surname>Berkes</surname></string-name>, <string-name name-style="western" hwp:sortable="Fiser József"><given-names>József</given-names> <surname>Fiser</surname></string-name>, and <string-name name-style="western" hwp:sortable="Lengyel Máté"><given-names>Máté</given-names> <surname>Lengyel</surname></string-name>. <article-title hwp:id="article-title-44">Neural Variability and Sampling-Based Probabilistic Representations in the Visual Cortex</article-title>. <source hwp:id="source-47">Neuron</source>, <volume>92</volume>(<issue>2</issue>):<fpage>530</fpage>–<lpage>543</lpage>, <year>2016</year>.</citation></ref><ref id="c48" hwp:id="ref-48" hwp:rev-id="xref-ref-48-1"><label>[48]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.48" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-48"><string-name name-style="western" hwp:sortable="Orhan A. Emin"><given-names>A. Emin</given-names> <surname>Orhan</surname></string-name> and <string-name name-style="western" hwp:sortable="Ma Wei Ji"><given-names>Wei Ji</given-names> <surname>Ma</surname></string-name>. <article-title hwp:id="article-title-45">Efficient probabilistic inference in generic neural networks trained with non-probabilistic feedback</article-title>. <source hwp:id="source-48">Nature Communications</source>, <volume>8</volume>(<issue>138</issue>), <year>2017</year>.</citation></ref><ref id="c49" hwp:id="ref-49" hwp:rev-id="xref-ref-49-1"><label>[49]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.49" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-49"><string-name name-style="western" hwp:sortable="Owen Art B."><given-names>Art B.</given-names> <surname>Owen</surname></string-name>. <article-title hwp:id="article-title-46">Importance Sampling</article-title>. <source hwp:id="source-49">In Monte Carlo theory, methods and examples</source>, chapter 9. <year>2013</year>.</citation></ref><ref id="c50" hwp:id="ref-50" hwp:rev-id="xref-ref-50-1"><label>[50]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.50" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-50"><string-name name-style="western" hwp:sortable="Piet Alex T"><given-names>Alex T</given-names> <surname>Piet</surname></string-name>, <string-name name-style="western" hwp:sortable="El Hady Ahmed"><given-names>Ahmed</given-names> <surname>El Hady</surname></string-name>, and <string-name name-style="western" hwp:sortable="Brody Carlos D."><given-names>Carlos D.</given-names> <surname>Brody</surname></string-name>. <article-title hwp:id="article-title-47">Rats adopt the optimal timescale for evidence integration in a dynamic environment</article-title>. <source hwp:id="source-50">Nature Communications</source>, <volume>9</volume>, <year>2018</year>.</citation></ref><ref id="c51" hwp:id="ref-51" hwp:rev-id="xref-ref-51-1 xref-ref-51-2 xref-ref-51-3"><label>[51]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.51" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-51"><string-name name-style="western" hwp:sortable="Pouget Alexandre"><given-names>Alexandre</given-names> <surname>Pouget</surname></string-name>, <string-name name-style="western" hwp:sortable="Beck Jeffrey M."><given-names>Jeffrey M.</given-names> <surname>Beck</surname></string-name>, <string-name name-style="western" hwp:sortable="Ma Wei Ji"><given-names>Wei Ji</given-names> <surname>Ma</surname></string-name>, and <string-name name-style="western" hwp:sortable="Latham Peter E"><given-names>Peter E</given-names> <surname>Latham</surname></string-name>. <article-title hwp:id="article-title-48">Probabilistic brains: knowns and unknowns</article-title>. <source hwp:id="source-51">Nature Neuroscience</source>, <volume>16</volume>(<issue>9</issue>):<fpage>1170</fpage>–<lpage>8</lpage>, <year>2013</year>.</citation></ref><ref id="c52" hwp:id="ref-52" hwp:rev-id="xref-ref-52-1"><label>[52]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.52" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-52"><string-name name-style="western" hwp:sortable="Prat-Ortega Geíıs"><given-names>Geíıs</given-names> <surname>Prat-Ortega</surname></string-name>, <string-name name-style="western" hwp:sortable="Wimmer Klaus"><given-names>Klaus</given-names> <surname>Wimmer</surname></string-name>, <string-name name-style="western" hwp:sortable="Roxin Alex"><given-names>Alex</given-names> <surname>Roxin</surname></string-name>, and <string-name name-style="western" hwp:sortable="de la Rocha Jaime"><given-names>Jaime</given-names> <surname>de la Rocha</surname></string-name>. <article-title hwp:id="article-title-49">Flexible categorization in perceptual decision making</article-title>. <source hwp:id="source-52">Nature Communications</source>, <volume>12</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>15</lpage>, <year>2021</year>.</citation></ref><ref id="c53" hwp:id="ref-53" hwp:rev-id="xref-ref-53-1"><label>[53]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.53" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-53"><string-name name-style="western" hwp:sortable="Raju Rajkumar Vasudeva"><given-names>Rajkumar Vasudeva</given-names> <surname>Raju</surname></string-name> and <string-name name-style="western" hwp:sortable="Pitkow Xaq"><given-names>Xaq</given-names> <surname>Pitkow</surname></string-name>. <article-title hwp:id="article-title-50">Inference by Reparameterization in Neural Population Codes</article-title>. <source hwp:id="source-53">Advances in Neural Information Processing Systems</source>, <volume>30</volume>, <year>2016</year>.</citation></ref><ref id="c54" hwp:id="ref-54" hwp:rev-id="xref-ref-54-1"><label>[54]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.54" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-54"><string-name name-style="western" hwp:sortable="Raposo David"><given-names>David</given-names> <surname>Raposo</surname></string-name>, <string-name name-style="western" hwp:sortable="Kaufman Matthew T"><given-names>Matthew T</given-names> <surname>Kaufman</surname></string-name>, and <string-name name-style="western" hwp:sortable="Churchland Anne K"><given-names>Anne K</given-names> <surname>Churchland</surname></string-name>. <article-title hwp:id="article-title-51">A category-free neural population supports evolving demands during decision-making</article-title>. <source hwp:id="source-54">Nature Neuroscience</source>, <volume>17</volume>(<issue>12</issue>):<fpage>1784</fpage>–<lpage>1792</lpage>, <year>2014</year>.</citation></ref><ref id="c55" hwp:id="ref-55" hwp:rev-id="xref-ref-55-1"><label>[55]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.55" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-55"><string-name name-style="western" hwp:sortable="Sanborn Adam N"><given-names>Adam N</given-names> <surname>Sanborn</surname></string-name>. <article-title hwp:id="article-title-52">Types of approximation for probabilistic cognition: Sampling and variational</article-title>. <source hwp:id="source-55">Brain and Cognition</source>, <year>2015</year>.</citation></ref><ref id="c56" hwp:id="ref-56" hwp:rev-id="xref-ref-56-1"><label>[56]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.56" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-56"><string-name name-style="western" hwp:sortable="Savin Cristina"><given-names>Cristina</given-names> <surname>Savin</surname></string-name> and <string-name name-style="western" hwp:sortable="Denève Sophie"><given-names>Sophie</given-names> <surname>Denève</surname></string-name>. <article-title hwp:id="article-title-53">Spatio-temporal representations of uncertainty in spiking neural networks</article-title>. <source hwp:id="source-56">Advances in Neural Information Processing Systems</source>, pages <fpage>1</fpage>–<lpage>9</lpage>, <year>2014</year>.</citation></ref><ref id="c57" hwp:id="ref-57" hwp:rev-id="xref-ref-57-1"><label>[57]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.57" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-57"><string-name name-style="western" hwp:sortable="Schustek Philipp"><given-names>Philipp</given-names> <surname>Schustek</surname></string-name> and <string-name name-style="western" hwp:sortable="Moreno-bote Rubén"><given-names>Rubén</given-names> <surname>Moreno-bote</surname></string-name>. <article-title hwp:id="article-title-54">Human confidence judgments reflect reliability-based hierarchical integration of contextual information</article-title>. <source hwp:id="source-57">bioRxiv</source>, <year>2018</year>.</citation></ref><ref id="c58" hwp:id="ref-58" hwp:rev-id="xref-ref-58-1"><label>[58]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.58" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-58"><string-name name-style="western" hwp:sortable="Schütt Heiko H."><given-names>Heiko H.</given-names> <surname>Schütt</surname></string-name>, <string-name name-style="western" hwp:sortable="Harmeling Stefan"><given-names>Stefan</given-names> <surname>Harmeling</surname></string-name>, <string-name name-style="western" hwp:sortable="Macke Jakob H."><given-names>Jakob H.</given-names> <surname>Macke</surname></string-name>, and <string-name name-style="western" hwp:sortable="Wichmann Felix A."><given-names>Felix A.</given-names> <surname>Wichmann</surname></string-name>. <article-title hwp:id="article-title-55">Painfree and accurate Bayesian estimation of psychometric functions for (potentially) overdispersed data</article-title>. <source hwp:id="source-58">Vision Research</source>, <volume>122</volume>:<fpage>105</fpage>–<lpage>123</lpage>, <year>2016</year>.</citation></ref><ref id="c59" hwp:id="ref-59" hwp:rev-id="xref-ref-59-1"><label>[59]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.59" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-59"><string-name name-style="western" hwp:sortable="Stocker Alan A"><given-names>Alan A</given-names> <surname>Stocker</surname></string-name> and <string-name name-style="western" hwp:sortable="Simoncelli Eero P"><given-names>Eero P</given-names> <surname>Simoncelli</surname></string-name>. <article-title hwp:id="article-title-56">A Bayesian Model of Conditioned Perception</article-title>. <source hwp:id="source-59">Advances in Neural Infromation Processing Systems</source>, <volume>2007</volume>:<fpage>1409</fpage>–<lpage>1416</lpage>, <year>2007</year>.</citation></ref><ref id="c60" hwp:id="ref-60" hwp:rev-id="xref-ref-60-1 xref-ref-60-2"><label>[60]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.60" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-60"><string-name name-style="western" hwp:sortable="Tajima Chihiro I."><given-names>Chihiro I.</given-names> <surname>Tajima</surname></string-name>, <string-name name-style="western" hwp:sortable="Tajima Satohiro"><given-names>Satohiro</given-names> <surname>Tajima</surname></string-name>, <string-name name-style="western" hwp:sortable="Koida Kowa"><given-names>Kowa</given-names> <surname>Koida</surname></string-name>, <string-name name-style="western" hwp:sortable="Komatsu Hidehiko"><given-names>Hidehiko</given-names> <surname>Komatsu</surname></string-name>, <string-name name-style="western" hwp:sortable="Aihara Kazuyuki"><given-names>Kazuyuki</given-names> <surname>Aihara</surname></string-name>, and <string-name name-style="western" hwp:sortable="Suzuki Hideyuki"><given-names>Hideyuki</given-names> <surname>Suzuki</surname></string-name>. <article-title hwp:id="article-title-57">Population code dynamics in categorical perception</article-title>. <source hwp:id="source-60">Nature Scientific Reports</source>, <volume>5</volume>(<issue>August 2015</issue>):<fpage>1</fpage>–<lpage>13</lpage>, <year>2016</year>.</citation></ref><ref id="c61" hwp:id="ref-61" hwp:rev-id="xref-ref-61-1 xref-ref-61-2 xref-ref-61-3"><label>[61]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.61" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-61"><string-name name-style="western" hwp:sortable="Tajima Satohiro"><given-names>Satohiro</given-names> <surname>Tajima</surname></string-name>, <string-name name-style="western" hwp:sortable="Koida Kowa"><given-names>Kowa</given-names> <surname>Koida</surname></string-name>, <string-name name-style="western" hwp:sortable="Tajima Chihiro I."><given-names>Chihiro I.</given-names> <surname>Tajima</surname></string-name>, <string-name name-style="western" hwp:sortable="Suzuki Hideyuki"><given-names>Hideyuki</given-names> <surname>Suzuki</surname></string-name>, <string-name name-style="western" hwp:sortable="Aihara Kazuyuki"><given-names>Kazuyuki</given-names> <surname>Aihara</surname></string-name>, and <string-name name-style="western" hwp:sortable="Komatsu Hidehiko"><given-names>Hidehiko</given-names> <surname>Komatsu</surname></string-name>. <article-title hwp:id="article-title-58">Task-dependent recurrent dynamics in visual cortex</article-title>. <source hwp:id="source-61">eLife</source>, <volume>6</volume>:<fpage>1</fpage>–<lpage>27</lpage>, <year>2017</year>.</citation></ref><ref id="c62" hwp:id="ref-62" hwp:rev-id="xref-ref-62-1 xref-ref-62-2"><label>[62]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.62" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-62"><string-name name-style="western" hwp:sortable="Talluri Bharath Chandra"><given-names>Bharath Chandra</given-names> <surname>Talluri</surname></string-name>, <string-name name-style="western" hwp:sortable="Urai Anne E"><given-names>Anne E</given-names> <surname>Urai</surname></string-name>, <string-name name-style="western" hwp:sortable="Tsetsos Konstantinos"><given-names>Konstantinos</given-names> <surname>Tsetsos</surname></string-name>, <string-name name-style="western" hwp:sortable="Usher Marius"><given-names>Marius</given-names> <surname>Usher</surname></string-name>, and <string-name name-style="western" hwp:sortable="Donner Tobias H"><given-names>Tobias H</given-names> <surname>Donner</surname></string-name>. <article-title hwp:id="article-title-59">Confirmation Bias through Selective Overweighting of Choice-Consistent Evidence Report</article-title>. <source hwp:id="source-62">Current Biology</source>, pages <fpage>1</fpage>–<lpage>8</lpage>, <year>2018</year>.</citation></ref><ref id="c63" hwp:id="ref-63" hwp:rev-id="xref-ref-63-1"><label>[63]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.63" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-63"><string-name name-style="western" hwp:sortable="Talluri Bharath Chandra"><given-names>Bharath Chandra</given-names> <surname>Talluri</surname></string-name>, <string-name name-style="western" hwp:sortable="Urai Anne E."><given-names>Anne E.</given-names> <surname>Urai</surname></string-name>, <string-name name-style="western" hwp:sortable="Bronfman Zohar Z."><given-names>Zohar Z.</given-names> <surname>Bronfman</surname></string-name>, <string-name name-style="western" hwp:sortable="Brezis Noam"><given-names>Noam</given-names> <surname>Brezis</surname></string-name>, <string-name name-style="western" hwp:sortable="Tsetsos Konstantinos"><given-names>Konstantinos</given-names> <surname>Tsetsos</surname></string-name>, <string-name name-style="western" hwp:sortable="Usher Marius"><given-names>Marius</given-names> <surname>Usher</surname></string-name>, and <string-name name-style="western" hwp:sortable="Donner Tobias H."><given-names>Tobias H.</given-names> <surname>Donner</surname></string-name>. <article-title hwp:id="article-title-60">Choices change the temporal weighting of decision evidence</article-title>. <source hwp:id="source-63">bioRxiv</source>, <year>2020</year>.</citation></ref><ref id="c64" hwp:id="ref-64" hwp:rev-id="xref-ref-64-1 xref-ref-64-2 xref-ref-64-3 xref-ref-64-4"><label>[64]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.64" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-64"><string-name name-style="western" hwp:sortable="Tsetsos Konstantinos"><given-names>Konstantinos</given-names> <surname>Tsetsos</surname></string-name>, <string-name name-style="western" hwp:sortable="Gao Juan"><given-names>Juan</given-names> <surname>Gao</surname></string-name>, <string-name name-style="western" hwp:sortable="McClelland James L."><given-names>James L.</given-names> <surname>McClelland</surname></string-name>, and <string-name name-style="western" hwp:sortable="Usher Marius"><given-names>Marius</given-names> <surname>Usher</surname></string-name>. <article-title hwp:id="article-title-61">Using time-varying evidence to test models of decision dynamics: Bounded diffusion vs. The leaky competing accumulator model</article-title>. <source hwp:id="source-64">Frontiers in Neuroscience</source>, <volume>6</volume>(<issue>JUN</issue>):<fpage>1</fpage>–<lpage>17</lpage>, <year>2012</year>.</citation></ref><ref id="c65" hwp:id="ref-65" hwp:rev-id="xref-ref-65-1"><label>[65]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.65" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-65"><string-name name-style="western" hwp:sortable="Tversky Amos"><given-names>Amos</given-names> <surname>Tversky</surname></string-name> and <string-name name-style="western" hwp:sortable="Khaneman Daniel"><given-names>Daniel</given-names> <surname>Khaneman</surname></string-name>. <article-title hwp:id="article-title-62">Judgment under uncertainty: Heuristics and biases</article-title>. <source hwp:id="source-65">Science</source>, <volume>185</volume>:<fpage>1124</fpage>—-<lpage>1131</lpage>, <year>1974</year>.</citation></ref><ref id="c66" hwp:id="ref-66" hwp:rev-id="xref-ref-66-1"><label>[66]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.66" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-66"><string-name name-style="western" hwp:sortable="Urai Anne E."><given-names>Anne E.</given-names> <surname>Urai</surname></string-name>, <string-name name-style="western" hwp:sortable="de Gee Jan Willem"><given-names>Jan Willem</given-names> <surname>de Gee</surname></string-name>, <string-name name-style="western" hwp:sortable="Tsetsos Konstantinos"><given-names>Konstantinos</given-names> <surname>Tsetsos</surname></string-name>, and <string-name name-style="western" hwp:sortable="Donner Tobias H."><given-names>Tobias H.</given-names> <surname>Donner</surname></string-name>. <article-title hwp:id="article-title-63">Choice History Biases Subsequent Evidence Accumulation</article-title>. <source hwp:id="source-66">eLife</source>, <volume>8</volume>(<issue>e46331</issue>), <year>2019</year>.</citation></ref><ref id="c67" hwp:id="ref-67" hwp:rev-id="xref-ref-67-1 xref-ref-67-2"><label>[67]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.67" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-67"><string-name name-style="western" hwp:sortable="Usher Marius"><given-names>Marius</given-names> <surname>Usher</surname></string-name> and <string-name name-style="western" hwp:sortable="McClelland James L."><given-names>James L.</given-names> <surname>McClelland</surname></string-name>. <article-title hwp:id="article-title-64">The Time Course of Perceptual Choice: The Leaky, Competing Accumulator Model</article-title>. <source hwp:id="source-67">Psychological Review</source>, <volume>108</volume>(<issue>2</issue>):<fpage>550</fpage>–<lpage>592</lpage>, <year>2001</year>.</citation></ref><ref id="c68" hwp:id="ref-68" hwp:rev-id="xref-ref-68-1"><label>[68]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.68" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-68"><string-name name-style="western" hwp:sortable="Wald A."><given-names>A.</given-names> <surname>Wald</surname></string-name> and <string-name name-style="western" hwp:sortable="Wolfowitz J."><given-names>J.</given-names> <surname>Wolfowitz</surname></string-name>. <article-title hwp:id="article-title-65">Optimum Character of the Sequential Probability Ratio Test</article-title>. <source hwp:id="source-68">The Annals of Mathematical Statistics</source>, <volume>19</volume>(<issue>3</issue>):<fpage>326</fpage>–<lpage>339</lpage>, <year>1948</year>.</citation></ref><ref id="c69" hwp:id="ref-69" hwp:rev-id="xref-ref-69-1 xref-ref-69-2"><label>[69]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.69" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-69"><string-name name-style="western" hwp:sortable="Walker Edgar Y"><given-names>Edgar Y</given-names> <surname>Walker</surname></string-name>, <string-name name-style="western" hwp:sortable="Cotton R. James"><given-names>R. James</given-names> <surname>Cotton</surname></string-name>, <string-name name-style="western" hwp:sortable="Ma Wei Ji"><given-names>Wei Ji</given-names> <surname>Ma</surname></string-name>, and <string-name name-style="western" hwp:sortable="Tolias Andreas S"><given-names>Andreas S</given-names> <surname>Tolias</surname></string-name>. <article-title hwp:id="article-title-66">A neural basis of probabilistic computation in visual cortex</article-title>. <source hwp:id="source-69">Nature Neuroscience</source>, <volume>23</volume>:<fpage>122</fpage>–<lpage>129</lpage>, <year>2019</year>.</citation></ref><ref id="c70" hwp:id="ref-70" hwp:rev-id="xref-ref-70-1"><label>[70]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.70" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-70"><string-name name-style="western" hwp:sortable="Wang Xiao-Jing"><given-names>Xiao-Jing</given-names> <surname>Wang</surname></string-name>. <article-title hwp:id="article-title-67">Probabilistic Decision Making by Slow Reverberation in Cortical Circuits</article-title>. <source hwp:id="source-70">Neuron2</source>, <volume>36</volume>:<fpage>955</fpage>–<lpage>968</lpage>, <year>2002</year>.</citation></ref><ref id="c71" hwp:id="ref-71" hwp:rev-id="xref-ref-71-1"><label>[71]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.71" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-71"><string-name name-style="western" hwp:sortable="Wang Xiao Jing"><given-names>Xiao Jing</given-names> <surname>Wang</surname></string-name>. <article-title hwp:id="article-title-68">Decision Making in Recurrent Neuronal Circuits</article-title>. <source hwp:id="source-71">Neuron</source>, <volume>60</volume>(<issue>2</issue>):<fpage>215</fpage>–<lpage>234</lpage>, <year>2008</year>.</citation></ref><ref id="c72" hwp:id="ref-72" hwp:rev-id="xref-ref-72-1"><label>[72]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.72" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-72"><string-name name-style="western" hwp:sortable="Wilming Niklas"><given-names>Niklas</given-names> <surname>Wilming</surname></string-name>, <string-name name-style="western" hwp:sortable="Murphy Peter R."><given-names>Peter R.</given-names> <surname>Murphy</surname></string-name>, <string-name name-style="western" hwp:sortable="Meyniel Florent"><given-names>Florent</given-names> <surname>Meyniel</surname></string-name>, and <string-name name-style="western" hwp:sortable="Donner Tobias H."><given-names>Tobias H.</given-names> <surname>Donner</surname></string-name>. <article-title hwp:id="article-title-69">Large-scale dynamics of perceptual decision information across human cortex</article-title>. <source hwp:id="source-72">Nature Communications</source>, <volume>11</volume> (<issue>1</issue>):<fpage>1</fpage>–<lpage>14</lpage>, <year>2020</year>.</citation></ref><ref id="c73" hwp:id="ref-73" hwp:rev-id="xref-ref-73-1 xref-ref-73-2"><label>[73]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.73" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-73"><string-name name-style="western" hwp:sortable="Wimmer Klaus"><given-names>Klaus</given-names> <surname>Wimmer</surname></string-name>, <string-name name-style="western" hwp:sortable="Compte Albert"><given-names>Albert</given-names> <surname>Compte</surname></string-name>, <string-name name-style="western" hwp:sortable="Roxin Alex"><given-names>Alex</given-names> <surname>Roxin</surname></string-name>, <string-name name-style="western" hwp:sortable="Peixoto Diogo"><given-names>Diogo</given-names> <surname>Peixoto</surname></string-name>, <string-name name-style="western" hwp:sortable="Renart Alfonso"><given-names>Alfonso</given-names> <surname>Renart</surname></string-name>, and <string-name name-style="western" hwp:sortable="De Rocha Jaime"><given-names>Jaime</given-names> <surname>De Rocha</surname></string-name>. <article-title hwp:id="article-title-70">Sensory integration dynamics in a hierarchical network explains choice probabilities in cortical area MT</article-title>. <source hwp:id="source-73">Nature Communications</source>, <volume>6</volume>(<issue>6177</issue>):<fpage>1</fpage>–<lpage>13</lpage>, <year>2015</year>.</citation></ref><ref id="c74" hwp:id="ref-74" hwp:rev-id="xref-ref-74-1 xref-ref-74-2 xref-ref-74-3"><label>[74]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.74" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-74"><string-name name-style="western" hwp:sortable="Wong Kong-fatt"><given-names>Kong-fatt</given-names> <surname>Wong</surname></string-name> and <string-name name-style="western" hwp:sortable="Wang Xiao-jing"><given-names>Xiao-jing</given-names> <surname>Wang</surname></string-name>. <article-title hwp:id="article-title-71">A Recurrent Network Mechanism of Time Integration in Perceptual Decisions</article-title>. <source hwp:id="source-74">The Journal of Neuroscience</source>, <volume>26</volume>(<issue>4</issue>):<fpage>1314</fpage>–<lpage>1328</lpage>, <year>2006</year>.</citation></ref><ref id="c75" hwp:id="ref-75" hwp:rev-id="xref-ref-75-1 xref-ref-75-2 xref-ref-75-3"><label>[75]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.75" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-75"><string-name name-style="western" hwp:sortable="Wong Kong Fatt"><given-names>Kong Fatt</given-names> <surname>Wong</surname></string-name>, <string-name name-style="western" hwp:sortable="Huk Alexander C."><given-names>Alexander C.</given-names> <surname>Huk</surname></string-name>, <string-name name-style="western" hwp:sortable="Shadlen Michael N."><given-names>Michael N.</given-names> <surname>Shadlen</surname></string-name>, and <string-name name-style="western" hwp:sortable="Wang Xiao Jing"><given-names>Xiao Jing</given-names> <surname>Wang</surname></string-name>. <article-title hwp:id="article-title-72">Neural circuit dynamics underlying accumulation of time-varying evidence during perceptual decision making</article-title>. <source hwp:id="source-75">Frontiers in Computational Neuroscience</source>, <volume>1</volume>(<issue>NOV</issue>):<fpage>1</fpage>–<lpage>11</lpage>, <year>2007</year>.</citation></ref><ref id="c76" hwp:id="ref-76" hwp:rev-id="xref-ref-76-1"><label>[76]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.76" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-76"><string-name name-style="western" hwp:sortable="Wyart Valentin"><given-names>Valentin</given-names> <surname>Wyart</surname></string-name>, <string-name name-style="western" hwp:sortable="De Gardelle Vincent"><given-names>Vincent</given-names> <surname>De Gardelle</surname></string-name>, <string-name name-style="western" hwp:sortable="Scholl Jacqueline"><given-names>Jacqueline</given-names> <surname>Scholl</surname></string-name>, and <string-name name-style="western" hwp:sortable="Summerfield Christopher"><given-names>Christopher</given-names> <surname>Summerfield</surname></string-name>. <article-title hwp:id="article-title-73">Rhythmic Fluctuations in Evidence Accumulation during Decision Making in the Human Brain</article-title>. <source hwp:id="source-76">Neuron</source>, <volume>76</volume>(<issue>4</issue>):<fpage>847</fpage>–<lpage>858</lpage>, <year>2012</year>.</citation></ref><ref id="c77" hwp:id="ref-77" hwp:rev-id="xref-ref-77-1 xref-ref-77-2"><label>[77]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.77" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-77"><string-name name-style="western" hwp:sortable="Yates Jacob L."><given-names>Jacob L.</given-names> <surname>Yates</surname></string-name>, <string-name name-style="western" hwp:sortable="Park Il Memming"><given-names>Il Memming</given-names> <surname>Park</surname></string-name>, <string-name name-style="western" hwp:sortable="Katz Leor N."><given-names>Leor N.</given-names> <surname>Katz</surname></string-name>, <string-name name-style="western" hwp:sortable="Pillow Jonathan W."><given-names>Jonathan W.</given-names> <surname>Pillow</surname></string-name>, and <string-name name-style="western" hwp:sortable="Huk Alexander C."><given-names>Alexander C.</given-names> <surname>Huk</surname></string-name>. <article-title hwp:id="article-title-74">Functional dissection of signal and noise in MT and LIP during decision-making</article-title>. <source hwp:id="source-77">Nature neuroscience</source>, <volume>20</volume>(<issue>9</issue>):<fpage>1285</fpage>–<lpage>1292</lpage>, <year>2017</year>.</citation></ref><ref id="c78" hwp:id="ref-78" hwp:rev-id="xref-ref-78-1 xref-ref-78-2 xref-ref-78-3"><label>[78]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.78" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-78"><string-name name-style="western" hwp:sortable="Yuille Alan"><given-names>Alan</given-names> <surname>Yuille</surname></string-name> and <string-name name-style="western" hwp:sortable="Kersten Daniel"><given-names>Daniel</given-names> <surname>Kersten</surname></string-name>. <article-title hwp:id="article-title-75">Vision as Bayesian inference: analysis by synthesis?</article-title> <source hwp:id="source-78">Trends in Cognitive Sciences</source>, <volume>10</volume>(<issue>7</issue>):<fpage>301</fpage>–<lpage>308</lpage>, <year>2006</year>.</citation></ref><ref id="c79" hwp:id="ref-79" hwp:rev-id="xref-ref-79-1"><label>[79]</label><citation publication-type="journal" citation-type="journal" ref:id="440321v5.79" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-79"><string-name name-style="western" hwp:sortable="Zylberberg Ariel"><given-names>Ariel</given-names> <surname>Zylberberg</surname></string-name>, <string-name name-style="western" hwp:sortable="Wolpert Daniel M"><given-names>Daniel M</given-names> <surname>Wolpert</surname></string-name>, and <string-name name-style="western" hwp:sortable="Shadlen Michael N"><given-names>Michael N</given-names> <surname>Shadlen</surname></string-name>. <article-title hwp:id="article-title-76">Counterfactual reasoning underlies the learning of priors in decision making</article-title>. <source hwp:id="source-79">Neuron</source>, <volume>99</volume>:<fpage>1</fpage>–<lpage>15</lpage>, <year>2018</year>.</citation></ref></ref-list></back></article>
