<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/2021.05.29.446289</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;2021.05.29.446289</article-id><article-id pub-id-type="other" hwp:sub-type="slug">2021.05.29.446289</article-id><article-id pub-id-type="other" hwp:sub-type="atom-slug">2021.05.29.446289</article-id><article-id pub-id-type="other" hwp:sub-type="tag">2021.05.29.446289</article-id><article-version>1.4</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Neuroscience" hwp:journal="biorxiv"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">A connectomic study of a petascale fragment of human cerebral cortex</article-title></title-group><author-notes hwp:id="author-notes-1"><fn fn-type="equal" id="n1" hwp:id="fn-1" hwp:rev-id="xref-fn-1-1 xref-fn-1-2"><label>%</label><p hwp:id="p-1">Equal contribution</p></fn><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1 xref-corresp-1-2"><label>*</label>Corresponding Authors: <email hwp:id="email-1">jeff@mcb.harvard.edu</email>; <email hwp:id="email-2">viren@google.com</email></corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-9008-3783</contrib-id><name name-style="western" hwp:sortable="Shapson-Coe Alexander"><surname>Shapson-Coe</surname><given-names>Alexander</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref><xref ref-type="fn" rid="n1" hwp:id="xref-fn-1-1" hwp:rel-id="fn-1">%</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0001-9008-3783"/></contrib><contrib contrib-type="author" hwp:id="contrib-2"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-3480-2744</contrib-id><name name-style="western" hwp:sortable="Januszewski Michał"><surname>Januszewski</surname><given-names>Michał</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref><xref ref-type="fn" rid="n1" hwp:id="xref-fn-1-2" hwp:rel-id="fn-1">%</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-3480-2744"/></contrib><contrib contrib-type="author" hwp:id="contrib-3"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-9677-6932</contrib-id><name name-style="western" hwp:sortable="Berger Daniel R."><surname>Berger</surname><given-names>Daniel R.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">1</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-9677-6932"/></contrib><contrib contrib-type="author" hwp:id="contrib-4"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-7159-2731</contrib-id><name name-style="western" hwp:sortable="Pope Art"><surname>Pope</surname><given-names>Art</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-1" hwp:rel-id="aff-3">3</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-7159-2731"/></contrib><contrib contrib-type="author" hwp:id="contrib-5"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-0075-1237</contrib-id><name name-style="western" hwp:sortable="Wu Yuelong"><surname>Wu</surname><given-names>Yuelong</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-3" hwp:rel-id="aff-1">1</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-0075-1237"/></contrib><contrib contrib-type="author" hwp:id="contrib-6"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-0995-5471</contrib-id><name name-style="western" hwp:sortable="Blakely Tim"><surname>Blakely</surname><given-names>Tim</given-names></name><xref ref-type="aff" rid="a4" hwp:id="xref-aff-4-1" hwp:rel-id="aff-4">4</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-0995-5471"/></contrib><contrib contrib-type="author" hwp:id="contrib-7"><name name-style="western" hwp:sortable="Schalek Richard L."><surname>Schalek</surname><given-names>Richard L.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-4" hwp:rel-id="aff-1">1</xref></contrib><contrib contrib-type="author" hwp:id="contrib-8"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-6193-4454</contrib-id><name name-style="western" hwp:sortable="Li Peter H."><surname>Li</surname><given-names>Peter H.</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-2" hwp:rel-id="aff-3">3</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0001-6193-4454"/></contrib><contrib contrib-type="author" hwp:id="contrib-9"><name name-style="western" hwp:sortable="Wang Shuohong"><surname>Wang</surname><given-names>Shuohong</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-5" hwp:rel-id="aff-1">1</xref></contrib><contrib contrib-type="author" hwp:id="contrib-10"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-8453-7961</contrib-id><name name-style="western" hwp:sortable="Maitin-Shepard Jeremy"><surname>Maitin-Shepard</surname><given-names>Jeremy</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-3" hwp:rel-id="aff-3">3</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0001-8453-7961"/></contrib><contrib contrib-type="author" hwp:id="contrib-11"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-4059-1290</contrib-id><name name-style="western" hwp:sortable="Karlupia Neha"><surname>Karlupia</surname><given-names>Neha</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-6" hwp:rel-id="aff-1">1</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-4059-1290"/></contrib><contrib contrib-type="author" hwp:id="contrib-12"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-2352-319X</contrib-id><name name-style="western" hwp:sortable="Dorkenwald Sven"><surname>Dorkenwald</surname><given-names>Sven</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-4" hwp:rel-id="aff-3">3</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-2352-319X"/></contrib><contrib contrib-type="author" hwp:id="contrib-13"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0327-7377</contrib-id><name name-style="western" hwp:sortable="Sjostedt Evelina"><surname>Sjostedt</surname><given-names>Evelina</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-7" hwp:rel-id="aff-1">1</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-0327-7377"/></contrib><contrib contrib-type="author" hwp:id="contrib-14"><name name-style="western" hwp:sortable="Leavitt Laramie"><surname>Leavitt</surname><given-names>Laramie</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-5" hwp:rel-id="aff-3">3</xref></contrib><contrib contrib-type="author" hwp:id="contrib-15"><name name-style="western" hwp:sortable="Lee Dongil"><surname>Lee</surname><given-names>Dongil</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-8" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a5" hwp:id="xref-aff-5-1" hwp:rel-id="aff-5">5</xref></contrib><contrib contrib-type="author" hwp:id="contrib-16"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-2213-7430</contrib-id><name name-style="western" hwp:sortable="Bailey Luke"><surname>Bailey</surname><given-names>Luke</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-9" hwp:rel-id="aff-1">1</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-2213-7430"/></contrib><contrib contrib-type="author" hwp:id="contrib-17"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-9787-7703</contrib-id><name name-style="western" hwp:sortable="Fitzmaurice Angerica"><surname>Fitzmaurice</surname><given-names>Angerica</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-10" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a6" hwp:id="xref-aff-6-1" hwp:rel-id="aff-6">6</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0001-9787-7703"/></contrib><contrib contrib-type="author" hwp:id="contrib-18"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-0412-6746</contrib-id><name name-style="western" hwp:sortable="Kar Rohin"><surname>Kar</surname><given-names>Rohin</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-11" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a6" hwp:id="xref-aff-6-2" hwp:rel-id="aff-6">6</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-0412-6746"/></contrib><contrib contrib-type="author" hwp:id="contrib-19"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-1533-0769</contrib-id><name name-style="western" hwp:sortable="Field Benjamin"><surname>Field</surname><given-names>Benjamin</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-12" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a6" hwp:id="xref-aff-6-3" hwp:rel-id="aff-6">6</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-1533-0769"/></contrib><contrib contrib-type="author" hwp:id="contrib-20"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-0348-2888</contrib-id><name name-style="western" hwp:sortable="Wu Hank"><surname>Wu</surname><given-names>Hank</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-13" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a6" hwp:id="xref-aff-6-4" hwp:rel-id="aff-6">6</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-0348-2888"/></contrib><contrib contrib-type="author" hwp:id="contrib-21"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-4039-5647</contrib-id><name name-style="western" hwp:sortable="Wagner-Carena Julian"><surname>Wagner-Carena</surname><given-names>Julian</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-14" hwp:rel-id="aff-1">1</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-4039-5647"/></contrib><contrib contrib-type="author" hwp:id="contrib-22"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-1993-612X</contrib-id><name name-style="western" hwp:sortable="Aley David"><surname>Aley</surname><given-names>David</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-15" hwp:rel-id="aff-1">1</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-1993-612X"/></contrib><contrib contrib-type="author" hwp:id="contrib-23"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-0614-2360</contrib-id><name name-style="western" hwp:sortable="Lau Joanna"><surname>Lau</surname><given-names>Joanna</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-16" hwp:rel-id="aff-1">1</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-0614-2360"/></contrib><contrib contrib-type="author" hwp:id="contrib-24"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-4176-8035</contrib-id><name name-style="western" hwp:sortable="Lin Zudi"><surname>Lin</surname><given-names>Zudi</given-names></name><xref ref-type="aff" rid="a7" hwp:id="xref-aff-7-1" hwp:rel-id="aff-7">7</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-4176-8035"/></contrib><contrib contrib-type="author" hwp:id="contrib-25"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-2329-5484</contrib-id><name name-style="western" hwp:sortable="Wei Donglai"><surname>Wei</surname><given-names>Donglai</given-names></name><xref ref-type="aff" rid="a7" hwp:id="xref-aff-7-2" hwp:rel-id="aff-7">7</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-2329-5484"/></contrib><contrib contrib-type="author" hwp:id="contrib-26"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-3620-2582</contrib-id><name name-style="western" hwp:sortable="Pfister Hanspeter"><surname>Pfister</surname><given-names>Hanspeter</given-names></name><xref ref-type="aff" rid="a7" hwp:id="xref-aff-7-3" hwp:rel-id="aff-7">7</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-3620-2582"/></contrib><contrib contrib-type="author" hwp:id="contrib-27"><name name-style="western" hwp:sortable="Peleg Adi"><surname>Peleg</surname><given-names>Adi</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-17" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a8" hwp:id="xref-aff-8-1" hwp:rel-id="aff-8">8</xref></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-28"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-1488-3505</contrib-id><name name-style="western" hwp:sortable="Jain Viren"><surname>Jain</surname><given-names>Viren</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-6" hwp:rel-id="aff-3">3</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-1488-3505"/></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-29"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0208-3212</contrib-id><name name-style="western" hwp:sortable="Lichtman Jeff W."><surname>Lichtman</surname><given-names>Jeff W.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-18" hwp:rel-id="aff-1">1</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-2" hwp:rel-id="corresp-1">*</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-0208-3212"/></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2 xref-aff-1-3 xref-aff-1-4 xref-aff-1-5 xref-aff-1-6 xref-aff-1-7 xref-aff-1-8 xref-aff-1-9 xref-aff-1-10 xref-aff-1-11 xref-aff-1-12 xref-aff-1-13 xref-aff-1-14 xref-aff-1-15 xref-aff-1-16 xref-aff-1-17 xref-aff-1-18"><label>1</label><institution hwp:id="institution-1">Dept. of Molecular and Cellular Biology, Center for Brain Science, Harvard U.</institution>, Cambridge, MA</aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1"><label>2</label><institution hwp:id="institution-2">Google Research</institution>, Zürich, <country>Switzerland</country></aff><aff id="a3" hwp:id="aff-3" hwp:rev-id="xref-aff-3-1 xref-aff-3-2 xref-aff-3-3 xref-aff-3-4 xref-aff-3-5 xref-aff-3-6"><label>3</label><institution hwp:id="institution-3">Google Research</institution>, Mountain View, CA</aff><aff id="a4" hwp:id="aff-4" hwp:rev-id="xref-aff-4-1"><label>4</label><institution hwp:id="institution-4">Google Research</institution>, Seattle, WA</aff><aff id="a5" hwp:id="aff-5" hwp:rev-id="xref-aff-5-1"><label>5</label><institution hwp:id="institution-5">Dept. of Bio and Brain Engineering, Korea Advanced Institute of Science and Technology</institution>, <country>Korea</country></aff><aff id="a6" hwp:id="aff-6" hwp:rev-id="xref-aff-6-1 xref-aff-6-2 xref-aff-6-3 xref-aff-6-4"><label>6</label><institution hwp:id="institution-6">Northeastern University</institution></aff><aff id="a7" hwp:id="aff-7" hwp:rev-id="xref-aff-7-1 xref-aff-7-2 xref-aff-7-3"><label>7</label><institution hwp:id="institution-7">School of Engineering and Applied Sciences, Harvard U.</institution>, Cambridge, MA</aff><aff id="a8" hwp:id="aff-8" hwp:rev-id="xref-aff-8-1"><label>8</label><institution hwp:id="institution-8">Google</institution>, Cambridge, MA</aff></contrib-group><pub-date pub-type="epub-original" date-type="pub" publication-format="electronic" hwp:start="2021"><year>2021</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2021-05-30T12:39:28-07:00">
    <day>30</day><month>5</month><year>2021</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2021-10-23T19:54:12-07:00">
    <day>23</day><month>10</month><year>2021</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2021-05-30T12:43:19-07:00">
    <day>30</day><month>5</month><year>2021</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2021-10-23T19:58:55-07:00">
    <day>23</day><month>10</month><year>2021</year>
  </pub-date><elocation-id>2021.05.29.446289</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2021-05-29"><day>29</day><month>5</month><year>2021</year></date>
<date date-type="rev-recd" hwp:start="2021-10-23"><day>23</day><month>10</month><year>2021</year></date>
<date date-type="accepted" hwp:start="2021-10-23"><day>23</day><month>10</month><year>2021</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2021</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="license-1"><p hwp:id="p-2">This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by-nc-nd/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></p></license></permissions><self-uri xlink:href="446289.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/external-links" xlink:role="external-links" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2021/pdf/2021.05.29.446289v3.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="446289.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2021/abstracts/2021.05.29.446289v3/2021.05.29.446289v3.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2021/fulltext/2021.05.29.446289v3/2021.05.29.446289v3.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-3">We acquired a rapidly preserved human surgical sample from the temporal lobe of the cerebral cortex. We stained a 1 mm<sup>3</sup> volume with heavy metals, embedded it in resin, cut more than 5000 slices at ∼30 nm and imaged these sections using a high-speed multibeam scanning electron microscope. We used computational methods to render the three-dimensional structure containing 57,216 cells, hundreds of millions of neurites and 133.7 million synaptic connections. The 1.4 petabyte electron microscopy volume, the segmented cells, cell parts, blood vessels, myelin, inhibitory and excitatory synapses, and 104 manually proofread cells are <underline>available to peruse online</underline>. Many <underline>interesting and unusual features</underline> were evident in this dataset. Glia outnumbered neurons 2:1 and oligodendrocytes were the most common cell type in the volume. Excitatory spiny neurons comprised 69% of the neuronal population, and excitatory synapses also were in the majority (76%). The synaptic drive onto spiny neurons was biased more strongly toward excitation (70%) than was the case for inhibitory interneurons (48%). Despite incompleteness of the automated segmentation caused by split and merge errors, we could automatically generate (and then validate) connections between most of the excitatory and inhibitory neuron types both within and between layers. In studying these neurons we found that deep layer excitatory cell types can be classified into new subsets, based on structural and connectivity differences, and that chandelier interneurons not only innervate excitatory neuron initial segments as previously described, but also each other’s initial segments. Furthermore, among the thousands of weak connections established on each neuron, there exist rarer highly powerful axonal inputs that establish multi-synaptic contacts (up to ∼20 synapses) with target neurons. Our analysis indicates that these strong inputs are specific, and allow small numbers of axons to have an outsized role in the activity of some of their postsynaptic partners.</p></abstract><counts><page-count count="95"/></counts><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-1">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta><notes hwp:id="notes-1"><notes notes-type="competing-interest-statement" hwp:id="notes-2"><title hwp:id="title-2">Competing Interest Statement</title><p hwp:id="p-4">The authors have declared no competing interest.</p></notes><fn-group content-type="external-links" hwp:id="fn-group-1"><fn fn-type="dataset" hwp:id="fn-2"><p hwp:id="p-5">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://h01-release.storage.googleapis.com/landing.html" ext-link-type="uri" xlink:href="https://h01-release.storage.googleapis.com/landing.html" hwp:id="ext-link-2">https://h01-release.storage.googleapis.com/landing.html</ext-link>
</p></fn><fn fn-type="dataset" hwp:id="fn-3"><p hwp:id="p-6">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/google/neuroglancer" ext-link-type="uri" xlink:href="https://github.com/google/neuroglancer" hwp:id="ext-link-3">https://github.com/google/neuroglancer</ext-link>
</p></fn><fn fn-type="dataset" hwp:id="fn-4"><p hwp:id="p-7">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/ashapsoncoe/CREST" ext-link-type="uri" xlink:href="https://github.com/ashapsoncoe/CREST" hwp:id="ext-link-4">https://github.com/ashapsoncoe/CREST</ext-link>
</p></fn><fn fn-type="dataset" hwp:id="fn-5"><p hwp:id="p-8">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/ashapsoncoe/h01" ext-link-type="uri" xlink:href="https://github.com/ashapsoncoe/h01" hwp:id="ext-link-5">https://github.com/ashapsoncoe/h01</ext-link>
</p></fn><fn fn-type="dataset" hwp:id="fn-6"><p hwp:id="p-9">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://storage.googleapis.com/h01-release/data/20210601/svg/connections_I.svg" ext-link-type="uri" xlink:href="https://storage.googleapis.com/h01-release/data/20210601/svg/connections_I.svg" hwp:id="ext-link-6">https://storage.googleapis.com/h01-release/data/20210601/svg/connections_I.svg</ext-link>
</p></fn><fn fn-type="dataset" hwp:id="fn-7"><p hwp:id="p-10">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://storage.googleapis.com/h01-release/data/20210601/svg/connections_E.svg" ext-link-type="uri" xlink:href="https://storage.googleapis.com/h01-release/data/20210601/svg/connections_E.svg" hwp:id="ext-link-7">https://storage.googleapis.com/h01-release/data/20210601/svg/connections_E.svg</ext-link>
</p></fn><fn fn-type="dataset" hwp:id="fn-8"><p hwp:id="p-11">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://www.youtube.com/watch?v=g5r3OcChnRg&amp;feature=youtu.be" ext-link-type="uri" xlink:href="https://www.youtube.com/watch?v=g5r3OcChnRg&amp;feature=youtu.be" hwp:id="ext-link-8">https://www.youtube.com/watch?v=g5r3OcChnRg&amp;feature=youtu.be</ext-link>
</p></fn><fn fn-type="dataset" hwp:id="fn-9"><p hwp:id="p-12">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://www.youtube.com/watch?v=vg2wT_36jmA&amp;feature=youtu.be" ext-link-type="uri" xlink:href="https://www.youtube.com/watch?v=vg2wT_36jmA&amp;feature=youtu.be" hwp:id="ext-link-9">https://www.youtube.com/watch?v=vg2wT_36jmA&amp;feature=youtu.be</ext-link>
</p></fn></fn-group></notes></front><body><sec id="s1" hwp:id="sec-1"><title hwp:id="title-3">Introduction</title><p hwp:id="p-13">While the functions carried out by most of the vital organs in humans are not remarkably different when compared to other animals, the human brain clearly separates us from the rest of life on the planet. It is a vastly complicated tissue, and to date, little is known about its cellular microstructure, and in particular its synaptic circuits. These circuits underlie the unparalleled capabilities of the human mind, and when disrupted, likely underlie incurable disorders of human brain function. One critical barrier that has prevented detailed knowledge of the cells and circuits of the human brain has been the access to high quality human brain tissue. Organ biopsies provide valuable information in many human organ systems, but biopsies are rarely done in the brain except to examine or excise neoplastic masses, and hence, most of them are of little value for the investigation of human brain structure. Moreover, for many organ systems, tissue from model organisms are useful for human disease: a mouse liver or lung can provide insights into human pathophysiology. The human brain is different. We don’t have many good models of cognitive and developmental disorders (although this may be changing with genetic manipulation of non-human primates <sup><xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">1</xref></sup>). Also, the human brain is clearly not the same as a mouse’s brain, and if we go by functional repertoire, humans are dramatically different from other primates. We therefore must find ways to explore human brain tissue per se. One attempt has been to use brain organoids made from human cells. This is certainly a promising field <sup><xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">2</xref>–<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">4</xref></sup> but at present they do not approximate brain tissue architectonics (e.g., cortical layers are not present) nor do they have circuits that resemble those in the human brain. An alternative to organoids is the direct approach: use state-of-the-art tools to map cells and circuits from human specimens. Human specimens are available, owing to neurosurgical interventions for neurological conditions where the cortex is discarded or destroyed, because it obstructs access. Human tissue that is a byproduct of neurosurgical procedures on patients can be leveraged to understand normal, and perhaps disordered human neural circuits. One source of such samples are individuals with drug-resistant epilepsy. These patients are sometimes treated by invasive surgical extirpation of the focus site determined by EEG <sup><xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">5</xref></sup>. The most common type of focal epilepsy occurs in the medial part of the temporal lobe, and when these are treated via neurosurgery, it is by unilateral resection of medial structures often including the hippocampus. Medial structure access is usually by transection through the overlying temporal cortex, and significant volumes of temporal lobe (approaching one half a cubic cm) are sometimes removed. The number of patients with drug-resistant epilepsy is large (in the US, about 750,000 patients) but very few (0.2%) undergo epilepsy surgery per year (Natl. Assoc. of Epilepsy Centers, 2014). Nonetheless, 1,500 patients per year in the US potentially could provide tissue.</p><p hwp:id="p-14">Here we describe such a sample, a cubic millimeter in volume, that extends through all cortical layers which we imaged at the ultrastructural level with serial high-throughput electron microscopy, and analyzed with computational approaches. The acquisition of digital human brain tissue at this large scale and this fine resolution, enables not only access to neuronal circuitry comprising thousands of neurons and millions of synapses, but such volume microscopy also provides a clear view of all the other tissue elements that comprise human brain matter including all glial cells, the blood vasculature, and the relations between these various cell types. A wide range of questions related to human brain biology are thus open to scrutiny from a single sample. Because the dataset is large and incompletely scrutinized, to aid in its analysis we are <underline>sharing all of the data online</underline>.</p></sec><sec id="s2" hwp:id="sec-2"><title hwp:id="title-4">Results</title><p hwp:id="p-15">The sample we analyzed is from an anonymized 45 year old patient with drug-resistant epilepsy who had a left hippocampal resection via the anterior temporal lobe at Massachusetts General Hospital, Boston, MA. Traditional neuropathology showed that the ablated cortex was not abnormal, but the underlying hippocampus was sclerotic with neuron loss, as is typical in such epilepsy patients.</p><p hwp:id="p-16">We ran the resected temporal lobe fragment (superficial to the hippocampus) through a pipeline of steps. We used rapid immersion fixation for excellent preservation of ultrastructure. The tissue was further preserved and stained with osmium and other heavy metals using a ROTO staining protocol <sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">6</xref></sup>. The sample was then embedded in a resin (epon) block and trimmed. Using an automatic tape-collecting ultramicrotome (ATUM; <sup><xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">7</xref></sup>) we sectioned 5,292 sections at a section thickness that averaged 33 nm (range 30-40 nm) and imaged with a multibeam scanning electron microscope (<bold><xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Fig. 1</xref></bold>). The images were acquired with pixels that were 4 x 4 nm<sup>2</sup>. The raw data size was up to 350 GB per section due to necessary overlap at the edges of the tiles, or for the entire set of sections ∼2.1 petabytes (PB). While the scope was acquiring images, a custom-built workflow manager assessed each tile for quality and flagged problems. The total throughput of the image acquisition ranged from 125 million (M) pixels per second to 190 M pixels per second. The majority of the data was acquired at 190 M pixels per second. The total imaging time for the 1 mm<sup>3</sup> sample was 326 days.</p><fig id="fig1" position="float" orientation="portrait" fig-type="figure" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1.</label><caption hwp:id="caption-1"><title hwp:id="title-5">Image acquisition for the human brain sample.</title><p hwp:id="p-17">A fresh surgical cerebral cortex sample was rapidly preserved, then stained, embedded in resin, and sectioned. More than 5000 sequential ∼30 nm sections were collected on tape using an ATUM (upper left panel). Yellow box shows the site where the brain sample is cut with the diamond knife and thin sections are collected onto the tape. The tape was then cut into strips and imaged in a multibeam scanning electron microscope (mSEM). This large machine (see middle panel with person on chair as reference) uses 61 beams that image a hexagonal area of about ∼10,000 μm<sup>2</sup> simultaneously (see upper right). For each thin section, all the resulting tiles are then stitched together. One such stitched section is shown (bottom). This section is about 4 mm<sup>2</sup> in area and was imaged with 4 x 4 nm<sup>2</sup> pixels (see image of synapse at lower right). Given the necessity of some overlap between the stitched tiles, this single section required the collection of more than 300 GB of data.</p></caption><graphic xlink:href="446289v4_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-18">The acquired image data was then re-composed into three-dimensional cellular objects from which all the neuronal and glial elements could be itemized. The neurons in the volume and the processes of neurons passing through the volume were then rendered and their synapses identified to give rise to the connectomic reconstruction. This entire compute-intensive process consisted of a series of largely automated workflows (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Fig. 2</xref>,</bold> and see Methods). The raw acquired image tiles were first stitched together and coarsely aligned by using microscope stage coordinates, semi-automated feature correspondences, and image patch cross-correlations to relax an elastic triangular mesh of each tile and each section (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Fig. 2A</xref></bold>, left) <sup><xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">8</xref></sup>. A fine-scale refining alignment based on optical flow between neighboring sections removed remaining drift and jitter from the volume (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Fig. 2A</xref></bold>, center and right). From a total of 247 M tiles (2.1 PB), 196 M tiles containing cortex (1.7 PB) were stitched, aligned, and ultimately segmented, creating a unified ∼1.4 PB human cerebral cortex image volume.</p><fig id="fig2" position="float" orientation="portrait" fig-type="figure" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3 xref-fig-2-4 xref-fig-2-5 xref-fig-2-6 xref-fig-2-7 xref-fig-2-8 xref-fig-2-9 xref-fig-2-10 xref-fig-2-11 xref-fig-2-12 xref-fig-2-13 xref-fig-2-14"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2:</label><caption hwp:id="caption-2"><title hwp:id="title-6">Reconstruction pipeline overview.</title><p hwp:id="p-19"><bold>A:</bold> Fine-scale alignment with optical flow. Left: An XZ cross-section of the initial coarsely aligned subvolume exhibits drift and jitter. Center:Two adjacent XY sections z (green) and z-1 are overlaid to illustrate their misalignment. Image patch-based cross-correlation computes an XY flow field between them. Red and blue intensities, which indicate the respective horizontal and vertical flow components are used to warp one of the sections, improving their alignment (relax and warp overlay). Right: XZ view of the same subvolume with flow realignment applied. <bold>B:</bold> Example of sequential segmentation with an FFN. XY cross-sections illustrate the 3D segmentation process. Each yellow crosshair indicates the seed location for the next segment. <bold>C:</bold> FFN agglomeration. Left: Site between two adjacent base segments (white box in 2D, black box in 3D below) is a candidate agglomeration location. Center: FFN segmentation is seeded from points A and B independently. Right: If the resulting A and B segmentations are mutually consistent, the object pair is merged (below). <bold>D:</bold> Synapse detection and classification. Top: XY cross-section of EM image input to synapse detection model (left), and the resulting presynaptic (magenta) and postsynaptic (green) prediction masks (right). Bottom: cross-section of EM image (left) and presynaptic (magenta) and postsynaptic (green) object segmentation (right) inputs to excitatory versus inhibitory classification model. Right: <underline>3D render</underline> of a dendrite with predicted incoming excitatory (yellow) and inhibitory (blue) synaptic sites. <bold>E:</bold> Subcompartment prediction and merge error correction (<underline>link</underline>). Leftmost: a single reconstructed object with a merge error where axon and dendrite cross near each other. Left center: the object is converted to a reduced skeleton representation (blue). Right center: fields of view around a subset of skeleton nodes are input to a subcompartment classification model. Red nodes: predicted dendrite; blue nodes: predicted axon. The inconsistency in subcompartment predictions is detected, and the agglomeration graph is cut at the location that maximally improves subcompartment consistency. Rightmost: the separated axon and dendrite after applying the suggested cut.</p></caption><graphic xlink:href="446289v4_fig2" position="float" orientation="portrait" hwp:id="graphic-2"/></fig><p hwp:id="p-20">Reconstruction of the structure of every cell and process in the aligned volume proceeded via Flood-Filling Network (FFN) segmentation and agglomeration (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-4" hwp:rel-id="F2">Fig. 2B</xref> and <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-5" hwp:rel-id="F2">C</xref></bold>) <sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">9</xref></sup>. Multi-resolution FFN segmentation and oversegmentation consensus produced base segments (also known as supervoxels, <bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-6" hwp:rel-id="F2">Fig. 2B</xref></bold>) that were then agglomerated via FFN resegmentation followed by mutual consistency criteria to produce more complete reconstructed cells (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-7" hwp:rel-id="F2">Fig. 2C</xref></bold>). Synaptic connections were added by a pre- and postsynaptic masking model applied to EM image blocks (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-8" hwp:rel-id="F2">Fig. 2D</xref>,</bold> top), while the polarity of synapses (excitatory versus inhibitory) was predicted by a classification model that considered the EM imagery centered around each putative synapse, as well as the local pre- and postsynaptic neuron segment masks and whether or not the postsynaptic site was a dendritic spine (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-9" hwp:rel-id="F2">Fig. 2D</xref></bold>, bottom and right). A skeleton (“ball and stick”) representation was also automatically generated from the volumetric segmentation, and higher-dimensional embeddings were computed for skeleton nodes with the help of a self-supervised neural network model. Skeletons were then used for automated subcompartment classification, and embeddings for glial type identification.</p><p hwp:id="p-21">The agglomerated segmentation was further refined using subcompartment predictions (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-10" hwp:rel-id="F2">Fig. 2E</xref></bold>). A classification model predicted axon, dendrite, astrocyte, soma, cilium, and axon initial segment classes at skeleton node locations distributed throughout each cell<sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">10</xref></sup>. Occasional agglomeration errors produced merges between nearby objects, such as a passing axon and dendrite (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-11" hwp:rel-id="F2">Fig. 2E</xref></bold>, leftmost). We used subcompartment predictions to distinguish the two merged objects (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-12" hwp:rel-id="F2">Fig. 2E</xref></bold>, center right) and allow an automated cut to separate them (<bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-13" hwp:rel-id="F2">Fig. 2E</xref></bold>, rightmost). The final data set is provided with two different agglomerations: c2 agglomeration favors fewer breaks (and hence longer processes) but with a higher number of incorrect mergers and c3 agglomeration that is more coservative and has shorter fragments but fewer merge errors (both are available <underline>here</underline>).</p><p hwp:id="p-22">For analysis, the various forms of data have been made available in SQL databases that enable specific queries about the neuronal and synaptic circuit data. We wrote software to aid in these queries including modifications to <underline>Neuroglancer</underline> and a new program, <underline>CREST</underline>.</p><sec id="s2a" hwp:id="sec-3"><title hwp:id="title-7">Cellular and Macroscopic Organization</title><p hwp:id="p-23">We first analyzed the cellular and macroscopic organization of the brain sample (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Fig. 3</xref></bold>).</p><fig id="fig3" position="float" orientation="portrait" fig-type="figure" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3 xref-fig-3-4 xref-fig-3-5 xref-fig-3-6 xref-fig-3-7 xref-fig-3-8 xref-fig-3-9 xref-fig-3-10 xref-fig-3-11 xref-fig-3-12 xref-fig-3-13 xref-fig-3-14 xref-fig-3-15 xref-fig-3-16 xref-fig-3-17 xref-fig-3-18 xref-fig-3-19 xref-fig-3-20 xref-fig-3-21 xref-fig-3-22 xref-fig-3-23 xref-fig-3-24 xref-fig-3-25 xref-fig-3-26"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3:</label><caption hwp:id="caption-3"><title hwp:id="title-8">Distribution of cells, blood vessels and myelin in the sample.</title><p hwp:id="p-24">White lines indicate layer boundaries based on cell clustering. <bold>A</bold>: All 49,080 cell bodies of neurons and glia in the sample, colored by soma volume. <bold>B</bold>: Spiny neurons (putatively excitatory), colored by soma volume. <bold>C</bold>: Interneurons (few spines, putatively inhibitory), colored by soma volume. <bold>D</bold>: Astrocytes mostly tile but in some cases, arbors of nearby astrocytes interdigitate. <bold>E</bold>: Most of the oligodendrocytes in the volume. Note clustering along large blood vessels, especially in white matter. <bold>F</bold>: Cell bodies of microglia and oligodendrocyte precursor cells (OPCs). <bold>G</bold>: Blood vessels and the nuclei of the 8,136 associated cells (<underline>link</underline>). Inset shows a magnified view of the location of the individual cell types. <bold>H</bold>: Myelinated axons in the volume, color-coded by topological orientation. Most axons in white matter run in the perpendicular direction. Thick axon bundles run between white matter and cortex in the radial direction. In layer 1, a set of large-caliber myelinated axons runs tangentially through our slice, parallel to the pia. In layers 3-6 many myelinated axons also run in diagonal (tangential/perpendicular) directions.</p></caption><graphic xlink:href="446289v4_fig3" position="float" orientation="portrait" hwp:id="graphic-3"/></fig><p hwp:id="p-25">We manually identified all of the cell bodies in the data set (see <bold><xref ref-type="table" rid="tbls3" hwp:id="xref-table-wrap-3-1" hwp:rel-id="T3">Supplementary Table 3</xref></bold>). The cell census included 49,080 neurons and glia (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Fig. 3A</xref></bold>), and 8.1k blood vessel cells (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Fig. 3G</xref></bold>). The number of neurons in this human sample is ∼16k/1 mm<sup>3</sup>, many fold lower than the density of neurons in mouse cortex <sup><xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">11</xref>, <xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">12</xref></sup>. Simply by measuring the neuron and glial cell body cross-sectional areas colorized by size, the cortical layering was obvious (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-4" hwp:rel-id="F3">Fig. 3A</xref></bold>). Two regions that had a paucity of neurons (white matter at the left edge of the images in <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-5" hwp:rel-id="F3">Fig. 3</xref></bold>) and the most superficial layer (at the right edge of <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-6" hwp:rel-id="F3">Fig. 3A</xref></bold>) were populated mainly by glial cells whose cell body sizes were smaller than neurons (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-7" hwp:rel-id="F3">Fig. 3A</xref></bold>, blue). The largest cells (red) were mostly in a broad deep infragranular band (i.e., closer to the white matter) and a more superficial (supragranular) one. Because the cells were segmented into 3-dimensional objects, their appearance plus the ultrastructural features of somata allowed classification of the cells into types across layers. The largest cell somata belonged to spiny pyramidal neurons. These cells typically possess one large apical dendrite projecting to the most superficial layer (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-8" hwp:rel-id="F3">Fig. 3B</xref></bold>). However, even their somata were distinctly different in size across cortical layers. Non-pyramidal neurons were much less spiny, had smaller cell body sizes and had a less obvious layer arrangement (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-9" hwp:rel-id="F3">Fig. 3C</xref></bold>). We sought to find an objective layering criterion and used cell soma size and clustering density to group cells into three non-adjacent layers and assigned the cells adjacent to these layers to four additional layers (see Methods). This approach generated a 6-layered cortex and white matter. The fiducial lines in each panel of <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-10" hwp:rel-id="F3">Fig. 3</xref></bold> are based on these layers (named in <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-11" hwp:rel-id="F3">Fig. 3A</xref></bold>).</p><p hwp:id="p-26">The glial cells also showed differences between layers (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-12" hwp:rel-id="F3">Fig. 3D, E</xref> and <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-13" hwp:rel-id="F3">F</xref></bold>). The compact and complicated arbors of protoplasmic astrocytes are densely tiled in all layers (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-14" hwp:rel-id="F3">Fig. 3D</xref></bold>), but the fibrous astrocytes in the white matter are more elongated than the protoplasmic astrocytes that occupy the cortical layers. Astrocytes in layer 1 were somewhat smaller in expanse, in line with astrocytes characterized in mouse cortex <sup><xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">13</xref></sup>. Layer 1 astrocytes also stand out because of higher densities of these cells (see <bold><xref ref-type="fig" rid="figs1" hwp:id="xref-fig-7-1" hwp:rel-id="F7">Supplementary Fig. 1A</xref> and <xref ref-type="fig" rid="figs5" hwp:id="xref-fig-11-1" hwp:rel-id="F11">5A</xref></bold>). Interestingly, the astrocyte density divides layer 1 into a superficial and deep region with the upper part of layer 1 being most densely populated with astrocytes, while the deeper part of layer 1 and layer 2 contain fewer astrocytes compared to upper layer 1 or layers 3-6, and even the white matter. Layer 1 is also unusual because it includes small aggregates of astrocytes (<bold><xref ref-type="fig" rid="figs1" hwp:id="xref-fig-7-2" hwp:rel-id="F7">Supplementary Fig. 1B</xref></bold>) where the arbors of neighboring astrocytes extensively intermingle. Transcriptomic characterization of astrocytes in the cerebral cortex has previously separated layer 1 and 2 from the other layers <sup><xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">14</xref></sup> or separated astrocytes into three cortical layers <sup><xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">15</xref></sup>. Layer 1 includes the primate-specific interlaminar astrocytes <sup><xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">16</xref></sup>, however, the aggregates of highly overlapping astrocytes we see in layer 1 are not interlaminar astrocytes, as they are lacking projections and are further away from the pial surface. We also noted extensive overlap between protoplasmic astrocytes in many layers (<bold><xref ref-type="fig" rid="figs1" hwp:id="xref-fig-7-3" hwp:rel-id="F7">Supplementary Fig. 1C</xref></bold>). This intermingling was unexpected since protoplasmic astrocytes (in rodents) are mainly described to have non-overlapping territories <sup><xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">17</xref>–<xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">19</xref></sup>. Oligodendrocytes had a different distribution. They were most plentiful in the white matter, as expected, given their role in myelin formation. There were also long lines of oligodendrocytes that surrounded the larger radially directed blood vessels in the white matter. The ultrastructure of this association is shown in <bold><xref ref-type="fig" rid="figs2" hwp:id="xref-fig-8-1" hwp:rel-id="F8">Supplementary Fig. 2A-C</xref></bold>. We noted perivascular oligodendrocytes <sup><xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">20</xref></sup> throughout the volume, with similar distance and interaction to blood vessels as microglia and OPCs (further described in <bold><xref ref-type="fig" rid="figs2" hwp:id="xref-fig-8-2" hwp:rel-id="F8">Supplementary Fig. 2D</xref> and <xref ref-type="fig" rid="figs2" hwp:id="xref-fig-8-3" hwp:rel-id="F8">E</xref></bold>). Oligodendrocyte density decreased in more superficial cortical layers, reaching a minimum in layer 2 (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-15" hwp:rel-id="F3">Fig. 3E</xref> and <xref ref-type="fig" rid="figs5" hwp:id="xref-fig-11-2" hwp:rel-id="F11">Supplementary Figure 5A</xref></bold>). In layer 1 they were slightly higher in density, probably related to the horizontally running myelinated axons in this layer (see below). Oligodendrocyte precursor cells which have different morphology and function than oligodendrocytes were difficult to differentiate by appearance from microglia (see <bold><xref ref-type="fig" rid="figs3" hwp:id="xref-fig-9-1" hwp:rel-id="F9">Supplementary Fig. 3</xref></bold>). Therefore, we used the skeleton node embeddings and a small set of manually labeled examples to train a model to classify candidate cells as microglia or OPCs (see Embeddings in Methods). The model predicted 2,049 cells to be microglia and 1,395 cells to be OPCs, whereas 2,836 cells were deemed ambiguous, often because of merge or split errors in the segmentation (see Methods and <bold><xref ref-type="fig" rid="figs25" hwp:id="xref-fig-31-1" hwp:rel-id="F31">Supplementary Fig. 25</xref></bold>). <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-16" hwp:rel-id="F3">Fig. 3F</xref></bold> shows the spatial distribution of the three classes. Unclassified cells tend to be at the sides of the sample owing to poorer alignment there and in the white matter, where the appearance of these glial cells is somewhat different than in the cortex. The reconstructed blood vessels (22.6 cms in total length) also did not show much evidence of layer-specific behavior (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-17" hwp:rel-id="F3">Fig. 3G</xref></bold>). There was clearly a lower density in the white matter, presumably because of the lower energy requirements of myelinated axons, as compared to unmyelinated processes <sup><xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">21</xref></sup>. Panel <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-18" hwp:rel-id="F3">Fig. 3G</xref></bold> also shows the location of 4,604 endothelial cells (∼20 per mm of vasculature) lining the vessel lumen (green) and a more heterogeneous group of 3,549 pericytes (blue, ∼15 per mm of vasculature) within the basement membrane but displaced slightly further from the lumen. Identification of smooth muscle cells as a type distinct from pericytes was possible in arteries and arterioles, however this distinction was not as clear in veins and venules as predicted by the expression profiles of these cells <sup><xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">22</xref></sup>. We estimated the number of vascular smooth muscle cells in the sample to be 574 and that there were 78 fibroblast-like pericytes <sup><xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-2" hwp:rel-id="ref-22">22</xref></sup> surrounding the smooth muscle cells. In the capillaries, where smooth muscle cells are missing, pericytes (total 2339 in the volume) help regulate blood flow <sup><xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">23</xref>, <xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">24</xref></sup>. Perivascular macrophages <sup><xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">25</xref></sup> (total 396) were identified based on location and large intracellular granules, as well as 128 perivascular lymphocytes, also located within the basement membrane. The total number of pericytes included a group of 25 cells we could not categorize further (see Methods for more details about cell type criteria). In addition, 46 circulating white cells (mainly neutrophils) were observed in the blood vasculature of the 1 mm<sup>3</sup> volume which was not perfused to remove blood.</p><fig id="figs1" position="float" orientation="portrait" fig-type="figure" hwp:id="F7" hwp:rev-id="xref-fig-7-1 xref-fig-7-2 xref-fig-7-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F7</object-id><object-id pub-id-type="publisher-id">figs1</object-id><label>Supplementary Figure 1:</label><caption hwp:id="caption-7"><title hwp:id="title-77">Minimal distance between astrocytes in cortical layers.</title><p hwp:id="p-173"><bold>(A)</bold> The Y and X coordinates for all 5474 astrocytes in the volume colored by the minimal distance to the next astrocyte. Red marking shows the approximate location of examples highlighted in B and C. <bold>(B)</bold> Example of six astrocytes in layer 1 (left panel shows four of the six cell bodies in the same EM section) resulting in cell aggregate with intermingling arbors, as shown in the 3D rendering (<underline>link</underline>). <bold>(C)</bold> Example of two astrocytes in layer 5 with closely connected cell bodies and overlapping territories (<underline>link</underline>).</p></caption><graphic xlink:href="446289v4_figs1" position="float" orientation="portrait" hwp:id="graphic-7"/></fig><fig id="figs2" position="float" orientation="portrait" fig-type="figure" hwp:id="F8" hwp:rev-id="xref-fig-8-1 xref-fig-8-2 xref-fig-8-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F8</object-id><object-id pub-id-type="publisher-id">figs2</object-id><label>Supplementary Figure 2:</label><caption hwp:id="caption-8"><title hwp:id="title-78">Affinity of oligodendrocytes for blood vessels.</title><p hwp:id="p-174"><bold>(A)</bold> Oligodendrocyte cell bodies (randomly colored) cluster at large blood vessels in white matter. In turn, around the blood vessel there is a region of lower oligodendrocyte density. EM image cross-sections in XY <bold>(B)</bold> and YZ directions <bold>(C)</bold> reveal that oligodendrocytes (blue) cluster above and below the large blood vessel (orange), but not at the sides. This suggests, at least in white matter, a mechanical reason for their location rather than a metabolic one (possibly related to tissue anisotropy; most myelinated axons in the area run along the Z axis). <bold>(D)</bold> Minimal distance between different cell types and blood vessels is shown in the x-axis (micrometers) and number of cells in the y-axis of the histogram. Astrocytes and neurons show similar distance to the blood vessels, while a large portion of oligodendrocytes and microglia/OPC’s are within a 5mu distance to blood vessels. <bold>(E)</bold> Cross-section of an example showing a perivascular oligodendrocyte. Single arrow shows a location where the oligodendrocyte membrane touches the basement membrane, double arrow shows a close-by location where the oligodendrocyte is separated from the basement membrane by a thin layer of astrocytic endfeet.</p></caption><graphic xlink:href="446289v4_figs2" position="float" orientation="portrait" hwp:id="graphic-8"/></fig><fig id="figs3" position="float" orientation="portrait" fig-type="figure" hwp:id="F9" hwp:rev-id="xref-fig-9-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F9</object-id><object-id pub-id-type="publisher-id">figs3</object-id><label>Supplementary Figure 3:</label><caption hwp:id="caption-9"><title hwp:id="title-79">Cell type examples from our dataset.</title><p hwp:id="p-175">Example cross-sections of an astrocyte with empty-looking cytoplasm and typical feathered outline; an oligodendrocyte with gray cytoplasm, and a pyramidal neuron with visible apical dendrite (black arrow) and axon initial segment (white arrow). Lower right shows two examples each of microglia and oligodendrocyte precursor cells (OPCs) as 3D-rendered models.</p></caption><graphic xlink:href="446289v4_figs3" position="float" orientation="portrait" hwp:id="graphic-9"/></fig><p hwp:id="p-27">Although astrocytic end feet touched blood vessels in many locations, their cell bodies were usually not abutting the blood vessels, but microglia, OPCs and oligodendrocytes were adjacent to the blood vessels. We also noted the capillary-free “Pfeifer spaces” surrounding the larger blood vessels <sup><xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">26</xref></sup>. Based on the number and positioning/orientation of contractile cells, we could separate the larger vessels into arterioles and venules. However, the narrowness of the sample prevented us from reconstructing a full blood circuit from artery to vein. In the vasculature we found 73 thin bloodless bridges connecting different capillaries <sup><xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-1" hwp:rel-id="ref-27">27</xref> <xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">28</xref> <xref ref-type="bibr" rid="c29" hwp:id="xref-ref-29-1" hwp:rel-id="ref-29">29</xref></sup> that were composed of a basement membrane and pericytes but lacking endothelial cells (marked red in <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-19" hwp:rel-id="F3">Fig. 3G</xref></bold>, and shown in more detail in <bold><xref ref-type="fig" rid="figs4" hwp:id="xref-fig-10-1" hwp:rel-id="F10">Supplementary Fig. 4</xref></bold>).</p><fig id="figs4" position="float" orientation="portrait" fig-type="figure" hwp:id="F10" hwp:rev-id="xref-fig-10-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F10</object-id><object-id pub-id-type="publisher-id">figs4</object-id><label>Supplementary Figure 4:</label><caption hwp:id="caption-10"><title hwp:id="title-80">Thin bridges between blood vessels.</title><p hwp:id="p-176"><bold>(A)</bold> Among the segmented blood vessels we identified 73 thin bridges without blood vessel lumen, consisting solely of basement membrane and pericyte soma. Here only the thin bridges are shown, seen in red in <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-24" hwp:rel-id="F3">Fig. 3G</xref></bold>. These bridges were rare in white matter and layer 6. Two examples were investigated in detail, location shown in square boxes. <bold>(B)</bold> The thin bridge is approximately 10 μm and connects two closely located capillaries (<underline>link</underline>). Pericyte cell body is colored blue and the basement membrane is gray. The pericyte nucleus and large portion of soma is located in one of the capillaries. The pericyte projects through the bridge, which is only partly covered by basement membrane, and into the neighboring capillary interacting with the endothelial cell. <bold>(C)</bold> Shows a thin bridge approximately 40 μm long between two capillaries (<underline>link</underline>). The pericyte projection in the thin bridge is mostly covered by the basement membrane, however several pericyte protrusions and gaps in the basement membrane were observed.</p></caption><graphic xlink:href="446289v4_figs4" position="float" orientation="portrait" hwp:id="graphic-10"/></fig><p hwp:id="p-28">From all of this cellular data, we could describe the complete cellular census of this brain sample (<bold><xref ref-type="fig" rid="figs5" hwp:id="xref-fig-11-3" hwp:rel-id="F11">Supplementary Fig. 5</xref></bold> and <bold><xref ref-type="table" rid="tbls3" hwp:id="xref-table-wrap-3-2" hwp:rel-id="T3">Supplementary Table 3</xref></bold>). The oligodendrocyte was the most common cell type. 20,139 oligodendrocytes were found in this sample. Glia outnumber neurons by 2:1 (32,315 versus 16,087) though this varies by cortical layer (see <bold><xref ref-type="fig" rid="figs5" hwp:id="xref-fig-11-4" hwp:rel-id="F11">Supplementary Fig. 5A, B</xref></bold>). The 8,096 vasculature cells were already described above. The most common neurons were spiny cells (10,531 spiny neurons, of which 8,803 had a clear pyramidal shape. The spiny cells accounted for 69% of the neurons in the sample). We describe one new subclass below. The 31% (n=4,688) non-spiny neurons were classified by us as interneurons. There was a subset of neurons that did not easily fit into this binary categorization because either their somata were not fully in the volume, or more rarely, they appeared anomalous in other ways (868 cells). Other unusual neurons are shown in <bold><xref ref-type="fig" rid="figs6" hwp:id="xref-fig-12-1" hwp:rel-id="F12">Supplementary Fig. 6</xref>.</bold></p><fig id="figs5" position="float" orientation="portrait" fig-type="figure" hwp:id="F11" hwp:rev-id="xref-fig-11-1 xref-fig-11-2 xref-fig-11-3 xref-fig-11-4 xref-fig-11-5 xref-fig-11-6 xref-fig-11-7"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F11</object-id><object-id pub-id-type="publisher-id">figs5</object-id><label>Supplementary Figure 5:</label><caption hwp:id="caption-11"><title hwp:id="title-81">Cell densities per type and layer.</title><p hwp:id="p-177"><bold>(A)</bold> shows densities of cell bodies of different types per cubic millimeter in our sample, separate for each layer. These values are corrected for the estimated 28% mechanical compression in the cutting direction. The numbers for this plot are listed in <bold>Supplementary Table 8</bold>. <bold>(B)</bold> Shows the relative abundance of excitatory versus inhibitory neuron cell bodies (top) and neurons versus glia (bottom), for the layers in A. <bold>(C)</bold> For this analysis, layers were approximated by using a circular distance measure from a center point at (800, 2650) which approximates the curvature in the tissue. <bold>(D)</bold> To get cell body densities the number of cell bodies of each type has to be divided by the volume of tissue they are found in. Only the volume in which cell body labeling was fully saturated was used (see <bold><xref ref-type="fig" rid="figs10" hwp:id="xref-fig-16-3" hwp:rel-id="F16">Supplementary Fig. 10</xref></bold>), and individual tiles were associated with one layer each. <bold>(E)</bold> shows the XYZ locations of the cell bodies included in this analysis and their layer assignment in color. Note that towards layer 1 the upper layers are cut in deeper sections; this was taken into account for the volume estimation.</p></caption><graphic xlink:href="446289v4_figs5" position="float" orientation="portrait" hwp:id="graphic-11"/></fig><fig id="figs6" position="float" orientation="portrait" fig-type="figure" hwp:id="F12" hwp:rev-id="xref-fig-12-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F12</object-id><object-id pub-id-type="publisher-id">figs6</object-id><label>Supplementary Figure 6:</label><caption hwp:id="caption-12"><title hwp:id="title-82">Examples of unusual cells.</title><p hwp:id="p-178"><bold>(A)</bold> Shows a <underline>neuron with clear pyramidal shape which is almost devoid of spines</underline>. <bold>(B)</bold> Shows a <underline>neuron with interneuron morphology but many spine-like protrusions on its dendrites</underline>. <bold>(C)</bold> Shows a <underline>rare interneuron which extends horizontally</underline> (tangentially) through our data set. This cell can be seen <italic toggle="yes">in situ</italic> in <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-25" hwp:rel-id="F3">Fig. 3C</xref></bold> in the middle of layer 3. <bold>(D)</bold> and <bold>(E)</bold> Show an example of a <underline>‘dark’ cell</underline> in the tissue which has pyramidal cell morphology. Most dark cells were found towards the upper edge of our sample, in layers 4-6. <bold>(F)</bold> This <underline>neuron has two separate axons emerging from the soma</underline> (white arrows). Both make outgoing synapses in the volume (white boxes), shown below in <bold>(G)</bold>. <bold>(H)</bold> Shows a <underline>neuron with an unusual dendritic tree</underline> (cell body displaced to the side). <bold>(I)</bold> Shows a cross-section of an <underline>astrocyte cell body with two nuclei</underline> (separate in 3D). We found 34 cells with two clearly separate nuclei in the tissue, most of which were astrocytes.</p></caption><graphic xlink:href="446289v4_figs6" position="float" orientation="portrait" hwp:id="graphic-12"/></fig><p hwp:id="p-29">Myelin was found throughout the volume (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-20" hwp:rel-id="F3">Fig. 3H</xref></bold>). Its density was highest in the white matter as expected. There were layer-specific differences in myelin density. The layer with the least myelin was layer 2. As already described, layer 2 was also the layer with the lowest density of oligodendrocytes (see <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-21" hwp:rel-id="F3">Fig. 3E</xref></bold> and <bold><xref ref-type="fig" rid="figs5" hwp:id="xref-fig-11-5" hwp:rel-id="F11">Supplementary Fig. 5A</xref></bold>). Because we annotated the myelin and skeletonized the axons it wrapped, it was possible to render not only the density of the myelin, but also its direction. Myelin direction is the basis of the diffusion tensor measurements made in the human brain <italic toggle="yes">in vivo</italic> <sup><xref ref-type="bibr" rid="c30" hwp:id="xref-ref-30-1" hwp:rel-id="ref-30">30</xref></sup>. The myelin in the white matter is running primarily orthogonal to the plane of the section and hence appears blue in this direction-color plot. Bundles of myelinated axons project radially (green color) between the white matter and the cortical layers. In layer 3 the myelin is also running mostly orthogonal to the plane of sectioning (blue). In layer 1 myelin is running horizontally within this layer and hence orthogonal to the white matter and the radial myelin and colorized red (see also <bold><xref ref-type="fig" rid="figs23" hwp:id="xref-fig-29-1" hwp:rel-id="F29">Supplementary Fig. 23B</xref></bold>).</p><p hwp:id="p-30">Because all the objects in the cortical tissue were annotated by types we could assess the volumetric contribution of different types of cells and cell parts to the cortical parenchyma. By volume, this brain sample was 40.6% unmyelinated axons, 26.1% dendrites, 16.0% astrocytes and other glial cells, 9.6% somata, 7.6% myelinated axons, 0.07% axon initial segments, and 0.03% cilia (<bold><xref ref-type="fig" rid="figs22" hwp:id="xref-fig-28-1" hwp:rel-id="F28">Supplementary Fig. 22</xref></bold>). The ratio of dendritic processes to axonal processes (4.9:1) is tipped more in favor of unmyelinated axons than the volumetric measurements above because individual axons on average occupy less volume than dendrites. In addition to these well known categories, we found in the volume a number of UCOs (unidentified cortical objects) that accounted for very little volume. These are shown in <bold><xref ref-type="fig" rid="figs7" hwp:id="xref-fig-13-1" hwp:rel-id="F13">Supplementary Fig. 7</xref>.</bold></p><fig id="figs7" position="float" orientation="portrait" fig-type="figure" hwp:id="F13" hwp:rev-id="xref-fig-13-1 xref-fig-13-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS7</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F13</object-id><object-id pub-id-type="publisher-id">figs7</object-id><label>Supplementary Figure 7:</label><caption hwp:id="caption-13"><title hwp:id="title-83">Unusual and unidentified cortical objects.</title><p hwp:id="p-179"><bold>(A)</bold> Whorled axon that makes inhibitory synapses on cell soma and dendritic shafts in L5, L6 (<underline>link</underline>)<bold>. (B)</bold> Soma of interneuron engulfed by the dendritic process of another interneuron (<underline>link</underline>)<bold>. (C)</bold> Unidentified object filled with fibrous substance (<underline>link</underline><bold>). (D)</bold> Whorls of loosely coiled myelin (<underline>link</underline>). <bold>(E)</bold> Egg shaped object with no associated processes (<underline>link</underline>). <bold>(F)</bold> Myelinated oval object. <bold>(G)</bold> Greyish object. <bold>(H)</bold> Interacting climbing dendrites <underline>link</underline> <bold>(I)</bold> Myelinated dendritic trunk in grey matter (<underline>link</underline>). <bold>(J)</bold> Myelinated dendritic trunk in white matter (<underline>link</underline>). <bold>(K)</bold> Swollen dendritic spine containing 150 intramembranous objects (segmented manually; <underline>link</underline>). <bold>(L)</bold> Unidentified object filled with small spherical objects (<underline>link</underline>). <bold>(M)</bold> Myelinated axon filled with unidentified substance (<underline>link</underline>). <bold>(N)</bold> Myelinated object filled with small debris (<underline>link</underline>). <bold>(O)</bold> Compartmentalized fibrous object (<underline>link</underline>). <bold>(P)</bold> Whorls within the soma surrounding a cell nucleus (<underline>link</underline>). <bold>(Q)</bold> Random lying whorled substance (<underline>link</underline>). <bold>(R)</bold> Conjoint whorls (<underline>link</underline>). <bold>(S)</bold> Synapse wrapped by astrocytic processes (<underline>link</underline>). <bold>(T)</bold> Myelinated object with multiple membranous rings (<underline>link</underline>).</p></caption><graphic xlink:href="446289v4_figs7" position="float" orientation="portrait" hwp:id="graphic-13"/></fig><fig id="figs8" position="float" orientation="portrait" fig-type="figure" hwp:id="F14" hwp:rev-id="xref-fig-14-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS8</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F14</object-id><object-id pub-id-type="publisher-id">figs8</object-id><label>Supplementary Figure 8:</label><caption hwp:id="caption-14"><title hwp:id="title-84">Chandelier cells.</title><p hwp:id="p-180"><bold>(A)</bold> Two chandelier cells, ChC-1 and ChC-2. <bold>(B)</bold> Incoming and outgoing synapses on both ChC-1 and ChC-2 chandelier cells. The arrows indicate the characteristic cartridges made by chandelier cell axons. <bold>(C)</bold> Incoming inhibitory synapse on AIS of ChC- 1 made by the axon of ChC-2 (<underline>link</underline>). <bold>(D)</bold> Close-up of the ChC-ChC AIS synapse shown in panel <bold>C</bold>.</p></caption><graphic xlink:href="446289v4_figs8" position="float" orientation="portrait" hwp:id="graphic-14"/></fig><fig id="figs9" position="float" orientation="portrait" fig-type="figure" hwp:id="F15" hwp:rev-id="xref-fig-15-1 xref-fig-15-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS9</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F15</object-id><object-id pub-id-type="publisher-id">figs9</object-id><label>Supplementary Figure 9:</label><caption hwp:id="caption-15"><title hwp:id="title-85">Low-resolution electron microscopy overview of a representative section.</title><p hwp:id="p-181">Region of interest (ROI) is indicated by a yellow polygon. Blue arrows and corresponding percentages indicate the minimum distance (expressed as a proportion of that edge of the section, including any resin) between the corner of the section at the foot of the arrow, and the point of the ROI at its head.</p></caption><graphic xlink:href="446289v4_figs9" position="float" orientation="portrait" hwp:id="graphic-15"/></fig><fig id="figs10" position="float" orientation="portrait" fig-type="figure" hwp:id="F16" hwp:rev-id="xref-fig-16-1 xref-fig-16-2 xref-fig-16-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS10</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F16</object-id><object-id pub-id-type="publisher-id">figs10</object-id><label>Supplementary Figure 10:</label><caption hwp:id="caption-16"><title hwp:id="title-86">Manual cell body labeling and classification.</title><p hwp:id="p-182"><bold>(A)</bold> Systematic search for all cell bodies in the tissue was done in VAST by using an overlaid grid (image layer). Each block which was surveyed was marked by a red dot (separate segmentation layer). The area of red dots shows where very close to 100% of all cell bodies should be labeled. <bold>(B)</bold> Shows the resolution at which manual cell body labeling in VAST was done (mip 4, every 128th section) and the approximate accuracy of manual labels. <bold>(C)</bold> Cell body classification. VAST (left) is linked to Matlab via its API and vasttools.m. A Matlab script is running in the background which polls for SPACE key presses in VAST. Once the user presses the SPACE key, Matlab remote-controls VAST to advance to the next segment in the list and moves the 2D view in VAST to that location. At the same time it queries the corresponding ID in the automated segmentation and opens a Neuroglancer 3D view of the same cell in a browser window. The user can then inspect the cell in 2D and 3D and make a decision for classification. The classification key is added to the name of the cell segment in the VAST ‘Segment Colors’ list as a list of tags in square brackets. Specific tags can be added by clicking the buttons in VASTs configurable ‘Control Buttons’ window. The names list can later be exported together with other metadata and used for analysis. (<underline>See an interactive view of all annotated cells</underline>.)</p></caption><graphic xlink:href="446289v4_figs10" position="float" orientation="portrait" hwp:id="graphic-16"/></fig><fig id="figs11" position="float" orientation="portrait" fig-type="figure" hwp:id="F17" hwp:rev-id="xref-fig-17-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS11</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F17</object-id><object-id pub-id-type="publisher-id">figs11</object-id><label>Supplementary Figure 11:</label><caption hwp:id="caption-17"><title hwp:id="title-87">Tissue sample.</title><p hwp:id="p-183">(<bold>A</bold>) The human brain vibratome section in its resin block, stained, embedded and ready for trimming and sectioning. This vibratome section was taken from a larger brain biopsy sample of the human temporal cortex (<bold>B</bold>) which was approximately 2 x 1 cm in size. <bold>(C)</bold> The fixed sample before vibratoming.</p></caption><graphic xlink:href="446289v4_figs11" position="float" orientation="portrait" hwp:id="graphic-17"/></fig><fig id="figs12" position="float" orientation="portrait" fig-type="figure" hwp:id="F18" hwp:rev-id="xref-fig-18-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS12</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F18</object-id><object-id pub-id-type="publisher-id">figs12</object-id><label>Supplementary Figure 12.</label><caption hwp:id="caption-18"><title hwp:id="title-88">Optical flow field correction.</title><p hwp:id="p-184">XZ section of a part of the dataset exhibiting drift and some misalignments before (left) and after optical flow field correction (right). Scale bar 2 μm.</p></caption><graphic xlink:href="446289v4_figs12" position="float" orientation="portrait" hwp:id="graphic-18"/></fig><fig id="figs13" position="float" orientation="portrait" fig-type="figure" hwp:id="F19" hwp:rev-id="xref-fig-19-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS13</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F19</object-id><object-id pub-id-type="publisher-id">figs13</object-id><label>Supplementary Figure 13.</label><caption hwp:id="caption-19"><title hwp:id="title-89">Semantic segmentation predictions.</title><p hwp:id="p-185"><bold>A:</bold> tissue types detected by the semantic segmentation model. (a) Blood vessel (b) Nucleus (c) Myelin (d) Neuropil (e) Fissure (f) Myeloid bodies within a dendritic branch. Scale bar is 1 μm. <bold>B:</bold> predicted masks indicating cell nuclei (yellow), blood vessels (red), tissue fissure artefact (green), myelin (light gray), other neuropil (dark blue). White frame indicates the region shown in A.</p></caption><graphic xlink:href="446289v4_figs13" position="float" orientation="portrait" hwp:id="graphic-19"/></fig><fig id="figs14" position="float" orientation="portrait" fig-type="figure" hwp:id="F20" hwp:rev-id="xref-fig-20-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS14</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F20</object-id><object-id pub-id-type="publisher-id">figs14</object-id><label>Supplementary Figure 14.</label><caption hwp:id="caption-20"><title hwp:id="title-90">Synapse prediction.</title><p hwp:id="p-186">Left: Typical example of a chemical synapse, showing vesicles in the axon, dark post-synaptic density at the cleft, and a lack of vesicles in the receiving dendrite. Right: voxel-wise annotations denoting presynaptic site (blue) and postsynaptic site (orange). Other voxels are assumed to be background.</p></caption><graphic xlink:href="446289v4_figs14" position="float" orientation="portrait" hwp:id="graphic-20"/></fig><fig id="figs15" position="float" orientation="portrait" fig-type="figure" hwp:id="F21" hwp:rev-id="xref-fig-21-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS15</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F21</object-id><object-id pub-id-type="publisher-id">figs15</object-id><label>Supplementary Figure 15.</label><caption hwp:id="caption-21"><title hwp:id="title-91">Neuron proofreading interface in Neuroglancer with CREST.</title><p hwp:id="p-187">A fully proofread neuron is shown, with added dendritic and axonal base segments indicated in yellow and green, respectively. The base segment containing the soma is indicated in blue. White dots are point annotations added to indicate the ends of branches. Numbers of classified and unclassified base segments are displayed in a count near the bottom of the screen.</p></caption><graphic xlink:href="446289v4_figs15" position="float" orientation="portrait" hwp:id="graphic-21"/></fig><fig id="figs16" position="float" orientation="portrait" fig-type="figure" hwp:id="F22" hwp:rev-id="xref-fig-22-1 xref-fig-22-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS16</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F22</object-id><object-id pub-id-type="publisher-id">figs16</object-id><label>Supplementary Figure 16.</label><caption hwp:id="caption-22"><title hwp:id="title-92">Clusters of neurons with fitted upper and lower bounds.</title><p hwp:id="p-188">Blue lines: fitted layer bounds. Points: individual neurons defining a cluster, colored by cluster membership.</p></caption><graphic xlink:href="446289v4_figs16" position="float" orientation="portrait" hwp:id="graphic-22"/></fig><fig id="figs17" position="float" orientation="portrait" fig-type="figure" hwp:id="F23" hwp:rev-id="xref-fig-23-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS17</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F23</object-id><object-id pub-id-type="publisher-id">figs17</object-id><label>Supplementary Figure 17.</label><caption hwp:id="caption-23"><title hwp:id="title-93">Identification of shaft, synapse and terminal bouton stalk components of axonal skeletons.</title><p hwp:id="p-189">Upper panels: Segmentation views of axons.</p><p hwp:id="p-190">Lower panels: Skeleton views of axons. Right panels: axon with three ‘en-passant’ synapses. Left panels: axon with two terminal bouton synapses and one ‘en passant’ synapse. Blue dots: synapse-associated skeleton nodes. White dots: shaft skeleton nodes. Yellow dots: skeleton nodes connecting synapse nodes to the shaft.</p></caption><graphic xlink:href="446289v4_figs17" position="float" orientation="portrait" hwp:id="graphic-23"/></fig><fig id="figs18" position="float" orientation="portrait" fig-type="figure" hwp:id="F24" hwp:rev-id="xref-fig-24-1 xref-fig-24-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS18</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F24</object-id><object-id pub-id-type="publisher-id">figs18</object-id><label>Supplementary Figure 18.</label><caption hwp:id="caption-24"><title hwp:id="title-94">Distribution of synapse distances from axonal shaft.</title><p hwp:id="p-191">Blue columns indicate distribution of observed distances and the black curve indicates the fitted probability density function. Upper panel: distribution of distances from synapse location to closest point on shaft for ‘en passant’ (‘shaft-type’) synapses, with fitted scaled, shifted lognormal distribution (shape: 0.577, location: 2.42, scale: 338, see <ext-link l:rel="related" l:ref-type="uri" l:ref="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html" ext-link-type="uri" xlink:href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html" hwp:id="ext-link-15">https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html</ext-link> for details). Lower panel: Distribution of distances from synapse location to ‘root point’ on shaft for ‘terminal bouton stalk’’ (‘stalk-type’) synapses, with fitted scaled, shifted chi-sq distribution (df: 7.43, location: 369, scale: 254, see <ext-link l:rel="related" l:ref-type="uri" l:ref="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html" ext-link-type="uri" xlink:href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html" hwp:id="ext-link-16">https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.chi2.html</ext-link> for details).</p></caption><graphic xlink:href="446289v4_figs18" position="float" orientation="portrait" hwp:id="graphic-24"/></fig><fig id="figs19" position="float" orientation="portrait" fig-type="figure" hwp:id="F25" hwp:rev-id="xref-fig-25-1 xref-fig-25-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS19</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F25</object-id><object-id pub-id-type="publisher-id">figs19</object-id><label>Supplementary Figure 19.</label><caption hwp:id="caption-25"><title hwp:id="title-95">Excitatory cell making multiple synapses on inhibitory cell dendrite.</title><p hwp:id="p-192">E: excitatory cell. I: inhibitory cell. Numbered arrows: individual synapses.</p></caption><graphic xlink:href="446289v4_figs19" position="float" orientation="portrait" hwp:id="graphic-25"/></fig><fig id="figs20" position="float" orientation="portrait" fig-type="figure" hwp:id="F26" hwp:rev-id="xref-fig-26-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS20</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F26</object-id><object-id pub-id-type="publisher-id">figs20</object-id><label>Supplementary Figure 20.</label><caption hwp:id="caption-26"><title hwp:id="title-96">Difference in number of classified skeleton nodes in ‘forward’ and ‘reverse’ layer 6 pyramidal neuron basal dendrites.</title><p hwp:id="p-193">‘Reverse’ basal dendrites (upper panel) have less mass as measured by number of classified skeleton nodes (mean: 2514) than ‘forward’ basal dendrites (lower panel, mean: 4437). Skeleton nodes are classified as described in ‘Cellular subcompartment classification and merge error correction’.</p></caption><graphic xlink:href="446289v4_figs20" position="float" orientation="portrait" hwp:id="graphic-26"/></fig><fig id="figs21" position="float" orientation="portrait" fig-type="figure" hwp:id="F27" hwp:rev-id="xref-fig-27-1 xref-fig-27-2 xref-fig-27-3 xref-fig-27-4 xref-fig-27-5 xref-fig-27-6"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS21</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F27</object-id><object-id pub-id-type="publisher-id">figs21</object-id><label>Supplementary Figure 21:</label><caption hwp:id="caption-27"><title hwp:id="title-97">Layer 5/6 triangular (or compass) cells.</title><p hwp:id="p-194"><bold>(A)</bold> Estimation of tissue topology by fitting a grid of tangential and radial lines to 2D projection images of different extracted properties of the sample in VAST. <bold>(B)</bold>, <bold>(C)</bold> Interpolated vector fields from these lines. <bold>(D)-(F)</bold> Basal dendrite directions around the local radial direction with respect to the topology field, as polar plot (D) and histograms of angular (E) and radial (F) coordinate.</p></caption><graphic xlink:href="446289v4_figs21" position="float" orientation="portrait" hwp:id="graphic-27"/></fig><fig id="figs22" position="float" orientation="portrait" fig-type="figure" hwp:id="F28" hwp:rev-id="xref-fig-28-1 xref-fig-28-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS22</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F28</object-id><object-id pub-id-type="publisher-id">figs22</object-id><label>Supplementary Figure 22:</label><caption hwp:id="caption-28"><title hwp:id="title-98">Volume occupancy by layer.</title><p hwp:id="p-195">All objects in the C3 segmentation were classified into seven classes based on the classification of their skeletons. The resulting voxel data was sampled at 2048 x 2048 x 2112 nm per pixel (mip 8) and masked by a manually generated tissue mask to remove all voxels outside the segmented volume. <bold>(A)</bold> Overall statistics of the volume percentage of different classes in the complete segmented volume. 36.82% of the voxels within the tissue were unlabeled and are excluded from the analysis. Unlabeled regions include: blood vessels, myelin sheaths, regions of fissures or other image defects, and extracellular space. <bold>(B)</bold> Since tissue statistics vary by cortical layer, we split the volume into regions based on the circular layer estimates (see <bold><xref ref-type="fig" rid="figs16" hwp:id="xref-fig-22-2" hwp:rel-id="F22">Supplementary Fig. 16</xref></bold>) and analyzed volume occupancy separately per layer. See <bold><xref ref-type="table" rid="tbls9" hwp:id="xref-table-wrap-9-1" hwp:rel-id="T9">Supplementary Table 9</xref></bold> for the data values.</p></caption><graphic xlink:href="446289v4_figs22" position="float" orientation="portrait" hwp:id="graphic-28"/></fig></sec><sec id="s2b" hwp:id="sec-4"><title hwp:id="title-9">Synaptic Connectivity</title><p hwp:id="p-31">The most functionally significant aspect of cortical tissue is the synaptic connectivity that allows neurons to send and receive signals to and from other neurons. This wiring diagram is likely central to the way human brains store memory and give rise to behavior. The segmentation of neurons described above was insufficient to generate a wiring diagram because these segmentations did not identify synapses. As described in <bold><xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-14" hwp:rel-id="F2">Fig. 2</xref></bold>, we therefore used machine learning tools to train automated synapse classifiers to identify the pre- and postsynaptic component of each synapse and whether the presynaptic terminal was putatively excitatory or inhibitory. Proofreading showed that the number of missed synapses (i.e., false negatives) was 12%. Because we found no convincing cases of dendrites, glia, or cell somata establishing synapses (i.e., presynaptically) we could eliminate many of the false positives. After these corrections, the final false positive rate was 1.5%. Automated classification of each synapse as excitatory or inhibitory was based on the appearance of each individual synapse and whether its postsynaptic structure was a dendritic spine or not, as well as the whether the presynaptic neuron was an excitatory or inhibitory type, for those neurons where the soma was in the volume. This approach classified excitatory and inhibitory synapses correctly 99.42% and 92.00% of the time, respectively. In total, we found 149.8 M synapses in the volume between axons and either: dendrites (99.4%), AIS (0.197%), or somata (0.393%). There were: 40.6 M (27.13%) inhibitory and 109.2 M excitatory (72.87%). The density of the automatically annotated excitatory synapses was highest in layers 1 and 3 (<bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Fig. 4A</xref></bold>). The distribution of the inhibitory synapses was different and peaked in layer 1 (<bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-2" hwp:rel-id="F4">Fig. 4B</xref></bold>). The percentage of excitatory synapses of total E/(E+I) is highest in layer 3 and lowest in layer 1 (<bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-3" hwp:rel-id="F4">Fig. 4C</xref></bold>). A relatively higher density of inhibitory synapses in human cortex layer 1 has been reported before <sup><xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">31</xref></sup>. Synapse density estimates for different layers are shown in <bold><xref ref-type="fig" rid="figs26" hwp:id="xref-fig-32-1" hwp:rel-id="F32">Supplementary Fig. 26</xref></bold>.</p><fig id="fig4" position="float" orientation="portrait" fig-type="figure" hwp:id="F4" hwp:rev-id="xref-fig-4-1 xref-fig-4-2 xref-fig-4-3 xref-fig-4-4 xref-fig-4-5 xref-fig-4-6 xref-fig-4-7 xref-fig-4-8 xref-fig-4-9 xref-fig-4-10 xref-fig-4-11 xref-fig-4-12 xref-fig-4-13 xref-fig-4-14"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4:</label><caption hwp:id="caption-4"><title hwp:id="title-10">Synapses and circuit reconstruction.</title><p hwp:id="p-32"><bold>A</bold>: Volumetric density of inhibitory synapses. <bold>B</bold>: Volumetric distribution of excitatory synapses. <bold>C</bold>: Excitatory-inhibitory balance (E/E+I). Lowest values are purple, highest values are yellow. <bold>D</bold>: Interneuron and <bold>E</bold>: Pyramidal neuron with synapse locations shown in orange for synapses classified as excitatory and blue for synapses classified as inhibitory. Note large numbers of I synapses on the pyramidal neuron’s axon initial segment. <bold>F</bold>: Balance of inhibitory and excitatory synapses (E/E+I) onto interneurons (blue) and pyramidal neurons (orange) for neurons with cell bodies in different layers. <bold>G,H</bold>: Excitatory (orange) and inhibitory (blue) synaptic connections between neurons with cell bodies in the volume, based on non-proofread, automatically extracted cells and synapses; high-resolution online versions are available for both <underline>inhibitory</underline> and <underline>excitatory</underline> synaptic connections. <bold>I</bold>: Synaptic network between a set of 104 manually proofread neurons and their postsynaptic targets in the volume. Pyramidal cells are shown as orange triangles, interneurons as blue circles. Blue circles indicate spiny stellate neurons. <bold>J</bold>: From the automatically segmented connections we identified 96 categories of synapses (all subsequently validated by proofreading) and diagrammed the layer location of the synapses (arrowheads) and the layer location of the cell somata of the pre- and postsynaptic partners of each category (blue neurons are non-spiny and orange are spiny). Chandelier neurons whose axons innervate initial segments are the rightmost cells.</p></caption><graphic xlink:href="446289v4_fig4" position="float" orientation="portrait" hwp:id="graphic-4"/></fig><p hwp:id="p-33">Because each identified synapse was associated with a postsynaptic target, it was possible to analyze the inhibitory and excitatory drive to every neuron in the volume (see an example interneuron and pyramidal neuron in <bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-4" hwp:rel-id="F4">Fig. 4D</xref> and <xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-5" hwp:rel-id="F4">E</xref></bold>). Inhibitory neurons on average received roughly equal numbers of excitatory and inhibitory synapses (<bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-6" hwp:rel-id="F4">Fig. 4F</xref></bold>) and they were distributed uniformly along dendrites and the cell somata. Excitatory neurons had relatively few synapses on the cell body and proximal (non-spiny) dendritic branches. For excitatory neurons, the synapses on the cell body and proximal dendrites were largely inhibitory. In contrast, in the spiny dendritic regions there were more excitatory synapses than inhibitory and because so much of the dendritic tree was spiny, the total excitatory drive as percent of total synapses on pyramidal cells was shifted to more excitation than the input to inhibitory neurons. There was also a large number of inhibitory synapses from chandelier interneurons on the axonal initial segment to the vast majority of spiny neurons (e.g., <bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-7" hwp:rel-id="F4">Fig. 4E</xref></bold>) but not on interneurons. One exception, these chandelier axons also innervated the axon initial segment of other chandelier interneurons (see <bold><xref ref-type="fig" rid="figs8" hwp:id="xref-fig-14-1" hwp:rel-id="F14">Supplementary Fig. 8</xref></bold>). In layers 2-6 and the white matter, the tendency was the same: Pyramidal cells received a greater proportion of excitatory synapses than non-spiny interneurons (<bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-8" hwp:rel-id="F4">Fig. 4F</xref></bold>).</p><p hwp:id="p-34">In this volume there were many hundreds of millions of axons originating from sites that were outside the volume. More rarely were the presynaptic terminals from axons of neurons in the volume. This asymmetry is accounted for by the fact that the majority of axonal input to cells originate from neurons outside the volume and most axons of neurons in the volume project outside the volume where they establish the majority of their synapses. Nonetheless, among the sparse axonal synapses of neurons with somata in the volume, 11,470 (71.3%) were synaptically connected to one or more other neurons with somata in the volume. We have graphed all of these connections (excitatory input <bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-9" hwp:rel-id="F4">Fig. 4G</xref></bold>; inhibitory input <bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-10" hwp:rel-id="F4">Fig. 4H</xref></bold>). These synapses gave rise to 29,498 in-volume neuron to neuron connections, and comprised 38,191 synapses. These synapses were mostly on dendrites (36,158, 94.68%), axonal initial segments (1065, 2.79%) and axonal input to neuronal somata (968, 2.53%). This neuron connectivity circuit data is available at full resolution for both <underline>inhibitory</underline> and <underline>excitatory</underline> connections.</p><p hwp:id="p-35">To better understand potential modes of information flow in the network, we algorithmically traversed the connectome according to its connectivity. Specifically, we chose L4 pyramidal neurons as a starting point because this layer is often the target of feed-forward connections from other brain regions<sup><xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">32</xref></sup> and input to other cortical layers<sup><xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">33</xref></sup> and then traversed their postsynaptic partners if a threshold criteria was satisfied (see Analysis of information flow through network in Methods). We found that the layer 4 pyramidal cells (n = 908) primarily connect to cells in layer 3, which in turn connect to cells in layer 2. As this progression iterates toward the upper surface of the cortex, connections to cells in deeper layers 6 and 5 also become visible (see <underline>video online</underline>). Because the number of connections being traversed is extremely sparse, owing to axonal breaks in the automatic segmentation, and the fact that only connections between neurons with somata in the volume are being considered, this information flow should not be confused with a neural activity simulation of this cortical slice.</p><p hwp:id="p-36">Our large-scale automated segmentation combined with the development of efficient segmentation proofreading tools such as <underline>CREST</underline> also make possible the reconstruction of verified neural networks composed of the outputs of hundreds of neurons to hundreds of postsynaptic neurons. To obtain such a network, we proofread 104 neurons, which together with their postsynaptic target neurons form a network of 585 neurons, shown in <bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-11" hwp:rel-id="F4">Fig. 4I</xref></bold>. In this network axonal branches that were broken by split errors and merge errors (more rare) were corrected to give the entire arbor of neurons with few branches missing in order to provide the connectivity of these neurons to other cells within the volume. Within this network, a small number of neurons form a disproportionately large number of the connections, with the most connected neuron, a chandelier cell, synapsing on 70 other neurons in the network. The number of postsynaptic neurons within the volume receiving synapses from a single proofread neuron ranged from 0 to 70, with a mean of 5. Given the number of neuronal elements in petascale volumes it is not conceivable to proofread more than a small fraction of the data segmented by machine learning. We expect that with improvements both in image data quality and advances in AI, future datasets will substantially improve the automatic segmentation, however we wondered if we could leverage the large number of connected pairs discovered by machine learning to find a substantial fraction of the canonical intracortical circuit. For this analysis we used the more conservative c3 agglomeration which minimized merge errors, albeit with more axon breaks. This approach meant that we were certainly missing a substantial number of axonal connections between neurons in the volume. Nonetheless, we analyzed nearly 30,000 connections between neurons with somata in the volume, all identified by machine learning. We categorized neurons as excitatory and inhibitory based on the presynaptic neuron’s dendrites (smooth or spiny). We identified the layer in which the pre- and postsynaptic somata were located and the layer where the synapse(s) that connected them were located. Because there were no spiny neurons found in Layer 1, we had 6 layers possessing inhibitory cell bodies and 5 layers (layer 2-6) with excitatory cell bodies. We further divided the set of inhibitory cells into interneurons that innervated cell somata and dendrites and the set of interneurons that innervated axon initial segments, which we presume are Chandelier cells <sup><xref ref-type="bibr" rid="c34" hwp:id="xref-ref-34-1" hwp:rel-id="ref-34">34</xref>, <xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-1" hwp:rel-id="ref-35">35</xref></sup>. We drew a circuit diagram based on these connections in which we connected neurons based on both the layer of origin of the pre- and postsynaptic cell and the layer where a synaptic interconnection was found (<bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-12" hwp:rel-id="F4">Fig. 4J</xref></bold>). All told, we found 96 verified categories of connections based on spot proofreading. The spot proofreading revealed that at least 2/3 of the machine learning (ML)-identified connections were real, although false positive rates varied by connection type (<bold><xref ref-type="table" rid="tbls5" hwp:id="xref-table-wrap-5-1" hwp:rel-id="T5">Supp. Table 5</xref></bold>). Because most of the categorical connections were based on multiple examples, even removing the false positive connections had a small effect on the final number of connection categories. Moreover the connections based on manual proofreading to correct all the axon breaks from 104 randomly chosen neurons (see above) revealed only 2 categories of connections that were missed in the machine learning data (<bold><xref ref-type="table" rid="tbls6" hwp:id="xref-table-wrap-6-1" hwp:rel-id="T6">Supp. Table 6</xref>)</bold>. These results suggest that the automatic segmentation even with a conservatve agglomeration that minimizes merge errors at the expense of fewer long axonal segments, still could reveal the vast majority of cell-to-cell connectivity categories in this cortical slab. The connectivity that was revealed connected the majority of cells within and between layers and presents a complex picture of what a full canonical circuit would look like. It is important to emphasize that the approach we took does not provide insight into which types of connections are most or least common. The most numerous connection found was between layer 2 excitatory to layer 2 inhibitory cells (&gt;3000 such connections). This may reflect the short distance needed for axons to connect two cells of the same layer.</p></sec><sec id="s2c" hwp:id="sec-5"><title hwp:id="title-11">New morphological subcategories of layer 6 triangular neurons</title><p hwp:id="p-37">The deepest layer of the cerebral cortex has remained poorly studied compared to more superficial layers for a number of reasons <sup><xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">36</xref></sup>. Among these is the fact that there is a greater diversity of cell types in this layer, especially in primates <sup><xref ref-type="bibr" rid="c37" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">37</xref></sup>. When cell types are classified by Golgi stains or dye fills, as is often the case in the cerebral cortex, the data may be too sparse to categorize types clearly. This human cortical sample however provides a very large set of neurons that reside in each layer and therefore could potentially be used to reveal categories that were previously unnoticed. As a test of this idea we looked at the so-called “triangular” or “compass” cells that have long been known to reside in layer 6 but are not well understood <sup><xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-2" hwp:rel-id="ref-36">36</xref>, <xref ref-type="bibr" rid="c38" hwp:id="xref-ref-38-1" hwp:rel-id="ref-38">38</xref>–<xref ref-type="bibr" rid="c40" hwp:id="xref-ref-40-1" hwp:rel-id="ref-40">40</xref></sup>. These neurons have an apical-going dendrite and are spiny like the more common pyramidal neurons. However these cells each have a second large basal dendrite that projects in a more tangential direction, unlike typical pyramidal cells that have a skirt of several basal dendrites. In layers 5 and 6 we located all the triangular neurons (n = 864, roughly one third of the spiny neurons in these layers in our sample; <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Fig. 5A</xref></bold>). The cells we studied all did have a large apical-going dendrite, but unlike typical pyramidal cells, they all also had one large basal dendrite that was projecting in another direction. For some of these cells the large basal dendrite projected directly toward the white matter (green cells, <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-2" hwp:rel-id="F5">Fig. 5B</xref></bold>). The majority however, had one large basal dendrite that projected roughly horizontally within the layer. Interestingly, the direction these basal dendrites projected was highly constrained. Almost equal numbers of these triangular neurons fell into two subcategories: those whose large basal dendrite projected roughly orthogonal to the cutting plane, but towards section #1 and those whose large basal dendrite also projected orthogonal to the cutting plane, but in the opposite direction (towards section #5292) (<bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-3" hwp:rel-id="F5">Fig. 5B</xref></bold>; yellow neurons with basal dendrites projecting towards section #1 or “reverse-going direction”; and pink neurons whose large basal dendrites projected in the opposite or “forward-going direction’’; see <underline>video online</underline>). Two individual neurons from these two subgroups are shown in <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-4" hwp:rel-id="F5">Fig. 5C, D</xref> and <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-5" hwp:rel-id="F5">E</xref></bold>. We measured the angle of each of the basal dendrites of all the triangular neurons. The angles formed a bimodal distribution with peaks for basal dendrites that point along the z-axis in the forward or reverse directions (i.e., where 90 degrees means the basal dendrite is pointing in the z-axis towards slice 0, 270 degrees means the basal dendrite is pointing in the z-axis towards slice 5292, and 0 or 180 degrees means the basal dendrite points within the cutting plane; see <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-6" hwp:rel-id="F5">Fig. 5F, G</xref></bold> and <bold><xref ref-type="fig" rid="figs21" hwp:id="xref-fig-27-1" hwp:rel-id="F27">Supplementary Fig. 21</xref></bold>). The fact that the bimodal modes peaked at 60 degrees away from the white matter (i.e., away from the inverted radial direction) (<bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-7" hwp:rel-id="F5">Fig. 5G</xref></bold> and <bold><xref ref-type="fig" rid="figs21" hwp:id="xref-fig-27-2" hwp:rel-id="F27">Supplementary Fig. 21F</xref></bold>) meant that these two sets of basal dendrites were not parallel to each other. Rather, each subgroup had basal dendrites that projected at a more or less constant angle downward, toward the white matter. For this reason the forward and reverse going basal dendrites formed two sets of parallel basal dendrites that were easily distinguished, one headed forward in the z-axis but tipped slightly towards the white matter and one headed in the opposite direction, and also tipped slightly toward the white matter but at the mirror symmetrical angle (see, <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-8" hwp:rel-id="F5">Fig. 5C, D</xref> and <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-9" hwp:rel-id="F5">E</xref></bold>). Notably, there were almost no triangular cells with a large basal dendrite that projected tangentially, that is, in directions that were roughly aligned to the plane of section (gray cells in <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-10" hwp:rel-id="F5">Fig. 5G</xref></bold>, <bold><xref ref-type="fig" rid="figs21" hwp:id="xref-fig-27-3" hwp:rel-id="F27">Supplementary Fig. 21 D,E</xref></bold>).</p><fig id="fig5" position="float" orientation="portrait" fig-type="figure" hwp:id="F5" hwp:rev-id="xref-fig-5-1 xref-fig-5-2 xref-fig-5-3 xref-fig-5-4 xref-fig-5-5 xref-fig-5-6 xref-fig-5-7 xref-fig-5-8 xref-fig-5-9 xref-fig-5-10 xref-fig-5-11 xref-fig-5-12 xref-fig-5-13 xref-fig-5-14 xref-fig-5-15 xref-fig-5-16 xref-fig-5-17 xref-fig-5-18 xref-fig-5-19 xref-fig-5-20 xref-fig-5-21 xref-fig-5-22 xref-fig-5-23 xref-fig-5-24 xref-fig-5-25 xref-fig-5-26 xref-fig-5-27 xref-fig-5-28 xref-fig-5-29"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIG5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">fig5</object-id><label>Figure 5:</label><caption hwp:id="caption-5"><title hwp:id="title-12">Two mirror symmetrical subgroups of deep layer triangular neurons.</title><p hwp:id="p-38"><bold>A</bold>: Location of neurons with both one large apical and one large basal dendrite; most are found in layers 5 and 6. <bold>B</bold>: Side view of a selection of these neurons, with apical dendrites pointing either forward in the z-stack (magenta) or in the reverse direction (light green) or straight toward the white matter (dark green). Notice that many of the magenta or light green neurons project their large basal dendrite at very similar angles. <bold>C, D, and E</bold>: Example of two bipolar pyramidal neurons with basal dendrites pointing in opposite directions showing the mirror symmetry in these two subgroups (<underline>link</underline>). <bold>F:</bold> The histogram of basal dendrite angles (572 cells; light green, magenta and gray cells from G) shows a clear bimodal distribution with peaks around 90 and 270 degrees representing the light green and magenta groups respectively. <bold>G:</bold> The polar plot of the data in F shows peaks of the basal dendrite directions at ∼ 60 degrees away from the inverse radial direction. Light green: 257 triangular cells with basal dendrite pointing towards section 0; magenta: 247 triangular cells with basal dendrite pointing towards section 5292; gray: 68 triangular cells with basal dendrite pointing sideways in the cutting plane; dark green: 281 compass cells with basal dendrite pointing towards the white matter. 11 compass cells excluded (basal dendrite pointing away from the white matter). <bold>H</bold>: For axons innervating two bipolar pyramidal neurons, connections to neurons of the same polarity are overrepresented and connections to neurons of opposite polarity are underrepresented (blue dots and 95% confidence intervals; red dots show expected values). <bold>I</bold>: Statistically significant likelihood that neurons whose large basal dendrite points in the same direction are nearer to each other than expected by chance. <bold>J, K, L</bold>: Anatomical clustering among members of the two subgroups.</p></caption><graphic xlink:href="446289v4_fig5" position="float" orientation="portrait" hwp:id="graphic-5"/></fig><p hwp:id="p-39">Looking at the full cell segmentations of each of these 257 reverse-going + 247 forward-going triangular neurons with tipped basal dendrites (n=504), several other consistent features were notable. First, the apical dendrites were also sometimes tipped so that neurons whose basal dendrites projected in opposite directions sometimes looked roughly mirror symmetrical to each other (see <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-11" hwp:rel-id="F5">Fig. 5D</xref></bold>). Second, there was an asymmetry to the location of dendritic side branches originating from both the proximal parts of the large basal dendrite and the apical dendrite. Side branches were far more prevalent on the outer edges of these bent bipolar cells than the parts facing inward. For an example, see in <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-12" hwp:rel-id="F5">Fig. 5C</xref></bold>, the dendritic side branches of the proximal apical dendrite facing to the left, and the dendritic side branches of the large basal dendrite projecting downward. The same is true in mirror symmetry for the cell shown in <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-13" hwp:rel-id="F5">Fig. 5E</xref></bold>. This was a general feature of these cells.</p><p hwp:id="p-40">The different shapes, albeit mirrored, of these two categories of neurons raised the possibility that they are functionally distinct as well. Because we had the complete set of axonal inputs that made synapses to all of these cells, it was possible to analyze if their synaptic input was distinct. We thus analyzed the axonal innervation to 504 neurons with forward- and reverse-going basal dendrites to see if individual axons that innervated more than one triangular neuron showed a tendency to innervate neurons whose basal dendrites projected in the same direction. If there were equal numbers of axonal inputs to the forward- and reverse-going neurons, then one would expect twice the likelihood of individual axons to innervate one forward- and one reverse-going dendrite than 2 forward-going or 2 reverse-going (as is the case in flipping a coin twice yielding twice as often one head one tail (HT 50% of the time) versus two heads (HH 25% of the time) or two tails (TT 25% of the time). Because the total number of axonal inputs to forward- and reverse-going neurons was not equal, the expected outcome, assuming a random process, was finding axons that innervated two neurons with forward-going basal dendrites (FF) to be 32% (32% of the axons that innervated two neurons with large basal dendrites would innervate both forward-going neurons), 49% FR and 19% RR (<bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-14" hwp:rel-id="F5">Fig. 5H</xref></bold>, red dots). However, the connectivity was significantly skewed for axons to choose pairs of neurons with basal dendrites that projected in the same directions: FF (40% versus 32% expected) or RR (21% versus 19% expected) compared to dendrites pointed in opposite directions, FR (39% versus 49% expected) (<bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-15" hwp:rel-id="F5">Fig. 5H</xref></bold>, blue dots, p = 3.34 · 10<sup>-14</sup>). In an attempt to understand the origin of this specificity, we divided the axons into excitatory, inhibitory, and inhibitory onto the axon initial segment of the triangular cells. The results were equally significant for the subset of excitatory axons that innervated the basal dendrite neurons as it was for the inhibitory neurons that innervated the dendrites and somata of these cells (<bold><xref ref-type="fig" rid="figs24" hwp:id="xref-fig-30-1" hwp:rel-id="F30">Supplementary Fig. 24</xref></bold>). However, the chandelier interneurons that innervated the axon initial segments of more than one of these cells, did not show a significant preference for co-innervating FF or RR pairs, and in fact, as would be expected in a random model, made most of their co-innervation on RF pairs (<bold><xref ref-type="fig" rid="figs24" hwp:id="xref-fig-30-2" hwp:rel-id="F30">Supplementary Fig. 24</xref></bold>). These triangular cells’ dendritic arbors and axon initial segments overlapped in the volume (see <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-16" hwp:rel-id="F5">Fig. 5B</xref> and <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-17" hwp:rel-id="F5">D</xref></bold>). Nonetheless, when we rendered the two subgroups of neurons (forward-going or reverse-going) we noticed that they were not uniformly distributed in layer 6. Neurons whose large basal dendrites pointed in the same direction are nearer to each other than expected by chance (<bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-18" hwp:rel-id="F5">Fig. 5I</xref></bold>) and the two sets, despite some overlap, appeared clumped (<bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-19" hwp:rel-id="F5">Fig. 5J, K</xref> and <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-20" hwp:rel-id="F5">L</xref></bold>). Each clump formed a rough radial column approximately 250 μm from the next column of the same subclass. Patchiness of axonal projections to layer 6 have been seen with anterograde labeling experiments in humans <sup><xref ref-type="bibr" rid="c41" hwp:id="xref-ref-41-1" hwp:rel-id="ref-41">41</xref></sup>.</p><fig id="figs23" position="float" orientation="portrait" fig-type="figure" hwp:id="F29" hwp:rev-id="xref-fig-29-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS23</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F29</object-id><object-id pub-id-type="publisher-id">figs23</object-id><label>Supplementary Figure 23:</label><caption hwp:id="caption-29"><title hwp:id="title-99">Myelinated axons from skeletonization.</title><p hwp:id="p-196">Statistics about the myelinated axons were extracted from skeletonization. <bold>(A)</bold> Maximum projection view of the myelinated axon calibers (excluding myelin sheath). The colors were mapped linearly to the axon calibers, with the blue end corresponding to 0 and red end corresponding to a caliber of 1 micron. <bold>(B)</bold> The angular distribution of the myelinated axons by layer in the perpendicular-tangential plane defined in <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-26" hwp:rel-id="F3">Fig. 3H</xref></bold>. The vertical axes of the polar plots correspond to the perpendicular direction (perpendicular to the sectioning plane) and the horizontal axes correspond to the tangential direction (tangential to the pia). Only axons with an angle larger than 45 degrees away from the radial direction were counted.</p></caption><graphic xlink:href="446289v4_figs23" position="float" orientation="portrait" hwp:id="graphic-29"/></fig><fig id="figs24" position="float" orientation="portrait" fig-type="figure" hwp:id="F30" hwp:rev-id="xref-fig-30-1 xref-fig-30-2 xref-fig-30-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS24</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F30</object-id><object-id pub-id-type="publisher-id">figs24</object-id><label>Supplementary Figure 24:</label><caption hwp:id="caption-30"><title hwp:id="title-100">Basal dendrite type pair preferences of basal dendrite-targeting axons.</title><p hwp:id="p-197"><bold>(A)</bold> Axon initial segment (AIS) targeting inhibitory axons (p = 0.319, n = 174). <bold>(B)</bold> Largest basal dendrite (non-AIS) targeting inhibitory axons (p = 9.89 · 10<sup>-6</sup>, n=372). <bold>(C)</bold> Largest basal dendrite (non-AIS) targeting excitatory axons (p = 1.60 · 10<sup>-7</sup>, n=808). Red dots indicate expected proportions, blue bars indicate 95% confidence intervals around observed proportions, P-values are calculated using the Chi-Squared Test to compare expected and observed counts.</p></caption><graphic xlink:href="446289v4_figs24" position="float" orientation="portrait" hwp:id="graphic-30"/></fig><fig id="figs25" position="float" orientation="portrait" fig-type="figure" hwp:id="F31" hwp:rev-id="xref-fig-31-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS25</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F31</object-id><object-id pub-id-type="publisher-id">figs25</object-id><label>Supplementary Figure 25:</label><caption hwp:id="caption-31"><title hwp:id="title-101">Classifying Microglia (MGCs) vs. Oligodendrocyte Precursor Cells (OPCs) by using linear embeddings. (A), (B):</title><p hwp:id="p-198">Two-dimensional views of three-dimensional UMAP space derived from the 32-dimensional embedding space. Ground-truth examples used for training a linear classifier shown in darker color. ‘Unclassified’ cells could not be reliably classified as either microglia or OPC. <bold>(C)</bold>: Pie chart shows that more than half of the 6731 candidate cells could be classified by this method.</p></caption><graphic xlink:href="446289v4_figs25" position="float" orientation="portrait" hwp:id="graphic-31"/></fig><fig id="figs26" position="float" orientation="portrait" fig-type="figure" hwp:id="F32" hwp:rev-id="xref-fig-32-1 xref-fig-32-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIGS26</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F32</object-id><object-id pub-id-type="publisher-id">figs26</object-id><label>Supplementary Figure 26:</label><caption hwp:id="caption-32"><title hwp:id="title-102">Excitatory and inhibitory synapses in different layers. (A):</title><p hwp:id="p-199">Densities of excitatory and inhibitory synapses in different layers. The values of this plot can be found in <xref ref-type="table" rid="tbls10" hwp:id="xref-table-wrap-10-1" hwp:rel-id="T10">Supplementary Table 10</xref>. <bold>(B):</bold> E/I balance of synapse numbers in different layers. This analysis includes all automatically detected synapses within a region of 0.65 mm<sup>3</sup> of the dataset, using the layer boundaries and volumetric tissue mask used for estimating cell densities (<xref ref-type="fig" rid="figs5" hwp:id="xref-fig-11-6" hwp:rel-id="F11">Supplementary Figure 5</xref>). This statistics is based on 116.92 million synapses, of which 86.08 million were classified as excitatory (73.6%) and 30.84 million as inhibitory (26.4%). The average number of synapses is 0.1789 per μm<sup>3</sup> in the analyzed volume.</p></caption><graphic xlink:href="446289v4_figs26" position="float" orientation="portrait" hwp:id="graphic-32"/></fig></sec><sec id="s2d" hwp:id="sec-6"><title hwp:id="title-13">Axonal Targeting</title><p hwp:id="p-41">Because we could identify all the synapses on a neuron and the identity of the presynaptic partner of each (<bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Fig. 6A</xref></bold>), we noted that only a small percentage of the axonal inputs to a neuron established more than one synapse with that postsynaptic cell (<bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-2" hwp:rel-id="F6">Fig. 6B</xref></bold>). For nearly all cells, the histogram of the number of synapses per axonal input showed a rapid fall off from the prevalent motif where an axon established one synapse with a target cell (&gt; 90%). Two synapse contacts occurred uncommonly, however all neurons showed some two synapse contacts. Even fewer three synapse contacts were observed and typically four synapse connections occurred only 0.001% of the time. One common exception to weak connectivity is the chandelier axon input to axon initial segments of pyramidal cells. Their cartridge inputs sometimes give rise to ten or more synapses from a single presynaptic neuron. On dendrites however, weak connections are the rule. Nonetheless, we noted exceptional outlier connections on dendrites, and more rarely somata where a single axon established eight or even twenty synapses with a single target cell (<bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-3" hwp:rel-id="F6">Fig. 6C</xref> and <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-4" hwp:rel-id="F6">D</xref></bold>). In the example shown in <bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-5" hwp:rel-id="F6">Fig. 6C</xref></bold>, an axon establishes nineteen excitatory synapses distributed to several dendrites of an inhibitory neuron. Another example in which an excitatory neuron in the volume establishes nine synapses on an inhibitory postsynaptic neuron is shown in <bold><xref ref-type="fig" rid="figs19" hwp:id="xref-fig-25-1" hwp:rel-id="F25">Supplementary Fig. 19</xref></bold>. This example is notable because of the way in which the synapses are established on both sides of an en passant synapse between an axon and a dendrite (see below).</p><fig id="fig6" position="float" orientation="portrait" fig-type="figure" hwp:id="F6" hwp:rev-id="xref-fig-6-1 xref-fig-6-2 xref-fig-6-3 xref-fig-6-4 xref-fig-6-5 xref-fig-6-6 xref-fig-6-7 xref-fig-6-8 xref-fig-6-9 xref-fig-6-10 xref-fig-6-11 xref-fig-6-12 xref-fig-6-13 xref-fig-6-14 xref-fig-6-15"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/FIG6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">fig6</object-id><label>Figure 6:</label><caption hwp:id="caption-6"><title hwp:id="title-14">Unusually powerful synaptic connections.</title><p hwp:id="p-42"><bold>A</bold>: We assayed all innervation to each neuron in the volume. Left panel, a pyramidal cell showing the sites of its incoming synapses (red balls). Right panel shows all the axons that give rise to the incoming synapses. <bold>B</bold>: The vast majority of the 5600 axons innervating this pyramidal cell establish one synapse with it, with a small number of axons that provide two to four. <bold>C:</bold> Occasionally a very large number of synapses exist between an axon and a dendrite, as here where an axon (cyan) provides 19 synapses to three dendrites of an inhibitory neuron (red) in layer 2- see inset. Yellow balls show sites of all incoming synapses. <bold>D</bold>: Histogram shows that most inputs to this cell are weak and the powerful axon is an outlier. <bold>E-H:</bold> Despite their rarity, in such big data there are many strong connections between excitatory and inhibitory neurons. <bold>E:</bold> For example, in this case an excitatory axon (green) forms 8 synapses onto a spiny dendrite of an excitatory neuron (purple). As often was the case, one of these connections is en passant and the rest of the synapses appeared to require directed growth of the axon to contact this same dendrite. <bold>F</bold> An excitatory axon (blue) forms 8 synapses onto a smooth dendrite of an inhibitory neuron (green) again with one en passant connection and the rest apparently requiring directed growth. <bold>G</bold>: An inhibitory axon (red) forming 18 synapses on the apical dendrite of a spiny pyramidal excitatory neuron (yellow). <bold>H</bold>: An inhibitory axon (yellow) forming 13 synapses onto the smooth dendrite (purple) of another inhibitory neuron, including one en passant contact. <bold>I</bold>: A log normal plot showing incidence of axons establishing between 1 and 20 synapses to individual postsynaptic target cells (red line). This incidence far exceeds a model where these same axons establish the same number of synapses but are slightly displaced in space (blue line, see Methods). For all connection strengths greater than 3 synapses, axons show more multiple synapses than expected by chance. For example there were 94-fold more axonal connections with 8 synapses to one target cell than expected if axons establish the same number of synapses on nearby dendrites in a random way.</p></caption><graphic xlink:href="446289v4_fig6" position="float" orientation="portrait" hwp:id="graphic-6"/></fig><p hwp:id="p-43">Such outlier connections were not restricted to excitatory input to inhibitory dendrites (see also <bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-6" hwp:rel-id="F6">Fig. 6F</xref></bold>). Excitatory axons also occasionally formed strong (multisynaptic) connections onto spiny (excitatory) postsynaptic neurons (<bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-7" hwp:rel-id="F6">Fig. 6E</xref></bold>). In addition, inhibitory axons made such outlier powerful connections onto the shafts of excitatory neurons (<bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-8" hwp:rel-id="F6">Fig. 6G</xref></bold>) and onto the dendrites of inhibitory neurons (<bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-9" hwp:rel-id="F6">Fig. 6H</xref></bold>). Thus both excitatory and inhibitory neurons establish unusually strong connections with both excitatory and inhibitory postsynaptic cells, albeit rarely. Importantly, these strong connections appeared to be a property of the particular pre- and postsynaptic pair: most of the synapses established by the axons that formed outlier connections were typical one-synapse connections (on other neurons) and most of the input to the postsynaptic cells that received these powerful inputs were typical one-synapse weak connections (from other axons). Despite the overall rarity of strong connections, we found that 28% of the 2659 neurons that were well innervated in the volume (i.e., that had at least 3000 axonal inputs onto their dendrites) had at least one input that had 7 or more synapses, raising the possibility that rare powerful axonal inputs are a general characteristic of neuronal innervation in the human cerebral cortex.</p><p hwp:id="p-44">Many of these powerful connections shared a common morphological configuration. In some cases the axon co-fasciculated with the dendrite to remain in close contact for tens of microns, allowing it to establish many en passant synapses with the same target cell (e.g., <bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-10" hwp:rel-id="F6">Fig. 6G</xref></bold>). More commonly however, the axon did not appear to have a special affinity for growing along the dendrite and approached the dendrite, as was typical of axons that made one synapse connections, by forming a synapse at the site of intersection without deviating its trajectory before or after the synapse. Remarkably, in addition to a synapse at the closest point of intersection, these axons sent terminal branches to the same target cell, usually both before and after the intersection. Because many of these axon fragments left the volume without reaching a soma, it was not possible in most cases to decide which side of the intersection was actually “before” or “after”. Nonetheless, the behavior of the axon was the same on both sides: the axon potentially sprouted “up” to establish synapses on the dendrite, and on the other side it potentially sprouted terminal branches “down” to establish additional synapses with the same target cell (see <bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-11" hwp:rel-id="F6">Fig. 6E, F</xref> and <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-12" hwp:rel-id="F6">H</xref></bold> and <bold><xref ref-type="fig" rid="figs19" hwp:id="xref-fig-25-2" hwp:rel-id="F25">Supplementary Fig. 19</xref></bold>). All of these cases, and many of the thousands strong connections not shown, were suggestive of intentionality, meaning that some pre-postsynaptic pairs had a reason to be far more strongly connected than was typical. The alternative possibility is that, given the thousands of axonal inputs to each of thousands of target cells, outlier results are simply part of the long tail of a distribution. These powerful connections may also be more common than we found given that axon breaks in the automatic segmentation likely had a disproportionately greater likelihood of reducing the number of connections as the length and number of synapses produced by an axon increased. We thus sought a conservative model to simulate the number of axons with powerful connections, based on the actual trajectories of axons and dendrites and the observed properties of axonal branches. The model allowed every simulated axon to form the same number of synapses as it did in the actual data, but now on any of the dendritic branches that came within its vicinity, to match the reach of the actual axons. We were interested to see how often an axon would establish one or more synapses with a single target cell. The results shown in <bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-13" hwp:rel-id="F6">Fig. 6I</xref></bold>, indicate that this random model of synaptic partnering is inconsistent with the incidence of strongly paired neurons that we found in H01 (p &lt; 10<sup>-</sup><sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-2" hwp:rel-id="ref-10">10</xref></sup>). This tendency for axons to establish more synapses with certain target cells than expected by chance was found to about the same degree when we analyzed just inhibitory or just excitatory axons. Thus, amongst a large number of exceedingly weak connections, human cerebral cortex neurons receive a small subset of inputs with approximately an order of magnitude more power.</p></sec></sec><sec id="s3" hwp:id="sec-7"><title hwp:id="title-15">Discussion</title><p hwp:id="p-45">The central tenet of connectomics is capturing both big and small scales: reconstructing individual synaptic connections in volumes large enough to encompass neural circuits <sup><xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-1" hwp:rel-id="ref-42">42</xref></sup>. Our aim in this work was to study the structure of the human cerebral cortex at nanometer-scale resolution within a ∼millimeter-scale volume that permitted seeing all of the cortical layers and some white matter. To observe intracortical connections between six layers of cortex, it was necessary to image a volume encompassing its full thickness, which in humans (including this sample) averages 2.5 mm from the top of layer 1 to the bottom of layer 6 <sup><xref ref-type="bibr" rid="c43" hwp:id="xref-ref-43-1" hwp:rel-id="ref-43">43</xref></sup>. Given that the axons of neurons may travel over one hundred microns before making their first synapses <sup><xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-1" hwp:rel-id="ref-44">44</xref></sup>, the other two dimensions of the imaged volume must be wide enough and deep enough to trace intracortical network connections. We found that a full cortical thickness volume equivalent to a cubic millimeter provided us with sufficient tissue. The nanometer scale is required to identify individual synapses and distinguish tightly-packed axonal and dendritic processes from one another <sup><xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-1" hwp:rel-id="ref-45">45</xref></sup>. This big and small requirement necessitated the acquisition of trillions of voxels, and hence more than a petabyte of digital image data. This petascale dataset offers the opportunity to look at the same volume of brain tissue at supracellular, cellular, and subcellular levels and to study the relationships between and among large numbers of neurons, glia, and vasculature. Most importantly perhaps it gives a glimpse into the enormous complexity of the synaptic relationships between many neurons in a slab of human association cerebral cortex.</p><p hwp:id="p-46">This “digital tissue” <sup><xref ref-type="bibr" rid="c46" hwp:id="xref-ref-46-1" hwp:rel-id="ref-46">46</xref></sup> is a ∼660,000-fold scale up of an earlier saturated reconstruction from a small region of mouse cortex, published in 2015 <sup><xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-1" hwp:rel-id="ref-47">47</xref></sup>. Although this scaleup was difficult, it was not hundreds of thousands of times more difficult and took about the same amount of time as the previous data set (∼4 years). This means that many of the technical hurdles with imaging and computer-based analysis have improved dramatically over the past few years. This improvement was in large part due to two noteworthy advances: fast imaging owing to multibeam scanning electron microscopy <sup><xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-1" hwp:rel-id="ref-48">48</xref></sup> and the profound effect of AI on image processing and analysis <sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-2" hwp:rel-id="ref-9">9</xref></sup>. The rapid improvements over the past few years <sup><xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-1" hwp:rel-id="ref-49">49</xref>–<xref ref-type="bibr" rid="c58" hwp:id="xref-ref-58-1" hwp:rel-id="ref-58">58</xref></sup> argues that analyzing volumes that are even three orders of magnitude larger, such as an exascale whole mouse brain connectome, will likely be in reach within a decade <sup><xref ref-type="bibr" rid="c59" hwp:id="xref-ref-59-1" hwp:rel-id="ref-59">59</xref></sup>.</p><p hwp:id="p-47">Studying human brain samples has special challenges. Fortunately, the quality of the H01 brain sample was comparable to cardiac perfused rodent samples used in the past. This strongly suggests that rapid immersion of fresh tissue in fixative is a viable alternative to perfusion and should be especially useful in human connectomic studies going forward. More problematic is that fresh samples from completely normal individuals are unlikely to ever be available via this neurosurgical route. Although this patient’s temporal lobe did not show obvious signs of abnormality, as stated by the neuropathologist, it is possible that long term epilepsy had some more subtle effects on the connectivity or structure of the cortical tissue. Moreover, it is likely that an epilepsy patient such as the one who supplied this sample was treated (albeit with limited success, hence the surgery) with pharmacological agents that could affect brain structure. Importantly however, the neurosurgical specimen that we obtained was not part of the pathological process per se, it was removed only because it was “in the way” – that is, the surgical procedure could not be done without its removal. Given that patients with successful outcomes after surgery have normal brain function, it is assumed that the procedure pinpointed the abnormality, and the remaining brain is functioning normally. The normal functioning brain would presumably include the incidentally resected tissue. However, only by comparing samples obtained from patients with different underlying disorders may we eventually learn whether this sample is normal. There were some oddities in this tissue that we found, but at present, we cannot decide if they are pathological or just unusual. These include a number of extremely large spines and axon varicosities filled with unusual material (see <bold><xref ref-type="fig" rid="figs7" hwp:id="xref-fig-13-2" hwp:rel-id="F13">Supplementary Fig. 7</xref></bold>).</p><p hwp:id="p-48">Another challenge with human brain tissue from the association cortex is that it is probably the location of circuits that were established as a consequence of experience. If memories are stored in this part of the human brain, then it is unlikely that another brain will be similar, in the way that, for example, multiple <italic toggle="yes">C. elegans</italic> nematode brains are stereotyped.<sup><xref ref-type="bibr" rid="c60" hwp:id="xref-ref-60-1" hwp:rel-id="ref-60">60</xref></sup> But even in isogenic worms, 40% of the neuron to neuron connectivity was different between specimens. Given the far greater variability in human experience, behavior, memory and genetics, and the fact that humans and other vertebrates have pools of identified neurons classes rather than individual identified neuron types, it will no doubt be challenging to compare neural circuits between brains. This challenge also presents an opportunity: to uncover the physical instantiation of learned information. Even if the circuits differ in their particulars, it is possible that a metalogic for memory can be uncovered by looking at enough data, maybe in the future field of “engramics” <sup><xref ref-type="bibr" rid="c61" hwp:id="xref-ref-61-1" hwp:rel-id="ref-61">61</xref>, <xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-1" hwp:rel-id="ref-62">62</xref></sup>. To be sure, approaches to the profound questions of uncovering the meaning in neural circuit connectivity data are in their infancy, but it would seem to us that perhaps the best stimulus for making progress will be an abundance of actual data -- this petascale dataset is a start.</p><p hwp:id="p-49">However, we have come to realize that big data raises big problems that do not have ready answers. Although segmentation is improving rapidly, the automatically reconstructed circuits are far from perfect. The tension between split errors and merge errors means that depending on the aim, one may prefer segmentations that provide fewer split errors or fewer merge errors (we share online two agglomerations that are both these alternatives, c2 and c3). In this sample we used higher level semantic annotations to remove some merge errors, such as trimming astrocytes or axons that were merged to dendritic trees. These higher-level machine learning approaches are likely to be profoundly useful as they become perfected in the years to come. At the current level of automated accuracy, it is impractical to manually correct all segmentation errors in a volume as large as H01. However, when we scrutinized the segmentation errors in this data, they were almost always secondary to flaws in the image acquisition, such as staining artifacts at a critical site, alignment difficulties due to variations in the thickness, or distortions of the sections that were picked up onto tape. We suspect that improved methods of tissue sectioning and staining may help to reduce the number of errors in the future.</p><p hwp:id="p-50">One power of connectomic study of large data is that rare events, which might be too uncommon to find in a small sample, are manifest in the larger data size. It has long been recognized that dendritic trees allow neurons to collect information from, as shown in this study, many thousands of different neurons. Because the overwhelming majority of these connections are weak (∼ 99.9% with 1, or at most 4 synapses), it has been assumed that neural processing must occur by integration via spatial and temporal summation of a number of weak inputs that happen to be active at roughly the same time. We found however that amongst the very large population of weak axonal connections, there are a few inputs that are outliers forming ten or even twenty synapses on the dendrites of a postsynaptic neuron. By virtue of their common origin, these multiple release sites assure that one input will synchronously activate a target cell, perhaps strongly enough to be suprathreshold (if excitatory) or able to block activity (if inhibitory). In a much smaller volume of proofread mouse somatosensory cortex we previously saw axons that made as many as up to five synapses on the same dendrite that also did not appear to be a chance occurrence<sup><xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-2" hwp:rel-id="ref-47">47</xref></sup>, perhaps implying that sparse powerful inputs may be a general feature of mammalian brains.</p><p hwp:id="p-51">A number of years ago, neuropsychologists <sup><xref ref-type="bibr" rid="c63" hwp:id="xref-ref-63-1" hwp:rel-id="ref-63">63</xref></sup> made the case that motor learning occurs in three stages: cognitive, associative, and autonomous. The point being that early on a motor task is hard to do, and takes much cognitive effort, however eventually it occurs with little thought (e.g., learning to use the brake pedal when seeing a red light as a beginner driver, versus the automatic and almost unconscious braking by an experienced driver). Clearly the human brain can reach a decision much more quickly once a task is completely learned. How might that occur? One possibility is to strengthen a pathway so it is less reliant on summation from many sources, as might occur if one input becomes capable of activating a target cell on its own. Interestingly, this is the maturational strategy in the final limb of the motor system <sup><xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-1" hwp:rel-id="ref-64">64</xref>, <xref ref-type="bibr" rid="c65" hwp:id="xref-ref-65-1" hwp:rel-id="ref-65">65</xref></sup>. In young animals (probably including humans) neuromuscular junctions are innervated by many weak motor axons, at which point it is likely that multiple axons need to be activated synchronously to cause reliable muscle fiber twitching. Over time, many of these inputs are eliminated and the remaining axon compensates by adding more synaptic release sites <sup><xref ref-type="bibr" rid="c66" hwp:id="xref-ref-66-1" hwp:rel-id="ref-66">66</xref></sup>. The remaining input is strong enough to dependably activate the muscle fiber given the high quantal content of twenty or more release sites. Such strengthening also occurs in the CNS, such as the strong excitatory input of one climbing fiber on an inhibitory postsynaptic neuron, the Purkinje cell. This multisynaptic release also emerges after a set of weaker climbing fiber inputs are eliminated and the remaining axon adds many synapses <sup><xref ref-type="bibr" rid="c67" hwp:id="xref-ref-67-1" hwp:rel-id="ref-67">67</xref></sup>. Is it possible that the association cortex permits some inputs to become autonomous drivers of activity by the addition of synapses? If so, such connectivity should be even less common in younger human brains.</p><p hwp:id="p-52">The presumption has long been that human neuroscience <italic toggle="yes">must</italic> utilize approaches that are both less direct, and more poorly resolved than those that can be brought to bear on questions in animal models. In particular, it has been assumed that while it might be possible to get complete wiring diagrams and structural cell type analysis of all cells in the cerebral cortex of a rodent, or in the CNS of a fruit fly or a worm, a similar feat would be impossible in a human. However, should the technical barriers with human specimens be overcome, would it not be more relevant to do these same kinds of analyses in human specimens? Would it not be especially significant to do this in specimens from humans afflicted with psychiatric or developmental disorders? The petascale data presented here supports the idea that fine-scale connectomics is a viable path for learning about the human brain.</p></sec></body><back><ack hwp:id="ack-1"><title hwp:id="title-16">Acknowledgments</title><p hwp:id="p-53">We thank Matthew Frosch, MD, PhD, Massachusetts General Hospital for kindly providing the human tissue. We are very grateful for all the advice from the multiSEM team at Carl Zeiss that helped us get their device into our workflow. We would like to thank Kathleen Rockland for helping us with relevant literature. We are also appreciative for the careful reading of the manuscript by Suzanne Montgomery. Several students provided help in various aspects of this project; they include: Allen Judd, Elisa Paravino, Ray Jiang, Rachael Han, Peng Miao, Tianxin Lu and Jana Afeeli. We gratefully recognize the generous support from the NIMH for the Conte Center Award: P50 MH094271, The Stanley center at the Broad Institute, and the BRAIN Initiative of the NIH for support from U19 NS104653, U24 NS109102 and UO1 EB026996.</p></ack><sec id="s4" hwp:id="sec-8"><title hwp:id="title-17">Data availability</title><p hwp:id="p-54">All data is available via the dedicated webpage for this project: <ext-link l:rel="related" l:ref-type="uri" l:ref="http://h01-release.storage.googleapis.com/landing.html" ext-link-type="uri" xlink:href="http://h01-release.storage.googleapis.com/landing.html" hwp:id="ext-link-10">http://h01-release.storage.googleapis.com/landing.html</ext-link>.</p></sec><sec id="s5" hwp:id="sec-9"><title hwp:id="title-18">Code availability</title><p hwp:id="p-55">All custom code used is cited in the text, and is freely available at <ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/ashapsoncoe/h01" ext-link-type="uri" xlink:href="https://github.com/ashapsoncoe/h01" hwp:id="ext-link-11">https://github.com/ashapsoncoe/h01</ext-link>.</p></sec><sec id="s6" hwp:id="sec-10"><title hwp:id="title-19">Statistics</title><p hwp:id="p-56">For the analysis of spatial clustering of cells in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-21" hwp:rel-id="F5">Figure 5</xref>, Fisher’s Exact Test was used to establish whether equal-color neighbours were occurring significantly more often than by chance (p = 0.00745, n = 504). For the analysis of forward and reverse facing connectivity in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-22" hwp:rel-id="F5">Figure 5</xref>, the Chi-Squared Test was used to compare observed and expected frequencies of forward-forward, forward-reverse and reverse-reverse linked pairs of forward and reverse going neurons (p = 3.34·10-14, n = 1180). For the analysis of connectivity strengths in <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-14" hwp:rel-id="F6">Figure 6</xref>, the Chi-Squared Test was used to compare observed and expected frequencies of axons’ strongest connections (p &lt; 10<sup>-10</sup>, n = 79,816,870), but plotted as percentages for clarity.</p></sec><sec id="s7" hwp:id="sec-11"><title hwp:id="title-20">Materials &amp; Correspondence</title><p hwp:id="p-57">Correspondence and requests for materials should be addressed to J.W.L. and V.J.</p></sec><sec id="s8" hwp:id="sec-12"><title hwp:id="title-21">Author contributions</title><p hwp:id="p-58">Tissue sample was prepared for EM and embedded for sectioning by DL. Block trimming and initial screening was done by DRB. Sample block was sectioned by RLS. Sections were mounted onto wafers and post-stained by ASC. Raw electron microscopy data was acquired by ASC, RLS and YW. Image quality assessment tools were developed by YW and used to assess images by ASC. Image alignment was performed by A Pope, YW, SW and A Peleg, with fine realignment by MJ. Bridging of re-entry sections was performed by SW, AP, ASC, AF and RK. Ground truth for segmentation was produced by ASC, DRB, AF and RK. Ground truth for semantic segmentation was produced by ASC, NK and DRB. Segmentation and agglomeration was performed by MJ, with further correction of agglomeration by PHL. Ground truth for synapse prediction was produced by ASC, AF, RK, JWC, DA, JL, DW, ZL and HF. Synapse prediction was performed by TB. Ground truth for synapse excitatory vs inhibitory classification was produced by ASC, TB and NK. Synapse excitatory vs inhibitory classification performed by TB. Ground truth for subcompartment classification produced by PL, ASC, AF and RK. Skeletonization and subcompartment classification was performed by PHL. Embeddings produced by SD. Proofreading of neurons performed by ASC, BF, HW, JWC, DA, JL, and LB. Identification of cortical layers performed by ASC and LB. Neuroglancer software developed by JMS. API development and support performed by LL. CREST proofreading program developed by ASC. Extension of VAST to access Google-hosted datasets developed by DRB. Manual identification of cell nuclei performed by ASC, BF and HW. Manual cell soma painting and classification of cells performed by DRB. Analysis of powerful synaptic connections performed by ASC. Analysis of triangular neurons performed by DRB and ASC. Astrocyte distance analysis, type-specific blood vessel distance analysis, and cell density analysis was performed by DRB. Analysis of synaptic network was performed by ASC, JWL and YW. Analysis of inputs to interneurons and pyramidal neurons by NK, YW and ASC. Manual annotation of blood vessels cells and their skeletonization was performed by ES and DRB. Manual reconstruction of whorled axons and identification of anomalous objects and chandelier-chandelier connections was performed by NK. Analysis of distribution of myelin was performed by YW. Manuscript written by JWL, ASC, MJ, AP, DRB, TB, PHL, VJ.</p></sec><sec id="s9" hwp:id="sec-13"><title hwp:id="title-22">Competing interests</title><p hwp:id="p-59">The authors declare no competing interests.</p></sec><sec id="s10" hwp:id="sec-14"><title hwp:id="title-23">Methods</title><sec id="s10a" hwp:id="sec-15"><title hwp:id="title-24">Sample acquisition and preparation</title><p hwp:id="p-60">A 45 year old woman with a history of simple and complex partial seizures with occasional generalization, refractory to medical management, underwent surgical ablation of an epileptic focus in her left medial temporal lobe. During the procedure medial temporal lobe tissue containing the epileptic focus, as well as unaffected cortical tissue from the left anterior temporal lobe was removed. A pathological assessment of the excised medial temporal lobe sample showed hippocampal sclerosis, and marked neuronal loss from CA1 and less severe neuronal loss from DG, CA2 and CA3, but no significant pathologic changes were noted in the anterior temporal lobe sample that we reconstructed. The anterior temporal lobe sample when excised was 2.5 cm by 0.8 cm in its longest and perpendicular axes, forming an irregular oval shape that included the full thickness of the human cerebral cortex (see <bold><xref ref-type="fig" rid="figs11" hwp:id="xref-fig-17-1" hwp:rel-id="F17">Supplementary Fig. 11</xref></bold>). Immediately after excision, Matthew P. Frosch, M.D., Ph.D., a neuropathologist, fixed the sample by immersion in cold 2.5% paraformaldehyde / 2.5% glutaraldehyde in 0.1 M Sodium Cacodylate Buffer, pH 7.4 (Electron Microscopy Sciences, #15949) <sup><xref ref-type="bibr" rid="c68" hwp:id="xref-ref-68-1" hwp:rel-id="ref-68">68</xref></sup>) and maintained the sample in fixative overnight. The sample was then washed in 0.1 M Sodium Cacodylate and 2 mM CaCl<sub>2</sub> buffer, trimmed manually and divided into 300 micrometer-thick sub-samples by Vibratome (Leica VT1000S), each then stained with reduced osmium tetroxide-thiocarbohydrazide (TCH)-osmium <sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">6</xref></sup>, washed in ddH<sub>2</sub>O, stained with en-bloc 2% uranyl acetate overnight at 4°C, dehydrated with 20%, 50%, 70%, 80%, and then 100% ethanol, washed twice in propylene oxide (PO), immersed in a 50:50 mixture of PO and 812 Epon resin (EMbed-812, Electron Microscopy Sciences, #14121) overnight, followed by a 30:70 PO Epon mixture immersion overnight and then 100% Epon immersion overnight. The infiltrated tissue sample was cured at 60°C for 48 hours.</p></sec><sec id="s10b" hwp:id="sec-16"><title hwp:id="title-25">Sample sectioning</title><p hwp:id="p-61">The second Vibratome section down from the original sample surface was selected for electron microscopy imaging. The resin block was trimmed using a 3 mm UltraTrim diamond knife (Diatome, USA) and ultramicrotome (UC6, Leica, Germany) to a rectangular area of 4584 x 1975 micrometers, oriented so that it included all cortical layers from layer 1 down to superficial white matter. 30-40 nm thick serial sections were cut with several 4 mm wide Ultra 45 or Ultra 35 diamond knives using the automated tape collection ultramicrotome (ATUM) system as described in <sup><xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-3" hwp:rel-id="ref-47">47</xref></sup> at a cutting speed of 0.3 mm/s and collected onto carbon-coated Kapton tape. After 1639 serial sections had been cut, the cutting process became unstable, with sections intermittently breaking into two or more pieces (see <bold><xref ref-type="table" rid="tbls1" hwp:id="xref-table-wrap-1-1" hwp:rel-id="T1">Supplementary Table 1</xref></bold> for per-section details), resulting in cutting being paused after 1695 sections so that the knife could be replaced, as blunting of the knife during the cutting process has been observed to result in unstable cutting <sup><xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-4" hwp:rel-id="ref-47">47</xref></sup>. Upon resuming the cutting, due to the replaced knife being significantly non-parallel to the face of the block, sections were initially composed of one part of the face of the block (termed ‘reentry’ sections), and gradually became ‘full’ sections after thirty further sections had been cut. We estimate that we lost no more than the equivalent of three 30 nm sections in this reentry region. The subsequent alignment process in the reentry region is described below. After a further 66 sections had been cut, cutting remained unstable, as indicated sections which alternated between being thicker and thinner than the desired 30 nm thickness. Cutting was paused and the block rotated 180 degrees, with cutting resumed at 33 nm per section. This resulted in a second series of ‘reentry’ sections of 62 sections duration, after which cutting remained stable for a further 3193 sections, giving a total of 5053 consecutive sections cut and collected onto tape. The tape was manually inspected for evidence of failure to cut a section followed by a ‘double-thickness’ section of 60 or 66 nm thickness and found that 5.8% of sections were ‘double-thickness’, as listed in <bold><xref ref-type="table" rid="tbls1" hwp:id="xref-table-wrap-1-2" hwp:rel-id="T1">Supplementary Table 1</xref></bold>. These sections are deliberately duplicated in the digital aligned stack to maintain a realistic size of the digital dataset, resulting in 5292 layers in the digital stack.</p></sec><sec id="s10c" hwp:id="sec-17"><title hwp:id="title-26">Estimation of tissue compression introduced during ultrathin sectioning</title><p hwp:id="p-62">Comparing electron microscopic images of full ultrathin sections with known pixel resolution to photographs of the trimmed tissue sample in the resin block before sectioning allowed us to estimate the compression factor of ultrathin sections with respect to the embedded block which occurred during sectioning and tape collection. Compression in the direction parallel to the knife edge was negligible (0.997) whereas there was a large compression perpendicular to the knife edge (0.72). This means that sections in the electron microscopic stack are compressed by 27.96% with respect to the tissue in the resin block, but only along the longer axis of the section. The corrected true pixel size in the published aligned image stack is thus estimated as 11.1 nm x 8 nm or 5.55 nm x 4 nm in the full-resolution images. This analysis only estimates size changes between embedded tissue and the EM image stack. It excludes any size changes that may have occurred between the tissue <italic toggle="yes">in vivo</italic> and the processed, resin-embedded sample.</p></sec><sec id="s10d" hwp:id="sec-18"><title hwp:id="title-27">Wafer fabrication and mapping</title><p hwp:id="p-63">The tape holding the sections was cut into strips containing between nine and fifteen sections each and attached via strips of 25.4 mm double-sided carbon tape (Ted Pella, USA) onto either round or square silicon wafers (University Wafers, USA) of either a 4 inch diameter or a 90 mm x 80 mm area, respectively. Each wafer held nine strips of tape, and between 110 (round wafer) and 135 (square wafer) sections. To enhance the signal from cell membranes, each wafer was first plasma-treated for 30 seconds (operating pressure of 6 x 10<sup>-1</sup> mb, plasma current of 10 mA) to increase its hydrophilicity and then immediately stained with 4% uranyl acetate for three minutes, rinsed with ddH<sub>2</sub>O for thirty seconds three times, air-dried, stained with 3% lead citrate for three minutes, rinsed and air-dried as before, stored overnight under vacuum and mounted on a metal wafer holder with fiduciaries to target high-resolution imaging by the multibeam scanning electron microscope (mSEM). As previously described <sup><xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-2" hwp:rel-id="ref-7">7</xref></sup>, we mapped the position of each section on the wafer, relative to fiducial marks on the stage by using a reflected light microscope to produce a low-resolution (3.57 μm / pixel) optical image of each wafer mounted on the wafer holder, which identified the position of each section relative to the wafer holder fiduciaries. These positions were sent to the electron microscope to guide the stage automatically to each section. Several whole sections were imaged by low-resolution SEM (220 nm / pixel, secondary emission, FEI Magellan microscope), within which cortical layers and a perpendicular axis of apical dendrites and axonal bundles were observed (see <bold><xref ref-type="fig" rid="figs9" hwp:id="xref-fig-15-1" hwp:rel-id="F15">Supplementary Fig. 9</xref></bold> for a representative example). A six-sided polygonal region of interest (ROI) was defined to follow this axis, using distances from the corners of the section as indicated in <bold><xref ref-type="fig" rid="figs9" hwp:id="xref-fig-15-2" hwp:rel-id="F15">Supplementary Fig. 9</xref></bold>. This ROI was superimposed onto each section in the optical image of each wafer using the Zen software package (Zeiss), to target high resolution imaging in the mSEM.</p></sec><sec id="s10e" hwp:id="sec-19"><title hwp:id="title-28">EM image acquisition</title><p hwp:id="p-64">To speed imaging, a wafer attached to the stage was mounted in the multibeam scanning electron microscope (mSEM; Zeiss), the stage was automatically sent to each section, and the scope’s software calculated the local stage movements to image each section. Each section was imaged by scanning 61 overlapping rectangular regions with 61 electron beams simultaneously <sup><xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-2" hwp:rel-id="ref-48">48</xref></sup>, producing 61 image tiles, each 3128 x 2724 pixels, comprising one multibeam field of view (mFOV) that had a length of 108 μm <sup><xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-3" hwp:rel-id="ref-48">48</xref></sup> (<bold><xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Fig. 1</xref></bold>). Once one mFoV had been acquired, the mSEM stage moved to an adjacent site within the section to acquire another mFoV. Each image ROI required approximately 700 overlapping mFoVs to image the entire ROI at 4 nm per pixel resolution, with a tile overlap (within mFoV) of 10% and a between-mFoV overlap of between 3% and 10% (see <bold><xref ref-type="table" rid="tbls1" hwp:id="xref-table-wrap-1-3" hwp:rel-id="T1">Supplementary Table 1</xref></bold> for all per-section imaging metrics). Each ROI was imaged with a landing energy of 1.5 kV with each scanning beam at 576 pA, and a dwell time of either 200, 400 or 800 ns per pixel. The data was imaged using secondary electron emission. Typically sections were imaged with a 200 ns dwell time, but if small structures such as the outline of synaptic vesicles, or thin processes could not be seen clearly, then the section would be reimaged at a higher dwell time. At a dwell time of 200 ns and stage settling-time of 0.6 s, acquisition of one ROI takes approximately thirty minutes. Brightness and contrast for each ROI were set to maximize the dynamic range of the images acquired, by maximizing the spread of the histogram of image grey levels without clipping its tails. Prior to imaging each ROI, the mSEM was programmed to determine the optimal focus distance and stigmation settings at 12 or more ‘focus support points’ (FSPs) within the section. If this procedure failed at more than 25% of the FSPs, then the ROI was not acquired, and the procedure was restarted with new FSPs added and failed FSPs removed or moved to other locations. Once this procedure had succeeded at 75% or more FSPs, Delaunay triangulation was used to interpolate a topological map of the ROI, to guide the autofocus of the mSEM during the imaging of the ROI.</p></sec><sec id="s10f" hwp:id="sec-20"><title hwp:id="title-29">EM image quality checks</title><p hwp:id="p-65">After each ROI had been acquired, a suite of custom MATLAB scripts (<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/lichtman-lab/mSEM_workflow_manager" ext-link-type="uri" xlink:href="https://github.com/lichtman-lab/mSEM_workflow_manager" hwp:id="ext-link-12">https://github.com/lichtman-lab/mSEM_workflow_manager</ext-link>) was used for further quality checks. A previously described measurement of image quality <sup><xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-3" hwp:rel-id="ref-7">7</xref></sup> was plotted for each mFOV in the section, highlighting areas within the section of relatively lower image quality, which enabled the identification of out of focus areas, so that affected ROIs could be reacquired with additional FSPs. A correlation measure between tiles that should overlap with one another, both within-mFOV and between-mFOV, allowed the identification of any ‘gaps’ in the imaged ROI. The tops of tiles were automatically checked for evidence of either insufficient mSEM stage settling time (manifesting as a ‘sawtooth’ appearance), or charging (manifesting as compression of the image). Degrees of mFoV rotation and completeness of image tiles or metadata files were also recorded. If any of these tests indicated errors in image acquisition, that would impact on subsequent image stitching, alignment and segmentation, then the section in question was reacquired. Per section quality check results are listed in <bold><xref ref-type="table" rid="tbls1" hwp:id="xref-table-wrap-1-4" hwp:rel-id="T1">Supplementary Table 1</xref></bold>. In total, 5053 consecutive ROIs and 1830 TB of raw imaging data was acquired.</p></sec><sec id="s10g" hwp:id="sec-21"><title hwp:id="title-30">Image Alignment, Stitching and Rendering</title><p hwp:id="p-66">Stitching and alignment presented particular challenges due to the large section area; the fragmentation of some sequences of consecutive sections at coincident fracture boundaries; and reentry periods where, due to sample tilt during sectioning, some sections interfaced with several adjacent sections rather than single ones. These issues were addressed by the techniques described below. The large size of the dataset, also a challenge, was addressed by parallelizing each step over image tiles or regions of the volume, as appropriate. The overall approach was similar to Saalfeld et al. <sup><xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-2" hwp:rel-id="ref-8">8</xref></sup>.</p><sec id="s10g1" hwp:id="sec-22"><title hwp:id="title-31">Stitching</title><p hwp:id="p-67">To stitch imagery within sections, we obtained point correspondences between overlapping tiles, then optimized tile position estimates to minimize the correspondences’ sum of squared errors. We found correspondences by first matching whole tiles around positions suggested by stage position data (or by preliminary, partial stitch solutions in the case of some sections with poor stage position data and low cross-tile overlap), then matching patches around locations suggested by these whole tile matches. We used CLAHE-enhanced imagery subsampled to 8 nm resolution, patches of 400 x 400 nm, the normalized correlation coefficient as a match measure, and subpixel estimation of correlation peaks. To obtain well distributed correspondences, we attempted matches at successive locations generated by Halton sequences, stopping when finding a desired number of patches per pair, or an excessive rate of match failure. We found that the relative position of tiles within the 61-beam field of view varied during acquisition (perhaps due to variations in section surface height) so we solved translation of each field’s tiles individually, interpolating from adjacent fields in cases of insufficient correspondences (e.g., in low texture regions such as blood vessels). When stitching together whole fields, we found that these could not always be adequately aligned by translations or other affine transforms, perhaps because of deformation of the tissue during image acquisition. After solving for an optimal translation of each field, we modeled each with a triangular elastic mesh and adjusted mesh vertices to further reduce correspondence errors, formulating the problem as a sparse nonlinear system and solving it with the conjugate gradient method.</p></sec><sec id="s10g2" hwp:id="sec-23"><title hwp:id="title-32">Alignment correspondences</title><p hwp:id="p-68">To align sections, we first matched coarse and fine structural features between different sections, then used those to guide searches for patch matches. We sought matches between all pairs of sections up to three sections apart or, within reentry periods where more widely separated sections could still be physically proximate due to cutting angle, up to 200 nm apart. Where consecutive sections were fragmented at coincident boundaries, we also obtained matches to widely separated sections in order to adequately constrain those fragments. Features and matches were obtained from section renderings generated from the previous steps stitching solutions, with CLAHE enhancement. We detected coarse features using the OpenCV SimpleBlobDetector<sup><xref ref-type="bibr" rid="c69" hwp:id="xref-ref-69-1" hwp:rel-id="ref-69">69</xref></sup> on imagery subsampled to 2-micron resolution, typically obtaining features at blood vessels and some cell nuclei. We detected fine features using a Google proprietary scale-invariant keypoint detector comparable to SIFT <sup><xref ref-type="bibr" rid="c70" hwp:id="xref-ref-70-1" hwp:rel-id="ref-70">70</xref></sup> on 64 nm imagery. In both cases, we used a SIFT-like feature descriptor to characterize the neighborhood around each feature, and compared those descriptors to identify putative feature pairs. With coarse features, we used RANSAC <sup><xref ref-type="bibr" rid="c71" hwp:id="xref-ref-71-1" hwp:rel-id="ref-71">71</xref></sup> to find a global affine aligning each pair of sections, constraining affines to ones with plausible rotation, scale and skew. However, with fine features, the density of features together with the size and deformation of sections made RANSAC insufficiently selective, so in that case we used JLinkage <sup><xref ref-type="bibr" rid="c72" hwp:id="xref-ref-72-1" hwp:rel-id="ref-72">72</xref></sup>, a multi-model variant of RANSAC, to perform a similar function, finding a series of affines each valid in some local region. Next, we performed patch matching at both coarse and fine resolutions. At 8 micron intervals, and in 64 nm resolution renderings, we matched 6 x 6 micron patches in 64 x 64 micron neighborhoods to obtain coarse patch matches, using a distance-weighted average of neighboring fine feature matches to locate each search neighborhood. We then repeated this at 1.2 micron intervals in 32 nm renderings, matching 2.4 x 2.4 micron patches in 16 x 16 micron neighborhoods to obtain fine patch matches, using coarse patch matches to locate neighborhoods. In regions where feature or patch matches could not be found between a pair of sections, but were found between those and other nearby sections, we cascaded transforms to get the needed neighborhood location estimates. Finally, we filtered each set of patch matches for spatial coherence, discarding any that differed significantly from transforms fit to neighboring matches.</p></sec><sec id="s10g3" hwp:id="sec-24"><title hwp:id="title-33">Alignment transforms</title><p hwp:id="p-69">Fixing the position of one central section, we used a random subset of patch match correspondences to estimate similarity transforms for all other sections, optimizing both correspondence errors and a regularization term maintaining scale near unity. Then, modeling each section as transformed by its similarity transform with an elastic mesh, we adjusted mesh vertices to reduce correspondence errors. We performed this step first with coarse meshes and sparsely sampled correspondences, followed by progressively finer ones and larger fractions of available correspondences, to a finest mesh resolution of 8 microns vertex spacing. In later steps of this process, we subdivided the volume into progressively smaller, overlapping segments of contiguous sections and solved these independently, while keeping their boundary sections fixed, reducing alignment problems to a tractable size. The final step repeated the penultimate one, while using staggered segment boundaries to improve continuity.</p></sec><sec id="s10g4" hwp:id="sec-25"><title hwp:id="title-34">Rendering</title><p hwp:id="p-70">We classified each whole tile as to whether it primarily depicted tissue as opposed to resin or tape. For most sections, this classification was done by a random forest classifier trained on manually labeled tiles characterized by statistics of intensity and spatial frequency. For some sections within reentry periods, tile classification was done by measuring the entropy of the spatial frequency spectrum of ORB keypoints <sup><xref ref-type="bibr" rid="c73" hwp:id="xref-ref-73-1" hwp:rel-id="ref-73">73</xref></sup>, selecting tiles where that measure exceeded a threshold, and classifying as tissue the morphological closure of the largest connected component of such tiles. Finally, for selected sections throughout the volume, tissue tiles were identified manually by drawing section-bounding polygons. Classification results were used to exclude non-tissue tiles from the volume.</p><p hwp:id="p-71">We rendered a 3D volume of the aligned tissue tiles with each triangle of elastic mesh determining an affine transform of pixels within that triangle. We used CLAHE enhancement and bicubic interpolation. Where multiple tiles had content for one pixel, we selected the tile with the closest center. In general, each tissue section provided content for one or two layers of the volume, depending on the estimated thickness of that section. However, within reentry periods, where the change in cutting angle resulted in some sections filling their volume layers incompletely, we completed those layers by copying in voxel values from adjacent layers. This replication was limited to copying voxels identified as tissue, to ones identified as not tissue (i.e., resin or tape).</p></sec><sec id="s10g5" hwp:id="sec-26"><title hwp:id="title-35">Fine-scale alignment with optical flow</title><p hwp:id="p-72">In order to address remaining misalignment (such as systematic drift and section jitter), we used the section-to-section optical flow regularized with an elastic mesh to realign the complete dataset, with the results of elastic alignment as its initial state. We computed an optical flow field between every section and its two predecessors using cross-correlation. The flow vector was estimated by identifying the peak of the correlation image computed between 160 x 160 pixel patches extracted from the same XY position in the two sections. The patch centers were distributed over a regular grid with 40 pixel spacing. In addition to the flow vector, we recorded the ratio of the peak height, and the minimum correlation image intensity within a 5 pixel radius region around it (“sharpness”). If more than one peak was detected in the correlation image, we also recorded the “height ratio” of the two largest peaks. The flow field estimation procedure was performed over data at 8 x 8, 16 x 16, 32 x 32, 64 x 64, 128 x 128, and 256 x 256 nm<sup>2</sup> pixel size, computed with area-averaging.</p><p hwp:id="p-73">At every downsampling level, we filtered the flow field for “local consistency” by invalidating entries with: height ratio lower than 1.6, sharpness lower than 1.6, absolute flow magnitude larger than 40 pixels, or an absolute deviation from the 3 x 3 window median of more than 10 pixels. We then upsampled all flows to the highest resolution, and attempted to replace invalid flow entries with values of a lower resolution flow field at the same XY location, with preference given to estimates obtained at higher resolutions. The reconciled flow field was then filtered once more for local consistency as described above. The reconciled flow field might still contain invalid entries, either due to consistency filtering, or failure to find a valid value in the lower resolution flow fields.</p><p hwp:id="p-74">We modeled every section as a spring-mass system of Hookean springs <sup><xref ref-type="bibr" rid="c74" hwp:id="xref-ref-74-1" hwp:rel-id="ref-74">74</xref></sup>, with nodes of the springs positioned at the grid used for flow estimation, and nearest neighbor and next nearest neighbor nodes within every section connected together. Sections were optimized sequentially. Valid flow vectors were used to connect the optimized section with two previous sections with 0-length springs with a spring constant 10x lower than the in-plane springs <sup><xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-3" hwp:rel-id="ref-8">8</xref></sup>. We treated this system as a set of damped harmonic oscillators at critical damping, and integrated it in time with the velocity Verlet scheme <sup><xref ref-type="bibr" rid="c75" hwp:id="xref-ref-75-1" hwp:rel-id="ref-75">75</xref></sup> until the maximum velocity magnitude for all nodes fell below a threshold value of 0.01. Optimization proceeded simultaneously towards lower and higher <italic toggle="yes">z</italic> coordinates, starting with <italic toggle="yes">z</italic> = 1900 as the anchor section.</p><p hwp:id="p-75">In this procedure, significant imaging artifacts or missing sections can cause mesh distortions which propagate through the stack. To avoid this problem, we manually reviewed downsampled versions of all sections in the dataset, and decided to mark 287 single sections as invalid (i.e., both preceding and following sections were valid), as well as 96 sections within contiguously invalid blocks of two or more (up to nine) consecutive sections. The invalid sections were not included in the optimization, and instead the flow field was computed between the valid sections directly preceding and following the invalid block. Invalid sections were then optimized separately in a second pass, at which point all valid sections were held fixed. A representative example of a corrected region of misalignment is shown in <bold><xref ref-type="fig" rid="figs12" hwp:id="xref-fig-18-1" hwp:rel-id="F18">Supplementary Fig. 12</xref>.</bold></p></sec></sec><sec id="s10h" hwp:id="sec-27"><title hwp:id="title-36">Semantic segmentation</title><sec id="s10h1" hwp:id="sec-28"><title hwp:id="title-37">Valid tissue detection</title><p hwp:id="p-76">We used a simple heuristic filter to detect “out of bounds” (OOB) regions of the dataset which did not contain neural tissue. First, we computed a high-pass filtered version of the imagery as <italic toggle="yes">I</italic><sub>hp</sub> = <italic toggle="yes">I</italic> + min<sub>3×3</sub>(255 - <italic toggle="yes">I</italic>), where <italic toggle="yes">I</italic> is the pixel intensity of the CLAHE-normalized data downsampled to a pixel size of 64 x 64 nm<sup>2</sup> and min<sub>3×3</sub> is the minimum function, applied convolutionally with a kernel size of 3 x 3 pixels. We then downsampled <italic toggle="yes">I</italic><sub>hp</sub> to 320 x 320 nm<sup>2</sup> pixel size, filtered the results with a 10 x 10 pixel uniform filter, and binarized the results at a threshold of 230. To form the final OOB mask, we computed the in-plane connected components of the binary mask, and removed any components smaller than 10,000 pixels.</p></sec><sec id="s10h2" hwp:id="sec-29"><title hwp:id="title-38">Voxel-wise classification</title><p hwp:id="p-77">We trained four convolutional networks to perform four separate semantic segmentation (i.e., voxel-wise multi-class prediction) tasks: 1) tissue classification, 2) neurite type classification, 3) myeloid body detection, and 4) data irregularity detection. The tissue classification model operated on the aligned data at 64 x 64 x 66 nm<sup>3</sup> voxel size, but all the other models used the aligned data at 32 x 32 x 33 nm<sup>3</sup> voxel size. The architecture of the networks, training hyperparameters, and class balancing were the same as in Januszewski et al. <sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-3" hwp:rel-id="ref-9">9</xref></sup>, with all networks having a 65 x 65 x 65 voxel field of view (FOV) at their operating resolution. The tissue classification model was trained with random 3D rotation augmentation in addition to the reflection and axis permutation augmentations used for the other models.</p><p hwp:id="p-78">The tissue classification model classified every voxel as neuropil, nucleus, myelin, blood vessel, or fissure - see <bold><xref ref-type="fig" rid="figs13" hwp:id="xref-fig-19-1" hwp:rel-id="F19">Supplementary Fig. 13</xref></bold> for a representative example. “Fissures” denoted unusual cylindrical-shaped regions of the dataset in which it was impossible to distinguish individual neurites. We hypothesize that these regions originated from physical damage during tissue resection. The dataset contains five distinct fissure regions, two of which penetrate the whole stack, while the remaining three are more superficial. To speed up annotation, the myelin class included both the myelin sheath and the axon it wrapped, unlike prior work <sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-4" hwp:rel-id="ref-9">9</xref></sup>. Ground truth annotations were collected by manual mask painting in a web-based tool (“Armitage”). 17,361,918 voxels were annotated as neuropil, 2,731,823 as nucleus, 2,702,242 as blood vessels, 1,529,997 as myelin, and 25,678,685 as fissure.</p><p hwp:id="p-79">The neurite classification model classified every voxel as axon, dendrite or glia. Ground truth data was created by selecting neurite fragments in a partially agglomerated neuron (instance) segmentation of the dataset. The neurites were then skeletonized, and the nodes of the skeletons served as the FOV centers for the training examples of the network. In total, we manually identified 887 axon fragments (298,250 points), 71 dendrite fragments (307,339 points), and 75 glia fragments (810,480 points).</p><p hwp:id="p-80">The myeloid body classification model performed voxel-wise binary classification. Ground truth data was created by manually annotating segments in the base neuron (instance) segmentation of the complete dataset as myeloid (2,001) and not myeloid (2,662). All voxels belonging to the manually selected segments were used as FOV centers for training the classifier (myeloid: 6,696,491, not myeloid: 5,743,067,192).</p><p hwp:id="p-81">The data irregularity model classified every voxel as regular or irregular. Irregular voxels were deemed to be those corresponding to acquisition artifacts, such as dust, knife marks, or partially missing sections. Ground truth for this model was collected through manual annotation, using a procedure similar to that used for the tissue classification model. 15,541,762 voxels were manually annotated as regular, and 13,396,821 as irregular.</p></sec></sec><sec id="s10i" hwp:id="sec-30"><title hwp:id="title-39">Neuron and glial segmentation</title><p hwp:id="p-82">The dataset was segmented with Flood-Filling Networks (FFNs), with scale- and seed-order over segmentation consensus <sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-5" hwp:rel-id="ref-9">9</xref></sup>. We trained three separate FFN models, operating on 32 x 32 x 33 nm<sup>3</sup>, 16x 16 x 33 nm<sup>3</sup> and 8 x 8 x 33 nm<sup>3</sup> data. The 16 x 16 x 33 nm<sup>3</sup> and 8 x 8 x 33 nm<sup>3</sup> models used an FFN model architecture identical to that in Januszewski et al. <sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-6" hwp:rel-id="ref-9">9</xref></sup>: Eight residual modules, an FOV size of 33 x 33 x 17 voxels and an 8 pixel step size in-plane and 4 pixel step size in the axial direction. The lowest resolution 32 x 32 x 33 nm<sup><xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">3</xref></sup> model used a slightly modified architecture: twelve residual modules, an FOV size of 33 x 33 x 33 voxels, and an 8 pixel step size in both in-plane and axial directions. The models were trained with 375 Mvx (32 nm), 1,285 Mvx (16 nm) and 6,142 Mvx (8 nm) of ground truth data created by human annotators through de novo voxel-wise painting or correction of automatically generated candidate segmentations <sup><xref ref-type="bibr" rid="c76" hwp:id="xref-ref-76-1" hwp:rel-id="ref-76">76</xref></sup>.</p><p hwp:id="p-83">Segmentation proceeded in two stages. First, we created a “base segmentation” that was optimized to minimize the frequency of merge errors. Then, we applied a multi-step agglomeration procedure to reduce split errors, while keeping the rate of false mergers at an acceptable level.</p><sec id="s10i1" hwp:id="sec-31"><title hwp:id="title-40">Base segmentation</title><p hwp:id="p-84">The base segmentation was created by first segmenting the EM imagery downsampled to 32 x 32 x 33 nm<sup>3</sup> and 16 x 16 x 33 nm<sup>3</sup> voxel size with FFN models trained for these respective resolutions. Segmentation results for both forward and reverse seed ordering were combined with an over segmentation consensus procedure that produced a new segmentation with smaller segments formed so that all voxels contained in a consensus segment belonged to exactly one segment in both the forward and reverse input segmentations <sup>9</sup>. We then removed any objects smaller than 100,000 voxels from the 32 nm segmentation and upsampled it to 8 x 8 x 33 nm<sup>3</sup>, and segmented the empty areas with the 8 nm FFN model. Finally, we computed the over segmentation consensus between the segmentations from all three resolutions to build the overall base segmentation.</p><p hwp:id="p-85">During FFN inference, we used FOV “movement restriction” in areas where the magnitude of optical flow (see ‘Fine-scale alignment with optical flow’) exceeded 8 pixels (at 32 nm), 6 pixels (at 16 nm), or 4 pixels (at 8 nm). The FFNs were also prevented from creating seeds in voxels where the mean intensity of the EM images within a 7 x 7 in-plane window centered at the voxel was lower than: 100 for the 32 nm model, 80 for the 16 nm model, and 130 within a 14 x 14 window for the 8 nm model. This procedure prevented segments from being initiated within myelin, lipofuscin, or other electron-dense structures.</p><p hwp:id="p-86">We also excluded (“masked”) various regions in the dataset and prevented the FFN from performing inference in FOVs centered in these areas. Masked areas included: 1) 135 largest segments created by binarizing the “blood vessel” and “fissure” predictions of the tissue classifier and computing their connected components, 2) regions in which optical flow alignment mesh nodes connected to springs whose relative horizontal or vertical compression or extension exceeded 20% after optimization, and 3) regions in which more than two sections (not necessarily in consecutive order) were missing (as determined by the OOB mask) within a 17-section window centered at the FFN FOV.</p></sec></sec><sec id="s10j" hwp:id="sec-32"><title hwp:id="title-41">Agglomeration</title><sec id="s10j1" hwp:id="sec-33"><title hwp:id="title-42">Pairwise resegmentation</title><p hwp:id="p-87">We used FFN resegmentation to agglomerate objects from the base segmentation as described in Januszewski et al. <sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-7" hwp:rel-id="ref-9">9</xref></sup>. Briefly, we evaluated segment pairs (A, B) selected due to their spatial proximity, and performed FFN inference within a small subvolume centered on the pair of original segments, creating temporary segments A* and B* in the process. These were then used to compute: the recovered voxel fractions (f<sub>AA</sub>, f<sub>AB</sub>, f<sub>BA</sub>, and f<sub>BB</sub>, where f<sub>AB</sub> is the fraction of B found in A*, and so on), the Jaccard index J<sub>AB</sub> between A* and B*, and the number of voxels contained in A* or B* that had been ‘deleted’ (i.e., during inference their value in the predicted object mask fell from &gt; 0.8 to &lt; 0.5) during one of the runs (d<sub>A</sub>, d<sub>B</sub>). Criteria based on these scores were used to include some segment pairs as edges in the agglomeration graph, as outlined in <bold><xref ref-type="table" rid="tbls2" hwp:id="xref-table-wrap-2-1" hwp:rel-id="T2">Supplementary Table 2</xref></bold>. A subset of segment pairs for which an artifact was detected by the data irregularity detection model within five sections of the pair center point were reevaluated with the voxels classified as irregular replaced by those from the preceding section (type “artifact” in <bold><xref ref-type="table" rid="tbls2" hwp:id="xref-table-wrap-2-2" hwp:rel-id="T2">Supplementary Table 2</xref></bold>).</p></sec><sec id="s10j2" hwp:id="sec-34"><title hwp:id="title-43">Endpoint resegmentation</title><p hwp:id="p-88">Since pairwise resegmentation can fail to connect segments which are heavily fragmented or separated by more than a few unsegmented (background) voxels, we also skeletonized the base segmentation with TEASAR <sup><xref ref-type="bibr" rid="c77" hwp:id="xref-ref-77-1" hwp:rel-id="ref-77">77</xref></sup> and identified all skeleton nodes of degree 1 (“endpoints”). For each base segment A, and for all its endpoints we then ran FFN inference within a subvolume centered at each endpoint, seeding from locations originally covered by A, and generating a new segment Q. When Q covered at least 60% of the voxels of segments A and B within the corresponding subvolume, we considered (A, B) as a candidate agglomeration graph edge. The candidate edge was accepted if there was another candidate edge (B, A), i.e. generated from an endpoint of segment B.</p></sec><sec id="s10j3" hwp:id="sec-35"><title hwp:id="title-44">Ensembling</title><p hwp:id="p-89">In addition to evaluating agglomerations for selected segment pairs and endpoints, we also computed agglomeration candidates based on ensembling multiple base segmentations. Specifically, we segmented the complete dataset with twenty snapshots of the FFN network weights saved during training. This resulted in twenty segmentations, which we compared to the base segmentation by computing the number of voxels covered by both a base segment A and a segment A’ from an alternative segmentation. A’ was considered to “match” A if the number of overlapping voxels exceeded either 10,000, or 1,000 voxels when they corresponded to at least 50% of all voxels of A. When an alternative segment A’ matched two segments A and B from the base segmentation which were also spatially proximal (i.e. we could compute a decision point for it, as used in FFN agglomeration described above), we generated a candidate edge (A, B) for the agglomeration graph. An edge was accepted if it was generated by a sufficiently large fraction of the alternative segmentations (see <bold><xref ref-type="table" rid="tbls2" hwp:id="xref-table-wrap-2-3" hwp:rel-id="T2">Supplementary Table 2</xref>).</bold></p><p hwp:id="p-90">We used the tissue classification model to determine the dominant type for every base segment (supervoxel). Segments for which the fissure class was dominant, as well as those created by the 8 nm FFN model for which myelin was dominant, were excluded from all stages of agglomeration. Segments with a dominant myelin classification were excluded from agglomeration stages involving the 8 nm FFN model, regardless of the origin of the segment. We also converted the predictions of the myeloid classification model into individual instances by computing the connected components of the binary predictions. We excluded from agglomeration all base segments that: overlapped with at least 1,000 voxels of a myeloid segment, were no larger than 1,000,000 voxels, and 90% of their voxels overlapped with a myeloid segment.</p><p hwp:id="p-91">Wherever further processing required establishing a total order within the agglomeration graph, edges were sorted in descending order of max (f<sub>AB</sub>, f<sub>BA</sub>) within the stage from which they originated, and stages were ordered as listed in <bold><xref ref-type="table" rid="tbls2" hwp:id="xref-table-wrap-2-4" hwp:rel-id="T2">Supplementary Table 2</xref></bold>. The agglomeration graph resulting from the preceding steps, as well as merging segments completely contained within other segments, had 1.7B edges. We denoted the agglomerated segmentation 20201123b. An earlier version of the agglomeration graph which did not include stages of type “ensemble” and “artifact” as listed in <bold><xref ref-type="table" rid="tbls2" hwp:id="xref-table-wrap-2-5" hwp:rel-id="T2">Supplementary Table 2</xref></bold>, or myeloid segment filtering as described above, was denoted “20200916” and used for some of the analysis requiring lower false merge rates.</p></sec></sec><sec id="s10k" hwp:id="sec-36"><title hwp:id="title-45">Soma and fragment type separation</title><p hwp:id="p-92">In order to create a database of cell bodies within the volume, we first binarized the “nuclei” predictions of the tissue type classifier, and computed the connected components of the resulting binary mask, forming an instance segmentation of the putative nuclei. These instances were then reviewed by human annotators in order of descending volume in a web-based visualization tool showing 3D meshes and 2D cross sections of the segmentation and EM data (“Neuroglancer”). Annotators classified nuclei segments as correct, incorrect, or merged. In the “merged” case, point markers were placed to indicate the approximate centers of the individual nuclei. In addition, we manually painted masks for all somas on every 128th section at a downsampled (512 x 512 nm<sup>2</sup>) resolution. These annotations were then converted to points, and reconciled to build a set of 48,682 cell body center locations. Finally, we identified large segments near the z-boundaries of the volume that were initial regions of axons or dendrites whose cell bodies were not contained within the volume itself. Specifically, we reviewed all segments not previously annotated as a cell body and having a cross section of at least 1,000 pixels at 32 x 32 nm<sup>2</sup> pixel size at z = 250 and z = 5100 (close to the boundary, but also far enough from the boundary such that at least some large fragments were likely to continue deeper within the volume). Neurites which could be identified as likely having their soma outside of the EM volume (based on spatial orientation and branching pattern) were converted to a point annotation located at the centroid of its cross-section at z = 250 or 5100. These points were added to the cell body center annotations, bringing the total number of annotations to 53,395.</p><p hwp:id="p-93">We then computationally filtered the agglomeration graph to enforce that segments corresponding to distinct annotated cell body points remain in separate components. Specifically, when computing connected components we scanned the list of edges sorted in descending order of the agglomeration scores, adding them sequentially to a disjoint-set data structure, and discarding any edges which would cause the annotated objects to be merged together. 0.6 M edges were removed as a result of this enforced soma separation procedure.</p><p hwp:id="p-94">We also associated every segment with a per-class (axon, dendrite, glia) voxel count according to the predictions of the neurite type classification model, excluding any voxels identified as nuclei by the tissue type model. The voxel counts were updated to reflect the merge decisions between the segments as the agglomeration graph was processed. Wherever an edge would merge two objects containing at least 100,000 voxels each, and 80% of one were classified as glia and 80% of the other as non-glia, the edge was removed from the agglomeration graph. During this process we maintained two sets of connected components and their voxelwise classifications -- one containing all the edges in the agglomeration graph, and the other containing all edges with the exception of those involving a segment previously identified as containing a cell body. The second set of connected components was necessary to track the connected components of neurites specifically, as the segments containing the soma often also contained parts of its dendritic branches and the axon, and as such could not be associated with an axon/dendrite type. We applied the same splitting rule (100,000 voxels, 80% of the same type) between axons and dendrites using the neurite-specific set of connected components. 3.7 M edges were removed due to this neurite type separation procedure.</p><p hwp:id="p-95">We acknowledge that the resulting set of cell somata still contains some merge errors. In comparison to the manually annotated cell somata, which were completed afterwards, we found that in the C3 version of the automatic segmentation there are 1345 segments which contain more than one cell body, with a total of 2936 manually annotated cell bodies in those segments (504 of which are neurons). Frequently this includes small glial satellite cell bodies merged with a larger neuronal cell body, and sets of smaller glial cells next to blood vessels. 1100 manually annotated cell bodies could not be assigned to a C3 segment because they did not overlap with any C3 segment.</p></sec><sec id="s10l" hwp:id="sec-37"><title hwp:id="title-46">Skeletonization of segments</title><p hwp:id="p-96">We preprocessed the voxel segmentation data to remove any small holes or “island” segments that were completely contained within a surrounding segment. We computed these relabelings at 32 x 32 x 33 nm resolution on blocks of 256 x 256 x 256 voxels with overlap of 128 voxels in each dimension. First, we computed connected components on all background labeled voxels within the block and assigned each background component a new unique object ID. Next, we determined the set &#x01d53c; of all “exterior” objects, i.e. those that touched a face of the block. Finally, we built a 6-connected region adjacency graph (RAG) between all object labels, and found all object pairs A, B for which all paths from A to &#x01d53c; in the RAG passed through a single “surrounding” object B. The surrounding objects B correspond to the articulation points of the RAG. Relabeling the voxels of each A with the ID of the corresponding B fills all holes and islands that are completely surrounded within the block, including in cases where there are multiple A’s per B.</p><p hwp:id="p-97">We then skeletonized the voxel segmentation via automated block-wise TEASAR <sup><xref ref-type="bibr" rid="c77" hwp:id="xref-ref-77-2" hwp:rel-id="ref-77">77</xref></sup>, based on the Kimimaro implementation <sup><xref ref-type="bibr" rid="c78" hwp:id="xref-ref-78-1" hwp:rel-id="ref-78">78</xref></sup>. Kimimaro supports running with non-overlapping blocks via special handling of the block faces, but we found that running with overlapping blocks yielded smoother block transitions. We skeletonized at 32 x 32 x 33 nm resolution on blocks of 512 x 512 x 512 voxels with overlap of 128 voxels in each dimension and invalidation scale 3.0, and then clipped the skeletons back in overlapping regions. This yielded a set of unconnected skeleton fragments for each segment ID.</p><p hwp:id="p-98">To reconnect fragments, we then iterated through all fragment endpoints and connected each endpoint to the nearest skeleton node within the set of other fragments for the same segment ID, provided the distance was within 1.5 μm. To avoid excess / spurious reconnections, the candidate connections were ordered from shortest distance to longest, and the set of still-unconnected fragments for the same segment ID was updated at each iteration. Skeletons were then eroded back from endpoints by 100 nm, and sparsified to approximately 300 nm node spacing while retaining all branch points and endpoints.</p><p hwp:id="p-99">Finally, we made two types of skeleton corrections in order to bias skeleton connectivity to properly reflect the segment agglomeration graph. First, we cut skeleton edges that jumped between widely separated parts of the base segment agglomeration graph (&gt; 3 hops away). This can occur when two branches of the same cell happen to pass close to each other, or when two dendritic spines from the same shaft touch, resulting in a skeleton edge that erroneously connects parts that are spatially adjacent, but are cytoplasmically discontiguous (a “self-merge error”). One weakness in the &gt; 3 hops criterion occurs in areas where image irregularities result in many small base segments; to address this we also kept skeleton edges that connected parts of the agglomeration graph &gt; 3 hops away if the agglomeration graph was confirmed to have a path connecting them via the set of base segment IDs that impinge on a field of view surrounding the skeleton edge.</p><p hwp:id="p-100">Second, we aggressively reconnected pairs of skeleton fragments (maximum reconnect distance 10 μm) if their nodes overlapped the same base segment. This largely fixed disconnections remaining after the standard reconnection procedure (see above), particularly in large objects such as somas where the block overlap was insufficient to ensure smooth block transitions. It also fixed most disconnections introduced by the self-merge error cutting procedure. We considered base segments in descending order by the number of distinct skeleton fragments that each base segment overlapped. As above, we sorted candidate connections from the shortest distance to longest and recomputed the still disconnected set of fragments at each iteration. In this case, only nodes that overlapped the same base segment were considered for reconnection, but we did not require that reconnection initiate from endpoints as above. For the skeletonization of volume 20201123c2 (see below), self-merge cutting removed 9,813,220 skeleton edges, while aggressive base segment reconnection added 4,519,438 edges in the final skeletons. For volume 20200916c3 (see below), self-merge cutting removed 7,500,074 edges and reconnection added 3,291,662.</p></sec><sec id="s10m" hwp:id="sec-38"><title hwp:id="title-47">Cellular subcompartment classification and merge error correction</title><sec id="s10m1" hwp:id="sec-39"><title hwp:id="title-48">Subcompartment classification</title><p hwp:id="p-101">We trained deep networks to classify the cellular subcompartment or cell type for a subset of skeleton nodes (20% uniformly sampled) following the approach of Li et al. <sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-3" hwp:rel-id="ref-10">10</xref></sup>. The model architecture was a ResNet-18 <sup><xref ref-type="bibr" rid="c79" hwp:id="xref-ref-79-1" hwp:rel-id="ref-79">79</xref></sup> with all convolutions extended to 3D and inputs of 129 x 129 x 129 voxels at 32 x 32 x 33 nm resolution centered on each skeleton node. The three input channels comprised 1) CLAHE normalized EM masked by the segmentation, 2) a pre-synapse mask, and 3) a post-synapse mask (see ‘Synaptic site detection’). The model outputs were probabilities for four classes: axon, dendrite, astrocyte, or soma, and models were trained via stochastic gradient descent with batch size 64 for up to 1.5 M steps. The number of unique training examples were 262,395 axon; 1,151,175 dendrite; 1,392,702 astrocyte; and 39,444 soma. For training we class-balanced the examples by upsampling axon, astrocyte, and soma classes to match the number of dendrite examples. In later experiments, two additional classes were added: cilium and axon initial segment (AIS), and the number of training examples were 257,713 axon; 1,151,175 dendrite; 1,392,702 astrocyte; 40,072 soma; 577 cilium; and 4,682 AIS. We upsampled axon, dendrite, and soma to match the number of astrocyte examples, and upsampled cilium and AIS to 10% of the other class counts.</p></sec><sec id="s10m2" hwp:id="sec-40"><title hwp:id="title-49">Merge error correction</title><p hwp:id="p-102">We built on the approach of Li et al. <sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-4" hwp:rel-id="ref-10">10</xref></sup> to use subcompartment predictions to fix segmentation errors based on the observation that while FFN base segments are largely free of merge errors, occasionally in FFN agglomeration two base segments with inconsistent classes (e.g. axon versus dendrite) are erroneously merged. In brief, merge error correction consists of 1) soma removal, 2) branch consistency calculation, and 3) cut candidate scoring and thresholding. Prior to processing, the agglomeration graph for each object was modified to remove cycles by breaking an arbitrary edge of each cycle. We also simplified on Li et al. <sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-5" hwp:rel-id="ref-10">10</xref></sup> by considering only the highest probability predicted class label for each node, rather than working with predicted class probabilities per node.</p><p hwp:id="p-103">First, for the subset of objects that included somas, we detected the soma and removed it so that the remaining detached branches could be considered independently. For each agglomerated object, we identified the base segment with the largest number of soma predicted nodes and considered this a true soma if the number of soma nodes exceeded four. We then iteratively considered adjacent base segments in the agglomeration graph, and added them to the soma cluster if they also had more than four soma predictions. The resulting soma cluster generally contained the majority of the soma, as well as most proximal dendritic and axonal branches. These soma base segments were then removed from the agglomeration graph, and each remaining disconnected branch subgraph was considered independently.</p><p hwp:id="p-104">For each remaining object we took the predominant predicted node class as the proposed object class, and assigned a weighted consistency score as the total number of nodes with that class prediction. Finally, we considered every edge in the agglomeration graph as a cut candidate, and computed the consistency scores of the two new objects that would result from the proposed cut. For a cut to be accepted, the sum of the two new scores had to exceed the original object score by at least five. We found it helpful to increase this threshold to 15 in cases where the predominant class of the leaving object was dendrite or soma, due to an occasional tendency of the prediction model to cluster these predictions at the ends of branches. In this case, the leaving object was defined as the side of the cut further from the soma, or else the side further from an arbitrary base segment if no soma was detected. We also found it helpful to prevent the removal of large axon components if the cut score improvement was only marginal, so we added a criterion that when the leaving object class was axon the number of leaving axon classified nodes divided by the leaving cut score could not exceed 6.0.</p><p hwp:id="p-105">We combined 2.9 M suggested consistency cuts computed from the 4-class (axon, dendrite, astrocyte, soma) predictions on agglomeration 20201123b, along with 3.7 M partially redundant suggested cuts from the “Soma and fragment type separation” procedure above, for a total of 6.0 M distinct cuts. Applying these cuts to 20201123b resulted in segmentation 20201123c2. Applying the same set of cuts to 20200916 resulted in segmentation 20200916c3. Because we removed somas first to avoid spurious suggested cuts at the soma / branch interface, we did not fix any agglomeration errors involving the soma cluster of base segments, although methods to address this were proposed for songbird data <sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-6" hwp:rel-id="ref-10">10</xref></sup>. We did not distinguish between myelinated and unmyelinated axons in the subcompartment predictions, however that information can be useful in biological analyses and is available from the myelin mask described in “Semantic segmentation” above. Therefore we post-processed the subcompartment predictions for any skeleton component that entered the myelin sheath for more than approximately 3 μm consecutively by incrementing their predicted node class labels by 1000.</p></sec><sec id="s10m3" hwp:id="sec-41"><title hwp:id="title-50">Subcompartment rendering</title><p hwp:id="p-106">To produce a volumetric rendering of the subcompartment classification, we first ran topology-preserving erosion on all segments at 64 x 64 x 66 nm resolution. We then computed marker watersheds within each segment, with seed positions at each subcompartment classified node, and assigned voxels within each watershed to the corresponding subcompartment. Because the subcompartment axon class label conflicted with the conventional volumetric background label (0), we incremented the rendered subcompartment classes by 100.</p></sec><sec id="s10m4" hwp:id="sec-42"><title hwp:id="title-51">Spine detection</title><p hwp:id="p-107">We trained a separate network to detect dendritic spine subcompartments, using the same configuration as described for “Subcompartment classification” above. For spine detection, the training data consisted of 33,753 positive examples from pyramidal cell dendritic spines, and a total of 2,628,949 negative examples, comprising 1,976,109 examples from axon, soma, or astrocyte; 578,439 from pyramidal dendrite shafts; and 74,401 from non-spiny dendrites. To detect spines, we ran this network on all skeleton endpoint nodes (leaf nodes with exactly 1 impinging edge) for segments with at least 5 dendrite labeled nodes in the 20200916c3 subcompartment classification.</p></sec></sec><sec id="s10n" hwp:id="sec-43"><title hwp:id="title-52">Embeddings</title><p hwp:id="p-108">We trained a ResNet-18 <sup><xref ref-type="bibr" rid="c79" hwp:id="xref-ref-79-2" hwp:rel-id="ref-79">79</xref></sup> with all convolutions extended to 3D an input field of view of 129 x 129 x 129 voxels at 32 x 32 x 33 nm resolution to produce embeddings for volume locations centered at skeleton nodes. The only input channel was the CLAHE-normalized EM masked by the segmentation. Specifically, the input channel only contained the EM values where the segmentation matched the neuron id, all other values were set to 0. The model output was a 32 dimensional vector. The network was trained following the SimCLR framework <sup><xref ref-type="bibr" rid="c80" hwp:id="xref-ref-80-1" hwp:rel-id="ref-80">80</xref></sup> using contrast and brightness augmentations as well as shifts of the field of view. We used a batch size of 256 pairs and trained the network for 300k steps.</p><p hwp:id="p-109">After prediction, we sampled ∼130k skeleton nodes from segments with more than 150 skeleton nodes for dimensionality reduction. From each segment we sampled embeddings from 2% of the skeleton nodes. We next fit a UMAP <sup><xref ref-type="bibr" rid="c81" hwp:id="xref-ref-81-1" hwp:rel-id="ref-81">81</xref></sup> on the sampled embeddings and applied it to all embeddings.</p><p hwp:id="p-110">We used these embeddings to distinguish microglia and oligodendrocyte precursor cells (OPCs) in the dataset. First, we identified a number of microglia and OPCs manually by their shape and ultrastructural features (36 microglia, 21 OPCs). Then, we trained a linear classifier to label local embeddings as either belonging to microglia (N=29,536) or OPC (N=25,035). We tested the model’s performance by training on randomly selected 75% of the cells and testing on the remaining ones. The model achieved a mean accuracy of 0.89 (100 sampling rounds). We inferred cell labels for 6,280 cells identified as either microglia or OPC by averaging the probabilities of the local classifications and thresholding at 0.6 for each class. This left 1,058 cells unclassified. Additionally, we excluded 1,778 cells due to large false mergers as identified in the embedding space. In total, our model identified 2,049 microglia, 1,395 OPCs and left out 2,836 cells.</p></sec><sec id="s10o" hwp:id="sec-44"><title hwp:id="title-53">Manual cell body labeling and classification</title><p hwp:id="p-111">To enable efficient manual labeling of all cell bodies (and nuclei of blood vessel cells), VAST <sup><xref ref-type="bibr" rid="c76" hwp:id="xref-ref-76-2" hwp:rel-id="ref-76">76</xref></sup> was extended so that image data could be streamed in on demand from the Google Brainmaps server, and functionality was added to let users quickly jump between specific sections at large intervals while showing intermediate sections during the transitions. Inspection of the EM images at different resolutions showed that the lowest resolution at which cell bodies could be reliably identified in XY sections was mip level 4 (128 nm per pixel). Since the smallest cells in the dataset have a cell body around 6 micrometers in diameter, we chose a Z-stepping of 128 sections (4.2 micrometers) to minimize the number of sections that needed to be painted and at the same time to minimize the chances of missing small cell bodies.</p><p hwp:id="p-112">The manual labeling was done in VAST using a screen pen tablet (Wacom Cintiq 13HD, Wacom Inc.). The initial labeling was done cell-by-cell in the following way: Starting from specific XY sections, any unlabeled cell body cross-section which was spotted (nucleus visible) was given a new label ID. It was then painted in that section and also in all other multiple-of-128 sections in which its nucleus was visible, and beyond to capture the whole cell body, scrolling forward and backward through the stack in 128-section steps. This ensured that each cell body painted received exactly one ID and was not erroneously recounted in a different section.</p><p hwp:id="p-113">Once the whole dataset was traversed in this way and no unpainted cell bodies were spotted easily, the tissue sample was visually scanned for any unlabeled cell bodies in a systematic way. A XY grid was overlaid over the complete dataset and each grid cell was systematically visually traversed in Z (<bold><xref ref-type="fig" rid="figs10" hwp:id="xref-fig-16-1" hwp:rel-id="F16">Supplementary Fig. 10 A, B</xref></bold>). Any unpainted cell body was added to the list. Each verified grid cell was marked. This should ensure that almost all cell bodies were found. If there are any missing cells, they are likely small glia which only show up in a single painted section or may in rare cases fall between painted sections.</p><p hwp:id="p-114">Once all cell bodies were identified and listed in VAST, we classified them manually as neurons or glia of different types based on their appearance in the EM sections and their 3D shape. Criteria used from EM images included cell body and nucleus size, cell body outline, cytoplasm shading, and appearance of the endoplasmic reticulum. For glial cells, the appearance in the EM section is sufficient to identify astrocytes and oligodendrocytes reliably. We did not attempt to manually separate microglia and oligodendrocyte precursor cells, which have only subtle differences in their arborization and ultrastructural features. For neurons, it was necessary to verify/correct their classification by displaying their 3D models in Neuroglancer (<bold><xref ref-type="fig" rid="figs10" hwp:id="xref-fig-16-2" hwp:rel-id="F16">Supplementary Fig. 10 C</xref></bold>).</p></sec><sec id="s10p" hwp:id="sec-45"><title hwp:id="title-54">Manual labeling of blood vessels and their nuclei</title><p hwp:id="p-115">As for cell bodies, XY cross-sections of blood vessels were initially manually painted in VAST at mip 4 (128 nm per pixel), every 128<sup>th</sup> section. Different label IDs were used for different parts of the blood vessel network in such a way that individual labels (segments) do not contain branching (linear pieces of the network; new color introduced at branch points). To ensure that no branches were missed, each segment was initially tagged as ‘unfinished’. The tag was only removed once inspection of the segment showed that all branches coming off of it were also labeled. Additional inspection of regions devoid of capillary labels and comparison to automatic blood vessel identification revealed some missing blood vessels, in particular large arteries, which were disconnected from the local capillary network. These were added to the segmentation. In a second step the blood vessel labels were augmented by adding intermediate sections semi-automatically to get to every 64<sup>th</sup> section in Z, followed by manual correction and specific labeling of thin blood vessel branches at even higher resolution.</p><p hwp:id="p-116">Based on the linear blood vessel segments, nuclei of blood vessel cells were identified and painted in VAST at mip 3, every 32<sup>nd</sup> section. Blood vessel cell bodies have more complex shapes than their nuclei, making nucleus labeling a good alternative to enumerate and locate these cells. Blood vessel cells were first classified as endothelial cells and pericytes, followed by sub-classification of pericytes into further cell types based on location with respect to the blood vessel lumen and basement membrane, as well as their appearance in EM. Circulating immune cells were located inside the blood vessel lumen. Perivascular lymphocytes appear similar to circulating lymphocytes but reside within the basement membrane. Perivascular macrophages were defined by their location in the outer layer of basement membrane and abundance of large granules. The difficulty in distinguishing fibroblast-like pericytes from perivascular macrophages resulted in a small group of cells being marked as undecided. Fibroblast-like pericytes were defined by the location surrounding smooth muscle cells and lack of large granules. Smooth muscle cells were separated from pericytes based on their location and slightly larger cytoplasm.</p></sec><sec id="s10q" hwp:id="sec-46"><title hwp:id="title-55">3D rendering of cells</title><p hwp:id="p-117">Projection images (<bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-22" hwp:rel-id="F3">Fig. 3</xref></bold>) were rendered directly from volumetric (voxel) data in Matlab (The Mathworks Inc.) using VAST and the Matlab script VastTools. The method produces parallel projection images and uses a simple simulation of light occlusion to generate shading. Other images of cells were either generated from Neuroglancer directly, or were rendered in 3dsMax (Autodesk Inc.) using 3D meshes generated from voxel data through VAST and Matlab (The Mathworks Inc.).</p></sec><sec id="s10r" hwp:id="sec-47"><title hwp:id="title-56">Synapse identification</title><sec id="s10r1" hwp:id="sec-48"><title hwp:id="title-57">Synaptic site detection</title><p hwp:id="p-118">To identify synaptic sites, we trained a classifier based on the UNet architecture described in Çiçek et al <sup><xref ref-type="bibr" rid="c82" hwp:id="xref-ref-82-1" hwp:rel-id="ref-82">82</xref></sup> to label three classes: background, pre-synaptic, and postsynaptic (see <bold><xref ref-type="fig" rid="figs14" hwp:id="xref-fig-20-1" hwp:rel-id="F20">Supplementary Fig. 14</xref></bold> for representative example). The model used the same three-down/three-up architecture as described in the paper, with initial dimensionality of 32, and a multiplicative factor of 2 for each down and up stage.</p><p hwp:id="p-119">Ground truth labels were generated by having trained annotators volumetrically label each pre- and postsynaptic site on both sides of the both sides of the synaptic cleft, for each Z slice where the synaptic density was visible. Six regions of interest were selected (one from each cortical layer) of size [600, 600, 3300] voxels at a resolution of 8 x 8 x 33 nm. The ROI shape was chosen to both allow annotators to observe the entire XY FoV on a single screen to minimize missed annotations, while capturing as much variation in neuropil as possible in Z. Only chemical synapses were labeled, with particular care taken to ensure that any synaptic sites that were nearly parallel with the cutting plane were also labeled. In total 6434 synaptic sites were annotated from 3217 unique synapses across the six ROIs.</p><p hwp:id="p-120">Training examples were balanced between positive examples centered on the synapse, and negative examples corresponding to locations where there were no pre- or post-annotations within the FoV. During training, we performed data augmentation, including permutations of X and Y, and reflections along X, Y, and/or Z. The input FoV was [403,403,42] voxels centered around the example points, corresponding to an output size of [191,191,14]. Due to the network’s large memory requirement, a batch size of 2 was used, with batch normalization applied during training. Due to the relative sparsity of synaptic annotations compared to the total number of voxels in the volume, positive pre-/post-annotations were weighted 2x compared to background classifications in the loss calculation. The network was trained to 51 M steps at a learning rate of 10<sup>-5</sup> using asynchronous stochastic gradient descent, using 32 NVIDIA V100 workers.</p></sec><sec id="s10r2" hwp:id="sec-49"><title hwp:id="title-58">Prediction filtering and connectome assembly</title><p hwp:id="p-121">After generating predictions from the synapse detection model across the entire h01 sample, a unique identifier was assigned to each pre- and post-synaptic site by running connected components, resulting in 1.9 B unique synaptic sites. While this site count is much larger than the number of expected sites from a sample of this size, we had intentionally biased the network towards capturing more true positive sites at the expense of potential false positives by weighting the positive examples 2x during training. To correct the false positives as a result of the bias, a multi-stage filtering pipeline was applied to ensure site predictions were potentially valid synapses.</p><p hwp:id="p-122">First, we discarded synaptic sites that contained less than 30 voxels. We further discarded sites that were in non-neuropil “OOB” regions (as classified by the mask described in “Valid tissue detection”).</p><p hwp:id="p-123">Because the synaptic predictions were volumetric in nature and did not take the neurite segmentation into account, it was possible for a synaptic site prediction to span more than one neuropil segment, causing multiple true synaptic sites to be merged into one predicted site after applying connected components. This failure case was particularly relevant to cases where a single pre or postsynaptic partner made synapses with multiple pre or postsynaptic partners, such as a single spine revealing multiple synaptic inputs. To correct for this, we first masked the volumetric labels associated with each site by the segmentation to remove any synaptic labels that exceeded neuropil boundaries, then applied a one voxel 2D erosion to correct for anisotropy. Connected components were then applied to the result. In the case of two or more components, each component was considered a new, unique synaptic site if its volume was greater than 20% of the original prediction’s volume. Any components that did not meet this criteria had their voxels assigned to the closest valid component. Finally, any voxels spanning cell walls that were masked out by the segmentation were joined and assigned to the closest resulting split site.</p><p hwp:id="p-124">After splitting, two additional filtering steps were applied. Each post-split site was required to have a minimum voxel size of 100. Next, sites were required to be in areas classified as neuropil, filtering out any sites that were within blood vessels, tears, myelin, or missing data; a site was considered valid if 20% or more of its voxels resided in areas classified as neuropil. Finally each synaptic site was assigned an associated neurite supervoxel based on the neurite segmentation volume (the supervoxel with the largest overlap with the synaptic site mask was selected). If the site mask did not overlap with any supervoxels (potential out of bounds or cell-wall-only), the site was dropped.</p><p hwp:id="p-125">After all synaptic sites were identified, split, and filtered, individual sites were paired into synapses. For each site, a local search was performed for any adjacent site within 800 nm. If one or more complimentary sites were identified (e.g. one or more post-sites for a given pre-) and were associated with two unique supervoxels, the closest site was selected as the partner and considered a true synapse. Note that because the process is applied to both pre- and post-sites individually, this pairing process can identify polyadic synapses where one site is partnered to two or more complementary sites.</p><p hwp:id="p-126">Because of errors in the original volumetric predictions, the model may correctly identify a synapse, but incorrectly swap pre- and postsynaptic sites. To correct these instances, a final conservative reorientation step was applied using the subcompartment fragment classifications produced for all neurites. For each site associated with a single synapse, the nearest skeleton node was identified based on shortest-path distance through the associated neurite and the node’s class is identified (see section ‘Cellular subcompartment classification and merge error correction’ for fragment categories). If no nearby skeleton node was identified within a radius of 5.3 μm from the synaptic site, the closest skeleton node was assigned based on Euclidean distance (ignoring the segmentation). The identified class was then used to generate a vote to correct (“flip”) the orientation of the synapse. For each site, a set of votes were collected:</p><list list-type="order" hwp:id="list-1"><list-item hwp:id="list-item-1"><p hwp:id="p-127">If an outgoing synapse originates on an axon, the outgoing vote is “no flip”.</p></list-item><list-item hwp:id="list-item-2"><p hwp:id="p-128">If an outgoing synapse does not originate on an axon, the outgoing vote is “flip”.</p></list-item><list-item hwp:id="list-item-3"><p hwp:id="p-129">If an incoming synapse is not onto an axon, the outgoing vote is “no flip”.</p></list-item><list-item hwp:id="list-item-4"><p hwp:id="p-130">If an incoming synapse is onto an axon, the incoming vote is “flip”.</p></list-item><list-item hwp:id="list-item-5"><p hwp:id="p-131">If either an outgoing or incoming synapse is onto an astrocyte, no vote occurs.</p></list-item><list-item hwp:id="list-item-6"><p hwp:id="p-132">If the nearest skeleton node has no compartment class, no vote occurs.</p></list-item><list-item hwp:id="list-item-7"><p hwp:id="p-133">If there is no nearby skeleton node, no vote occurs.</p></list-item><list-item hwp:id="list-item-8"><p hwp:id="p-134">If there is no skeleton for the neurite, no vote occurs.</p></list-item></list><p hwp:id="p-135">Once all votes were generated for a site, votes were applied based on a consensus measure:</p><list list-type="order" hwp:id="list-2"><list-item hwp:id="list-item-9"><p hwp:id="p-136">If both votes agree to flip or to keep the original orientation, the corresponding correction was applied.</p></list-item><list-item hwp:id="list-item-10"><p hwp:id="p-137">If only one vote is present (flip/no flip) the corresponding action is applied.</p></list-item><list-item hwp:id="list-item-11"><p hwp:id="p-138">If two votes were generated but they conflict, no correction was applied.</p></list-item><list-item hwp:id="list-item-12"><p hwp:id="p-139">If no votes occur, no correction was applied.</p></list-item></list></sec><sec id="s10r3" hwp:id="sec-50"><title hwp:id="title-59">Correction of synapse over-splitting</title><p hwp:id="p-140">Following the processes described above, 190,576,758 individual synapses were identified, although many duplicate synaptic predictions existed at the same individual synaptic site, artificially inflating the number of identified synapses. To correct this, a procedure was applied to consider each pair of synapses sharing the same pre- and postsynaptic associated agglomeration ID and decide whether that pair represented one synapse (should be merged together) or two distinct synapses (should be kept apart), as follows. For each pair, the distance between the centroids of each member of the synaptic pair was calculated. If this distance was less than 750 nm, the pair was merged together. If the distance was greater than 1050 nm, the pair was kept separate. If the distance was in between, then on the pre- and postsynaptic sides of the pair the distance along the skeleton of the pre- or postsynaptic partner between the skeleton nodes closest to each of the two synapses was calculated, and divided by the distance between the two synapses. The greater of these two (pre- and post-) skeleton distances was then used in a logistic regression model (<underline>train_synapse_merger_upper_and_lower_thresholds.py</underline>) to predict whether the pair should be kept separate or merged together. The overall accuracy of this approach was AUC=0.875. Training data (<underline>001_pr_axons.zip</underline>) was generated by randomly selecting 117 axons making 10 or more synapses and assessing for each pair of synapses being made onto the same postsynaptic partner, whether they should be merged together or not, using our tool, CREST (see ‘Measurement of synapse prediction errors’, below). After application of the model (<underline>get_syn_pairs_with_skel_dists_and_apply_merge_model_parallel.py</underline>), the number of predicted synapses fell to 166,216,068. Filtering these synapses to only include those where the presynaptic site was an axon and the postsynaptic site was either a dendrite, soma or axon initial segment, resulted in 133,704,943 synapses.</p></sec></sec><sec id="s10s" hwp:id="sec-51"><title hwp:id="title-60">Excitatory versus inhibitory synapse classification</title><p hwp:id="p-141">To determine whether a synapse was excitatory or inhibitory, we trained a two-class ResNet-50 classifier with an input FoV of [100,100,24], whose input was two-channels: the image data normalized to be centered around zero ((uint8 data - 128) / 33), and a weighted mask of the segments associated with the synapse (pre_weight = 0.95, post_weight = −0.95, background = 0). The center position of each training example was the geometric mean of the pre- and post-masks and included an augmentation that was randomly offset up to +/- [17, 17, 4] voxels in each direction (in order to encourage translation invariance). Additional augmentations of random XY permutations, XY reflections, and 2D rotations around the Z axis were also applied.</p><p hwp:id="p-142">Ground truth used to train the classifier was generated by manually proofreading 47 cells (22 excitatory and 22 inhibitory, classified by a single human expert based on morphology) for all outgoing axonal synapses, under the assumption that all outgoing synapses from a single cell were of a common type. Any outgoing synapses that were not originating from axons were discarded, along with any outgoing synapses that were originating from axon fragments containing a merger. This resulted in a total of 2143 excitatory and 2080 inhibitory synapses for training. Since the locations of synapses were determined by the connectome assembly pipeline, no negative examples were generated or used. The model was trained for 733k steps using a batch size of 16 and a learning rate of 2.5·10<sup>-4</sup>.</p><p hwp:id="p-143">Given that each dendritic spine is thought to generally correspond to one excitatory synapse <sup><xref ref-type="bibr" rid="c83" hwp:id="xref-ref-83-1" hwp:rel-id="ref-83">83</xref></sup>, a subsequent correction step was applied to synapses occurring on spines. We assigned synapses as excitatory if their post-synaptic segment contained a spine-positive skeleton node within 1 μm (see “Spine detection” above), potentially overriding the type determined by the classifier. In addition, any outgoing synapses that originated from a known excitatory or inhibitory cell type - pyramidal and interneuron, respectively - was corrected to the corresponding type.</p><p hwp:id="p-144">To assess the performance of the classifier, 2,129 verified synaptic connections identified as arising from excitatory or inhibitory neurons (see section ‘Analysis of manual and ML-generated neuronal networks’, below) were compared to their predicted E or I status (<underline>measure_e_vs_i_accuracy.py</underline>). Excitatory and inhibitory synapses were correctly classified 99.25% and 89.68% of the time, respectively, with an AUC score of 0.948. Performance was broadly similar across the six cortical layers (<bold><xref ref-type="table" rid="tbls7" hwp:id="xref-table-wrap-7-1" hwp:rel-id="T7">Supp Table 7</xref></bold>). Counts of excitatory and inhibitory synaptic inputs to all neurons were then generated (<underline>get_neuron_e_to_i_ratios.py</underline>).</p></sec><sec id="s10t" hwp:id="sec-52"><title hwp:id="title-61">Measurement of synapse prediction errors</title><p hwp:id="p-145">To assess our ability to identify synapses arising from axons, where the postsynaptic target structure is either a dendrite, soma or axon initial segment, we made a random selection of 50 synapse-forming axons from across the volume (see <underline>50_random_pure_and_majority_axons_FP_and_FN.csv</underline>), and verified each predicted synapse. We also searched for synapses that the model failed to predict by examining each bouton or swelling along the axon. The overall false negative rate was 12% and the overall false discovery rate was 1.5%.</p></sec><sec id="s10u" hwp:id="sec-53"><title hwp:id="title-62">Correction of segmentation errors by computer-assisted proofreading</title><p hwp:id="p-146">Since the automatic agglomeration produces neurons and glia that are prone to having split- and merge-errors, we sought a method of correcting these errors efficiently, to facilitate certain analyses that would require 100% correct connectomic data. To this end, we created a simple Python-based tool with a GUI, which makes use of the <underline>Neuroglancer Python API</underline> and other Python packages to allow the correction of segmentation data, verification and classification of synapses, and structured exploration of the synaptic network of a dataset, called CREST (Connectome Reconstruction and Exploration Simple Tool; <underline>CREST_v1.0.py</underline>).</p><p hwp:id="p-147">For this purpose, a biological object is considered ‘correct’ once all of the base segments that are part of it in the dataset are identified, and no base segments that are not part of it are considered to be part of it. CREST starts with the base segments that have been automatically agglomerated together as part of a single biological object and presents them to the user. The user can then correct split errors by adding on agglomerated segments (which results in all of the base segments that make up that agglomerated segment being added on), or removing base segments that do not belong to that biological object (correcting mergers).</p><p hwp:id="p-148">Because CREST treats the single biological object as a graph of connected base segments, correction of mergers is very efficient, as when the user removes a single base segment, all base segments connected to the main part (the part which contains the cell body) via that base segment will be removed at the same time. In the cases where the user wishes to correct structures without cell bodies (such as axonal and dendritic fragments), they may specify which part of that structure is to be considered as the ‘cell body part’ for the purposes of merger correction.</p><p hwp:id="p-149">The structures corrected (e.g. neurons) are often highly-branching and complex objects and it can therefore be challenging for the user to keep track of which branches they have corrected. To address this, CREST introduces two features to aid the proofreader. Firstly, the user may specify any number of custom types of Neuroglancer ‘point annotations’, via the GUI, which can be placed at the end of a completed branch, where the ‘type’ of point can be used to record the reason that the branch could not be extended further. The second feature, which builds more on the Neuroglancer Python API, allows the user to mark a base segment and all base segments on the other side of that base segment with respect to the cell body in a certain color. This serves two purposes - firstly to act as a visual aid to the proofreader that a part of a branch is complete (as it is in color - incomplete parts are grey by default). Secondly, the specific color indicates a specific ‘cell structure type’ (e.g. axon, dendrite, cilia), which is saved in a simple JSON state that also includes the complete set of base segments, point annotations and underlying base segment graph, and can be reloaded in CREST for further proofreading.</p><p hwp:id="p-150">An example of a complex cell, which contacts 70 postsynaptic partners which also have cell bodies in the volume, completed by CREST in Neuroglancer, is shown in <bold><xref ref-type="fig" rid="figs15" hwp:id="xref-fig-21-1" hwp:rel-id="F21">Supplementary Fig. 15</xref></bold>. Following training in use of CREST and neurobiology, four proofreaders were able to complete 104 randomly-selected neurons (where the center-point of the cell body of each neuron fell between 23 and 30 micrometers in the z axis from the start of the block), which, along with their un-proofread postsynaptic target neurons, form the basis of the network displayed in <bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-13" hwp:rel-id="F4">Fig. 4I</xref>.</bold></p></sec><sec id="s10v" hwp:id="sec-54"><title hwp:id="title-63">Analysis of manual and ML-generated neuronal networks</title><p hwp:id="p-151">Base segments of 104 proofread neurons whose ‘cell structure type’ had been marked as axonal during the proofreading process with CREST (see ‘Correction of segmentation errors by computer-assisted proofreading’) were identified, and synapses whose presynaptic associated base segments were present within this group were identified as the outgoing synapses of the proofread neurons. These synapses were used to identify the postsynaptic partner neurons with cell bodies in the volume, whether proofread or not (<underline>get_edge_list_for_pr_cells_and_unproofread_targets.py</underline>), forming the network plotted in <bold><xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-14" hwp:rel-id="F4">Fig. 4I</xref></bold> (<underline>edge_list_to_graph.py</underline>).</p><p hwp:id="p-152">For the ML-generated network, all connections between segments where both the pre- and post-synaptic segments had been identified as neurons, the presynaptic structure had been identified as an axon and the postsynaptic structure had been identified as either dendrite, soma or axon initial segment, were identified and form the ML-generated network (<underline>edge_list_to_graph.py</underline>). Because individual connections can erroneously be automatically identified between neurons due to merge errors in the agglomeration or, less commonly, false positive synapse predictions, we sought to measure the false positive rate of each connection type, where one connection type is a combination of a pre and postsynaptic neuron type, and a neuron’s type, for this purpose, is determined by the combination of its cortical layer membership and whether it is excitatory or inhibitory. For example, a layer 2 excitatory neuron forming synapses on a layer 3 inhibitory neuron would be considered one connection type. We made a random selection of connections of each possible connection type (<underline>get_subset_of_connections_to_check.py</underline>) and created a simple neuroglancer-based python program to manually verify each synapse forming each connection (<underline>proofread_connections.py</underline>), where an individual synaptic connection between two neurons was considered to be verified if (a) the synapse itself was real and (b) the connection did not arise as a result of merge errors in the agglomeration on either the pre or postsynaptic side. An individual connection (which is defined as all of the synapses formed between two individual neurons), was considered to be verified if at least one of the individual synapses that formed it was verified. Summaries of ML-generated connection type counts and their false positive rates (<bold><xref ref-type="table" rid="tbls5" hwp:id="xref-table-wrap-5-2" hwp:rel-id="T5">Supp. Table 5</xref></bold>), as well as manually-generated connection types (<bold><xref ref-type="table" rid="tbls6" hwp:id="xref-table-wrap-6-2" hwp:rel-id="T6">Supp. Table 6</xref></bold>) were then generated (<underline>get_connection_type_accuracy_summary_table.py</underline>).</p></sec><sec id="s10w" hwp:id="sec-55"><title hwp:id="title-64">Identification of cortical layers</title><p hwp:id="p-153">For the purposes of analysis, we wished to divide the cortex into layers, each of which would run perpendicularly to the pial-white matter axis. However, we sought a method that would achieve this objectively, without any prior assumptions about the numbers of these layers, or their locations along the pial-white matter axis. We approached this problem in two parts - firstly the identification of clusters of neurons, and secondly, the fitting of boundaries to these clusters.</p><sec id="s10w1" hwp:id="sec-56"><title hwp:id="title-65">Identification of neuronal clusters</title><p hwp:id="p-154">The clustering algorithm HDBSCAN <sup><xref ref-type="bibr" rid="c84" hwp:id="xref-ref-84-1" hwp:rel-id="ref-84">84</xref></sup> was used to identify clusters of neurons based on the distance of the neurons from one another in the x and y axes (we found that including the distance in z made no difference to the result), as well as the ‘distance’ (i.e. difference) in neuronal soma volume. HDBSCAN has two tunable parameters - the minimum number of points that a cluster must possess to be considered as a cluster (<italic toggle="yes">min_cluster_size</italic>), and <italic toggle="yes">min_samples</italic>, which determines how ‘conservative’ the clustering is. To set the value of <italic toggle="yes">min_samples</italic>, we first estimated a probability density function for the neurons, given their positions in x, y and soma size using a Gaussian kernel. For each neuron we then found the mutual reachability distance between it and each neighbor kth- closest or higher, where the mutual reachability distance between between it (a) and one of its neighbors (b) is the maximum of (1) the distance from a to its kth-nearest neighbor (its ‘core distance’), (2) the core distance of b and (3) the distance from a to b. We then calculated the mean mutual reachability distance for each neuron at that value of k, and calculated the correlation between the mean mutual reachability distance and estimated probability density for all neurons. The value of k that produced the greatest correlation between these two measures of neuronal density was selected as the value of <italic toggle="yes">min_samples</italic> for the HDBSCAN algorithm. HDBSCAN was then run, gradually increasing the value of <italic toggle="yes">min_cluster_size</italic> until multiple ‘acceptable’ clusters were identified. Because we sought large clusters running perpendicular to the pial-white matter axis, a cluster was considered ‘acceptable’ if it contained neurons at both the upper and lower edges of the dataset (perpendicular to the pial-white matter axis) and at least 50 neurons in total. This approach identified three clusters. Outlier points were removed from clusters by using a random sample consensus (RANSAC) regressor to fit a second order polynomial through the center of each cluster. For each cluster, the maximum residual threshold such that the resulting curve was still convex was chosen (<underline>get_cluster_bounds.py</underline>).</p></sec><sec id="s10w2" hwp:id="sec-57"><title hwp:id="title-66">Fitting boundaries to neuronal clusters</title><p hwp:id="p-155">After generating three clusters of neurons, it was possible to fit bounds to the upper and lower edges of each cluster. A concave hull was fit to each cluster, by fitting a Delaunay triangulation to the set of points and then only adding triangles of points to the resulting concave hull if the circumference of said triangle is below a given <italic toggle="yes">ɑ</italic> hyperparameter. Because of the varying density of points in the three clusters, the alpha hyperparameter was tuned to best generate a hull for each cluster of points. Additionally, where there still remained points that extended far out from the central mass of each cluster, by choosing an appropriate <italic toggle="yes">ɑ</italic> value these points were not included in the hull and thus classified as outliers.</p><p hwp:id="p-156">With the concave hull of each cluster fitted, the edge points of each concave hull were isolated by only selecting endpoints of edges that were part of one triangle and not two (any edge within the concave hull would be part of two triangles). These edge points were then split into two sets separated by the original central second order polynomial that was fit to each cluster. This method generated two sets of points for each cluster, one corresponding to the upper edge of the cluster and one to the lower edge of the cluster.</p><p hwp:id="p-157">Experiments were then conducted to see what curve could best be used to fit the boundary points of the clusters. Arcs of circles were found to be an excellent solution (<underline>get_cluster_bounds.py</underline>). For each cluster, a circular arc was fit through the center. Let the center of this circle be A. Circular arcs were then fit to the top and bottom edge points of the cluster with fixed center point equal to A. Thus each cluster was bounded by arcs of two concentric circles (see <bold><xref ref-type="fig" rid="figs16" hwp:id="xref-fig-22-1" hwp:rel-id="F22">Supplementary Fig. 16</xref></bold>). These six boundaries (<underline>circle cortical layer bounds.json</underline>), two for each of the three clusters, divided the cortex into seven regions, corresponding to classical descriptions of layers 1 through 6 and white matter. These boundaries were then used to classify all cells in the dataset into a cortical layer according to what bounds the cell was in between (<underline>classify_layers_all_segments.py</underline>).</p></sec></sec><sec id="s10x" hwp:id="sec-58"><title hwp:id="title-67">Measurement of synapse densities</title><p hwp:id="p-158">To estimate the distribution of excitatory and inhibitory synapses across XY, the entire dataset was divided into cubes 10 micrometers on each side, and the numbers of each type of synapses counted in each cube. Only 133,440,987 synapses where the presynaptic structure had been identified as an axon and the postsynaptic structure had been identified as either dendrite, soma, or axon initial segment, were considered. The density of E synapses, density of I synapses, and percentage of synapses that are E, was then calculated for each cube, and the values in cubes were then averaged across z (excluding cubes where the total number of synapses within them was zero, to avoid large regions of no data impacting the results) and plotted as heatmaps (<underline>plot_synapse_density_and_ei_ratio.py</underline>).</p></sec><sec id="s10y" hwp:id="sec-59"><title hwp:id="title-68">Measurement of layer 5 and 6 triangular cell basal dendrite angles</title><p hwp:id="p-159">During manual classification of all neurons, spiny neurons with a distinct bipolar shape, one apical and one prominent basal dendrite, were tagged. Of these, we selected only cells in cortical layer 5 and 6 (estimated radial cortical depth &gt; 1750 micrometers). This yielded a set of 845 neurons for this analysis. For each of these cells, further analysis was done at low resolution (mip 7, every 128th section) in Matlab (The Mathworks, Inc.). We used the manually labeled cell body to extract the Google segment (C3 agglomeration) which overlaps with it maximally (gseg), assuming that that segment corresponds to the analyzed cell. We then computed the bounding box of gseg and used connected components analysis to identify the main connected region of the object while discarding any disconnected parts. Next, we dilated the manual cell body mask by three pixels and subtracted it from gseg to disconnect all branches coming off of the cell body, followed by a second connected components analysis to individualize the branches. Next, we computed center-of-mass coordinates (centroids) of the manual cell body mask and of the two largest branches (by volume), assuming that one of them is the apical and the other the basal dendrite (the axon has a much smaller caliber and would have a much smaller volume that the two big dendrites of these neurons). Centroids which did not end up on the gseg segment were moved to the closest voxel which was part of gseg (minimal Euclidean distance).</p><p hwp:id="p-160">Which of the two largest dendrites is the apical dendrite was decided by computing the inner product between the vector from the cell body center to the dendrite centroid and an estimated apical direction. The dendrite running closer to the apical direction was assumed to be the apical dendrite. Cases in which the two dendrites could not be extracted in this automatic way were removed from the list, leaving 816 cells for further analysis.</p><p hwp:id="p-161">For the next step we computed a topological field to be able to define ‘radial’ and ‘tangential’ directions at different locations in the tissue. This was done in 2D (XY) only, assuming that the directional variability across sections is minimal. First, we manually fit a grid of tangential and radial lines to 2D projection images of different extracted properties of the sample (cell bodies, excitatory cells, and myelin) by using VAST’s skeleton functions (see <bold><xref ref-type="fig" rid="figs21" hwp:id="xref-fig-27-4" hwp:rel-id="F27">Supplementary Fig. 21A</xref></bold>). We then used Matlab’s function <italic toggle="yes">scatteredInterpolant</italic> to generate interpolated vector fields from these lines (<bold><xref ref-type="fig" rid="figs21" hwp:id="xref-fig-27-5" hwp:rel-id="F27">Supplementary Fig. 21B</xref> and <xref ref-type="fig" rid="figs21" hwp:id="xref-fig-27-6" hwp:rel-id="F27">C</xref></bold>). These topological fields were also used to define radial and tangential directions in the myelin image in <bold><xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-23" hwp:rel-id="F3">Fig. 3H</xref></bold>.</p><p hwp:id="p-162">To compute the angles at which the basal dendrites run through the tissue with respect to radial, tangential and perpendicular directions, we used the vectors between the cell body centroid and the basal dendrite centroid (basal dendrite vector). Coordinates were scaled to nanometers for correct geometry. We computed polar coordinates of the basal dendrite vector relative to the inverted radial direction at the cell body location (taken from the vector field described above). We name the angle between the inverted radial vector and the basal dendrite vector the radial coordinate ‘rho’ (distance of point from center in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-23" hwp:rel-id="F5">Figure 5G</xref>), and the angle of the basal dendrite vector around the inverted radial vector the angular coordinate ‘theta’. Basal dendrites with rho below 45° point in a mostly radial direction towards the white matter (dark green dots in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-24" hwp:rel-id="F5">Figure 5G</xref>). Basal dendrites with rho between 45°-90° and theta between 0°-45°, 135°-225°, or 315°-360° point roughly along the sectioning plane and parallel to the pia (tangential direction; gray points in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-25" hwp:rel-id="F5">Figure 5G</xref>). Basal dendrites with rho between 45°-90° and theta between 45°-135° point in a mostly perpendicular direction towards section 0 in the stack (light green dots in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-26" hwp:rel-id="F5">Figure 5G</xref>) and basal dendrites with rho between 45°-90° and theta between 225°-315° point in a mostly perpendicular direction towards section 5292 in the stack (magenta dots in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-27" hwp:rel-id="F5">Figure 5G</xref>).</p><p hwp:id="p-163">For statistical analysis of clustering of cells with basal dendrites pointing towards section 0 and towards section 5292 we selected cells with a basal dendrite pointing towards section 0 as described above (light green, 257 cells) and cells with a basal dendrite pointing towards section 5292 (magenta, 247 cells).</p><p hwp:id="p-164">For each of these 504 cells, we found the nearest neighbor and compared their colors, yielding four groups (145 light green-light green, 109 light green-magenta, 112 magenta-light green and 138 magenta-magenta). We performed Fisher’s exact test on these numbers and found that equal-color neighbors were occurring significantly more often than chance (<italic toggle="yes">p</italic> = 0.00745) which we verified by shuffling the colors across cells followed by the same test (<italic toggle="yes">p</italic> = 0.476, n.s.).</p></sec><sec id="s10z" hwp:id="sec-60"><title hwp:id="title-69">Analysis of axon partners of layer 5 and 6 triangular cell basal dendrites</title><p hwp:id="p-165">Axonal inputs onto the largest basal dendrites of layer 5 and 6 triangular cells (see ‘Measurement of layer 6 pyramidal neuron basal dendrite angles’), were identified as follows. First, the skeletons with classified nodes (see ‘Cellular subcompartment classification and merge error correction’) of the layer 5 and 6 triangular cells were converted into graphs. The nodes corresponding to the cell’s soma were automatically identified and removed, creating several disconnected connected components corresponding to the axonal and dendritic branches of the neuron (<underline>get_separate_components_of_neurons.py</underline>). A point was placed within the thickest basal dendrite of each neuron and the disconnected skeleton branch with the skeleton node closest to this was identified as the thickest basal dendrite branch. The accuracy of this process was assessed by manually measuring, for 20 ‘forward basal dendrite’ and ‘reverse basal dendrite’ neurons, the number of dendritic branches wrongly identified as being part of the largest basal dendrite (90% of both ‘forward’ and ‘reverse’ neurons did not have any wrongly-identified branches), as well as the average number of sub-branches arising from the largest basal dendrite which were not identified as part of it, which was 1.9 for ‘forward’ neurons and 1.3 for ‘reverse’ neurons (<xref ref-type="table" rid="tbls4" hwp:id="xref-table-wrap-4-1" hwp:rel-id="T4">Supplementary Table 4</xref>). All incoming synapses to that neuron were then downloaded, and those that were located within 3000 nm of at least one of the thickest basal dendrite branch skeleton were identified as synaptic inputs to the thickest basal dendrite branch, and of the the axons making these synapses, those where 100% of their classified skeleton nodes were of the type ‘axon’, were recorded as axonal inputs to the thickest basal dendrite branch (<underline>get_partners_for_basal_dendrites_parallel.py</underline>).</p><p hwp:id="p-166">Having identified the axonal inputs to the thickest basal dendrite (and its subsequent branches), we decided to focus on those axons (n=1180) which made one synapse each on the thickest basal dendrite of two different layer 5/6 triangular cells, both of which would either be in the group of ‘forward-going’ triangular cells or ‘reverse-going’ triangular cells (see ‘New morphological subcategories of layer 6 triangular neurons’). We calculated the proportion of axons that fell into one of three groups; those that targeted two forward basal dendrites, those that targeted two reverse basal dendrites, and those that targeted one of each. For these three proportions we also calculated 95% confidence intervals,<sup><xref ref-type="bibr" rid="c85" hwp:id="xref-ref-85-1" hwp:rel-id="ref-85">85</xref></sup> shown as blue bars in <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-28" hwp:rel-id="F5">Fig. 5G</xref></bold>. We observed that ‘forward’ basal dendrites receive more synapses than reverse basal dendrites, and have more skeleton nodes (<bold><xref ref-type="fig" rid="figs20" hwp:id="xref-fig-26-1" hwp:rel-id="F26">Supplementary Fig. 20</xref></bold>), suggesting that axons have a greater probability of randomly forming synapses onto ‘forward’ basal dendrites than ‘reverse’. Therefore, to take this into account, we decided to calculate expected proportions (or FF, RR and FR) under a null model whereby each axon selects two basal dendrite partners randomly, but with the probability of choosing either a forward or reverse basal dendrite determined by the total number of synapses being made onto these two types of basal dendrite, resulting in the point estimates shown as red dots in <bold><xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-29" hwp:rel-id="F5">Fig. 5G</xref></bold>. From these estimated proportions, we were able to calculate expected frequencies under the null model, and these were compared to the observed frequencies by a chi-squared test, which resulted in a p-value of 3.34·10<sup>-14</sup>, with the same approach used for excitatory (n=808, p = 1.60·10<sup>-7</sup>) and inhibitory (n=372, p = 9.89·10<sup>-6</sup>) subsets of these axons (<bold><xref ref-type="fig" rid="figs24" hwp:id="xref-fig-30-3" hwp:rel-id="F30">Supplementary Fig. 24</xref></bold>). This analysis excluded those axons making a synapse on any axon initial segment (AIS), whose interactions with layer 5/6 triangular cells were analysed separately in exactly the same way, except that axons targeting more than two triangular cells were included, and two triangular cell partners randomly selected from each axon’s set of postsynaptic targets (n=174, p = 0.319; <underline>basal_dendrite_analysis.py</underline>).</p></sec><sec id="s10aa" hwp:id="sec-61"><title hwp:id="title-70">Analysis of axonal selectivity</title><p hwp:id="p-167">To simulate the expected frequencies of different connection strengths in the dataset for comparison to the observed frequencies (<bold><xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-15" hwp:rel-id="F6">Fig. 6</xref></bold>) we took the four-part approach described below; firstly, identifying for each synapse the point at which it attached to the shaft of its parent axon, secondly, measuring the distances between either ‘en passant’ or ‘terminal bouton’ synapses to the axonal shaft and estimating the distributions of these distances, thirdly, using these estimated distributions to simulate the random formation of synapses arising from the axonal shaft, and finally, using these simulated random synapses to estimate the expected frequencies of different connection strengths across the dataset as a whole.</p><sec id="s10aa1" hwp:id="sec-62"><title hwp:id="title-71">Identification of distinct axonal skeleton components</title><p hwp:id="p-168">To facilitate the analysis of the connectivity of individual axons, methods were developed to identify separate components of the skeletons of axons, in particular distinguishing the ‘shaft’ of the axon from its terminal bouton stalks, and based on this, distinguishing synapses that are intrinsic to the shaft (en passant synapses) from those that arise from the shaft on terminal bouton stalks (see <bold><xref ref-type="fig" rid="figs17" hwp:id="xref-fig-23-1" hwp:rel-id="F23">Supplementary Fig. 17</xref></bold> for a representative example). To achieve this we first attempted to identify the skeleton node where each synapse connected to the shaft (hereafter ‘root node’), whether or not that synapse was on a stalk or an en passant synapse. To do this, we first used CREST to manually mark the root nodes of several synapses. We then trained a simple model which for each synapse, (1) identifies the longest path from the skeleton node closest to the synapse to any ‘end node’ in the skeleton, (2) considers each node on this longest path in order, starting from the synapse-associated node, and decides whether it is the ‘root node’ of that synapse, based on whether the two longest paths arising from that candidate root node’s immediate neighbour nodes to end nodes in the skeleton (and not including current or previously-considered root node candidates, or the synapse-associated node) each exceed specified minimum lengths. Once a root node candidate is identified which meets these criteria, the search is terminated and that candidate is designated the root node of that synapse. If a specified number of candidate root nodes are rejected, then no root node is assigned to that synapse at that stage. All paths between ‘end’ nodes which pass through the root nodes, but not through synapse nodes or nodes on the paths between synapse nodes and their individual root nodes, are identified, and designated as ‘shaft’ nodes. For synapses without identified root nodes at this stage, their root node is set to the closest shaft node. Any branches shorter than a certain specified length that do not contain synapses are removed. The model therefore has four tunable parameters; the number of candidate root nodes that will be considered for each synapse, the lengths that the longest and second-longest paths arising from each candidate root note much exceed to be accepted as a root node, and the minimum length for a non-synapse containing side-branch to be kept ( <underline>train_skeleton_pruner.py</underline>, <underline>prune_a_batch_of_skeletons_ig_parallel.py</underline>). This process identifies root nodes with an accuracy of 94.4% and distinguishes shaft nodes from non-shaft nodes with an accuracy of 94.3%. Once this process is complete, the distance from each synapse-associated node to its root node is used in a simple logistic regression model to classify that synapse as either an ‘en-passant’ synapse or a ‘terminal bouton’ synapse (AUC = 0.968).</p></sec><sec id="s10aa2" hwp:id="sec-63"><title hwp:id="title-72">Estimation of distributions of distances from synapse to axonal shaft</title><p hwp:id="p-169">For many connectomic analyses, it is desirable to compare observed results to the range of results that might have occurred given some null model. One approach to this for analyses concerning the targeting preferences of axons, is to simulate which postsynaptic partners any given axon might have been expected to target if it were making its outgoing synapses according to a process that is in some sense ‘random’. However, for any such random simulation / null model to be biologically plausible, it must be constrained in some way by real features observed in the data. To create a biologically plausible model under which an axon might make random outgoing synapses, we first examined the range of distances between synapses and the axonal shafts from which they arose, plotting the range of differences for ‘en passant’ synapses and ‘terminal bouton’ synapses separately. We observed that ‘en passant’ and ‘terminal bouton’ synapses are on average made 270 nm and 1500 nm from the axonal shaft respectively, with both distributions having long-right-hand tails. We were able to fit probability density functions (PDFs) to each of these datasets (see <bold><xref ref-type="fig" rid="figs18" hwp:id="xref-fig-24-1" hwp:rel-id="F24">Supplementary Fig.18</xref></bold> and <underline>fit_distribution_to_synapse_distances.py</underline>).</p></sec><sec id="s10aa3" hwp:id="sec-64"><title hwp:id="title-73">Simulation of random connectivity of an individual axon</title><p hwp:id="p-170">We then devised a method of simulating random connectivity for a single axon as follows. First, the axon is moved (translated) by a user-specified distance in the x, y and z axes, or not at all. For each ‘en passant’ synapse, a random point along the shaft of the axon is chosen (the ‘root point’ of this simulated synapse), a distance for the simulated synapse to occur from the randomly-select root point is chosen according to the PDF of distances described above for ‘en-passant’ synapses, and then a random angle is chosen to determine the direction from the shaft that the simulated synapse will be made from, constrained to a plane that is perpendicular to the shaft skeleton at that root point. For each terminal bouton stalk synapse, the same process is used to generate a simulated synapse location around the shaft, except that the PDF of distances for terminal bouton stalk synapses is used instead, and the simulated synapse location may project from the root point in any direction in 3D space around it. Once a simulated synapse location has been selected, it the segment ID at that point lies on the surface of a segment which is included in a user-supplied list of ‘acceptable post-synaptic partners’ (typically dendrites), then it is accepted as a simulated synaptic connection. This process is repeated to simulate that axon’s connectivity an arbitrary number of times that is specified by the user. An alternative, more ‘constrained’ version (as opposed to the ‘unconstrained’ version described above) of this method of simulation has also been devised, whereby the simulated synapses arise from the actual root points of their real counterparts (<underline>sample_points_around_neurites.py</underline>). We verified for both ‘constrained’ and ‘unconstrained versions for a random subset of axons that the distribution of the sampled points for each individual axon followed the targeted distribution of synapse distances shown in <bold><xref ref-type="fig" rid="figs18" hwp:id="xref-fig-24-2" hwp:rel-id="F24">Supplementary Fig.18</xref></bold>. The distribution of distances for the simulated synapses was a close match to the empirically measured one.</p></sec><sec id="s10aa4" hwp:id="sec-65"><title hwp:id="title-74">Analysis of axonal selectivity</title><p hwp:id="p-171">CREST was used to identify multisynaptic connections between neurons (i.e. strong connections). To establish whether the numbers of strong connections we observed in the data were likely have arisen by random chance, we first randomly selected 10,000 axons of each ‘strongest connection strength type’, where, for example, an axon whose strongest post-synaptic connection was formed of three synapses would have a ‘strongest connection strength type’ of 3. Where there were less than 10,000 axons in a certain connection strength type, we selected all axons of that type. Furthermore, we only selected axons which did not make any synapses on axon initial segments of neurons, and which only have ‘axon’ classified nodes in their skeletons (hereafter ‘pure axons’, see <underline>get_sample_of_axodendritic_only_axons_organised_by_strength.py</underline>). This resulted in a selection of 53,695 axons. We then used the ‘unconstrained’ version of the null model described above with a random 15 micron displacement in the x and y axes (‘Simulation of random connectivity of an individual axon’), for each axon simulating the same number of ‘en passant’ and ‘terminal bouton stalk’ synapses as are found on the axon, to simulate the postsynaptic targets of that axon, to estimate its strongest connection strength under the null model. To prevent axons being moved to within the somas of other cells, we rejected any randomly-selected 15 micron XY displacement location that fell within 25 microns of the centre of a cell body, resulting in 9,190 of the 53,695 axons having their partners randomly simulated. Following the simulation, we manually checked all axons making a high number (&gt;=6) of simulated connections onto a single postsynaptic partner for any artifactual causes of such strong connections, and excluded one axon from the subsequent analysis. Each group of simulated axons (where one group is all axons with a certain combination of inhibitory/excitatory and a certain strongest partner strength) could then contribute simulated outcomes proportional to the overall occurrence of that group of axons in the dataset as a whole, allowing us to calculate expected frequencies of each type for all ‘pure axons’ and compare these to the observed frequencies with the chi-squared test (<underline>connection_strengths_analysis.py</underline>).</p></sec></sec><sec id="s10ab" hwp:id="sec-66"><title hwp:id="title-75">Analysis of information flow through network</title><p hwp:id="p-172">An <underline>animation of information flow</underline> in the automatically-generated network was generated in Python by stepping through discrete time points based on the following preset rules: 1) only pyramidal cells and interneurons with somata inside the volume were considered; 2) when a pyramidal neuron was activated, it added +1 per synapse to the inputs of all its postsynaptic partners; 3) when an interneuron was activated, it added −1 per synapse to the inputs of all its postsynaptic partners; 4) when the summation of all the input synapses to a neuron was larger than 0, it would be activated at the next time step and last for one time step. At the beginning of the process, all the pyramidal cells in cortical layer 4 were set to active. The activated neurons are shown as bright green (pyramidal) or bright red (interneurons) circles. Neurons receiving negative net inputs at the current time step are colored blue. Each time step is subdivided into multiple frames for visualization purposes, with the neurons receiving the largest absolute net inputs changing their color first followed by the ones receiving smaller net positive or negative inputs. The output edges of all the activated neurons were marked as colored straight lines (green for pyramidal and red for interneurons).</p></sec></sec><ref-list hwp:id="ref-list-1"><title hwp:id="title-76">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1"><label>1.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Zhou Y."><surname>Zhou</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-2">Atypical behaviour and connectivity in SHANK3-mutant macaques</article-title>. <source hwp:id="source-1">Nature</source> <volume>570</volume>, <fpage>326</fpage>–<lpage>331</lpage> (<year>2019</year>).</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1"><label>2.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Birey F."><surname>Birey</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-3">Assembly of functionally integrated human forebrain spheroids</article-title>. <source hwp:id="source-2">Nature</source> <volume>545</volume>, <fpage>54</fpage>–<lpage>59</lpage> (<year>2017</year>).</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><label>3.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Quadrato G."><surname>Quadrato</surname>, <given-names>G.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-4">Cell diversity and network dynamics in photosensitive human brain organoids</article-title>. <source hwp:id="source-3">Nature</source> <volume>545</volume>, <fpage>48</fpage>–<lpage>53</lpage> (<year>2017</year>).</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1"><label>4.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Velasco S."><surname>Velasco</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-5">Individual brain organoids reproducibly form cell diversity of the human cerebral cortex</article-title>. <source hwp:id="source-4">Nature</source> vol. <volume>570</volume> <fpage>523</fpage>–<lpage>527</lpage> (<year>2019</year>).</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1"><label>5.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Engel J."><surname>Engel</surname>, <given-names>J.</given-names></string-name> <article-title hwp:id="article-title-6">Early Surgical Therapy for Drug-Resistant Temporal Lobe Epilepsy</article-title>. <source hwp:id="source-5">JAMA</source> vol. <volume>307</volume> <fpage>922</fpage> (<year>2012</year>).</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2"><label>6.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Tapia ."><given-names>.</given-names> <surname>Tapia</surname></string-name>, <string-name name-style="western" hwp:sortable="et al J. C."><given-names>J. C.</given-names>, <surname>et al</surname></string-name>. <article-title hwp:id="article-title-7">High-contrast en bloc staining of neuronal tissue for field emission scanning electron microscopy</article-title>. <source hwp:id="source-6">Nat. Protoc</source>. <volume>7</volume>, <fpage>193</fpage>–<lpage>206</lpage> (<year>2012</year>).</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1 xref-ref-7-2 xref-ref-7-3"><label>7.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Hayworth K. J."><surname>Hayworth</surname>, <given-names>K. J.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-8">Imaging ATUM ultrathin section libraries with WaferMapper: a multi-scale approach to EM reconstruction of neural circuits</article-title>. <source hwp:id="source-7">Front. Neural Circuits</source> <volume>8</volume>, <fpage>68</fpage> (<year>2014</year>).</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1 xref-ref-8-2 xref-ref-8-3"><label>8.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Saalfeld S."><surname>Saalfeld</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fetter R."><surname>Fetter</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cardona A."><surname>Cardona</surname>, <given-names>A.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Tomancak P."><surname>Tomancak</surname>, <given-names>P.</given-names></string-name> <article-title hwp:id="article-title-9">Elastic volume reconstruction from series of ultra-thin microscopy sections</article-title>. <source hwp:id="source-8">Nat. Methods</source> <volume>9</volume>, <fpage>717</fpage>–<lpage>720</lpage> (<year>2012</year>).</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1 xref-ref-9-2 xref-ref-9-3 xref-ref-9-4 xref-ref-9-5 xref-ref-9-6 xref-ref-9-7"><label>9.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Januszewski M."><surname>Januszewski</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-10">High-precision automated reconstruction of neurons with flood- filling networks</article-title>. <source hwp:id="source-9">Nat. Methods</source> <volume>15</volume>, <fpage>605</fpage>–<lpage>610</lpage> (<year>2018</year>).</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1 xref-ref-10-2 xref-ref-10-3 xref-ref-10-4 xref-ref-10-5 xref-ref-10-6"><label>10.</label><citation publication-type="other" citation-type="journal" ref:id="2021.05.29.446289v3.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Li H."><surname>Li</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Januszewski M."><surname>Januszewski</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jain V."><surname>Jain</surname>, <given-names>V.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Li P. H."><surname>Li</surname>, <given-names>P. H.</given-names></string-name> <source hwp:id="source-10">Neuronal Subcompartment Classification and Merge Error Correction</source>. doi:<pub-id pub-id-type="doi">10.1101/2020.04.16.043398</pub-id>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><label>11.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Keller D."><surname>Keller</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Erö C."><surname>Erö</surname>, <given-names>C.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Markram H."><surname>Markram</surname>, <given-names>H.</given-names></string-name> <article-title hwp:id="article-title-11">Cell Densities in the Mouse Brain: A Systematic Review</article-title>. <source hwp:id="source-11">Front. Neuroanat</source>. <volume>12</volume>, <fpage>83</fpage> (<year>2018</year>).</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1"><label>12.</label><citation publication-type="other" citation-type="journal" ref:id="2021.05.29.446289v3.12" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Bae J. A."><surname>Bae</surname>, <given-names>J. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Baptiste M."><surname>Baptiste</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bodor A. L."><surname>Bodor</surname>, <given-names>A. L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Brittain D."><surname>Brittain</surname>, <given-names>D.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Buchanan J. A."><surname>Buchanan</surname>, <given-names>J. A.</given-names></string-name> <article-title hwp:id="article-title-12">Functional connectomics spanning multiple areas of mouse visual cortex</article-title>. <source hwp:id="source-12">bioRxiv</source> (<year>2021</year>).</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1"><label>13.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Lanjakornsiripan D."><surname>Lanjakornsiripan</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-13">Layer-specific morphological and molecular differences in neocortical astrocytes and their dependence on neuronal layers</article-title>. <source hwp:id="source-13">Nat. Commun</source>. <volume>9</volume>, <fpage>1623</fpage> (<year>2018</year>).</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><label>14.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Hodge R. D."><surname>Hodge</surname>, <given-names>R. D.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-14">Conserved cell types with divergent features in human versus mouse cortex</article-title>. <source hwp:id="source-14">Nature</source> <volume>573</volume>, <fpage>61</fpage>–<lpage>68</lpage> (<year>2019</year>).</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><label>15.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.15" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Bayraktar O. A."><surname>Bayraktar</surname>, <given-names>O. A.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-15">Astrocyte layers in the mammalian cerebral cortex revealed by a single-cell in situ transcriptomic map</article-title>. <source hwp:id="source-15">Nat. Neurosci</source>. <volume>23</volume>, <fpage>500</fpage>–<lpage>509</lpage> (<year>2020</year>).</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1"><label>16.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Colombo J. A."><surname>Colombo</surname>, <given-names>J. A.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Reisin H. D."><surname>Reisin</surname>, <given-names>H. D.</given-names></string-name> <article-title hwp:id="article-title-16">Interlaminar astroglia of the cerebral cortex: a marker of the primate brain</article-title>. <source hwp:id="source-16">Brain Res</source>. <volume>1006</volume>, <fpage>126</fpage>–<lpage>131</lpage> (<year>2004</year>).</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><label>17.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Bushong E. A."><surname>Bushong</surname>, <given-names>E. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Martone M. E."><surname>Martone</surname>, <given-names>M. E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jones Y. Z."><surname>Jones</surname>, <given-names>Y. Z.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Ellisman M. H."><surname>Ellisman</surname>, <given-names>M. H.</given-names></string-name> <article-title hwp:id="article-title-17">Protoplasmic astrocytes in CA1 stratum radiatum occupy separate anatomical domains</article-title>. <source hwp:id="source-17">J. Neurosci</source>. <volume>22</volume>, <fpage>183</fpage>– <lpage>192</lpage> (<year>2002</year>).</citation></ref><ref id="c18" hwp:id="ref-18"><label>18.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Ogata K."><surname>Ogata</surname>, <given-names>K.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Kosaka T."><surname>Kosaka</surname>, <given-names>T.</given-names></string-name> <article-title hwp:id="article-title-18">Structural and quantitative analysis of astrocytes in the mouse hippocampus</article-title>. <source hwp:id="source-18">Neuroscience</source> <volume>113</volume>, <fpage>221</fpage>–<lpage>233</lpage> (<year>2002</year>).</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><label>19.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Halassa M. M."><surname>Halassa</surname>, <given-names>M. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fellin T."><surname>Fellin</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Takano H."><surname>Takano</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dong J.-H."><surname>Dong</surname>, <given-names>J.-H.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Haydon P. G."><surname>Haydon</surname>, <given-names>P. G.</given-names></string-name> <article-title hwp:id="article-title-19">Synaptic islands defined by the territory of a single astrocyte</article-title>. <source hwp:id="source-19">J. Neurosci</source>. <volume>27</volume>, <fpage>6473</fpage>–<lpage>6477</lpage> (<year>2007</year>).</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><label>20.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Marques S."><surname>Marques</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-20">Oligodendrocyte heterogeneity in the mouse juvenile and adult central nervous system</article-title>. <source hwp:id="source-20">Science</source> <volume>352</volume>, <fpage>1326</fpage>–<lpage>1329</lpage> (<year>2016</year>).</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1"><label>21.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Harris J. J."><surname>Harris</surname>, <given-names>J. J.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Attwell D."><surname>Attwell</surname>, <given-names>D.</given-names></string-name> <article-title hwp:id="article-title-21">The energetics of CNS white matter</article-title>. <source hwp:id="source-21">J. Neurosci</source>. <volume>32</volume>, <fpage>356</fpage>–<lpage>371</lpage> (<year>2012</year>).</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1 xref-ref-22-2"><label>22.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Vanlandewijck M."><surname>Vanlandewijck</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-22">A molecular atlas of cell types and zonation in the brain vasculature</article-title>. <source hwp:id="source-22">Nature</source> <volume>554</volume>, <fpage>475</fpage>–<lpage>480</lpage> (<year>2018</year>).</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1"><label>23.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Hall C. N."><surname>Hall</surname>, <given-names>C. N.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-23">Capillary pericytes regulate cerebral blood flow in health and disease</article-title>. <source hwp:id="source-23">Nature</source> <volume>508</volume>, <fpage>55</fpage>–<lpage>60</lpage> (<year>2014</year>).</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1"><label>24.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Hartmann D. A."><surname>Hartmann</surname>, <given-names>D. A.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-24">Brain capillary pericytes exert a substantial but slow influence on blood flow</article-title>. <source hwp:id="source-24">Nat. Neurosci</source>. <volume>24</volume>, <fpage>633</fpage>–<lpage>645</lpage> (<year>2021</year>).</citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1"><label>25.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Lapenna A."><surname>Lapenna</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="De Palma M."><surname>De Palma</surname>, <given-names>M.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Lewis C. E."><surname>Lewis</surname>, <given-names>C. E.</given-names></string-name> <article-title hwp:id="article-title-25">Perivascular macrophages in health and disease</article-title>. <source hwp:id="source-25">Nat. Rev. Immunol</source>. <volume>18</volume>, <fpage>689</fpage>–<lpage>702</lpage> (<year>2018</year>).</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1"><label>26.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.26" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Duvernoy H. M."><surname>Duvernoy</surname>, <given-names>H. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Delon S."><surname>Delon</surname>, <given-names>S.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Vannson J. L."><surname>Vannson</surname>, <given-names>J. L.</given-names></string-name> <article-title hwp:id="article-title-26">Cortical blood vessels of the human brain</article-title>. <source hwp:id="source-26">Brain Res. Bull</source>. <volume>7</volume>, <fpage>519</fpage>–<lpage>579</lpage> (<year>1981</year>).</citation></ref><ref id="c27" hwp:id="ref-27" hwp:rev-id="xref-ref-27-1"><label>27.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.27" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Brown W. R."><surname>Brown</surname>, <given-names>W. R.</given-names></string-name> <article-title hwp:id="article-title-27">A Review of String Vessels or Collapsed</article-title>, <source hwp:id="source-27">Empty Basement Membrane Tubes. Journal of Alzheimer’s Disease</source> vol. <volume>21</volume> <fpage>725</fpage>–<lpage>739</lpage> (<year>2010</year>).</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1"><label>28.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.28" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Mendes-Jorge L."><surname>Mendes-Jorge</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-28">Intercapillary bridging cells: immunocytochemical characteristics of cells that connect blood vessels in the retina</article-title>. <source hwp:id="source-28">Exp. Eye Res</source>. <volume>98</volume>, <fpage>79</fpage>–<lpage>87</lpage> (<year>2012</year>).</citation></ref><ref id="c29" hwp:id="ref-29" hwp:rev-id="xref-ref-29-1"><label>29.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.29" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="Alarcon-Martinez L."><surname>Alarcon-Martinez</surname>, <given-names>L.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-29">Interpericyte tunnelling nanotubes regulate neurovascular coupling</article-title>. <source hwp:id="source-29">Nature</source> <volume>585</volume>, <fpage>91</fpage>–<lpage>95</lpage> (<year>2020</year>).</citation></ref><ref id="c30" hwp:id="ref-30" hwp:rev-id="xref-ref-30-1"><label>30.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.30" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="Soares J. M."><surname>Soares</surname>, <given-names>J. M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Marques P."><surname>Marques</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Alves V."><surname>Alves</surname>, <given-names>V.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Sousa N."><surname>Sousa</surname>, <given-names>N.</given-names></string-name> <article-title hwp:id="article-title-30">A hitchhiker’s guide to diffusion tensor imaging</article-title>. <source hwp:id="source-30">Front. Neurosci</source>. <volume>7</volume>, <fpage>31</fpage> (<year>2013</year>).</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1"><label>31.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="DeFelipe J."><surname>DeFelipe</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Alonso-Nanclares L."><surname>Alonso-Nanclares</surname>, <given-names>L.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Arellano J. I."><surname>Arellano</surname>, <given-names>J. I.</given-names></string-name> <article-title hwp:id="article-title-31">Microstructure of the neocortex: comparative aspects</article-title>. <source hwp:id="source-31">J. Neurocytol</source>. <volume>31</volume>, <fpage>299</fpage>–<lpage>316</lpage> (<year>2002</year>).</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1"><label>32.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.32" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="Felleman D. J."><surname>Felleman</surname>, <given-names>D. J.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Van Essen D. C."><surname>Van Essen</surname>, <given-names>D. C.</given-names></string-name> <article-title hwp:id="article-title-32">Distributed hierarchical processing in the primate cerebral cortex</article-title>. <source hwp:id="source-32">Cereb. Cortex</source> <volume>1</volume>, <fpage>1</fpage>–<lpage>47</lpage> (<year>1991</year>).</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1"><label>33.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.33" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Callaway E. M."><surname>Callaway</surname>, <given-names>E. M.</given-names></string-name> <article-title hwp:id="article-title-33">Local circuits in primary visual cortex of the macaque monkey</article-title>. <source hwp:id="source-33">Annu. Rev. Neurosci</source>. <volume>21</volume>, <fpage>47</fpage>–<lpage>74</lpage> (<year>1998</year>).</citation></ref><ref id="c34" hwp:id="ref-34" hwp:rev-id="xref-ref-34-1"><label>34.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.34" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Szentágothai J."><surname>Szentágothai</surname>, <given-names>J.</given-names></string-name> <article-title hwp:id="article-title-34">The ‘module-concept’ in cerebral cortex architecture</article-title>. <source hwp:id="source-34">Brain Res</source>. <volume>95</volume>, <fpage>475</fpage>–<lpage>496</lpage> (<year>1975</year>).</citation></ref><ref id="c35" hwp:id="ref-35" hwp:rev-id="xref-ref-35-1"><label>35.</label><citation publication-type="other" citation-type="journal" ref:id="2021.05.29.446289v3.35" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Schneider-Mizell C. M."><surname>Schneider-Mizell</surname>, <given-names>C. M.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-35">Chandelier cell anatomy and function reveal a variably distributed but common signal</article-title>. doi:<pub-id pub-id-type="doi">10.1101/2020.03.31.018952</pub-id>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1 xref-ref-36-2"><label>36.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.36" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Briggs F."><surname>Briggs</surname>, <given-names>F.</given-names></string-name> <article-title hwp:id="article-title-36">Organizing principles of cortical layer 6</article-title>. <source hwp:id="source-35">Front. Neural Circuits</source> <volume>4</volume>, <fpage>3</fpage> (<year>2010</year>).</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1"><label>37.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.37" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Callaway E. M."><surname>Callaway</surname>, <given-names>E. M.</given-names></string-name> <article-title hwp:id="article-title-37">Cell types and local circuits in primary visual cortex of the macaque monkey</article-title>. <source hwp:id="source-36">The visual neurosciences</source> <volume>1</volume>, <fpage>680</fpage>–<lpage>694</lpage> (<year>2004</year>).</citation></ref><ref id="c38" hwp:id="ref-38" hwp:rev-id="xref-ref-38-1"><label>38.</label><citation publication-type="book" citation-type="book" ref:id="2021.05.29.446289v3.38" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-38"><string-name name-style="western" hwp:sortable="Ramón y Cajal S."><surname>Ramón y Cajal</surname>, <given-names>S.</given-names></string-name> <source hwp:id="source-37">Histologie du système nerveux de l’homme et des vertébrés</source>. (<publisher-name>A. Maloine</publisher-name>, <year>1909</year>).</citation></ref><ref id="c39" hwp:id="ref-39"><label>39.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.39" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-39"><string-name name-style="western" hwp:sortable="De Crinis M."><surname>De Crinis</surname>, <given-names>M.</given-names></string-name> <article-title hwp:id="article-title-38">Uber die Spezialzellen in der menschlichen Grosshirnrinde</article-title>. <source hwp:id="source-38">J Psych Neurol</source> <volume>45</volume>, <fpage>439</fpage>–<lpage>449</lpage> (<year>1934</year>).</citation></ref><ref id="c40" hwp:id="ref-40" hwp:rev-id="xref-ref-40-1"><label>40.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.40" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-40"><string-name name-style="western" hwp:sortable="Braak H."><surname>Braak</surname>, <given-names>H.</given-names></string-name> <article-title hwp:id="article-title-39">Architectonics of the Human Telencephalic Cortex</article-title>. <source hwp:id="source-39">Studies of Brain Function</source> (<year>1980</year>) doi:<pub-id pub-id-type="doi">10.1007/978-3-642-81522-5</pub-id>.</citation></ref><ref id="c41" hwp:id="ref-41" hwp:rev-id="xref-ref-41-1"><label>41.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.41" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-41"><string-name name-style="western" hwp:sortable="Burkhalter A."><surname>Burkhalter</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bernardo K. L."><surname>Bernardo</surname>, <given-names>K. L.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Charles V."><surname>Charles</surname>, <given-names>V.</given-names></string-name> <article-title hwp:id="article-title-40">Development of local circuits in human visual cortex</article-title>. <source hwp:id="source-40">J. Neurosci</source>. <volume>13</volume>, <fpage>1916</fpage>–<lpage>1931</lpage> (<year>1993</year>).</citation></ref><ref id="c42" hwp:id="ref-42" hwp:rev-id="xref-ref-42-1"><label>42.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.42" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-42"><string-name name-style="western" hwp:sortable="Lichtman J. W."><surname>Lichtman</surname>, <given-names>J. W.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Denk W."><surname>Denk</surname>, <given-names>W.</given-names></string-name> <article-title hwp:id="article-title-41">The big and the small: challenges of imaging the brain’s circuits</article-title>. <source hwp:id="source-41">Science</source> <volume>334</volume>, <fpage>618</fpage>–<lpage>623</lpage> (<year>2011</year>).</citation></ref><ref id="c43" hwp:id="ref-43" hwp:rev-id="xref-ref-43-1"><label>43.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.43" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-43"><string-name name-style="western" hwp:sortable="Fischl B."><surname>Fischl</surname>, <given-names>B.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Dale A. M."><surname>Dale</surname>, <given-names>A. M.</given-names></string-name> <article-title hwp:id="article-title-42">Measuring the thickness of the human cerebral cortex from magnetic resonance images</article-title>. <source hwp:id="source-42">Proc. Natl. Acad. Sci. U. S. A</source>. <volume>97</volume>, <fpage>11050</fpage>–<lpage>11055</lpage> (<year>2000</year>).</citation></ref><ref id="c44" hwp:id="ref-44" hwp:rev-id="xref-ref-44-1"><label>44.</label><citation publication-type="book" citation-type="book" ref:id="2021.05.29.446289v3.44" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-44"><string-name name-style="western" hwp:sortable="Braitenberg V."><surname>Braitenberg</surname>, <given-names>V.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Schüz A."><surname>Schüz</surname>, <given-names>A.</given-names></string-name> <source hwp:id="source-43">Cortex: Statistics and Geometry of Neuronal Connectivity</source>. (<publisher-name>Springer Science &amp; Business Media</publisher-name>, <year>2013</year>).</citation></ref><ref id="c45" hwp:id="ref-45" hwp:rev-id="xref-ref-45-1"><label>45.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.45" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-45"><string-name name-style="western" hwp:sortable="Mishchenko Y."><surname>Mishchenko</surname>, <given-names>Y.</given-names></string-name> <article-title hwp:id="article-title-43">Automation of 3D reconstruction of neural tissue from large volume of conventional serial section transmission electron micrographs</article-title>. <source hwp:id="source-44">J. Neurosci. Methods</source> <volume>176</volume>, <fpage>276</fpage>–<lpage>289</lpage> (<year>2009</year>).</citation></ref><ref id="c46" hwp:id="ref-46" hwp:rev-id="xref-ref-46-1"><label>46.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.46" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-46"><string-name name-style="western" hwp:sortable="Morgan J. L."><surname>Morgan</surname>, <given-names>J. L.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Lichtman J. W."><surname>Lichtman</surname>, <given-names>J. W.</given-names></string-name> <article-title hwp:id="article-title-44">Digital tissue and what it may reveal about the brain</article-title>. <source hwp:id="source-45">BMC Biol</source>. <volume>15</volume>, <fpage>101</fpage> (<year>2017</year>).</citation></ref><ref id="c47" hwp:id="ref-47" hwp:rev-id="xref-ref-47-1 xref-ref-47-2 xref-ref-47-3 xref-ref-47-4"><label>47.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.47" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-47"><string-name name-style="western" hwp:sortable="Kasthuri N."><surname>Kasthuri</surname>, <given-names>N.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-45">Saturated Reconstruction of a Volume of Neocortex</article-title>. <source hwp:id="source-46">Cell</source> <volume>162</volume>, <fpage>648</fpage>– <lpage>661</lpage> (<year>2015</year>).</citation></ref><ref id="c48" hwp:id="ref-48" hwp:rev-id="xref-ref-48-1 xref-ref-48-2 xref-ref-48-3"><label>48.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.48" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-48"><string-name name-style="western" hwp:sortable="Eberle A. L."><surname>Eberle</surname>, <given-names>A. L.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-46">High-resolution, high-throughput imaging with a multibeam scanning electron microscope</article-title>. <source hwp:id="source-47">J. Microsc</source>. <volume>259</volume>, <fpage>114</fpage>–<lpage>120</lpage> (<year>2015</year>).</citation></ref><ref id="c49" hwp:id="ref-49" hwp:rev-id="xref-ref-49-1"><label>49.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.49" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-49"><string-name name-style="western" hwp:sortable="Briggman K. L."><surname>Briggman</surname>, <given-names>K. L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Helmstaedter M."><surname>Helmstaedter</surname>, <given-names>M.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Denk W."><surname>Denk</surname>, <given-names>W.</given-names></string-name> <article-title hwp:id="article-title-47">Wiring specificity in the direction-selectivity circuit of the retina</article-title>. <source hwp:id="source-48">Nature</source> <volume>471</volume>, <fpage>183</fpage>–<lpage>188</lpage> (<year>2011</year>).</citation></ref><ref id="c50" hwp:id="ref-50"><label>50.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.50" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-50"><string-name name-style="western" hwp:sortable="Bock D. D."><surname>Bock</surname>, <given-names>D. D.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-48">Network anatomy and in vivo physiology of visual cortical neurons</article-title>. <source hwp:id="source-49">Nature</source> vol. <volume>471</volume> <fpage>177</fpage>–<lpage>182</lpage> (<year>2011</year>).</citation></ref><ref id="c51" hwp:id="ref-51"><label>51.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.51" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-51"><string-name name-style="western" hwp:sortable="Helmstaedter M."><surname>Helmstaedter</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-49">Connectomic reconstruction of the inner plexiform layer in the mouse retina</article-title>. <source hwp:id="source-50">Nature</source> <volume>500</volume>, <fpage>168</fpage>–<lpage>174</lpage> (<year>2013</year>).</citation></ref><ref id="c52" hwp:id="ref-52"><label>52.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.52" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-52"><string-name name-style="western" hwp:sortable="Takemura S.-Y."><surname>Takemura</surname>, <given-names>S.-Y.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-50">A visual motion detection circuit suggested by Drosophila connectomics</article-title>. <source hwp:id="source-51">Nature</source> <volume>500</volume>, <fpage>175</fpage>–<lpage>181</lpage> (<year>2013</year>).</citation></ref><ref id="c53" hwp:id="ref-53"><label>53.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.53" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-53"><string-name name-style="western" hwp:sortable="Lee W.-C. A."><surname>Lee</surname>, <given-names>W.-C. A.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-51">Anatomy and function of an excitatory network in the visual cortex</article-title>. <source hwp:id="source-52">Nature</source> <volume>532</volume>, <fpage>370</fpage>–<lpage>374</lpage> (<year>2016</year>).</citation></ref><ref id="c54" hwp:id="ref-54"><label>54.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.54" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-54"><string-name name-style="western" hwp:sortable="Motta A."><surname>Motta</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-52">Dense connectomic reconstruction in layer 4 of the somatosensory cortex</article-title>. <source hwp:id="source-53">Science</source> <volume>366</volume>, (<year>2019</year>).</citation></ref><ref id="c55" hwp:id="ref-55"><label>55.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.55" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-55"><string-name name-style="western" hwp:sortable="Scheffer L. K."><surname>Scheffer</surname>, <given-names>L. K.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-53">A connectome and analysis of the adult Drosophila central brain</article-title>. <source hwp:id="source-54">Elife</source> <volume>9</volume>, (<year>2020</year>).</citation></ref><ref id="c56" hwp:id="ref-56"><label>56.</label><citation publication-type="other" citation-type="journal" ref:id="2021.05.29.446289v3.56" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-56"><string-name name-style="western" hwp:sortable="Dorkenwald S."><surname>Dorkenwald</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="McKellar C."><surname>McKellar</surname>, <given-names>C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Macrina T."><surname>Macrina</surname>, <given-names>T.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Kemnitz N."><surname>Kemnitz</surname>, <given-names>N.</given-names></string-name> <article-title hwp:id="article-title-54">FlyWire: Online community for whole-brain connectomics</article-title>. <source hwp:id="source-55">bioRxiv</source> (<year>2020</year>).</citation></ref><ref id="c57" hwp:id="ref-57"><label>57.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.57" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-57"><string-name name-style="western" hwp:sortable="Yin W."><surname>Yin</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-55">A petascale automated imaging pipeline for mapping neuronal circuits with high-throughput transmission electron microscopy</article-title>. <source hwp:id="source-56">Nat. Commun</source>. <volume>11</volume>, <fpage>4949</fpage> (<year>2020</year>).</citation></ref><ref id="c58" hwp:id="ref-58" hwp:rev-id="xref-ref-58-1"><label>58.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.58" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-58"><string-name name-style="western" hwp:sortable="Gour A."><surname>Gour</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-56">Postnatal connectomic development of inhibition in mouse barrel cortex</article-title>. <source hwp:id="source-57">Science</source> <volume>371</volume>, (<year>2021</year>).</citation></ref><ref id="c59" hwp:id="ref-59" hwp:rev-id="xref-ref-59-1"><label>59.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.59" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-59"><string-name name-style="western" hwp:sortable="Abbott L. F."><surname>Abbott</surname>, <given-names>L. F.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-57">The mind of a mouse</article-title>. <source hwp:id="source-58">Cell</source> <volume>182</volume>, <fpage>1372</fpage>–<lpage>1376</lpage> (<year>2020</year>).</citation></ref><ref id="c60" hwp:id="ref-60" hwp:rev-id="xref-ref-60-1"><label>60.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.60" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-60"><string-name name-style="western" hwp:sortable="Witvliet D."><surname>Witvliet</surname>, <given-names>D.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-58">Connectomes across development reveal principles of brain maturation</article-title>. <source hwp:id="source-59">Nature</source> <volume>596</volume>, <fpage>257</fpage>–<lpage>261</lpage> (<year>2021</year>).</citation></ref><ref id="c61" hwp:id="ref-61" hwp:rev-id="xref-ref-61-1"><label>61.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.61" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-61"><string-name name-style="western" hwp:sortable="Seung H. S."><surname>Seung</surname>, <given-names>H. S.</given-names></string-name> <article-title hwp:id="article-title-59">Reading the book of memory: sparse sampling versus dense mapping of connectomes</article-title>. <source hwp:id="source-60">Neuron</source> <volume>62</volume>, <fpage>17</fpage>–<lpage>29</lpage> (<year>2009</year>).</citation></ref><ref id="c62" hwp:id="ref-62" hwp:rev-id="xref-ref-62-1"><label>62.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.62" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-62"><string-name name-style="western" hwp:sortable="Morgan J. L."><surname>Morgan</surname>, <given-names>J. L.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Lichtman J. W."><surname>Lichtman</surname>, <given-names>J. W.</given-names></string-name> <article-title hwp:id="article-title-60">Why not connectomics?</article-title> <source hwp:id="source-61">Nat. Methods</source> <volume>10</volume>, <fpage>494</fpage>–<lpage>500</lpage> (<year>2013</year>).</citation></ref><ref id="c63" hwp:id="ref-63" hwp:rev-id="xref-ref-63-1"><label>63.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.63" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-63"><string-name name-style="western" hwp:sortable="Fitts P. M."><surname>Fitts</surname>, <given-names>P. M.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Posner M. I."><surname>Posner</surname>, <given-names>M. I.</given-names></string-name> <source hwp:id="source-62">Human performance</source>. (<year>1967</year>).</citation></ref><ref id="c64" hwp:id="ref-64" hwp:rev-id="xref-ref-64-1"><label>64.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.64" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-64"><string-name name-style="western" hwp:sortable="Tapia J. C."><surname>Tapia</surname>, <given-names>J. C.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-61">Pervasive synaptic branch removal in the mammalian neuromuscular system at birth</article-title>. <source hwp:id="source-63">Neuron</source> <volume>74</volume>, <fpage>816</fpage>–<lpage>829</lpage> (<year>2012</year>).</citation></ref><ref id="c65" hwp:id="ref-65" hwp:rev-id="xref-ref-65-1"><label>65.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.65" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-65"><string-name name-style="western" hwp:sortable="Lichtman J. W."><surname>Lichtman</surname>, <given-names>J. W.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Colman H."><surname>Colman</surname>, <given-names>H.</given-names></string-name> <article-title hwp:id="article-title-62">Synapse elimination and indelible memory</article-title>. <source hwp:id="source-64">Neuron</source> <volume>25</volume>, <fpage>269</fpage>–<lpage>278</lpage> (<year>2000</year>).</citation></ref><ref id="c66" hwp:id="ref-66" hwp:rev-id="xref-ref-66-1"><label>66.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.66" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-66"><string-name name-style="western" hwp:sortable="Walsh M. K."><surname>Walsh</surname>, <given-names>M. K.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Lichtman J. W."><surname>Lichtman</surname>, <given-names>J. W.</given-names></string-name> <article-title hwp:id="article-title-63">In vivo time-lapse imaging of synaptic takeover associated with naturally occurring synapse elimination</article-title>. <source hwp:id="source-65">Neuron</source> vol. <volume>37</volume> <fpage>67</fpage>–<lpage>73</lpage> (<year>2003</year>).</citation></ref><ref id="c67" hwp:id="ref-67" hwp:rev-id="xref-ref-67-1"><label>67.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.67" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-67"><string-name name-style="western" hwp:sortable="Wilson A. M."><surname>Wilson</surname>, <given-names>A. M.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-64">Developmental Rewiring between Cerebellar Climbing Fibers and Purkinje Cells Begins with Positive Feedback Synapse Addition</article-title>. <source hwp:id="source-66">Cell Rep</source>. <volume>29</volume>, <fpage>2849</fpage>– <lpage>2861</lpage>.e6 (<year>2019</year>).</citation></ref><ref id="c68" hwp:id="ref-68" hwp:rev-id="xref-ref-68-1"><label>68.</label><citation publication-type="book" citation-type="book" ref:id="2021.05.29.446289v3.68" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-68"><string-name name-style="western" hwp:sortable="Sheehan D. C."><surname>Sheehan</surname>, <given-names>D. C.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Hrapchak B. B."><surname>Hrapchak</surname>, <given-names>B. B.</given-names></string-name> <source hwp:id="source-67">Theory and practice of histochemistry</source>. <publisher-name>CV Mosby</publisher-name>, <publisher-loc>St Louis</publisher-loc> (<year>1980</year>).</citation></ref><ref id="c69" hwp:id="ref-69" hwp:rev-id="xref-ref-69-1"><label>69.</label><citation publication-type="website" citation-type="web" ref:id="2021.05.29.446289v3.69" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-69"><source hwp:id="source-68">OpenCV: cv::SimpleBlobDetector Class Reference</source>. <ext-link l:rel="related" l:ref-type="uri" l:ref="https://docs.opencv.org/3.4/d0/d7a/classcv_1_1SimpleBlobDetector.html" ext-link-type="uri" xlink:href="https://docs.opencv.org/3.4/d0/d7a/classcv_1_1SimpleBlobDetector.html" hwp:id="ext-link-13">https://docs.opencv.org/3.4/d0/d7a/classcv_1_1SimpleBlobDetector.html</ext-link>.</citation></ref><ref id="c70" hwp:id="ref-70" hwp:rev-id="xref-ref-70-1"><label>70.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.70" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-70"><string-name name-style="western" hwp:sortable="Lowe D. G."><surname>Lowe</surname>, <given-names>D. G.</given-names></string-name> <article-title hwp:id="article-title-65">Distinctive image features from scale-invariant keypoints</article-title>. <source hwp:id="source-69">Int. J. Comput. Vis</source>. <volume>60</volume>, <fpage>91</fpage>–<lpage>110</lpage> (<year>2004</year>).</citation></ref><ref id="c71" hwp:id="ref-71" hwp:rev-id="xref-ref-71-1"><label>71.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.71" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-71"><string-name name-style="western" hwp:sortable="Fischler M. A."><surname>Fischler</surname>, <given-names>M. A.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Bolles R. C."><surname>Bolles</surname>, <given-names>R. C.</given-names></string-name> <article-title hwp:id="article-title-66">Random Sample Consensus: A Paradigm for Model Fitting with Applications to Image Analysis and Automated Cartography</article-title>. <source hwp:id="source-70">Readings in Computer Vision</source> <fpage>726</fpage>–<lpage>740</lpage> (<year>1987</year>) doi:<pub-id pub-id-type="doi">10.1016/b978-0-08-051581-6.50070-2</pub-id>.</citation></ref><ref id="c72" hwp:id="ref-72" hwp:rev-id="xref-ref-72-1"><label>72.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.72" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-72"><string-name name-style="western" hwp:sortable="Toldo R."><surname>Toldo</surname>, <given-names>R.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Fusiello A."><surname>Fusiello</surname>, <given-names>A.</given-names></string-name> <article-title hwp:id="article-title-67">Robust Multiple Structures Estimation with J-Linkage</article-title>. <source hwp:id="source-71">Lecture Notes in Computer Science</source> <fpage>537</fpage>–<lpage>547</lpage> (<year>2008</year>) doi:<pub-id pub-id-type="doi">10.1007/978-3-540-88682-2_41</pub-id>.</citation></ref><ref id="c73" hwp:id="ref-73" hwp:rev-id="xref-ref-73-1"><label>73.</label><citation publication-type="other" citation-type="journal" ref:id="2021.05.29.446289v3.73" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-73"><string-name name-style="western" hwp:sortable="Rublee E."><surname>Rublee</surname>, <given-names>E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rabaud V."><surname>Rabaud</surname>, <given-names>V.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Konolige K."><surname>Konolige</surname>, <given-names>K.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Bradski G."><surname>Bradski</surname>, <given-names>G.</given-names></string-name> <article-title hwp:id="article-title-68">ORB: An efficient alternative to SIFT or SURF</article-title>. <source hwp:id="source-72">2011 International Conference on Computer Vision</source> (<year>2011</year>) doi:<pub-id pub-id-type="doi">10.1109/iccv.2011.6126544</pub-id>.</citation></ref><ref id="c74" hwp:id="ref-74" hwp:rev-id="xref-ref-74-1"><label>74.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.74" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-74"><string-name name-style="western" hwp:sortable="Nealen A."><surname>Nealen</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Müller M."><surname>Müller</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Keiser R."><surname>Keiser</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Boxerman E."><surname>Boxerman</surname>, <given-names>E.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Carlson M."><surname>Carlson</surname>, <given-names>M.</given-names></string-name> <article-title hwp:id="article-title-69">Physically Based Deformable Models in Computer Graphics</article-title>. <source hwp:id="source-73">Computer Graphics Forum</source> vol. <volume>25</volume> <fpage>809</fpage>–<lpage>836</lpage> (<year>2006</year>).</citation></ref><ref id="c75" hwp:id="ref-75" hwp:rev-id="xref-ref-75-1"><label>75.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.75" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-75"><string-name name-style="western" hwp:sortable="Swope W. C."><surname>Swope</surname>, <given-names>W. C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Andersen H. C."><surname>Andersen</surname>, <given-names>H. C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Berens P. H."><surname>Berens</surname>, <given-names>P. H.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Wilson K. R."><surname>Wilson</surname>, <given-names>K. R.</given-names></string-name> <article-title hwp:id="article-title-70">A computer simulation method for the calculation of equilibrium constants for the formation of physical clusters of molecules: Application to small water clusters</article-title>. <source hwp:id="source-74">The Journal of Chemical Physics</source> vol. <volume>76</volume> <fpage>637</fpage>–<lpage>649</lpage> (<year>1982</year>).</citation></ref><ref id="c76" hwp:id="ref-76" hwp:rev-id="xref-ref-76-1 xref-ref-76-2"><label>76.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.76" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-76"><string-name name-style="western" hwp:sortable="Berger D. R."><surname>Berger</surname>, <given-names>D. R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Seung H. S."><surname>Seung</surname>, <given-names>H. S.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Lichtman J. W."><surname>Lichtman</surname>, <given-names>J. W.</given-names></string-name> <article-title hwp:id="article-title-71">VAST (Volume Annotation and Segmentation Tool): Efficient Manual and Semi-Automatic Labeling of Large 3D Image Stacks</article-title>. <source hwp:id="source-75">Front. Neural Circuits</source> <volume>12</volume>, <fpage>88</fpage> (<year>2018</year>).</citation></ref><ref id="c77" hwp:id="ref-77" hwp:rev-id="xref-ref-77-1 xref-ref-77-2"><label>77.</label><citation publication-type="other" citation-type="journal" ref:id="2021.05.29.446289v3.77" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-77"><string-name name-style="western" hwp:sortable="Sato M."><surname>Sato</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bitter I."><surname>Bitter</surname>, <given-names>I.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bender M. A."><surname>Bender</surname>, <given-names>M. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kaufman A. E."><surname>Kaufman</surname>, <given-names>A. E.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Nakajima M."><surname>Nakajima</surname>, <given-names>M.</given-names></string-name> <article-title hwp:id="article-title-72">TEASAR: tree- structure extraction algorithm for accurate and robust skeletons</article-title>. <source hwp:id="source-76">Proceedings the Eighth Pacific Conference on Computer Graphics and Applications</source> doi:<pub-id pub-id-type="doi">10.1109/pccga.2000.883951</pub-id>.</citation></ref><ref id="c78" hwp:id="ref-78" hwp:rev-id="xref-ref-78-1"><label>78.</label><citation publication-type="website" citation-type="web" ref:id="2021.05.29.446289v3.78" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-78"><collab hwp:id="collab-1">seung-lab</collab>. <source hwp:id="source-77">seung-lab/kimimaro</source>. <ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/seung-lab/kimimaro" ext-link-type="uri" xlink:href="https://github.com/seung-lab/kimimaro" hwp:id="ext-link-14">https://github.com/seung-lab/kimimaro</ext-link>.</citation></ref><ref id="c79" hwp:id="ref-79" hwp:rev-id="xref-ref-79-1 xref-ref-79-2"><label>79.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.79" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-79"><string-name name-style="western" hwp:sortable="He K."><surname>He</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zhang X."><surname>Zhang</surname>, <given-names>X.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ren S."><surname>Ren</surname>, <given-names>S.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Sun J."><surname>Sun</surname>, <given-names>J.</given-names></string-name> <article-title hwp:id="article-title-73">Deep residual learning for image recognition</article-title>. <source hwp:id="source-78">arXiv</source> preprint arXiv:1512. 03385 (<year>2015</year>).</citation></ref><ref id="c80" hwp:id="ref-80" hwp:rev-id="xref-ref-80-1"><label>80.</label><citation publication-type="other" citation-type="journal" ref:id="2021.05.29.446289v3.80" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-80">C<string-name name-style="western" hwp:sortable="hen T."><surname>hen</surname>, <given-names>T.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kornblith S."><surname>Kornblith</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Norouzi M."><surname>Norouzi</surname>, <given-names>M.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Hinton G."><surname>Hinton</surname>, <given-names>G.</given-names></string-name> <source hwp:id="source-79">A Simple Framework for Contrastive Learning of Visual Representations</source>. (2<year>020</year>).</citation></ref><ref id="c81" hwp:id="ref-81" hwp:rev-id="xref-ref-81-1"><label>81.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.81" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-81"><string-name name-style="western" hwp:sortable="McInnes L."><surname>McInnes</surname>, <given-names>L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Healy J."><surname>Healy</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Saul N."><surname>Saul</surname>, <given-names>N.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Großberger L."><surname>Großberger</surname>, <given-names>L.</given-names></string-name> <article-title hwp:id="article-title-74">UMAP: Uniform Manifold Approximation and Projection</article-title>. <source hwp:id="source-80">Journal of Open Source Software</source> vol. <volume>3</volume> <fpage>861</fpage> (<year>2018</year>).</citation></ref><ref id="c82" hwp:id="ref-82" hwp:rev-id="xref-ref-82-1"><label>82.</label><citation publication-type="other" citation-type="journal" ref:id="2021.05.29.446289v3.82" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-82"><string-name name-style="western" hwp:sortable="Çiçek Ö."><surname>Çiçek</surname>, <given-names>Ö.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Abdulkadir A."><surname>Abdulkadir</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lienkamp S. S."><surname>Lienkamp</surname>, <given-names>S. S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Brox T."><surname>Brox</surname>, <given-names>T.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Ronneberger O."><surname>Ronneberger</surname>, <given-names>O.</given-names></string-name> <article-title hwp:id="article-title-75">3D U-Net: Learning Dense Volumetric Segmentation from Sparse Annotation</article-title>. <source hwp:id="source-81">arXiv [cs.CV]</source> (<year>2016</year>).</citation></ref><ref id="c83" hwp:id="ref-83" hwp:rev-id="xref-ref-83-1"><label>83.</label><citation publication-type="book" citation-type="book" ref:id="2021.05.29.446289v3.83" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-83"><string-name name-style="western" hwp:sortable="Yuste R."><surname>Yuste</surname>, <given-names>R.</given-names></string-name> <source hwp:id="source-82">Dendritic Spines</source>. (<publisher-name>MIT Press</publisher-name>, <year>2010</year>).</citation></ref><ref id="c84" hwp:id="ref-84" hwp:rev-id="xref-ref-84-1"><label>84.</label><citation publication-type="book" citation-type="book" ref:id="2021.05.29.446289v3.84" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-84"><string-name name-style="western" hwp:sortable="Campello R. J. G. B."><surname>Campello</surname>, <given-names>R. J. G. B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Moulavi D."><surname>Moulavi</surname>, <given-names>D.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Sander J."><surname>Sander</surname>, <given-names>J.</given-names></string-name> <chapter-title>Density-Based Clustering Based on Hierarchical Density Estimates</chapter-title>. in <source hwp:id="source-83">Advances in Knowledge Discovery and Data Mining</source> <fpage>160</fpage>–<lpage>172</lpage> (<publisher-name>Springer Berlin Heidelberg</publisher-name>, <year>2013</year>).</citation></ref><ref id="c85" hwp:id="ref-85" hwp:rev-id="xref-ref-85-1"><label>85.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.05.29.446289v3.85" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-85"><string-name name-style="western" hwp:sortable="Goodman L. A."><surname>Goodman</surname>, <given-names>L. A.</given-names></string-name> <article-title hwp:id="article-title-76">On Simultaneous Confidence Intervals for Multinomial Proportions</article-title>. <source hwp:id="source-84">Technometrics</source> <volume>7</volume>, <fpage>247</fpage>–<lpage>254</lpage> (<year>1965</year>).</citation></ref></ref-list><sec hwp:id="sec-68"><title hwp:id="title-103">Supplementary Tables</title><table-wrap id="tbls1" orientation="portrait" position="float" hwp:id="T1" hwp:rev-id="xref-table-wrap-1-1 xref-table-wrap-1-2 xref-table-wrap-1-3 xref-table-wrap-1-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/TBLS1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">tbls1</object-id><label>Supplementary Table 1.</label><caption hwp:id="caption-33"><title hwp:id="title-104">Imaging metrics</title><p hwp:id="p-200">See <underline>h01_imaging_metrics.csv</underline></p></caption></table-wrap><table-wrap id="tbls2" orientation="portrait" position="float" hwp:id="T2" hwp:rev-id="xref-table-wrap-2-1 xref-table-wrap-2-2 xref-table-wrap-2-3 xref-table-wrap-2-4 xref-table-wrap-2-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/TBLS2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T2</object-id><object-id pub-id-type="publisher-id">tbls2</object-id><label>Supplementary Table 2.</label><caption hwp:id="caption-34"><title hwp:id="title-105">Agglomeration graph edge selection criteria by agglomeration stage.</title><p hwp:id="p-201">The criteria are: strict = ((dA ≤ 0.02 ∨ dB ≤ 0.02) ∧ (f** ≥ 0.6 ∧ JAB ≥ 0.8)), relaxed = strict ∨ (f** ≥ 0.9 ∧ JAB ≥ 0.9). Ensemble criteria refer to the number of alternative segmentations contributing a given (A, B) Candidate edge. Endpoint size criteria refer to object sizes in the base segmentation. The endpoint criterion excluded all segment pairs for which skeleton endpoints for both segments in the pair were not present within a 500 nm of the pair center. Geometric criteria excluded points for which y &lt; 181053 + (276044 - 181053) * ((x - 104865) / (204645 - 104865)) (white matter, only applied when the 8 nm FFN model was used), (x - (328769 + (z - 1919) / (5251 - 1919) * (343919 - 328769))2 + (y - (75082 + (z - 1919) / (5251 - 1919) * (65206 - 75082))2 &gt;= 37452 (fissure), or (x - (338167 + (z - 1904) / (5286 - 1904) * (339636 - 338167))2 + (y - (138052 + (z - 1904) / (5286 - 1904) * (142197 - 138052))2 &gt;= 17592 (fissure).</p></caption><graphic xlink:href="446289v4_tbls2" position="float" orientation="portrait" hwp:id="graphic-33"/></table-wrap><table-wrap id="tbls3" orientation="portrait" position="float" hwp:id="T3" hwp:rev-id="xref-table-wrap-3-1 xref-table-wrap-3-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/TBLS3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T3</object-id><object-id pub-id-type="publisher-id">tbls3</object-id><label>Supplementary Table 3.</label><caption hwp:id="caption-35"><title hwp:id="title-106">Manual counts of all cells in H01, Phase 1 &amp; 2</title></caption><graphic xlink:href="446289v4_tbls3" position="float" orientation="portrait" hwp:id="graphic-34"/></table-wrap><table-wrap id="tbls4" orientation="portrait" position="float" hwp:id="T4" hwp:rev-id="xref-table-wrap-4-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/TBLS4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T4</object-id><object-id pub-id-type="publisher-id">tbls4</object-id><label>Supplementary Table 4.</label><caption hwp:id="caption-36"><title hwp:id="title-107">Basal dendrite branch identification performance</title></caption><graphic xlink:href="446289v4_tbls4" position="float" orientation="portrait" hwp:id="graphic-35"/><graphic xlink:href="446289v4_tbls4a" position="float" orientation="portrait" hwp:id="graphic-36"/></table-wrap><table-wrap id="tbls5" orientation="portrait" position="float" hwp:id="T5" hwp:rev-id="xref-table-wrap-5-1 xref-table-wrap-5-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/TBLS5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T5</object-id><object-id pub-id-type="publisher-id">tbls5</object-id><label>Supplementary Table 5.</label><caption hwp:id="caption-37"><title hwp:id="title-108">Summary of Machine Learning-identified connections</title><p hwp:id="p-202">Pre- and post-synaptic cell type (E or I) and Layer (L) are indicated in row and column headings, respectively. Each cell contains the total number of connections (t), number manually checked (c), the percentage of those checked that are valid, and the most common layer for the connection to occur in (L), for that connection type.</p></caption><graphic xlink:href="446289v4_tbls5" position="float" orientation="portrait" hwp:id="graphic-37"/></table-wrap><table-wrap id="tbls6" orientation="portrait" position="float" hwp:id="T6" hwp:rev-id="xref-table-wrap-6-1 xref-table-wrap-6-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/TBLS6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T6</object-id><object-id pub-id-type="publisher-id">tbls6</object-id><label>Supplementary Table 6.</label><caption hwp:id="caption-38"><title hwp:id="title-109">Summary of manually-identified connections</title><p hwp:id="p-203">Rows indicate pre-synaptic neuron types and columns indicate post-synaptic neuron types. L numbers indicate layer membership of cell and E and I indicate excitatory and inhibitory cell types, respectively. Counts indicate numbers of connections between the pre-synaptic type indicated by the row and the post-synaptic type indicated by the column, where one connection consists of all of the synapses between two individual neurons</p></caption><graphic xlink:href="446289v4_tbls6" position="float" orientation="portrait" hwp:id="graphic-38"/></table-wrap><table-wrap id="tbls7" orientation="portrait" position="float" hwp:id="T7" hwp:rev-id="xref-table-wrap-7-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/TBLS7</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T7</object-id><object-id pub-id-type="publisher-id">tbls7</object-id><label>Supplementary Table 7.</label><caption hwp:id="caption-39"><title hwp:id="title-110">Excitatory and inhibitory synapse classification accuracy</title><p hwp:id="p-204">Columns indicate cortical layers in which synapses were formed. E and I refer to excitatory and inhibitory, respectively.</p></caption><graphic xlink:href="446289v4_tbls7" position="float" orientation="portrait" hwp:id="graphic-39"/></table-wrap><table-wrap id="tbls8" orientation="portrait" position="float" hwp:id="T8"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/TBLS8</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T8</object-id><object-id pub-id-type="publisher-id">tbls8</object-id><label>Supplementary Table 8.</label><caption hwp:id="caption-40"><title hwp:id="title-111">Estimated number of cells per cubic millimeter for different layers</title><p hwp:id="p-205">These are the values of the plot shown in <xref ref-type="fig" rid="figs5" hwp:id="xref-fig-11-7" hwp:rel-id="F11">Supplementary Figure 5A</xref>.</p></caption><graphic xlink:href="446289v4_tbls8" position="float" orientation="portrait" hwp:id="graphic-40"/></table-wrap><table-wrap id="tbls9" orientation="portrait" position="float" hwp:id="T9" hwp:rev-id="xref-table-wrap-9-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/TBLS9</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T9</object-id><object-id pub-id-type="publisher-id">tbls9</object-id><label>Supplementary Table 9.</label><caption hwp:id="caption-41"><title hwp:id="title-112">Estimated volume occupancy percentages for different layers</title><p hwp:id="p-206">These are the values of the plot shown in <xref ref-type="fig" rid="figs22" hwp:id="xref-fig-28-2" hwp:rel-id="F28">Supplementary Figure 22B</xref>.</p></caption><graphic xlink:href="446289v4_tbls9" position="float" orientation="portrait" hwp:id="graphic-41"/></table-wrap><table-wrap id="tbls10" orientation="portrait" position="float" hwp:id="T10" hwp:rev-id="xref-table-wrap-10-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.05.29.446289v3/TBLS10</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T10</object-id><object-id pub-id-type="publisher-id">tbls10</object-id><label>Supplementary Table 10.</label><caption hwp:id="caption-42"><title hwp:id="title-113">Estimated synapse densities for different layers</title><p hwp:id="p-207">These are the values of the plot shown in <xref ref-type="fig" rid="figs26" hwp:id="xref-fig-32-2" hwp:rel-id="F32">Supplementary Figure 26A</xref>.</p></caption><graphic xlink:href="446289v4_tbls10" position="float" orientation="portrait" hwp:id="graphic-42"/></table-wrap></sec></back></article>
