<article xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><issn pub-type="ppub"/><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="manuscript">BIORXIV/2021/466943</article-id><article-id pub-id-type="doi">10.1101/2021.11.19.466943</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.11.19.466943v1</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;2021.11.19.466943</article-id><article-id pub-id-type="other" hwp:sub-type="slug">2021.11.19.466943</article-id><article-id pub-id-type="other" hwp:sub-type="atom-slug">2021.11.19.466943</article-id><article-id pub-id-type="other" hwp:sub-type="tag">2021.11.19.466943</article-id><article-version>1.1</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Neuroscience" hwp:journal="biorxiv"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">Beyond gradients: Noise correlations control Hebbian plasticity to shape credit assignment</article-title></title-group><aff id="aff1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2">
				<label/> Brown University
			</aff><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1">
					<label>*</label> Corresponding author; email: <email xlink:type="simple" hwp:id="email-1">dnscott87@gmail.com</email>
				</corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" corresp="yes" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-6128-1721</contrib-id><name name-style="western" hwp:sortable="Scott Daniel Nelson"><surname>Scott</surname><given-names>Daniel Nelson</given-names></name><xref ref-type="aff" rid="aff1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1"/><xref ref-type="fn" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">1</xref><email hwp:id="email-2">dnscott87@gmail.com</email><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0001-6128-1721"/></contrib><contrib contrib-type="author" hwp:id="contrib-2"><name name-style="western" hwp:sortable="Frank Michael J"><surname>Frank</surname><given-names>Michael J</given-names></name><xref ref-type="aff" rid="aff1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1"/></contrib></contrib-group><pub-date pub-type="epub-original" date-type="pub" publication-format="electronic" hwp:start="2021"><year>2021</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2021-11-20T14:39:12-08:00">
    <day>20</day><month>11</month><year>2021</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2021-11-20T14:39:12-08:00">
    <day>20</day><month>11</month><year>2021</year>
  </pub-date><elocation-id>2021.11.19.466943</elocation-id><history hwp:id="history-1">
				<date date-type="received" hwp:start="2021-11-19"><day>19</day><month>11</month><year>2021</year></date>
			<date date-type="rev-recd" hwp:start="2021-11-19"><day>19</day><month>11</month><year>2021</year></date>
				<date date-type="accepted" hwp:start="2021-11-20"><day>20</day><month>11</month><year>2021</year></date>
			</history><permissions><copyright-statement hwp:id="copyright-statement-1">Â© 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2021</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="license-1"><p hwp:id="p-1">This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by-nc-nd/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></p></license></permissions><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2021/pdf/2021.11.19.466943v1.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="466943.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2021/abstracts/2021.11.19.466943v1/2021.11.19.466943v1.htslp"/><abstract hwp:id="abstract-1"><p hwp:id="p-2">Two key problems that span biological and industrial neural network research are how networks can be trained to generalize well and to minimize destructive interference between tasks. Both hinge on credit assignment, the targeting of specific network weights for change. In artificial networks, credit assignment is typically governed by gradient descent. Biological learning is thus often analyzed as a means to approximate gradients. We take the complementary perspective that biological learning rules likely confer advantages when they aren't gradient approximations. Further, we hypothesized that noise correlations, often considered detrimental, could usefully shape this learning. Indeed, we show that noise and three-factor plasticity interact to compute directional derivatives of reward, which can improve generalization, robustness to interference, and multi-task learning. This interaction also provides a method for routing learning quasi-independently of activity and connectivity, and demonstrates how biologically inspired inductive biases can be fruitfully embedded in learning algorithms.</p></abstract></article-meta><notes hwp:id="notes-1"><notes notes-type="competing-interest-statement" hwp:id="notes-2"><title hwp:id="title-1">Competing Interest Statement</title><p hwp:id="p-3">The authors have declared no competing interest.</p></notes></notes></front></article>
