<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/220319</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;220319v1</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;220319</article-id><article-id pub-id-type="other" hwp:sub-type="slug">220319</article-id><article-id pub-id-type="other" hwp:sub-type="tag">220319</article-id><article-version>1.1</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Neuroscience" hwp:journal="biorxiv"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">Suboptimal eye movements for seeing fine details</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1">
<label>*</label>corresponding author, lead contact: <email hwp:id="email-1">mnagaoglu@gmail.com</email></corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" corresp="yes" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-7937-3250</contrib-id><name name-style="western" hwp:sortable="Ağaoğlu Mehmet N."><surname>Ağaoğlu</surname><given-names>Mehmet N.</given-names></name><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-7937-3250"/></contrib><contrib contrib-type="author" hwp:id="contrib-2"><name name-style="western" hwp:sortable="Sheehy Christy K."><surname>Sheehy</surname><given-names>Christy K.</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-1" hwp:rel-id="aff-3">3</xref></contrib><contrib contrib-type="author" hwp:id="contrib-3"><name name-style="western" hwp:sortable="Tiruveedhula Pavan"><surname>Tiruveedhula</surname><given-names>Pavan</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref></contrib><contrib contrib-type="author" hwp:id="contrib-4"><name name-style="western" hwp:sortable="Roorda Austin"><surname>Roorda</surname><given-names>Austin</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref></contrib><contrib contrib-type="author" hwp:id="contrib-5"><name name-style="western" hwp:sortable="Chung Susana T.L."><surname>Chung</surname><given-names>Susana T.L.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-3" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-2" hwp:rel-id="aff-2">2</xref></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2 xref-aff-1-3"><label>1</label><institution hwp:id="institution-1">School of Optometry, University of California</institution>, Berkeley</aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1 xref-aff-2-2"><label>2</label><institution hwp:id="institution-2">Vision Science Graduate Group, University of California</institution>, Berkeley</aff><aff id="a3" hwp:id="aff-3" hwp:rev-id="xref-aff-3-1"><label>3</label><institution hwp:id="institution-3">Department of Neurology, University of California</institution>, San Francisco</aff></contrib-group><pub-date pub-type="epub-original" hwp:start="2017"><year>2017</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2017-11-16T01:15:13-08:00">
    <day>16</day><month>11</month><year>2017</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2017-11-16T01:15:13-08:00">
    <day>16</day><month>11</month><year>2017</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2017-11-16T01:20:48-08:00">
    <day>16</day><month>11</month><year>2017</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2017-11-16T01:20:48-08:00">
    <day>16</day><month>11</month><year>2017</year>
  </pub-date><elocation-id>220319</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2017-11-15"><day>15</day><month>11</month><year>2017</year></date>
<date date-type="rev-recd" hwp:start="2017-11-15"><day>15</day><month>11</month><year>2017</year></date>
<date date-type="accepted" hwp:start="2017-11-16"><day>16</day><month>11</month><year>2017</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2017</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="license-1"><p hwp:id="p-1">This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by-nc-nd/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></p></license></permissions><self-uri xlink:href="220319.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2019/pdf/220319v1.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="220319.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2019/abstracts/220319v1/220319v1.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2019/fulltext/220319v1/220319v1.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-2">Human eyes are never stable, even during attempts of maintaining gaze on a visual target. Considering transient response characteristics of retinal ganglion cells, a certain amount of motion of the eyes is required to efficiently encode information and to prevent neural adaptation. However, excessive motion of the eyes leads to insufficient exposure to the stimuli which creates blur and reduces visual acuity. Normal miniature eye movements fall in between these extremes but it is unclear if they are optimally tuned for seeing fine spatial details. We used a state-of-the-art retinal imaging technique with eye tracking to address this question. We sought to determine the optimal gain (stimulus/eye motion ratio) that corresponds to maximum performance in an orientation discrimination task performed at the fovea. We found that miniature eye movements are tuned, but may not be optimal, for seeing fine spatial details.</p></abstract><counts><page-count count="22"/></counts><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-1">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta></front><body><p hwp:id="p-3">We make large, rapid, voluntary eye movements – saccades, to redirect our gaze to accomplish numerous visual tasks (e.g., searching for an object, reading a book, etc.). This is to form a fine-grained representation of the external world by taking advantage of a part of the retina – the fovea, which has the highest spatial resolution. However, our eyes are always in motion between epochs of saccades, even when we try to maintain our gaze on an object. Miniature eye movements that we make during fixation are often referred to as fixational eye movements (FEM). Different types of FEM have been identified depending on their spatiotemporal characteristics(<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">1</xref>,<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">2</xref>). Microsaccades are small jerky eye movements, and share similar peak velocity-amplitude dynamics as larger saccades (<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">3</xref>). Drifts are relatively slower and smoother but rather erratic eye movements that occur between (micro) saccades, and have been usually modeled as various types of random walk or Brownian motion(<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">4</xref>–<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">6</xref>). Lastly, tremors are usually defined as very low-amplitude and high-frequency oscillatory movements that are superimposed on drifts(<xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">7</xref>–<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">9</xref>).</p><p hwp:id="p-4">In addition to the non-uniform distribution of density and size of receptive fields of ganglion cells across the retina(<xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">10</xref>–<xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">12</xref>), there is another unique property that differentiates our visual system from a computer vision system – neural adaptation. For instance, retinal ganglion cells (RGC) are most responsive to light transients and their responses decay with prolonged exposure(<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">13</xref>,<xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">14</xref>). Although such a system is ideal for the detection of changes or movements that are crucial for survival in a natural setting, it comes with a consequence. It has been known that in the absence of FEM, visual perception fades away, and more so for small visual stimuli(<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">15</xref>–<xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">17</xref>). This suggests that retinal image motion is essential for continuous and high-acuity vision. However, if FEM are too large or too fast, the light intensity defining a visual stimulus will spread over a large population of cells each with an insufficient exposure to the stimulus, resulting in nothing but smeared, ghost-like impressions. Therefore, there must be an optimum movement between these two extremes whereby visual perception is maximized such that the ability to perform a visual task is highest at that particular movement.</p><p hwp:id="p-5">Previous research showed that naturally occurring or artificially induced irregular and continuous retinal image drifts help in seeing fine spatial details(<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">6</xref>,<xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">18</xref>). Likewise, naturally occurring microsaccades or sudden jumps of stimuli are known to counteract visual fading(<xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">19</xref>,<xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">20</xref>), and help redirect our gaze to compensate for the non-homogeneous acuity within the fovea(<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">21</xref>). If there is a causal relationship between FEM and visual perception, the latter should show a “tuning” function with different levels of the former, analogous to orientation tuning of cells in the early visual areas where firing rate of a given cell is continuously modulated by how close the orientation of a stimulus in its receptive field to its “preferred orientation.” In other words, direct manipulation of FEM, or the way retinal image moves as a function of FEM should result in systematic changes in visual perception, where maximum performance in a visual task would be obtained at the preferred or optimal FEM. From an evolutionary point of view, FEM in normal vision can be thought as optimally tuned for seeing fine details at the fovea. Here, we explicitly tested this hypothesis. Our results show that normal FEM are tuned, but not quite optimal, for fine discrimination at the fovea. We also found that within the range of spatial frequencies where the human visual system has highest contrast sensitivity, this relationship disappears suggesting a higher tolerance for retinal image motion for coarse visual structures.</p><sec id="s1" hwp:id="sec-1"><title hwp:id="title-2">Results</title><p hwp:id="p-6">Using a tracking scanning laser ophthalmoscope (TSLO)(<xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">22</xref>), we presented seven human subjects with a high spatial frequency grating (12 cpd) for 900 ms while imaging their retina and tracking their eye movements in real time (<bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Fig. 1a, b</xref></bold>). We systematically manipulated the way retinal image motion and the actual FEM are related. The motion of the stimulus on the scanning raster was a function of the estimated eye motion times a <italic toggle="yes">gain</italic> factor (<bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Fig. 1d</xref></bold>). A gain of 0 means that the stimulus position remained fixed relative to the raster but slipped across the retina based on natural FEM. A gain of 1 means that the stimulus was stabilized on the retina, i.e., the retinal image motion due to FEM was completely cancelled out. A gain of 0.5 refers to partial stabilization, i.e., the stimulus moved only half as much as the eye motion. Assuming similar oculomotor behavior under different gains, a gain of -1 doubles the retinal slip of the stimulus compared to that under natural viewing (i.e., gain = 0), and a gain of 2 results in the same retinal slip but in the opposite direction of what would occur under natural viewing. Offline analyses of retinal videos for eye movement extraction revealed that eye tracking and stimulus delivery were performed with near-perfect accuracy (~99%) for complete retinal stabilization (gain = 1). For gain conditions other than 0 and 1, there was some trial-to-trial variability in accuracy of stimulus delivery (<bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-3" hwp:rel-id="F1">Fig. 1e, f</xref></bold>). Nevertheless, each gain condition resulted in a statistically distinct distribution of effective gains centered at the desired gain (<bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-4" hwp:rel-id="F1">Fig. 1e, f</xref></bold>). We measured subjects’ ability to discriminate the direction of the grating’s orientation from vertical under different gain conditions. If FEM are not tuned for fine discrimination at the fovea, then performance should not depend on gain (the null hypothesis, <bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-5" hwp:rel-id="F1">Fig. 1c</xref></bold>). On the other hand, if the retinal image motion due to FEM is tightly tuned for fine discrimination, performance should manifest a non-monotonic relationship with gain, where a particular value of gain results in the best (or worst) performance (<bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-6" hwp:rel-id="F1">Fig. 1c</xref></bold>). The tuning hypothesis can hold true in various ways. If FEM are optimal for fine discrimination at the fovea, then visual performance should peak at the gain of 0. Alternatively, retinal image motion might be the primary determinant of visual performance. If retinal image motion is always detrimental for seeing, visual performance should be highest at the gain of 1. Retinal motion might also be beneficial regardless of the underlying FEM. If that is the case, the lowest discrimination performance should occur when the stimulus is fully stabilized on the retina.</p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2 xref-fig-1-3 xref-fig-1-4 xref-fig-1-5 xref-fig-1-6 xref-fig-1-7 xref-fig-1-8 xref-fig-1-9 xref-fig-1-10 xref-fig-1-11 xref-fig-1-12"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;220319v1/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1</label><caption hwp:id="caption-1"><p hwp:id="p-7">Manipulating the relationship between retinal image motion and eye motion with the TSLO. <bold>(a)</bold> An orientation discrimination task at the fovea. Subjects’ view of a grating on the raster (left), and corresponding retinal image (right). Note that the stimulus is imprinted on the retinal image. <bold>(b)</bold> The luminance profile used to create grating patterns on the raster. The mean luminance of the grating was set to ~70% of the background and the contrast of grating was adjusted for each subject. <bold>(c)</bold> Predictions from the no tuning (null) and tuning hypotheses. The panels with blue and red outlines show various ways tuning can occur. <bold>(d)</bold> Sample eye motion and retinal image motion traces (black lines) and corresponding probability densities (red clouds) for different gains. The horizontal and vertical lines in the lower left corner of each panel represent 0.1°. Dimensions were adjusted for clarity. <bold>(e)</bold> Retinal ISOA as a function of eye ISOA across gains in Experiment 1. Different colors represent different gains, and subjects are coded by different symbols. Inset shows a close-up view of data for smallest retinal/eye motion. <bold>(f)</bold> The distribution of retinal/eye ISOA ratios for different gains, averaged across seven subjects. Vertical dotted lines show theoretical ISOA ratios, i.e., assuming that eye tracking, stimulus delivery, and offline eye movement extraction were perfect. Error bars represent ±SEM (n=7). Color conventions for gains are identical across all figures.</p></caption><graphic xlink:href="220319_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-8">We found that orientation discrimination performance is tuned to gain (<bold><xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Fig. 2a, b</xref></bold>). Averaged across subjects, the peak performance occurred at a gain of 0.43 (95% confidence intervals: 0.12, 0.74), suggesting that partially reducing the effects of FEM is actually helpful in seeing fine spatial details. Results were similar when data from each subject were fitted separately (polynomial: t<sub>6</sub>=3.165, p=0.019; Gaussian: t<sub>6</sub>=2.600, p=0.041) (<bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-7" hwp:rel-id="F1">Fig. 1b</xref></bold> and <bold><xref ref-type="fig" rid="figS1" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Figure S1</xref></bold>). The exact choice of the tuning model (a quadratic polynomial or a Gaussian) did not matter (paired t-test: ti2=3.165, p=0.019). Bootstrapping tuning curve fits to binary data (correct vs incorrect) also revealed no optimality in six of the seven subjects (<bold><xref ref-type="fig" rid="figS1" hwp:id="xref-fig-5-2" hwp:rel-id="F5">Figure S1</xref></bold>). These results suggest that FEM are tuned but not optimal for fine discrimination at the fovea, at least within the range of parameters investigated here.</p><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3 xref-fig-2-4 xref-fig-2-5 xref-fig-2-6 xref-fig-2-7 xref-fig-2-8 xref-fig-2-9 xref-fig-2-10"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;220319v1/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2</label><caption hwp:id="caption-2"><p hwp:id="p-9">FEM are tuned, but not optimal, for fine discrimination at the fovea. <bold>(a)</bold> Proportion correct as a function of gain, averaged across subjects, in Experiment 1. A Gaussian tuning function was fit to all data (black curve) to estimate the optimum gain. Vertical white line represents optimal gain defined as the gain corresponding to the peak of the Gaussian. Shaded regions represent 95% confidence intervals of the optimum gain. <bold>(b)</bold> (Top) Average optimal gains based on individual tuning function fits along with individual optimal gains. A guadratic polynomial and a Gaussian tuning function resulted in statistically indistinguishable optimal gains. (Bottom) To compare the “no tuning” and “tuning” hypotheses in terms of how well they can explain our data, we computed Adjusted R<sup>2</sup> metric for the constant model and tuning models (a guadratic polynomial or a Gaussian), respectively. For all subjects, tuning models performed better. <bold>(c)</bold> (Top-right) the distribution of preferred retinal locus (PRL) across trials for one representative subject. Each symbol represents one trial. (Bottom-left) A close-up view of the central “2.5° part of the retina. Note the systematic change in PRLs across gains. <bold>(d, e)</bold> Retinal image motion and eye motion ISO A as a function of gain. <bold>(f, g)</bold> Microsaccade rates and PRL eccentricity across gains. Optimal gain and confidence intervals in (a) are replotted in (d, e, f, and g). Error bars represent ±SEM (n=7).</p></caption><graphic xlink:href="220319_fig2" position="float" orientation="portrait" hwp:id="graphic-2"/></fig><p hwp:id="p-10">In order to check whether or not the tuning between performance and gain is limited only to fine discrimination tasks, we repeated the experiment with a spatial frequency (3 cpd) at which the human visual system has highest contrast sensitivity for static displays(<xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">23</xref>). The hypothesis was that the retinal jitter due to FEM causes much less modulations in retinal ganglion cells with low spatial frequency stimuli, therefore, gain manipulations should result in minimal or no change in performance. We found no effect of gain on performance (<bold><xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Fig. 3a</xref></bold>), despite the retinal image motion varied over two log units across conditions (<bold><xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Fig. 3d</xref></bold>). Different performance trends with gain in Experiments 1 and 2 cannot be explained by differences in retinal motion, eye motion, microsaccade rate, or PRL eccentricity (<bold><xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Fig. 2d-g</xref></bold> vs <bold><xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Fig. 3d-g</xref></bold>).</p><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3 xref-fig-3-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;220319v1/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3</label><caption hwp:id="caption-3"><p hwp:id="p-11">FEM are not tuned for coarse discrimination at the fovea. <bold>(a)</bold> Proportion correct as a function of gain in Experiment 2. <bold>(b)</bold> Average optimal gains based on individual tuning function fits along with individual optimal gains. <bold>(c)</bold> The distribution of retinal/eye motion ISOA in Experiment 2. <bold>(d, e)</bold> Retinal image motion and eye motion ISOA as a function of gain. <bold>(f, g)</bold> Microsaccade rates and PRL eccentricity across gains. Optimal gain and confidence intervals in (a) are replotted in (d, e, f, and g). Error bars represent ±SEM (n=7). Conventions are as in <bold><xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Figure 2</xref>.</bold></p></caption><graphic xlink:href="220319_fig3" position="float" orientation="portrait" hwp:id="graphic-3"/></fig><p hwp:id="p-12">Next, we sought to determine what drives the strong dependency between performance and gain with high spatial frequency gratings. If gain manipulation only modulates the retinal image motion, then the answer would simply be retinal image motion, assuming no interference from extra-retinal mechanisms. The approach taken in most retinal stabilization studies in the literature implicitly assumes that gain manipulation only results in changes in retinal image motion. In other words, retinal image motion is considered as the one and only mediator of performance. However, we found that gain modulates multiple mediators. We computed two-dimensional probability density of stimulus locations on the retina and eye positions on the raster (e.g., <bold><xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-4" hwp:rel-id="F2">Fig. 2d</xref></bold>), and quantified, on a trial-by-trial basis, the extent of retinal image motion and eye motion by the isoline area (ISOA) containing roughly 68% of the retinal/eye motion traces (<bold><xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-5" hwp:rel-id="F2">Fig. 2d</xref></bold>, <xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-6" hwp:rel-id="F2"><bold>e</bold></xref> and <bold><xref ref-type="fig" rid="figS1" hwp:id="xref-fig-5-3" hwp:rel-id="F5">Figure S1</xref></bold>). As expected, the minimum retinal ISOA occurred when the stimulus was stabilized on the retina (i.e., gain = 1) but the pattern of changes in retinal ISOA as a function of gain revealed an asymmetric “V” shape around the gain of 1 (<bold><xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-7" hwp:rel-id="F2">Fig. 2d</xref></bold>). This asymmetry can be explained by differences in oculomotor behavior of subjects across different gains. More specifically, consistent with previous literature(<xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">24</xref>), subjects made smooth pursuit-like eye movements for gains of 1 and larger, which resulted in larger eye ISOAs (<bold><xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-8" hwp:rel-id="F2">Fig. 2e</xref></bold>). This change in behavior occurred as soon as the retinal slip is no longer in a direction that is consistent with eye motion, in line with recent perceptual observations(<xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">25</xref>). In addition, subjects made slightly more microsaccades for negative gains where retinal image motion is amplified (<bold><xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-9" hwp:rel-id="F2">Fig. 2f</xref></bold> and <bold><xref ref-type="fig" rid="figS1" hwp:id="xref-fig-5-4" hwp:rel-id="F5">Figure S1</xref></bold>). In addition, although each trial started with a fixation cross at the center of the raster, the preferred retinal locus (PRL) during grating presentation, defined here as the retinal location corresponding to peak probability density of retinal stimulus locations, also changed with gain (<bold><xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-10" hwp:rel-id="F2">Fig. 2c, f, g</xref></bold> and <bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-8" hwp:rel-id="F1">Figure S1</xref></bold>). To determine what really drives the relationship between gain and performance, one must take these mediators into account. In a regression-based mediation analysis following the most commonly used four-step approach(<xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">26</xref>), we found that (i) gain has a significant effect on performance, (ii) gain significantly modulated all four mediators (retinal ISOA, eye ISOA, microsaccade rate, and PRL eccentricity), (iii) all mediators individually, with the exception of microsaccade rate, are significant predictors of performance, (iv) gain remains a significant predictor of performance even when the effects of all significant mediators are taken into account (<bold><xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Fig. 4</xref></bold>). In order to determine whether or not mediators can account for the data as well as gain by itself, we performed a series of linear-mixed effects regression analyses (<bold><xref ref-type="fig" rid="figS4" hwp:id="xref-fig-8-1" hwp:rel-id="F8">Figure S4</xref>).</bold> In terms of explained variance and log-likelihood, where number of factors is not penalized, several purely mediator-based models could surpass the models based on gain only, suggesting that mediators identified here might fully account for how gain modulates performance. However, as the Bayes Information Criterion (BIC) differences show, none of the mediator-based models could outperform the simple model that is based only on gain. Through additional regression analyses and model comparisons using BIC, we confirmed that performance cannot be fully accounted by mediators alone (<bold><xref ref-type="fig" rid="figS4" hwp:id="xref-fig-8-2" hwp:rel-id="F8">Figure S4</xref>).</bold></p><fig id="fig4" position="float" fig-type="figure" orientation="portrait" hwp:id="F4" hwp:rev-id="xref-fig-4-1 xref-fig-4-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;220319v1/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4</label><caption hwp:id="caption-4"><p hwp:id="p-13">Teasing apart contributions of different mediators. <bold>(a)</bold> The first step in mediation analysis is to establish a significant relationship between gain (G) and proportion correct (PC). Since the tuning hypothesis predicts a guadratic relationship between G and PC, we included the G<sup>2</sup> in our regression analyses. <bold>(b)</bold> Second, whether or not gain is a significant predictor of each covarying factor (Ret: retinal ISO A, Eye: eye ISO A, PRL: PRL eccentricity, MR: microsaccade rate) is established. <bold>(c)</bold> The third step tests separately for a significant effect each mediator on performance. <bold>(d)</bold> Finally, gain and mediators with a significant correlation on performance are used to explain performance. Red and blue colors represent statistically significant negative and positive effects whereas gray lines represent insignificant relationships. The final model in <bold>(d)</bold> shows that even when all significant mediators are taken into account, gain still has a significant effect on performance. <bold>(e)</bold> When all mediators are included, regardless of the outcome of <bold>(c)</bold>, gain remains to be a significant factor. Thickness of each line represent the absolute value of the standardized effect size.</p></caption><graphic xlink:href="220319_fig4" position="float" orientation="portrait" hwp:id="graphic-4"/></fig></sec><sec id="s2" hwp:id="sec-2"><title hwp:id="title-3">Discussion</title><p hwp:id="p-14">“Tuning” refers to a relationship between an independent variable and an outcome measure, where a certain level of the former is more preferable than others. Optimality in this context refers to achieving the best possible outcome in the face of several antagonist factors. Throughout the vast literature on FEM and visual perception, the word “optimal” has been used quite liberally in regard to spatiotemporal properties of FEM(<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-2" hwp:rel-id="ref-1">1</xref>,<xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-1" hwp:rel-id="ref-27">27</xref>–<xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">32</xref>) although there has never been an explicit test for addressing it. Here, we tested whether visual performance in a fine orientation discrimination task would show tuning as a function of the relationship between the retinal image motion and actual eye movements. We found strong tuning for a fine-detail discrimination task (Experiment 1) but not for a coarse discrimination task (Experiment 2). The absence of tuning in Experiment 2, despite up to a two log-unit change in retinal motion across conditions, suggests a very high tolerance for motion. Surprisingly, the optimal gain in Experiment 1 was obtained at a gain value between 0 and 1, suggesting that partially compensating for FEM can be beneficial.</p><p hwp:id="p-15">Our results might seem inconsistent with previous reports where complete retinal stabilization resulted in impaired discrimination performance(<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-3" hwp:rel-id="ref-6">6</xref>,<xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-2" hwp:rel-id="ref-18">18</xref>). A simple interpolation between the two extremes suggests a monotonie impairment in visual performance with better compensation for FEM. This apparent inconsistency may not be real. First, it is technically possible to get impaired performance with complete stabilization <italic toggle="yes">and</italic> a nonzero optimal gain at the same time (which was the case for five out of seven subjects, <bold><xref ref-type="fig" rid="figS1" hwp:id="xref-fig-5-5" hwp:rel-id="F5">Figure S1</xref></bold>). Second, none of the existing studies explored the range of gains used here for discrimination tasks at the fovea. In addition, in previous studies, fading that resulted from retinal stabilization was quantified by threshold elevations, but the degree to which fading occurs depends on many variables such as stimulus duration, size, contrast, eccentricity, equipment used, etc.(<xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">16</xref>,<xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">33</xref>–<xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">36</xref>). Early studies on retinal stabilization used small stimuli extending only a few arcmin, and was closely surrounded by other visual cues coming from the apparatus (<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">8</xref>,<xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-2" hwp:rel-id="ref-16">16</xref>,<xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-2" hwp:rel-id="ref-17">17</xref>). More recent studies used foveally presented gratings extending several degrees of visual angle far from display boundaries(<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-4" hwp:rel-id="ref-6">6</xref>,<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-2" hwp:rel-id="ref-21">21</xref>), or parafoveally presented diffraction-limited stimuli covering only a few cones within a visible raster covering 1-1.3 deg(<xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-3" hwp:rel-id="ref-18">18</xref>). The paradigm used here was somewhere in between; we presented through natural optics of the eye a grating that covers the fovea and is situated within a visible raster covering 10 deg. Therefore, it is possible to make qualitative comparisons across aforementioned studies, however, it is not feasible to extrapolate previous studies to the conditions investigated here.</p><p hwp:id="p-16">Our results are highly consistent with recent theoretical work that has been successfully used to account for performance impairment due to retinal stabilization(<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">5</xref>,<xref ref-type="bibr" rid="c37" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">37</xref>,<xref ref-type="bibr" rid="c38" hwp:id="xref-ref-38-1" hwp:rel-id="ref-38">38</xref>). According to this framework, there are two distinct mechanisms that work in tandem, one for estimating FEM from RGC responses across the retina which negates the need for an extra-retinal mechanism to properly decode spatial information, and another one for making an <italic toggle="yes">optimal</italic> inference about the spatial layout of the stimuli. The presence of a global motion compensation mechanism for FEM was demonstrated by a striking visual illusion(<xref ref-type="bibr" rid="c39" hwp:id="xref-ref-39-1" hwp:rel-id="ref-39">39</xref>). Surprisingly, when receptive field size and density across the retina and the statistics of FEM under normal viewing conditions are factored in, this model predicted that normal human FEM are not optimal for high acuity tasks(<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-2" hwp:rel-id="ref-5">5</xref>,<xref ref-type="bibr" rid="c37" hwp:id="xref-ref-37-2" hwp:rel-id="ref-37">37</xref>). This theory also predicts that larger stimulus sizes and peripheral cues would improve discrimination at the fovea since estimating FEM would be easier and more accurate in these conditions. It is possible that the absence of optimality might have arisen since the scanning raster was always visible in the present work. Although several lines of evidence against this prediction have been presented(<xref ref-type="bibr" rid="c40" hwp:id="xref-ref-40-1" hwp:rel-id="ref-40">40</xref>), they turned out to be lacking technical precision and proper controls to directly test this prediction(<xref ref-type="bibr" rid="c41" hwp:id="xref-ref-41-1" hwp:rel-id="ref-41">41</xref>).</p><p hwp:id="p-17">We have identified several mediator factors that could explain a significant portion of the variability in the data. Note that the presence of these mediators is not due to the equipment used or stimulus parameters, but reflects the inevitable consequence of foveal presentation of the stimuli. None of these mediators have been reported quantitatively or used to account for data in the previous literature about the roles of FEM. Parafoveal (or peripheral) presentation of stabilized stimuli may not activate all of the aforementioned mediators (e.g., eye ISOA), however, non-foveal presentation of stimuli would defeat the purpose of this study since one cannot make strong inferences about foveal viewing with peripherally presented stimuli. Alternatively, an experiment where stimulus moves in an incongruent manner to avoid chasing can be performed, however, it is unclear whether or not small amplitudes of stimulus motion would still lead to pursuit-like eye movements. The way we chose to address what factors underlie the tuning between performance and gain reported here is to perform a mediation analysis(<xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-1" hwp:rel-id="ref-42">42</xref>). This analysis showed that even when retinal motion, eye motion, PRL eccentricity, and microsaccade rate were factored in, gain still had a significant direct effect on performance. This finding suggests that (i) there are additional mediators not considered here, or (ii) “post-retinal” factors such as changes in attentional engagement in the task depending on gain value might be at play.</p><p hwp:id="p-18">In order to assign extra-retinal factors a role for perception during FEM, one needs to factor out all possible retinal factors such as retinal ISOA, velocity, acceleration, PRL eccentricity, initial retinal position of the stimuli, etc. Obviously, these factors are not independent from each other, limiting the use of mediation analysis described here. Admittedly, the optimal gain might also be affected by these mediators. A way to compensate for their effects for the purpose of estimating optimal gain might be normalizing performance by each mediator and then testing for tuning. However, this exacerbates the problem since (i) whether a covarying factor is a positive mediator (reducing the effect) or a negative one (increasing the effect) is not known a priori, (ii) the relative contribution of each mediator is different but normalization assumes equal contribution, and (iii) each mediator has a different scale of change across conditions, which could result in numerical instabilities and prevent accurate determination of the optimal gain. Point (iii) can be addressed by log-transforming some mediators (e.g., retinal ISOA) and/or standardizing them, and point (i) can be addressed by using the outcome of a mediation analysis to guide the normalization process, but point (ii) cannot be readily addressed. On the other hand, since visual performance comes about via mediators, there may not be a need for normalizing performance before computing optimal gains. From this perspective, they are not just artifacts to be removed, but the actual underlying factors of visual function. The logic is that whatever the exact value of optimal gain is, visual performance results from an interplay between various mediators, and it may not be possible to uniformly sample the multidimensional space defined by multiple mediators. A case in point, it seems that foveal presentation of a stimulus almost always leads to smooth pursuit-like oculomotor behaviors when the retinal projection of it is stabilized(<xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-2" hwp:rel-id="ref-24">24</xref>).</p><p hwp:id="p-19">Human retina is non-homogeneous, even within the fovea. Therefore, making microsaccades to redirect gaze to enjoy the highest acuity part of the retina is a reasonable strategy(<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-3" hwp:rel-id="ref-21">21</xref>,<xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">28</xref>). Microsaccades are not always initiated voluntarily, however, and recent studies claimed that they often occur after a period of low retinal slip and are executed to avoid fading(<xref ref-type="bibr" rid="c43" hwp:id="xref-ref-43-1" hwp:rel-id="ref-43">43</xref>). Their occurrence seems to be coupled to heartbeat as well(<xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-1" hwp:rel-id="ref-44">44</xref>). Based on the finding that microsaccades cause widespread activity across the visual system and help temporally synchronize neural activity, some researchers supported the view that microsaccades, among other FEM, contribute most to visual function(<xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-2" hwp:rel-id="ref-20">20</xref>,<xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-1" hwp:rel-id="ref-45">45</xref>,<xref ref-type="bibr" rid="c46" hwp:id="xref-ref-46-1" hwp:rel-id="ref-46">46</xref>). Although the rate of microsaccades in our experiments was very low, we still performed a series of analyses on microsaccades made by all observers to test these hypotheses (<bold><xref ref-type="fig" rid="figS2" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Figure S2</xref></bold>). The low rate of microsaccades itself, especially when retinal image motion was minimized, is an evidence against a primary role for microsaccades for visual processing. In response to partial or complete retinal stabilization for instance, subjects made larger drifts rather than larger or more frequent microsaccades. Moreover, we found evidence for both low retinal slip and gaze redirection, although the evidence for the latter was stronger. More specifically, we found that retinal image velocity was slightly reduced immediately before microsaccade onset, and most microsaccades were made to bring the retinal projection of the stimuli closer to the PRL.</p><p hwp:id="p-20">There are several other facts to be considered when functional roles of drifts and microsaccades are to be determined. First, RGCs are most responsive to light transients, and the time constant of their responses can vary from 30 to 100 ms(<xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-1" hwp:rel-id="ref-47">47</xref>). Second, although the initial burst activity of RGCs in response to a light transient is highly precise, prolonged presentation breaks this temporal synchrony, and the tonic neural activity demonstrates quite a bit of variability(<xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-1" hwp:rel-id="ref-48">48</xref>,<xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-1" hwp:rel-id="ref-49">49</xref>). Encoding spatial information using a rate code with a few spikes necessitates the accumulation of information over time to improve the signal to noise ratio. The presence of FEM makes encoding of spatial information via rate coding even less reliable by further increasing variability in spiking activity. Third, FEM create retinal motion signals that are well beyond motion detection thresholds but not perceived.</p><p hwp:id="p-21">From an evolutionary standpoint, it is unclear which of the facts listed so far was the root cause for the others. For instance, whether RGCs prefer light transients and do not respond as strongly after prolonged presentation due to FEM, or FEM exist due to the temporal characteristics of RGC responses is a hard problem to address. In addition, a recent modeling work demonstrated potential alternatives to spatial encoding via rate coding, where FEM do not pose problems to be solved by the visual system, but instead they are part of the solution to efficient information encoding(<xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-2" hwp:rel-id="ref-32">32</xref>). This also renders the mystery of how the visual system differentiates motion due to FEM from those of external objects a non-issue since if we actually see via FEM, why correct for them? In fact, drifts transform the spectral content of retinal stimulation into spatiotemporal frequencies to which the early visual system is most sensitive(<xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">31</xref>), but it is unclear whether this is an epiphenomenon or a result targeted by an active and/or adaptive process. However, the current implementation of this model relies on weak assumptions, one of which is that drifts are cyclic (sinusoidal) motions (to drive phase-locking mechanism) within time courses that reflect average fixation duration (~300 ms). Except in very few instances, we did not observe such patterns (<bold><xref ref-type="fig" rid="figS3" hwp:id="xref-fig-7-1" hwp:rel-id="F7">Figure S3</xref>).</bold></p><p hwp:id="p-22">Some visual/cortical impairments (e.g., amblyopia, central vision loss) result in “abnormal” FEM (<xref ref-type="bibr" rid="c50" hwp:id="xref-ref-50-1" hwp:rel-id="ref-50">50</xref>,<xref ref-type="bibr" rid="c51" hwp:id="xref-ref-51-1" hwp:rel-id="ref-51">51</xref>). In a computer vision system with limited spatial resolution or blurry optics, it is theoretically possible to achieve “super-resolution” or de-blurring by moving a sensor array. Therefore, we think that to classify FEM as abnormal, one needs to consider several factors such as the amount of blur, receptive field sizes, and contrast sensitivity at the PRL. Otherwise, a genuine strategy of a perfectly normal oculomotor system might be misinterpreted as an artifact. In the case of central vision loss, the use of peripheral PRL leads to changes in all these factors, and it is quite possible that apparently abnormal FEM in these patients might be a way to compensate for these changes. In fact, recent studies on the effects of retinal image motion in peripheral vision reported improvements in reading and discrimination performance with increased motion(<xref ref-type="bibr" rid="c52" hwp:id="xref-ref-52-1" hwp:rel-id="ref-52">52</xref>,<xref ref-type="bibr" rid="c53" hwp:id="xref-ref-53-1" hwp:rel-id="ref-53">53</xref>).</p><p hwp:id="p-23">The statistics of FEM may change when a subject’s head is restrained compared to head-free viewing(<xref ref-type="bibr" rid="c54" hwp:id="xref-ref-54-1" hwp:rel-id="ref-54">54</xref>). The amplitudes of FEM increase under free viewing. Measurements using a Dual-Purkinje tracker showed that drifts from the two eyes show minimal correlation under head-fixed conditions, and they become mostly conjugate under head-free conditions. However, retinal imaging via a binocular TSLO revealed almost complete conjugacy under head-fixed conditions(<xref ref-type="bibr" rid="c55" hwp:id="xref-ref-55-1" hwp:rel-id="ref-55">55</xref>). Nonetheless, the conditions reported here may demonstrate a special case of oculomotor control, which need not be optimized since outside the laboratory, we always view the environment with freely moving body and head. In addition, since the stimulus presentation was monocular in the present study, it remains to be seen whether similar tuning functions would be obtained with binocular presentation. It may be that binocular viewing increases the tolerance of the visual system to retinal image motion due to FEM even for high spatial frequencies due to redundancy from the second eye. Finally, the different patterns of results in the two experiments reported here also suggest that the relationship between FEM and frequency might be a continuum, from no tuning to optimal tuning with increasing spatiotemporal frequency. Future endeavors along these lines will require denser sampling of the frequency space as well as accurate eye tracking combined with fast stimulus delivery to both eyes.</p></sec><sec id="s3" hwp:id="sec-3"><title hwp:id="title-4">Methods</title><sec id="s3a" hwp:id="sec-4"><title hwp:id="title-5">Participants</title><p hwp:id="p-24">Seven human subjects (including the first author, S1) with normal or corrected-to-normal vision (20/20 or better in each eye) participated in the study. All seven subjects took part in Experiment 1. Three of the seven subjects participated in Experiment 2. All subjects, except the first author, were naïve as to the purpose and the details of the experiments. All subjects gave written informed consent prior to the experiments. All experimental procedures were approved by the Institutional Review Board at the University of California, Berkeley.</p></sec><sec id="s3b" hwp:id="sec-5"><title hwp:id="title-6">Apparatus</title><p hwp:id="p-25">For stimulus delivery and eye tracking, we used a custom-built tracking scanning laser ophthalmoscope (TSLO)(<xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-2" hwp:rel-id="ref-22">22</xref>). The TSLO has a diffraction-limited optical design, provides high-fidelity imaging of the retina, and more importantly, offers online tracking of eye movements. For the experiments presented here, we used a 10 x 10 deg<sup>2</sup> (512 x 512 pixels<sup>2</sup>) field of view (FOV), which yielded a pixel size of 1.17 arcmin. A large FOV enabled us to capture videos with rich retinal structure which, in turn, allowed accurate image-based eye tracking and stimulus delivery. The horizontal scanner operates at 16 kHz whereas the vertical scanner operates at 1/512 of this rate to record full frames at 30 frames per sec. An 840 nm super luminescent diode with a 50 nm bandwidth was used to scan the retina. Visual stimuli were delivered by manipulating the laser beam via an acousto-optic modulator with the output controlled by a 14-bit digital to analog converter. Therefore, the stimuli had a negative contrast on the dim red raster created by the scanner (i.e., appeared black on a red background). Details of online eye movement tracking have been reported elsewhere (<xref ref-type="bibr" rid="c56" hwp:id="xref-ref-56-1" hwp:rel-id="ref-56">56</xref>–<xref ref-type="bibr" rid="c58" hwp:id="xref-ref-58-1" hwp:rel-id="ref-58">58</xref>). Briefly, each frame was broken into 32 horizontal strips (16 x 512 pixel<sup>2</sup>) and each strip was cross-correlated with a reference frame acquired earlier. The horizontal and vertical shifts required to match a strip to the reference frame represent a measure of the relative motion of the eye. This method results in an eye movement sampling rate of 960 Hz. These computations occur in near real-time (with 2.5±0.5 ms delay) and allows accurate stimulus delivery at specific retinal locations.</p></sec><sec id="s3c" hwp:id="sec-6"><title hwp:id="title-7">Stimuli and Procedures</title><p hwp:id="p-26">The task was to report the orientation of a sinusoidal grating from vertical (2AFC, clockwise or counterclockwise). The amount of tilt was ±45° from vertical and the spatial frequency of the grating was 12 cpd in Experiment 1 (<bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-9" hwp:rel-id="F1">Fig. 1a</xref></bold>) and 3 cpd in Experiment 2. Prior to each experiment, the contrast of the grating was adjusted for each subject to yield ~80% correct discrimination performance under the natural viewing condition (i.e., gain = 0). The size of the grating was 3 x 0.75 deg<sup>2</sup>. Horizontal edges were smoothed using a cosine profile. Mean luminance (as measured indirectly from laser power) of the grating was kept at ~70% of the luminance of the scanning raster for all subjects, regardless of the contrast of the grating (<bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-10" hwp:rel-id="F1">Fig. 1b</xref></bold>). All experiments were performed in a dark room, and subjects were dark adapted for about half an hour prior to any data collection. For some subjects (three out of seven), pupil of the imaged eye was dilated to maintain good retinal image quality throughout the session.</p><p hwp:id="p-27">Each trial started with a fixation cross (0.2 deg) presented at the center of the raster. The experimenter manually acquired a reference frame for online tracking at the start of each trial. Following a random delay (up to 1 sec), the stimulus was presented for 900 ms (flickered at 30 Hz). Subjects responded via a gamepad, had unlimited time to respond, and could have a break at any point during a block of trials. The set of gains used were -1, -0.5, 0, 0.5,1,1.5, and 2. Different gains were interleaved within a block of trials. All observers completed at least 100 trials per gain. Right after the completion of the main experiment and before data analyses, subject S4 was tested for a second run in Experiment 1 since her retinal image quality and head stability during the experiment was poor, causing retinal stabilization to fail in many of her trials. In the second run, we used finer steps of gain (from -0.25 to 1.25 in steps of 0.125) and subject S4 again ran at least 100 trials per gain. However, all results presented in the main text include only the data from the first run for S4. The results from both runs for S4 are shown in <bold><xref ref-type="fig" rid="figS3" hwp:id="xref-fig-7-2" hwp:rel-id="F7">Figure S3</xref>.</bold></p></sec><sec id="s3d" hwp:id="sec-7"><title hwp:id="title-8">Retinal video analysis</title><p hwp:id="p-28">Retinal videos were analyzed offline for five main reasons. First, we sought to determine how well and where the stimulus was delivered on a trial-by-trial basis. Second, online eye tracking was performed by using raw retinal images which were corrupted by high frequency noise and low frequency luminance gradients. In order to get more accurate eye motion estimates relatively less dependent on changes in overall brightness and uniformity of retinal images across trials, one needs to perform several pre-processing steps on retinal images. To this end, we performed the following image processing steps before computing eye motion. Trimming, detection and removal of frames during which subjects blinked, extracting stimulus position and removal of the stimulus (replaced by random noise patterns whose statistics –mean and standard deviation, matched to the rest of the frame), gamma correction, bandpass filtering (for removal of high frequency noise and low frequency brightness gradients), and making a reference frame. Third, during online eye tracking, if the peak of normalized cross-correlation between a strip and the reference frame was below 0.3, possibly due to (i) bad image quality, (ii) excessive distortion of image features due to a rapid eye movement, (iii) insufficient amount of overlap between the strip and the reference frame due to large eye motion, or (iv) blinks, the stimulus was not delivered. By offline processing of retinal videos, we also sought to inspect each and every frame of retinal videos and discard the trials if the stimuli was delivered inaccurately or was not delivered at all in more than two frames per trial (note that with this criterion, trials where subjects blinked were also discarded). This procedure resulted in removal of 28.8% (1305/4525) and 8.7% (206/2353) of all trials in Experiment 1 and 2, respectively. Fourth, since the reference frames used for online tracking were basically snapshots of the retina taken manually by the experimenter, and since the eyes are almost never stationary, the reference frames themselves might have some distortions due to these motions. By offline processing, we created a relatively motion-free reference frame for each and every trial separately in an iterative process. This process started by selecting one of the frames in a retinal video as the reference frame, and computing eye motion. After each iteration, a new reference frame was built by using computed eye motion and individual strips. We performed three iterations for each video, and the reference frames made in the last iteration were used for the final computation of eye motion. The strip height and sampling rate used for the final strip analysis were 25 pixels and 540 Hz, respectively. Fifth, during offline analysis, we could interpolate the cross-correlation maps around where the peak occurs to achieve subpixel resolution (one tenth of a pixel, 0.12 arcmin) in computing eye motion.</p></sec><sec id="s3e" hwp:id="sec-8"><title hwp:id="title-9">Post-processing</title><p hwp:id="p-29">Following strip analysis of individual videos, the computed eye motion traces were subjected to several post-processing steps. First, eye motion traces were “re-referenced” to a larger reference frame created by retinal videos recorded in a separate session where subjects were asked to fixate at different position on the scanning raster. This essentially allowed us to capture images from different part of the retina and tile them on a larger (“global”) reference frame. Re-referencing was needed since each and every video had a slightly different (“local”) reference frame (since reference frames were created for each video separately), and hence, the absolute values of the eye motion would differ across trials. This step is required also for computing the absolute retinal position of the stimulus across all trials for a given subject. Re-referencing was performed by adding a constant shift to the previously computed eye motion traces, where the amount of shift was defined as the position of the local reference frame on the global one. After re-referencing, eye motions were then converted to visual degrees, low-pass filtered (passband and stopband frequencies of 80 and 120 Hz, respectively, with 65 dB attenuation in the stopband), and median filtered (with a window of 9 samples, ~17 ms) to reduce frame-rate artifacts (30 Hz noise and its harmonics). Filtered traces were used to compute retinal motion of the stimulus (defined as the difference between stimulus motion and eye motion). We quantified the amount of eye and retinal motion on a trial-by-trial basis as the 68% isoline area(<xref ref-type="bibr" rid="c59" hwp:id="xref-ref-59-1" hwp:rel-id="ref-59">59</xref>) (referred to as ISOA in the main text), which corresponds to the area of the 0.68 cumulative probability isoline (<bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-11" hwp:rel-id="F1">Fig. 1d</xref></bold>). This also roughly corresponds to the area covered by 68% percent of the motion samples. In the case of retinal motion, this metric quantifies the retinal area traversed by the stimulus in a given trial, and for eye motion, it represents the area of the raster (in world centered coordinates) over which the eye moved. The distribution of the ratio of retinal ISOA and eye ISOA reveals how well the stimulus was delivered in different conditions (see Fig. X). The theoretical ratio for a given gain is defined as
<disp-formula hwp:id="disp-formula-1"><alternatives hwp:id="alternatives-1"><graphic xlink:href="220319_ueqn1.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives>
</disp-formula>
where <italic toggle="yes">g</italic> represents gain, and <italic toggle="yes">sgn(.</italic>) represents the signum function which was introduced to differentiate between gains that result in the same retinal motion magnitude but in opposite directions (<bold><xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-12" hwp:rel-id="F1">Fig. 1f</xref></bold>, and <bold><xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-4" hwp:rel-id="F3">Fig. 3c</xref></bold>).</p><p hwp:id="p-30">We also computed the preferred retinal locus (PRL) of the stimulus for each trial. PRL was defined as the retinal location corresponding to the highest probability density of stimulus presence. The probability densities were computed by the “kernel density estimation via diffusion” method(<xref ref-type="bibr" rid="c60" hwp:id="xref-ref-60-1" hwp:rel-id="ref-60">60</xref>) with a slight modification. More specifically, the kernel bandwidth was set to one-sixth of the standard deviation of the eye (or retinal) motion (as in Kwon et al.(<xref ref-type="bibr" rid="c61" hwp:id="xref-ref-61-1" hwp:rel-id="ref-61">61</xref>)). The median PRL in the trials where the gain was 0 (i.e., natural viewing) was taken as the location of the fovea and trial-to-trial PRL eccentricity was calculated with respect to this quantity. Finally, we identified microsaccades by using a median-based velocity threshold(<xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-1" hwp:rel-id="ref-62">62</xref>). Eye motion traces from all trials were visually inspected to ensure that microsaccade detection was performed correctly.</p><p hwp:id="p-31">The PRL estimated when gain is 0 reflects the true PRL. Since PRL is mostly determined by the position of the stimulus at the beginning of a trial (e.g., when gain is 1, the stimulus will stay at the start position), the estimated PRLs in other gain conditions do not necessarily reflect the preferences of the subjects. However, they demonstrate the idiosyncratic eye movements which govern the starting position of the stimulus. Nevertheless, to keep a consistent nomenclature, we used the term PRL across all conditions.</p></sec><sec id="s3f" hwp:id="sec-9"><title hwp:id="title-10">Statistics</title><p hwp:id="p-32">In order to test the tuning and no tuning hypotheses, we fit performance with a flat line and a quadratic polynomial (as well as a Gaussian, although polynomial and Gaussian fits produced almost identical results), and compared the adjusted R<sup>2</sup> values as a metric of goodness of fit.</p><p hwp:id="p-33">Due to foveal presentation of the stimuli, different gains led to different idiosyncratic oculomotor behaviors which could not be controlled during the experiments. We quantified several covarying factors such as retinal ISOA, eye ISOA, PRL eccentricity, and microsaccade rate. The exact choice of covarying factors was driven by the need to account for main retinal and eye movement-related metrics. It is possible to estimate retinal image velocity, acceleration, or components of retinal image motion parallel or perpendicular to the orientation of the gratings. It is also possible to quantify these metrics in multiple ways, such as by their mean, standard deviation, minimum, maximum, or any combination of these together. However, since most of these metrics are strongly related to each other, adding different variants of them does not add much explanatory power. In addition, eye position traces extracted from retinal videos tend to have frame-rate artifacts, i.e., more power than normal at temporal frequencies around the frame rate of the videos. The frame-rate artifact gets amplified for velocity and acceleration due to differentiation, and more importantly, the severity of the effect interacts with different gain conditions (due to changes in oculomotor behavior). Position estimates are not influenced as much and indirectly captures the effect of its derivatives.</p><p hwp:id="p-34">In order to determine how much of the effect of gain on performance is mediated by the aforementioned covarying factors, we performed a linear-mixed effects regression-based mediation analysis(<xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-2" hwp:rel-id="ref-42">42</xref>). We followed the commonly-used four-step approach suggested by Baron and Kenny (<xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-2" hwp:rel-id="ref-26">26</xref>). The aim of this analysis was to determine whether or not gain had a significant direct effect on discrimination performance, even after taking into account the effects of mediators (i.e., significant covarying factors). Mediation analysis can be done in many ways depending on the causal relationship between the independent variable and mediators. When there are multiple mediators, say n, there are 2<sup>(n!)</sup> possible ways of decomposing total effect size. In our case, n=4, this yields 16,777,216 possibilities(<xref ref-type="bibr" rid="c63" hwp:id="xref-ref-63-1" hwp:rel-id="ref-63">63</xref>). Since finding the best way of organizing mediators to account for data is beyond the scope of the present work, we chose a simple case where all mediators were treated as independent factors that are directly modulated by only the independent variable, the gain, and they did not have interactions among each other nor with the gain. However, they were allowed to covary with subjects, and each had a fixed slope and a random intercept to account for individual differences in mediator values.</p></sec></sec><sec id="s4" hwp:id="sec-10"><title hwp:id="title-11">Author contributions</title><p hwp:id="p-35">MNA and STLC conceived the idea and designed the experiments. MNA and STLC performed the experiments. MNA analyzed the data and wrote the manuscript. CKS, PT, and AR provided technical support for the TSLO system (hardware, electronics, and software), and CKS, PT, AR, and STLC reviewed the manuscript.</p></sec><sec id="s5" hwp:id="sec-11"><title hwp:id="title-12">Competing financial interests</title><p hwp:id="p-36">MNA and STLC have no financial interest. AR, CKS, and PT hold a patent for the design of the TSLO, and have financial interest in C.Light Technologies.</p></sec></body><back><ack hwp:id="ack-1"><title hwp:id="title-13">Acknowledgements</title><p hwp:id="p-37">We would like to thank Jonathan Patrick, Arun Kumar Krishnan and Haluk Ogmen for his comments on the manuscript, and Harold Bedell for many discussions of our results. This study was supported by grants R01-EY012810 (STLC), R01-EY017707 (STLC), R01-EY023591 (AR), P30-EY003176 (core grant) from the National Institutes of Health, and UCSF-CTSI grant TL1-TR001871 (CKS).</p></ack><ref-list hwp:id="ref-list-1"><title hwp:id="title-14">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1 xref-ref-1-2"><label>1.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Martinez-Conde S"><surname>Martinez-Conde</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Macknik SL"><surname>Macknik</surname> <given-names>SL</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hubel DH"><surname>Hubel</surname> <given-names>DH</given-names></string-name>. <article-title hwp:id="article-title-2">The role of fixational eye movements in visual perception</article-title>. <source hwp:id="source-1">Nat Rev Neurosci</source>. <year>2004</year>;<volume>5</volume>(<issue>3</issue>):<fpage>229</fpage>–<lpage>40</lpage>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1"><label>2.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.2" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Rucci M"><surname>Rucci</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Poletti M"><surname>Poletti</surname> <given-names>M</given-names></string-name>. <article-title hwp:id="article-title-3">Control and Functions of Fixational Eye Movements</article-title>. <source hwp:id="source-2">Annu Rev Vis Sci</source>. <year>2015</year>;<volume>1</volume>(<issue>1</issue>):<comment>annurev-vision-082114-035742</comment>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><label>3.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Otero-Millan J"><surname>Otero-Millan</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Troncoso XG"><surname>Troncoso</surname> <given-names>XG</given-names></string-name>, <string-name name-style="western" hwp:sortable="Macknik SL"><surname>Macknik</surname> <given-names>SL</given-names></string-name>, <string-name name-style="western" hwp:sortable="Serrano-Pedraza I"><surname>Serrano-Pedraza</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Martinez-Conde S"><surname>Martinez-Conde</surname> <given-names>S</given-names></string-name>. <article-title hwp:id="article-title-4">Saccades and microsaccades during visual fixation, exploration, and search: Foundations for a common saccadic generator</article-title>. <source hwp:id="source-3">J Vis. 2008</source> <month>Dec</month> <year>1</year>;<volume>8</volume>(<issue>14</issue>):<fpage>21</fpage>–<lpage>21</lpage>.</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1"><label>4.</label><citation publication-type="confproc" citation-type="confproc" ref:id="220319v1.4" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Engbert R"><surname>Engbert</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mergenthaler K"><surname>Mergenthaler</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sinn P"><surname>Sinn</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pikovsky A"><surname>Pikovsky</surname> <given-names>A</given-names></string-name>. <article-title hwp:id="article-title-5">An integrated model of fixational eye movements and microsaccades</article-title>. <conf-name>Proc Natl Acad Sci</conf-name>. <year>2011</year>;<volume>108</volume>(<issue>39</issue>)E<fpage>765</fpage>–<lpage>70</lpage>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1 xref-ref-5-2"><label>5.</label><citation publication-type="confproc" citation-type="confproc" ref:id="220319v1.5" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Burak Y"><surname>Burak</surname> <given-names>Y</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rokni U"><surname>Rokni</surname> <given-names>U</given-names></string-name>, <string-name name-style="western" hwp:sortable="Meister M"><surname>Meister</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sompolinsky H"><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>. <article-title hwp:id="article-title-6">Bayesian model of dynamic image stabilization in the visual system</article-title>. <conf-name>Proc Natl Acad Sci</conf-name>. <year>2010</year>;<volume>107</volume>(<issue>45</issue>):<fpage>19525</fpage>–<lpage>30</lpage>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2 xref-ref-6-3 xref-ref-6-4"><label>6.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Rucci M"><surname>Rucci</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="lovin R"><surname>lovin</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Poletti M"><surname>Poletti</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Santini F"><surname>Santini</surname> <given-names>F</given-names></string-name>. <article-title hwp:id="article-title-7">Miniature eye movements enhance fine spatial detail</article-title>. <source hwp:id="source-4">Nature</source>. <year>2007</year>;<volume>447</volume>(<issue>7146</issue>):<fpage>852</fpage>–<lpage>5</lpage>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1"><label>7.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Ratliff F"><surname>Ratliff</surname> <given-names>F</given-names></string-name>, <string-name name-style="western" hwp:sortable="Riggs L"><surname>Riggs</surname> <given-names>L</given-names></string-name>. <article-title hwp:id="article-title-8">Involuntary motions of the eye during monocular fixation</article-title>. <source hwp:id="source-5">J Exp Psychol</source>. <year>1950</year>;<volume>40</volume>(<issue>6</issue>):<fpage>687</fpage>–<lpage>701</lpage>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><label>8.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Ditchburn R"><surname>Ditchburn</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ginsborg BL"><surname>Ginsborg</surname> <given-names>BL</given-names></string-name>. <article-title hwp:id="article-title-9">Involuntary Eye Movements During Fixation</article-title>. <source hwp:id="source-6">J Physiol</source>. <year>1953</year>;<volume>119</volume>(<issue>1940</issue>):<fpage>1</fpage>–<lpage>17</lpage>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1"><label>9.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.9" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="kyoung Ko H"><given-names>Ko H</given-names> <surname>kyoung</surname></string-name>, <string-name name-style="western" hwp:sortable="Snodderly DM"><surname>Snodderly</surname> <given-names>DM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Poletti M"><surname>Poletti</surname> <given-names>M</given-names></string-name>. <article-title hwp:id="article-title-10">Eye movements between saccades: Measuring ocular drift and tremor</article-title>. <source hwp:id="source-7">Vision Res</source>. <year>2016</year>;122:<fpage>93</fpage>–<lpage>104</lpage>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><label>10.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Curcio C"><surname>Curcio</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sloan K"><surname>Sloan</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kalina R"><surname>Kalina</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hendrickson A"><surname>Hendrickson</surname> <given-names>A</given-names></string-name>. <article-title hwp:id="article-title-11">Human photoreceptor topography</article-title>. <source hwp:id="source-8">J Comp Neurol</source>. <year>1990</year>;<volume>4</volume>(<issue>292</issue>):<fpage>497</fpage>–<lpage>523</lpage>.</citation></ref><ref id="c11" hwp:id="ref-11"><label>11.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Watson AB"><surname>Watson</surname> <given-names>AB</given-names></string-name>. <article-title hwp:id="article-title-12">A formula for human retinal ganglion cell receptive field density as a function of visual field location</article-title>. <source hwp:id="source-9">J Vis</source>. <year>2016</year>;<volume>14</volume>(<issue>2014</issue>):<fpage>1</fpage>–<lpage>17</lpage>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1"><label>12.</label><citation publication-type="confproc" citation-type="confproc" ref:id="220319v1.12" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Dacey DM"><surname>Dacey</surname> <given-names>DM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Petersen MR"><surname>Petersen</surname> <given-names>MR</given-names></string-name>. <article-title hwp:id="article-title-13">Dendritic field size and morphology of midget and parasol ganglion cells of the human retina</article-title>. <conf-name>Proc Natl Acad Sci USA</conf-name>. <year>1992</year>;<volume>89</volume>(<issue>20</issue>):<fpage>9666</fpage>–<lpage>70</lpage>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1"><label>13.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.13" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Kaplan E"><surname>Kaplan</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Benardete E"><surname>Benardete</surname> <given-names>E</given-names></string-name>. <article-title hwp:id="article-title-14">The dynamics of primate M retinal ganglion cells</article-title>. <source hwp:id="source-10">Vis Neurosci</source>. <year>1999</year>;16:<fpage>355</fpage>–<lpage>68</lpage>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><label>14.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Benardete EA"><surname>Benardete</surname> <given-names>EA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kaplan E"><surname>Kaplan</surname> <given-names>E</given-names></string-name>. <article-title hwp:id="article-title-15">The receptive field of the primate P retinal ganglion cell, I: Linear dynamics</article-title>. <source hwp:id="source-11">Vis Neurosci</source>. <year>1997</year>;<volume>14</volume>(<issue>1997</issue>):<fpage>169</fpage>–<lpage>85</lpage>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><label>15.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.15" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Ditchburn RW"><surname>Ditchburn</surname> <given-names>RW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ginsborg BL"><surname>Ginsborg</surname> <given-names>BL</given-names></string-name>. <article-title hwp:id="article-title-16">Vision with a stabilized retinal image</article-title>. <source hwp:id="source-12">Nature</source>. <year>1952</year>;<volume>170</volume>:<fpage>36</fpage>–<lpage>7</lpage>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1 xref-ref-16-2"><label>16.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Riggs LA"><surname>Riggs</surname> <given-names>LA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ratliff F"><surname>Ratliff</surname> <given-names>F</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cornsweet JC"><surname>Cornsweet</surname> <given-names>JC</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cornsweet TN"><surname>Cornsweet</surname> <given-names>TN</given-names></string-name>. <article-title hwp:id="article-title-17">The disappearance of steadily fixated visual test objects</article-title>. <source hwp:id="source-13">J Opt Soc Am</source>. <year>1953</year>;<volume>43</volume>(<issue>6</issue>):<fpage>495</fpage>–<lpage>501</lpage>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1 xref-ref-17-2"><label>17.</label><citation publication-type="book" citation-type="book" ref:id="220319v1.17" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Yarbus AL"><surname>Yarbus</surname> <given-names>AL</given-names></string-name>. <chapter-title>Perception of Objects Stationary Relative to the Retina</chapter-title>. In: <source hwp:id="source-14">Eye Movements and Vision</source>. <publisher-loc>Boston, MA</publisher-loc>: <publisher-name>Springer US</publisher-name>; <year>1967</year>. p. <fpage>59</fpage>–<lpage>101</lpage>.</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1 xref-ref-18-2 xref-ref-18-3"><label>18.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Ratnam K"><surname>Ratnam</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Harmening WM"><surname>Harmening</surname> <given-names>WM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Roorda A"><surname>Roorda</surname> <given-names>A</given-names></string-name>. <article-title hwp:id="article-title-18">Benefits of retinal image motion at the limits of spatial vision</article-title>. <source hwp:id="source-15">J Vis</source>. <year>2017</year>;<volume>17</volume>((<issue>1</issue>):30):<fpage>1</fpage>–<lpage>11</lpage>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><label>19.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Costela FM"><surname>Costela</surname> <given-names>FM</given-names></string-name>, <string-name name-style="western" hwp:sortable="McCamy MB"><surname>McCamy</surname> <given-names>MB</given-names></string-name>, <string-name name-style="western" hwp:sortable="Macknik SL"><surname>Macknik</surname> <given-names>SL</given-names></string-name>, <string-name name-style="western" hwp:sortable="Otero-Millan J"><surname>Otero-Millan</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Martinez-Conde S"><surname>Martinez-Conde</surname> <given-names>S</given-names></string-name>. <article-title hwp:id="article-title-19">Microsaccades restore the visibility of minute foveal targets</article-title>. <source hwp:id="source-16">Peer J</source>. <year>2013</year>;<volume>1</volume>:<fpage>e119</fpage>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1 xref-ref-20-2"><label>20.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Martinez-Conde S"><surname>Martinez-Conde</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Otero-Millan J"><surname>Otero-Millan</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Macknik SL"><surname>Macknik</surname> <given-names>SL</given-names></string-name>. <article-title hwp:id="article-title-20">The impact of microsaccades on vision: towards a unified theory of saccadic function</article-title>. <source hwp:id="source-17">Nat Rev Neurosci</source>. <year>2013</year>;<volume>14</volume>(<issue>2</issue>):<fpage>83</fpage>–<lpage>96</lpage>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1 xref-ref-21-2 xref-ref-21-3"><label>21.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Poletti M"><surname>Poletti</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Listorti C"><surname>Listorti</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rucci M"><surname>Rucci</surname> <given-names>M</given-names></string-name>. <article-title hwp:id="article-title-21">Microscopic eye movements compensate for nonhomogeneous vision within the fovea</article-title>. <source hwp:id="source-18">Curr Biol</source>. <year>2013</year>;<volume>23</volume>(<issue>17</issue>):<fpage>1691</fpage>–<lpage>5</lpage>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1 xref-ref-22-2"><label>22.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Sheehy CK"><surname>Sheehy</surname> <given-names>CK</given-names></string-name>, <string-name name-style="western" hwp:sortable="Yang Q"><surname>Yang</surname> <given-names>Q</given-names></string-name>, <string-name name-style="western" hwp:sortable="Arathorn DW"><surname>Arathorn</surname> <given-names>DW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tiruveedhula P"><surname>Tiruveedhula</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="de Boer JF"><surname>de Boer</surname> <given-names>JF</given-names></string-name>, <string-name name-style="western" hwp:sortable="Roorda A"><surname>Roorda</surname> <given-names>A</given-names></string-name>. <article-title hwp:id="article-title-22">High-speed, image-based eye tracking with a scanning laser ophthalmoscope</article-title>. <source hwp:id="source-19">Biomed Opt Express</source>. <year>2012</year> <month>Oct</month> <day>1</day>;<volume>3</volume>(<issue>10</issue>):<fpage>2611</fpage>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1"><label>23.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Kelly DH"><surname>Kelly</surname> <given-names>DH</given-names></string-name>. <article-title hwp:id="article-title-23">Visual Contrast Sensitivity</article-title>. <source hwp:id="source-20">Opt Acta Int J Opt</source>. <year>1977</year>;<volume>24</volume>(<issue>2</issue>):<fpage>107</fpage>–<lpage>29</lpage>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1 xref-ref-24-2"><label>24.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Poletti M"><surname>Poletti</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Listorti C"><surname>Listorti</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rucci M"><surname>Rucci</surname> <given-names>M</given-names></string-name>. <article-title hwp:id="article-title-24">Stability of the visual world during eye drift</article-title>. <source hwp:id="source-21">J Neurosci</source>. <year>2010</year> <month>Aug</month> <day>18</day>;<volume>30</volume>(<issue>33</issue>):<fpage>11143</fpage>–<lpage>50</lpage>.</citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1"><label>25.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.25" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Arathorn D"><surname>Arathorn</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Stevenson S"><surname>Stevenson</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Yang Q"><surname>Yang</surname> <given-names>Q</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tiruveedhula P"><surname>Tiruveedhula</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Roorda A"><surname>Roorda</surname> <given-names>A</given-names></string-name>. <article-title hwp:id="article-title-25">How the unstable eye sees a stable and moving world</article-title>. <source hwp:id="source-22">J Vis</source>. <year>2013</year>;13:<fpage>1</fpage>–<lpage>19</lpage>.</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1 xref-ref-26-2"><label>26.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.26" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Baron RM"><surname>Baron</surname> <given-names>RM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kenny DA"><surname>Kenny</surname> <given-names>DA</given-names></string-name>. <article-title hwp:id="article-title-26">The moderator-mediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations</article-title>. <source hwp:id="source-23">J Pers Soc Psychol</source>. <year>1986</year>;<volume>51</volume>(<issue>6</issue>):<fpage>1173</fpage>–<lpage>82</lpage>.</citation></ref><ref id="c27" hwp:id="ref-27" hwp:rev-id="xref-ref-27-1"><label>27.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.27" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Skavenski AA"><surname>Skavenski</surname> <given-names>AA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hansen RM"><surname>Hansen</surname> <given-names>RM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Steinman RM"><surname>Steinman</surname> <given-names>RM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Winterson BJ"><surname>Winterson</surname> <given-names>BJ</given-names></string-name>. <article-title hwp:id="article-title-27">Quality of retinal image stabilization during small natural and artificial body rotations in man</article-title>. <source hwp:id="source-24">Vision Res</source>. <year>1979</year> <month>Jan</month> <day>1</day>;<volume>19</volume>(<issue>6</issue>):<fpage>675</fpage>–<lpage>83</lpage>.</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1"><label>28.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.28" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Cornsweet TN"><surname>Cornsweet</surname> <given-names>TN</given-names></string-name>. <article-title hwp:id="article-title-28">Determination of the Stimuli for Involuntary Drifts and Saccadic Eye Movements</article-title>. <source hwp:id="source-25">J Opt Soc Am</source>. <year>1956</year>;<volume>46</volume>(<issue>11</issue>):<fpage>987</fpage>–<lpage>8</lpage>.</citation></ref><ref id="c29" hwp:id="ref-29"><label>29.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.29" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="Ditchburn R"><surname>Ditchburn</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fender DH"><surname>Fender</surname> <given-names>DH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mayne S"><surname>Mayne</surname> <given-names>S</given-names></string-name>. <article-title hwp:id="article-title-29">Vision with Controlled Movements of the Retinal Image</article-title>. <source hwp:id="source-26">J Physiol</source>. <year>1959</year>;<volume>145</volume>:<fpage>98</fpage>–<lpage>107</lpage>.</citation></ref><ref id="c30" hwp:id="ref-30"><label>30.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.30" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="Gerrits HJM"><surname>Gerrits</surname> <given-names>HJM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Vendrik AJH"><surname>Vendrik</surname> <given-names>AJH</given-names></string-name>. <article-title hwp:id="article-title-30">Artificial movements of a stabilized image</article-title>. <source hwp:id="source-27">Vision Res</source>. <year>1970</year> <month>Dec</month> <day>1</day>;<volume>10</volume>(<issue>12</issue>):<fpage>1443</fpage>–<lpage>56</lpage>.</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1"><label>31.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="Kuang X"><surname>Kuang</surname> <given-names>X</given-names></string-name>, <string-name name-style="western" hwp:sortable="Poletti M"><surname>Poletti</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Victor JD"><surname>Victor</surname> <given-names>JD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rucci M"><surname>Rucci</surname> <given-names>M</given-names></string-name>. <article-title hwp:id="article-title-31">Temporal encoding of spatial information during active visual fixation</article-title>. <source hwp:id="source-28">Curr Biol</source>. <year>2012</year>;<volume>22</volume>(<issue>6</issue>):<fpage>510</fpage>–<lpage>4</lpage>.</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1 xref-ref-32-2"><label>32.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.32" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="Ahissar E"><surname>Ahissar</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Arieli A"><surname>Arieli</surname> <given-names>A</given-names></string-name>. <article-title hwp:id="article-title-32">Seeing via Miniature Eye Movements: A Dynamic Hypothesis for Vision</article-title>. <source hwp:id="source-29">Front Comput Neurosci</source>. <year>2012</year> <month>Nov</month> <day>8</day>;<volume>6</volume>:<fpage>89</fpage>.</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1"><label>33.</label><citation publication-type="confproc" citation-type="confproc" ref:id="220319v1.33" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Coppola D"><surname>Coppola</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Purves D"><surname>Purves</surname> <given-names>D</given-names></string-name>. <article-title hwp:id="article-title-33">The extraordinarily rapid disappearance of entopic images</article-title>. <conf-name>Proc Natl Acad Sci</conf-name>. <year>1996</year>;<volume>93</volume>(<issue>15</issue>):<fpage>8001</fpage>–<lpage>4</lpage>.</citation></ref><ref id="c34" hwp:id="ref-34"><label>34.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.34" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Kelly DH"><surname>Kelly</surname> <given-names>DH</given-names></string-name>. <article-title hwp:id="article-title-34">Motion and vision</article-title>. <source hwp:id="source-30">I. Stabilized images of stationary gratings. J Opt Soc Am</source>. <year>1979</year>;<volume>69</volume>(<issue>9</issue>):<fpage>1266</fpage>–<lpage>74</lpage>.</citation></ref><ref id="c35" hwp:id="ref-35"><label>35.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.35" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Kelly DH"><surname>Kelly</surname> <given-names>DH</given-names></string-name>. <article-title hwp:id="article-title-35">Motion and vision</article-title>. <source hwp:id="source-31">II. Stabilized spatio-temporal threshold surface. J Opt Soc Am</source>. <year>1979</year>;<volume>69</volume>(<issue>10</issue>):<fpage>1340</fpage>–<lpage>9</lpage>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1"><label>36.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.36" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Riggs LA"><surname>Riggs</surname> <given-names>LA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tulunay SÜ"><surname>Tulunay</surname> <given-names>SÜ</given-names></string-name>. <article-title hwp:id="article-title-36">Visual Effects of Varying the Extent of Compensation for Eye Movements*</article-title>. <source hwp:id="source-32">J Opt Soc Am</source>. <year>1959</year> <month>Aug</month> <day>1</day>;<volume>49</volume>(<issue>8</issue>):<fpage>741</fpage>.</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1 xref-ref-37-2"><label>37.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.37" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Pitkow X"><surname>Pitkow</surname> <given-names>X</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sompolinsky H"><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Meister M"><surname>Meister</surname> <given-names>M</given-names></string-name>. <article-title hwp:id="article-title-37">A neural computation for visual acuity in the presence of eye movements</article-title>. <source hwp:id="source-33">PLoS Biol</source>. <year>2007</year>;<volume>5</volume>(<issue>12</issue>):<fpage>2898</fpage>–<lpage>911</lpage>.</citation></ref><ref id="c38" hwp:id="ref-38" hwp:rev-id="xref-ref-38-1"><label>38.</label><citation publication-type="confproc" citation-type="confproc" ref:id="220319v1.38" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-38"><string-name name-style="western" hwp:sortable="Anderson AG"><surname>Anderson</surname> <given-names>AG</given-names></string-name>, <string-name name-style="western" hwp:sortable="Olshausen BA"><surname>Olshausen</surname> <given-names>BA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ratnam K"><surname>Ratnam</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Roorda A"><surname>Roorda</surname> <given-names>A</given-names></string-name>. <article-title hwp:id="article-title-38">A neural model of high-acuity vision in the presence of fixational eye movements</article-title>. In: <conf-name>2016 50th Asilomar Conference on Signals, Systems and Computers. IEEE</conf-name>; <year>2016</year>. p. <fpage>588</fpage>–<lpage>92</lpage>.</citation></ref><ref id="c39" hwp:id="ref-39" hwp:rev-id="xref-ref-39-1"><label>39.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.39" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-39"><string-name name-style="western" hwp:sortable="Murakami I"><surname>Murakami</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cavanagh P"><surname>Cavanagh</surname> <given-names>P</given-names></string-name>. <article-title hwp:id="article-title-39">A jitter after-effect reveals motion-based stabilization of vision</article-title>. <source hwp:id="source-34">Nature</source>. <year>1998</year> <month>Oct</month> <day>22</day>;<volume>395</volume>(<issue>6704</issue>):<fpage>798</fpage>–<lpage>801</lpage>.</citation></ref><ref id="c40" hwp:id="ref-40" hwp:rev-id="xref-ref-40-1"><label>40.</label><citation publication-type="confproc" citation-type="confproc" ref:id="220319v1.40" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-40"><string-name name-style="western" hwp:sortable="Wehrhahn C"><surname>Wehrhahn</surname> <given-names>C</given-names></string-name>. <article-title hwp:id="article-title-40">Psychophysical and physiological evidence contradicts a model of dynamic image stabilization</article-title>. <conf-name>Proc Natl Acad Sci USA</conf-name>. <year>2011</year> <month>Mar</month> <day>8</day>;<volume>108</volume>(<issue>10</issue>):<fpage>E35</fpage>; <comment>author reply E36</comment>.</citation></ref><ref id="c41" hwp:id="ref-41" hwp:rev-id="xref-ref-41-1"><label>41.</label><citation publication-type="confproc" citation-type="confproc" ref:id="220319v1.41" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-41"><string-name name-style="western" hwp:sortable="Burak Y"><surname>Burak</surname> <given-names>Y</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rokni U"><surname>Rokni</surname> <given-names>U</given-names></string-name>, <string-name name-style="western" hwp:sortable="Meister M"><surname>Meister</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sompolinsky H"><surname>Sompolinsky</surname> <given-names>H</given-names></string-name>. <article-title hwp:id="article-title-41">Reply to Wehrhahn: Experimental requirements for testing the role of peripheral cues in dynamic image stabilization</article-title>. <conf-name>Proc Natl Acad Sci USA</conf-name>. <year>2011</year> <month>Mar</month> <day>8</day>;<volume>108</volume>(<issue>10</issue>)E36.</citation></ref><ref id="c42" hwp:id="ref-42" hwp:rev-id="xref-ref-42-1 xref-ref-42-2"><label>42.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.42" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-42"><string-name name-style="western" hwp:sortable="MacKinnon DP"><surname>MacKinnon</surname> <given-names>DP</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fairchild AJ"><surname>Fairchild</surname> <given-names>AJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fritz MS"><surname>Fritz</surname> <given-names>MS</given-names></string-name>. <article-title hwp:id="article-title-42">Mediation Analysis</article-title>. <source hwp:id="source-35">Annu Rev Psychol</source>. <year>2007</year>;<volume>58</volume>(<issue>1</issue>):<fpage>593</fpage>–<lpage>614</lpage>.</citation></ref><ref id="c43" hwp:id="ref-43" hwp:rev-id="xref-ref-43-1"><label>43.</label><citation publication-type="confproc" citation-type="confproc" ref:id="220319v1.43" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-43"><string-name name-style="western" hwp:sortable="Engbert R"><surname>Engbert</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mergenthaler K"><surname>Mergenthaler</surname> <given-names>K</given-names></string-name>. <article-title hwp:id="article-title-43">Microsaccades are triggered by low retinal image slip</article-title>. <conf-name>Proc Natl Acad Sci USA</conf-name>. <year>2006</year>;<volume>103</volume>(<issue>18</issue>):<fpage>7192</fpage>–<lpage>7</lpage>.</citation></ref><ref id="c44" hwp:id="ref-44" hwp:rev-id="xref-ref-44-1"><label>44.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.44" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-44"><string-name name-style="western" hwp:sortable="Ohi S"><surname>Ohi</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wohltat C"><surname>Wohltat</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kliegl R"><surname>Kliegl</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Pollatos O"><surname>Pollatos</surname> <given-names>O</given-names></string-name>, <string-name name-style="western" hwp:sortable="Engbert R"><surname>Engbert</surname> <given-names>R</given-names></string-name>. <article-title hwp:id="article-title-44">Microsaccades Are Coupled to Heartbeat</article-title>. <source hwp:id="source-36">J Neurosci</source>. <year>2016</year>;<volume>36</volume>(<issue>4</issue>):<fpage>1237</fpage>–<lpage>41</lpage>.</citation></ref><ref id="c45" hwp:id="ref-45" hwp:rev-id="xref-ref-45-1"><label>45.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.45" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-45">MasquelierT, <string-name name-style="western" hwp:sortable="Portelli G"><surname>Portelli</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kornprobst P"><surname>Kornprobst</surname> <given-names>P</given-names></string-name>. <article-title hwp:id="article-title-45">Microsaccades enable efficient synchrony-based coding in the retina: a simulation study</article-title>. <source hwp:id="source-37">Sci Rep</source>. <year>2016</year>;<day>6</day>(<month>October</month> 2015):<fpage>24086</fpage>.</citation></ref><ref id="c46" hwp:id="ref-46" hwp:rev-id="xref-ref-46-1"><label>46.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.46" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-46"><string-name name-style="western" hwp:sortable="McCamy MB"><surname>McCamy</surname> <given-names>MB</given-names></string-name>, <string-name name-style="western" hwp:sortable="Otero-Millan J"><surname>Otero-Millan</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Macknik SL"><surname>Macknik</surname> <given-names>SL</given-names></string-name>, <string-name name-style="western" hwp:sortable="Yang Y"><surname>Yang</surname> <given-names>Y</given-names></string-name>, <string-name name-style="western" hwp:sortable="Troncoso XG"><surname>Troncoso</surname> <given-names>XG</given-names></string-name>, <string-name name-style="western" hwp:sortable="Baer SM"><surname>Baer</surname> <given-names>SM</given-names></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-46">Microsaccadic Efficacy and Contribution to Foveal and Peripheral Vision</article-title>. <source hwp:id="source-38">J Neurosci</source>. <year>2012</year>;<volume>32</volume>(<issue>27</issue>):<fpage>9194</fpage>–<lpage>204</lpage>.</citation></ref><ref id="c47" hwp:id="ref-47" hwp:rev-id="xref-ref-47-1"><label>47.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.47" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-47"><string-name name-style="western" hwp:sortable="Brien BJO"><surname>Brien</surname> <given-names>BJO</given-names></string-name>, <string-name name-style="western" hwp:sortable="Isayama T"><surname>Isayama</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Richardson R"><surname>Richardson</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Berson DM"><surname>Berson</surname> <given-names>DM</given-names></string-name>, O’<string-name name-style="western" hwp:sortable="Brien BJ"><surname>Brien</surname> <given-names>BJ</given-names></string-name>. <article-title hwp:id="article-title-47">Intrinsic physiological properties of cat retinal ganglion cells</article-title>. <source hwp:id="source-39">J Physiol</source>. <year>2002</year>;<volume>538</volume>(<issue>Pt 3</issue>):<fpage>787</fpage>–<lpage>802</lpage>.</citation></ref><ref id="c48" hwp:id="ref-48" hwp:rev-id="xref-ref-48-1"><label>48.</label><citation publication-type="confproc" citation-type="confproc" ref:id="220319v1.48" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-48"><string-name name-style="western" hwp:sortable="Berry MJ"><surname>Berry</surname> <given-names>MJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Warland DK"><surname>Warland</surname> <given-names>DK</given-names></string-name>, <string-name name-style="western" hwp:sortable="Meister M"><surname>Meister</surname> <given-names>M</given-names></string-name>. <article-title hwp:id="article-title-48">The structure and precision of retinal spike trains</article-title>. <conf-name>Proc Natl Acad Sci</conf-name>. <year>1997</year>;<volume>94</volume>(<issue>10</issue>):<fpage>5411</fpage>–<lpage>6</lpage>.</citation></ref><ref id="c49" hwp:id="ref-49" hwp:rev-id="xref-ref-49-1"><label>49.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.49" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-49"><string-name name-style="western" hwp:sortable="Reich DS"><surname>Reich</surname> <given-names>DS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Victor JD"><surname>Victor</surname> <given-names>JD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Knight BW"><surname>Knight</surname> <given-names>BW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ozaki T"><surname>Ozaki</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kaplan E"><surname>Kaplan</surname> <given-names>E</given-names></string-name>. <article-title hwp:id="article-title-49">Response variability and timing precision of neuronal spike trains in vivo</article-title>. <source hwp:id="source-40">J Neurophysiol</source>. <year>1997</year>;<volume>77</volume>(<issue>5</issue>):<fpage>2836</fpage>–<lpage>41</lpage>.</citation></ref><ref id="c50" hwp:id="ref-50" hwp:rev-id="xref-ref-50-1"><label>50.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.50" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-50"><string-name name-style="western" hwp:sortable="Kumar G"><surname>Kumar</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chung STL"><surname>Chung</surname> <given-names>STL</given-names></string-name>. <article-title hwp:id="article-title-50">Characteristics of fixational eye movements in people with macular disease</article-title>. <source hwp:id="source-41">Invest Ophthalmol Vis Sci</source>. <year>2014</year> <month>Aug</month>;<volume>55</volume>(<issue>8</issue>):<fpage>5125</fpage>–<lpage>33</lpage>.</citation></ref><ref id="c51" hwp:id="ref-51" hwp:rev-id="xref-ref-51-1"><label>51.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.51" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-51"><string-name name-style="western" hwp:sortable="Chung STL"><surname>Chung</surname> <given-names>STL</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kumar G"><surname>Kumar</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="Li RW"><surname>Li</surname> <given-names>RW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Levi DM"><surname>Levi</surname> <given-names>DM</given-names></string-name>. <article-title hwp:id="article-title-51">Characteristics of fixational eye movements in amblyopia: Limitations on fixation stability and acuity?</article-title> <source hwp:id="source-42">Vision Res</source>. <year>2015</year> <month>Sep</month> <day>1</day>;<volume>114</volume>:<fpage>87</fpage>–<lpage>99</lpage>.</citation></ref><ref id="c52" hwp:id="ref-52" hwp:rev-id="xref-ref-52-1"><label>52.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.52" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-52"><string-name name-style="western" hwp:sortable="Patrick JA"><surname>Patrick</surname> <given-names>JA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Roach NW"><surname>Roach</surname> <given-names>NW</given-names></string-name>, <string-name name-style="western" hwp:sortable="McGraw P V"><surname>McGraw</surname> <given-names>P V</given-names></string-name>. <article-title hwp:id="article-title-52">Motion-based super-resolution in the peripheral visual field</article-title>. <source hwp:id="source-43">J Vis</source>. <year>2017</year> <month>Sep</month> <day>18</day>;<volume>17</volume>(<issue>9</issue>)15.</citation></ref><ref id="c53" hwp:id="ref-53" hwp:rev-id="xref-ref-53-1"><label>53.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.53" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-53"><string-name name-style="western" hwp:sortable="Watson LM"><surname>Watson</surname> <given-names>LM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Strang NC"><surname>Strang</surname> <given-names>NC</given-names></string-name>, <string-name name-style="western" hwp:sortable="Scobie F"><surname>Scobie</surname> <given-names>F</given-names></string-name>, <string-name name-style="western" hwp:sortable="Love GD"><surname>Love</surname> <given-names>GD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Seidel D"><surname>Seidel</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Manahilov V"><surname>Manahilov</surname> <given-names>V</given-names></string-name>. <article-title hwp:id="article-title-53">Image Jitter Enhances Visual Performance when Spatial Resolution Is Impaired</article-title>. <source hwp:id="source-44">Investig Opthalmology Vis Sci</source>. <year>2012</year> <month>Sep</month> <day>6</day>;<volume>53</volume>(<issue>10</issue>):<fpage>6004</fpage>.</citation></ref><ref id="c54" hwp:id="ref-54" hwp:rev-id="xref-ref-54-1"><label>54.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.54" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-54"><string-name name-style="western" hwp:sortable="Poletti M"><surname>Poletti</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Aytekin M"><surname>Aytekin</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rucci M"><surname>Rucci</surname> <given-names>M</given-names></string-name>. <article-title hwp:id="article-title-54">Head-Eye Coordination at a Microscopic Scale</article-title>. <source hwp:id="source-45">Curr Biol</source>. <year>2015</year>;<volume>25</volume>(<issue>24</issue>):<fpage>3253</fpage>–<lpage>9</lpage>.</citation></ref><ref id="c55" hwp:id="ref-55" hwp:rev-id="xref-ref-55-1"><label>55.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.55" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-55"><string-name name-style="western" hwp:sortable="Stevenson SB"><surname>Stevenson</surname> <given-names>SB</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sheehy CK"><surname>Sheehy</surname> <given-names>CK</given-names></string-name>, <string-name name-style="western" hwp:sortable="Roorda A"><surname>Roorda</surname> <given-names>A</given-names></string-name>. <article-title hwp:id="article-title-55">Binocular eye tracking with the Tracking Scanning Laser Ophthalmoscope</article-title>. <source hwp:id="source-46">Vision Res</source>. <year>2016</year>;<volume>118</volume>:<fpage>98</fpage>–<lpage>104</lpage>.</citation></ref><ref id="c56" hwp:id="ref-56" hwp:rev-id="xref-ref-56-1"><label>56.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.56" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-56"><string-name name-style="western" hwp:sortable="Arathorn DW"><surname>Arathorn</surname> <given-names>DW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Yang Q"><surname>Yang</surname> <given-names>Q</given-names></string-name>, <string-name name-style="western" hwp:sortable="Vogel CR"><surname>Vogel</surname> <given-names>CR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zhang Y"><surname>Zhang</surname> <given-names>Y</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tiruveedhula P"><surname>Tiruveedhula</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Roorda A"><surname>Roorda</surname> <given-names>A</given-names></string-name>. <article-title hwp:id="article-title-56">Retinally stabilized cone-targeted stimulus delivery</article-title>. <source hwp:id="source-47">Opt Express</source>. <year>2007</year> <month>Oct</month> <day>17</day>;<volume>15</volume>(<issue>21</issue>):<fpage>13731</fpage>.</citation></ref><ref id="c57" hwp:id="ref-57"><label>57.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.57" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-57"><string-name name-style="western" hwp:sortable="Yang Q"><surname>Yang</surname> <given-names>Q</given-names></string-name>, <string-name name-style="western" hwp:sortable="Arathorn DW"><surname>Arathorn</surname> <given-names>DW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tiruveedhula P"><surname>Tiruveedhula</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Vogel CR"><surname>Vogel</surname> <given-names>CR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Roorda A"><surname>Roorda</surname> <given-names>A</given-names></string-name>. <article-title hwp:id="article-title-57">Design of an integrated hardware interface for AOSLO image capture and cone-targeted stimulus delivery</article-title>. <source hwp:id="source-48">Opt Express</source>. <year>2010</year> <month>Aug</month> <day>16</day>;<volume>18</volume>(<issue>17</issue>):<fpage>17841</fpage>.</citation></ref><ref id="c58" hwp:id="ref-58" hwp:rev-id="xref-ref-58-1"><label>58.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.58" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-58"><string-name name-style="western" hwp:sortable="Mulligan JB"><surname>Mulligan</surname> <given-names>JB</given-names></string-name>. <article-title hwp:id="article-title-58">Recovery of motion parameters from distortions in scanned images</article-title>. <source hwp:id="source-49">Proc Image Regist Work</source>. <year>1997</year>;<fpage>281</fpage>–<lpage>92</lpage>.</citation></ref><ref id="c59" hwp:id="ref-59" hwp:rev-id="xref-ref-59-1"><label>59.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.59" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-59"><string-name name-style="western" hwp:sortable="Castet E"><surname>Castet</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Crossland M"><surname>Crossland</surname> <given-names>M</given-names></string-name>. <article-title hwp:id="article-title-59">Quantifying Eye Stability During a Fixation Task: A Review of Definitions and Methods</article-title>. <source hwp:id="source-50">Seeing Perceiving</source>. <year>2012</year>;<volume>25</volume>(<issue>5</issue>):<fpage>449</fpage>–<lpage>69</lpage>.</citation></ref><ref id="c60" hwp:id="ref-60" hwp:rev-id="xref-ref-60-1"><label>60.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.60" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-60"><string-name name-style="western" hwp:sortable="Botev ZI"><surname>Botev</surname> <given-names>ZI</given-names></string-name>, <string-name name-style="western" hwp:sortable="Grotowski JF"><surname>Grotowski</surname> <given-names>JF</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kroese DP"><surname>Kroese</surname> <given-names>DP</given-names></string-name>. <article-title hwp:id="article-title-60">Kernel density estimation via diffusion</article-title>. <source hwp:id="source-51">Ann Stat</source>. <year>2010</year> <month>Oct</month> <day>11</day>;<volume>38</volume>(<issue>5</issue>):<fpage>2916</fpage>–<lpage>57</lpage>.</citation></ref><ref id="c61" hwp:id="ref-61" hwp:rev-id="xref-ref-61-1"><label>61.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.61" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-61"><string-name name-style="western" hwp:sortable="Kwon M"><surname>Kwon</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Nandy AS"><surname>Nandy</surname> <given-names>AS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tjan BS"><surname>Tjan</surname> <given-names>BS</given-names></string-name>. <article-title hwp:id="article-title-61">Rapid and persistent adaptability of human oculomotor control in response to simulated central vision loss</article-title>. <source hwp:id="source-52">Curr Biol</source>. <year>2013</year>;<volume>23</volume>(<issue>17</issue>):<fpage>1663</fpage>–<lpage>9</lpage>.</citation></ref><ref id="c62" hwp:id="ref-62" hwp:rev-id="xref-ref-62-1"><label>62.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.62" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-62"><string-name name-style="western" hwp:sortable="Engbert R"><surname>Engbert</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kliegl R"><surname>Kliegl</surname> <given-names>R</given-names></string-name>. <article-title hwp:id="article-title-62">Microsaccades uncover the orientation of covert attention</article-title>. <source hwp:id="source-53">Vision Res</source>. <year>2003</year>;<volume>43</volume>(<issue>9</issue>):<fpage>1035</fpage>–<lpage>45</lpage>.</citation></ref><ref id="c63" hwp:id="ref-63" hwp:rev-id="xref-ref-63-1"><label>63.</label><citation publication-type="journal" citation-type="journal" ref:id="220319v1.63" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-63"><string-name name-style="western" hwp:sortable="Daniel RM"><surname>Daniel</surname> <given-names>RM</given-names></string-name>, <string-name name-style="western" hwp:sortable="De Stavola BL"><surname>De Stavola</surname> <given-names>BL</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cousens SN"><surname>Cousens</surname> <given-names>SN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Vansteelandt S"><surname>Vansteelandt</surname> <given-names>S</given-names></string-name>. <article-title hwp:id="article-title-63">Causal mediation analysis with multiple mediators</article-title>. <source hwp:id="source-54">Biometrics</source>. <year>2015</year>;<volume>71</volume>(<issue>1</issue>):<fpage>1</fpage>–<lpage>14</lpage>.</citation></ref></ref-list><sec sec-type="supplementary-material" id="s6" hwp:id="sec-12"><title hwp:id="title-15">Supplemental Figures</title><fig id="figS1" position="float" fig-type="figure" orientation="portrait" hwp:id="F5" hwp:rev-id="xref-fig-5-1 xref-fig-5-2 xref-fig-5-3 xref-fig-5-4 xref-fig-5-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;220319v1/FIGS1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">figS1</object-id><label>Figure S1</label><caption hwp:id="caption-5"><p hwp:id="p-38">Individual results from Experiment 1. (a) Proportion correct and all mediators quantified in the present study, binned based on gain. (b) Bootstrapping tuning curve fits (top) and optimal gains (bottom) for each subject by using binary data (correct vs incorrect). White lines represent the fits corresponding to median parameters. Shaded regions (top) represent 2.5-97.5% percentiles of the bootstrapped distributions of fitted curves. For each panel, bootstrapping was done by resampling the individual trial data with replacement 1000 times. Vertical dashed lines (bottom) represents the median optimal gains. The data from second run of S4 were combined with the first run and analyzed together, and are shown here in the rightmost panels.</p></caption><graphic xlink:href="220319_figS1" position="float" orientation="portrait" hwp:id="graphic-6"/></fig><fig id="figS2" position="float" fig-type="figure" orientation="portrait" hwp:id="F6" hwp:rev-id="xref-fig-6-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;220319v1/FIGS2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">figS2</object-id><label>Figure S2</label><caption hwp:id="caption-6"><p hwp:id="p-39">Analyses of microsaccades. <bold>(a)</bold> Amplitude and direction distribution of microsaccades, combined across seven subjects, in Experiment 1. <bold>(b)</bold> The retinal position of the stimuli at the start (black squares) and end (red circles) of microsaccades. Clearly, the primary role of microsaccades was redirecting gaze to compensate for non-homogeneous vision. <bold>(c)</bold> Retinal image velocity just before microsaccades. The blue and red lines represent downward and upward microsaccades (within ±45° from vertical was considered as upward). <bold>(d)</bold> Retinal position of the stimuli across microsaccades. In <bold>(c)</bold> and <bold>(d)</bold>, the panels on the left and right represent data from horizontal and vertical component of the eye movements, respectively.</p></caption><graphic xlink:href="220319_figS2" position="float" orientation="portrait" hwp:id="graphic-7"/></fig><fig id="figS3" position="float" fig-type="figure" orientation="portrait" hwp:id="F7" hwp:rev-id="xref-fig-7-1 xref-fig-7-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;220319v1/FIGS3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F7</object-id><object-id pub-id-type="publisher-id">figS3</object-id><label>Figure S3</label><caption hwp:id="caption-7"><p hwp:id="p-40">Ocular drifts under normal viewing conditions. To qualitatively test the assumption that drifts are cyclic motions within the time scale of typical fixation (~300 ms), we randomly sampled 20 eye position traces from three subjects in the zero-gain condition, and computed the power spectra of both the horizontal and vertical components in <bold>(a)</bold> a 300 ms and <bold>(b)</bold> ~900 ms time windows. If indeed, drifts show three to five cycles per ~300 ms, this should be visible as clear peaks in the power spectra, and disappear when power spectra are computed over a longer time scale. However, except for a few cases, we did not encounter such motions. For some subjects, much lower-frequency fluctuations were visible, but these fluctuations are too slow to be of any use for fast and efficient temporal encoding. For this particular figure, eye position traces were further filtered with a low-pass filter with a cut-off frequency of 25 Hz. Power spectra are shown with a linear frequency axis with limits from 3 to 30 Hz.</p></caption><graphic xlink:href="220319_figS3" position="float" orientation="portrait" hwp:id="graphic-8"/></fig><fig id="figS4" position="float" fig-type="figure" orientation="portrait" hwp:id="F8" hwp:rev-id="xref-fig-8-1 xref-fig-8-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;220319v1/FIGS4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F8</object-id><object-id pub-id-type="publisher-id">figS4</object-id><label>Figure S4</label><caption hwp:id="caption-8"><p hwp:id="p-41">Contributions of gain and mediators in explaining variance. <bold>(a)</bold> Change in (left) explained variance, (middle) log-likelihood, and (right) BIC with addition of mediators. Note that the sign of ΔBIC is flipped so that red color represents superiority of a model on the vertical axis with respect to another one on the horizontal axis. G: Gain, R: retinal ISOA, E: eye ISOA, P: PRL eccentricity, M: microsaccade rate. <bold>(b)</bold> Can mediators fully account for the effects of gain? Here, we explicitly tested whether having gain in addition to mediators improve statistical models substantially. The right diagonal in each panel represents the exact contribution of the gain term. The red squares represent the final model in the mediation analysis (G+G<sup>2</sup>+R+E+P) (<bold><xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-2" hwp:rel-id="F4">Fig. 4d</xref></bold>). In general, adding gain was helpful only when there are three or less mediators in the regression model.</p></caption><graphic xlink:href="220319_figS4" position="float" orientation="portrait" hwp:id="graphic-9"/></fig></sec></back></article>
