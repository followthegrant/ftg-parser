<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/2021.09.08.459546</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;2021.09.08.459546</article-id><article-id pub-id-type="other" hwp:sub-type="slug">2021.09.08.459546</article-id><article-id pub-id-type="other" hwp:sub-type="atom-slug">2021.09.08.459546</article-id><article-id pub-id-type="other" hwp:sub-type="tag">2021.09.08.459546</article-id><article-version>1.2</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Neuroscience" hwp:journal="biorxiv"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">Humans reconfigure target and distractor processing to address distinct task demands</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1"><label>*</label><italic toggle="yes">Corresponding author:</italic> <email hwp:id="email-1">harrison.ritz@gmail.com</email></corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" corresp="yes" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-3011-2946</contrib-id><name name-style="western" hwp:sortable="Ritz Harrison"><surname>Ritz</surname><given-names>Harrison</given-names></name><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*</xref><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-3011-2946"/></contrib><contrib contrib-type="author" hwp:id="contrib-2"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0222-0774</contrib-id><name name-style="western" hwp:sortable="Shenhav Amitai"><surname>Shenhav</surname><given-names>Amitai</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-2" hwp:rel-id="aff-2">2</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-0222-0774"/></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2"><label>1</label><institution hwp:id="institution-1">Cognitive, Linguistic &amp; Psychological Science, Brown University</institution>, Providence, RI</aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1 xref-aff-2-2"><label>2</label><institution hwp:id="institution-2">Carney Institute for Brain Science, Brown University</institution>, Providence, RI</aff></contrib-group><pub-date pub-type="epub-original" date-type="pub" publication-format="electronic" hwp:start="2021"><year>2021</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2021-09-10T11:09:13-07:00">
    <day>10</day><month>9</month><year>2021</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2021-10-26T17:57:16-07:00">
    <day>26</day><month>10</month><year>2021</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2021-09-10T11:14:12-07:00">
    <day>10</day><month>9</month><year>2021</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2021-10-26T18:03:02-07:00">
    <day>26</day><month>10</month><year>2021</year>
  </pub-date><elocation-id>2021.09.08.459546</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2021-09-08"><day>08</day><month>9</month><year>2021</year></date>
<date date-type="rev-recd" hwp:start="2021-10-26"><day>26</day><month>10</month><year>2021</year></date>
<date date-type="accepted" hwp:start="2021-10-26"><day>26</day><month>10</month><year>2021</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2021</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nd/4.0/" hwp:id="license-1"><p hwp:id="p-1">This pre-print is available under a Creative Commons License (Attribution-NoDerivs 4.0 International), CC BY-ND 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by-nd/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nd/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by-nd/4.0/</ext-link></p></license></permissions><self-uri xlink:href="459546.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2021/pdf/2021.09.08.459546v2.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="459546.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2021/abstracts/2021.09.08.459546v2/2021.09.08.459546v2.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2021/fulltext/2021.09.08.459546v2/2021.09.08.459546v2.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-2">When faced with distraction, we can focus more on goal-relevant information (targets) or focus less goal-conflicting information (distractors). How people decide to distribute cognitive control across targets and distractors remains unclear. To help address this question, we developed a parametric attentional control task that can index both target discriminability and distractor interference. We find that participants exert independent control over target and distractor processing. We measured control adjustments through the influence of incentives and previous conflict on target and distractor sensitivity, finding that these have dissociable influences on control. Whereas incentives preferentially led to target enhancement, conflict on the previous trial preferentially led to distractor suppression. These distinct drivers of control altered sensitivity to targets and distractors early in the trial, promptly followed by reactive reconfiguration towards task-appropriate feature sensitivity. Finally, we provide a process-level account of these findings by show that these control adjustments are well-captured by an evidence accumulation model with attractor dynamics over feature weights. These results help establish a process-level account of control configuration that provides new insights into how multivariate attentional signals are optimized to achieve task goals.</p></abstract><counts><page-count count="45"/></counts><custom-meta-wrap><custom-meta hwp:id="custom-meta-1"><meta-name>special-property</meta-name><meta-value>contains-inline-supplementary-material</meta-value></custom-meta></custom-meta-wrap><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-2">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta><notes hwp:id="notes-1"><notes notes-type="competing-interest-statement" hwp:id="notes-2"><title hwp:id="title-2">Competing Interest Statement</title><p hwp:id="p-3">The authors have declared no competing interest.</p></notes></notes></front><body><sec id="s1" hwp:id="sec-1"><title hwp:id="title-3">Introduction</title><p hwp:id="p-4">Whether we are having a conversation in a crowded coffee shop or writing a paper at our desk while surrounded by browser tabs, most tasks require us to engage in two distinct forms of control. One form of control supports the processing of task-<italic toggle="yes">relevant</italic> information, for instance by paying careful attention to what our conversation partner is sharing with us. The other form of control suppresses the processing of task-<italic toggle="yes">irrelevant</italic> information, particularly that which conflicts with our primary goal (e.g., distraction from a nearby conversation). While past research has extensively studied the processes underpinning these two loci of control, it has done so primarily by focusing on each one separately. As a result, relatively little is known about how control over task-relevant information (targets) interacts with control over task-irrelevant information (distractors), and under what situations one would be prioritized over the other. Here, we bridge previous methodological gaps to gain new insight into how control is differentially allocated to achieve these aims, and provide an integrative model that accounts for the dynamics by which these two forms of control are adjusted within and across trials.</p><p hwp:id="p-5">Research into how people enhance the target of their attention versus actively suppress distractors has been largely governed by separate research areas, using different approaches. Studies of perceptual decision-making have characterized the process by which people try to determine the correct response (e.g., which of two categories this stimulus belongs to) based on noisy information about a target stimulus, and how this varies with the difficulty of discriminating that stimulus (e.g., how perceptually similar two stimuli are; <xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">Britten et al., 1992</xref>; <xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">Gold and Shadlen, 2007</xref>). This contrasts with studies of inhibitory control, in which the correct response to a target is typically unambiguous (e.g., respond left when seeing a high-contrast leftward-facing arrow), but a second dimension of the stimulus display (one that is typically processed more automatically; e.g., flanking arrows pointing rightward) triggers a conflicting response (<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">Botvinick and Cohen, 2014</xref>; <xref ref-type="bibr" rid="c38" hwp:id="xref-ref-38-1" hwp:rel-id="ref-38">Posner and Snyder, 1975</xref>).</p><p hwp:id="p-6">Despite the substantial progress that has been made in understanding these two processes in parallel, critical questions remain that can only be addressed by studying them in tandem (<xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-1" hwp:rel-id="ref-44">Ritz et al., 2021</xref>). Most notably, it is unclear how people decide how to distribute their control between targets and distractors. When the demands or incentives for performing a task change, do people re-direct control towards target enhancement, distractor suppression, or both? For instance, previous work has shown that people are less susceptible to the influence of distractors after overcoming a previously conflicting distractor (the so-called <italic toggle="yes">conflict adaptation</italic> or <italic toggle="yes">congruency sequence</italic> effect; <xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">Egner, 2007</xref>; <xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">Gratton et al., 1992</xref>). Prevailing models have accounted for these findings by assuming that participants increase attention to the target dimension following a high-conflict trial (<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">Botvinick et al., 2001</xref>; <xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-2" hwp:rel-id="ref-15">Egner, 2007</xref>; <xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">Egner et al., 2007</xref>), but limitations of the relevant experiments (in particular, that their focus on variability in distractor congruency) make it difficult to rule out that adaptation is occurring at the level of distractor suppression instead (<xref ref-type="bibr" rid="c29" hwp:id="xref-ref-29-1" hwp:rel-id="ref-29">Lindsay and Jacoby, 1994</xref>; <xref ref-type="bibr" rid="c55" hwp:id="xref-ref-55-1" hwp:rel-id="ref-55">Soutschek et al., 2015</xref>; <xref ref-type="bibr" rid="c59" hwp:id="xref-ref-59-1" hwp:rel-id="ref-59">Tzelgov et al., 1992</xref>). It is more generally an open question whether effects of recent task difficulty (e.g., low discriminability or high-conflict) result in control-specific or control-general adaptations and, similarly, whether the motivation to improve performance in such settings leads to preferential engagement of one or both forms of control.</p><p hwp:id="p-7">More recent models of controlled decision-making have emphasized the role that within-trial attentional dynamics play in response conflict tasks, offering new insight into the implementation of cognitive control (<xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-1" hwp:rel-id="ref-49">Servant et al., 2014</xref>; <xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-1" hwp:rel-id="ref-62">Weichart et al., 2020</xref>; <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-1" hwp:rel-id="ref-64">White et al., 2011</xref>; <xref ref-type="bibr" rid="c69" hwp:id="xref-ref-69-1" hwp:rel-id="ref-69">Yu et al., 2009</xref>). These models have largely been used for the Eriksen flanker task, modelling how an attentional spotlight centered on the target item narrows over time. This formulation necessarily yokes target enhancement and distractor suppression due to the spatial spread of attention. As a result, little is known about whether target and distractor processing dynamics can fall under independent control when these are not explicitly yoked, as in the case of feature-based attention. Less still is known about how adjustments driven by factors like conflict adaptation and incentives alter the <italic toggle="yes">dynamics</italic> of target and distractor processing (<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">Adkins and Lee, 2021</xref>).</p><p hwp:id="p-8">To address these questions, we developed a novel task that orthogonally varies target and distractor information, measuring how processing of these two dimensions varies both within and across trials. Our task merges elements of paradigms that have been separately popularized within the two research areas above. To capture variability in target processing, we based our task on the random dot kinematogram paradigm (<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">Danielmeier et al., 2011</xref>; <xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">Kang et al., 2021</xref>; <xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="c52" hwp:id="xref-ref-52-1" hwp:rel-id="ref-52">Shenhav et al., 2018</xref>). This task parametrically varies the motion discriminability (e.g., percentage of dots moving left) and color discriminability (e.g., percentage of green dots) across an array of dots. Participants were instructed to respond to the color dimension, while ignoring the motion dimension. Critically, whereas color response mappings were arbitrary (e.g., left hand for green), motion responses were exactly aligned with the direction of motion (e.g., left hand for leftward moving stimuli), resulting in potent “Simon-like” response interference from this prepotent distractor. Previous work has shown that this paradigm elicits response conflict and trial-to-trial adjusts for binary conflict (<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-2" hwp:rel-id="ref-13">Danielmeier et al., 2011</xref>), and our current approach extends these previous findings by parametrizing both target coherence and distractor congruence to gain new insight into feature-selective control.</p><p hwp:id="p-9">We find that participants independently and dynamically control target and distractor processing within a trial. Participants preferentially enhance target sensitivity under incentives, and preferentially suppress distractor sensitivity after high conflict trials. Moreover, they implement these control configurations by changing the initial conditions of feature processing dynamics. Finally, we find that these control strategies can be captured by extending classic neural network models of cognitive control to incorporate attractor dynamics that independently regulate the attentional priority of different task features. Together, these results extend our understanding of both decision-making and cognitive control by bridging the methodological and theoretical divides between these fields, providing new assays and process models for the top-down control of information processing.</p></sec><sec id="s2" hwp:id="sec-2"><title hwp:id="title-4">Results</title><p hwp:id="p-10">Participants performed the Parametric Attentional Control Task (PACT), a perceptual discrimination task that required them to classify the dominant color in an array of moving dots (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1a</xref>). Participants made bimanual responses, for example responding with their left hand when the dominant color was purple or blue or responding with their right hand when the dominant color was green or beige. Across trials, we varied the extent to which those dots were coherently moving in the same or opposite direction as the correct response (distractor interference; Experiments 1-3) and how easily the participant could determine the dominant color (target discriminability; Experiments 2-3; <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Figure 1b</xref>). Participants performed the main <italic toggle="yes">Attend-Color</italic> PACT in blocks of 100 trials. To enhance the potency of motion as a distracting dimension (<xref ref-type="bibr" rid="c53" hwp:id="xref-ref-53-1" hwp:rel-id="ref-53">Shiffrin and Schneider, 1977</xref>) and allow for additional measures of automaticity and feature-specificity, participants alternated between these blocks-of-interest and shorter blocks (20-50 trials) in which participants instead responded to the direction of dot motion (<italic toggle="yes">Attend-Motion</italic> PACT; <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-3" hwp:rel-id="F1">Figure 1c</xref>).</p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2 xref-fig-1-3 xref-fig-1-4 xref-fig-1-5 xref-fig-1-6 xref-fig-1-7"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1.</label><caption hwp:id="caption-1"><title hwp:id="title-5">Parametric Attentional Control Task (PACT).</title><p hwp:id="p-11"><bold>A)</bold> On each trial, participants responded to the dominant color in a bivalent random dot kinematogram. This stimulus had a random color (target) coherence, depending on the proportion of dots that were in the majority. This stimulus also had a random motion (distractor) congruence, depending on motion coherence in the same or opposite direction as the color response. <bold>B)</bold> Across trials, we parametrically and independently varied the coherence of the dominant color (y-axis) and the congruence of the motion direction (x-axis). <bold>C)</bold> In experiments 1 and 2, participants alternated between longer blocks of Attend-Color trials (target dimension was color, as in A) and shorter blocks of Attend-Motion trials (target dimension was motion). Participants took a self-timed break between blocks. <bold>D)</bold> In experiment 3, participants alternated between pairs of Reward blocks and No Reward blocks. On Reward blocks, participants could earn a monetary bonus if they were fast and accurate, whereas we just encourage good performance on No Reward blocks. Participants were informed of the reward condition during their break between blocks.</p></caption><graphic xlink:href="459546v2_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><sec id="s2a" hwp:id="sec-3"><title hwp:id="title-6">Task performance varies parametrically with target discriminability and distractor interference</title><p hwp:id="p-12">In Experiment 1 (N = 56), participants performed the PACT with uniformly colored dots (e.g., all blue or all green), but with the dots moving in a direction either congruent or incongruent with that target response. We varied the strength of this distractor dimension between being fully congruent with the correct color response (100% leftward coherence for a left color response) to being fully incongruent (100% rightward coherence for a left color response; <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-4" hwp:rel-id="F1">Figure 1b</xref>). For trials mid-way between these two extremes (cf. ‘neutral’ trials), the dots did not move consistently in one direction or another (0% motion coherence).</p><p hwp:id="p-13">Consistent with past research on cognitive control, we found that participants were slowest and least accurate when distractors were fully incongruent (median RT = 585ms, mean accuracy = 89%) and fastest and most accurate were fully congruent (median RT = 553ms, mean accuracy = 97%; cf. <xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-3" hwp:rel-id="ref-13">Danielmeier et al., 2011</xref>). Performance on neutral trials (0% motion coherence) fell between these two extremes (median RT = 576ms, mean accuracy = 94%). Extending this work, hierarchical regression analyses (see Methods) revealed that performance varied in a graded fashion across this continuum of interference. Both accuracy (Cohen’s <italic toggle="yes">d</italic> on regression estimate; <italic toggle="yes">d</italic> = −1.47) and reaction time (<italic toggle="yes">d</italic> = 1.25) worsened with parametrically increasing levels of interference (<italic toggle="yes">p</italic>s &lt; 0.001, <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-5" hwp:rel-id="F1">Figure 1c</xref>, <xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-1" hwp:rel-id="T1">Table 1</xref>).</p><table-wrap id="tbl1" orientation="portrait" position="float" hwp:id="T1" hwp:rev-id="xref-table-wrap-1-1 xref-table-wrap-1-2 xref-table-wrap-1-3 xref-table-wrap-1-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBL1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">tbl1</object-id><label>Table 1.</label><caption hwp:id="caption-2"><title hwp:id="title-7">Target and distractor sensitivity</title></caption><graphic xlink:href="459546v2_tbl1" position="float" orientation="portrait" hwp:id="graphic-2"/><graphic xlink:href="459546v2_tbl1a" position="float" orientation="portrait" hwp:id="graphic-3"/></table-wrap><p hwp:id="p-14">In Experiment 2 (N = 40) and Experiment 3 (N = 60), participants performed the same task as in Experiment 1, but we additionally varied the discriminability of the target (color) dimension. Across trials, the proportion of the majority color (<italic toggle="yes">color coherence</italic>) varied parametrically to make color discrimination easier (higher coherence) or more difficult (lower coherence). As in Experiment 1, the level of motion interference also varied across trials, independently of targets.</p><p hwp:id="p-15">Consistent with past research on perceptual decision-making (<xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-2" hwp:rel-id="ref-7">Britten et al., 1992</xref>; <xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-2" hwp:rel-id="ref-31">Mante et al., 2013</xref>), we found that discrimination performance improved with higher levels of target discriminability. Participants in both studies were faster (Exp 2: <italic toggle="yes">d</italic> = −1.90, Exp 3: <italic toggle="yes">d</italic> = −1.99) and more accurate (Exp 2: <italic toggle="yes">d</italic> = 3.27, Exp 3: <italic toggle="yes">d</italic> = 3.73) with parametrically increasing levels of color coherence (aggregate <italic toggle="yes">p</italic>s &lt; 0.001; <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2a</xref>, <xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-2" hwp:rel-id="T1">Table 1</xref>). At the same time, we continued to find that participants were slower and less accurate when the goal-irrelevant movement of those dots was increasingly incongruent with the correct color response (see <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2b</xref>, <xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-3" hwp:rel-id="T1">Table 1</xref>).</p><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2.</label><caption hwp:id="caption-3"><title hwp:id="title-8">Target and distractor sensitivity.</title><p hwp:id="p-16"><bold>A)</bold> Participants were more accurate (blue, left axis) and responded faster (red, right axis) when the target color had higher coherence. Lines depict aggregated regression predictions. In all graphs, behavior and regression predictions are averaged over participants and experiments. <bold>B)</bold> Regression estimates for the effect of target coherence on performance within each experiment, plotted for accuracy (blue, left axis) and RT (red, right axis). <bold>C)</bold> Participants were more accurate and responded faster when the distracting motion had higher congruence (coherence signed relative to target response). In all graphs, behavior and regression predictions are averaged over participants and experiments. <bold>D)</bold> Regression estimates for the effect of distractor congruence on performance within each experiment, plotted for accuracy and RT. <bold>E-F)</bold> Similar to A-B, performance (E) and regression estimates (F) for the effects of target coherence during Attend-Motion blocks, in which motion was the target dimension. <bold>G-H)</bold> Similar to A-B, performance (G) and regression estimates (H) for the effects of distractor congruence during Attend-Motion blocks, in which color was the distractor dimension. Error bars on behavior reflect within-participant SEM, error bars on regression coefficients reflect 95% CI.</p></caption><graphic xlink:href="459546v2_fig2" position="float" orientation="portrait" hwp:id="graphic-4"/></fig><p hwp:id="p-17">Performance on our task varied parametrically with both color coherence and motion coherence, but these two coherence manipulations were designed to exert their influence on performance in different ways. Whereas variability in color coherence was intended to influence the stimulus uncertainty directly relevant to goal-directed decision-making (i.e., determining which response is the correct one), motion coherence was intended to exert a more automatic influence on response selection by facilitating responses consistent with the direction of motion. We confirmed this assumption regarding the relative automaticity of motion versus color processing by having participants perform interleaved blocks in which they responded based on motion and ignored color (‘Attend-Motion’). We found that participants were more sensitive to the now-relevant motion coherence, but were no longer sensitive to the now-irrelevant color congruence (<xref rid="tblS1" ref-type="table" hwp:id="xref-table-wrap-7-1" hwp:rel-id="T7">Supplementary Table 1</xref>-<xref ref-type="table" rid="tblS2" hwp:id="xref-table-wrap-8-1" hwp:rel-id="T8">2</xref>). This asymmetry suggests that participants’ decisions were not solely driven by the bottom-up salience of these features, as participants were more sensitive to color when it was relevant and less sensitive to motion when it was irrelevant, reflecting differential engagement of top-down control across the two tasks (<xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">Cohen et al., 1992</xref>).</p></sec><sec id="s2b" hwp:id="sec-4"><title hwp:id="title-9">Target discrimination and distractor interference occur in parallel</title><p hwp:id="p-18">We found that participants’ task performance varied parametrically with both the target discriminability and distractor congruence, both for choice and reaction time. We next sought to further understand the relationships between these changes in performance, within and across features.</p><p hwp:id="p-19">First, we tested whether a given feature exerted a similar influence on both accuracy and RT. We found that this was indeed the case, as there was a significant correlation between the effect distractors had on accuracy and RT (<italic toggle="yes">r</italic>s &lt; −0.87, <italic toggle="yes">p</italic>s &lt; 0.001). The influences of target discriminability on accuracy and RT were also significantly correlated (<italic toggle="yes">r</italic>s &lt; −0.54, <italic toggle="yes">p</italic>s &lt; 0.001; <xref rid="tblS3" ref-type="table" hwp:id="xref-table-wrap-9-1" hwp:rel-id="T9">Supplementary Table 3</xref>). Thus, participants who became faster with higher levels of a given feature’s strength also became more accurate, suggesting that accuracy and RT shared a common underlying process (e.g., evidence accumulation rate, which we return to below).</p><p hwp:id="p-20">Second, we tested whether the influences of target discriminability and distractor congruence on performance were independent (e.g., distractors and targets are processed in parallel; <xref ref-type="bibr" rid="c29" hwp:id="xref-ref-29-2" hwp:rel-id="ref-29">Lindsay and Jacoby, 1994</xref>; <xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-2" hwp:rel-id="ref-49">Servant et al., 2014</xref>) or instead modulatory (e.g., distractor congruence influences target sensitivity). If the two forms of feature processing modulated one another, we would predict that target and distractor coherence would interact in predicting performance. We did not find such an interaction in RTs (<italic toggle="yes">d</italic>s = 0.05 to 0.23, <italic toggle="yes">p</italic> = 0.33; <xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-4" hwp:rel-id="T1">Table 1</xref>), though we did find a small but significant interaction between target and distractor coherence on accuracy (<italic toggle="yes">d</italic>s = − 0.18 to −0.34, <italic toggle="yes">p</italic> = 0.023). For both studies, removing target-distractor interactions as predictors in our accuracy regressions improved model fit (Protected exceedance probability on AIC: Exp 2 PXP = 1; Exp 3 PXP = 1). If distractors had an antagonistic influence on target processing, we would also predict that target and distractor sensitivity would be negatively correlated across subjects. Contrary to this prediction, these effects were either not significantly correlated or positively correlated, both for RT (Exp 2: <italic toggle="yes">r</italic>(25) = .14, <italic toggle="yes">p</italic> = .48; Exp 3: <italic toggle="yes">r</italic>(45) = .44, <italic toggle="yes">p</italic> = .0019) and accuracy (Exp 2: <italic toggle="yes">r</italic>(25) = −.15, <italic toggle="yes">p</italic> = .45; Exp 3: <italic toggle="yes">r</italic>(45) = .12, <italic toggle="yes">p</italic> = .43), suggesting that individual differences in target and distractor processing were not antagonistic.</p></sec><sec id="s2c" hwp:id="sec-5"><title hwp:id="title-10">Previous conflict preferentially suppresses distractor sensitivity</title><p hwp:id="p-21">Within a given trial, we found that performance varies parametrically and independently with the coherence of target and distractor features. We next sought to understand how participants adapted their information processing <italic toggle="yes">across</italic> trials, to provide insight into the control processes that guide performance in this task. We measured how participants’ feature sensitivity changed after difficult (e.g., more incongruent) trials, an index of cognitive control known as conflict adaptation (<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-3" hwp:rel-id="ref-15">Egner, 2007</xref>; <xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-2" hwp:rel-id="ref-20">Gratton et al., 1992</xref>). The classic effect is that participants show weaker congruence effects after incongruent trials than after congruent trials, with the traditional interpretation being that this reflects upregulated target sensitivity (<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-2" hwp:rel-id="ref-4">Botvinick et al., 2001</xref>; <xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-4" hwp:rel-id="ref-15">Egner, 2007</xref>). Our task allowed us to build on this work to test whether this adaptation effect varies parametrically with distractor congruence. Critically, we can also test whether adaptation occurs through an influence of previous conflict on subsequent target enhancement, distractor suppression, or both. Finally, we can further test whether adaptation occurs due to the discriminability of the <italic toggle="yes">target</italic> on the previous trial.</p><p hwp:id="p-22">Across all three of our studies, we found that participants’ sensitivity to the distractor dimension was robustly and parametrically influenced by the distractor congruence on the previous trial, as reflected both in their choice (<italic toggle="yes">d</italic>s = 1.44 to 1.74, <italic toggle="yes">p</italic> &lt; .001; <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure 3a</xref>) and RT (<italic toggle="yes">d</italic>s = 0.83 to 1.79, <italic toggle="yes">p</italic> &lt; .001; <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Figure 3b</xref>; <xref rid="tbl2" ref-type="table" hwp:id="xref-table-wrap-2-1" hwp:rel-id="T2">Table 2</xref>). When the previous trial had congruent distractors, participants had strong sensitivity to the distractor congruence (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Figure 3a-b</xref>, navy). When the previous trial had incongruent distractors, participants were much less sensitive to distractors (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-4" hwp:rel-id="F3">Figure 3a-b</xref>, red). These patterns are consistent with those typically observed in studies of conflict adaptation (<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-4" hwp:rel-id="ref-13">Danielmeier et al., 2011</xref>; <xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-5" hwp:rel-id="ref-15">Egner, 2007</xref>), and further demonstrate gradations within these classic effects.</p><table-wrap id="tbl2" orientation="portrait" position="float" hwp:id="T2" hwp:rev-id="xref-table-wrap-2-1 xref-table-wrap-2-2 xref-table-wrap-2-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBL2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T2</object-id><object-id pub-id-type="publisher-id">tbl2</object-id><label>Table 2.</label><caption hwp:id="caption-4"><title hwp:id="title-11">Effects of previous conflict on feature sensitivity</title></caption><graphic xlink:href="459546v2_tbl2" position="float" orientation="portrait" hwp:id="graphic-5"/><graphic xlink:href="459546v2_tbl2a" position="float" orientation="portrait" hwp:id="graphic-6"/></table-wrap><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3 xref-fig-3-4 xref-fig-3-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3.</label><caption hwp:id="caption-5"><title hwp:id="title-12">Distractor-dependent adaptation.</title><p hwp:id="p-23"><bold>A-B)</bold> The relationship between distractor congruence and accuracy (A) and RT (B) was weaker when the previous trial was more incongruent (redder colors). Lines depict aggregated regression predictions. <bold>C)</bold> Regression estimates for the current distractor congruence by previous distractor congruence interaction, within each experiment. <bold>D-E)</bold> The relationship between target coherence and performance was stronger after more incongruent trials in accuracy (D) but not RT (E). <bold>F)</bold> Regression estimates for the current target coherence by previous distractor congruence interaction, within each experiment. Error bars on behavior reflect within-participant SEM, error bars on regression coefficients reflect 95% CI.</p></caption><graphic xlink:href="459546v2_fig3" position="float" orientation="portrait" hwp:id="graphic-7"/></fig><p hwp:id="p-24">When varying both target and distractor features (Experiments 2-3), we found an additional influence of previous distractor congruence on target processing, whereby more incongruent previous trials enhanced the influence of target discriminability on the current trial (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-5" hwp:rel-id="F3">Figure 3d-e</xref>). However, the influence of previous distraction on target processing was substantially smaller than its effect on distractor processing (see <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Figure 5</xref>), and was only found for accuracy (<italic toggle="yes">p</italic> &lt; .001) and not RT (<italic toggle="yes">p</italic> = .57), Finally, we found that performance adapted to the strength of the previous <italic toggle="yes">target</italic>, with less-discriminable targets yielding <italic toggle="yes">lower</italic> sensitivity to target strength (i.e., poorer performance) on the following trial, potentially due to disengagement (<xref rid="figS2" ref-type="fig" hwp:id="xref-fig-13-1" hwp:rel-id="F13">Supplementary Figure 2</xref>, <xref rid="tbl2" ref-type="table" hwp:id="xref-table-wrap-2-2" hwp:rel-id="T2">Table 2</xref>). However, like the distractor-target effect, this target-target effect was much smaller than the distractor-distractor effects and only observable in accuracy (<italic toggle="yes">p</italic> &lt; .001) and not RT (<italic toggle="yes">p</italic> = .19).</p><p hwp:id="p-25">A common concern when measuring conflict adaptation effects is the extent to which these reflect control adjustment (as typically assumed) or low-level priming that can occur due to stimulus-stimulus or stimulus-response associations (<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">Braem et al., 2019</xref>; <xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">Hommel et al., 2004</xref>; <xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">Mayr et al., 2003</xref>; <xref ref-type="bibr" rid="c48" hwp:id="xref-ref-48-1" hwp:rel-id="ref-48">Schmidt and De Houwer, 2011</xref>). For example, in some tasks, if two adjacent trials are both congruent or both incongruent, they are also more likely to share stimulus-response mappings, biasing analyses of sequential adaptation. Our experiment was designed to largely avoid this potential confound by eliminating stimulus-stimulus repetitions (with two colors assigned to each response hand that never repeat), and by using stochastic motion stimuli (versus, e.g., static arrows) that also have very infrequent exact repetitions (probability of coherence repetition is ∼9%).</p><p hwp:id="p-26">However, to further rule out that our key adaptation findings resulted from priming effects, we tested whether adaptation effects were present in our more automatic Attend-Motion blocks. Whereas a priming account would predict similar (within-feature) adaptation effects across both Attend-Color and Attend-Motion blocks, a cognitive control account would predict weaker adaptation effects for Attend-Motion than Attend-Color blocks. We found that adaptation effects during Attend-Motion blocks were overall weak and inconsistently signed (e.g., previous interference led to either increased or decreased sensitivity to distractors across studies; <xref rid="tblS4" ref-type="table" hwp:id="xref-table-wrap-10-1" hwp:rel-id="T10">Supplementary Table 4</xref>-<xref ref-type="table" rid="tblS5" hwp:id="xref-table-wrap-11-1" hwp:rel-id="T11">5</xref>). Comparing the adaptation effects across the two types of blocks directly, we found significantly stronger adaptation effects during Attend-Color than Attend-Motion blocks, both for distractors (distractor-distractor adaptation; Choice: <italic toggle="yes">p</italic> &lt; .001; RT: <italic toggle="yes">p</italic> &lt; .001) and for motion (target-target adaptation; Choice: <italic toggle="yes">p</italic> &lt; .001; RT: <italic toggle="yes">p</italic> = .34; <xref rid="tblS5" ref-type="table" hwp:id="xref-table-wrap-11-2" hwp:rel-id="T11">Supplementary Table 5</xref>). Together, these results suggest that the adaptation effects we observed during Attend-Color trials likely reflected changes in control states rather than stimulus-driven priming.</p><p hwp:id="p-27">In addition to affecting sensitivity of choices and RTs to individual features (adaptation effects described above), we found that previous target and distractor information also exerted a small but reliable influence on the likelihood that the participant would respond randomly on the next trial (<italic toggle="yes">lapse rates</italic>). Specifically, higher levels of distractor incongruence and lower levels of target discriminability increased subsequent lapse rates (<italic toggle="yes">p</italic>s &lt; .001; <xref rid="tbl2" ref-type="table" hwp:id="xref-table-wrap-2-3" hwp:rel-id="T2">Table 2</xref>), though these changes were subtle (e.g., post-congruent lapse rates ranged from 0.023% to 0.13% across studies; post-incongruent lapse rates ranged from 0.13% to 0.41% across studies). We did not otherwise find consistent main effects of previous targets and distractors on choice behavior (i.e., in the direction of a particular response) or on RT.</p></sec><sec id="s2d" hwp:id="sec-6"><title hwp:id="title-13">Performance incentives preferentially enhance target sensitivity</title><p hwp:id="p-28">We found that performance on our task adapted to previous distractor-related interference, and that this influence was observed primarily in subsequent processing of the distractor rather than the target. This may reflect a fundamental bias in the control system towards adjusting distractor processing in our task, but it may also reflect a process that is specialized for conflict adaptation. To disentangle these possibilities, we examined how target and distractor processing are influenced by heightened levels of motivation. In Experiment 3 we incorporated an incentive manipulation, with blocks of trials for which participants could either earn a monetary reward for fast and accurate performance, and blocks where performance was not rewarded (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-6" hwp:rel-id="F1">Figure 1d</xref>).</p><p hwp:id="p-29">We found that participants’ accuracy was more sensitive to target discriminability in rewarded blocks than non-rewarded blocks (<italic toggle="yes">d</italic> = 0.61, <italic toggle="yes">p</italic> &lt; .001; <xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Figure 4a</xref>, <xref rid="tbl3" ref-type="table" hwp:id="xref-table-wrap-3-1" hwp:rel-id="T3">Table 3</xref>), but they did not significantly differ in their sensitivity to distractors (<italic toggle="yes">d</italic> = −0.016, <italic toggle="yes">p</italic> = 0.91). This effect of incentives on target sensitivity was specific to accuracy and not RTs (<italic toggle="yes">d</italic> = −0.10, <italic toggle="yes">p</italic> = 0.47), though participants were overall faster in rewarded blocks (<italic toggle="yes">d</italic> = −0.41, <italic toggle="yes">p</italic> = 0.0045). In terms of distractors, we found that in rewarded blocks participants were less sensitive to distractors in RT (<italic toggle="yes">d</italic> = 0.35, <italic toggle="yes">p</italic> = 0.012), albeit with a small effect size, and no effect on accuracy (<italic toggle="yes">d</italic> = −0.10, <italic toggle="yes">p</italic> = 0.47).</p><table-wrap id="tbl3" orientation="portrait" position="float" hwp:id="T3" hwp:rev-id="xref-table-wrap-3-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBL3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T3</object-id><object-id pub-id-type="publisher-id">tbl3</object-id><label>Table 3.</label><caption hwp:id="caption-6"><title hwp:id="title-14">Effects of incentives on feature sensitivity</title></caption><graphic xlink:href="459546v2_tbl3" position="float" orientation="portrait" hwp:id="graphic-8"/></table-wrap><fig id="fig4" position="float" fig-type="figure" orientation="portrait" hwp:id="F4" hwp:rev-id="xref-fig-4-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4.</label><caption hwp:id="caption-7"><title hwp:id="title-15">Influence of incentives on target and distractor sensitivity.</title><p hwp:id="p-30"><bold>A-B)</bold> The relationship between target coherence and performance was stronger during incentivized blocks (gold) in the domain of accuracy (A), but not RT (B). Lines depict aggregated regression predictions. <bold>C)</bold> Regression estimates for the target coherence by incentive interaction. <bold>D-E)</bold> The relationship between distractor congruence and performance was weaker on incentivized blocks (gold) in the for RT (E), but not Accuracy (D). <bold>F)</bold> Regression estimates for the distractor congruence by incentive interaction. Error bars on behavior reflect within-participant SEM, error bars on regression coefficients reflect 95% CI.</p></caption><graphic xlink:href="459546v2_fig4" position="float" orientation="portrait" hwp:id="graphic-9"/></fig><p hwp:id="p-31">We further found that the target-enhancing effects of incentives also were not specific to the color dimension. When motion was the target dimension (attend-motion blocks), incentives preferentially increased sensitivity to motion coherence (<italic toggle="yes">d</italic> = 0.70, <italic toggle="yes">p</italic> &lt; .001). Interestingly, incentives had an even larger influence on target sensitivity in attend-motion relative to attend-color blocks (<italic toggle="yes">t</italic>(59.0) = 2.14, <italic toggle="yes">p</italic> = 0.036; <xref rid="tblS6" ref-type="table" hwp:id="xref-table-wrap-12-1" hwp:rel-id="T12">Supplementary Table 6</xref>-7).</p></sec><sec id="s2e" hwp:id="sec-7"><title hwp:id="title-16">Previous conflict and incentives have dissociable influences on target and distractor processing</title><p hwp:id="p-32">Our within-trial results demonstrated that participants are sensitive to target and distractor information, with little interaction between these dimensions. Consistent with this putative independence, we found that previous interference primarily influenced distractor sensitivity (suppressing distractor sensitivity after trials with incongruent distractors), and that rewards primarily influenced target sensitivity (enhancing target sensitivity when incentivized). These findings strongly suggest a dissociation between target and distractor processing.</p><p hwp:id="p-33">To confirm these findings, we formally tested the double dissociation between how incentives and previous interference influenced target and distractor choice sensitivity (<xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-2" hwp:rel-id="F5">Figure 5</xref>). We found that previous conflict had a larger absolute effect on distractor processing than it did on target processing in both accuracy (<italic toggle="yes">t</italic>(31.4) = 9.54, <italic toggle="yes">p</italic> = 8.36 × 10<sup>−11</sup>) and RT (<italic toggle="yes">t</italic>(33.7) = 4.64, <italic toggle="yes">p</italic> = 5.14 × 10<sup>−5</sup>). We found that rewards conversely had a larger influence on targets than distractors in Accuracy (<italic toggle="yes">t</italic>(44.5) = 5.08, <italic toggle="yes">p</italic> = 7.22 × 10<sup>−6</sup>), though not in RT (<italic toggle="yes">t</italic>(37.7) = 0.25, <italic toggle="yes">p</italic> = 0.80). The cross-over interaction was also significant in both Accuracy (<italic toggle="yes">t</italic>(39.6) = 10.2, <italic toggle="yes">p</italic> = 1.36 × 10<sup>−12</sup>) and RT (<italic toggle="yes">t</italic>(48.3) = 3.11, <italic toggle="yes">p</italic> = 0.0031), supporting dissociable control over different dimensions of feature processing.</p><fig id="fig5" position="float" fig-type="figure" orientation="portrait" hwp:id="F5" hwp:rev-id="xref-fig-5-1 xref-fig-5-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">fig5</object-id><label>Figure 5.</label><caption hwp:id="caption-8"><title hwp:id="title-17">Dissociations between previous conflict and incentive effects.</title><p hwp:id="p-34">Post-conflict effects were significantly larger on distractor sensitivity than target sensitivity in accuracy (A) and RT (B). In contrast, reward effects were significantly larger on target sensitivity than distractor sensitivity in accuracy (A) and similarly large in RT (B). Errors bars show MAP SEM.</p></caption><graphic xlink:href="459546v2_fig5" position="float" orientation="portrait" hwp:id="graphic-10"/></fig><p hwp:id="p-35">These findings are consistent with a pervious neuroimaging experiment that found incentives enhanced responses in target-related areas (visual word form area for text targets) and mostly-incongruent blocks suppressed responses in distractor-related areas (fusiform face area for face distractors; <xref ref-type="bibr" rid="c55" hwp:id="xref-ref-55-2" hwp:rel-id="ref-55">Soutschek et al., 2015</xref>). In the following sections, we extend these convergent findings to explore how previous conflict and incentives influence the dynamics of control implementation.</p></sec><sec id="s2f" hwp:id="sec-8"><title hwp:id="title-18">Differential within-trial dynamics of target and distractor processing</title><p hwp:id="p-36">Our initial results show that participants independently control their sensitivity to target and distractor information. However, previous research has revealed that participants’ task processing also dynamically changes within a trial (<xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-3" hwp:rel-id="ref-49">Servant et al., 2014</xref>; <xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-2" hwp:rel-id="ref-62">Weichart et al., 2020</xref>; <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-2" hwp:rel-id="ref-64">White et al., 2011</xref>), including in response to incentives (<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-2" hwp:rel-id="ref-1">Adkins and Lee, 2021</xref>). Whereas much of the previous research has focused on dynamics in spatial attention during flanker tasks (e.g., a shrinking spotlight of attention; <xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-3" hwp:rel-id="ref-62">Weichart et al., 2020</xref>; <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-3" hwp:rel-id="ref-64">White et al., 2011</xref>), less is known about the dynamics of attention between features of conjunctive stimuli like those in our task, where target and distractor processing may be more independent (<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-3" hwp:rel-id="ref-1">Adkins and Lee, 2021</xref>; <xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-4" hwp:rel-id="ref-49">Servant et al., 2014</xref>).</p><p hwp:id="p-37">To test how sensitivity to target and distractor features changed within each trial, we measured whether the influence of coherence on participants’ choices depended on reaction time (i.e., the <italic toggle="yes">choice ∼ coherence</italic> × <italic toggle="yes">RT</italic> interaction). These analyses work under the logic that faster RTs reflect earlier epochs of information processing, consistent with ‘delta function’ analyses of how congruence effects differ across RT quantiles (<xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">De Jong et al., 1994</xref>; <xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-1" hwp:rel-id="ref-42">Ridderinkhof, 2002</xref>). In the current study, we extended this methodology to study parametric changes in both target and distractor sensitivity over time.</p><p hwp:id="p-38">At the earliest RTs, participants were the least sensitive to targets (<xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Figure 6a</xref>) and the most sensitive to distractors (<xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-2" hwp:rel-id="F6">Figure 6d</xref>). At later RTs, participants became more sensitive to targets (<italic toggle="yes">ds</italic> = 0.69 to 0.97, <italic toggle="yes">p</italic> &lt; .001), and less sensitive to distractors (<italic toggle="yes">ds</italic> = −0.71 to −1.5, <italic toggle="yes">p</italic> &lt; .001; <xref rid="tbl4" ref-type="table" hwp:id="xref-table-wrap-4-1" hwp:rel-id="T4">Table 4</xref>). This is consistent with an attentional control process that enhances sensitivity to goal-relevant features and suppresses attention towards goal-irrelevant features. Notably, these results suggest that this attentional process occurs ‘online’ within the course of a trial.</p><table-wrap id="tbl4" orientation="portrait" position="float" hwp:id="T4" hwp:rev-id="xref-table-wrap-4-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBL4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T4</object-id><object-id pub-id-type="publisher-id">tbl4</object-id><label>Table 4.</label><caption hwp:id="caption-9"><title hwp:id="title-19">Dynamics of feature sensitivity across response times</title></caption><graphic xlink:href="459546v2_tbl4" position="float" orientation="portrait" hwp:id="graphic-11"/></table-wrap><fig id="fig6" position="float" fig-type="figure" orientation="portrait" hwp:id="F6" hwp:rev-id="xref-fig-6-1 xref-fig-6-2 xref-fig-6-3 xref-fig-6-4 xref-fig-6-5 xref-fig-6-6 xref-fig-6-7"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">fig6</object-id><label>Figure 6.</label><caption hwp:id="caption-10"><title hwp:id="title-20">Target and distractor sensitivity dynamics.</title><p hwp:id="p-39"><bold>A)</bold> The relationship between target coherence and accuracy increased at later RTs (pinker color). <bold>B)</bold> Participants responded faster on error trials that correct trial when target coherence was higher. <bold>C)</bold> Regression estimates for the interaction between target coherence and RT (blue) and accuracy (red), within each experiment. <bold>D)</bold> The relationship between distractor congruence and accuracy decreased at later RTs (pinker). Note that these data are mean-centered within each RT bin to remove the target effects from this visualization. <bold>E)</bold> Participants responded faster on error trials than correct trials when distractors were incongruent. <bold>F)</bold> Regression estimates for the interaction between distractor congruence and RT (blue) and accuracy (red), within each experiment. <bold>G)</bold> Target (green) and distractor (cyan) sensitivity plotted as a function of reaction time, as estimated by our regression model in Attend-Color blocks. Vertical lines indicate quartiles of the RT distribution. <bold>H)</bold> Same as G, but generated from regression models fit to the Attend-Motion blocks. Note the different scaling of the x-axis and y-axis (see dashed line between plots). Error bars on behavior reflect within-participant SEM, error bars on sensitivity estimates reflect between-participant SEM of the predictions, error bars on regression coefficients reflect 95% CI.</p></caption><graphic xlink:href="459546v2_fig6" position="float" orientation="portrait" hwp:id="graphic-12"/></fig><p hwp:id="p-40">We also fit a complementary analysis for RT (i.e., the <italic toggle="yes">RT ∼ coherence</italic> × <italic toggle="yes">accuracy</italic> interaction). We found that participants had steeper target coherence slopes on error trials (<italic toggle="yes">ds</italic> = 0.89 to 1.5, <italic toggle="yes">p</italic> &lt; .001; <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-3" hwp:rel-id="F6">Figure 6b</xref>), driven by faster errors when the targets were high coherence, consistent with participants responding before their maximal target sensitivity. Likewise, we found that the relationship between RT and distractor congruence inverted on error trials (<italic toggle="yes">ds</italic> = −0.68 to −1.8, <italic toggle="yes">p</italic> &lt; .001; <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-4" hwp:rel-id="F6">Figure 6e</xref>), with participants making faster errors on more incongruent trials, consistent with an early sensitivity to distractors that is suppressed over time.</p><p hwp:id="p-41">These findings suggest online dynamics in the allocation of top-down attention to facilitate target processing and suppress distractor processing, but it is possible that they instead reflect dynamics inherent to the bottom-up processing of color and motion information. To rule out this alternative hypothesis, we tested whether similar sensitivity dynamics were present during Attend-Motion blocks, when color information serves as a much less potent distractor. During these blocks, we found that participants enhanced target (motion) sensitivity faster than they did during Attend-Color blocks (<italic toggle="yes">p</italic> &lt; .001; <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-5" hwp:rel-id="F6">Figure 6h</xref>; <xref rid="tblS8" ref-type="table" hwp:id="xref-table-wrap-14-1" hwp:rel-id="T14">Supplementary Table 8</xref>-<xref ref-type="table" rid="tblS9" hwp:id="xref-table-wrap-15-1" hwp:rel-id="T15">9</xref>). In contrast, participants had slower distractor sensitivity dynamics during Attend-Motion blocks (<italic toggle="yes">p</italic> &lt; .001). Together these results demonstrate that these sensitivity dynamics depend on the task that participants are performing, rather than being exclusively due to stimulus-driven factors.</p></sec><sec id="s2g" hwp:id="sec-9"><title hwp:id="title-21">Previous conflict and incentives influence early trial dynamics</title><p hwp:id="p-42">We found that, within a trial, participants dynamically adjusted attention depending on the task at hand, with increasing sensitivity to task-relevant information and decreasing sensitivity to task-irrelevant information over the course of a trial. This raises the question whether the two forms of adaptation we observed, related to previous conflict and incentives, influenced different components of the within-trial attentional dynamics.</p><p hwp:id="p-43">To address this question, we first examined how the dynamics of target and distractor sensitivity were altered by the congruence of the distractor on the previous trial (i.e., <italic toggle="yes">Choice ∼ PreviousDistractor</italic> × <italic toggle="yes">RT</italic> × <italic toggle="yes">Coherence</italic>). We found that after incongruent trials, participants started the next trial more sensitive to targets and less sensitive to distractors (<xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-1" hwp:rel-id="F7">Figure 7a</xref>). Although this means that after congruent trials participants had worse initial conditions (starting less sensitive to targets and more sensitive to distractors), they appeared to compensate for this early disadvantage with faster increases in target enhancement (<italic toggle="yes">ds</italic> = 0.65 to 1.0, <italic toggle="yes">p</italic> &lt; .001) and distractor suppression (<italic toggle="yes">ds</italic> = −0.68 to −1.1, <italic toggle="yes">p</italic> &lt; .001; Table 5). Both post-congruent and post-incongruent trials thus reached similar asymptotic levels of feature sensitivity.</p><fig id="fig7" position="float" fig-type="figure" orientation="portrait" hwp:id="F7" hwp:rev-id="xref-fig-7-1 xref-fig-7-2 xref-fig-7-3 xref-fig-7-4 xref-fig-7-5 xref-fig-7-6"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG7</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F7</object-id><object-id pub-id-type="publisher-id">fig7</object-id><label>Figure 7.</label><caption hwp:id="caption-11"><title hwp:id="title-22">Influence of conflict and incentives on sensitivity dynamics.</title><p hwp:id="p-44"><bold>A)</bold> The relationship between previous distractor congruence and current distractor congruence was strongest for early RTs (pinker color). The y-axis depicts the difference in accuracy between the extreme tertiles of previous congruence, for visualization purposes. <bold>B)</bold> Target (green) and distractor (cyan) sensitivity plotted as a function of previous congruence (color shade) and reaction time (x-axis), as estimated by our regression model. Vertical lines indicate quartiles of the RT distribution. <bold>C)</bold> Regression estimates for the interactions between reaction time and previous congruence on lapse rate (orange); or reaction time, previous congruence, and feature coherence on accuracy (target is green, distractor is cyan). <bold>D)</bold> The relationship between incentives and target coherence was strongest for early RTs (pinker color). The y-axis depicts the difference in accuracy between blocks where there were rewards vs blocks without rewards. <bold>E)</bold> Target (green) and distractor (cyan) sensitivity plotted as a function of incentives (gold) and reaction time (x-axis), as estimated by our regression model. Vertical lines indicate quartiles of the RT distribution. <bold>F)</bold> Regression estimates for the interactions between reaction time and incentives on lapse rate (orange); or reaction time, incentives, and feature coherence on accuracy (target is green, distractor is cyan). Error bars on behavior reflect within-participant SEM, error bars on sensitivity estimates reflect between-participant SEM on the predictions, error bars on regression coefficients reflect 95% CI.</p></caption><graphic xlink:href="459546v2_fig7" position="float" orientation="portrait" hwp:id="graphic-13"/></fig><table-wrap id="fig5a" orientation="portrait" position="float" hwp:id="T5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG5A</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T5</object-id><object-id pub-id-type="publisher-id">fig5a</object-id><label>Figure 5.</label><caption hwp:id="caption-12"><title hwp:id="title-23">Effects of previous conflict on feature sensitivity dynamics</title></caption><graphic xlink:href="459546v2_fig5a" position="float" orientation="portrait" hwp:id="graphic-14"/></table-wrap><p hwp:id="p-45">We performed the equivalent analysis for incentive-related adaptation (i.e., <italic toggle="yes">Choice ∼ Reward</italic> × <italic toggle="yes">RT</italic> × <italic toggle="yes">Coherence</italic>). We found that during incentivized blocks, participants’ initial target sensitivity was higher than during non-incentivized blocks, and remained so across much of the trial (see <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-2" hwp:rel-id="F7">Figure 7d</xref>). However, target sensitivity eventually reached an asymptote, such that towards the end of the trial both incentivized and non-incentivized trials had similar levels of target sensitivity (see slowest quantile in <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-3" hwp:rel-id="F7">Figure 7d</xref>). This convergence was accounted for by larger increases in lapse rates later in incentivized trials (<italic toggle="yes">d</italic> = 0.52, <italic toggle="yes">p</italic> &lt; .001; <xref rid="tbl6" ref-type="table" hwp:id="xref-table-wrap-6-1" hwp:rel-id="T6">Table 6</xref>). The dynamics of distractor sensitivity, by contrast, did not significantly differ between incentivized and non-incentivized trials (<italic toggle="yes">d</italic> = 0.055, <italic toggle="yes">p</italic> = 0.71).</p><table-wrap id="tbl6" orientation="portrait" position="float" hwp:id="T6" hwp:rev-id="xref-table-wrap-6-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBL6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T6</object-id><object-id pub-id-type="publisher-id">tbl6</object-id><label>Table 6.</label><caption hwp:id="caption-13"><title hwp:id="title-24">Effects of incentives on feature sensitivity dynamics</title></caption><graphic xlink:href="459546v2_tbl6" position="float" orientation="portrait" hwp:id="graphic-15"/><graphic xlink:href="459546v2_tbl6a" position="float" orientation="portrait" hwp:id="graphic-16"/></table-wrap></sec><sec id="s2h" hwp:id="sec-10"><title hwp:id="title-25">An accumulator model of attentional control over target and distractor processing</title><p hwp:id="p-46">Our results demonstrate that participants independently control the initialization and online adjustment of attention towards target and distractor features. To parsimoniously account for this set of findings, we developed an accumulator model that integrated elements of previous models used to separately account for performance in tasks involving perceptual discrimination (<xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-2" hwp:rel-id="ref-19">Gold and Shadlen, 2007</xref>; <xref ref-type="bibr" rid="c39" hwp:id="xref-ref-39-1" hwp:rel-id="ref-39">Ratcliff and McKoon, 2008</xref>) and overriding prepotent distractors (<xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">Cohen et al., 1990</xref>; <xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-4" hwp:rel-id="ref-62">Weichart et al., 2020</xref>; <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-4" hwp:rel-id="ref-64">White et al., 2011</xref>). We used a variant of a feedforward inhibition model, in which inputs provide excitatory inputs to associated response units and inhibitory inputs to alternative response units (<xref ref-type="bibr" rid="c50" hwp:id="xref-ref-50-1" hwp:rel-id="ref-50">Shadlen and Newsome, 2001</xref>). Our decision model takes as inputs the color and motion coherence in support of different responses, nonlinearly transforms these inputs, and then integrates evidence for each response in separate rectified accumulators with balanced feedforward excitation and inhibition (<xref rid="fig8" ref-type="fig" hwp:id="xref-fig-8-1" hwp:rel-id="F8">Figure 8</xref>). The signal-to-noise ratio of the intermediate layer’s outputs are determined by control units that determine the gain of a given feature (<xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-2" hwp:rel-id="ref-11">Cohen et al., 1990</xref>; <xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-1" hwp:rel-id="ref-35">Musslick et al., 2019</xref>). We hand-tuned the parameters of this model to determine whether it could capture our core experimental findings across choice and reaction time.</p><fig id="fig8" position="float" fig-type="figure" orientation="portrait" hwp:id="F8" hwp:rev-id="xref-fig-8-1 xref-fig-8-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG8</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F8</object-id><object-id pub-id-type="publisher-id">fig8</object-id><label>Figure 8.</label><caption hwp:id="caption-14"><title hwp:id="title-26">Feedforward inhibition with control.</title><p hwp:id="p-47">Color evidence (green) and motion evidence (blue) are transformed and accumulated to make a choice. Balanced excitatory connections (black solid lines) and inhibitory connections (red dashed lines) cause accumulation of the difference in evidence for each response. <bold>A)</bold> Evidence for the left response (purple) and right response (orange) are accumulated over time without leak. When one of the accumulators crosses a (linearly collapsing) decision threshold, the model chooses that response. <bold>B)</bold> Within each trial, the signal-to-noise of each feature pathways is controlled by a feature gain. Over time within a trial, the feature gains for targets (green) and distractors (cyan) exponentially decay to a fixed level (high gain for targets, zero gain for distractors). <bold>C)</bold> An equivalent visualization of the dynamics in B. Attractor dynamics drive target and distractor gains to their fixed level, shown at different timepoints within the trial (pinker colors are later in the trial). The horizontal line depicts zero distractor gain.</p></caption><graphic xlink:href="459546v2_fig8" position="float" orientation="portrait" hwp:id="graphic-17"/></fig><p hwp:id="p-48">Our accumulator model was able to reproduce our key within-trial findings. During our main Attend-Color trials, it generated responses that were faster and more accurate with increasing color coherence (<xref rid="fig9" ref-type="fig" hwp:id="xref-fig-9-1" hwp:rel-id="F9">Figure 9a</xref>) and slower and less accurate with increasing motion incongruence (<xref rid="fig9" ref-type="fig" hwp:id="xref-fig-9-2" hwp:rel-id="F9">Figure 9b</xref>). We simulated Attend-Motion trials by increasing the target gain and decreasing the distractor gain, to capture potential differences in both automaticity and control. Now, our model generated responses that were even faster and more accurate with increasing target coherence (now motion; <xref rid="fig9" ref-type="fig" hwp:id="xref-fig-9-3" hwp:rel-id="F9">Figure 9c</xref>) but that were insensitive to distractor congruence (now color; <xref rid="fig9" ref-type="fig" hwp:id="xref-fig-9-4" hwp:rel-id="F9">Figure 9d</xref>), replicating the main behavioral results in Attend-Motion blocks. Notably, distractor effects were not reproduced in an accumulator competition model parameterized to be more ‘race-like’ (<xref rid="figS3" ref-type="fig" hwp:id="xref-fig-14-1" hwp:rel-id="F14">Supplementary Figure 3</xref>; <xref ref-type="bibr" rid="c57" hwp:id="xref-ref-57-1" hwp:rel-id="ref-57">Teodorescu and Usher, 2013</xref>). This occurred because larger inputs (whether congruent or incongruent) drove faster reaction times.</p><fig id="fig9" position="float" fig-type="figure" orientation="portrait" hwp:id="F9" hwp:rev-id="xref-fig-9-1 xref-fig-9-2 xref-fig-9-3 xref-fig-9-4 xref-fig-9-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG9</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F9</object-id><object-id pub-id-type="publisher-id">fig9</object-id><label>Figure 9.</label><caption hwp:id="caption-15"><title hwp:id="title-27">Simulation of target and distractor sensitivity (see <xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Figure 2</xref>).</title><p hwp:id="p-49"><bold>A-B)</bold> Sensitivity to target coherence (A) and distractor congruence (B) in behavior (left) and in the FFIc simulation (right) for Attend-Color blocks. <bold>C-D)</bold> Same as A-B, but for Attend-Motion blocks.</p></caption><graphic xlink:href="459546v2_fig9" position="float" orientation="portrait" hwp:id="graphic-18"/></fig><p hwp:id="p-50">We next used this model to test potential mechanisms underlying participants’ within- and between-trial control adaptations. First, we tested whether participants’ apparent within-trial dynamics in feature sensitivity plausibly resulted from actual within-trial changes in control gains governing feature sensitivity, or whether such dynamics could result from static control gains. We implemented time-varying feature gains as attractors with an initial gain (e.g., reflecting bottom-up salience or learning) that exponentially decays to a fixed point (e.g., determined by the task goals and control; cf. <xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-2" hwp:rel-id="ref-35">Musslick et al., 2019</xref>; <xref ref-type="bibr" rid="c56" hwp:id="xref-ref-56-1" hwp:rel-id="ref-56">Steyvers et al., 2019</xref>). We found that incorporating these time-varying gains into our accumulator model allowed it to reproduce participants’ behavioral dynamics. In accuracy, our model replicated the shift in target sensitivity over time, with the collapsing bound reducing performance on the slowest trials (<xref rid="fig10" ref-type="fig" hwp:id="xref-fig-10-1" hwp:rel-id="F10">Figure 10a</xref>). Our model similarly captured participants’ decreased target sensitivity at later RTs (<xref rid="fig10" ref-type="fig" hwp:id="xref-fig-10-2" hwp:rel-id="F10">Figure 10b</xref>). Finally, our model recreated the analogous effects in RT, with faster errors for high coherence targets and incongruent distractors (<xref rid="fig10" ref-type="fig" hwp:id="xref-fig-10-3" hwp:rel-id="F10">Figure 10c-d</xref>). Critically, we were unable to replicate these qualitative patterns of behavior with a model in which control gains that were frozen throughout the trial (<xref rid="figS4" ref-type="fig" hwp:id="xref-fig-15-1" hwp:rel-id="F15">Supplementary Figure 4</xref>).</p><fig id="fig10" position="float" fig-type="figure" orientation="portrait" hwp:id="F10" hwp:rev-id="xref-fig-10-1 xref-fig-10-2 xref-fig-10-3 xref-fig-10-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG10</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F10</object-id><object-id pub-id-type="publisher-id">fig10</object-id><label>Figure 10.</label><caption hwp:id="caption-16"><title hwp:id="title-28">Simulation of target and distractor sensitivity dynamics (see <xref ref-type="fig" rid="fig6" hwp:id="xref-fig-6-6" hwp:rel-id="F6">Figure 6</xref>).</title><p hwp:id="p-51"><bold>A-B)</bold> RT-dependent (A) and accuracy-dependent (B) sensitivity to target coherence in behavior (left) and in the FFIc simulation (right). <bold>C-D)</bold> Same as A-B, but for distractor congruence.</p></caption><graphic xlink:href="459546v2_fig10" position="float" orientation="portrait" hwp:id="graphic-19"/></fig><p hwp:id="p-52">The parallel feature pathways in this model are designed to capture the independent influences of a target and distractor information (<xref ref-type="bibr" rid="c29" hwp:id="xref-ref-29-3" hwp:rel-id="ref-29">Lindsay and Jacoby, 1994</xref>). However, the time-varying feature gains providing an account for the weak interactions we observed between target and distractor sensitivity in accuracy. Despite there being no competition in feature processing in our model, we found these weak target-distractor interactions emerge in <italic toggle="yes">simulated</italic> accuracies but not simulated RTs. This interaction appeared to result from the different time courses of target and distractor sensitivity. As in participants’ behavior, the model’s errors due to incongruent distractors tend to occur early (<xref rid="fig10" ref-type="fig" hwp:id="xref-fig-10-4" hwp:rel-id="F10">Figure 10c-d</xref>), censoring target processing at a lower (early) level of sensitivity. This interplay between feature sensitivity <italic toggle="yes">dynamics</italic> (but not overall feature sensitivity per se) offers a plausible explanation for the subtle and seeming inconsistent interactions in participants’ behavior.</p><p hwp:id="p-53">Having provided an account of how each of our stimulus features is processed over the course of the trial depending on the task goal, we next tested a potential model-based account of the two forms of control adaptation we observed across trials. Our participants demonstrated enhanced target sensitivity on rewarded blocks, and suppressed distractor sensitivity after increasingly incongruent trials. In both cases, adaptation appeared to enhance sensitivity to stimulus features at the fastest reaction times. To account for these findings, we modified the initial conditions of our model’s gain dynamics (<xref rid="fig11" ref-type="fig" hwp:id="xref-fig-11-1" hwp:rel-id="F11">Figure 11a</xref>). We simulated post-interference adaptation by initializing the distractor gain closer to its asymptote, and we simulated reward incentivization by initializing the target gain closer to its asymptote. We found that these simulations qualitatively reproduced participants’ behavior, with stronger adaptation and reward effects earlier in the trial than later. The exponential decay in our attractor network parsimoniously accounts for the fact that dynamics tended to be faster when they were initialized further from the fixed point (i.e., post-congruent trials). Thus, our model was able to capture the range of findings in this experiment, from target-distractor sensitivity, within-trial dynamics, and how the dynamics of target and distractor processing may be influenced by control.</p><fig id="fig11" position="float" fig-type="figure" orientation="portrait" hwp:id="F11" hwp:rev-id="xref-fig-11-1 xref-fig-11-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIG11</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F11</object-id><object-id pub-id-type="publisher-id">fig11</object-id><label>Figure 11.</label><caption hwp:id="caption-17"><title hwp:id="title-29">Simulation of post-conflict and incentive effects (see <xref ref-type="fig" rid="fig7" hwp:id="xref-fig-7-4" hwp:rel-id="F7">Figure 7</xref>).</title><p hwp:id="p-54"><bold>A)</bold> The influences of previous congruence (shade) and incentive effects (gold) were implemented through changes to the initial conditions of the feature gain dynamics, with previous congruence influencing initial distractor gain and incentives influence initial target gain. <bold>B-C)</bold> The influence of previous congruence on distractor sensitivity dynamics in behavior (B) and in the FFIc simulation (C). <bold>D-E)</bold> The influence of incentives on target sensitivity dynamics in behavior (D) and in the FFIc simulation (E).</p></caption><graphic xlink:href="459546v2_fig11" position="float" orientation="portrait" hwp:id="graphic-20"/></fig></sec></sec><sec id="s3" hwp:id="sec-11"><title hwp:id="title-30">Discussion</title><p hwp:id="p-55">When faced with distraction, we can sustain good performance by engaging with relevant information or ignoring disruptive information. Our experiment revealed that these strategies are under independent cognitive control, and are driven by distinct attentional dynamics. Using a bivalent random dot motion task with parametric target and distractor coherence (PACT), we found that target and distractor information have independent influences on participants’ performance. Furthermore, we found that participants’ sensitivity to targets and distractors was preferentially modulated by incentives and previous interference, respectively. These adaptations altered the initial conditions of feature-selective gains, which was followed by dynamic enhancement to target gains and suppression of distractor gains. These behavioral phenomena could be parsimoniously explained by a hybrid sequential sampling model with goal-dependent attractor dynamics over feature weights.</p><p hwp:id="p-56">Together, these results support a cognitive control architecture that is parametric, multivariate, and dynamic. Previous research has found that cognitive effort is enhanced in response to incentives (<xref ref-type="bibr" rid="c37" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">Parro et al., 2018</xref>; <xref ref-type="bibr" rid="c67" hwp:id="xref-ref-67-1" hwp:rel-id="ref-67">Yee and Braver, 2018</xref>) and to previous conflict (<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-6" hwp:rel-id="ref-15">Egner, 2007</xref>; <xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-3" hwp:rel-id="ref-20">Gratton et al., 1992</xref>). The current experiments extend these previous findings to show that these adaptations are both graded in their intensity, and selective in their allocation. These findings are consistent with a multivariate perspective on cognitive control (<xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-2" hwp:rel-id="ref-44">Ritz et al., 2021</xref>), in which people optimize a configuration of control signal according to their costs and benefits (<xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">Musslick et al., 2015</xref>; <xref ref-type="bibr" rid="c51" hwp:id="xref-ref-51-1" hwp:rel-id="ref-51">Shenhav et al., 2013</xref>). The target and distractor configurations observed here add to a body of work teasing apart the conditions under which people coordinate across multiple control signals (<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-5" hwp:rel-id="ref-13">Danielmeier et al., 2011</xref>; <xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">Leng et al., 2020</xref>; <xref ref-type="bibr" rid="c54" hwp:id="xref-ref-54-1" hwp:rel-id="ref-54">Simen et al., 2009</xref>; <xref ref-type="bibr" rid="c55" hwp:id="xref-ref-55-3" hwp:rel-id="ref-55">Soutschek et al., 2015</xref>).</p><p hwp:id="p-57">A core question arising from these results is why there are preferential relationships between previous conflict with distractors, and incentives with targets. One possibility is that this is due to credit assignment. A system that could properly assign credit to features based on their contribution to conflict and incentives should allocate control towards distractors and targets. Distractors are a salient source of response conflict, and participants could adjust sensitivity to reduce this conflict. When participants were performing the more automatic Attend-Motion blocks, during which response conflict was absent, this adaptation was also absent. In contrast, reward contingencies were explicitly tied to target discrimination performance. During Attend-Motion blocks, there was a stronger association between target coherence and performance (e.g., due to response compatibility, and that only targets contributed to accuracy), potentially explaining why these blocks had larger incentive effects. This account is consistent with Bayesian models of cognitive control, such as those that predict feature congruence (<xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">Jiang et al., 2014</xref>; <xref ref-type="bibr" rid="c69" hwp:id="xref-ref-69-2" hwp:rel-id="ref-69">Yu et al., 2009</xref>) or the value of control policies (<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">Bustamante et al., 2021</xref>; <xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">Lieder et al., 2018</xref>).</p><p hwp:id="p-58">Our results also provide insight into the dynamic implementation of attentional control. Previous work has shown that within-trial attentional dynamics play an important role in both decision making (<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">Callaway et al., 2021</xref>; <xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">Krajbich et al., 2010</xref>; <xref ref-type="bibr" rid="c27" hwp:id="xref-ref-27-1" hwp:rel-id="ref-27">Li and Ma, 2021</xref>; <xref ref-type="bibr" rid="c63" hwp:id="xref-ref-63-1" hwp:rel-id="ref-63">Westbrook et al., 2020</xref>) and cognitive control (<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-4" hwp:rel-id="ref-1">Adkins and Lee, 2021</xref>; <xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">Hardwick et al., 2019</xref>; <xref ref-type="bibr" rid="c49" hwp:id="xref-ref-49-5" hwp:rel-id="ref-49">Servant et al., 2014</xref>; <xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-5" hwp:rel-id="ref-62">Weichart et al., 2020</xref>; <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-5" hwp:rel-id="ref-64">White et al., 2011</xref>). These foundational experiments have largely focused on spatial attention, with far less known about the dynamics of feature-based attention, where processing of targets and distractors is less mutually constrained. Furthermore, relatively few experiments have studied how attentional dynamics are modified in response to control drivers like incentives or task demands (<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-5" hwp:rel-id="ref-1">Adkins and Lee, 2021</xref>; <xref ref-type="bibr" rid="c69" hwp:id="xref-ref-69-3" hwp:rel-id="ref-69">Yu et al., 2009</xref>).</p><p hwp:id="p-59">Our experiment shows that the dynamics of target and distractor sensitivity are independent, and that previous conflict and incentives appear to operate through changes to the initial conditions of these feature gains, rather than their speed or asymptotic level. If participants are learning the relevance of different features, it’s possible that these initial conditions reflect the prior probability that attention towards targets or distractors will support task goals (<xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-2" hwp:rel-id="ref-28">Lieder et al., 2018</xref>; <xref ref-type="bibr" rid="c69" hwp:id="xref-ref-69-4" hwp:rel-id="ref-69">Yu et al., 2009</xref>). Similar to how response priors are reflected in the initial decision state (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="c54" hwp:id="xref-ref-54-2" hwp:rel-id="ref-54">Simen et al., 2009</xref>), priors on feature priority may be reflected in the initial attentional state. In the case of previous interference, this could reflect learning whether distractors enhance performance (e.g., after trials on which congruent distractors led to better performance), or a local estimate of the probability a trial will be congruent (<xref ref-type="bibr" rid="c69" hwp:id="xref-ref-69-5" hwp:rel-id="ref-69">Yu et al., 2009</xref>). For incentives this may reflect the expected target-reward contingency. Future research should investigate this account by measuring attentional dynamics as participants learn task contingencies (<xref ref-type="bibr" rid="c52" hwp:id="xref-ref-52-2" hwp:rel-id="ref-52">Shenhav et al., 2018</xref>).</p><p hwp:id="p-60">Our patterns of conflict- and incentive-dependent dynamics help rule out stimulus-driven dynamics and support independent control over feature processing. After congruent trials, participants started the next trial with more similar target and distractor gains, that were then more quickly separated within the trial (<xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-5" hwp:rel-id="F7">Figure 7b</xref>). If these dynamics were an artifact of the decision process (e.g., due to accumulator attractors; <xref ref-type="bibr" rid="c66" hwp:id="xref-ref-66-1" hwp:rel-id="ref-66">Wong and Wang, 2006</xref>), then we would expect that when target and distractor gains are initially more similar, there would be slower dynamics. Instead, we found faster dynamics, supporting a role for feedback control that reconfigures attentional gain to align with task goals. Additionally, during incentivized blocks, we saw that participants modified attentional dynamics for targets, but not distractors. This finding further supports the independence of these attentional dynamics, demonstrating that participants can alter attention towards one feature but not the other.</p><p hwp:id="p-61">Our dynamical process model may help link behavior in response conflict tasks to cognitive dynamics in other domains. In the domain of task-switching, recent cognitive models have developed similar dynamical accounts of how people reconfigure task sets. Classic work has shown that switch costs exponentially decay with preparation time (<xref ref-type="bibr" rid="c34" hwp:id="xref-ref-34-1" hwp:rel-id="ref-34">Monsell and Mizon, 2006</xref>; <xref ref-type="bibr" rid="c45" hwp:id="xref-ref-45-1" hwp:rel-id="ref-45">Rogers and Monsell, 1995</xref>), similar to the dynamics in the current task. Computational models have formalized these task sets dynamics during the switch preparation period (<xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-3" hwp:rel-id="ref-35">Musslick et al., 2019</xref>; <xref ref-type="bibr" rid="c60" hwp:id="xref-ref-60-1" hwp:rel-id="ref-60">Ueltzhöffer et al., 2015</xref>) across trials (<xref ref-type="bibr" rid="c56" hwp:id="xref-ref-56-2" hwp:rel-id="ref-56">Steyvers et al., 2019</xref>). If the within-trial dynamics we observe reflect a “task set micro-adjustment” (<xref ref-type="bibr" rid="c42" hwp:id="xref-ref-42-2" hwp:rel-id="ref-42">Ridderinkhof, 2002</xref>), then this modeling approach may help unify switching dynamics across executive domains. Interestingly, control over initial conditions also plays a central role in the neural dynamics of motor preparation (<xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">Churchland et al., 2010</xref>; <xref ref-type="bibr" rid="c41" hwp:id="xref-ref-41-1" hwp:rel-id="ref-41">Remington et al., 2018b</xref>, <xref ref-type="bibr" rid="c40" hwp:id="xref-ref-40-1" hwp:rel-id="ref-40">2018a</xref>), highlighting the similarities across motor and cognitive domains (<xref ref-type="bibr" rid="c43" hwp:id="xref-ref-43-1" hwp:rel-id="ref-43">Ritz et al., 2020</xref>, <xref ref-type="bibr" rid="c44" hwp:id="xref-ref-44-3" hwp:rel-id="ref-44">2021</xref>) and offering potential neural predictions for our task.</p><p hwp:id="p-62">Our analyses of attentional dynamics depend on participants’ own response times and choices, raising concerns about selection biases. While evidence accumulation modelling typically depends on choice-conditioned reaction times, inferring time-varying influence of targets and distractors presents a particular challenge. To address these concerns, we used simulations to show that the dynamic profiles we observed cannot be accounted for by an evidence accumulation model with static gains on target and distractor processing (<xref rid="figS4" ref-type="fig" hwp:id="xref-fig-15-2" hwp:rel-id="F15">Supplementary Figure 4</xref>). Introducing dynamic feature gains allowed us to account for those same patterns (<xref rid="fig9" ref-type="fig" hwp:id="xref-fig-9-5" hwp:rel-id="F9">Figure 9</xref>-<xref ref-type="fig" rid="fig11" hwp:id="xref-fig-11-2" hwp:rel-id="F11">11</xref>). These results are consistent with previous work validating DDM estimates of attentional dynamics in conflict tasks (<xref ref-type="bibr" rid="c65" hwp:id="xref-ref-65-1" hwp:rel-id="ref-65">White et al., 2018</xref>, <xref ref-type="bibr" rid="c64" hwp:id="xref-ref-64-6" hwp:rel-id="ref-64">2011</xref>). Even if these measurements are valid, using sparse behavioral measures is an inefficient method for measuring latent dynamics, and may combine multiple processes (e.g., accumulation and threshold adjustments). By integrating across multiple convergent measures of decision and attentional dynamics – including interrogation protocols (<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-6" hwp:rel-id="ref-1">Adkins and Lee, 2021</xref>; <xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-2" hwp:rel-id="ref-21">Hardwick et al., 2019</xref>), motor tracking (<xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">Erb et al., 2016</xref>; <xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">Menceloglu et al., 2021</xref>; <xref ref-type="bibr" rid="c46" hwp:id="xref-ref-46-1" hwp:rel-id="ref-46">Scherbaum et al., 2010</xref>), and/or temporally-resolved neuroimaging (<xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">Fischer et al., 2018</xref>; <xref ref-type="bibr" rid="c47" hwp:id="xref-ref-47-1" hwp:rel-id="ref-47">Scherbaum et al., 2011</xref>; <xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-6" hwp:rel-id="ref-62">Weichart et al., 2020</xref>; <xref ref-type="bibr" rid="c68" hwp:id="xref-ref-68-1" hwp:rel-id="ref-68">Yeung et al., 2004</xref>) – future work can help strengthen and build on our understanding of continuous changes in the configuration of multiple control processes.</p><p hwp:id="p-63">This experiment provides new insight into how we flexibly adapt to the changing demands of our environment. We find that this flexible control aligns information processing with task goals, and can be captured by a well-defined process model. The developments from this experiment can help extend models of cognitive control towards richer accounts of how multivariate control configurations, such as across targets and distractors, are optimized during goal-directed behavior.</p></sec><sec id="s4" hwp:id="sec-12"><title hwp:id="title-31">Methods</title><sec id="s4a" hwp:id="sec-13"><title hwp:id="title-32">Participants</title><p hwp:id="p-64">All participants provided informed consent in compliance with Brown University’s Institutional Review Board, participating for either course credit or pay. We excluded participants from our analyses if they had &lt;70% accuracy during attend-color blocks or completed less than half of the experiment. Fifty-seven individuals participated in Experiment 1 (mean(SD) age: 20.6(2.21); 36 female; 1 excluded), 42 individuals participated in Experiment 2 (age: 19.1(0.971); 31 female; 2 excluded), and 62 individuals participated in Experiment 3 (age: 19.8(1.38); 47 female; 2 excluded), resulting in 156 included participants across the three experiments.</p></sec><sec id="s4b" hwp:id="sec-14"><title hwp:id="title-33">Parametric Attentional Control Task (PACT)</title><p hwp:id="p-65">We developed the Parametric Attentional Control Task (PACT), extending tasks used to study decision-making (<xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-2" hwp:rel-id="ref-24">Kang et al., 2021</xref>; <xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-3" hwp:rel-id="ref-31">Mante et al., 2013</xref>; <xref ref-type="bibr" rid="c52" hwp:id="xref-ref-52-3" hwp:rel-id="ref-52">Shenhav et al., 2018</xref>) and cognitive control (<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-6" hwp:rel-id="ref-13">Danielmeier et al., 2011</xref>). On each trial, participants viewed an array of moving dots (i.e., random dot kinematogram), presented in one of four colors (see <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-7" hwp:rel-id="F1">Figure 1</xref>). Participants were taught to match two colors to a left keypress and two colors to a right keypress (with colors counterbalanced across participants). The majority color did not repeat on adjacent trials to avoid priming (<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">Braem et al., 2019</xref>).</p><p hwp:id="p-66">The direction of the dot motion (leftward or rightward) was task-irrelevant and could be consistent with the color response (distractor congruent trials) or it could be inconsistent with this response (distractor incongruent trials). Uniquely in this experiment, we parametrically varied the degree of distractor congruence on each trial by varying the motion coherence (percentage of dots moving in the same direction). Distractor congruence was linearly spaced between 95% congruence and 95% incongruence, drawn randomly across trials.</p><p hwp:id="p-67">In Experiment 1, all of the dots were the same color (100% color coherence), creating a parametric extension of the Simon conflict tasks (<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-7" hwp:rel-id="ref-13">Danielmeier et al., 2011</xref>). In Experiments 2 and 3, the dots contained a mixture of two colors associated with different responses. Color coherence was linearly spaced between 65% to 95%, drawn randomly across trials.</p><p hwp:id="p-68">To maintain the salience of the motion dimension throughout the session (<xref ref-type="bibr" rid="c53" hwp:id="xref-ref-53-2" hwp:rel-id="ref-53">Shiffrin and Schneider, 1977</xref>), participants alternated between blocks of the task above (‘attend-color’ trials, putatively more control-demanding) and blocks where participants were instructed to instead indicate the direction of the dot motion (‘attend-motion’ trials, putatively less control-demanding). Mirroring the attend-color blocks, in Experiment 1 we held the motion coherence constant (maximal) during attend-motion blocks, while varying the color coherence across trials. In Experiments 2 and 3, we varied the coherence of both dimensions during attend-motion blocks.</p></sec><sec id="s4c" hwp:id="sec-15"><title hwp:id="title-34">Session</title><p hwp:id="p-69">Participants first performed 100 motion-only training trials (0% coherent color) and 100 color-only training trials (0% coherent motion; order counterbalanced across participants) to learn the stimulus-response mappings. During training, participants received accuracy feedback on every trial. During the main experiment, participants performed two types of interleaved blocks, without trial-wise feedback. Participants alternated between longer attend-color blocks (100 trials) and shorter attend-motion blocks (Experiment 1: 20-50 trials; Experiment 2-3: 30 trials; order counterbalanced across participants). In Experiments 1 and 2, at the end of each block participants were told their average accuracy and median RT, and encouraged to respond quickly and accurately. Participants were not given this information in Experiment 3 to avoid interactions with the incentive manipulation (see below). Participants took self-timed breaks between blocks.</p></sec><sec id="s4d" hwp:id="sec-16"><title hwp:id="title-35">Stimuli</title><p hwp:id="p-70">Participants were seated approximately 60cm from a computer screen, making their responses on a customizable gaming keyboard in a dark testing booth. The random dot motion array was presented in the center of the screen (∼15 visual degrees in diameter; ∼66.8 dots per visual degree squared; 19” LCD display at 60Hz). The dots colors were approximately (uncalibrated) isoluminant and perceptually equidistant (RGB: [187, 165, 222], [150, 180, 198], [192, 169, 168], [157, 184, 130]; <xref ref-type="bibr" rid="c58" hwp:id="xref-ref-58-1" hwp:rel-id="ref-58">Teufel and Wehrhahn, 2000</xref>) and moved at ∼15 visual degrees per second. Each trial started with a random inter-trial interval (Experiment 1: 0.5 – 1.5s; Experiment 2-3: 0.5 – 1.0s). There was an alerting cue 300ms before the trial onset, indicated by the fixation cross turning from grey to white, to minimize non-decision time. The stimuli were then presented until either a response was made, or a deadline was reached (Experiment 1: 3s; Experiment 2-3: 5s).</p></sec><sec id="s4e" hwp:id="sec-17"><title hwp:id="title-36">Task Variants</title><sec id="s4e1" hwp:id="sec-18"><title hwp:id="title-37">Experiment 1</title><p hwp:id="p-71">These data incorporate several similar versions of this task developed during piloting. The main differences across versions were the number of distractor congruence levels (mean(range) = 13.5(11-15)), the number of trials per attend-motion block (mean(range) = 26(20-50)), and the total number of trials (mean(range) = 469(300-700) attend-color trials). We did not find significant differences in performance across versions, and so our analyses collapsed across these versions. Experiment 1 also included a learning condition in a separate set of blocks, which was outside the scope of the current paper and not included in the analyses we report.</p></sec><sec id="s4e2" hwp:id="sec-19"><title hwp:id="title-38">Experiments 2 &amp; 3</title><p hwp:id="p-72">These data come from a single task variant (though see Experiment 3’s incentive manipulation below). In this variant, we presented participants with 11 levels of target coherence and 11 levels of distractor congruence, linearly spaced within their coherence range and randomly sampled across trials. Participants performed 12 blocks of 100 attend-color trials interleaved with 12 blocks of 30 attend-motion trials.</p></sec></sec><sec id="s4f" hwp:id="sec-20"><title hwp:id="title-39">Incentivized Variant (Experiment 3)</title><p hwp:id="p-73">In Experiment 3, we informed participants before the main session that they would be able to earn a monetary reward for good performance. On ‘Reward’ blocks, we would randomly select trials, and if they were both fast and accurate on those trials, they would receive a bonus payment. On ‘No Reward’ blocks, participants would not be eligible to earn a reward. We indicated the incentive condition at the beginning of each block with a label and text coloring (gold text for ‘Reward’, white text for ‘No Reward’). Participants performed Attend-Color and Attend-Motion blocks in one incentive condition before alternating to the other incentive condition (order counterbalanced across participants). At the end of the experiment, participants received a bonus calculated from their performance (mean(SD) bonus: $2.5($0.57)USD).</p></sec><sec id="s4g" hwp:id="sec-21"><title hwp:id="title-40">Regression Analyses</title><p hwp:id="p-74">We used a hierarchical nonlinear regression of choice and reaction time as a tractable and minimally theory-laden measure of performance (<xref rid="figS1" ref-type="fig" hwp:id="xref-fig-12-1" hwp:rel-id="F12">Supplementary Figure 1</xref>). In particular, we implemented hierarchical expectation maximization (EM) in MATLAB R2020a (using emfit; available at github.com/mpc-ucl/emfit) to provide a maximum a posteriori (MAP) estimates for the mean and covariance of parameters linking task features to performance. This fitting algorithm alternates between finding the MAP estimates of participants’ parameters given the current group-level expectations (M-step; with 5 parameter re-initialization per step), and updating this group-level expectation based on participants’ estimated parameters (E-step), repeated until convergence. We fit separate regression to each experiment for independent replications of our findings. Analysis code is available at github.com/shenhavlab/PACT-public.</p><p hwp:id="p-75">Our regression approach simultaneously estimated parameters for choice and RT:
<disp-formula id="ueqn1" hwp:id="disp-formula-1">
<alternatives hwp:id="alternatives-1"><graphic xlink:href="459546v2_ueqn1.gif" position="float" orientation="portrait" hwp:id="graphic-21"/></alternatives>
</disp-formula>
Our choice sub-function used a lapse-logistic likelihood function:
<disp-formula id="ueqn2" hwp:id="disp-formula-2">
<alternatives hwp:id="alternatives-2"><graphic xlink:href="459546v2_ueqn2.gif" position="float" orientation="portrait" hwp:id="graphic-22"/></alternatives>
</disp-formula>
Where <italic toggle="yes">β</italic><sub><italic toggle="yes">Choice</italic></sub> and <italic toggle="yes">β</italic><sub><italic toggle="yes">Lapse</italic></sub> are parameter vectors, and <italic toggle="yes">X</italic><sub><italic toggle="yes">Choice</italic></sub> and <italic toggle="yes">X</italic><sub><italic toggle="yes">Lapse</italic></sub> are design matrices. Our RT sub-function used a shifted lognormal likelihood function:
<disp-formula id="ueqn3" hwp:id="disp-formula-3">
<alternatives hwp:id="alternatives-3"><graphic xlink:href="459546v2_ueqn3.gif" position="float" orientation="portrait" hwp:id="graphic-23"/></alternatives>
</disp-formula>
Where again <italic toggle="yes">β</italic><sub><italic toggle="yes">RT</italic>,</sub><italic toggle="yes">X</italic><sub><italic toggle="yes">RT</italic>,</sub> is a linear model, and <italic toggle="yes">ndt</italic> is the estimated non-decision time. Rare RTs less than <italic toggle="yes">ndt</italic> were assigned a small likelihood.</p><p hwp:id="p-76">Finally, the prior probability of the parameters was evaluated under a multivariate normal distribution defined by the group-level parameter mean and covariance, improving the robustness of our estimates through regularization. Critically, we estimated this group-level covariance across both choice and RT parameters, which better regularized our estimates and produced a joint model of performance at the group level.</p><p hwp:id="p-77">All regression design matrices included an intercept (choice bias or average RT), an autoregressive component (previous trial’s choice or RT), and the transformed target and distractor coherence (scaled between −1 and 1). We transformed feature coherences using a saturating nonlinearity,
<disp-formula id="ueqn4" hwp:id="disp-formula-4">
<alternatives hwp:id="alternatives-4"><graphic xlink:href="459546v2_ueqn4.gif" position="float" orientation="portrait" hwp:id="graphic-24"/></alternatives>
</disp-formula>
with <italic toggle="yes">α</italic><sub><italic toggle="yes">target</italic></sub> and <italic toggle="yes">α</italic><sub><italic toggle="yes">distractor</italic></sub> fit as free parameters. This approach distinguishes the coherence nonlinearity (<italic toggle="yes">α</italic>) from how strongly coherence influences performance (<italic toggle="yes">β</italic><sub><italic toggle="yes">Choice</italic></sub> and <italic toggle="yes">β</italic><sub><italic toggle="yes">RT</italic>,</sub>), with our analyses focused on the latter. To constrain these <italic toggle="yes">α</italic> parameters, we estimated one parameter for both choice and RT, capturing similar non-linearities across both performance measures.</p><p hwp:id="p-78">In our more complex models (e.g., incentives), our primary focus was on how additional task features moderated the influence of feature coherence on performance. Lower order effects of moderating factors (e.g., previous distractor congruence) were included in the lapse rate for choice analysis, and as a main effect in RT analyses. The full parameter sets for all analyses are available in Supplementary Data.</p><p hwp:id="p-79">We excluded trials in our regression if they were 1) the first trial of the block, 2) shorter than 200ms or longer than 2s, 3) occurred after an error or after a trial was too fast/slow and 4) in reaction time analyses, if the current trial was an error. These exclusion criteria were chosen to be inclusive, while avoiding trials where there were likely to be a mixture of different cognitive processes (e.g., post-error adjustments).</p><p hwp:id="p-80">We performed statistical inference on the parameters using an estimate of the group-level error variance from the emfit package, necessary to avoid violations of independence across participants from our hierarchical modelling. Contrast tests across models used Welsh’s (unequal variance) t-tests, with contrasts weighting studies by the square root of the sample size. We aggregated <italic toggle="yes">p</italic>-values across studies using Lipták’s method (<xref ref-type="bibr" rid="c30" hwp:id="xref-ref-30-1" hwp:rel-id="ref-30">Lipták, 1958</xref>; <xref ref-type="bibr" rid="c70" hwp:id="xref-ref-70-1" hwp:rel-id="ref-70">Zaykin, 2011</xref>), weighting studies by the square root of their sample size. Correlations between parameters were calculated by converting the group-level MAP covariance matrix to a correlation matrix.</p><p hwp:id="p-81">We generated posterior predictive checks (trend lines on figures) by generating model predictions for all trials, and then aggregating these predictions in the same way as participants’ behavior. This approach allows us to distinguish whether our model systematically deviates from behavior from whether deviations are driven by variability in parameters across participants.</p><p hwp:id="p-82">We generated sensitivity dynamics plots (e.g., <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-7" hwp:rel-id="F6">Figure 6</xref>) by computing the regression-estimated coherence effect conditioned on RT. For a range of simulated RTs, the estimated motion sensitivity timeseries is:
<disp-formula id="ueqn5" hwp:id="disp-formula-5">
<alternatives hwp:id="alternatives-5"><graphic xlink:href="459546v2_ueqn5.gif" position="float" orientation="portrait" hwp:id="graphic-25"/></alternatives>
</disp-formula>
Where <italic toggle="yes">βs</italic> are regression weights estimated in our analysis, <italic toggle="yes">SimRT</italic> is a vector of simulated RTs (e.g., .5:.01:1), and ⊙ indicates element-wise multiplication. For control-dependent dynamics (i.e., incentivized dynamics; see <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-6" hwp:rel-id="F7">Figure 7</xref>), we included 2-way and 3-way interactions between feature sensitivity, RT, and control drivers. We generated these sensitivity dynamics for each participant, and then plotted the mean and between-participant standard error.</p></sec><sec id="s4h" hwp:id="sec-22"><title hwp:id="title-41">Feedforward Inhibition with Control Model</title><p hwp:id="p-83">To provide a bridge between our regression analyses and processes models of decision-making, we adopted a generative modeling approach and tested whether participants behavior could be reproduced by a sequential sampling model (<xref rid="fig8" ref-type="fig" hwp:id="xref-fig-8-2" hwp:rel-id="F8">Figure 8</xref>). See simulation code for full parameter set at github.com/shenhavlab/PACT-public.</p><p hwp:id="p-84">This model takes as inputs the color and motion coherence in support of different responses (e.g., <italic toggle="yes">coh</italic><sub><italic toggle="yes">colorLeft</italic></sub>), nonlinearly transforms these inputs (e.g., <italic toggle="yes">coh</italic><sup>*</sup><sub><italic toggle="yes">colorLeft</italic></sub>; see regression analyses above), and then integrates evidence for each response in separate rectified accumulators (<italic toggle="yes">x</italic><sub><italic toggle="yes">left</italic></sub> and <italic toggle="yes">x</italic><sub><italic toggle="yes">right</italic></sub>).</p><p hwp:id="p-85">For example, evidence for the left response would be calculated as:
<disp-formula id="ueqn6" hwp:id="disp-formula-6">
<alternatives hwp:id="alternatives-6"><graphic xlink:href="459546v2_ueqn6.gif" position="float" orientation="portrait" hwp:id="graphic-26"/></alternatives>
</disp-formula>
The model makes a choice when one of the accumulators reaches a linearly collapsing decision bound rectified above 0.01. We used a balanced feedforward inhibition model without leak (<italic toggle="yes">λ</italic> = 0 and <italic toggle="yes">ω</italic> = 1), approximating a (rectified) drift diffusion process (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-2" hwp:rel-id="ref-2">Bogacz et al., 2006</xref>). Note that parameterizations of a leaky competing accumulator could also approximate the DDM (<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">Bogacz et al., 2007</xref>, <xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-3" hwp:rel-id="ref-2">2006</xref>), and so are plausible alternatives to our implementation. We preferred the FFI model because it provides a simple interpolation between DDM and race-like decision processes.</p><p hwp:id="p-86">To capture dynamics in participants’ feature sensitivity, we modified our accumulation model to incorporate an attractor network for the feature weights, a model we call the feedforward inhibition with control model (FFIc model). This control process has a gain setpoint (e.g., aims for zero gain on distractors), and noisily drives the gain from its initial condition (<italic toggle="yes">β</italic><sup>0</sup>) towards this attractor according to a gain <italic toggle="yes">K</italic>. For example, the motion gain would be governed by:
<disp-formula id="ueqn7" hwp:id="disp-formula-7">
<alternatives hwp:id="alternatives-7"><graphic xlink:href="459546v2_ueqn7.gif" position="float" orientation="portrait" hwp:id="graphic-27"/></alternatives>
</disp-formula>
With the leak term <italic toggle="yes">γ</italic> fixed to 0 as in the decision process.</p><p hwp:id="p-87">We simulated 10,000 trials for each combination of target discriminability and distractor congruence (11 × 11 × 10,000), and then aggregated simulated behavior in the same way we aggregated participants’ behavior.</p></sec></sec><sec sec-type="supplementary-material" hwp:id="sec-23"><title hwp:id="title-42">Supporting information</title><supplementary-material position="float" orientation="portrait" hwp:id="DC1"><object-id pub-id-type="other" hwp:sub-type="slug">DC1</object-id><label>withinTrial models</label><media xlink:href="supplements/459546_file02.xlsx" position="float" orientation="portrait" hwp:id="media-1"/></supplementary-material><supplementary-material position="float" orientation="portrait" hwp:id="DC2"><object-id pub-id-type="other" hwp:sub-type="slug">DC2</object-id><label>priorConflict models</label><media xlink:href="supplements/459546_file03.xlsx" position="float" orientation="portrait" hwp:id="media-2"/></supplementary-material><supplementary-material position="float" orientation="portrait" hwp:id="DC3"><object-id pub-id-type="other" hwp:sub-type="slug">DC3</object-id><label>incentives models</label><media xlink:href="supplements/459546_file04.xlsx" position="float" orientation="portrait" hwp:id="media-3"/></supplementary-material></sec></body><back><sec id="s5" hwp:id="sec-24"><title hwp:id="title-43">Supplementary Tables</title><table-wrap id="tblS1" orientation="portrait" position="float" hwp:id="T7" hwp:rev-id="xref-table-wrap-7-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBLS1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T7</object-id><object-id pub-id-type="publisher-id">tblS1</object-id><label>Supplementary Table 1.</label><caption hwp:id="caption-18"><title hwp:id="title-44">Target and distractor sensitivity (Attend-Motion)</title></caption><graphic xlink:href="459546v2_tblS1" position="float" orientation="portrait" hwp:id="graphic-28"/></table-wrap><table-wrap id="tblS2" orientation="portrait" position="float" hwp:id="T8" hwp:rev-id="xref-table-wrap-8-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBLS2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T8</object-id><object-id pub-id-type="publisher-id">tblS2</object-id><label>Supplementary Table 2.</label><caption hwp:id="caption-19"><title hwp:id="title-45">Target and distractor sensitivity (Attend-Color - Attend-Motion)</title></caption><graphic xlink:href="459546v2_tblS2" position="float" orientation="portrait" hwp:id="graphic-29"/></table-wrap><table-wrap id="tblS3" orientation="portrait" position="float" hwp:id="T9" hwp:rev-id="xref-table-wrap-9-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBLS3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T9</object-id><object-id pub-id-type="publisher-id">tblS3</object-id><label>Supplementary Table 3.</label><caption hwp:id="caption-20"><title hwp:id="title-46">Correlations between RT and accuracy betas</title></caption><graphic xlink:href="459546v2_tblS3" position="float" orientation="portrait" hwp:id="graphic-30"/><graphic xlink:href="459546v2_tblS3a" position="float" orientation="portrait" hwp:id="graphic-31"/></table-wrap><table-wrap id="tblS4" orientation="portrait" position="float" hwp:id="T10" hwp:rev-id="xref-table-wrap-10-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBLS4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T10</object-id><object-id pub-id-type="publisher-id">tblS4</object-id><label>Supplementary Table 4.</label><caption hwp:id="caption-21"><title hwp:id="title-47">Effects of previous conflict on feature sensitivity (Attend-Motion)</title></caption><graphic xlink:href="459546v2_tblS4" position="float" orientation="portrait" hwp:id="graphic-32"/></table-wrap><table-wrap id="tblS5" orientation="portrait" position="float" hwp:id="T11" hwp:rev-id="xref-table-wrap-11-1 xref-table-wrap-11-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBLS5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T11</object-id><object-id pub-id-type="publisher-id">tblS5</object-id><label>Supplementary Table 5.</label><caption hwp:id="caption-22"><title hwp:id="title-48">Effects of previous conflict on feature sensitivity (Attend-Color - Attend-Motion)</title></caption><graphic xlink:href="459546v2_tblS5" position="float" orientation="portrait" hwp:id="graphic-33"/></table-wrap><table-wrap id="tblS6" orientation="portrait" position="float" hwp:id="T12" hwp:rev-id="xref-table-wrap-12-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBLS6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T12</object-id><object-id pub-id-type="publisher-id">tblS6</object-id><label>Supplementary Table 6.</label><caption hwp:id="caption-23"><title hwp:id="title-49">Effects of incentives on feature sensitivity (Attend-Motion)</title></caption><graphic xlink:href="459546v2_tblS6" position="float" orientation="portrait" hwp:id="graphic-34"/><graphic xlink:href="459546v2_tblS6a" position="float" orientation="portrait" hwp:id="graphic-35"/></table-wrap><table-wrap id="tblS6b" orientation="portrait" position="float" hwp:id="T13"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBLS6B</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T13</object-id><object-id pub-id-type="publisher-id">tblS6b</object-id><label>Supplementary Table 6.</label><caption hwp:id="caption-24"><title hwp:id="title-50">Effects of incentives on feature sensitivity (Attend-Color - Attend-Motion)</title></caption><graphic xlink:href="459546v2_tblS6b" position="float" orientation="portrait" hwp:id="graphic-36"/></table-wrap><table-wrap id="tblS8" orientation="portrait" position="float" hwp:id="T14" hwp:rev-id="xref-table-wrap-14-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBLS8</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T14</object-id><object-id pub-id-type="publisher-id">tblS8</object-id><label>Supplementary Table 8.</label><caption hwp:id="caption-25"><title hwp:id="title-51">Dynamics of feature sensitivity across response times (Attend-Motion)</title></caption><graphic xlink:href="459546v2_tblS8" position="float" orientation="portrait" hwp:id="graphic-37"/></table-wrap><table-wrap id="tblS9" orientation="portrait" position="float" hwp:id="T15" hwp:rev-id="xref-table-wrap-15-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/TBLS9</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T15</object-id><object-id pub-id-type="publisher-id">tblS9</object-id><label>Supplementary Table 9.</label><caption hwp:id="caption-26"><title hwp:id="title-52">Dynamics of feature sensitivity across response times (Attend-Color - Attend- Motion)</title></caption><graphic xlink:href="459546v2_tblS9" position="float" orientation="portrait" hwp:id="graphic-38"/><graphic xlink:href="459546v2_tblS9a" position="float" orientation="portrait" hwp:id="graphic-39"/></table-wrap></sec><sec id="s6" hwp:id="sec-25"><title hwp:id="title-53">Supplementary Figures</title><fig id="figS1" position="float" fig-type="figure" orientation="portrait" hwp:id="F12" hwp:rev-id="xref-fig-12-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIGS1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F12</object-id><object-id pub-id-type="publisher-id">figS1</object-id><label>Supplementary Figure 1.</label><caption hwp:id="caption-27"><title hwp:id="title-54">Regression schematic.</title><p hwp:id="p-88">To estimate feature sensitivity, trial-specific color (green) and motion (cyan) coherence levels were passed through a hyperbolic tangent non-linearity (tanh), with the <italic toggle="yes">α</italic> parameter determining the strength of the non-linearity (see Methods). We estimated the linear mapping from this transformed coherence onto to RT (red) and Choice (blue) as participants feature sensitivity. Our critical analyses tested whether potential indices of control (e.g., task instructions or incentives) interacted with these estimates of feature sensitivity.</p></caption><graphic xlink:href="459546v2_figS1" position="float" orientation="portrait" hwp:id="graphic-40"/></fig><fig id="figS2" position="float" fig-type="figure" orientation="portrait" hwp:id="F13" hwp:rev-id="xref-fig-13-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIGS2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F13</object-id><object-id pub-id-type="publisher-id">figS2</object-id><label>Supplementary Figure 2.</label><caption hwp:id="caption-28"><title hwp:id="title-55">Target-dependent adaptation.</title><p hwp:id="p-89"><bold>A-B)</bold> The relationship between target coherence and accuracy (A) was weaker when the previous trial had weaker target coherence (redder colors). There was not a significant effect for RT (B) Lines depict aggregated regression predictions. <bold>C)</bold> Regression estimates for the current target coherence by previous target coherence interaction, within each experiment. <bold>D-E)</bold> There was not a significant relationship between distractor congruence and previous target coherence in accuracy (D) or RT (E). <bold>F)</bold> Regression estimates for the current distractor congruence by previous target coherence interaction, within each experiment. Error bars on behavior reflect within-participant SEM, error bars on regression coefficients reflect 95% CI.</p></caption><graphic xlink:href="459546v2_figS2" position="float" orientation="portrait" hwp:id="graphic-41"/></fig><fig id="figS3" position="float" fig-type="figure" orientation="portrait" hwp:id="F14" hwp:rev-id="xref-fig-14-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIGS3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F14</object-id><object-id pub-id-type="publisher-id">figS3</object-id><label>Supplementary Figure 3.</label><caption hwp:id="caption-29"><title hwp:id="title-56">Leak competing accumulator simulation.</title><p hwp:id="p-90"><bold>A)</bold> We simulated behavior from a leaky competing accumulator (<xref ref-type="bibr" rid="c61" hwp:id="xref-ref-61-1" hwp:rel-id="ref-61">Usher and McClelland, 2001</xref>). In this model, the response accumulators directly compete. In our parameter regime, leak and competition parameters produce race-like accumulation dynamics (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-4" hwp:rel-id="ref-2">Bogacz et al., 2006</xref>; <xref ref-type="bibr" rid="c62" hwp:id="xref-ref-62-7" hwp:rel-id="ref-62">Weichart et al., 2020</xref>). <bold>B-C)</bold> We found that this parameter regime was unable to capture the effect of distractor congruence on reaction time, as stronger inputs (congruent or incongruent) produce faster RTs in a race-like regime (<xref ref-type="bibr" rid="c57" hwp:id="xref-ref-57-2" hwp:rel-id="ref-57">Teodorescu and Usher, 2013</xref>). Other parameter regime, producing DDM-like dynamics, would replicate our main simulation results (<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-5" hwp:rel-id="ref-2">Bogacz et al., 2006</xref>).</p></caption><graphic xlink:href="459546v2_figS3" position="float" orientation="portrait" hwp:id="graphic-42"/></fig><fig id="figS4" position="float" fig-type="figure" orientation="portrait" hwp:id="F15" hwp:rev-id="xref-fig-15-1 xref-fig-15-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.09.08.459546v2/FIGS4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F15</object-id><object-id pub-id-type="publisher-id">figS4</object-id><label>Supplementary Figure 4.</label><caption hwp:id="caption-30"><title hwp:id="title-57">Static feature gain simulations.</title><p hwp:id="p-91">We simulated the FFI model under different formulations that lack feature sensitivity dynamics, showing that gain dynamics are necessary to capture the RT- and Accuracy-dependent feature sensitivity we observed in participants’ behavior. Feature-specific processes are necessary to capture the opposite-going dynamics on target sensitivity and distractor sensitivity. A) Static model without feature dynamics. B) Static model without feature dynamics or collapse response threshold. C) Static model without feature dynamics, collapsing response threshold, or positive-rectified accumulators.</p></caption><graphic xlink:href="459546v2_figS4" position="float" orientation="portrait" hwp:id="graphic-43"/></fig></sec><ack hwp:id="ack-1"><title hwp:id="title-58">Acknowledgements</title><p hwp:id="p-92">This work was supported by the Daniel Cooper Graduate Student Fellowship (H.R.), as well as grants R01MH124849 and NSF CAREER Award 2046111 (A.S.). We are grateful to Kia Sadahiro, William McNelis, Allison Loynd, and Savannah Doelfel for assistance in data collection, and to Michael J. Frank, Matthew N. Nassar, Jonathan Cohen, David Badre, Tobias Egner, Senne Braem, Sebastian Musslick, and both the Shenhav Lab and LNCC for helpful discussions on these topics.</p></ack><sec id="s7" sec-type="COI-statement" hwp:id="sec-26"><title hwp:id="title-59">Conflicts of Interest</title><p hwp:id="p-93">None</p></sec><sec id="s8" hwp:id="sec-27"><title hwp:id="title-60">Data Availability</title><p hwp:id="p-94">Data and analysis scripts are available at github.com/shenhavlab/PACT-public</p></sec><ref-list hwp:id="ref-list-1"><title hwp:id="title-61">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1 xref-ref-1-2 xref-ref-1-3 xref-ref-1-4 xref-ref-1-5 xref-ref-1-6"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Adkins TJ"><surname>Adkins</surname> <given-names>TJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lee T."><surname>Lee</surname> <given-names>T.</given-names></string-name> <year>2021</year>. <source hwp:id="source-1">Reward reduces habitual errors by enhancing the preparation of goal-directed actions</source>. doi:<pub-id pub-id-type="doi">10.31234/osf.io/hv9mz</pub-id></citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1 xref-ref-2-2 xref-ref-2-3 xref-ref-2-4 xref-ref-2-5"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Bogacz R"><surname>Bogacz</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Brown E"><surname>Brown</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Moehlis J"><surname>Moehlis</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Holmes P"><surname>Holmes</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>. <year>2006</year>. <article-title hwp:id="article-title-2">The physics of optimal decision making: a formal analysis of models of performance in two-alternative forced-choice tasks</article-title>. <source hwp:id="source-2">Psychol Rev</source> <volume>113</volume>:<fpage>700</fpage>–<lpage>765</lpage>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Bogacz R"><surname>Bogacz</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Usher M"><surname>Usher</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zhang J"><surname>Zhang</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="McClelland JL"><surname>McClelland</surname> <given-names>JL</given-names></string-name>. <year>2007</year>. <article-title hwp:id="article-title-3">Extending a biologically inspired model of choice: multi-alternatives, nonlinearity and value-based multidimensional choice</article-title>. <source hwp:id="source-3">Philos Trans R Soc Lond B Biol Sci</source> <volume>362</volume>:<fpage>1655</fpage>–<lpage>1670</lpage>.</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1 xref-ref-4-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Botvinick MM"><surname>Botvinick</surname> <given-names>MM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Braver TS"><surname>Braver</surname> <given-names>TS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Barch DM"><surname>Barch</surname> <given-names>DM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Carter CS"><surname>Carter</surname> <given-names>CS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>. <year>2001</year>. <article-title hwp:id="article-title-4">Conflict monitoring and cognitive control</article-title>. <source hwp:id="source-4">Psychol Rev</source> <volume>108</volume>:<fpage>624</fpage>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Botvinick MM"><surname>Botvinick</surname> <given-names>MM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>. <year>2014</year>. <article-title hwp:id="article-title-5">The computational and neural basis of cognitive control: charted territory and new frontiers</article-title>. <source hwp:id="source-5">Cogn Sci</source> <volume>38</volume>:<fpage>1249</fpage>–<lpage>1285</lpage>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Braem S"><surname>Braem</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bugg JM"><surname>Bugg</surname> <given-names>JM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schmidt JR"><surname>Schmidt</surname> <given-names>JR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Crump MJC"><surname>Crump</surname> <given-names>MJC</given-names></string-name>, <string-name name-style="western" hwp:sortable="Weissman DH"><surname>Weissman</surname> <given-names>DH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Notebaert W"><surname>Notebaert</surname> <given-names>W</given-names></string-name>, <string-name name-style="western" hwp:sortable="Egner T."><surname>Egner</surname> <given-names>T.</given-names></string-name> <year>2019</year>. <article-title hwp:id="article-title-6">Measuring Adaptive Control in Conflict Tasks</article-title>. <source hwp:id="source-6">Trends Cogn Sci</source> <volume>0</volume>. doi:<pub-id pub-id-type="doi">10.1016/j.tics.2019.07.002</pub-id></citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1 xref-ref-7-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Britten KH"><surname>Britten</surname> <given-names>KH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shadlen MN"><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newsome WT"><surname>Newsome</surname> <given-names>WT</given-names></string-name>, <string-name name-style="western" hwp:sortable="Movshon JA"><surname>Movshon</surname> <given-names>JA</given-names></string-name>. <year>1992</year>. <article-title hwp:id="article-title-7">The analysis of visual motion: a comparison of neuronal and psychophysical performance</article-title>. <source hwp:id="source-7">J Neurosci</source> <volume>12</volume>:<fpage>4745</fpage>–<lpage>4765</lpage>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Bustamante L"><surname>Bustamante</surname> <given-names>L</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lieder F"><surname>Lieder</surname> <given-names>F</given-names></string-name>, <string-name name-style="western" hwp:sortable="Musslick S"><surname>Musslick</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shenhav A"><surname>Shenhav</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen J."><surname>Cohen</surname> <given-names>J.</given-names></string-name> <year>2021</year>. <article-title hwp:id="article-title-8">Learning to Overexert Cognitive Control in a Stroop Task</article-title>. <source hwp:id="source-8">Cogn Affect Behav Neurosci</source>. doi:<pub-id pub-id-type="doi">10.3758/s13415-020-00845-x</pub-id></citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Callaway F"><surname>Callaway</surname> <given-names>F</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rangel A"><surname>Rangel</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Griffiths TL"><surname>Griffiths</surname> <given-names>TL</given-names></string-name>. <year>2021</year>. <article-title hwp:id="article-title-9">Fixation patterns in simple choice reflect optimal information sampling</article-title>. <source hwp:id="source-9">PLoS Comput Biol</source> <volume>17</volume>:<fpage>e1008863</fpage>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Churchland MM"><surname>Churchland</surname> <given-names>MM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cunningham JP"><surname>Cunningham</surname> <given-names>JP</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kaufman MT"><surname>Kaufman</surname> <given-names>MT</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ryu SI"><surname>Ryu</surname> <given-names>SI</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shenoy KV"><surname>Shenoy</surname> <given-names>KV</given-names></string-name>. <year>2010</year>. <article-title hwp:id="article-title-10">Cortical preparatory activity: representation of movement or first cog in a dynamical machine?</article-title> <source hwp:id="source-10">Neuron</source> <volume>68</volume>:<fpage>387</fpage>–<lpage>400</lpage>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1 xref-ref-11-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dunbar K"><surname>Dunbar</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="McClelland JL"><surname>McClelland</surname> <given-names>JL</given-names></string-name>. <year>1990</year>. <article-title hwp:id="article-title-11">On the control of automatic processes: a parallel distributed processing account of the Stroop effect</article-title>. <source hwp:id="source-11">Psychol Rev</source> <volume>97</volume>:<fpage>332</fpage>–<lpage>361</lpage>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.12" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Servan-Schreiber D"><surname>Servan-Schreiber</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="McClelland JL"><surname>McClelland</surname> <given-names>JL</given-names></string-name>. <year>1992</year>. <article-title hwp:id="article-title-12">A parallel distributed processing approach to automaticity</article-title>. <source hwp:id="source-12">Am J Psychol</source> <volume>105</volume>:<fpage>239</fpage>–<lpage>269</lpage>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1 xref-ref-13-2 xref-ref-13-3 xref-ref-13-4 xref-ref-13-5 xref-ref-13-6 xref-ref-13-7"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Danielmeier C"><surname>Danielmeier</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Eichele T"><surname>Eichele</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Forstmann BU"><surname>Forstmann</surname> <given-names>BU</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tittgemeyer M"><surname>Tittgemeyer</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ullsperger M."><surname>Ullsperger</surname> <given-names>M.</given-names></string-name> <year>2011</year>. <article-title hwp:id="article-title-13">Posterior medial frontal cortex activity predicts post-error adaptations in task-related visual and motor areas</article-title>. <source hwp:id="source-13">J Neurosci</source> <volume>31</volume>:<fpage>1780</fpage>–<lpage>1789</lpage>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="De Jong R"><surname>De Jong</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Liang CC"><surname>Liang</surname> <given-names>CC</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lauber E."><surname>Lauber</surname> <given-names>E.</given-names></string-name> <year>1994</year>. <article-title hwp:id="article-title-14">Conditional and unconditional automaticity: a dual-process model of effects of spatial stimulus-response correspondence</article-title>. <source hwp:id="source-14">J Exp Psychol Hum Percept Perform</source> <volume>20</volume>:<fpage>731</fpage>–<lpage>750</lpage>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1 xref-ref-15-2 xref-ref-15-3 xref-ref-15-4 xref-ref-15-5 xref-ref-15-6"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.15" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Egner T."><surname>Egner</surname> <given-names>T.</given-names></string-name> <year>2007</year>. <article-title hwp:id="article-title-15">Congruency sequence effects and cognitive control</article-title>. <source hwp:id="source-15">Cogn Affect Behav Neurosci</source> <volume>7</volume>:<fpage>380</fpage>–<lpage>390</lpage>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Egner T"><surname>Egner</surname> <given-names>T</given-names></string-name>, <string-name name-style="western" hwp:sortable="Delano M"><surname>Delano</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hirsch J."><surname>Hirsch</surname> <given-names>J.</given-names></string-name> <year>2007</year>. <article-title hwp:id="article-title-16">Separate conflict-specific cognitive control mechanisms in the human brain</article-title>. <source hwp:id="source-16">Neuroimage</source> <volume>35</volume>:<fpage>940</fpage>–<lpage>948</lpage>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Erb CD"><surname>Erb</surname> <given-names>CD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Moher J"><surname>Moher</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sobel DM"><surname>Sobel</surname> <given-names>DM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Song J-H."><surname>Song</surname> <given-names>J-H.</given-names></string-name> <year>2016</year>. <article-title hwp:id="article-title-17">Reach tracking reveals dissociable processes underlying cognitive control</article-title>. <source hwp:id="source-17">Cognition</source> <volume>152</volume>:<fpage>114</fpage>–<lpage>126</lpage>.</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Fischer AG"><surname>Fischer</surname> <given-names>AG</given-names></string-name>, <string-name name-style="western" hwp:sortable="Nigbur R"><surname>Nigbur</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Klein TA"><surname>Klein</surname> <given-names>TA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Danielmeier C"><surname>Danielmeier</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ullsperger M."><surname>Ullsperger</surname> <given-names>M.</given-names></string-name> <year>2018</year>. <article-title hwp:id="article-title-18">Cortical beta power reflects decision dynamics and uncovers multiple facets of post-error adaptation</article-title>. <source hwp:id="source-18">Nat Commun</source> <volume>9</volume>:<fpage>5038</fpage>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1 xref-ref-19-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Gold JI"><surname>Gold</surname> <given-names>JI</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shadlen MN"><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <year>2007</year>. <article-title hwp:id="article-title-19">The neural basis of decision making</article-title>. <source hwp:id="source-19">Annu Rev Neurosci</source> <volume>30</volume>:<fpage>535</fpage>–<lpage>574</lpage>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1 xref-ref-20-2 xref-ref-20-3"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Gratton G"><surname>Gratton</surname> <given-names>G</given-names></string-name>, <string-name name-style="western" hwp:sortable="Coles MGH"><surname>Coles</surname> <given-names>MGH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Donchin E."><surname>Donchin</surname> <given-names>E.</given-names></string-name> <year>1992</year>. <article-title hwp:id="article-title-20">Optimizing the use of information: strategic control of activation of responses</article-title>. <source hwp:id="source-20">J Exp Psychol Gen</source> <volume>121</volume>:<fpage>480</fpage>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1 xref-ref-21-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Hardwick RM"><surname>Hardwick</surname> <given-names>RM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Forrence AD"><surname>Forrence</surname> <given-names>AD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Krakauer JW"><surname>Krakauer</surname> <given-names>JW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Haith AM"><surname>Haith</surname> <given-names>AM</given-names></string-name>. <year>2019</year>. <article-title hwp:id="article-title-21">Time-dependent competition between goal-directed and habitual response preparation</article-title>. <source hwp:id="source-21">Nat Hum Behav</source> <volume>3</volume>:<fpage>1252</fpage>–<lpage>1262</lpage>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Hommel B"><surname>Hommel</surname> <given-names>B</given-names></string-name>, <string-name name-style="western" hwp:sortable="Proctor RW"><surname>Proctor</surname> <given-names>RW</given-names></string-name>, <string-name name-style="western" hwp:sortable="K-PL Vu"><given-names>Vu</given-names> <surname>K-PL</surname></string-name>. <year>2004</year>. <article-title hwp:id="article-title-22">A feature-integration account of sequential effects in the Simon task</article-title>. <source hwp:id="source-22">Psychol Res</source> <volume>68</volume>:<fpage>1</fpage>–<lpage>17</lpage>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Jiang J"><surname>Jiang</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Heller K"><surname>Heller</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Egner T."><surname>Egner</surname> <given-names>T.</given-names></string-name> <year>2014</year>. <article-title hwp:id="article-title-23">Bayesian modeling of flexible cognitive control</article-title>. <source hwp:id="source-23">Neurosci Biobehav Rev</source> <volume>46 Pt 1</volume>:<fpage>30</fpage>–<lpage>43</lpage>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1 xref-ref-24-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Kang YH"><surname>Kang</surname> <given-names>YH</given-names></string-name>, <string-name name-style="western" hwp:sortable="Löffler A"><surname>Löffler</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jeurissen D"><surname>Jeurissen</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zylberberg A"><surname>Zylberberg</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wolpert DM"><surname>Wolpert</surname> <given-names>DM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shadlen MN"><surname>Shadlen</surname> <given-names>MN</given-names></string-name>. <year>2021</year>. <article-title hwp:id="article-title-24">Multiple decisions about one object involve parallel sensory acquisition but time-multiplexed evidence incorporation</article-title>. <source hwp:id="source-24">Elife</source> <volume>10</volume>. doi:<pub-id pub-id-type="doi">10.7554/eLife.63721</pub-id></citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Krajbich I"><surname>Krajbich</surname> <given-names>I</given-names></string-name>, <string-name name-style="western" hwp:sortable="Armel C"><surname>Armel</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Rangel A."><surname>Rangel</surname> <given-names>A.</given-names></string-name> <year>2010</year>. <article-title hwp:id="article-title-25">Visual fixations and the computation and comparison of value in simple choice</article-title>. <source hwp:id="source-25">Nat Neurosci</source> <volume>13</volume>:<fpage>1292</fpage>–<lpage>1298</lpage>.</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.26" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Leng X"><surname>Leng</surname> <given-names>X</given-names></string-name>, <string-name name-style="western" hwp:sortable="Yee D"><surname>Yee</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ritz H"><surname>Ritz</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shenhav A."><surname>Shenhav</surname> <given-names>A.</given-names></string-name> <year>2020</year>. <article-title hwp:id="article-title-26">Dissociable influences of reward and punishment on adaptive cognitive control</article-title>. <source hwp:id="source-26">bioRxiv</source>. doi:<pub-id pub-id-type="doi">10.1101/2020.09.11.294157</pub-id></citation></ref><ref id="c27" hwp:id="ref-27" hwp:rev-id="xref-ref-27-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.27" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Li Z-W"><surname>Li</surname> <given-names>Z-W</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ma WJ"><surname>Ma</surname> <given-names>WJ</given-names></string-name>. <year>2021</year>. <article-title hwp:id="article-title-27">An uncertainty-based model of the effects of fixation on choice</article-title>. <source hwp:id="source-27">PLoS Comput Biol</source> <volume>17</volume>:<fpage>e1009190</fpage>.</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1 xref-ref-28-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.28" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Lieder F"><surname>Lieder</surname> <given-names>F</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shenhav A"><surname>Shenhav</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Musslick S"><surname>Musslick</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Griffiths TL"><surname>Griffiths</surname> <given-names>TL</given-names></string-name>. <year>2018</year>. <article-title hwp:id="article-title-28">Rational metareasoning and the plasticity of cognitive control</article-title>. <source hwp:id="source-28">PLoS Comput Biol</source> <volume>14</volume>:<fpage>e1006043</fpage>.</citation></ref><ref id="c29" hwp:id="ref-29" hwp:rev-id="xref-ref-29-1 xref-ref-29-2 xref-ref-29-3"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.29" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="Lindsay DS"><surname>Lindsay</surname> <given-names>DS</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jacoby LL"><surname>Jacoby</surname> <given-names>LL</given-names></string-name>. <year>1994</year>. <article-title hwp:id="article-title-29">Stroop process dissociations: the relationship between facilitation and interference</article-title>. <source hwp:id="source-29">J Exp Psychol Hum Percept Perform</source> <volume>20</volume>:<fpage>219</fpage>–<lpage>234</lpage>.</citation></ref><ref id="c30" hwp:id="ref-30" hwp:rev-id="xref-ref-30-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.30" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="Lipták T."><surname>Lipták</surname> <given-names>T.</given-names></string-name> <year>1958</year>. <article-title hwp:id="article-title-30">On the combination of independent tests</article-title>. <source hwp:id="source-30">Magyar Tud Akad Mat Kutato Int Kozl</source> <volume>3</volume>:<fpage>171</fpage>–<lpage>197</lpage>.</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1 xref-ref-31-2 xref-ref-31-3"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="Mante V"><surname>Mante</surname> <given-names>V</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sussillo D"><surname>Sussillo</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shenoy KV"><surname>Shenoy</surname> <given-names>KV</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newsome WT"><surname>Newsome</surname> <given-names>WT</given-names></string-name>. <year>2013</year>. <article-title hwp:id="article-title-31">Context-dependent computation by recurrent dynamics in prefrontal cortex</article-title>. <source hwp:id="source-31">Nature</source> <volume>503</volume>:<fpage>78</fpage>–<lpage>84</lpage>.</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.32" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="Mayr U"><surname>Mayr</surname> <given-names>U</given-names></string-name>, <string-name name-style="western" hwp:sortable="Awh E"><surname>Awh</surname> <given-names>E</given-names></string-name>, <string-name name-style="western" hwp:sortable="Laurey P."><surname>Laurey</surname> <given-names>P.</given-names></string-name> <year>2003</year>. <article-title hwp:id="article-title-32">Conflict adaptation effects in the absence of executive control</article-title>. <source hwp:id="source-32">Nat Neurosci</source> <volume>6</volume>:<fpage>450</fpage>–<lpage>452</lpage>.</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.33" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Menceloglu M"><surname>Menceloglu</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Suzuki S"><surname>Suzuki</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Song J-H."><surname>Song</surname> <given-names>J-H.</given-names></string-name> <year>2021</year>. <article-title hwp:id="article-title-33">Revealing the effects of temporal orienting of attention on response conflict using continuous movements</article-title>. <source hwp:id="source-33">Atten Percept Psychophys</source>. doi:<pub-id pub-id-type="doi">10.3758/s13414-020-02235-4</pub-id></citation></ref><ref id="c34" hwp:id="ref-34" hwp:rev-id="xref-ref-34-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.34" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Monsell S"><surname>Monsell</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mizon GA"><surname>Mizon</surname> <given-names>GA</given-names></string-name>. <year>2006</year>. <article-title hwp:id="article-title-34">Can the task-cuing paradigm measure an endogenous task-set reconfiguration process?</article-title> <source hwp:id="source-34">J Exp Psychol Hum Percept Perform</source> <volume>32</volume>:<fpage>493</fpage>–<lpage>516</lpage>.</citation></ref><ref id="c35" hwp:id="ref-35" hwp:rev-id="xref-ref-35-1 xref-ref-35-2 xref-ref-35-3"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.35" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Musslick S"><surname>Musslick</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bizyaeva A"><surname>Bizyaeva</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Agaron S"><surname>Agaron</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Leonard N"><surname>Leonard</surname> <given-names>N</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>. <year>2019</year>. <source hwp:id="source-35">Stability-flexibility dilemma in cognitive control: a dynamical system perspectiveProceedings of the 41st Annual Meeting of the Cognitive Science Society</source>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.36" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Musslick S"><surname>Musslick</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shenhav A"><surname>Shenhav</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Botvinick M"><surname>Botvinick</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen J."><surname>Cohen</surname> <given-names>J.</given-names></string-name> <year>2015</year>. <article-title hwp:id="article-title-35">A Computational Model of Control Allocation based on the Expected Value of Control2nd Multidisciplinary Conference on Reinforcement Learning and Decision Making</article-title>. <source hwp:id="source-36">Presented at the Multidisciplinary Conference on Reinforcement Learning and Decision Making</source>.</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.37" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Parro C"><surname>Parro</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dixon ML"><surname>Dixon</surname> <given-names>ML</given-names></string-name>, <string-name name-style="western" hwp:sortable="Christoff K."><surname>Christoff</surname> <given-names>K.</given-names></string-name> <year>2018</year>. <article-title hwp:id="article-title-36">The neural basis of motivational influences on cognitive control</article-title>. <source hwp:id="source-37">Hum Brain Mapp</source> <volume>39</volume>:<fpage>5097</fpage>–<lpage>5111</lpage>.</citation></ref><ref id="c38" hwp:id="ref-38" hwp:rev-id="xref-ref-38-1"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.38" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-38"><string-name name-style="western" hwp:sortable="Posner M"><surname>Posner</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Snyder C."><surname>Snyder</surname> <given-names>C.</given-names></string-name> <year>1975</year>. <source hwp:id="source-38">Attention and cognitive control</source>.</citation></ref><ref id="c39" hwp:id="ref-39" hwp:rev-id="xref-ref-39-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.39" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-39"><string-name name-style="western" hwp:sortable="Ratcliff R"><surname>Ratcliff</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="McKoon G."><surname>McKoon</surname> <given-names>G.</given-names></string-name> <year>2008</year>. <article-title hwp:id="article-title-37">The diffusion decision model: theory and data for two-choice decision tasks</article-title>. <source hwp:id="source-39">Neural Comput</source> <volume>20</volume>:<fpage>873</fpage>–<lpage>922</lpage>.</citation></ref><ref id="c40" hwp:id="ref-40" hwp:rev-id="xref-ref-40-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.40" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-40"><string-name name-style="western" hwp:sortable="Remington ED"><surname>Remington</surname> <given-names>ED</given-names></string-name>, <string-name name-style="western" hwp:sortable="Egger SW"><surname>Egger</surname> <given-names>SW</given-names></string-name>, <string-name name-style="western" hwp:sortable="Narain D"><surname>Narain</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wang J"><surname>Wang</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jazayeri M."><surname>Jazayeri</surname> <given-names>M.</given-names></string-name> <year>2018a</year>. <article-title hwp:id="article-title-38">A Dynamical Systems Perspective on Flexible Motor Timing</article-title>. <source hwp:id="source-40">Trends Cogn Sci</source> <volume>22</volume>:<fpage>938</fpage>–<lpage>952</lpage>.</citation></ref><ref id="c41" hwp:id="ref-41" hwp:rev-id="xref-ref-41-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.41" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-41"><string-name name-style="western" hwp:sortable="Remington ED"><surname>Remington</surname> <given-names>ED</given-names></string-name>, <string-name name-style="western" hwp:sortable="Narain D"><surname>Narain</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hosseini EA"><surname>Hosseini</surname> <given-names>EA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jazayeri M."><surname>Jazayeri</surname> <given-names>M.</given-names></string-name> <year>2018b</year>. <article-title hwp:id="article-title-39">Flexible Sensorimotor Computations through Rapid Reconfiguration of Cortical Dynamics</article-title>. <source hwp:id="source-41">Neuron</source> <volume>98</volume>:<fpage>1005</fpage>-<lpage>1019</lpage>.e5.</citation></ref><ref id="c42" hwp:id="ref-42" hwp:rev-id="xref-ref-42-1 xref-ref-42-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.42" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-42"><string-name name-style="western" hwp:sortable="Ridderinkhof KR"><surname>Ridderinkhof</surname> <given-names>KR</given-names></string-name>. <year>2002</year>. <article-title hwp:id="article-title-40">Micro- and macro-adjustments of task set: activation and suppression in conflict tasks</article-title>. <source hwp:id="source-42">Psychol Res</source> <volume>66</volume>:<fpage>312</fpage>–<lpage>323</lpage>.</citation></ref><ref id="c43" hwp:id="ref-43" hwp:rev-id="xref-ref-43-1"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.43" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-43"><string-name name-style="western" hwp:sortable="Ritz H"><surname>Ritz</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Frömer R"><surname>Frömer</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shenhav A."><surname>Shenhav</surname> <given-names>A.</given-names></string-name> <year>2020</year>. <article-title hwp:id="article-title-41">Bridging Motor and Cognitive Control: It’s About Time!</article-title> <source hwp:id="source-43">Trends Cogn Sci</source>.</citation></ref><ref id="c44" hwp:id="ref-44" hwp:rev-id="xref-ref-44-1 xref-ref-44-2 xref-ref-44-3"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.44" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-44"><string-name name-style="western" hwp:sortable="Ritz H"><surname>Ritz</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Leng X"><surname>Leng</surname> <given-names>X</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shenhav A."><surname>Shenhav</surname> <given-names>A.</given-names></string-name> <year>2021</year>. <article-title hwp:id="article-title-42">Cognitive control as a multivariate optimization problem</article-title>. <source hwp:id="source-44">arXiv [q-bioNC]</source>.</citation></ref><ref id="c45" hwp:id="ref-45" hwp:rev-id="xref-ref-45-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.45" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-45"><string-name name-style="western" hwp:sortable="Rogers RD"><surname>Rogers</surname> <given-names>RD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Monsell S."><surname>Monsell</surname> <given-names>S.</given-names></string-name> <year>1995</year>. <article-title hwp:id="article-title-43">Costs of a predictible switch between simple cognitive tasks</article-title>. <source hwp:id="source-45">J Exp Psychol Gen</source> <volume>124</volume>:<fpage>207</fpage>.</citation></ref><ref id="c46" hwp:id="ref-46" hwp:rev-id="xref-ref-46-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.46" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-46"><string-name name-style="western" hwp:sortable="Scherbaum S"><surname>Scherbaum</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dshemuchadse M"><surname>Dshemuchadse</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fischer R"><surname>Fischer</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Goschke T."><surname>Goschke</surname> <given-names>T.</given-names></string-name> <year>2010</year>. <article-title hwp:id="article-title-44">How decisions evolve: the temporal dynamics of action selection</article-title>. <source hwp:id="source-46">Cognition</source> <volume>115</volume>:<fpage>407</fpage>–<lpage>416</lpage>.</citation></ref><ref id="c47" hwp:id="ref-47" hwp:rev-id="xref-ref-47-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.47" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-47"><string-name name-style="western" hwp:sortable="Scherbaum S"><surname>Scherbaum</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fischer R"><surname>Fischer</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dshemuchadse M"><surname>Dshemuchadse</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Goschke T."><surname>Goschke</surname> <given-names>T.</given-names></string-name> <year>2011</year>. <article-title hwp:id="article-title-45">The dynamics of cognitive control: evidence for within-trial conflict adaptation from frequency-tagged EEG</article-title>. <source hwp:id="source-47">Psychophysiology</source> <volume>48</volume>:<fpage>591</fpage>–<lpage>600</lpage>.</citation></ref><ref id="c48" hwp:id="ref-48" hwp:rev-id="xref-ref-48-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.48" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-48"><string-name name-style="western" hwp:sortable="Schmidt JR"><surname>Schmidt</surname> <given-names>JR</given-names></string-name>, <string-name name-style="western" hwp:sortable="De Houwer J."><surname>De Houwer</surname> <given-names>J.</given-names></string-name> <year>2011</year>. <article-title hwp:id="article-title-46">Now you see it, now you don’t: controlling for contingencies and stimulus repetitions eliminates the Gratton effect</article-title>. <source hwp:id="source-48">Acta Psychol</source> <volume>138</volume>:<fpage>176</fpage>–<lpage>186</lpage>.</citation></ref><ref id="c49" hwp:id="ref-49" hwp:rev-id="xref-ref-49-1 xref-ref-49-2 xref-ref-49-3 xref-ref-49-4 xref-ref-49-5"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.49" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-49"><string-name name-style="western" hwp:sortable="Servant M"><surname>Servant</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Montagnini A"><surname>Montagnini</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Burle B."><surname>Burle</surname> <given-names>B.</given-names></string-name> <year>2014</year>. <article-title hwp:id="article-title-47">Conflict tasks and the diffusion framework: Insight in model constraints based on psychological laws</article-title>. <source hwp:id="source-49">Cogn Psychol</source> <volume>72</volume>:<fpage>162</fpage>–<lpage>195</lpage>.</citation></ref><ref id="c50" hwp:id="ref-50" hwp:rev-id="xref-ref-50-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.50" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-50"><string-name name-style="western" hwp:sortable="Shadlen MN"><surname>Shadlen</surname> <given-names>MN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Newsome WT"><surname>Newsome</surname> <given-names>WT</given-names></string-name>. <year>2001</year>. <article-title hwp:id="article-title-48">Neural basis of a perceptual decision in the parietal cortex (area LIP) of the rhesus monkey</article-title>. <source hwp:id="source-50">J Neurophysiol</source> <volume>86</volume>:<fpage>1916</fpage>–<lpage>1936</lpage>.</citation></ref><ref id="c51" hwp:id="ref-51" hwp:rev-id="xref-ref-51-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.51" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-51"><string-name name-style="western" hwp:sortable="Shenhav A"><surname>Shenhav</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Botvinick MM"><surname>Botvinick</surname> <given-names>MM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>. <year>2013</year>. <article-title hwp:id="article-title-49">The expected value of control: an integrative theory of anterior cingulate cortex function</article-title>. <source hwp:id="source-51">Neuron</source> <volume>79</volume>:<fpage>217</fpage>–<lpage>240</lpage>.</citation></ref><ref id="c52" hwp:id="ref-52" hwp:rev-id="xref-ref-52-1 xref-ref-52-2 xref-ref-52-3"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.52" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-52"><string-name name-style="western" hwp:sortable="Shenhav A"><surname>Shenhav</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Straccia MA"><surname>Straccia</surname> <given-names>MA</given-names></string-name>, <string-name name-style="western" hwp:sortable="Musslick S"><surname>Musslick</surname> <given-names>S</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>, <string-name name-style="western" hwp:sortable="Botvinick MM"><surname>Botvinick</surname> <given-names>MM</given-names></string-name>. <year>2018</year>. <article-title hwp:id="article-title-50">Dissociable neural mechanisms track evidence accumulation for selection of attention versus action</article-title>. <source hwp:id="source-52">Nat Commun</source> <volume>9</volume>:<fpage>2485</fpage>.</citation></ref><ref id="c53" hwp:id="ref-53" hwp:rev-id="xref-ref-53-1 xref-ref-53-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.53" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-53"><string-name name-style="western" hwp:sortable="Shiffrin RM"><surname>Shiffrin</surname> <given-names>RM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schneider W."><surname>Schneider</surname> <given-names>W.</given-names></string-name> <year>1977</year>. <article-title hwp:id="article-title-51">Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory</article-title>. <source hwp:id="source-53">Psychol Rev</source> <volume>84</volume>:<fpage>127</fpage>.</citation></ref><ref id="c54" hwp:id="ref-54" hwp:rev-id="xref-ref-54-1 xref-ref-54-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.54" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-54"><string-name name-style="western" hwp:sortable="Simen P"><surname>Simen</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Contreras D"><surname>Contreras</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Buck C"><surname>Buck</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hu P"><surname>Hu</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Holmes P"><surname>Holmes</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>. <year>2009</year>. <article-title hwp:id="article-title-52">Reward rate optimization in two-alternative decision making: empirical tests of theoretical predictions</article-title>. <source hwp:id="source-54">J Exp Psychol Hum Percept Perform</source> <volume>35</volume>:<fpage>1865</fpage>–<lpage>1897</lpage>.</citation></ref><ref id="c55" hwp:id="ref-55" hwp:rev-id="xref-ref-55-1 xref-ref-55-2 xref-ref-55-3"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.55" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-55"><string-name name-style="western" hwp:sortable="Soutschek A"><surname>Soutschek</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Stelzel C"><surname>Stelzel</surname> <given-names>C</given-names></string-name>, <string-name name-style="western" hwp:sortable="Paschke L"><surname>Paschke</surname> <given-names>L</given-names></string-name>, <string-name name-style="western" hwp:sortable="Walter H"><surname>Walter</surname> <given-names>H</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schubert T."><surname>Schubert</surname> <given-names>T.</given-names></string-name> <year>2015</year>. <article-title hwp:id="article-title-53">Dissociable effects of motivation and expectancy on conflict processing: an fMRI study</article-title>. <source hwp:id="source-55">J Cogn Neurosci</source> <volume>27</volume>:<fpage>409</fpage>–<lpage>423</lpage>.</citation></ref><ref id="c56" hwp:id="ref-56" hwp:rev-id="xref-ref-56-1 xref-ref-56-2"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.56" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-56"><string-name name-style="western" hwp:sortable="Steyvers M"><surname>Steyvers</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hawkins GE"><surname>Hawkins</surname> <given-names>GE</given-names></string-name>, <string-name name-style="western" hwp:sortable="Karayanidis F"><surname>Karayanidis</surname> <given-names>F</given-names></string-name>, <string-name name-style="western" hwp:sortable="Brown SD"><surname>Brown</surname> <given-names>SD</given-names></string-name>. <year>2019</year>. <article-title hwp:id="article-title-54">A large-scale analysis of task switching practice effects across the lifespan</article-title>. <source hwp:id="source-56">Proc Natl Acad Sci U S A</source>. doi:<pub-id pub-id-type="doi">10.1073/pnas.1906788116</pub-id></citation></ref><ref id="c57" hwp:id="ref-57" hwp:rev-id="xref-ref-57-1 xref-ref-57-2"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.57" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-57"><string-name name-style="western" hwp:sortable="Teodorescu AR"><surname>Teodorescu</surname> <given-names>AR</given-names></string-name>, <string-name name-style="western" hwp:sortable="Usher M."><surname>Usher</surname> <given-names>M.</given-names></string-name> <year>2013</year>. <article-title hwp:id="article-title-55">Disentangling decision models: from independence to competition</article-title>. <source hwp:id="source-57">Psychol Rev</source> <volume>120</volume>:<fpage>1</fpage>–<lpage>38</lpage>.</citation></ref><ref id="c58" hwp:id="ref-58" hwp:rev-id="xref-ref-58-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.58" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-58"><string-name name-style="western" hwp:sortable="Teufel HJ"><surname>Teufel</surname> <given-names>HJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wehrhahn C."><surname>Wehrhahn</surname> <given-names>C.</given-names></string-name> <year>2000</year>. <article-title hwp:id="article-title-56">Evidence for the contribution of S cones to the detection of flicker brightness and red-green</article-title>. <source hwp:id="source-58">J Opt Soc Am A Opt Image Sci Vis</source> <volume>17</volume>:<fpage>994</fpage>–<lpage>1006</lpage>.</citation></ref><ref id="c59" hwp:id="ref-59" hwp:rev-id="xref-ref-59-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.59" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-59"><string-name name-style="western" hwp:sortable="Tzelgov J"><surname>Tzelgov</surname> <given-names>J</given-names></string-name>, <string-name name-style="western" hwp:sortable="Henik A"><surname>Henik</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="Berger J."><surname>Berger</surname> <given-names>J.</given-names></string-name> <year>1992</year>. <article-title hwp:id="article-title-57">Controlling Stroop effects by manipulating expectations for color words</article-title>. <source hwp:id="source-59">Mem Cognit</source> <volume>20</volume>:<fpage>727</fpage>–<lpage>735</lpage>.</citation></ref><ref id="c60" hwp:id="ref-60" hwp:rev-id="xref-ref-60-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.60" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-60"><string-name name-style="western" hwp:sortable="Ueltzhöffer K"><surname>Ueltzhöffer</surname> <given-names>K</given-names></string-name>, <string-name name-style="western" hwp:sortable="Armbruster-Genç DJN"><surname>Armbruster-Genç</surname> <given-names>DJN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fiebach CJ"><surname>Fiebach</surname> <given-names>CJ</given-names></string-name>. <year>2015</year>. <article-title hwp:id="article-title-58">Stochastic Dynamics Underlying Cognitive Stability and Flexibility</article-title>. <source hwp:id="source-60">PLoS Comput Biol</source> <volume>11</volume>:<fpage>e1004331</fpage>.</citation></ref><ref id="c61" hwp:id="ref-61" hwp:rev-id="xref-ref-61-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.61" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-61"><string-name name-style="western" hwp:sortable="Usher M"><surname>Usher</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="McClelland JL"><surname>McClelland</surname> <given-names>JL</given-names></string-name>. <year>2001</year>. <article-title hwp:id="article-title-59">The time course of perceptual choice: the leaky, competing accumulator model</article-title>. <source hwp:id="source-61">Psychol Rev</source> <volume>108</volume>:<fpage>550</fpage>–<lpage>592</lpage>.</citation></ref><ref id="c62" hwp:id="ref-62" hwp:rev-id="xref-ref-62-1 xref-ref-62-2 xref-ref-62-3 xref-ref-62-4 xref-ref-62-5 xref-ref-62-6 xref-ref-62-7"><citation publication-type="other" citation-type="journal" ref:id="2021.09.08.459546v2.62" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-62"><string-name name-style="western" hwp:sortable="Weichart ER"><surname>Weichart</surname> <given-names>ER</given-names></string-name>, <string-name name-style="western" hwp:sortable="Turner BM"><surname>Turner</surname> <given-names>BM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Sederberg PB"><surname>Sederberg</surname> <given-names>PB</given-names></string-name>. <year>2020</year>. <article-title hwp:id="article-title-60">A model of dynamic, within-trial conflict resolution for decision making</article-title>. <source hwp:id="source-62">Psychol Rev</source>. doi:<pub-id pub-id-type="doi">10.1037/rev0000191</pub-id></citation></ref><ref id="c63" hwp:id="ref-63" hwp:rev-id="xref-ref-63-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.63" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-63"><string-name name-style="western" hwp:sortable="Westbrook A"><surname>Westbrook</surname> <given-names>A</given-names></string-name>, <string-name name-style="western" hwp:sortable="van den Bosch R"><surname>van den Bosch</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Määttä JI"><surname>Määttä</surname> <given-names>JI</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hofmans L"><surname>Hofmans</surname> <given-names>L</given-names></string-name>, <string-name name-style="western" hwp:sortable="Papadopetraki D"><surname>Papadopetraki</surname> <given-names>D</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cools R"><surname>Cools</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Frank MJ"><surname>Frank</surname> <given-names>MJ</given-names></string-name>. <year>2020</year>. <article-title hwp:id="article-title-61">Dopamine promotes cognitive effort by biasing the benefits versus costs of cognitive work</article-title>. <source hwp:id="source-63">Science</source> <volume>367</volume>:<fpage>1362</fpage>–<lpage>1366</lpage>.</citation></ref><ref id="c64" hwp:id="ref-64" hwp:rev-id="xref-ref-64-1 xref-ref-64-2 xref-ref-64-3 xref-ref-64-4 xref-ref-64-5 xref-ref-64-6"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.64" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-64"><string-name name-style="western" hwp:sortable="White CN"><surname>White</surname> <given-names>CN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ratcliff R"><surname>Ratcliff</surname> <given-names>R</given-names></string-name>, <string-name name-style="western" hwp:sortable="Starns JJ"><surname>Starns</surname> <given-names>JJ</given-names></string-name>. <year>2011</year>. <article-title hwp:id="article-title-62">Diffusion models of the flanker task: discrete versus gradual attentional selection</article-title>. <source hwp:id="source-64">Cogn Psychol</source> <volume>63</volume>:<fpage>210</fpage>–<lpage>238</lpage>.</citation></ref><ref id="c65" hwp:id="ref-65" hwp:rev-id="xref-ref-65-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.65" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-65"><string-name name-style="western" hwp:sortable="White CN"><surname>White</surname> <given-names>CN</given-names></string-name>, <string-name name-style="western" hwp:sortable="Servant M"><surname>Servant</surname> <given-names>M</given-names></string-name>, <string-name name-style="western" hwp:sortable="Logan GD"><surname>Logan</surname> <given-names>GD</given-names></string-name>. <year>2018</year>. <article-title hwp:id="article-title-63">Testing the validity of conflict drift-diffusion models for use in estimating cognitive processes: A parameter-recovery study</article-title>. <source hwp:id="source-65">Psychon Bull Rev</source> <volume>25</volume>:<fpage>286</fpage>–<lpage>301</lpage>.</citation></ref><ref id="c66" hwp:id="ref-66" hwp:rev-id="xref-ref-66-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.66" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-66"><string-name name-style="western" hwp:sortable="Wong K-F"><surname>Wong</surname> <given-names>K-F</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wang X-J."><surname>Wang</surname> <given-names>X-J.</given-names></string-name> <year>2006</year>. <article-title hwp:id="article-title-64">A recurrent network mechanism of time integration in perceptual decisions</article-title>. <source hwp:id="source-66">J Neurosci</source> <volume>26</volume>:<fpage>1314</fpage>–<lpage>1328</lpage>.</citation></ref><ref id="c67" hwp:id="ref-67" hwp:rev-id="xref-ref-67-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.67" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-67"><string-name name-style="western" hwp:sortable="Yee DM"><surname>Yee</surname> <given-names>DM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Braver TS"><surname>Braver</surname> <given-names>TS</given-names></string-name>. <year>2018</year>. <article-title hwp:id="article-title-65">Interactions of Motivation and Cognitive Control</article-title>. <source hwp:id="source-67">Curr Opin Behav Sci</source> <volume>19</volume>:<fpage>83</fpage>–<lpage>90</lpage>.</citation></ref><ref id="c68" hwp:id="ref-68" hwp:rev-id="xref-ref-68-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.68" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-68"><string-name name-style="western" hwp:sortable="Yeung N"><surname>Yeung</surname> <given-names>N</given-names></string-name>, <string-name name-style="western" hwp:sortable="Botvinick MM"><surname>Botvinick</surname> <given-names>MM</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>. <year>2004</year>. <article-title hwp:id="article-title-66">The Neural Basis of Error Detection: Conflict Monitoring and the Error-Related Negativity</article-title>. <source hwp:id="source-68">Psychol Rev</source> <volume>111</volume>:<fpage>931</fpage>–<lpage>959</lpage>.</citation></ref><ref id="c69" hwp:id="ref-69" hwp:rev-id="xref-ref-69-1 xref-ref-69-2 xref-ref-69-3 xref-ref-69-4 xref-ref-69-5"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.69" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-69"><string-name name-style="western" hwp:sortable="Yu AJ"><surname>Yu</surname> <given-names>AJ</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dayan P"><surname>Dayan</surname> <given-names>P</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cohen JD"><surname>Cohen</surname> <given-names>JD</given-names></string-name>. <year>2009</year>. <article-title hwp:id="article-title-67">Dynamics of attentional selection under conflict: toward a rational Bayesian account</article-title>. <source hwp:id="source-69">J Exp Psychol Hum Percept Perform</source> <volume>35</volume>:<fpage>700</fpage>–<lpage>717</lpage>.</citation></ref><ref id="c70" hwp:id="ref-70" hwp:rev-id="xref-ref-70-1"><citation publication-type="journal" citation-type="journal" ref:id="2021.09.08.459546v2.70" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-70"><string-name name-style="western" hwp:sortable="Zaykin DV"><surname>Zaykin</surname> <given-names>DV</given-names></string-name>. <year>2011</year>. <article-title hwp:id="article-title-68">Optimally weighted Z-test is a powerful method for combining probabilities in meta-analysis</article-title>. <source hwp:id="source-70">J Evol Biol</source> <volume>24</volume>:<fpage>1836</fpage>–<lpage>1841</lpage>.</citation></ref></ref-list></back></article>
