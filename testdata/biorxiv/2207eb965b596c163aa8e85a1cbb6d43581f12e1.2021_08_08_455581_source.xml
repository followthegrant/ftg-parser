<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/2021.08.08.455581</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.08.08.455581v3</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;2021.08.08.455581</article-id><article-id pub-id-type="other" hwp:sub-type="slug">2021.08.08.455581</article-id><article-id pub-id-type="other" hwp:sub-type="atom-slug">2021.08.08.455581</article-id><article-id pub-id-type="other" hwp:sub-type="tag">2021.08.08.455581</article-id><article-version>1.3</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Bioinformatics" hwp:journal="biorxiv"><subject>Bioinformatics</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">KnowMore: an automated knowledge discovery tool for the FAIR SPARC datasets</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1"><label>*</label>Email: <email hwp:id="email-1">bpatel@calmi2.org</email></corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" hwp:id="contrib-1"><name name-style="western" hwp:sortable="Quey Ryan"><surname>Quey</surname><given-names>Ryan</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref></contrib><contrib contrib-type="author" hwp:id="contrib-2"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-8490-088X</contrib-id><name name-style="western" hwp:sortable="Schiefer Matthew A."><surname>Schiefer</surname><given-names>Matthew A.</given-names></name><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-1" hwp:rel-id="aff-3">3</xref><xref ref-type="aff" rid="a4" hwp:id="xref-aff-4-1" hwp:rel-id="aff-4">4</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0001-8490-088X"/></contrib><contrib contrib-type="author" hwp:id="contrib-3"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-2680-2303</contrib-id><name name-style="western" hwp:sortable="Kiran Anmol"><surname>Kiran</surname><given-names>Anmol</given-names></name><xref ref-type="aff" rid="a5" hwp:id="xref-aff-5-1" hwp:rel-id="aff-5">5</xref><xref ref-type="aff" rid="a6" hwp:id="xref-aff-6-1" hwp:rel-id="aff-6">6</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-2680-2303"/></contrib><contrib contrib-type="author" corresp="yes" hwp:id="contrib-4"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-0307-262X</contrib-id><name name-style="western" hwp:sortable="Patel Bhavesh"><surname>Patel</surname><given-names>Bhavesh</given-names></name><xref ref-type="aff" rid="a7" hwp:id="xref-aff-7-1" hwp:rel-id="aff-7">7</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-0307-262X"/></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1"><label>1</label><institution hwp:id="institution-1">Anant Corporation</institution>, Washington, D.C., <country>USA</country></aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1"><label>2</label><institution hwp:id="institution-2">Malcom Randall VA Medical Center</institution>, Gainesville, FL, <country>USA</country></aff><aff id="a3" hwp:id="aff-3" hwp:rev-id="xref-aff-3-1"><label>3</label><institution hwp:id="institution-3">Department of Biomedical Engineering, University of Florida</institution>, Gainesville, FL, <country>USA</country></aff><aff id="a4" hwp:id="aff-4" hwp:rev-id="xref-aff-4-1"><label>4</label><institution hwp:id="institution-4">SimNeurix, LLC</institution>, Gainesville, FL, <country>USA</country></aff><aff id="a5" hwp:id="aff-5" hwp:rev-id="xref-aff-5-1"><label>5</label><institution hwp:id="institution-5">Malawi-Liverpool-Wellcome Trust</institution>, Blantyre-3, <country>Malawi</country></aff><aff id="a6" hwp:id="aff-6" hwp:rev-id="xref-aff-6-1"><label>6</label><institution hwp:id="institution-6">Institute of Infection, Veterinary &amp; Ecological Sciences, University of Liverpool</institution>, Liverpool CH64 7TE, <country>UK</country></aff><aff id="a7" hwp:id="aff-7" hwp:rev-id="xref-aff-7-1"><label>7</label><institution hwp:id="institution-7">FAIR Data Innovations Hub, California Medical Innovations Institute</institution>, San Diego, CA, <country>USA</country></aff></contrib-group><pub-date pub-type="epub-original" date-type="pub" publication-format="electronic" hwp:start="2021"><year>2021</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2021-08-09T03:27:20-07:00">
    <day>9</day><month>8</month><year>2021</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2021-10-23T00:24:14-07:00">
    <day>23</day><month>10</month><year>2021</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2021-08-09T03:36:30-07:00">
    <day>9</day><month>8</month><year>2021</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2021-10-23T00:30:46-07:00">
    <day>23</day><month>10</month><year>2021</year>
  </pub-date><elocation-id>2021.08.08.455581</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2021-08-08"><day>08</day><month>8</month><year>2021</year></date>
<date date-type="rev-recd" hwp:start="2021-10-22"><day>22</day><month>10</month><year>2021</year></date>
<date date-type="accepted" hwp:start="2021-10-22"><day>22</day><month>10</month><year>2021</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">Â© 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2021</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/" hwp:id="license-1"><p hwp:id="p-1">This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by/4.0/</ext-link></p></license></permissions><self-uri xlink:href="455581.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/change-list" xlink:role="change-list" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/external-links" xlink:role="external-links" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2021/pdf/2021.08.08.455581v3.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="455581.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2021/abstracts/2021.08.08.455581v3/2021.08.08.455581v3.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2021/fulltext/2021.08.08.455581v3/2021.08.08.455581v3.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-2">This manuscript provides the methods and outcomes of KnowMore, the Grand Prize winning automated knowledge discovery tool developed by our team during the 2021 NIH SPARC FAIR Data Codeathon. The National Institutes of Health Stimulating Peripheral Activity to Relieve Conditions (NIH SPARC) program generates rich datasets from neuromodulation researches, curated according to the Findable, Accessible, Interoperable, and Reusable (FAIR) SPARC data standards. These datasets are publicly available through the SPARC Data Portal at sparc.science. Currently, the process of simultaneously comparing and analyzing multiple SPARC datasets is tedious because it requires investigating each dataset of interest individually and downloading all of them to conduct cross-analyses. It is crucial to enhance this process to enable rapid discoveries across SPARC datasets. To fill this need, we created KnowMore, a tool integrated into the SPARC Portal that only requires the user to select their datasets of interest to launch an automated discovery process. KnowMore uses several SPARC resources (Pennsieve, o<sup>2</sup>S<sup>2</sup>PARC, SciCrunch, protocols.io, Biolucida), data science methods, and machine learning algorithms in the back end to generate various visualizations in the front end intended to help the user identify potential similarities, differences, and relations across the datasets. These visualizations can lead to a new discovery, new hypothesis, or simply guide the user to the next logical step in their discovery process. The outcome of this project is a SPARC portal-ready code architecture that helps researchers to use SPARC datasets more efficiently and fully leverages their FAIR characteristics. The tool has been built and documented such that more data analysis methods and visualization items could be easily added. The potential for automated discoveries from SPARC datasets is huge given the unique SPARC data ecosystem promoting FAIR data practices, and KnowMore has only demonstrated a small highlight of what could be achieved to speed up discoveries from SPARC datasets.</p></abstract><kwd-group kwd-group-type="author" hwp:id="kwd-group-1"><title hwp:id="title-2">Keywords</title><kwd hwp:id="kwd-1">Data standards</kwd><kwd hwp:id="kwd-2">Data Science</kwd><kwd hwp:id="kwd-3">Metadata</kwd><kwd hwp:id="kwd-4">Natural Language Processing</kwd><kwd hwp:id="kwd-5">Knowledge graph</kwd><kwd hwp:id="kwd-6">Cloud computing</kwd><kwd hwp:id="kwd-7">Python</kwd></kwd-group><counts><page-count count="19"/></counts><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-1">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta><notes hwp:id="notes-1"><notes notes-type="competing-interest-statement" hwp:id="notes-2"><title hwp:id="title-3">Competing Interest Statement</title><p hwp:id="p-3">The authors have declared no competing interest.</p></notes><fn-group content-type="summary-of-updates" hwp:id="fn-group-1"><title hwp:id="title-4">Summary of Updates:</title><fn fn-type="update" hwp:id="fn-1"><p hwp:id="p-4">We have corrected some typos and revised the section titles.</p></fn></fn-group><fn-group content-type="external-links" hwp:id="fn-group-2"><fn fn-type="dataset" hwp:id="fn-2"><p hwp:id="p-5">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/SPARC-FAIR-Codeathon/KnowMore" ext-link-type="uri" xlink:href="https://github.com/SPARC-FAIR-Codeathon/KnowMore" hwp:id="ext-link-2">https://github.com/SPARC-FAIR-Codeathon/KnowMore</ext-link>
</p></fn><fn fn-type="dataset" hwp:id="fn-3"><p hwp:id="p-6">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://zenodo.org/record/5137255#.YRBoRo5Khyw" ext-link-type="uri" xlink:href="https://zenodo.org/record/5137255#.YRBoRo5Khyw" hwp:id="ext-link-3">https://zenodo.org/record/5137255#.YRBoRo5Khyw</ext-link>
</p></fn></fn-group></notes></front><body><sec id="s1" hwp:id="sec-1"><title hwp:id="title-5">Introduction</title><p hwp:id="p-7">The National Institutes of Healthâs (NIHâs) Stimulating Peripheral Activity to Relieve Conditions (SPARC) program seeks to accelerate the development of therapeutic devices that modulate electrical activity in nerves to improve organ function<sup><xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">1</xref></sup>. A major focus of the SPARC program is to generate rich datasets that provide resources for understanding nerve-organ interactions and guiding the development of neuromodulation therapies. These datasets are publicly available through an open data platform, the SPARC Data Portal<sup><xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">2</xref></sup>. As of July 2021, 115 datasets are available spanning multiple scales (cellular, tissue, organ level), organs (stomach, large intestine, small intestine, heart, bladder, urinary tract, lung, pancreas, spleen), species (pig, human, rat, mouse, dog), and data types (scaffold data, histology, immunohistochemistry, electrical impedance tomography, 3D microscopy, morphometric analyses, computer simulations of single axons or populations of axons, electrophysiological responses to electrical stimulation, etc.).</p><p hwp:id="p-8">To ensure SPARC datasets are findable, accessible, interoperable, and reusable (FAIR), they are curated according to the SPARC Data Structure (SDS), the data standards designed by the SPARC Data Curation Team to capture the large variety of data generated by SPARC investigators<sup><xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">3</xref>,<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">4</xref></sup>. Accordingly, many resources are made available to SPARC researchers for making their data FAIR, such as the cloud data platform Pennsieve, the curated vocabulary selector and annotation platform SciCrunch, the open source computational modeling platform Open Online Simulations for Stimulating Peripheral Activity to Relieve Condition (o<sup>2</sup>S<sup>2</sup>PARC), the online microscopy image viewer Biolucida, and the data curation Software to Organize Data Automatically (SODA)<sup><xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">5</xref>,<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">6</xref></sup>. As a result, the SPARC program provides a wealth of open and well-curated datasets that are accessible via the SPARC Data Portal. The portal provides several means of accessing data. A standard portal search feature is available. Alternatively, the user can find datasets by browsing through data categorized by organ system. The user can also use an interactive map to click on organs or nerves in animal models of interest and the portal provides links to associated datasets. These pathways make it easy to find datasets. Clicking a link to a dataset provides the user with details about the study and options to download all or subsets of the data files.</p><p hwp:id="p-9">While it is very easy to look at the details of any single SPARC dataset on the portal, there is currently no easy way to rapidly compare multiple datasets. Typically, a researcher wanting to find relations across datasets would have to do so manually by going through each dataset individually, i.e., read the description of each dataset, go through each protocol, browse files that are accessible from the browser, etc. Datasets that warrant further investigation must be downloaded for offline analyses and payment may be required for access to large datasets, according to Amazon Web Services (AWS) pricing. Depending on the formats of the data, this may require programming skills beyond that of many users. After spending time collating data in a form that allows comparison across the different datasets, the user may find that, in fact, the datasets did not contain the information they needed. This process of analyzing multiple datasets together is tedious, which ideally should not be the case since the SDS is designed to facilitate such analysis. Therefore, this process needs to be urgently improved to 1) enable rapid discoveries across SPARC datasets and 2) encourage more researchers to use the SPARC Data Portal.</p><p hwp:id="p-10">To address this shortcoming, we developed KnowMore during the 2021 SPARC FAIR Codeathon<sup><xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">7</xref></sup> (July 12<sup>th</sup>, 2021 â July 26<sup>th</sup>, 2021). KnowMore is an automated knowledge discovery tool integrated within the SPARC Portal. With minimal clicks, the user selects datasets of interest and KnowMore allows the user to visualize potential relations, similarities, differences, and correlations between the studies and associated datasets. This process, illustrated in <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1</xref>, is achieved by leveraging our knowledge of the SPARC data structure and metadata that allows us to perform text mining, generate a summary table, and plot data that is common across all selected datasets. The results are presented as several visualization items that provide the user with a quick means of identifying potential relations across the datasets. This manuscript describes the structure of KnowMore and provides an example of knowledge provided by the tool when applied to a set of three sample datasets that constituted our use case for demonstrating KnowMore during the 2021 SPARC FAIR Codeathon.</p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.08.08.455581v3/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1.</label><caption hwp:id="caption-1"><p hwp:id="p-11"><bold>Illustration of the simple user side workflow of KnowMore. Note that the tool is not currently integrated in the official SPARC Portal, but accessible through our fork of the sparc-app. It could be included into the official SPARC Portal after future consultation with SPARC</bold>.</p></caption><graphic xlink:href="455581v3_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig></sec><sec id="s2" hwp:id="sec-2"><title hwp:id="title-6">Methods</title><sec id="s2a" hwp:id="sec-3"><title hwp:id="title-7">Software architecture</title><p hwp:id="p-12">The overall workflow of KnowMore is shown in <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2</xref>. Our architecture consists of three main blocks that are independent:</p><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.08.08.455581v3/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2.</label><caption hwp:id="caption-2"><p hwp:id="p-13"><bold>Illustration of the overall technical workflow of KnowMore. The red rectangles highlight the major code blocks of KnowMore that were developed during the 2021 SPARC FAIR Codeathon</bold>.</p></caption><graphic xlink:href="455581v3_fig2" position="float" orientation="portrait" hwp:id="graphic-2"/></fig><list list-type="order" hwp:id="list-1"><list-item hwp:id="list-item-1"><p hwp:id="p-14">The front end of our app is based on a fork of the sparc-app (i.e. the front end of sparc.science) where we have integrated additional user interface elements and front end logic for KnowMore<sup><xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">8</xref></sup>.</p></list-item><list-item hwp:id="list-item-2"><p hwp:id="p-15">The back end consists of a Flask (a micro web framework written in Python programming language) application that listens to front end requests and launches the data processing jobs.</p></list-item><list-item hwp:id="list-item-3"><p hwp:id="p-16">The data processing and result generation are done through a MATLAB code (for âMATâ data files) and a Python code (all other data types) that both run on the o<sup>2</sup>S<sup>2</sup>PARC platform, the SPARC supported cloud computing platform<sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">9</xref></sup>.</p></list-item></list><p hwp:id="p-17">In our front end of the sparc-app, we have integrated an âAdd to KnowMoreâ button that is visible in the search result for each dataset and also available on the dataset page. By clicking on this button, the user can add their desired datasets for the analysis. Once all the datasets have been added, the user can go to the âKnowMoreâ tab we have included. On that page, the user can see a list of the selected datasets as well as a âDiscoverâ button. A click on that button initiates the discovery process, where the Pennsieve IDs (i.e., the unique ID attributed to each dataset on sparc.science) of the selected datasets are sent to the Flask server, which then sends the IDs and our data processing Python script to o<sup>2</sup>S<sup>2</sup>PARC, using the o<sup>2</sup>S<sup>2</sup>PARC application programming interface (API)<sup><xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">10</xref></sup>. Once the script is fully executed, the results are sent back to the Flask server, which then transfers them to the front end where visualization items are generated. More details about the visualization items are provided in the next section.</p><p hwp:id="p-18">The software architecture shown in <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2</xref> was motivated by our aim of making KnowMore ready to on-board the SPARC Data Portal:</p><list list-type="bullet" hwp:id="list-2"><list-item hwp:id="list-item-4"><p hwp:id="p-19">Integrating the front end of KnowMore will only require merging our fork of the sparc-app with the main branch sparc-app.</p></list-item><list-item hwp:id="list-item-5"><p hwp:id="p-20">The back end of the sparc-app, the sparc-api, is built with Flask so the KnowMore back end is readily integrable<sup><xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">11</xref></sup>.</p></list-item><list-item hwp:id="list-item-6"><p hwp:id="p-21">The data processing jobs are designed to run on o<sup>2</sup>S<sup>2</sup>PARC and do not require any type of integration as our back end ensures communication with o<sup>2</sup>S<sup>2</sup>PARC.</p></list-item></list><p hwp:id="p-22">Moreover, each of the three main elements of KnowMore is fully independent. While the front end will not be of much use on its own, having the back end fully interoperable is very valuable as our Flask application can be connected to any front end if needed (another analysis tool, website, software, etc.). The data processing and results generation jobs are also independent such that they can be used directly to get the visualization items. We have demonstrated that by developing a Jupyter Notebook that communicates directly with o<sup>2</sup>S<sup>2</sup>PARC to run the knowledge discovery jobs based on user-specified dataset IDs. Note that the data for the Knowledge Graph is obtained from Pennsieve/Scicrunch on the front end for efficiency but the same results can be generated in the back end as well. Thorough details for using the source code are available on the GitHub repository for this project<sup><xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">12</xref></sup>.</p></sec><sec id="s2b" hwp:id="sec-4"><title hwp:id="title-8">Data processing and outputs</title><p hwp:id="p-23">The output of KnowMore consists of multiple interactive visualization items displayed to the user so that they can progressively gain knowledge on the potential similarities, differences, and relations across the datasets. This output is intended to provide foundational information to the user so that they can rapidly make novel discoveries from SPARC datasets, generate new hypotheses, or simply decide on their next step (assess each dataset individually on the portal, download and analyze the datasets further, remove/add datasets to their analysis pool, etc.). A list of the visualization items is provided in <xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-1" hwp:rel-id="T1">Table 1</xref>, along with the potential knowledge that could be gained from each of them.</p><table-wrap id="tbl1" orientation="portrait" position="float" hwp:id="T1" hwp:rev-id="xref-table-wrap-1-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.08.08.455581v3/TBL1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">tbl1</object-id><label>Table 1.</label><caption hwp:id="caption-3"><title hwp:id="title-9">Table listing the visualization items automatically generated by KnowMore. The source of the raw data for generating the visualization items are also listed.</title></caption><graphic xlink:href="455581v3_tbl1" position="float" orientation="portrait" hwp:id="graphic-3"/></table-wrap><p hwp:id="p-24">The process of getting these outputs starts by getting the IDs of the datasets selected by the user, which are obtained using the Pennsieve API<sup><xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">13</xref></sup> in the front end. From there, we leverage several SPARC-supported and recommended resources in our data processing Python Script to collect the raw data required to generate the above-mentioned outputs. These resources include the Pennsieve API<sup><xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-2" hwp:rel-id="ref-13">13</xref></sup>, the Scicrunch Elasticsearch API<sup><xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">14</xref></sup>, the protocols.io API<sup><xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">15</xref></sup>, and the Biolucida API<sup><xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">16</xref></sup>. We refer to the paper on the SPARC Data Resource Center (DRC) for more details about these resources and their role in the SPARC data ecosystem<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">6</xref></sup>. Details about each of the visualization items are provided below. Each of these items can be easily saved from the front-end interface.</p><sec id="s2b1" hwp:id="sec-5"><title hwp:id="title-10">Knowledge graph</title><p hwp:id="p-25">Using the Pennsieve ID of each dataset, the following items are queried from SciCrunch Elasticsearch API<sup><xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-2" hwp:rel-id="ref-14">14</xref></sup>: Person (authors of the dataset), Affiliation (affiliation of the authors), and Award (funding source for the dataset). The visualization library Vega is used in the front end to display this information in an interactive knowledge graph, which instantly highlights high-level relations amongst the datasets.</p></sec><sec id="s2b2" hwp:id="sec-6"><title hwp:id="title-11">Summary table</title><p hwp:id="p-26">A summary table is built with information collected from the metadata.json file of each dataset, which is a standard file generated for each SPARC dataset when published, and the subjects and samples metadata files, which are standard metadata files prescribed for SPARC datasets by the SDS. The files are retrieved from the Pennsieve API within our Python code. The following items are parsed from the metadata.json file for each dataset: title of the dataset, subtitle of the dataset, publication date. The following items are parsed from the subjectsâ metadata file for each dataset: number of subjects, species, age, sex. The following items are parsed from the samples metadata file: number of samples, specimen, type, specimen anatomical locations. The visualization library Plotly is used in the front end to display the results in an interactive table, which shows this information side-by-side for each dataset, thus enabling quick comparison in the study design of each dataset.</p></sec><sec id="s2b3" hwp:id="sec-7"><title hwp:id="title-12">Keywords</title><p hwp:id="p-27">Text is obtained for each dataset from the description included in metadata.json file and the text from all the text files in the dataset using the Pennsieve API, and the text from the protocol on protocols.io associated with the dataset using the protocols.io API. The link to the protocol.io protocol is extracted from the metadata.json file of the dataset. All text is combined to create a paragraph for each dataset. The Natural Language Processing (NLP) Python library NLTK<sup><xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">17</xref></sup> is then used to clean the text (e.g., remove stopwords). Biological keywords are identified using the spaCy python module and ScispaCy models<sup><xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">18</xref>,<xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">19</xref></sup>. The frequency of biological words is counted for each dataset. The final frequency of the keywords is assigned based on lowest occurrence among the datasets and the twenty most frequent words are selected and displayed as a word cloud using the visualization library Vega. The minimum frequency of a keyword across the dataset is displayed when the cursor hovers over the word. These keywords conveniently allow the user to identify common themes across the datasets.</p></sec><sec id="s2b4" hwp:id="sec-8"><title hwp:id="title-13">Correlation matrix and abstract</title><p hwp:id="p-28">The correlation matrix demonstrates the putative relatedness between datasets<sup><xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">20</xref>,<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">21</xref></sup>. To generate the correlation matrix for the given datasets, pairwise similarity between datasets is calculated using the following Jaccard index equation<sup><xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">22</xref></sup>:
<disp-formula id="ueqn1" hwp:id="disp-formula-1">
<alternatives hwp:id="alternatives-1"><graphic xlink:href="455581v3_ueqn1.gif" position="float" orientation="portrait" hwp:id="graphic-4"/></alternatives>
</disp-formula>
where A and B are sets of biological keywords present in two datasets. The biological keywords are identified as explained earlier in the Keywords section.</p><p hwp:id="p-29">Paragraphs generated from datasets for the keywords identification are merged and divided into sentences. Each sentence is further divided into words and stopwords were removed. The frequency of each remaining word in a sentence is counted and converted into vectors where keywords represent the direction and frequencies represent the magnitude. The distance of two sentences is calculated using equation 1 â cos(<italic toggle="yes">Î¸</italic>) where cosine similarity is expressed as follows:
<disp-formula id="ueqn2" hwp:id="disp-formula-2">
<alternatives hwp:id="alternatives-2"><graphic xlink:href="455581v3_ueqn2.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives>
</disp-formula>
where A and B are words frequency in vectors of two sentences. Based on the pairwise distance of sentences a pagerank is assigned to each sentence using Python networkX module and sentences are ordered based on pagerank in decreasing order<sup><xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">23</xref></sup>. The top 10 highest-ranked sentences are selected to generate a common abstract for the datasets. This abstract is intended to provide a quick idea of any common study design and/or findings.</p></sec><sec id="s2b5" hwp:id="sec-9"><title hwp:id="title-14">Data plots</title><p hwp:id="p-30">If data files in .mat format are found under the âderivativeâ folder, the data processing Python script extracts and saves them then provides them to our MATLAB script that is compiled and deployed on o<sup>2</sup>S<sup>2</sup>PARC. The script collates the data into a data table. The script next determines which columns in the data table can be used for plotting purposes. Columns containing categorical data are limited to the x-axis. Columns containing numerical data can be plotted on the x-axis or y-axis. Columns containing any other type of data are excluded. Plots are then generated for every variable that can be displayed on a y-axis against every variable that can be plotted on an x-axis. In addition to the plots, the MATLAB script outputs an Excel file that lists each of the plots created and the variables included in each plot. The Excel file also includes data for each plot. Additionally, the script creates a json file that includes all data for each plot. These plots quickly highlight to the user relations between similar quantities measured across datasets.</p></sec><sec id="s2b6" hwp:id="sec-10"><title hwp:id="title-15">Image clustering</title><p hwp:id="p-31">An additional visualization item we aimed to provide to the user but could not complete during the Codeathon due to time constraints was a clustering of images across datasets, which may be particularly useful for histological data. All image data from SPARC datasets are stored on Biolucida. We currently have a function in place to retrieve image data from Biolucida given a Pennsieve dataset ID using the Biolucida API<sup><xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-2" hwp:rel-id="ref-16">16</xref></sup>. In the future, image clustering and visualization components will be added in the Python script and front end, respectively, to provide an additional element to the user for comparing datasets.</p></sec></sec><sec id="s2c" hwp:id="sec-11"><title hwp:id="title-16">Use case</title><sec id="s2c1" hwp:id="sec-12"><title hwp:id="title-17">Setup</title><p hwp:id="p-32">KnowMore was developed and tested using three datasets available at sparc.science (<xref rid="tbl2" ref-type="table" hwp:id="xref-table-wrap-2-1" hwp:rel-id="T2">Table 2</xref>). These datasets were selected because they have a common theme â quantified vagus nerve morphology â and span three species: rat, pig, and human. In principle, KnowMore is not specifically designed around these datasets and is coded to work with any user-selected datasets. However, for demonstration purposes, the data plots are currently limited to only appear when working with all or a subset of the three datasets listed in <xref rid="tbl2" ref-type="table" hwp:id="xref-table-wrap-2-2" hwp:rel-id="T2">Table 2</xref>. Reasons for this are addressed in the Challenges section below and recommendations are put forth to expand the usability of this feature and increase the interoperability of SPARC datasets.</p><table-wrap id="tbl2" orientation="portrait" position="float" hwp:id="T2" hwp:rev-id="xref-table-wrap-2-1 xref-table-wrap-2-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.08.08.455581v3/TBL2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T2</object-id><object-id pub-id-type="publisher-id">tbl2</object-id><label>Table 2.</label><caption hwp:id="caption-4"><title hwp:id="title-18">List of datasets used for our use case.</title></caption><graphic xlink:href="455581v3_tbl2" position="float" orientation="portrait" hwp:id="graphic-6"/></table-wrap><p hwp:id="p-33">Initiating a KnowMore analysis requires five steps:</p><list list-type="order" hwp:id="list-3"><list-item hwp:id="list-item-7"><p hwp:id="p-34">Use the search feature or browse for possible datasets of interest at sparc.science.</p></list-item><list-item hwp:id="list-item-8"><p hwp:id="p-35">As datasets are identified that the user wants to compare, click on the âAdd to KnowMoreâ button, visible in the header of the datasets or the search results. This will add the datasets to the KnowMore analysis.</p></list-item><list-item hwp:id="list-item-9"><p hwp:id="p-36">Go to the KnowMore tab at the top of the webpage and check that all of the desired datasets are listed.</p></list-item><list-item hwp:id="list-item-10"><p hwp:id="p-37">Decide which output to display. All possible output is displayed by default.</p></list-item><list-item hwp:id="list-item-11"><p hwp:id="p-38">Click on the âDiscoverâ button to initiate the automated analysis.</p></list-item></list><p hwp:id="p-39">The number of datasets selected will affect the duration of time required to run the full discovery analysis. The use case with these three datasets takes about 4 min to generate all the visualization items.</p></sec></sec><sec id="s2d" hwp:id="sec-13"><title hwp:id="title-19">Outputs</title><sec id="s2d1" hwp:id="sec-14"><title hwp:id="title-20">Knowledge Graph</title><p hwp:id="p-40">The Knowledge Graph provides an interactive tool to visualize metadata across the three datasets (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure 3</xref>). This provides the ability to quickly determine, for example, that all three datasets had four investigators in common (Cariello, Grill, Goldhagen, and Pelot) affiliated with the Department of Biomedical Engineering at Duke and that the human dataset had additional investigators (Ezzell and Clissold) affiliated with the Department of Cell Biology and Physiology at the University of North Carolina.</p><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.08.08.455581v3/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3.</label><caption hwp:id="caption-5"><title hwp:id="title-21">Knowledge Graph output for the three datasets in our use case.</title></caption><graphic xlink:href="455581v3_fig3" position="float" orientation="portrait" hwp:id="graphic-7"/></fig></sec><sec id="s2d2" hwp:id="sec-15"><title hwp:id="title-22">Summary Table</title><p hwp:id="p-41">The Summary Table provides the user with key pieces of information from each study in tabular format (<xref rid="tbl3" ref-type="table" hwp:id="xref-table-wrap-3-1" hwp:rel-id="T3">Table 3</xref>). From this table, the user can easily determine that datasets have several common metrics. However, perineurial thickness is not quantified in dataset 64.</p><table-wrap id="tbl3" orientation="portrait" position="float" hwp:id="T3" hwp:rev-id="xref-table-wrap-3-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.08.08.455581v3/TBL3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T3</object-id><object-id pub-id-type="publisher-id">tbl3</object-id><label>Table 3.</label><caption hwp:id="caption-6"><title hwp:id="title-23">KnowMore Summary Table output for the three datasets in our use case.</title></caption><graphic xlink:href="455581v3_tbl3" position="float" orientation="portrait" hwp:id="graphic-8"/></table-wrap></sec><sec id="s2d3" hwp:id="sec-16"><title hwp:id="title-24">Common Keywords</title><p hwp:id="p-42">The Common Keywords figure provides a graphical depiction of words that show up multiple times across the selected datasets (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Figure 4</xref>). This size of the word in the image provides a visual representation of the weight (or frequency) of that word across the datasets. Not surprisingly, ânerveâ is a large word as it shows up many times. Many other keywords highlight the quantified morphology across the datasets (diameter, cross-sectional area, fascicle, etc.).</p><fig id="fig4" position="float" fig-type="figure" orientation="portrait" hwp:id="F4" hwp:rev-id="xref-fig-4-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.08.08.455581v3/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4.</label><caption hwp:id="caption-7"><title hwp:id="title-25">Common Keywords output for the three datasets in our use case.</title></caption><graphic xlink:href="455581v3_fig4" position="float" orientation="portrait" hwp:id="graphic-9"/></fig></sec><sec id="s2d4" hwp:id="sec-17"><title hwp:id="title-26">Correlation Matrix and Abstract</title><p hwp:id="p-43">KnowMore generates a heatmap illustrating the correlation between the studies based on the words used in the text of these studies (<xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Figure 5</xref>). This figure can guide the user in selecting highly correlated studies or eliminating studies that do not correlate well. Additionally, KnowMore generates a combined abstract that provides an overview of all datasets included in the study.</p><fig id="fig5" position="float" fig-type="figure" orientation="portrait" hwp:id="F5" hwp:rev-id="xref-fig-5-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.08.08.455581v3/FIG5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">fig5</object-id><label>Figure 5.</label><caption hwp:id="caption-8"><title hwp:id="title-27">Correlation of the words used to describe the three datasets in our use case.</title></caption><graphic xlink:href="455581v3_fig5" position="float" orientation="portrait" hwp:id="graphic-10"/></fig></sec><sec id="s2d5" hwp:id="sec-18"><title hwp:id="title-28">Data Plots</title><p hwp:id="p-44">For this use case, KnowMore also generates 20 scatter plots. Due to time constraints, these plots are currently generated in the backend as png files and then displayed in the front-end. Data points are color-coded to each dataset. Each axis is labeled with the variable being plotted. The variable name is obtained directly from the datasets. Three of the plots are presented here (<xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Figure 6</xref>). Plot 3.4 reveals that pigs contain more fascicles in their vagus nerves than humans do, and humans contain more fascicles than rats. Plot 3.4 also reveals that pigs and rats have similar variability (spread) in their fascicle diameters whereas humans have a greater spread in their fascicle diameters. Finally, Plot 3.4 illustrates that humans can have larger fascicles than pigs. Plot 3.5 reveals that humans and pigs have similar-sized nerves, though pigs may, on average, have larger nerves. Plot 3.5 also reveals that the number of fascicles in the nerve may tend to be greater for nerves of larger diameter within each species. That is, there appears to be a positive correlation between the number of fascicles in the nerve and the diameter of the nerve. However, Plot 4.5 suggests that there may not be a trend between the fascicle diameter and the nerve diameter. Although these findings have been previously reported in some form<sup><xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">24</xref></sup>, the Data Plots can become a very useful tool in helping researchers quickly understand the underlying data across multiple datasets.</p><fig id="fig6" position="float" fig-type="figure" orientation="portrait" hwp:id="F6" hwp:rev-id="xref-fig-6-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;2021.08.08.455581v3/FIG6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">fig6</object-id><label>Figure 6.</label><caption hwp:id="caption-9"><title hwp:id="title-29">Three selected KnowMore Data Plots created from the three datasets in our use case.</title></caption><graphic xlink:href="455581v3_fig6" position="float" orientation="portrait" hwp:id="graphic-11"/></fig></sec></sec><sec id="s2e" hwp:id="sec-19"><title hwp:id="title-30">Conclusions and next steps</title><sec id="s2e1" hwp:id="sec-20"><title hwp:id="title-31">Potential for this tool</title><p hwp:id="p-45">In a few clicks to select datasets, KnowMore can provide both a high-level metanalysis and a granular comparison across two or more datasets on the SPARC portal. KnowMore outputs result at several levels depending on the needs of the researcher. One can quickly determine personnel, institutional, and funding relationships between datasets, and generate an overview of subjects included in the datasets and the techniques used to obtain data. Finally, if data are suitable for plotting, plots can reveal relationships within and across the studies that may reveal larger trends or help the researcher choose or eliminate particular datasets for more detailed analysis.</p></sec><sec id="s2e2" hwp:id="sec-21"><title hwp:id="title-32">Challenges</title><p hwp:id="p-46">SPARC has done an excellent job of standardizing the metadata associated with a study, and, as such, most of the KnowMore output is available across any selected studies. However, SPARC has not enforced standardization for tabular data. As such, the Data Plot output of KnowMore is currently limited to datasets that contain identical variable names and formats. This is an uncommon occurrence across datasets. Data can currently be stored in any number of formats. KnowMoreâs Data Plot currently requires data to be stored in a MATLAB .mat file due to our use case, but this could be expanded to several other file formats. It would be preferable from a programming perspective if all data formats and variable naming are consistent, however, within MATLAB alone, data can be stored in multiple formats. Data may be stored in vectors/matrices; cells; cell arrays of vectors, matrices or more cells; structures; or tables, among other formats. Even small differences in variable names such as NerveDiam versus NerveDiameter versus DiameterOfNerve are not immediately reconcilable, though NLP may alleviate such inconsistencies. Without unified variable naming, comparisons across datasets become very challenging. Inconsistent variable names are not the only challenge, however. Even if variable names are identical, the values stored for that variable may be different from study to study. Without unified data types, comparisons across datasets become very challenging. To make the KnowMore Data Plot tool universal we propose standardization of commonly used variable names, data formats, data types, and data units. We also recommend the inclusion of key pieces of information that describe the data in the metadata. We have submitted these recommendations to SPARC and a copy of the document is available in our GitHub repository. This may require a significant amount of effort to convert previously uploaded datasets but should not put an exceptional burden on new studies. Data standardization across the SPARC platform would make the data ready for much broader analysis using more sophisticated big data tools that could provide insights that are otherwise obscured or not readily accessible.</p></sec><sec id="s2e3" hwp:id="sec-22"><title hwp:id="title-33">Future directions</title><p hwp:id="p-47">Currently, the discovery process takes several minutes to run and display the visualization items (about 5 min for the use case). To improve performance, we suggest using multi-threading in the Python script; moving the .mat file processing directly into the Python script; collecting all required raw data (e.g., text) when a dataset is uploaded (e.g. save it in the metadata.json file) and even pre-process it (clean the text) so it is readily available during our discovery process. Image clustering components can be included in the future as well as any other visualization items that are deemed useful to the user. If the above-mentioned challenges with tabular data are addressed, the Data Plots feature of KnowMore can be generalized to work with any datasets.</p><p hwp:id="p-48">The SPARC data ecosystem that is built to deliver FAIR datasets, provides a unique opportunity to automate knowledge discovery across datasets. During this project, we leveraged that ecosystem to demonstrated what can be achieved to increase the speed and convenience of discoveries across SPARC datasets. The tool we have developed is a statement of the power of FAIR practices and the effort of SPARC in that regard. We believe that we have only scratched the surface during the Codeathon and the opportunities are yet immense.</p></sec></sec></sec></body><back><sec id="s3" hwp:id="sec-23"><title hwp:id="title-34">Software availability</title><p hwp:id="p-49">Source code available from: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/SPARC-FAIR-Codeathon/KnowMore" ext-link-type="uri" xlink:href="https://github.com/SPARC-FAIR-Codeathon/KnowMore" hwp:id="ext-link-4">https://github.com/SPARC-FAIR-Codeathon/KnowMore</ext-link><sup><xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-2" hwp:rel-id="ref-12">12</xref></sup></p><p hwp:id="p-50">Archived source code at the time of publication: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://doi.org/10.5281/zenodo.5137255" ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.5137255" hwp:id="ext-link-5">https://doi.org/10.5281/zenodo.5137255</ext-link><sup><xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">28</xref></sup></p><p hwp:id="p-51">License: MIT</p><p hwp:id="p-52">The repository and archive both contain detailed information for using the source code. They also contain a copy of our recommendation to SPARC for standardizing tabular data.</p></sec><sec id="s4" hwp:id="sec-24"><title hwp:id="title-35">Competing Interests</title><p hwp:id="p-53">No competing interests were disclosed.</p></sec><ack hwp:id="ack-1"><title hwp:id="title-36">Acknowledgments</title><p hwp:id="p-54">We would like to thank the NIH SPARC Program and the SPARC Data Resource Center (DRC) teams for organizing the 2021 SPARC FAIR Codeathon. We would also like to thank the DRC teams for their guidance and help during this Codeathon.</p></ack><ref-list hwp:id="ref-list-1"><title hwp:id="title-37">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1"><label>1.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.1" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-1"><collab hwp:id="collab-1">National Institutes of Health</collab>. <source hwp:id="source-1">Stimulating Peripheral Activity to Relieve Conditions (SPARC)</source>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://commonfund.nih.gov/sparc" ext-link-type="uri" xlink:href="https://commonfund.nih.gov/sparc" hwp:id="ext-link-6">https://commonfund.nih.gov/sparc</ext-link>. (Accessed: <date-in-citation content-type="access-date">19th September 2020</date-in-citation>)</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1"><label>2.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.2" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-2"><collab hwp:id="collab-2">National Institutes of Health</collab>. <source hwp:id="source-2">SPARC Data Portal</source>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://sparc.science/" ext-link-type="uri" xlink:href="https://sparc.science/" hwp:id="ext-link-7">https://sparc.science/</ext-link>. (Accessed: <date-in-citation content-type="access-date">19th September 2020</date-in-citation>)</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><label>3.</label><citation publication-type="other" citation-type="journal" ref:id="2021.08.08.455581v3.3" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Wilkinson M. D."><surname>Wilkinson</surname>, <given-names>M. D.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-2">The FAIR Guiding Principles for scientific data management and stewardship</article-title>. <source hwp:id="source-3">Sci. Data v3</source>, (<year>2016</year>).</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1"><label>4.</label><citation publication-type="other" citation-type="journal" ref:id="2021.08.08.455581v3.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Bandrowski A."><surname>Bandrowski</surname>, <given-names>A.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-3">SPARC Data Structure: Rationale and Design of a FAIR Standard for Biomedical Research Data</article-title>. <source hwp:id="source-4">bioRxiv</source> 2021.02.10.430563 (<year>2021</year>). doi:<pub-id pub-id-type="doi">10.1101/2021.02.10.430563</pub-id></citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1"><label>5.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.08.08.455581v3.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Patel B."><surname>Patel</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Srivastava H."><surname>Srivastava</surname>, <given-names>H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Aghasafari P."><surname>Aghasafari</surname>, <given-names>P.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Helmer K."><surname>Helmer</surname>, <given-names>K.</given-names></string-name> <article-title hwp:id="article-title-4">SPARC: SODA, an interactive software for curating SPARC datasets</article-title>. <source hwp:id="source-5">FASEB J</source>. <volume>34</volume>, <fpage>1</fpage>â<lpage>1</lpage> (<year>2020</year>).</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2"><label>6.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.08.08.455581v3.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Osanlouy M."><surname>Osanlouy</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-5">The SPARC DRC: Building a Resource for the Autonomic Nervous System Community</article-title>. <source hwp:id="source-6">Front. Physiol</source>. <volume>0</volume>, <fpage>929</fpage> (<year>2021</year>).</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1"><label>7.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.7" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-7"><collab hwp:id="collab-3">2021 SPARC FAIR Codeathon</collab>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://sparc.science/help/2021-sparc-fair-codeathon" ext-link-type="uri" xlink:href="https://sparc.science/help/2021-sparc-fair-codeathon" hwp:id="ext-link-8">https://sparc.science/help/2021-sparc-fair-codeathon</ext-link>. (Accessed: <date-in-citation content-type="access-date">1st August 2021</date-in-citation>)</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><label>8.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.8" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-8"><collab hwp:id="collab-4">NIH SPARC</collab>. <source hwp:id="source-7">Web Application for the SPARC Portal</source>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/nih-sparc/sparc-app" ext-link-type="uri" xlink:href="https://github.com/nih-sparc/sparc-app" hwp:id="ext-link-9">https://github.com/nih-sparc/sparc-app</ext-link>. (Accessed: <date-in-citation content-type="access-date">1st August 2021</date-in-citation>)</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1"><label>9.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.9" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-9"><collab hwp:id="collab-5">ITâIS Foundation</collab>. <source hwp:id="source-8">Open Online Simulations for Stimulating Peripheral Activity to Relieve Conditions</source>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://osparc.io/" ext-link-type="uri" xlink:href="https://osparc.io/" hwp:id="ext-link-10">https://osparc.io/</ext-link>. (Accessed: <date-in-citation content-type="access-date">1st August 2021</date-in-citation>)</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><label>10.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.10" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-10"><collab hwp:id="collab-6">ITâIS Foundation</collab>. <source hwp:id="source-9">osparc API client</source>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://itisfoundation.github.io/osparc-simcore-python-client/#/" ext-link-type="uri" xlink:href="https://itisfoundation.github.io/osparc-simcore-python-client/#/" hwp:id="ext-link-11">https://itisfoundation.github.io/osparc-simcore-python-client/#/</ext-link>. (Accessed: <date-in-citation content-type="access-date">1st August 2021</date-in-citation>)</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><label>11.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.11" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-11"><collab hwp:id="collab-7">NIH SPARC</collab>. <source hwp:id="source-10">SPARC Portal API</source>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/nih-sparc/sparc-api" ext-link-type="uri" xlink:href="https://github.com/nih-sparc/sparc-api" hwp:id="ext-link-12">https://github.com/nih-sparc/sparc-api</ext-link>. (Accessed: <date-in-citation content-type="access-date">1st August 2021</date-in-citation>)</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1 xref-ref-12-2"><label>12.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.12" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Patel B."><surname>Patel</surname>, <given-names>B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Quey R."><surname>Quey</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schiefer M."><surname>Schiefer</surname>, <given-names>M.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Kiran A."><surname>Kiran</surname>, <given-names>A.</given-names></string-name> <source hwp:id="source-11">KnowMore: Automated Knowledge Discovery Tool for SPARC Datasets</source>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/SPARC-FAIR-Codeathon/KnowMore" ext-link-type="uri" xlink:href="https://github.com/SPARC-FAIR-Codeathon/KnowMore" hwp:id="ext-link-13">https://github.com/SPARC-FAIR-Codeathon/KnowMore</ext-link>. (Accessed: <date-in-citation content-type="access-date">1st August 2021</date-in-citation>)</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1 xref-ref-13-2"><label>13.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.13" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-13"><collab hwp:id="collab-8">Pennsieve</collab>. <source hwp:id="source-12">Pennsieve API</source>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://docs.pennsieve.io/reference/discover_datasets" ext-link-type="uri" xlink:href="https://docs.pennsieve.io/reference/discover_datasets" hwp:id="ext-link-14">https://docs.pennsieve.io/reference/discover_datasets</ext-link>. (Accessed: <date-in-citation content-type="access-date">1st August 2021</date-in-citation>)</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1 xref-ref-14-2"><label>14.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.14" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-14"><collab hwp:id="collab-9">FDI Lab</collab>. <source hwp:id="source-13">SciCrunch ElasticSearch API</source>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://fdilab.gitbook.io/api-handbook/sparc-metadata-elasticsearch/untitled" ext-link-type="uri" xlink:href="https://fdilab.gitbook.io/api-handbook/sparc-metadata-elasticsearch/untitled" hwp:id="ext-link-15">https://fdilab.gitbook.io/api-handbook/sparc-metadata-elasticsearch/untitled</ext-link>. (Accessed: <date-in-citation content-type="access-date">1st August 2021</date-in-citation>)</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><label>15.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.15" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-15"><collab hwp:id="collab-10">protocols.io</collab>. <source hwp:id="source-14">protocols.io for Developers</source>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://www.protocols.io/developers" ext-link-type="uri" xlink:href="https://www.protocols.io/developers" hwp:id="ext-link-16">https://www.protocols.io/developers</ext-link>. (Accessed: <date-in-citation content-type="access-date">1st August 2021</date-in-citation>)</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1 xref-ref-16-2"><label>16.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.16" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-16"><collab hwp:id="collab-11">MBF Bioscience</collab>. <source hwp:id="source-15">Biolucida API v</source><year>2021</year>. Available at: <ext-link l:rel="related" l:ref-type="uri" l:ref="https://documenter.getpostman.com/view/8986837/SVtPXAVm" ext-link-type="uri" xlink:href="https://documenter.getpostman.com/view/8986837/SVtPXAVm" hwp:id="ext-link-17">https://documenter.getpostman.com/view/8986837/SVtPXAVm</ext-link>. (Accessed: <date-in-citation content-type="access-date">1st August 2021</date-in-citation>)</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><label>17.</label><citation publication-type="book" citation-type="book" ref:id="2021.08.08.455581v3.17" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Bird S."><surname>Bird</surname>, <given-names>S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Klein E."><surname>Klein</surname>, <given-names>E.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Loper E."><surname>Loper</surname>, <given-names>E.</given-names></string-name> <source hwp:id="source-16">Natural language processing with Python: analyzing text with the natural language toolkit</source>. (<publisher-name>OâReilly Media, Inc</publisher-name>, <year>2009</year>).</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1"><label>18.</label><citation publication-type="other" citation-type="journal" ref:id="2021.08.08.455581v3.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Honnibal Matthew Montani I."><surname>Honnibal Matthew Montani</surname>, <given-names>I.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Van Landeghem S."><surname>Van Landeghem</surname>, <given-names>S.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Boyd A."><surname>Boyd</surname>, <given-names>A.</given-names></string-name> <source hwp:id="source-17">spaCy: Industrial-strength Natural Language Processing in Python</source>. (<year>2020</year>). doi:<pub-id pub-id-type="doi">10.5281/zenodo.1212303</pub-id></citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><label>19.</label><citation publication-type="other" citation-type="journal" ref:id="2021.08.08.455581v3.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Neumann M."><surname>Neumann</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="King D."><surname>King</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Beltagy I."><surname>Beltagy</surname>, <given-names>I.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Ammar W."><surname>Ammar</surname>, <given-names>W.</given-names></string-name> <source hwp:id="source-18">ScispaCy: Fast and Robust Models for Biomedical Natural Language Processing</source>. <fpage>319</fpage>â<lpage>327</lpage> (<year>2019</year>). doi:<pub-id pub-id-type="doi">10.18653/v1/w19-5034</pub-id></citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><label>20.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.08.08.455581v3.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Thakur N."><surname>Thakur</surname>, <given-names>N.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Mehrotra D."><surname>Mehrotra</surname>, <given-names>D.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Bansal A."><surname>Bansal</surname>, <given-names>A.</given-names></string-name> <article-title hwp:id="article-title-6">Information Retrieval System Assigning Context to Documents by Relevance Feedback</article-title>. <source hwp:id="source-19">Int. J. Comput. Appl</source>. <volume>58</volume>, <fpage>975</fpage>â<lpage>8887</lpage> (<year>2012</year>).</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1"><label>21.</label><citation publication-type="book" citation-type="book" ref:id="2021.08.08.455581v3.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Kotu V."><surname>Kotu</surname>, <given-names>V.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Deshpande B."><surname>Deshpande</surname>, <given-names>B.</given-names></string-name> <source hwp:id="source-20">Classification. in Data Science - Concepts and Practice</source> <fpage>65</fpage>â<lpage>163</lpage> (<publisher-name>Morgan Kaufmann</publisher-name>, <year>2019</year>). doi:<pub-id pub-id-type="doi">10.1016/B978-0-12-814761-0.00004-6</pub-id></citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><label>22.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.08.08.455581v3.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Jaccard P."><surname>Jaccard</surname>, <given-names>P.</given-names></string-name> <article-title hwp:id="article-title-7">The distribution of the flora in the alpine zone</article-title>. <source hwp:id="source-21">New Phytol</source>. <volume>11</volume>, <fpage>37</fpage>â<lpage>50</lpage> (<year>1912</year>).</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1"><label>23.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.08.08.455581v3.23" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Hagberg A. A."><surname>Hagberg</surname>, <given-names>A. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schult D. A."><surname>Schult</surname>, <given-names>D. A.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Swart P. J."><surname>Swart</surname>, <given-names>P. J.</given-names></string-name> <article-title hwp:id="article-title-8">Exploring network structure, dynamics, and function using NetworkX</article-title>. <source hwp:id="source-22">in Proceedings of the 7th Python in Science Conference (SciPy2008)</source> (eds. <person-group person-group-type="editor" hwp:id="person-group-1"><string-name name-style="western" hwp:sortable="Varoquaux G."><surname>Varoquaux</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Vaught T."><surname>Vaught</surname>, <given-names>T.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Millman J"><surname>Millman</surname>, <given-names>J</given-names></string-name></person-group>.) <fpage>11</fpage>â<lpage>15</lpage> (<year>2008</year>).</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1"><label>24.</label><citation publication-type="journal" citation-type="journal" ref:id="2021.08.08.455581v3.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Pelot N. A."><surname>Pelot</surname>, <given-names>N. A.</given-names></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-9">Quantified Morphology of the Cervical and Subdiaphragmatic Vagus Nerves of Human, Pig, and Rat</article-title>. <source hwp:id="source-23">Front. Neurosci</source>. <volume>0</volume>, <fpage>1148</fpage> (<year>2020</year>).</citation></ref><ref id="c25" hwp:id="ref-25"><label>25.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.25" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Pelot N. A."><surname>Pelot</surname>, <given-names>N. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Goldhagen G. B."><surname>Goldhagen</surname>, <given-names>G. B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cariello J. E."><surname>Cariello</surname>, <given-names>J. E.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Grill W. M."><surname>Grill</surname>, <given-names>W. M.</given-names></string-name> <source hwp:id="source-24">Quantified Morphology of the Rat Vagus Nerve (Version 4)</source>. (<year>2020</year>). doi:<ext-link l:rel="related" l:ref-type="uri" l:ref="https://doi.org/10.26275/ILB9-0E2A" ext-link-type="uri" xlink:href="https://doi.org/10.26275/ILB9-0E2A" hwp:id="ext-link-18">https://doi.org/10.26275/ILB9-0E2A</ext-link></citation></ref><ref id="c26" hwp:id="ref-26"><label>26.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.26" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Pelot N. A."><surname>Pelot</surname>, <given-names>N. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Goldhagen G. B."><surname>Goldhagen</surname>, <given-names>G. B.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cariello J. E."><surname>Cariello</surname>, <given-names>J. E.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Grill W. M."><surname>Grill</surname>, <given-names>W. M.</given-names></string-name> <source hwp:id="source-25">Quantified Morphology of the Pig Vagus Nerve (Version 4)</source>. (<year>2020</year>). doi:<ext-link l:rel="related" l:ref-type="uri" l:ref="https://doi.org/10.26275/MAQ2-EII4" ext-link-type="uri" xlink:href="https://doi.org/10.26275/MAQ2-EII4" hwp:id="ext-link-19">https://doi.org/10.26275/MAQ2-EII4</ext-link></citation></ref><ref id="c27" hwp:id="ref-27"><label>27.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.27" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Pelot N. A."><surname>Pelot</surname>, <given-names>N. A.</given-names></string-name> <etal>et al.</etal> <source hwp:id="source-26">Quantified Morphology of the Human Vagus Nerve with Anti-Claudin-1 (Version 6)</source>. (<year>2020</year>). doi:<ext-link l:rel="related" l:ref-type="uri" l:ref="https://doi.org/10.26275/NLUU-1EWS" ext-link-type="uri" xlink:href="https://doi.org/10.26275/NLUU-1EWS" hwp:id="ext-link-20">https://doi.org/10.26275/NLUU-1EWS</ext-link></citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1"><label>28.</label><citation publication-type="website" citation-type="web" ref:id="2021.08.08.455581v3.28" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Quey R."><surname>Quey</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Kiran A."><surname>Kiran</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schiefer M."><surname>Schiefer</surname>, <given-names>M.</given-names></string-name> &amp; <string-name name-style="western" hwp:sortable="Patel B."><surname>Patel</surname>, <given-names>B.</given-names></string-name> (<year>2021</year>). <article-title hwp:id="article-title-10">KnowMore: v1.0.0 - Automated Knowledge Discovery Tool for SPARC Datasets (v1.0.0)</article-title>. <source hwp:id="source-27">Zenodo</source>. <ext-link l:rel="related" l:ref-type="uri" l:ref="https://doi.org/10.5281/zenodo.5137255" ext-link-type="uri" xlink:href="https://doi.org/10.5281/zenodo.5137255" hwp:id="ext-link-21">https://doi.org/10.5281/zenodo.5137255</ext-link></citation></ref></ref-list></back></article>
