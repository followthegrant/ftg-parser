<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/033662</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;033662v5</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;033662</article-id><article-id pub-id-type="other" hwp:sub-type="slug">033662</article-id><article-id pub-id-type="other" hwp:sub-type="tag">033662</article-id><article-version>1.5</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Neuroscience" hwp:journal="biorxiv"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">Putting value in context: A role for context memory in decisions for reward</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1"><label>*</label>To whom correspondence should be addressed: <email hwp:id="email-1">aaronmb@princeton.edu</email>.</corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" corresp="yes" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0001-6251-6000</contrib-id><name name-style="western" hwp:sortable="Bornstein Aaron M."><surname>Bornstein</surname><given-names>Aaron M.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0001-6251-6000"/></contrib><contrib contrib-type="author" hwp:id="contrib-2"><name name-style="western" hwp:sortable="Norman Kenneth A."><surname>Norman</surname><given-names>Kenneth A.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2"><label>1</label><institution hwp:id="institution-1">Neuroscience Institute, Princeton University</institution>, Princeton, NJ, <country>USA</country></aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1"><label>2</label><institution hwp:id="institution-2">Department of Psychology, Princeton University</institution>, Princeton, NJ, <country>USA</country></aff></contrib-group><pub-date pub-type="epub-original" hwp:start="2017"><year>2017</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2015-12-04T19:57:20-08:00">
    <day>4</day><month>12</month><year>2015</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2017-06-04T07:32:55-07:00">
    <day>4</day><month>6</month><year>2017</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2015-12-04T20:05:38-08:00">
    <day>4</day><month>12</month><year>2015</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2017-06-04T07:40:50-07:00">
    <day>4</day><month>6</month><year>2017</year>
  </pub-date><elocation-id>033662</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2015-12-04"><day>04</day><month>12</month><year>2015</year></date>
<date date-type="rev-recd" hwp:start="2017-06-03"><day>03</day><month>6</month><year>2017</year></date>
<date date-type="accepted" hwp:start="2017-06-04"><day>04</day><month>6</month><year>2017</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2017, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2017</copyright-year><license hwp:id="license-1"><p hwp:id="p-1">The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.</p></license></permissions><self-uri xlink:href="033662.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2019/pdf/033662v5.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="033662.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2019/abstracts/033662v5/033662v5.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2019/fulltext/033662v5/033662v5.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-2">How does experience inform decisions? In episodic sampling, decisions are guided by a few episodic memories of past choices. This process can yield choice patterns similar to model-free Reinforcement Learning (RL); however, samples can vary from trial to trial, causing decisions to vary. Here, we show that context retrieved during episodic sampling can cause choice behavior to deviate sharply from the predictions of RL. Specifically, we show that, when a given memory is sampled, choices (in the present) are influenced by the properties of other decisions made in the same context as the sampled event. This effect is mediated by fMRI measures of context retrieval on each trial, suggesting a mechanism whereby cues trigger retrieval of context, which then triggers retrieval of other decisions from that context. This result establishes a new avenue by which experience can guide choice, and as such has broad implications for the study of decisions.</p></abstract><counts><page-count count="30"/></counts><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-1">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta></front><body><sec id="s1" hwp:id="sec-1"><title hwp:id="title-2">Introduction</title><p hwp:id="p-3">How do we learn from our past decisions? According to the dominant model-free reinforcement learning (RL) theory of choice, actions are selected based on expected values that are computed as running averages of experienced rewards. This average is updated incrementally as new rewards are incorporated, resulting in a steadily decaying influence of past experiences [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">1</xref>]. We have previously shown that this pattern of dependence on experience can also result from an active deliberation process that draws, in a recency-weighted fashion, on episodic memories of relevant past choices as samples of possible outcome values [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">2</xref>]. For instance, we might evaluate a restaurant by recalling recent dining experiences at similar establishments.</p><p hwp:id="p-4">Both approaches assume that the influence of a past event on choice is a simple function of how long ago that event was experienced or remembered. Where they differ is in how that influence arises. In RL, the contribution of a given past trial to reward estimates on a given choice is a fixed, decreasing function of its age. In episodic sampling this influence is dynamic, which can cause its choices to diverge from RL. Because the process draws only a small number of samples, a given episode (even sometimes one from the far past) will, when recalled, have a large contribution to the estimated value for that decision. At the same time, recent episodes could be overlooked, and thus have no influence on the current choice. This distinction can be obscured when looking at average choice behavior in the sort of repeated decision task usually employed in the laboratory [<xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">3</xref>]. The difference between the predictions of these two models is more pronounced when incidental reminders of past choices are introduced to the decision-making task [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-2" hwp:rel-id="ref-2">2</xref>]. These reminders cue the past trial episode, recalling the action taken and reward received, and thus affect the next decision in a way not captured by standard RL.</p><p hwp:id="p-5">However, episodic memories consist of more than just the simple association between action and outcome. They also carry rich information about the temporal, spatial, and visual <italic toggle="yes">context</italic> of an experience [<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">4</xref>,<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">5</xref>]. When context is reinstated, it affects what we remember next: after recalling one event, we are more likely to subsequently recall events that share context with the first [<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">6</xref>]. For instance, when recalling one restaurant, we might also recall the street it was on, which could lead to recalling another restaurant from the same street.</p><p hwp:id="p-6">In this way, retrieval of contextual information could impact decisions made by episodic sampling. Specifically, context could induce a form of autocorrelation in sampling: The first sample also brings to mind the context from which subsequent samples are likely to be drawn. These following samples would also have an impact on decisions. The average influence on choice of a past episode would therefore be a function both of its age and the probability that other, contextually-related episodes would bring it to mind. This extra influence of context (if present) would constitute a radical departure from incremental RL, which has no means of accounting for this influence.</p><p hwp:id="p-7">To probe whether, and by what mechanism, context biases episodic sampling, we designed an experiment to isolate the effects of retrieved context on decision-making, distinct from the effect of the initial sampled trial. Participants performed a three-option choice task in which trials took place across seven visually-distinct contexts, described as “rooms” of a virtual casino, each distinguished by a context-specific image of an outdoor scene. After making each choice, participants were shown both the reward they earned and a trial-unique object picture. Some of these objects were later presented during recognition memory probes that were interleaved with the choice trials. Importantly, we designed the experiment such that the rewarded choice associated with a probed object was different from the choice that was most frequently rewarded in the room (context) where the probed object was originally presented. This procedure allowed us to disentangle the influence of the reminded trial episode [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-3" hwp:rel-id="ref-2">2</xref>] from that of the context.</p><p hwp:id="p-8">We hypothesized that, if recall of the reminded trial also triggered the reinstatement of context, we would observe that choices are influenced by the action rewarded in the context as a whole, not just the action rewarded on the reminded trial itself. This hypothesis further implies that the effects of retrieved context on choice will only be evident on trials where the object’s context (room) is retrieved. To test this prediction, we carried out an fMRI experiment and employed multivariate pattern analysis (MVPA) to covertly measure neural evidence for context reinstatement on each trial. Pattern classifiers (trained to recognize scene-related activity) output a trial-by-trial measure of how likely it was that participants were recalling a past context. We used this neural reinstatement index as a mediating variable to predict the effect of context on choices.</p><p hwp:id="p-9">Experiment 1 provided a behavioral test of influence of context. Experiment 2 provided both a behavioral test and a neural test (using fMRI) of the predictions outlined above. Taken together, these experiments reveal new aspects of the computational and neural mechanisms by which individual episodes of past experience are brought to bear on decisions for reward, and introduce a novel signature of decisions guided by episodic memory.</p></sec><sec id="s2" hwp:id="sec-2"><title hwp:id="title-3">Results</title><p hwp:id="p-10">In Experiment 1, 20 participants performed the task (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1</xref>) and their behavior was analyzed for evidence of context’s influence on decisions. In Experiment 2, 32 additional participants performed the task while being scanned in fMRI, which allowed us to examine a neural mechanism that gives rise to – and predicts the degree of – the influence of context on decisions.</p><fig id="fig1" position="float" orientation="portrait" fig-type="figure" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2 xref-fig-1-3 xref-fig-1-4 xref-fig-1-5 xref-fig-1-6 xref-fig-1-7 xref-fig-1-8 xref-fig-1-9 xref-fig-1-10"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;033662v5/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1:</label><caption hwp:id="caption-1"><title hwp:id="title-4">Task design.</title><p hwp:id="p-11">Participants (Experiment 1: 20; Experiment 2: 32) performed 300 trials of a three-option sequential choice task. <bold>a</bold>. <bold>Context learning.</bold> On each trial, participants chose between three card decks, each with a different, unsignaled, probability of paying out a $10 reward, as opposed to $0. After a deck was chosen, the top card was turned over, revealing a trial-unique object photograph. The first 180 choices took place in six “rooms” of a virtual casino. Rooms were distinguished by background photographs of outdoor scenes. <bold>b. Memory probes.</bold> The final 120 choices took place in a seventh room, which did not have a scene photograph in the background. Choices in this room were also rewarded, but did not result in object pictures. Interspersed among choices trials were 60 memory probe trials, which whether, and with what confidence, subjects remembered a given object picture. <bold>c. Example payoff timeseries</bold>. The probability that each deck would pay out $10 changed on each trial according to a Gaussian random walk centered around one of three distinct values: 60%, 30%, and 10%. Purple bands denote the first 10 trials in each new context room; after the 10th trial, the center values were shuffled across decks, such that the previous highest-paying deck was no longer the best option. Critically, images selected for memory probes were drawn only from these first 10 trials in each room, distinguishing the reward values of probed trials from those of the rest of the context.</p></caption><graphic xlink:href="033662_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-12">The following three phases were common to both experiments. In <italic toggle="yes">Phase 1</italic>, participants performed 300 trials of a three-option rewarded choice task (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Figure 1a,b</xref>). Choices returned either $10 or $0 with varying probability (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-3" hwp:rel-id="F1">Figure 1c</xref>; <xref rid="eqn1" ref-type="disp-formula" hwp:id="xref-disp-formula-1-1" hwp:rel-id="disp-formula-1">Equation 1</xref>). The first 180 trials took place across six “rooms” (contexts), distinguished by the presence of one of six scene images in the background (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-4" hwp:rel-id="F1">Figure 1a</xref>). In <italic toggle="yes">Phase 2</italic>, participants visited a seventh room, where no scene images were visible, and made 120 further choices; 60 recognition memory probes were interspersed between these choices at pseudorandom intervals (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-5" hwp:rel-id="F1">Figure 1b</xref>). On recognition probes, participants were asked whether, and with what confidence, they recognized the presented picture. Participants were rewarded with $0.25 for correct responses, and penalized by the same amount for incorrect responses. The average lag between initially viewing a picture and being tested on recognition of that picture was over 170 trials (Expt 1: Average lag 173.40 trials SEM 1.70; Expt 2: 175.88 SEM 0.64). In <italic toggle="yes">Phase 3</italic>, participants were given a source recognition test that assessed whether they could remember the room (context) in which the probed objects were encountered during Phase 1. Experiment 2 also had a fourth phase, an fMRI visual category localizer task used to train the pattern classifiers.</p><sec id="s2a" hwp:id="sec-3"><title hwp:id="title-5">Memory tasks</title><p hwp:id="p-13">Participants performed well on the recognition memory probes in Phase 2 (mean d’, Experiment 1: 2.51 SEM 0.29, Experiment 2: 2.43 SEM 0.20). Trials with incorrect answers on the recognition memory probe were rare. Trials with incorrect or low-confidence answers were excluded from further analysis because they were not of interest for our hypothesis; our goal was to evaluate the effect of <italic toggle="yes">successful</italic> reminders on subsequent decisions, and low-confidence and/or incorrect responses indicated that the reminders were unsuccessful. Performance on the Phase 3 source recognition task was also well above chance (Experiment 1 presented all six options, so chance level was 16.67%: actual performance mean 45.80% SEM 5.38% correct; Experiment 2 subselected three options to fit the MRI button box, so chance level was 33.33%: actual performance mean 68.12% SEM 2.38% correct).</p></sec><sec id="s2b" hwp:id="sec-4"><title hwp:id="title-6">Experiment 1</title><p hwp:id="p-14">Our primary measurement of interest was performance on choice trials after the recognition memory probes. By our hypothesis, these trials should show a significant influence of rewards received on trials across the reminded context (i.e., the room in which the reminded trial occurred during Phase 1; Figure S1 and Figure S2).</p><p hwp:id="p-15">We ran a multiple regression to model the effect on choice behavior of the recently received rewards, the identity of the recently chosen options, the value of the reward received on the probed trial, and the context reward. This analysis identified significant and separable effects of each of the three sources of reward information (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2a</xref>); in particular, we found that memory influenced choice in two distinct ways. First, replicating our previous results [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-4" hwp:rel-id="ref-2">2</xref>], we found that the reward content of trials evoked by memory probes influenced the option selected by participants on the ensuing choice trial. If the probed trial was not rewarded, participants were less likely to choose as they had on that probed trial. The reward received on the probed trial was a significant predictor of choice (<italic toggle="yes">t</italic>(19)=2.2043, <italic toggle="yes">P</italic>=0.04), with a mean regression weight of comparable magnitude to that of rewards directly received three trials earlier.</p><fig id="fig2" position="float" orientation="portrait" fig-type="figure" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3 xref-fig-2-4 xref-fig-2-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;033662v5/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2:</label><caption hwp:id="caption-2"><title hwp:id="title-7">Context reward influences choices following a probe.</title><p hwp:id="p-16">Multiple linear regression of three sources of reward information on choices following a probe. The increase in choice weight for a given deck resulting from each reward term are plotted here as the median (+/− one quartile) across participants, separately for each experiment (<bold>a</bold> for Experiment 1, <bold>b</bold> for Experiment 2). Columns 1-3 show the effect of recent rewards, which reflect an exponentially decaying influence of recent experience of the sort that could arise from either incremental model-free reinforcement learning or recency-weighted sampling models. These effects were significant in both experiments (Expt. 1: R<sub>-1</sub>: <italic toggle="yes">t</italic>(19)=7.8678, <italic toggle="yes">P</italic>&lt;0.0001; R<sub>-2</sub>: <italic toggle="yes">t</italic>(19)=9.5878, <italic toggle="yes">P</italic>&lt;0.0001; R<sub>-3</sub>: <italic toggle="yes">t</italic>(19)=3.0066, <italic toggle="yes">P</italic>=0.0073; Expt. 2: R<sub>-1</sub>: <italic toggle="yes">t</italic>(31)=11.8339, <italic toggle="yes">P</italic>&lt;0.0001, R<sub>-2</sub>: <italic toggle="yes">t</italic>(31)=9.2157, <italic toggle="yes">P</italic>&lt;0.0001; R<sub>-3</sub>: <italic toggle="yes">t</italic>(31)=9.6940, <italic toggle="yes">P</italic>&lt;0.0001). Column 4 shows the effect of reward received on the probed trial. This effect was significant in Experiment 1 (<italic toggle="yes">t</italic>(19)=2.2043, <italic toggle="yes">P</italic>=0.04), but not Experiment 2 (<italic toggle="yes">t</italic>(31)=−0.4878, <italic toggle="yes">P</italic>=0.6291). Column five shows the effect of rewards received in the context of the probed trial. This effect was significant in both experiments (Expt. 1: <italic toggle="yes">t</italic>(19)=3.5488, <italic toggle="yes">P</italic>=0.0021; Expt. 2: <italic toggle="yes">t</italic>(31)=2.4457, <italic toggle="yes">P</italic>=0.019). (* <italic toggle="yes">P</italic>&lt;0.05, ** <italic toggle="yes">P</italic> &lt; 0.01, *** <italic toggle="yes">P</italic> &lt; 0.001)</p></caption><graphic xlink:href="033662_fig2" position="float" orientation="portrait" hwp:id="graphic-2"/></fig><p hwp:id="p-17">Expanding beyond the previous results, we also found an effect of the rewards received for a given deck across other trials within the context of the probed trial (hereafter, the <italic toggle="yes">context reward</italic>; <xref rid="eqn2" ref-type="disp-formula" hwp:id="xref-disp-formula-2-1" hwp:rel-id="disp-formula-2">Equation 2</xref>). On choice trials following a memory probe, participants were more likely to choose a deck the greater were its proportion of trials being rewarded across the reminded context. This context reward was also a significant predictor of choices after a probe (<italic toggle="yes">t</italic>(19)=3.55, <italic toggle="yes">P</italic>=0.0021), with a mean regression weight of comparable magnitude to that of the reward received for direct experience just one or two trials previous. The effect of the reminded context was greater than the effect of the reminded trial (<italic toggle="yes">t</italic>(19)=2.7262, <italic toggle="yes">P</italic>=0.0134).</p></sec><sec id="s2c" hwp:id="sec-5"><title hwp:id="title-8">Experiment 2</title><p hwp:id="p-18">We then repeated the behavioral task from the first experiment with a new group of 32 participants. In this version, participants underwent fMRI scanning to allow us to identify brain activity predictive of the context reward effect. The results support the hypothesis that evoked context has a separate and strong influence on choice (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2b</xref>).</p><p hwp:id="p-19">Critically, as in the first experiment, the reward from the reminded context again had a significant effect on subsequent choice (<italic toggle="yes">t</italic>(31)=2.4457, <italic toggle="yes">P</italic>=0.0190). As in Experiment 2, the effect of reminded context was again greater than the effect of the reminded trial (<italic toggle="yes">t</italic>(31)=2.2613, P=0.0309). However, diverging from the results observed in Experiment 1 and the preceding study [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-5" hwp:rel-id="ref-2">2</xref>], the reward received on the probed trial did not have a significant effect on subsequent choice (<italic toggle="yes">t</italic>(31)=−0.4878, <italic toggle="yes">P</italic>=0.6291). Post-hoc simulations confirmed that both the relative prominence of the reminded context effect over the reminded trial effect and the sparing of the context effect when the single trial effect is not statistically reliable are consistent with our context-aware sampling mechanism. The intuition here is that – while the probe initially triggers sampling of the reminded trial – subsequent samples taken from the reminded context will outweigh the effects of sampling the reminded trial (Figures S3 and S4).</p><sec id="s2c1" hwp:id="sec-6"><title hwp:id="title-9">Regression results are incompatible with incremental learning models</title><p hwp:id="p-20">For the analyses reported above, we designed our context reward regressor to capture the average effect of sampling memories from the probed context: For a given context, each episode in that context in which a given card deck was chosen was treated as evidence for or against choosing that card deck (depending or whether the choice was rewarded). This way of computing context reward is qualitatively different from that which would be predicted by an incremental learning algorithm such as model-free temporal-difference learning. This is because those incremental algorithms would more heavily weight later experiences, and those with higher reward prediction errors. However, in our formulation, every trial from the probed context has equal weight.</p><p hwp:id="p-21">To explore whether the observed context reward effect could be explained by incrementally-learned action values, as in model-free reinforcement learning, we first fit RL models to choices in each of the six context rooms. Each model learned cached action values for the three card decks; two of these models reset those values when context changed–in one model, the context shifts/value resets at the time that the room changed, in the other model, values were reset at a variable trial number after the start of each room (to account for the possibility that context boundaries were inferred at the time the payoffs changed).</p><p hwp:id="p-22">The model that reset action values when the room changed was the best fit to behavior. By BIC versus the second-best model, in Experiment 1, the room-reset model was superior for 18/20 subjects, mean difference in BIC: 5.6981; In Experiment 2, 26/32 subjects, 4.6406. The fit parameters for the room-reset model – learning rate α, softmax temperature β, choice stickiness β<sub>p</sub> – were: Expt. 1 α mean 0.4802 SEM 0.0617, β mean 0.2333 SEM 0.2829, β<sub>p</sub> mean 0.4348 SEM 0.1392; Expt. 2 α mean 0.5738 SEM 0.0375, β mean 0.4623 SEM 0.0313, β<sub>p</sub> mean 0.2231 SEM 0.0738. These values were consistent across the two experiments (by unpaired, two-sample <italic toggle="yes">t</italic>-test: α: <italic toggle="yes">t</italic>(50)=1.3775, <italic toggle="yes">P</italic>=0.1745; β: <italic toggle="yes">t</italic>(50)=−1.0137, <italic toggle="yes">P</italic>=0.3156, β<sub>p</sub>: <italic toggle="yes">t</italic>(50)=1.4694, <italic toggle="yes">P</italic>=0.1480).</p><p hwp:id="p-23">We took the final values computed by this model for each card deck in each context and used them as context reward regressors in a regression analysis following that of <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Figure 2</xref>. The mean correlation between this new regressor and the corresponding original regressor was <italic toggle="yes">R</italic>=0.0564 (SEM 0.0645, <italic toggle="yes">t</italic>(19)=0.8749, <italic toggle="yes">P</italic>=0.3926) in Expt. 1 and <italic toggle="yes">R</italic>=0.1714 (SEM 0.0313, <italic toggle="yes">t</italic>(31)=5.4768, <italic toggle="yes">P</italic>=5.4728e−06) in Expt. 2. In each experiment the effect of this RL-derived context reward (<italic toggle="yes">β</italic><sub>RLCR</sub>) was significant or trending, but, critically, negative (Expt. 1, <italic toggle="yes">β</italic><sub>RLCR</sub>=−0.0125, SEM 0.0058, <italic toggle="yes">t</italic>(19)=2.1484, <italic toggle="yes">P</italic>=0.0448 across subjects; Expt. 2, <italic toggle="yes">β</italic><sub>RLCR</sub>=−0.0091, SEM 0.0050, <italic toggle="yes">t</italic>(31)=−1.8156, <italic toggle="yes">P</italic>=0.0791). When both the original context reward (β<sub>CR</sub>) and this new RL version were run alongside each other in a simultaneous regression, the weights to the original were unchanged compared to when run alone (Expt. 1: in the simultaneous regression, β<sub>CR</sub>=0.2335, SEM 0.0643; the difference between this and the original was not significant, <italic toggle="yes">t</italic>(19)=−0.1710, <italic toggle="yes">P</italic>=0.8660. Expt. 2: in the simultaneous regression, β<sub>CR</sub>=0.1306, SEM 0.0427; the difference between this and the original was not significant, <italic toggle="yes">t</italic>(31)=−0.4515, <italic toggle="yes">P</italic>=0.6548). Therefore, incrementally-learned action values cannot explain our observed results.</p></sec><sec id="s2c2" hwp:id="sec-7"><title hwp:id="title-10">fMRI analysis</title><p hwp:id="p-24">Previous work in our lab has shown that classifiers trained to identify fMRI correlates of scene processing can be used to track mental reinstatement of contexts in which scenes had (previously) been presented; furthermore, these neural measures of context reinstatement predict memory behavior [<xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">7</xref>]. We therefore used this same strategy in our study, “tagging” some contexts with scene pictures and then using scene evidence as a covert neural measure of context reinstatement. As both the probe image and the seventh “room” in which probes were presented are devoid of scene images, we interpret evidence of scene processing on probe trials as indicative of memory reinstatements, in particular of the scenes presented during the first six rooms of the experiment. On this basis we hypothesized that, as scene evidence increased, so too would the effect on decisions of context reward.</p><p hwp:id="p-25">We first identified regions of bilateral posterior parahippocampal cortex that were preferentially activated by the processing of scene images, using a post-task localizer scan where participants viewed scene images (and other kinds of images) that were not in the experiment (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure 3a</xref>). We then selected post-probe timepoints on which to perform our analysis. We selected as timepoints of interest those volumes following the presentation of a memory probe that reliably showed elevated classifier evidence for scenes (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Figure 3b</xref>). Based on this measure, timepoints four through six – representing the period from approximately eight to approximately twelve seconds after the onset of the probe image – were selected as our timepoints of interest.</p><fig id="fig3" position="float" orientation="portrait" fig-type="figure" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3 xref-fig-3-4 xref-fig-3-5 xref-fig-3-6"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;033662v5/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3:</label><caption hwp:id="caption-3"><title hwp:id="title-11">Context reward effect is mediated by scene reinstatement.</title><p hwp:id="p-26"><bold>a.</bold> We trained a classifier to discriminate between scenes, scrambled scenes, and objects, on the basis of activity in a scene-preferring region of posterior-parahippocampal cortex. <bold>b.</bold> Across subjects and trials, we selected the post-probe timepoints that showed elevated classifier evidence for scenes (.(* P &lt; 0.05) <bold>c.</bold> For each participant, we split choice trials following the probes into quartiles based on scene evidence during the selected timepoints. Repeating the regression of <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-4" hwp:rel-id="F2">Figure 2</xref> for each quartile of trials, we found that context reward effect was greater when scene evidence was higher (mean slope 0.041, SEM 0.0114, <italic toggle="yes">t</italic>(31)=3.5734, <italic toggle="yes">P</italic>=0.0012; plotted: for each bin, the median, +/- one quartile, across participants, of the standardized regression coefficients for the context reward effect).</p></caption><graphic xlink:href="033662_fig3" position="float" orientation="portrait" hwp:id="graphic-3"/></fig><p hwp:id="p-27">We then split probe trials into quartiles for each participant, based on the average level of scene evidence across the timepoints of interest in each trial. In other words, although these timepoints were selected because they showed elevated scene evidence on average, our analysis of interest relied on the variance in scene evidence across probe trials – specifically, we assessed whether scene evidence on probe trials predicted the effect of context reward on choices following those probes. For each quartile, we again ran the behavioral regression above, and calculated the size of the context reward effect, measured as the standardized regression weight applied to the context reward regressor computed as above. This regression weight was normalized to account for the different variance in the variable of interest across bins. We found that, on average, the influence of context reward increased along with classifier evidence for scenes (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Figure 3c</xref>, difference between lowest and highest quartile significant – <italic toggle="yes">t</italic>(31)=−3.2756, <italic toggle="yes">P</italic>=0.0026; Within subjects, a linear trend across the quartiles was positive and reliable – mean slope 0.041, SEM 0.0114, <italic toggle="yes">t</italic>(31)=3.5734, <italic toggle="yes">P</italic>=0.0012).</p></sec><sec id="s2c3" hwp:id="sec-8"><title hwp:id="title-12">Context reward is specifically modulated by scene evidence in PPA</title><p hwp:id="p-28">To confirm that scene reinstatement specifically modulated context reward, we repeated the analysis in <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-4" hwp:rel-id="F3">Figure 3c</xref> for each of our regressors of interest. We found that scene evidence did not reliably modulate any of the other regressors of interest (all <italic toggle="yes">P</italic> &gt; 0.14; Figure S5). Similar analyses excluded the possibility that our results could be explained by univariate activity or classifier evidence in several control regions (Figures S6 and S7).</p></sec><sec id="s2c4" hwp:id="sec-9"><title hwp:id="title-13">Reinstatement of individual scenes predicts the influence of context reward</title><p hwp:id="p-29">We next examined whether the patterns reinstated at probe trials were specific to individual room contexts. To test this, we first produced, for each participant and each context room, a template pattern consisting of the average PPA activity across all trials within that room. We then computed, at each probe trial that evoked a past decision, the average pattern in PPA across our timepoints of interest (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-5" hwp:rel-id="F3">Figure 3b</xref>). The evoked patterns were consistently in favor of the reminded room. On high-confidence, correct trials, the average (fisher-transformed) correlation between the pattern at probe and the room-pattern matching the context of the reminded trial was 0.0377 (SEM 0.0047, <italic toggle="yes">t</italic>(31)=7.9494, <italic toggle="yes">P</italic>=5.6502e−09 across subjects), while the average correlation with the non-reminded contexts was 0.0015 (SEM 0.0014, <italic toggle="yes">t</italic>(31)=1.0207, <italic toggle="yes">P</italic>=0.3153). Across subjects, the correlation with the reminded context was reliably larger than that with non-reminded contexts (<italic toggle="yes">t</italic>(31)=6.7397, <italic toggle="yes">P</italic>=1.5248e−07).</p><p hwp:id="p-30">We next incorporated this specific-scene measure into our regression, where it improved our estimation of the effect of context reward on choice. First, we turned the correlation values at each trial into a distribution of weights across the six possible contexts, by first adding one to each value (so they were all positive values within the range from zero to two), and then dividing each by the sum across all correlations. This produced a real number, between zero and one, reflecting the relative strength of evidence for reinstatement of each context room. Then, we computed the context reward regressor again for all six contexts, and multiplied these values by the corresponding specific-scene evidence, resulting in a distribution of context reward values scaled by the reinstatement evidence for each context. Finally, the sum of these scaled values was entered into the regression as a reinstatement-weighted version of the original context reward regressor.</p><p hwp:id="p-31">Consistent with the idea that the specific content of reinstatements was a strong influence on choices, the regression weight assigned to the evidence-scaled context reward regressor (<italic toggle="yes">β<sub>RCR</sub></italic>) was reliably positive (mean=0.3851, SEM 0.0863, <italic toggle="yes">t</italic>(31)=4.4611, <italic toggle="yes">P</italic>=9.9968e−05). The regression model containing the new, evidence-scaled, version of the context reward was consistently better than the original model (average difference in R<sup>2</sup>=0.0041, SEM 0.0016, <italic toggle="yes">t</italic>(31)=−2.6794, <italic toggle="yes">P</italic>=0.0117). When both versions of the regressor were placed alongside each other in the same regression model, the original variable was assigned essentially no regression weight (average <italic toggle="yes">β<sub>CR</sub></italic> =0.0141, SEM 0.0472, <italic toggle="yes">t</italic>(31)=0.8676, <italic toggle="yes">P</italic>=0.3923), while the scene-specific scaled variant remained a strong and consistent predictor of choices (mean <italic toggle="yes">β<sub>RCR</sub></italic> =0.3923, SEM 0.0877, <italic toggle="yes">t</italic>(31)= 4.4732, <italic toggle="yes">P</italic>=9.6597e−05). Supporting the hypothesis that these reinstatements reflect memory retrieval [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-6" hwp:rel-id="ref-2">2</xref>,<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">8</xref>], we observed that the entropy of each trial’s distribution of specific-scene reinstatement weights was positively correlated with activity in hippocampus (Figure S8).</p><p hwp:id="p-32">Together, these results affirm a specific and measurable role for context-aware episodic sampling during decisions for reward.</p></sec></sec></sec><sec id="s3" hwp:id="sec-10"><title hwp:id="title-14">Discussion</title><p hwp:id="p-33">Context is a critical aspect of episodic memories. Events do not happen in isolation – the memories of our lived experiences are necessarily situated within a web of associations with internal and external state: where they happened, who they happened with, and what else happened in relation. Items can cue retrieval of contextual features and vice-versa [<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-2" hwp:rel-id="ref-5">5</xref>]. When we bring our memories of the past to bear in deciding what actions to take in the present, it stands to reason that this rich contextual web would affect which memories are recalled and – through this – what decisions we make. However, previous work – even work investigating the use of episodic memory in decisions – has not examined the impact of contextual associations on choice.</p><p hwp:id="p-34">In this study, we investigated how memory for the context of past choice outcomes can affect present decisions for reward. We observed that decisions were biased by incidental memory probes that reminded participants of past choice trials. We observed a separate influence of both reward information on the reminded trial, and of reward information on other trials that shared context with the reminded trial. This influence of reminders is not captured by RL models, and the influence of context in particular is a novel prediction of episodic sampling [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-7" hwp:rel-id="ref-2">2</xref>], tested here for the first time. Across studies, the effect of the reminded context on choices was consistently greater than that of the individual reminded trial. This relationship matches our proposed sequential sampling model, where successive samples after that of the reminded trial are drawn from a linked context whose reward statistics were designed to run counter to the probed trials (Figure S3). The effect of both the reminded trial and its associated context were reduced in the second experiment. However, as predicted by the episodic sampling model, the effect of reminded context remained proportionally stronger than the reminded trial, and, critically, a significant influence on choices (Figure S4).</p><p hwp:id="p-35">To investigate the neural mechanism that gives rise to this effect, we used pattern classifiers trained on fMRI data to produce a continuous neural measurement of evidence for whether participants reinstated context from memory. Critically, we showed that this neural measurement predicted the size of the behavioral effect: The extent to which participants bring to mind the context of past episodes was correlated with the influence of context reward on decisions. These results are consistent with computational models of temporal context memory [<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">9</xref>] – a central prediction of these models is that, when context is reinstated, this leads to to additional memories being recalled from the same context [<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-3" hwp:rel-id="ref-5">5</xref>]. The present results tie together this effect of context on memory recall, and the neural mechanisms that mediate the effect, with recent findings that support a role for episodic memory recall in deliberative decisions for reward [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-8" hwp:rel-id="ref-2">2</xref>, <xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">10</xref>].</p><p hwp:id="p-36">The mechanism presented here is distinct from, but complementary to, the mechanism thought to underlie previous observations of episodic memory’s involvement in decisions via spreading associations [<xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">11</xref>]. In that study, Wimmer &amp; Shohamy showed that pairing rewards with unvalenced images can “spread” that reward (during learning) to other unvalenced images that had been associated with the first, and that this second-order reward association can induce a preference for the latter image. Our experiment design has a more complex associative structure that makes this kind of “reward spreading during learning” account highly unlikely. To get spreading during learning, we would need to posit that – when participants make choices late in the context (e.g., choosing the blue deck and getting rewarded) – they mentally activate objects shown early in the context (e.g., binoculars) and associate those objects to the blue deck getting rewarded. This is implausible because the only route for the binoculars to be activated is via their link to the context image, and the binoculars were just one of tens of items that were linked to this context; this high “fan out” of associations from the context image makes it unlikely that participants will strongly activate binoculars or any other single previous item from the context. In any case, even if this did happen infrequently, it is highly implausible that it would happen enough to explain our finding that indirect, contextually mediated associations exert a <italic toggle="yes">stronger</italic> effect on subsequent choice than direct associations. Throughout the paper, we have argued that – rather than “spreading” of associations between stimuli and reward during learning – our results arise from dynamic estimation of that value at the time of choice, based on contextually-mediated sampling. The distinction between these two types of memory-guided decisions reflects the proposed division [<xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">12</xref>] between “retrospective” (referring to the Wimmer &amp; Shohamy finding) versus “prospective” (this study, also Bornstein et al. [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-9" hwp:rel-id="ref-2">2</xref>]) integration. We provide here the first demonstration that such prospective integration is mediated by context-guided sampling from episodic memory, and that this context information induces sequential dependencies in the integration process. This case for prospective, dynamic estimation of value through sampling is convergently supported by our regression modeling (showing that indirect, contextually-mediated effects are larger than direct effects, and that these effects cannot be explained by incremental learning), simulation work (showing that our context-guided sampling model can account for context effects exceeding direct effects; Figures S3 and S4), and neural data (showing that variance in retrieval of specific scene contexts at the time of choice predicts how strongly context memory affects decision behavior).</p><p hwp:id="p-37">A key contribution of the present work is that it sharply distinguishes the pattern of choices arising from episodic sampling from those predicted by model-free RL. Our previous work assumed only that episodic memories were drawn according to their recency, yielding a dependence of decisions on past experience that follows the same qualitative form as that of incremental RL [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-10" hwp:rel-id="ref-2">2</xref>]. If that recency-dependent sampling was the only way that episodic memories translated to decisions, then it could be argued that model-free RL fits to behavior capture an approximate, average form of the underlying mechanism. However, the discovery that samples depend in part on context undermines the generalizability of that analogy, because context can induce sequential dependencies into the sampling process that are not explainable in terms of simple recency. Our results suggest that, to estimate the influence that a given past trial will have on the current decision, we must know not only its age, but also the relative likelihood that it might be brought to mind by the recall of other past trials. In this study, the context was made visually explicit, but in natural environments, contextual links between episodes may arise from a wide array of external or internal associations [<xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">13</xref>]; as such, we expect these contextual effects on decision-making to be ubiquitous in everyday life.</p><p hwp:id="p-38">More generally, the present findings pose a challenge for economic approaches to modeling decisions. This is because standard economic models eschew consideration of the underlying mechanism, instead focusing exclusively on inferring stable preferences as “revealed” via actual choices [<xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">14</xref>]. Contrary to this view, our results suggest that choices do not always depend solely on stable preferences – instead, they are constructed dynamically at the time of decision [<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">15</xref>, <xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">16</xref>], and critically via a process that draws on a complex web of contextual associations that might be only incidentally related to past decisions of the same kind. This idea considerably complicates models of decision making, but it also provides a way forward: By drawing on our understanding of the cognitive and neural mechanisms giving rise to decisions (here, episodic memory retrieval and contextual reinstatement), we account in a principled way for variance in choice behavior that would otherwise be attributed to noise.</p></sec><sec id="s4" hwp:id="sec-11"><title hwp:id="title-15">Data and code availability</title><p hwp:id="p-39">The data that support the findings of this study are available on reasonable request from the corresponding author (A.M.B). The data are not publicly available because they contain information that could compromise research participant privacy/consent. In the near future, they will be de-identified at the level of contemporary best practices and placed in a public repository, which will be linked to at the below GitHub URL. Standard software packages (SPM8 and FSL 5.0.4) were used for processing the MRI data in addition to custom Matlab scripts. Custom-written analysis code is available upon reasonable request to the corresponding author (A.M.B). Context-aware sampling model code is publicly available at the corresponding author’s GitHub repository (<ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/aaronbneuro/neurocode" ext-link-type="uri" xlink:href="https://github.com/aaronbneuro/neurocode" hwp:id="ext-link-1">https://github.com/aaronbneuro/neurocode</ext-link>).</p></sec></body><back><ack hwp:id="ack-1"><title hwp:id="title-16">Acknowledgements</title><p hwp:id="p-40">The authors wish to thank Jeremy Manning for providing localizer code and stimuli, A. Schapiro, A. Rangel, J. Poppenk, M. deBettencourt, S. Chan and Y. Niv for fruitful discussions, and M. Aly, C. Honey, A. Shenhav and anonymous reviewers for helpful comments on an earlier version of the manuscript. This publication was made possible through the support of a grant from the John Templeton Foundation (Grant ID #57876; K.A.N). The opinions expressed in this publication are those of the authors and do not necessarily reflect the views of the John Templeton Foundation.</p></ack><sec id="s5" hwp:id="sec-12"><title hwp:id="title-17">Author Contributions</title><p hwp:id="p-41">A.M.B and K.A.N designed the experiment; A.M.B ran the experiment; A.M.B analyzed the data; A.M.B and K.A.N wrote the paper</p></sec><sec sec-type="COI-statement" hwp:id="sec-13"><title hwp:id="title-18">Competing Financial Interests Statement</title><p hwp:id="p-42"><named-content content-type="COI-statement" hwp:id="named-content-1">The authors declare that they have no competing financial interests.</named-content></p></sec><ref-list hwp:id="ref-list-1"><title hwp:id="title-19">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1"><label>[1]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Lau Brian"><given-names>Brian</given-names> <surname>Lau</surname></string-name> and <string-name name-style="western" hwp:sortable="Glimcher Paul W"><given-names>Paul W</given-names> <surname>Glimcher</surname></string-name>. <article-title hwp:id="article-title-2">Dynamic Response-by-Response Models of Matching Behavior in Rhesus Monkeys</article-title>. <source hwp:id="source-1">Journal of the Experimental Analysis of Behavior</source>, <volume>84</volume>(<issue>3</issue>):<fpage>555</fpage>–<lpage>579</lpage>, nov <year>2005</year>. ISSN <pub-id pub-id-type="issn">0022-5002</pub-id>. doi: <pub-id pub-id-type="doi">10.1901/jeab.2005.110-04</pub-id>. URL <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.pubmedcentral.gov/articlerender.fcgi?artid=1389781" ext-link-type="uri" xlink:href="http://www.pubmedcentral.gov/articlerender.fcgi?artid=1389781" hwp:id="ext-link-2">http://www.pubmedcentral.gov/articlerender.fcgi?artid=1389781</ext-link>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1 xref-ref-2-2 xref-ref-2-3 xref-ref-2-4 xref-ref-2-5 xref-ref-2-6 xref-ref-2-7 xref-ref-2-8 xref-ref-2-9 xref-ref-2-10 xref-ref-2-11 xref-ref-2-12"><label>[2]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.2" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Bornstein Aaron M"><given-names>Aaron M</given-names> <surname>Bornstein</surname></string-name>, <string-name name-style="western" hwp:sortable="Khaw Mel W"><given-names>Mel W</given-names> <surname>Khaw</surname></string-name>, <string-name name-style="western" hwp:sortable="Shohamy Daphna"><given-names>Daphna</given-names> <surname>Shohamy</surname></string-name>, and <string-name name-style="western" hwp:sortable="Daw Nathaniel D."><given-names>Nathaniel D.</given-names> <surname>Daw</surname></string-name>. <article-title hwp:id="article-title-3">What’s past is present: Reminders of past choices bias decisions for reward in humans</article-title>. <source hwp:id="source-2">Nature Communications</source>, <year>2017</year>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><label>[3]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Daw N D"><given-names>N D</given-names> <surname>Daw</surname></string-name>, <string-name name-style="western" hwp:sortable="O’Doherty J P"><given-names>J P</given-names> <surname>O’Doherty</surname></string-name>, <string-name name-style="western" hwp:sortable="Dayan P"><given-names>P</given-names> <surname>Dayan</surname></string-name>, <string-name name-style="western" hwp:sortable="Seymour B"><given-names>B</given-names> <surname>Seymour</surname></string-name>, and <string-name name-style="western" hwp:sortable="Dolan R J"><given-names>R J</given-names> <surname>Dolan</surname></string-name>. <article-title hwp:id="article-title-4">Cortical substrates for exploratory decisions in humans</article-title>. <source hwp:id="source-3">Nature</source>, <volume>441</volume>:<fpage>876</fpage>–<lpage>879</lpage>, <year>2006</year>.</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1"><label>[4]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Polyn Sean M."><given-names>Sean M.</given-names> <surname>Polyn</surname></string-name>, <string-name name-style="western" hwp:sortable="Norman Kenneth A."><given-names>Kenneth A.</given-names> <surname>Norman</surname></string-name>, and <string-name name-style="western" hwp:sortable="Kahana Michael J."><given-names>Michael J.</given-names> <surname>Kahana</surname></string-name>. <article-title hwp:id="article-title-5">A context maintenance and retrieval model of organizational processes in free recall</article-title>. <source hwp:id="source-4">Psychological Review</source>, <volume>116</volume>(<issue>1</issue>):<fpage>129</fpage>–<lpage>156</lpage>, <year>2009</year>. ISSN <pub-id pub-id-type="issn">1939-1471</pub-id>. doi: <pub-id pub-id-type="doi">10.1037/a0014420</pub-id>. URL <ext-link l:rel="related" l:ref-type="uri" l:ref="http://doi.apa.org/getdoi.cfm?doi=10.1037/a0014420" ext-link-type="uri" xlink:href="http://doi.apa.org/getdoi.cfm?doi=10.1037/a0014420" hwp:id="ext-link-3">http://doi.apa.org/getdoi.cfm?doi=10.1037/a0014420</ext-link>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1 xref-ref-5-2 xref-ref-5-3"><label>[5]</label><citation publication-type="book" citation-type="book" ref:id="033662v5.5" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Manning Jeremy R"><given-names>Jeremy R</given-names> <surname>Manning</surname></string-name>, <string-name name-style="western" hwp:sortable="Kahana Michael J"><given-names>Michael J</given-names> <surname>Kahana</surname></string-name>, and <string-name name-style="western" hwp:sortable="Norman Kenneth A"><given-names>Kenneth A</given-names> <surname>Norman</surname></string-name>. <chapter-title>The role of context in episodic memory</chapter-title>. In <string-name name-style="western" hwp:sortable="Gazzaniga M"><given-names>M</given-names> <surname>Gazzaniga</surname></string-name>, editor, <source hwp:id="source-5">The Cognitive Neurosciences</source>, pages <fpage>557</fpage>–<lpage>566</lpage>. <publisher-name>MIT Press</publisher-name>, <publisher-loc>Cambridge, MA</publisher-loc>, <year>2014</year>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1"><label>[6]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Sederberg Per B"><given-names>Per B</given-names> <surname>Sederberg</surname></string-name>, <string-name name-style="western" hwp:sortable="Gershman Samuel J"><given-names>Samuel J</given-names> <surname>Gershman</surname></string-name>, <string-name name-style="western" hwp:sortable="Polyn Sean M"><given-names>Sean M</given-names> <surname>Polyn</surname></string-name>, and <string-name name-style="western" hwp:sortable="Norman Kenneth A"><given-names>Kenneth A</given-names> <surname>Norman</surname></string-name>. <article-title hwp:id="article-title-6">Human memory reconsolidation can be explained using the Temporal Context Model</article-title>. <source hwp:id="source-6">Psychonomic Bulletin &amp; Review</source>, <volume>18</volume>:<fpage>455</fpage>–<lpage>469</lpage>, <year>2011</year>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1 xref-ref-7-2"><label>[7]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Gershman Samuel J"><given-names>Samuel J</given-names> <surname>Gershman</surname></string-name>, <string-name name-style="western" hwp:sortable="Schapiro Anna C"><given-names>Anna C</given-names> <surname>Schapiro</surname></string-name>, <string-name name-style="western" hwp:sortable="Hupbach Almut"><given-names>Almut</given-names> <surname>Hupbach</surname></string-name>, and <string-name name-style="western" hwp:sortable="Norman Kenneth A"><given-names>Kenneth A</given-names> <surname>Norman</surname></string-name>. <article-title hwp:id="article-title-7">Neural context reinstatement predicts memory misattribution</article-title>. <source hwp:id="source-7">The Journal of Neuroscience</source>, <volume>33</volume>(<issue>20</issue>):<fpage>8590</fpage>–<lpage>5</lpage>, May <year>2013</year>. ISSN <pub-id pub-id-type="issn">1529-2401</pub-id>. doi: <pub-id pub-id-type="doi">10.1523/JNEUROSCI.0096-13.2013</pub-id>. URL <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.ncbi.nlm.nih.gov/pubmed/23678104" ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/23678104" hwp:id="ext-link-4">http://www.ncbi.nlm.nih.gov/pubmed/23678104</ext-link>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><label>[8]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Shadlen Michael N"><given-names>Michael N</given-names> <surname>Shadlen</surname></string-name> and <string-name name-style="western" hwp:sortable="Shohamy Daphna"><given-names>Daphna</given-names> <surname>Shohamy</surname></string-name>. <article-title hwp:id="article-title-8">Decision Making and Sequential Sampling from Memory</article-title>. <source hwp:id="source-8">Neuron</source>, <volume>90</volume>(<issue>5</issue>):<fpage>927</fpage>–<lpage>939</lpage>, <year>2016</year> doi: <pub-id pub-id-type="doi">10.1016/j.neuron.2016.04.036</pub-id>. ISSN <pub-id pub-id-type="issn">927-939</pub-id> URL <ext-link l:rel="related" l:ref-type="uri" l:ref="http://dx.doi.org/10.1016/j.neuron.2016.04.036" ext-link-type="uri" xlink:href="http://dx.doi.org/10.1016/j.neuron.2016.04.036" hwp:id="ext-link-5">http://dx.doi.org/10.1016/j.neuron.2016.04.036</ext-link>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1"><label>[9]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Howard Marc W."><given-names>Marc W.</given-names> <surname>Howard</surname></string-name> and <string-name name-style="western" hwp:sortable="Kahana Michael J."><given-names>Michael J.</given-names> <surname>Kahana</surname></string-name>. <article-title hwp:id="article-title-9">A Distributed Representation of Temporal Context</article-title>. <source hwp:id="source-9">Journal of Mathematical Psychology</source>, <volume>46</volume>(<issue>3</issue>):<fpage>269</fpage>– <lpage>299</lpage>, jun <year>2002</year>. ISSN <pub-id pub-id-type="issn">00222496</pub-id>. doi: <pub-id pub-id-type="doi">10.1006/jmps.2001.1388</pub-id>. URL <ext-link l:rel="related" l:ref-type="uri" l:ref="http://linkinghub.elsevier.com/retrieve/pii/S0022249601913884" ext-link-type="uri" xlink:href="http://linkinghub.elsevier.com/retrieve/pii/S0022249601913884" hwp:id="ext-link-6">http://linkinghub.elsevier.com/retrieve/pii/S0022249601913884</ext-link>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><label>[10]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Bornstein Aaron M."><given-names>Aaron M.</given-names> <surname>Bornstein</surname></string-name> and <string-name name-style="western" hwp:sortable="Daw Nathaniel D."><given-names>Nathaniel D.</given-names> <surname>Daw</surname></string-name>. <article-title hwp:id="article-title-10">Cortical and Hippocampal Correlates of Deliberation During Model-Based Decisions for Rewards in Humans</article-title>. <source hwp:id="source-10">PLoS Computational Biology</source>, <volume>9</volume>(<issue>12</issue>):<fpage>e1003387</fpage>, dec <year>2013</year>. ISSN <pub-id pub-id-type="issn">1553-7358</pub-id>. doi: <pub-id pub-id-type="doi">10.1371/journal.pcbi.1003387</pub-id>. URL <ext-link l:rel="related" l:ref-type="uri" l:ref="http://dx.plos.org/10.1371/journal.pcbi.1003387" ext-link-type="uri" xlink:href="http://dx.plos.org/10.1371/journal.pcbi.1003387" hwp:id="ext-link-7">http://dx.plos.org/10.1371/journal.pcbi.1003387</ext-link>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><label>[11]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Wimmer G.E."><given-names>G.E.</given-names> <surname>Wimmer</surname></string-name> and <string-name name-style="western" hwp:sortable="Shohamy D."><given-names>D.</given-names> <surname>Shohamy</surname></string-name>. <article-title hwp:id="article-title-11">Preference by association: How memory mechanisms in the hippocampus bias decisions</article-title>. <source hwp:id="source-11">Science</source>, <volume>338</volume>:<fpage>270</fpage>–<lpage>3</lpage>, <year>2012</year>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1"><label>[12]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.12" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Shohamy Daphna"><given-names>Daphna</given-names> <surname>Shohamy</surname></string-name> and <string-name name-style="western" hwp:sortable="Daw Nathaniel D."><given-names>Nathaniel D.</given-names> <surname>Daw</surname></string-name>. <article-title hwp:id="article-title-12">Integrating memories to guide decisions</article-title>. <source hwp:id="source-12">Current Opinion in Behavioral Sciences</source>, <volume>5</volume>(<issue>October</issue>):<fpage>85</fpage>–<lpage>90</lpage>, <year>2015</year>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1"><label>[13]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Gershman Samuel J"><given-names>Samuel J</given-names> <surname>Gershman</surname></string-name> and <string-name name-style="western" hwp:sortable="Niv Yael"><given-names>Yael</given-names> <surname>Niv</surname></string-name>. <article-title hwp:id="article-title-13">Learning latent structure: carving nature at its joints</article-title>. <source hwp:id="source-13">Current Opinion in Neurobiology</source>, <volume>20</volume>(<issue>2</issue>):<fpage>251</fpage>–<lpage>6</lpage>, apr <year>2010</year>. ISSN <pub-id pub-id-type="issn">1873-6882</pub-id>. doi: <pub-id pub-id-type="doi">10.1016/j.conb.2010.02.008</pub-id>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><label>[14]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Bernheim B Douglas"><given-names>B Douglas</given-names> <surname>Bernheim</surname></string-name>. <article-title hwp:id="article-title-14">On the potential of Neuroeconomics: A critical (but hopeful) appraisal</article-title>. <source hwp:id="source-14">American Economic Journal: Microeconomics</source>, <volume>1</volume>(<issue>2</issue>):<fpage>1</fpage>–<lpage>41</lpage>, <year>2009</year>. ISSN <pub-id pub-id-type="issn">1098-6596</pub-id>. doi: <pub-id pub-id-type="doi">10.1017/CBO9781107415324.004</pub-id>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><label>[15]</label><citation publication-type="book" citation-type="book" ref:id="033662v5.15" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Weber Elke U"><given-names>Elke U</given-names> <surname>Weber</surname></string-name> and <string-name name-style="western" hwp:sortable="Johnson Eric J"><given-names>Eric J</given-names> <surname>Johnson</surname></string-name>. <chapter-title>Constructing Preferences from Memory</chapter-title>. In <string-name name-style="western" hwp:sortable="Lichtenstein S"><given-names>S</given-names> <surname>Lichtenstein</surname></string-name> and <string-name name-style="western" hwp:sortable="Slovic P"><given-names>P</given-names> <surname>Slovic</surname></string-name>, editors, <source hwp:id="source-15">The Construction of Preference</source>, pages <fpage>397</fpage>–<lpage>410</lpage>. <publisher-name>Cambridge University Press</publisher-name>, <publisher-loc>New York, NY</publisher-loc>, <year>2006</year>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1"><label>[16]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Erev Ido"><given-names>Ido</given-names> <surname>Erev</surname></string-name>, <string-name name-style="western" hwp:sortable="Ert Eyal"><given-names>Eyal</given-names> <surname>Ert</surname></string-name>, and <string-name name-style="western" hwp:sortable="Yechiam Eldad"><given-names>Eldad</given-names> <surname>Yechiam</surname></string-name>. <string-name name-style="western" hwp:sortable="Aversion Loss"><given-names>Loss</given-names> <surname>Aversion</surname></string-name>, <article-title hwp:id="article-title-15">Diminishing Sensitivity, and the Effect of Experience on Repeated Decisions</article-title>. <source hwp:id="source-16">Journal of Behavioral Decision Making</source>, <volume>21</volume> (<issue>May</issue>):<fpage>575</fpage>–<lpage>597</lpage>, <year>2008</year>. doi: <pub-id pub-id-type="doi">10.1002/bdm</pub-id>.</citation></ref></ref-list><sec id="s7" hwp:id="sec-14"><title hwp:id="title-20">Online Methods</title><sec id="s7a" hwp:id="sec-15"><title hwp:id="title-21">Participants</title><p hwp:id="p-43">23 participants (12 female, mean age 24, range 18-50) performed the task in Experiment 1. Three were excluded for failing memory test criteria (object recognition memory in Phase 2 at d’ &lt; 1, or source recognition performance during Phase 3 not significantly different from chance), leaving 20 participants included in the analyses presented here. 38 participants (21 female, mean age 25, range 18-64) performed the task in Experiment 2. One was excluded for excessive motion during the scan, one was excluded for falling asleep during the scan, and four were excluded for a programming error that caused unrecorded responses, leaving 32 participants included in the analyses presented here. All participants were free of neurological or psychiatric disease, and fully consented to participate. The study protocol was approved by the Institutional Review Board for Human Subjects at Princeton University.</p></sec><sec id="s7b" hwp:id="sec-16"><title hwp:id="title-22">Task</title><p hwp:id="p-44">The experiment was controlled by a script written in Matlab (Mathworks, Natick, MA, USA), using the Psychophysics Toolbox [<xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">17</xref>]. Participants performed a series of 300 choices between three differently-colored card decks with continuously changing probabilities of reward.</p><p hwp:id="p-45">The experiment proceeded in four phases. In <italic toggle="yes">Phase 1</italic>, the <italic toggle="yes">Contexts</italic> phase, 180 choice trials were presented across six consecutive “rooms” of a virtual casino (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-6" hwp:rel-id="F1">Figure 1</xref>). Rooms were distinguished by the presence of one of six background images of natural scenes. Choices resulted in the top card of the chosen deck being turned over to reveal a trial-unique picture of an everyday object, followed by the presentation of a reward of $10 or $0 (described in detail below, <italic toggle="yes">Choice trials</italic>). The probability that each deck would deliver a $10 reward changed on each trial. This probability was generated according to the procedure described under <italic toggle="yes">Payoffs</italic>. Following Phase 1, participants were asked to rest for as long as they needed, and to indicate their desire to continue by pressing any button twice.</p><p hwp:id="p-46">In <italic toggle="yes">Phase 2</italic>, the <italic toggle="yes">Probes</italic> phase, participants performed 120 additional choice trials, along with 60 memory probe trials interspersed at pseudorandom intervals where we tested recognition memory for objects from Phase 1 (see <italic toggle="yes">Phase 2 recognition probes</italic> below). During this phase, participants were told that they had entered a seventh, “unfinished”, room of the casino. In this seventh room, the screen no longer contained a background scene image. Choices in the seventh room did not return object pictures, but continued to be rewarded according to slowly-varying payoff probabilities.</p><p hwp:id="p-47">In <italic toggle="yes">Phase 3</italic>, the <italic toggle="yes">Source Recognition</italic> phase, participants answered 50 source recognition memory questions in which they were asked to match a previously-encountered object image to the scene (context) in which it had appeared (in Experiment 1 the choice was out of all six scenes, while in Experiment 2 the choice was among three presented options to fit the constraints of the MRI button box and for clarity of identification on the projected screen).</p><p hwp:id="p-48">Lastly, in <italic toggle="yes">Phase 4</italic>, the <italic toggle="yes">Localizer</italic> phase, participants performed a blocked, one-back image repeat detection task. This task was used to identify fMRI responses to three image categories: objects, scenes, and scrambled scenes. The detailed timing and structure of trials in each of these four phases are described below.</p><p hwp:id="p-49">Prior to the experiment, participants were given written and verbal instructions as to the types of trials, the payoff probabilities, the button presses required of them, and the rules for determining the final payout. They were told that the decks had different probabilities of paying out, that these probabilities would continually change, and that the probabilities of each deck paying out were independent of each other (as were the outcomes themselves). They were also told that that no aspect of the decks or choice process would change when traveling between rooms – in other words, one could not expect payoff probabilities to shift suddenly when the rooms did – but that the payoff probabilities would occasionally change dramatically, in addition to continuously changing slowly. Instructions emphasized that there was no pattern linking the content of the object pictures to their dollar value or deck. Participants were not told that the Phase 2 memory probe trials should have an effect on their choices, nor was any effect implied. They were, however, told that their final payout would depend in part on their later memory linking the object pictures to the room scenes. To aid their memory, participants practiced, and were encouraged to use, an elaborative encoding strategy in which they would construct, but not vocalize, a sentence describing the object being used in the background scene (e.g. for the object-scene shown pair in <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-7" hwp:rel-id="F1">Figure 1</xref>, an example sentence might be “I use these binoculars to look at the city skyline.”). After participants read the instructions, the experimenter verbally administered a quiz testing their knowledge of the payout rules, room structure, and encoding strategy.</p><p hwp:id="p-50">Once in the scanner, participants performed four practice choice trials and one practice memory probe trial, all unscanned, before beginning the main experiment. If participants failed the practice memory probe trial, or expressed a desire to practice again, the practice trials were repeated until both the participant and operator were satisfied.</p><sec id="s7b1" hwp:id="sec-17"><title hwp:id="title-23">Choice trials</title><p hwp:id="p-51">On each choice trial in Phase 1 and Phase 2, participants were presented with three card decks, colored Red, Green, and Blue (order pseudorandomized across participants), arrayed across a green table along the top of the screen (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-8" hwp:rel-id="F1">Figure 1a</xref>). In Phase 1, the background of the screen contained a picture of one of six outdoor scenes. The background scene remained consistent for 30 consecutive trials, then changed at the onset of next “room”. Participants were given three seconds to make a choice between the decks. Decks were chosen by pressing the “1”, “2”, or “3” key in Experiment 1, and the buttons under the index, middle, or ring finger in Experiment 2, corresponding to the decks from left to right. When a choice was made, the unchosen decks were hidden and the chosen deck was isolated on the green table, and remained so until the end of the three second choice period. For Phase 1 only, the top card of the chosen deck was “turned over” to reveal a trial-unique picture of an everyday object. This picture remained on the screen for two seconds, and then the card was turned back over. The isolated deck remained on the screen and a reward value was displayed – either $10 (a picture of a US $10 bill) or $0 (a phase-scrambled version of the same bill). The reward value remained on the screen for 1.5 seconds, followed by a blank screen for an inter-trial-interval (ITI) of length varying between 0.5 and 8 seconds, mean 1 second, selected from a truncated, discretized exponential distribution generated pseudorandomly for each participant. Between rooms, participants were shown a screen with the name of the next room, and a countdown from four seconds before the next room began.</p></sec><sec id="s7b2" hwp:id="sec-18"><title hwp:id="title-24">Payoffs</title><p hwp:id="p-52">For Phase 1 and Phase 2, choices resulted in rewards with amounts selected according to continually changing probabilities. The probability that each deck I would pay out $10, <italic toggle="yes">π<sub>i,t</sub></italic>, changed independently on each trial according a decaying Gaussian random walk with reflecting bounds at 5% and 95% (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-9" hwp:rel-id="F1">Figure 1b</xref>). Specifically, for each deck <italic toggle="yes">i</italic>, payoffs were computed according to <xref rid="eqn1" ref-type="disp-formula" hwp:id="xref-disp-formula-1-2" hwp:rel-id="disp-formula-1">Equation 1</xref>
<disp-formula id="eqn1" hwp:id="disp-formula-1" hwp:rev-id="xref-disp-formula-1-1 xref-disp-formula-1-2">
<alternatives hwp:id="alternatives-1"><graphic xlink:href="033662_eqn1.gif" position="float" orientation="portrait" hwp:id="graphic-4"/></alternatives>
</disp-formula>
The initial values of the payoff probabilities, <italic toggle="yes">π</italic><sub><italic toggle="yes">i</italic>,0</sub>, were set to 60%, 30% and 10%, assigned pseudorandomly without replacement to each deck. The value of the stickiness parameter λ was 0.6, the drift target <italic toggle="yes">θ<sub>i</sub></italic> was set to the initial payoff for each deck, and the diffusion noise <italic toggle="yes">ν</italic> was zero-mean Gaussian with standard deviation <italic toggle="yes">σ<sub>d</sub></italic>=8. For the first three trials of each room, the stickiness parameter was temporarily set to 0.95, to ensure that outcomes affirmed to the participants that the preceding payoff probabilities carried through to the new room – in other words, that the decks remained the same, despite changing rooms. Between the tenth and eleventh trial in each room, the targets <italic toggle="yes">θ<sub>i</sub></italic> of each payoff timeseries were shuffled such that the deck that previously had the highest payout would no longer have the highest payout. Critically, memory probe images were chosen exclusively from the first ten trials of each room. In the seventh room, the payoffs continued drifting as above, with drift targets continuing to swap every thirty trials.</p></sec><sec id="s7b3" hwp:id="sec-19"><title hwp:id="title-25">Phase 2: recognition probes</title><p hwp:id="p-53">In the seventh room (the <italic toggle="yes">Probes</italic> phase) the series of choices was interrupted at pseudorandom intervals by 60 recognition memory probes (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-10" hwp:rel-id="F1">Figure 1b</xref>). Participants were questioned on their memory for an object photograph. Fifty of the probed photographs had been previously presented on a choice trial during Phase 1; the remaining 10 were novel lures. The probe images were chosen from the first ten trials of the context rooms, because these trials had different payoff values than did the other 20 trials in each room. This feature allowed us to distinguish the influence of memories for the reminded trial from the influence of the reminded context. Participants were instructed to press keys indicating their memory and their confidence level: “1” (indicating highly confident that it was an image they had seen before) through “4” (indicating highly confident that this was an image they had not seen before). For MRI experiment 2, buttons were numbered left to right for the fingers on the right hand, from index finger “1” to pinky finger “4”.</p><p hwp:id="p-54">Correct responses – “1” or “2” for previously seen images, or “3” or “4” for images that were not displayed on a previous trial – were rewarded with $0.25 added to the participant’s total payout. This additional reward was indicated by a photograph of a US quarter with a green ‘+’ to the left. Incorrect responses resulted in $0.25 being deducted from the participant’s total payout, indicated by a red ‘-’ to the left of an image of a US quarter. Memory probe rewards were displayed for two seconds.</p><p hwp:id="p-55">Rewards for memory probes accumulated over the course of the entire task, rather than for randomly selected rounds – so the total payout could be reduced or increased by as much as $15.00. Probe images remained on the screen for up to three seconds – if no answer was entered in that time, the trial was scored as incorrect.</p></sec><sec id="s7b4" hwp:id="sec-20"><title hwp:id="title-26">Phase 3: Source recognition test</title><p hwp:id="p-56">Before the experiment began, participants were instructed to remember as many of the object pictures as possible, along with their associated rooms. Their memory for these pairings was tested in 50 post-task source recognition probes. Post-task memory probes were drawn from the set of pictures shown during Phase 1 that were also tested in Phase 2 recognition memory probes. Participants were presented with an object picture and candidate rooms (all six in Experiment 1, but only three in Experiment 2 to restrict responses to the one-handed button box used in fMRI), and asked to select the room in which they first saw the object photograph. Each incorrect answer reduced the number of $10 rewards in their pile. The final payout was then determined as the sum of two pseudorandomly selected choice trials, drawn from the set of trials that remained after removing $10 rewards according to the results of the post-task source recognition test.</p></sec><sec id="s7b5" hwp:id="sec-21"><title hwp:id="title-27">Phase 4: Localizer</title><p hwp:id="p-57">To allow us to localize regions of cortex preferentially active during processing of scene images, participants performed a 1-back image repeat detection task. During this localizer task, images were presented in mini-blocks of 10 images. Stimuli in each mini-block were chosen from a large stimulus set of pictures not used in the main experiment, belonging to one of three categories – objects, scenes or phase-scrambled scenes. Images were each presented for 500ms and separated by a 1.3s ISI. Eight of the images in each block were trial-unique, and two were repeats. Repeats were inserted pseudorandomly, according to a uniform distribution. A total of 30 mini-blocks were presented (10 per each category), with each mini-block separated by a 12 second inter-block interval.</p></sec></sec><sec id="s7c" hwp:id="sec-22"><title hwp:id="title-28">Imaging methods</title><p hwp:id="p-58">Data were acquired using a 3T Siemens Skyra scanner with a 20-channel volume head coil. We collected two functional runs with a T2*-weighted gradient-echo echo-planar sequence (37 oblique axial slices, 3mm isotropic resolution, echo time 27.0 ms; TR 2080 ms; flip angle 64; field of view 192 mm). The first four volumes of each functional run (8.32s) were discarded to allow for T1 equilibration effects. We also collected a high-resolution 3D T1-weighted MPRAGE sequence for registration across participants to standard space. Functional image preprocessing was performed using FSL (FMRIB Software Library version 5.0.4; [<xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">18</xref>]). Anatomical images were coregistered to the standard MNI152 template image, then individual participant functional images were coregistered to the realigned anatomical images. The transformation matrices generated during this coregistration process were used to transform Region of Interest (ROI) images (described below, ROI definition). Functional images were motion corrected and spatially smoothed using a 5mm full-width half-maximum Gaussian kernel prior to analysis. Data were scaled to their global mean intensity and high-pass filtered with a cutoff period of 128s. Pattern analyses were performed using the Princeton Multi-Voxel Pattern Analysis Toolbox (MVPA Toolbox; <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.pni.princeton.edu/mvpa" ext-link-type="uri" xlink:href="http://www.pni.princeton.edu/mvpa" hwp:id="ext-link-8">http://www.pni.princeton.edu/mvpa</ext-link>) and custom code implemented in MATLAB.</p></sec><sec id="s7d" hwp:id="sec-23"><title hwp:id="title-29">Behavioral analysis</title><sec id="s7d1" hwp:id="sec-24"><title hwp:id="title-30">Regression analysis</title><p hwp:id="p-59">To examine the influence of past trials on choice in Phase 2, we conducted a regression analysis relating the outcomes of past choices to the choice made on the current trial. This regression included outcomes both from choice trials where rewards were directly experienced, and from trials evoked by memory probes.</p><p hwp:id="p-60">We constructed the following design matrix three times, once with each deck – red, green, and blue – as the given deck of interest. We first entered into the regression the <italic toggle="yes">identity</italic> of the deck chosen on the previous trial: 1 for the given deck, 0 for others. Next, we entered variables describing the directly received rewards. If a reward was received after choosing the given deck on trial <italic toggle="yes">t</italic> − <italic toggle="yes">τ</italic>, this was coded as a 1 in regressor <italic toggle="yes">τ</italic>, element <italic toggle="yes">t</italic>. If no reward was received after choosing the given deck, this was coded as a 0.</p><p hwp:id="p-61">Next, we included two variables coding aspects of the reminded trial (i.e., the trial cued by the memory probe, if there was a memory probe on the preceding trial). The first regressor coded the evoked identity of the deck chosen on the reminded trial (again, 1 for the given deck, 0 for others), and the following regressor coded for the evoked reward received on the reminded trial.</p></sec><sec id="s7d2" hwp:id="sec-25"><title hwp:id="title-31">Context reward</title><p hwp:id="p-62">The final regressor coded for the <italic toggle="yes">context reward</italic>, the net reward actually experienced for choosing the given deck within the evoked context. As discussed in the <italic toggle="yes">Results</italic>, we designed this regressor to capture the average effect of sampling memories from the probed context.</p><p hwp:id="p-63">For each deck, this value was calculated as the number of trials on which the option was chosen and rewarded, minus the number of trials on which the option was chosen and not rewarded, divided by the total number of trials on which the option was chosen. Explicitly, for deck <italic toggle="yes">i</italic> in context <italic toggle="yes">C</italic>, this value is:
<disp-formula id="eqn2" hwp:id="disp-formula-2" hwp:rev-id="xref-disp-formula-2-1 xref-disp-formula-2-2 xref-disp-formula-2-3">
<alternatives hwp:id="alternatives-2"><graphic xlink:href="033662_eqn2.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives>
</disp-formula>
If a deck was not chosen in the evoked context, <italic toggle="yes">EC<sup>C,i</sup></italic> was set to zero. If the preceding trial was not a memory probe, the evoked identity, evoked reward, and were all set to zero. In the dependent variable, choices were coded as 1 if the given deck was chosen and 0 otherwise.</p><p hwp:id="p-64">The regression was thus in the following form:
<disp-formula id="eqn3" hwp:id="disp-formula-3">
<alternatives hwp:id="alternatives-3"><graphic xlink:href="033662_eqn3.gif" position="float" orientation="portrait" hwp:id="graphic-6"/></alternatives>
</disp-formula>
where <italic toggle="yes">C</italic><sub><italic toggle="yes">i,t</italic></sub> specifies whether deck <italic toggle="yes">i</italic> was chosen at trial <italic toggle="yes">t</italic>, <italic toggle="yes">DI</italic> is ‘directly experienced identity’, <italic toggle="yes">DR</italic> is ‘directly experienced reward’, <italic toggle="yes">EI</italic> is ‘evoked identity’, and <italic toggle="yes">ER</italic> is ‘evoked reward’ for each trial preceding the current choice, and also for the given deck <italic toggle="yes">i</italic>. Following the patterns observed in our previous study [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-11" hwp:rel-id="ref-2">2</xref>], effects of memory and the identity of the previous deck are specified for the previous trial, while direct reward receipt is specified for the preceding three trials.</p><p hwp:id="p-65">In total, there were eight columns in the design matrix – the seven predictor variables just described, plus the constant term, and 360 rows – one for each of the 120 Test-phase choices, each specified three times coded for the three decks of interest. The resulting regression weights – indicating the degree to which the current choice was influenced by choices and rewards on a given evoked or directly experienced trial or context – were treated as random effects and tested against zero across the population by two-tailed <italic toggle="yes">t</italic>-test. See <xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-1" hwp:rel-id="T1">Table 1</xref> for a concrete illustration of how the design matrix was constructed.</p><table-wrap id="tbl1" orientation="portrait" position="float" hwp:id="T1" hwp:rev-id="xref-table-wrap-1-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;033662v5/TBL1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">tbl1</object-id><label>Table 1:</label><caption hwp:id="caption-4"><title hwp:id="title-32">Example regression design matrix.</title><p hwp:id="p-66">This table depicts the rows of the design matrix that code for the fourth trial, given the following scenario: Red was selected on the three preceding choice trials, the first two of which resulted in rewards; after the third Red trial, a memory probe was presented that evoked a trial on which Blue was chosen, in a context in which Blue was chosen on 12 trials and rewarded on 7, and Green was chosen on 18 trials and rewarded on 13. The regression design contained three rows for each trial, each reflecting the contribution of the independent variables to the probability of picking a given deck (Red, Green, or Blue). The independent variables code for the presence of choice-relevant information on recent trials. For instance, the first column (<italic toggle="yes">DI<sub>-1</sub></italic>) indicates whether the deck of interest was selected on the most recent choice trial. The second column (<italic toggle="yes">DR<sub>-1</sub></italic>) indicates whether the deck of interest was associated with reward on the most recent choice trial. The third and fourth (<italic toggle="yes">DR<sub>-2</sub>, DR<sub>-3</sub></italic>) columns indicate whether the deck of interest was associated with reward on the preceding two choice trials. If the most recent trial before the current choice was a memory probe, the fifth through seventh columns contain indicators of the choice and value information on the trial evoked by the probed image: respectively, the identity of the deck chosen on the reminded trial (<italic toggle="yes">EI<sub>-1</sub></italic>), whether or not that choice resulted in reward (<italic toggle="yes">ER<sub>-1</sub></italic>), and the reward received for choosing the given deck across the room in which the reminded trial took place (<italic toggle="yes">EC<sub>-1</sub></italic>) (<xref rid="eqn2" ref-type="disp-formula" hwp:id="xref-disp-formula-2-2" hwp:rel-id="disp-formula-2">Equation 2</xref>). The dependent variable predicted by the regression was a 1 or 0 coding for whether the deck of interest was selected on the current trial (trial 4 in this example). The resulting regression coefficients reflect the contribution of each variable to the probability of choosing as the participant did.</p></caption><graphic xlink:href="033662_tbl1" position="float" orientation="portrait" hwp:id="graphic-7"/></table-wrap></sec><sec id="s7d3" hwp:id="sec-26"><title hwp:id="title-33">Reinstatement-scaled context reward</title><p hwp:id="p-67">We also ran the regression analysis using a version of the context reward regressor that was augmented with neuroimaging evidence for reinstatement of each specific scene context (for details on the neuroimaging evidence calculation, see <italic toggle="yes">Specific-scene patterns</italic>, below).</p><p hwp:id="p-68">In this analysis, the <italic toggle="yes">EC</italic> regressor (<xref rid="eqn2" ref-type="disp-formula" hwp:id="xref-disp-formula-2-3" hwp:rel-id="disp-formula-2">Equation 2</xref>) was recomputed six times at each choice following a memory probe, once for each of the context rooms, producing <italic toggle="yes">EC<sup>C,k</sup></italic>. In other words, the regressor was computed as though the probe had reminded the participant of each room.</p><p hwp:id="p-69">We next incorporated the scene-specific reinstatement measure into our regression. First, we turned the correlation values at each trial into a distribution of weights across the six possible contexts. We did this by adding 1 (to account for negative correlations) to the correlation values, and then dividing the resulting values by the sum across all correlations. This resulted in a real number, between zero and one, indicating the relative degree of match between activity at probe and the template for each context.</p><p hwp:id="p-70">The six context reward values, <italic toggle="yes">EC<sup>C,k</sup></italic>, were each multiplied by our estimated probability that the participant was reinstating the given context <italic toggle="yes">C</italic><sup><italic toggle="yes">k</italic></sup>. The sum of the six probability-weighted context rewards was then entered into the regression in place of (or, in the second analysis, alongside) the original <italic toggle="yes">EC</italic> regressor.</p></sec><sec id="s7d4" hwp:id="sec-27"><title hwp:id="title-34">Context-aware sampling model</title><p hwp:id="p-71">To investigate how single-trial and context reward trade off with each other as the number of past episodes sampled increases, we simulated the task as performed by a context-aware episodic sampling model. In this simulation, all choices are made using episodic sampling alone (no influence of model-free values), to clearly isolate the influence of changing the number of samples. In episodic sampling, option values are estimated using the values encountered on one or more past episodes, with the likelihood of sampling a given episode diminishing exponentially with its recency. The context-aware episodic sampling model augments this idea, by positing that additional samples after the first are (with some probability) selected uniformly from the same context as the preceding sample.</p><p hwp:id="p-72">The model maintains a cache of episodes representing each experienced trial. When subjects respond correctly to a valid memory probes, the model with some probability “reinstates” the episode by copying the reminded trial to the front of the cache–thus, making it more likely to be drawn when evaluating options during the next choice. If the subject’s correct response to the memory probe is of high confidence, then the context of the probed trial is included in the episode copied to the front of the cache.</p><p hwp:id="p-73">We used this model to simulate subjects who used different numbers of samples from episodic memory to make decisions. The model had four parameters which were fixed across all simulations: <italic toggle="yes">α<sub>direct</sub></italic>, or the decay rate on temporal recency; <italic toggle="yes">α<sub>evoked</sub></italic>, or the probability of reinstating evoked trials because of memory probes; <italic toggle="yes">β</italic>, the softmax temperature; <italic toggle="yes">β<sub>p</sub></italic>, the choice perseveration term; and <italic toggle="yes">π</italic>, the likelihood of drawing sample <italic toggle="yes">k</italic> from the same context as sample <italic toggle="yes">k</italic>-1 (as opposed to based on temporal recency).</p><p hwp:id="p-74">A final parameter, the number of samples drawn, was varied between 1 and 15. For each fixed number of samples, we simulated 1,600 subjects (50 groups of 32) each performing an instantiation of the task. The simulated subject’s parameters <italic toggle="yes">α<sub>direct</sub></italic>, <italic toggle="yes">β</italic>, and <italic toggle="yes">β<sub>p</sub></italic>, were set to those fit to the real subjects with the number of samples equal to 1, and <italic toggle="yes">π</italic> was set to 1.</p><p hwp:id="p-75">For simplicity, in the first simulation <italic toggle="yes">α<sub>evoked</sub></italic> was set to 1. This assumption was relaxed for our second set of simulations, during which we varied <italic toggle="yes">α<sub>evoked</sub></italic> between 0 and 1 to illustrate the impact of changing this parameter. The simulated subjects were programmed to make, on average, the same proportion of low confidence and incorrect responses as did the subjects from Experiments 1 and 2.</p></sec><sec id="s7d5" hwp:id="sec-28"><title hwp:id="title-35">Incremental learning models</title><p hwp:id="p-76">To compare our context reward model to the others, we generated the timeseries of reinstated context reward values that would be learned according to three different specifications of model-free RL.</p><p hwp:id="p-77">The first variant followed the traditional method, learning the value of each card deck without regard to changes in room context. Specifically, at each step, the value for the chosen card deck, <italic toggle="yes">Q<sub>B</sub></italic>, was updated according to the reward received on that trial, <italic toggle="yes">R<sub>t</sub></italic>, and the learning rate <italic toggle="yes">α</italic>:
<disp-formula id="eqn4" hwp:id="disp-formula-4">
<alternatives hwp:id="alternatives-4"><graphic xlink:href="033662_eqn4.gif" position="float" orientation="portrait" hwp:id="graphic-8"/></alternatives>
</disp-formula>
We refer to this as the <italic toggle="yes">standard</italic> model. The second variant reset the value of each card deck when the room changed, giving separate values <italic toggle="yes">Q<sub>B,C</sub></italic> for each room-context, following <xref rid="eqn5" ref-type="disp-formula" hwp:id="xref-disp-formula-5-1" hwp:rel-id="disp-formula-5">Equation 5</xref>.
<disp-formula id="eqn5" hwp:id="disp-formula-5" hwp:rev-id="xref-disp-formula-5-1">
<alternatives hwp:id="alternatives-5"><graphic xlink:href="033662_eqn5.gif" position="float" orientation="portrait" hwp:id="graphic-9"/></alternatives>
</disp-formula>
We refer to this as the <italic toggle="yes">room-reset</italic> model. A third variant also reset action values, but this time it did so at a variable trial number within each room (e.g. 1, 2, 3, or more trials after room change). We designed this model to account for the possibility that participants took note of payoff reversals and discounted information prior to the switch [<xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">22</xref>]. We refer to this model as the <italic toggle="yes">reversal</italic> model.</p><p hwp:id="p-78">The three incremental learning models were fit to choices in rooms one through six, using maximum likelihood estimation of parameters. To compare the model likelihoods, we first transformed them using the Bayesian Information Criterion (BIC; [<xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">23</xref>]), which penalized the third model for its additional parameter.</p><p hwp:id="p-79">The best-fitting model was used to generate a replacement for the context-reward regressor as specified in <italic toggle="yes">Regression analysis</italic>. The resulting regression model weights were compared to the original (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-5" hwp:rel-id="F2">Figure 2</xref>).</p></sec></sec><sec id="s7e" hwp:id="sec-29"><title hwp:id="title-36">Imaging analysis</title><p hwp:id="p-80">To identify neural markers of context reinstatement, we first defined, using MVPA [<xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">19</xref>], the pattern of BOLD activity in posterior parahippocampal cortex that indicated participants were processing “scene” images. We then looked for evidence that this pattern was reinstated following probe trials. We reasoned that greater evidence of scene reinstatement would indicate that participants were recalling the context of the probed image (note that no scene images were present during Phase 2), and thus would show an increased influence of other trials from this context on their decision-making.</p><p hwp:id="p-81">ROI definition. We identified a region of interest consisting of voxels that (across the group) showed preferential activation to scene images, using the following procedure. First, for each participant, we performed a GLM analysis of the localizer phase data, and identified voxels selectively responding to scenes versus other categories (univariate contrast, scenes &gt; scrambled_scenes|objects). For each participant, we selected clusters in the posterior parahippocampal region (matching the reported Parahippocampal Place Area (PPA); [<xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">20</xref>]) that were significant at <italic toggle="yes">P</italic>&lt;0.005, uncorrected. Next, each per-participant voxel mask was binarized; all above-threshold voxels were set to 1. This mask was warped to match the group average anatomical so that each participant’s mask could be aligned and the collection averaged. The resulting group-space masks were added together and the summed image thresholded to include all voxels present in more than 90% of participants. This final group ROI was then warped back to the individual participant space, and the result used as a mask for pattern classifier analyses.</p><p hwp:id="p-82">To permit various control analyses, we followed a parallel procedure to identify a region of interest that preferentially responded to the scrambled scenes used in our localizer task. For this ROI, rather than selecting clusters within an anatomical area of interest, we simply used the contrast mask from across the entire brain.</p><sec id="s7e1" hwp:id="sec-30"><title hwp:id="title-37">Category-level pattern classification</title><p hwp:id="p-83">We trained a classifier to identify patterns of activity indicative of participants processing pictures of scenes. We first extracted, across the localizer task, activity of all of the voxels in the above-defined scene-responsive ROI. These labeled data were used to train an L2-regularized multinomial logistic regression classifier to predict scene versus scrambled scene labels. The regularization parameter was set to 0.1, but the results were insensitive to varying this parameter by several orders of magnitude in either direction.</p><p hwp:id="p-84">The trained classifier was then applied to activity after each probe trial. For each TR of interest, at each probe trial, the classifier provided a measure of the probability that participants were processing scenes; we refer to this real-valued number as scene evidence. We first selected as TRs of interest those timepoints after each probe that reflected peak selectivity to scenes. Because no scenes were on the screen during or after the probes, we treated elevated scene evidence as indicating that participants recollecting contextual information (background scenes) from Phase 1. We compared scene evidence in different conditions and at different time points using paired-sample t-tests; all tests were two-tailed.</p><p hwp:id="p-85">Our final analysis involves splitting probe trials into four bins by the amount of classifier evidence for scenes on our selected timepoints of interest. These bins may have different variance within them, which could potentially confound the subsequent regression analysis we perform using these evidence quantities. Therefore, to evaluate the relative contribution of classifier evidence in different quartiles to explaining the context reward effect, we report standardized regression coefficients (Schroeder et al. [<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">21</xref>]; <xref rid="eqn6" ref-type="disp-formula" hwp:id="xref-disp-formula-6-1" hwp:rel-id="disp-formula-6">Equation 6</xref>) that scale the regression weights by the relative variance of the evidence timeseries in quartile <italic toggle="yes">i</italic> as a proportion of the variance of the context reward in that quartile:
<disp-formula id="eqn6" hwp:id="disp-formula-6" hwp:rev-id="xref-disp-formula-6-1">
<alternatives hwp:id="alternatives-6"><graphic xlink:href="033662_eqn6.gif" position="float" orientation="portrait" hwp:id="graphic-10"/></alternatives>
</disp-formula></p></sec><sec id="s7e2" hwp:id="sec-31"><title hwp:id="title-38">Specific-scene patterns</title><p hwp:id="p-86">We evaluated whether memory probes caused participants to reinstate the specific context, rather than just a general measure of scene reinstatement, and whether measurements of the contexts that were actually reinstated could improve our predictions of behavior. For each participant, and for each context room, we produced a template pattern of PPA activity in that room, by averaging activity in each PPA voxel across all 30 choice trials. We then computed, at each probe trial that evoked a past decision, the average pattern in PPA across our timepoints of interest (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-6" hwp:rel-id="F3">Figure 3b</xref>). Next, we computed the fisher-transformed correlations between these trial patterns and each template. These values were then entered into the multiple regression analysis, as described in the section Reinstatement-scaled context reward, above.</p></sec></sec></sec><sec id="s8" hwp:id="sec-32"><title hwp:id="title-39">Statistics</title><p hwp:id="p-87">A within-subject design was used. Thus, experimental group randomization or blinding was not applicable. To examine the effect of recent and reminded rewards on choices, and parameters across model fits, we performed a multiple regression separately for each subject, and tested the resulting population of beta weights against zero, using one-sample <italic toggle="yes">t</italic>-tests. We compared beta weights within experiments using paired two-sample <italic toggle="yes">t-</italic>tests. We used unpaired, two-sample <italic toggle="yes">t</italic>-tests to compare beta weights across experiments. All <italic toggle="yes">t</italic>-tests were two-tailed, except for the localizer contrast, which used the standard SPM one-sample tests. Data distribution was assumed to be normal, but this was not formally tested before analysis. No statistical methods were used to pre-determine sample sizes. Sample size (20) in Experiment 1 was based on a previous experiment using a similar task [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-12" hwp:rel-id="ref-2">2</xref>]. For Experiment 2, sample size (32) was based on our current standard lab practice for fMRI sample stopping criterion, as well as referenced to the sample size in a previous fMRI study performed in our lab (14) that also used classifier evidence of scenes as a signature of context reinstatement [<xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-2" hwp:rel-id="ref-7">7</xref>], which here was more than doubled to account for the finer degree of distinction required for these analyses. Incremental learning models were compared on the basis of their likelihoods (summed log choice probabilities), using BIC [<xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-2" hwp:rel-id="ref-23">23</xref>] to penalize the third model for its additional parameter.</p></sec><ref-list hwp:id="ref-list-2"><title hwp:id="title-40">Methods-only References</title><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><label>[17]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Brainard David H."><given-names>David H.</given-names> <surname>Brainard</surname></string-name>. <article-title hwp:id="article-title-16">The Psychophysics Toolbox</article-title>. <source hwp:id="source-17">Spatial Vision</source>, <volume>10</volume>(<issue>4</issue>):<fpage>433</fpage>–<lpage>6</lpage>, Jan <year>1997</year>. ISSN <pub-id pub-id-type="issn">0169-1015</pub-id>. URL <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.ncbi.nlm.nih.gov/pubmed/9176952" ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/9176952" hwp:id="ext-link-9">http://www.ncbi.nlm.nih.gov/pubmed/9176952</ext-link>.</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1"><label>[18]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Smith Stephen M."><given-names>Stephen M.</given-names> <surname>Smith</surname></string-name>, <string-name name-style="western" hwp:sortable="Jenkinson Mark"><given-names>Mark</given-names> <surname>Jenkinson</surname></string-name>, <string-name name-style="western" hwp:sortable="Woolrich Mark W."><given-names>Mark W.</given-names> <surname>Woolrich</surname></string-name>, <string-name name-style="western" hwp:sortable="Beckmann Christian F."><given-names>Christian F.</given-names> <surname>Beckmann</surname></string-name>, <string-name name-style="western" hwp:sortable="Behrens Timothy E J"><given-names>Timothy E J</given-names> <surname>Behrens</surname></string-name>, <string-name name-style="western" hwp:sortable="Johansen-Berg Heidi"><given-names>Heidi</given-names> <surname>Johansen-Berg</surname></string-name>, <string-name name-style="western" hwp:sortable="Bannister Peter R."><given-names>Peter R.</given-names> <surname>Bannister</surname></string-name>, <string-name name-style="western" hwp:sortable="De Luca Marilena"><given-names>Marilena</given-names> <surname>De Luca</surname></string-name>, <string-name name-style="western" hwp:sortable="Drobnjak Ivana"><given-names>Ivana</given-names> <surname>Drobnjak</surname></string-name>, <string-name name-style="western" hwp:sortable="Flitney David E."><given-names>David E.</given-names> <surname>Flitney</surname></string-name>, <string-name name-style="western" hwp:sortable="Niazy Rami K."><given-names>Rami K.</given-names> <surname>Niazy</surname></string-name>, <string-name name-style="western" hwp:sortable="Saunders James"><given-names>James</given-names> <surname>Saunders</surname></string-name>, <string-name name-style="western" hwp:sortable="Vickers John"><given-names>John</given-names> <surname>Vickers</surname></string-name>, <string-name name-style="western" hwp:sortable="Zhang Yongyue"><given-names>Yongyue</given-names> <surname>Zhang</surname></string-name>, <string-name name-style="western" hwp:sortable="De Stefano Nicola"><given-names>Nicola</given-names> <surname>De Stefano</surname></string-name>, <string-name name-style="western" hwp:sortable="Brady J. Michael"><given-names>J. Michael</given-names> <surname>Brady</surname></string-name>, and <string-name name-style="western" hwp:sortable="Matthews Paul M."><given-names>Paul M.</given-names> <surname>Matthews</surname></string-name>. <article-title hwp:id="article-title-17">Advances in functional and structural MR image analysis and implementation as FSL</article-title>. <source hwp:id="source-18">NeuroImage</source>, <volume>23</volume> (<issue>SUPPL. 1</issue>):<fpage>208</fpage>–<lpage>219</lpage>, <year>2004</year>. ISSN <pub-id pub-id-type="issn">10538119</pub-id>. doi: <pub-id pub-id-type="doi">10.1016/j.neuroimage.2004.07.051</pub-id>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><label>[19]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Norman Kenneth A."><given-names>Kenneth A.</given-names> <surname>Norman</surname></string-name>, <string-name name-style="western" hwp:sortable="Polyn Sean M."><given-names>Sean M.</given-names> <surname>Polyn</surname></string-name>, <string-name name-style="western" hwp:sortable="Detre Greg J."><given-names>Greg J.</given-names> <surname>Detre</surname></string-name>, and <string-name name-style="western" hwp:sortable="Haxby James V."><given-names>James V.</given-names> <surname>Haxby</surname></string-name>. <article-title hwp:id="article-title-18">Beyond mind-reading: multi-voxel pattern analysis of fMRI data</article-title>. <source hwp:id="source-19">Trends in Cognitive Sciences</source>, <volume>10</volume>(<issue>9</issue>):<fpage>424</fpage>–<lpage>430</lpage>, <year>2006</year>. ISSN <pub-id pub-id-type="issn">13646613</pub-id>. doi: <pub-id pub-id-type="doi">10.1016/j.tics.2006.07.005</pub-id>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><label>[20]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Epstein R"><given-names>R</given-names> <surname>Epstein</surname></string-name> and <string-name name-style="western" hwp:sortable="Kanwisher N"><given-names>N</given-names> <surname>Kanwisher</surname></string-name>. <article-title hwp:id="article-title-19">A cortical representation of the local visual environment</article-title>. <source hwp:id="source-20">Nature</source>, <volume>392</volume>(<issue>6676</issue>):<fpage>598</fpage>–<lpage>601</lpage>, Apr <year>1998</year>. ISSN <pub-id pub-id-type="issn">0028-0836</pub-id>. doi: <pub-id pub-id-type="doi">10.1038/33402</pub-id>. URL <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.ncbi.nlm.nih.gov/pubmed/9560155" ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/9560155" hwp:id="ext-link-10">http://www.ncbi.nlm.nih.gov/pubmed/9560155</ext-link>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1"><label>[21]</label><citation publication-type="book" citation-type="book" ref:id="033662v5.21" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Schroeder L. D."><given-names>L. D.</given-names> <surname>Schroeder</surname></string-name>, <string-name name-style="western" hwp:sortable="Sjoquist D. L."><given-names>D. L.</given-names> <surname>Sjoquist</surname></string-name>, and <string-name name-style="western" hwp:sortable="Stephan P. E."><given-names>P. E.</given-names> <surname>Stephan</surname></string-name>. <source hwp:id="source-21">Understanding regression analysis: An introductory guide</source>. <publisher-name>Sage</publisher-name>, <publisher-loc>Beverly Hills, CA</publisher-loc>, <year>1986</year>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><label>[22]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Behrens Timothy E. J."><given-names>Timothy E. J.</given-names> <surname>Behrens</surname></string-name>, <string-name name-style="western" hwp:sortable="Woolrich Mark W."><given-names>Mark W.</given-names> <surname>Woolrich</surname></string-name>, <string-name name-style="western" hwp:sortable="Walton Mark E."><given-names>Mark E.</given-names> <surname>Walton</surname></string-name>, and <string-name name-style="western" hwp:sortable="Rushworth Matthew F S"><given-names>Matthew F S</given-names> <surname>Rushworth</surname></string-name>. <article-title hwp:id="article-title-20">Learning the value of information in an uncertain world</article-title>. <source hwp:id="source-22">Nature Neuroscience</source>, <volume>10</volume>(<issue>9</issue>):<fpage>1214</fpage>–<lpage>21</lpage>, Sep <year>2007</year>. ISSN <pub-id pub-id-type="issn">1097-6256</pub-id>. doi: <pub-id pub-id-type="doi">10.1038/nn1954</pub-id>. URL <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.ncbi.nlm.nih.gov/pubmed/17676057" ext-link-type="uri" xlink:href="http://www.ncbi.nlm.nih.gov/pubmed/17676057" hwp:id="ext-link-11">http://www.ncbi.nlm.nih.gov/pubmed/17676057</ext-link>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1 xref-ref-23-2"><label>[23]</label><citation publication-type="journal" citation-type="journal" ref:id="033662v5.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Schwarz Gideon"><given-names>Gideon</given-names> <surname>Schwarz</surname></string-name>. <article-title hwp:id="article-title-21">Estimating the Dimension of a Model</article-title>. <source hwp:id="source-23">Annals of Statistics</source>, <volume>6</volume>(<issue>2</issue>):<fpage>461</fpage>–<lpage>464</lpage>, <year>1978</year>.</citation></ref></ref-list></back></article>
