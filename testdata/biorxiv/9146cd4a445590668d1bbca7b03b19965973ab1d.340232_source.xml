<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/340232</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;340232</article-id><article-id pub-id-type="other" hwp:sub-type="slug">340232</article-id><article-id pub-id-type="other" hwp:sub-type="atom-slug">340232</article-id><article-id pub-id-type="other" hwp:sub-type="tag">340232</article-id><article-version>1.2</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Animal Behavior and Cognition" hwp:journal="biorxiv"><subject>Animal Behavior and Cognition</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">3D Reconstruction of Bird Flight Using a Single Video Camera</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1"><label>*</label>Corresponding author; email: <email hwp:id="email-1">m.srinivasan@uq.edu.au</email></corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" corresp="yes" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-2875-4985</contrib-id><name name-style="western" hwp:sortable="Srinivasan M.V."><surname>Srinivasan</surname><given-names>M.V.</given-names></name><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-2875-4985"/></contrib><contrib contrib-type="author" hwp:id="contrib-2"><name name-style="western" hwp:sortable="Vo H.D."><surname>Vo</surname><given-names>H.D.</given-names></name></contrib><contrib contrib-type="author" hwp:id="contrib-3"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0003-0044-1677</contrib-id><name name-style="western" hwp:sortable="Schiffner I."><surname>Schiffner</surname><given-names>I.</given-names></name><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0003-0044-1677"/></contrib><aff hwp:id="aff-1"><institution hwp:id="institution-1">Queensland Brain Institute, University of Queensland</institution>, QLD 4072, <country>Australia</country></aff></contrib-group><pub-date pub-type="epub-original" date-type="pub" publication-format="electronic" hwp:start="2021"><year>2021</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2018-06-06T16:14:49-07:00">
    <day>6</day><month>6</month><year>2018</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2021-04-27T07:45:21-07:00">
    <day>27</day><month>4</month><year>2021</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2018-06-06T16:20:17-07:00">
    <day>6</day><month>6</month><year>2018</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2021-04-27T07:50:08-07:00">
    <day>27</day><month>4</month><year>2021</year>
  </pub-date><elocation-id>340232</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2018-06-06"><day>06</day><month>6</month><year>2018</year></date>
<date date-type="rev-recd" hwp:start="2021-04-25"><day>25</day><month>4</month><year>2021</year></date>
<date date-type="accepted" hwp:start="2021-04-27"><day>27</day><month>4</month><year>2021</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2021</copyright-year><license hwp:id="license-1"><p hwp:id="p-1">The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.</p></license></permissions><self-uri xlink:href="340232.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/change-list" xlink:role="change-list" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/external-links" xlink:role="external-links" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2021/pdf/340232v2.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="340232.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2021/abstracts/340232v2/340232v2.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2021/fulltext/340232v2/340232v2.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">ABSTRACT</title><p hwp:id="p-2">Video cameras are finding increasing use in the study and analysis of bird flight over short ranges. However, reconstruction of flight trajectories in three dimensions typically requires the use of multiple cameras and elaborate calibration procedures. We present an alternative approach that uses a single video camera and a simple calibration procedure for the reconstruction of such trajectories. The technique combines prior knowledge of the wingspan of the bird with a camera calibration procedure that needs to be used only once in the lifetime of the system. The system delivers the exact 3D coordinates of the bird, and its roll angle, at the time of every full wing extension and uses interpolated height estimates to compute the 3D positions of the bird in the video frames between successive wing extensions. The system is inexpensive, compact and portable, and can be easily deployed in the laboratory as well as the field.</p></abstract><counts><page-count count="28"/></counts><custom-meta-wrap><custom-meta hwp:id="custom-meta-1"><meta-name>special-property</meta-name><meta-value>contains-inline-supplementary-material</meta-value></custom-meta></custom-meta-wrap><custom-meta-wrap>
    <custom-meta hwp:id="custom-meta-2">
      <meta-name>has-earlier-version</meta-name>
      <meta-value>yes</meta-value>
    </custom-meta>
  </custom-meta-wrap></article-meta><notes hwp:id="notes-1"><notes notes-type="competing-interest-statement" hwp:id="notes-2"><title hwp:id="title-2">Competing Interest Statement</title><p hwp:id="p-3">The authors have declared no competing interest.</p></notes><fn-group content-type="summary-of-updates" hwp:id="fn-group-1"><title hwp:id="title-3">Summary of Updates:</title><fn fn-type="update" hwp:id="fn-1"><p hwp:id="p-4">This revision extends the theory to account for the roll of the bird. The extended theory, which provides estimates of the 3D trajectory of the bird as well as its roll angle, is validated in a scaled-down arena using a model bird.</p></fn></fn-group><fn-group content-type="external-links" hwp:id="fn-group-2"><fn fn-type="dataset" hwp:id="fn-2"><p hwp:id="p-5">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://drive.google.com/file/d/1kKwyJ8IJtk3q7357YKiwodz-Ydlmya0M/view?usp=sharing" ext-link-type="uri" xlink:href="https://drive.google.com/file/d/1kKwyJ8IJtk3q7357YKiwodz-Ydlmya0M/view?usp=sharing" hwp:id="ext-link-1">https://drive.google.com/file/d/1kKwyJ8IJtk3q7357YKiwodz-Ydlmya0M/view?usp=sharing</ext-link>
</p></fn><fn fn-type="dataset" hwp:id="fn-3"><p hwp:id="p-6">
<ext-link l:rel="related" l:ref-type="uri" l:ref="https://drive.google.com/file/d/1n3FjqKH_oMk5Wfsb_xqQQS7zVJ9BhCkd/view?usp=sharing" ext-link-type="uri" xlink:href="https://drive.google.com/file/d/1n3FjqKH_oMk5Wfsb_xqQQS7zVJ9BhCkd/view?usp=sharing" hwp:id="ext-link-2">https://drive.google.com/file/d/1n3FjqKH_oMk5Wfsb_xqQQS7zVJ9BhCkd/view?usp=sharing</ext-link>
</p></fn></fn-group></notes></front><body><sec id="s1" hwp:id="sec-1"><label>1.</label><title hwp:id="title-4">I<sc>ntroduction</sc></title><p hwp:id="p-7">The increasing use of high-speed video cameras is offering new opportunities as well as challenges for tracking three-dimensional motions of humans and animals, and of their body parts (e.g. <xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">Shelton et al., 2014</xref>; <xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">Straw et al., 2011</xref>; <xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">Fontaine et al., 2009</xref>; <xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">Dakin et al., 2016</xref>); <xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">Ros et al., 2017</xref>; <xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">Troje, 2002</xref>; <xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">de Margerie et al., 2015</xref>; <xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">Jackson et al., 2016</xref>; <xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">Macfarlane et al., 2015</xref>; <xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">Deetjen et al., 2017</xref>).</p><p hwp:id="p-8">Stereo-based approaches that use two (or more) cameras are popular, however they require (a) synchronisation of the cameras (b) elaborate calibration procedures (e.g. <xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">Hedrick, 2008</xref>; <xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">Hartley and Zisserman, 2003</xref>; <xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">Theriault et al., 2014</xref>; <xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-2" hwp:rel-id="ref-12">Jackson et al., 2016</xref>) (b) collection of large amounts of data, particularly when using high frame rates; and (c) substantial post-processing that entails frame-by-frame tracking of individual features in all of the video sequences, and establishing the correct correspondences between these features across the video sequences (e.g. <xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">Cavagna et al., 2008</xref>). This is particularly complicated when tracking highly deformable objects, such as flying birds.</p><p hwp:id="p-9">Vicon-based stereo trackers simplify the problem of feature tracking by using special reflective markers or photodiodes attached to the tracked (e.g. <xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-2" hwp:rel-id="ref-14">Ros et al., 2017</xref>; <xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">Goller and Altshuler, 2014</xref>; <xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">Tobalske et al., 2007</xref>; <xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-2" hwp:rel-id="ref-23">Troje, 2002</xref>). However, these markers can potentially disturb natural movement and behaviour, especially when used on small animals.</p><p hwp:id="p-10">A novel recent approach uses structured light illumination produced by a laser system in combination a high-speed video camera to reconstruct the wing kinematics of a freely flying parrotlet at 3200 frames/second (<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">Deetjen et al., 2017</xref>). However, this impressive capability comes at the cost of some complexity, and works best if the bird possesses a highly reflective plumage of a single colour (preferably white).</p><p hwp:id="p-11">GPS-based tracking methods (e.g. <xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">Bouten et al., 2013</xref>) are useful for mapping long-range flights of birds, for example, but are not feasible in indoor laboratory settings, where GPS signals are typically unavailable or do not provide sufficiently accurate positioning. Furthermore, they require the animal to carry a GPS receiver, which can affect the flight of a small animal.</p><p hwp:id="p-12">A simple technique for reconstructing 3D flight trajectories of insects from a single overhead video camera involves tracking the position of the insect as well as the shadow that it casts on the ground (e.g. <xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">Zeil, 1993</xref>; <xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">Srinivasan et al., 2000</xref>). However, this technique requires the presence of the unobscured sun in the sky, or a strong artificial indoor light, which in itself could affect the animal’s behaviour. (The latter problem could be overcome, in principle, by using an infrared source of light and an infrared-sensitive camera).</p><p hwp:id="p-13">This paper presents a simple, inexpensive, compact, field-deployable technique for reconstructing the flight trajectories of birds in 3D, using a single video camera. The procedure for calibrating the camera is uncomplicated, and is an exercise that needs to be carried out only once in the lifetime of the lens/camera combination, irrespective of where the system is used in subsequent applications.</p><p hwp:id="p-14">The system was used in a study of bird flight (<xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">Vo et al., 2016</xref>) but that paper provided only a cursory description of the technique. This paper provides a comprehensive description of the underlying technique and procedure, which will enable it to be used in other laboratories and field studies.</p></sec><sec id="s2" hwp:id="sec-2"><label>2.</label><title hwp:id="title-5">M<sc>ethodology</sc></title><sec id="s2a" hwp:id="sec-3" hwp:rev-id="xref-sec-3-1"><label>2.1</label><title hwp:id="title-6">Derivation of basic method</title><p hwp:id="p-15">Our method uses a single, downward-looking camera positioned at the ceiling of the experimental arena in which the birds are filmed. The camera must have a field of view that is large enough to cover the entire volume of space within which the bird’s flight trajectories are to be reconstructed.</p><p hwp:id="p-16">Essentially, the approach involves combining knowledge of the bird’s wingspan (which provides a scale factor that determines the absolute distance of the bird from the camera) with a calibration of the camera that uses a grid of known geometry drawn on the floor. This calibration provides a means of accounting for all of the imaging distortions that are introduced by the wide-angle optics of the camera lens. In our initial derivation, we assume that the bird does not display a significant amount of roll during its tracked flight. In other words, the two wingtips are in the horizonal plane (or approximately so) when the wings are fully extended. In the Supplementary Information (Section B) we derive and validate a method that accounts for the effects of roll, and also measures the roll angle.</p><p hwp:id="p-17">A square grid of known mesh dimensions is laid out on the floor. The 2D locations (X,Y) of each of the intersection points are therefore known. <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1</xref> illustrates, schematically, a camera view of the grid on the floor, and of a bird in flight above it, as imaged in a video frame in which the wings are fully extended.</p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1</label><caption hwp:id="caption-1"><p hwp:id="p-18">Schematic view of image of the flight chamber from an overhead video camera, showing the calibration grid on the floor, and the instantaneous position of a bird with its wings extended. The origin of the pixel co-ordinates is taken to be the center of the image, i.e. corresponding to the direction of the camera’s optic axis. The origin of the calibration grid is taken to be point directly beneath the camera, i.e. the position where the optic axis of the camera intersects the floor.</p></caption><graphic xlink:href="340232v2_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-19">In general, the image of the grid will not be square, but distorted by the non-linear off-axis imaging produced by the wide-angle lens, as shown in the real image of <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2</xref>.</p><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2</label><caption hwp:id="caption-2"><p hwp:id="p-20">Camera view of the calibration grid on the floor (red points).</p></caption><graphic xlink:href="340232v2_fig2" position="float" orientation="portrait" hwp:id="graphic-2"/></fig><p hwp:id="p-21">The intersection points of the grid in the camera image are digitised (manually, or by using specially developed image analysis software), and their pixel locations are recorded. Thus, each grid location (Xi,Yi) on the floor is tagged with its corresponding pixel co-ordinates (pxi,pyi) in the image. This data is used to compute a function that characterises a two-dimensional mapping between the grid locations on the floor and their corresponding pixel co-ordinates in the image. We note that the calibration grid does not need to be on the floor: It can be at any distance from the camera, but this distance must be known and the plane of the grid must be perpendicular to the camera’s optic axis.</p><p hwp:id="p-22">Video footage of a bird flying in the chamber, as captured by the overhead camera, is then analysed to reconstruct the bird’s 3D flight trajectory, as described below. Two examples of such footage are provided in the Supplementary videos SV1 and SV2. The positions of the wingtips are digitised in every frame in which the wings are fully extended, i.e. when the distance between the wingtips is equal to the wingspan, and attains a maximum in the video image. In the Budgerigar this occurs once during each wingbeat cycle, roughly halfway through the downstroke. We denote the pixel co-ordinates of the wingtips in these frames, which we call the <italic toggle="yes">Wex</italic> frames, by (pxL,pyL) (left wingtip) and (pxR,pyR) (right wingtip). The projected locations of the two wingtips on the floor are determined by using the mapping function, described above, to carry out an interpolation. Essentially, the projected location of this wingtip on the floor is obtained by computing the position of the point on the floor that has the same location, relative to its four surrounding grid points, as does the position of the wingtip (in image pixel co-ordinates) in relation to the positions of the four surrounding grid locations (in image pixel co-ordinates). Thus, in the case of the left wing tip, for example, this computation effectively uses the locations of the four grid points 1,2, 3 and 4 (see <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Figure 1</xref>) with locations (X1,Y1), (X2,Y2), (X3,Y3) and (X4,Y4) on the floor, and their corresponding image pixel co-ordinates (px1,py1), (px2,py2), (px3,py3) and (px4,py4) respectively, to interpolate the projected position of the pixel co-ordinate (pxL,pyL) on the floor. A similar procedure is used to project the position of the right wingtip (pxR,pyR) on the floor. The construction of the two-dimensional mapping function, and the interpolation are accomplished by using the Matlab function <italic toggle="yes">TriScatteredInterp</italic>. (Equivalent customized codes could be written in any language.)</p><p hwp:id="p-23">Once the positions of the two wingtips have been projected on to the floor, this information can be used to determine the instantaneous position of the bird in three dimensions, as illustrated in <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure 3</xref>. In this figure the 3D positions of the left and right wingtips are denoted by M, with co-ordinates (xL,yL,z), and N, with co-ordinates (xR,yR,z), respectively. Their projected points on the floor are denoted by C, with co-ordinates (XL,YL,0), and D, with co-ordinates (XR,YR,0), respectively.</p><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3</label><caption hwp:id="caption-3"><p hwp:id="p-24">Schematic view of experimental chamber, showing the variables used for computing the instantaneous 3D position of the bird and its wingtips. E is the point on the floor that is directly beneath the camera, i.e. the point where the camera’s optic axis intersects the floor.</p></caption><graphic xlink:href="340232v2_fig3" position="float" orientation="portrait" hwp:id="graphic-3"/></fig><p hwp:id="p-25">The height of the bird above the floor is established by determining the ratio between the known wingspan of the bird (w), and the projection of its wingspan on the floor, which we denote by W. W, which is equal to the distance between points C and D in <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Figure 3</xref>, is given by
<disp-formula id="eqn1" hwp:id="disp-formula-1" hwp:rev-id="xref-disp-formula-1-1">
<alternatives hwp:id="alternatives-1"><graphic xlink:href="340232v2_eqn1.gif" position="float" orientation="portrait" hwp:id="graphic-4"/></alternatives>
</disp-formula>
We denote the ratio (W/w) by Q.</p><p hwp:id="p-26">From the geometrical similarity of the triangles OCD and OMN, and triangles OEF and ORG, we can write
<disp-formula id="eqn2" hwp:id="disp-formula-2">
<alternatives hwp:id="alternatives-2"><graphic xlink:href="340232v2_eqn2.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives>
</disp-formula>
where H is the height of the ceiling (assumed to be known), and <italic toggle="yes">u</italic> is the distance of the bird below the ceiling. The height <italic toggle="yes">h</italic> of the bird above the floor, equal to (H−u), is then computed from (2) as
<disp-formula id="eqn3" hwp:id="disp-formula-3" hwp:rev-id="xref-disp-formula-3-1">
<alternatives hwp:id="alternatives-3"><graphic xlink:href="340232v2_eqn3.gif" position="float" orientation="portrait" hwp:id="graphic-6"/></alternatives>
</disp-formula>
<italic toggle="yes">h</italic> is the height of the two wingtips above the floor. The (x,y) co-ordinates of the left and right wingtips can also be computed from the wingspan ratio Q as follows.</p><p hwp:id="p-27">From the similarity of triangles ODF and ONG, and OEF and ORG, we have:
<disp-formula id="eqn4" hwp:id="disp-formula-4">
<alternatives hwp:id="alternatives-4"><graphic xlink:href="340232v2_eqn4.gif" position="float" orientation="portrait" hwp:id="graphic-7"/></alternatives>
</disp-formula>
which can be rewritten as
<disp-formula id="eqn5" hwp:id="disp-formula-5">
<alternatives hwp:id="alternatives-5"><graphic xlink:href="340232v2_eqn5.gif" position="float" orientation="portrait" hwp:id="graphic-8"/></alternatives>
</disp-formula>
This implies that the (x,y) position co-ordinates of the left wingtip are given by
<disp-formula id="eqn6" hwp:id="disp-formula-6">
<alternatives hwp:id="alternatives-6"><graphic xlink:href="340232v2_eqn6.gif" position="float" orientation="portrait" hwp:id="graphic-9"/></alternatives>
</disp-formula>
and the (x,y) position co-ordinates of the right wingtip are
<disp-formula id="eqn7" hwp:id="disp-formula-7">
<alternatives hwp:id="alternatives-7"><graphic xlink:href="340232v2_eqn7.gif" position="float" orientation="portrait" hwp:id="graphic-10"/></alternatives>
</disp-formula>
Thus, the 3D position co-ordinates of the left and right wing tips are (<italic toggle="yes">xL,yL,h</italic>) and (<italic toggle="yes">xR,yR,h</italic>). If we assume that the centre of the bird (the approximate position of its centre of gravity) is located midway between the extended wingtips, then the 3D co-ordinates of the centre of the bird (<italic toggle="yes">xc,yc,zc</italic>) can be computed as
<disp-formula id="eqn8" hwp:id="disp-formula-8">
<alternatives hwp:id="alternatives-8"><graphic xlink:href="340232v2_eqn8.gif" position="float" orientation="portrait" hwp:id="graphic-11"/></alternatives>
</disp-formula>
However, computing the centre of the bird in this way is valid only at the instants when the wings are fully extended. At other times the wings would be pointing either forward or backward, and this calculation would yield an incorrect result. Another way to define the centre of the bird would be as the centre of its thorax. During flight, the head is the most stable part of the bird’s anatomy-it maintains a horizontal orientation that is largely independent of the pitch and roll attitude of the body (<xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">Warrick et al., 2002</xref>; <xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">Frost, 2009</xref>; <xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">Bhagavatula, 2011</xref>). It is also a highly visible part of the bird that can be tracked reliably - either manually through frame-by-frame digitisation, or by software algorithms that employ relatively simple heuristics. Moreover, the head carries the bird’s primary sense organs, including the eyes. Therefore, reconstructing the 3D trajectory of the head can be useful for determining the visual stimuli that the bird experiences during its flight.</p><p hwp:id="p-28">The 3D position co-ordinates of the head can be calculated for each frame as follows. The pixel co-ordinates of the head are determined in every frame (either through manual digitisation or an automated tracking algorithm). The head pixel co-ordinates are projected on to the floor, using the same interpolation procedure that was applied to the wingtips. We denote the floor co-ordinates of the head by (XH,YH) (not shown in <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Figure 3</xref>). Then, using the same geometrical reasoning as above, the (x,y) position co-ordinates of the head are given by
<disp-formula id="eqn9" hwp:id="disp-formula-9" hwp:rev-id="xref-disp-formula-9-1">
<alternatives hwp:id="alternatives-9"><graphic xlink:href="340232v2_eqn9.gif" position="float" orientation="portrait" hwp:id="graphic-12"/></alternatives>
</disp-formula>
and the full 3D co-ordinates of the head are given by
<disp-formula id="eqn10" hwp:id="disp-formula-10" hwp:rev-id="xref-disp-formula-10-1 xref-disp-formula-10-2">
<alternatives hwp:id="alternatives-10"><graphic xlink:href="340232v2_eqn10.gif" position="float" orientation="portrait" hwp:id="graphic-13"/></alternatives>
</disp-formula>
We note that the height of the head (<italic toggle="yes">h</italic>) is directly calculable only in the frames in which the wings are fully extended, because the bird’s wingspan is the known metric that enables determination of the height. The heights in other frames are estimated through temporal interpolation, assuming that the height varies approximately linearly between successive wing extensions. This is a reasonable assumption for most birds - typically, the height of flight varies slowly and smoothly across several wing beat cycles. However, the X and Y coordinates of the bird in 3D (<italic toggle="yes">xH,yH</italic>) are determined independently for each frame of the video sequence, based on the digitised pixel co-ordinates of the head in each frame, and the temporally interpolated height for that frame. Thus, while the height of the head (h) is temporally interpolated between wing extensions, the (X,Y) co-ordinates of the head (<italic toggle="yes">xH,yH</italic>) are calculated independently for each frame, based on the pixel co-ordinates of the head in that frame. The height of the thorax can be estimated through a similar calculation, by defining the thorax either as the midpoint between the extended wingtips in the image, or the midpoint between the wing bases in the image.</p><p hwp:id="p-29">In summary, our method delivers a sample of the bird’s height at every frame in which the wings are extended. These samples are interpolated in time to obtain a height profile of the head for the entire video sequence. This height profile is then used in combination with the pixel co-ordinates of the head in each frame to obtain the 3D co-ordinates of the bird for each frame of the video sequence.</p><p hwp:id="p-30">In Budgerigars, the wings are fully outstretched only once during each wingbeat cycle –roughly halfway through the downstroke, as we have noted above. This is also appears to be the case in pigeons and magpies (<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">Tobalske and Dial, 1996</xref>). It is possible that in certain other species, which move their wings in the same plane during the upstroke and the downstroke, without folding them, there are two <italic toggle="yes">Wex</italic> frames per wingbeat cycle - one occurring during the upstroke, the other during the downstroke. In such cases we can obtain two height estimates per wingbeat cycle, and therefore reconstruct the height profile at twice the temporal resolution.</p><p hwp:id="p-31">In the above analysis, we have assumed that the head of the bird is at the same height as that of its extended wingtips. If the head is at a different height - as may be evinced from prior knowledge or from side-view images of bird flight in wind tunnels - this known height offset can be added to the wingtip height to obtain the true height of the head.</p></sec><sec id="s2b" hwp:id="sec-4"><label>2.2</label><title hwp:id="title-7">Procedural steps</title><p hwp:id="p-32">Based on the theory described above, the step-by-step procedure for reconstructing the 3D trajectory of the head of a bird from a video sequence captured by a single overhead camera can be described as follows:</p><list list-type="roman-lower" hwp:id="list-1"><list-item hwp:id="list-item-1"><p hwp:id="p-33">Construct the floor grid and acquire an image of the grid from the video camera. An example is shown in <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2</xref>. The grid is used only once for the camera calibration, and does not need to be present in the experiments.</p></list-item><list-item hwp:id="list-item-2"><p hwp:id="p-34">Digitise the pixel co-ordinates of the grid locations in the camera image, to obtain a one-to-one mapping between the real co-ordinates of the grid locations on the floor and their corresponding pixel coordinates in the image.</p></list-item><list-item hwp:id="list-item-3"><p hwp:id="p-35">Acquire knowledge of the bird’s wingspan, either from published data for the species, or, preferably, from direct measurement of the actual individual (because the wingspan can vary from individual to individual due to age and other factors).</p></list-item><list-item hwp:id="list-item-4"><p hwp:id="p-36">Acquire video footage of the bird during flight in the chamber</p></list-item><list-item hwp:id="list-item-5"><p hwp:id="p-37">Select the frames in the video sequence in which the wings are fully extended. The selection can be done either manually, or through custom-written software. The wing-extension frames are denoted by <italic toggle="yes">Wex</italic>.</p></list-item><list-item hwp:id="list-item-6"><p hwp:id="p-38">Digitise the pixel positions of the left and right wingtips of the bird in each of the <italic toggle="yes">Wex</italic> frames, as shown in the illustrative example of <xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Figure 4</xref>.</p></list-item><list-item hwp:id="list-item-7"><p hwp:id="p-39">Determine the height of the thorax (midpoint between the extended wingtips) or of the head in each of the <italic toggle="yes">Wex</italic> frames from <xref ref-type="disp-formula" rid="eqn1" hwp:id="xref-disp-formula-1-1" hwp:rel-id="disp-formula-1">equations (1</xref>–<xref ref-type="disp-formula" rid="eqn3" hwp:id="xref-disp-formula-3-1" hwp:rel-id="disp-formula-3">3</xref>).</p></list-item><list-item hwp:id="list-item-8"><p hwp:id="p-40">Obtain the height profile of the thorax (and/or the head) for the entire video sequence by temporally interpolating the heights calculated for the <italic toggle="yes">Wex</italic> frames.</p></list-item><list-item hwp:id="list-item-9"><p hwp:id="p-41">Digitise the pixel position of the thorax/head in each frame of the video sequence.</p></list-item><list-item hwp:id="list-item-10"><p hwp:id="p-42">Compute the 3D position of the thorax/head for each frame from <xref ref-type="disp-formula" rid="eqn9" hwp:id="xref-disp-formula-9-1" hwp:rel-id="disp-formula-9">equations (9)</xref> and <xref ref-type="disp-formula" rid="eqn10" hwp:id="xref-disp-formula-10-1" hwp:rel-id="disp-formula-10">(10)</xref>.</p></list-item></list><fig id="fig4" position="float" fig-type="figure" orientation="portrait" hwp:id="F4" hwp:rev-id="xref-fig-4-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4</label><caption hwp:id="caption-4"><p hwp:id="p-43">Example of a video sequence showing superimposed images of the bird in successive frames. Successive wing extensions are marked by the crosses.</p></caption><graphic xlink:href="340232v2_fig4" position="float" orientation="portrait" hwp:id="graphic-14"/></fig></sec><sec id="s2c" hwp:id="sec-5"><label>2.3</label><title hwp:id="title-8">Test of accuracy</title><p hwp:id="p-44">The precision of the 3D trajectory reconstruction procedure was evaluated by placing a small test target at 44 different, known 3D locations within the tunnel, of which 39 were within the boundary of the grid. The test target was a model bird with a calibrated wingspan of 30 cm. The head was assumed to be midway between the wingtips, and at the same height as the wingtips. This assumption does not affect the generality of the results, as discussed above. The standard deviations of the errors along the x, y and H directions were 2.1 cm (X), 0.6 cm (Y) and 2.6 cm (H). A detailed compilation of the errors is given in Table S1 of the SI.</p></sec><sec id="s2d" hwp:id="sec-6"><label>2.4</label><title hwp:id="title-9">Ethics Statement</title><p hwp:id="p-45">All experiments were carried out in accordance with the Australian Law on the protection and welfare of laboratory animals and the approval of the Animal Experimentation Ethics Committees of the University of Queensland, Brisbane, Australia.</p></sec></sec><sec id="s3" hwp:id="sec-7"><label>3.</label><title hwp:id="title-10">R<sc>esults</sc></title><sec id="s3a" hwp:id="sec-8"><label>3.1</label><title hwp:id="title-11">Examples of flight tracking and reconstruction</title><p hwp:id="p-46">Here we show some examples of reconstruction of 3D trajectories of flights of Budgerigars through an indoor tunnel, of dimensions of dimensions 7.28 m (length) x 1.36 m (width) x 2.44 m (height). The birds were trained to fly from a perch at one end of the tunnel to a bird cage at the other. A downward-facing video camera, placed at the centre of the ceiling of the tunnel, was used to film the flights and reconstruct the trajectories in 3D. A grid, of check size 20 cm x 20 cm (as in <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Figure 2</xref>), was drawn on the floor to calibrate the camera using the procedure described above. The reconstructed 3D trajectories do not include the take-off and landing phases of the flight. They only show a section of the trajectory that extends over a window extending from about 1.75 m ahead of the aperture to about 0.25 m behind it, which could be viewed as a ‘cruise’ phase where the bird has completed take-off and not yet commenced landing.</p><p hwp:id="p-47">Flights through the tunnel were filmed with the tunnel being either empty (devoid of any obstacles) or carrying a narrow, vertically oriented aperture (a slit) at the halfway point, through which the birds had to fly to get to the other end. To prevent injuries to the birds, the aperture was created by suspending two cloth panels that reached from the ceiling to the floor. Two aperture widths were tested: In one set of tests, the aperture was 5cm wider than the bird’s wingspan; in the other set, the aperture was 5cm narrower than the bird’s wingspan. It has been shown in earlier studies (<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">Schiffner et al., 2014</xref>; <xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-2" hwp:rel-id="ref-24">Vo et al., 2016</xref>) that Budgerigars are acutely aware of their wingspan: when negotiating a narrow aperture, they fold their wings back briefly only when the aperture is narrower than their wingspan, and fly through without interrupting their wingbeat cycle if the aperture is wider than their wingspan.</p><p hwp:id="p-48">A plan view of a reconstructed flight is shown in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-1" hwp:rel-id="F5">Figure 5</xref>. In this example, the bird (<italic toggle="yes">Four</italic>) has a wingspan of 29 cm and it flies through a 34 cm aperture, which is 5 cm wider than the wingspan. The figure shows the (X,Y) positions of the two wingtips at the time of each wing extension, the centre of the body (defined as the midpoint of the line joining the wingtips), and the position of the head. It is evident that the bird flies through the aperture without interrupting its wingbeat cycle, as the wingbeat extensions are equally spaced.</p><fig id="fig5" position="float" fig-type="figure" orientation="portrait" hwp:id="F5" hwp:rev-id="xref-fig-5-1 xref-fig-5-2 xref-fig-5-3 xref-fig-5-4 xref-fig-5-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">fig5</object-id><label>Figure 5</label><caption hwp:id="caption-5"><p hwp:id="p-49">Plan view of a reconstructed flight of Bird Four. In this example, the wingspan of the bird is 29 cm and it flies through a 34 cm aperture, which is 5 cm wider than the wingspan. Details in text. The red circles show the wingtip positions at the time of each wing extension, the black circles show the inferred position of the thorax at these instants, and the blue asterisks depict the position of the head at these instants. The red lines show the wing extension trajectories interpolated between wing extensions. The arrow in this and other figures shows the direction of flight.</p></caption><graphic xlink:href="340232v2_fig5" position="float" orientation="portrait" hwp:id="graphic-15"/></fig><p hwp:id="p-50">This is also clear from <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Figure 6</xref>, which shows two 3D views of the same flight trajectory, where the blue circles represent the centre of the body at each wing extension and the red curve shows the reconstructed 3D position of the head for every frame, as described in the text above and in the legend. The lateral view of the trajectory (<xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-2" hwp:rel-id="F5">Figure 5</xref>, right hand panel) shows that the bird maintains its height while passing through the aperture, because the wingbeat cycle is not interrupted.</p><fig id="fig6" position="float" fig-type="figure" orientation="portrait" hwp:id="F6" hwp:rev-id="xref-fig-6-1 xref-fig-6-2 xref-fig-6-3 xref-fig-6-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">fig6</object-id><label>Figure 6</label><caption hwp:id="caption-6"><p hwp:id="p-51">Two 3D views of the trajectory shown in <xref ref-type="fig" rid="fig5" hwp:id="xref-fig-5-3" hwp:rel-id="F5">Figure 5</xref>, in which bird Four flies through an aperture that is 5 cm wider than its wingspan. The blue circles show the inferred position of the thorax at the time of each wing extension, the blue lines show the linearly interpolated thorax positions between successive wing extensions, and the red asterisks show the head position at the time of each wing extension. The image coordinates of the head, which were digitized in every video frame, were used to calculate the 3D trajectory of the head in every frame by linearly interpolating the image lengths of the extended wingspans across the frames between successive wing extensions, as described in the text. The red curve shows the resulting 3D trajectory of the head during the entire video sequence, after smoothing by a 9-point centered rectangular moving average filter. Left panel: View from −40 deg azimuth, 30 deg elevation. Right panel: Near-lateral view from −10 deg azimuth, 10 deg elevation.</p></caption><graphic xlink:href="340232v2_fig6" position="float" orientation="portrait" hwp:id="graphic-16"/></fig><p hwp:id="p-52"><xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-1" hwp:rel-id="F7">Figure 7</xref> shows two 3D views of a trajectory of the same bird during flight through an aperture that is 5 cm narrower than its wingspan. Here is clear that the wingbeat cycle is interrupted when the bird passes through the aperture – the distance between successive wing extensions is dramatically larger during the passage. This is also clear from the lateral view of the trajectory (<xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-2" hwp:rel-id="F6">Figure 6</xref>, right hand panel), which shows that the bird loses altitude while passing through the aperture, because the wingbeat cycle is interrupted.</p><fig id="fig7" position="float" fig-type="figure" orientation="portrait" hwp:id="F7" hwp:rev-id="xref-fig-7-1 xref-fig-7-2 xref-fig-7-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG7</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F7</object-id><object-id pub-id-type="publisher-id">fig7</object-id><label>Figure 7</label><caption hwp:id="caption-7"><p hwp:id="p-53">Two 3D views of a trajectory of bird Four during flight through an aperture that is 5 cm narrower than its wingspan. Details are as in <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-3" hwp:rel-id="F6">Figure 6</xref>.</p></caption><graphic xlink:href="340232v2_fig7" position="float" orientation="portrait" hwp:id="graphic-17"/></fig><p hwp:id="p-54"><xref rid="fig8" ref-type="fig" hwp:id="xref-fig-8-1" hwp:rel-id="F8">Figure 8</xref> shows two 3D views of a trajectory of the same bird during flight through the tunnel when there is no aperture. In this case – as in <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-4" hwp:rel-id="F5">Figure 5</xref> - the wingbeat cycle is not interrupted anywhere in the flight. This is also clear from the lateral view of the trajectory (<xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-2" hwp:rel-id="F7">Figure 7</xref>, right hand panel), which shows that the bird maintains a constant wingbeat cycle and does not lose altitude abruptly anywhere along the trajectory.</p><fig id="fig8" position="float" fig-type="figure" orientation="portrait" hwp:id="F8" hwp:rev-id="xref-fig-8-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG8</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F8</object-id><object-id pub-id-type="publisher-id">fig8</object-id><label>Figure 8</label><caption hwp:id="caption-8"><p hwp:id="p-55">Two 3D views of a trajectory of bird Four during flight through a tunnel which carries no aperture. Details are as in <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-4" hwp:rel-id="F6">Figure 6</xref>.</p></caption><graphic xlink:href="340232v2_fig8" position="float" orientation="portrait" hwp:id="graphic-18"/></fig><p hwp:id="p-56">It is clear from <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-5" hwp:rel-id="F5">Figs. 5</xref> – <xref ref-type="fig" rid="fig7" hwp:id="xref-fig-7-3" hwp:rel-id="F7">7</xref> that bird <italic toggle="yes">Four</italic> interrupts its wingbeat cycle only when it confronts an aperture that is narrower than its wingspan, and not when the aperture is wider than the wingspan or is not present in the tunnel. A loss of altitude occurs only when the wingbeat cycle in interrupted, and not otherwise.</p><p hwp:id="p-57"><xref rid="fig9" ref-type="fig" hwp:id="xref-fig-9-1" hwp:rel-id="F9">Figure 9</xref> shows plan views of the reconstructed 3D trajectories of the head for the three conditions. In each case, the asterisks mark the locations of the head at the times of full wing extension. Other details are given in the figure legend. In the case of the narrow aperture (red track), the bird temporarily interrupts its wing beat cycle while passing through the aperture. The final wing extension prior to passing the aperture occurs at a point approximately 0.35 m ahead of the aperture. The wing beat cycle resumes after passage through the aperture, with the first wing extension occurring at a point approximately 0.5m beyond the aperture. In the wide aperture and the no aperture conditions, the wing beat cycle continues uninterrupted throughout the flight. These observations are in agreement with those of <xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-2" hwp:rel-id="ref-15">Schiffner et al. (2014)</xref>, who report an exquisite ability of these birds to gauge the width of oncoming passages in relation to their wingspan. However, their study only recorded the frequency and timing of wing closures, and did not reconstruct the birds’ trajectories in 3D.</p><fig id="fig9" position="float" fig-type="figure" orientation="portrait" hwp:id="F9" hwp:rev-id="xref-fig-9-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG9</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F9</object-id><object-id pub-id-type="publisher-id">fig9</object-id><label>Figure 9</label><caption hwp:id="caption-9"><p hwp:id="p-58">Plan views of the reconstructed 3D trajectories for the narrow aperture condition (red), the wide aperture condition (grey) and the no aperture condition (green), for bird Four. In each case, the circles mark the locations of the thorax (defined as the mid-point of the line connecting the extended wing tips) at the time of each wing extension, the thick curves show the thorax trajectory interpolated from the thorax positions at these times, the asterisks mark the locations of the head at the times of the wing extensions, and the thin black curve through the asterisks shows the trajectory of the head, reconstructed from the digitized image co-ordinates of the head in each frame as explained in the text.</p></caption><graphic xlink:href="340232v2_fig9" position="float" orientation="portrait" hwp:id="graphic-19"/></fig><p hwp:id="p-59"><xref rid="fig10" ref-type="fig" hwp:id="xref-fig-10-1" hwp:rel-id="F10">Figure 10</xref> shows reconstructed profiles of the forward flight speed (speed along the X axis of the tunnel) for the flights of bird <italic toggle="yes">Four</italic> in the narrow aperture, wide aperture and no-aperture conditions. These profiles were constructed using three different procedures, the details of which are described in the legend. The three procedures yield consistent results. The principal observation is that the forward speed is more or less constant throughout the flight and is independent of the flight condition, as observed in <xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-3" hwp:rel-id="ref-24">Vo et al. (2016)</xref>. Interestingly, the interruption of the wing beat cycle during the flight through the narrow aperture does not significantly reduce the forward speed.</p><fig id="fig10" position="float" fig-type="figure" orientation="portrait" hwp:id="F10" hwp:rev-id="xref-fig-10-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG10</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F10</object-id><object-id pub-id-type="publisher-id">fig10</object-id><label>Figure 10</label><caption hwp:id="caption-10"><p hwp:id="p-60">Forward speed profile of bird Four during flight through the narrow aperture (top panel), the wide aperture (middle panel), and the empty tunnel (bottom panel). In each case, the black curve shows the speed profile of the head, computed from the frame-to-frame X positions of the head. The black asterisks denote the speeds at the head positions corresponding to the wing extensions, and the red curve and asterisks depict the result of smoothing the speed profile using a 9-point centered rectangular moving average filter. The edges of the grey bars denote the successive X positions of the thorax (defined as the midpoint between the wingtips) at each wing extension, computed as described in the text. The height of each grey bar depicts the mean forward speed of the thorax between successive wing extensions, computed as the ratio of the X distance between successive edges, to the time interval between these edges. Because the wingbeat kinematics are not perfectly identical from one wingbeat cycle to the next, the spatial relationship between the head and the line joining the wingtips is not exactly the same at the point of each wing extension. As a result, the measured speed of the thorax (grey bars) can occasionally be noticeably different from that of the head (asterisks): e.g. fourth grey bar (top panel), and fifth grey bar (middle panel).</p></caption><graphic xlink:href="340232v2_fig10" position="float" orientation="portrait" hwp:id="graphic-20"/></fig><p hwp:id="p-61">In the Supplementary Information (Figures S1-S6) we show results for another bird (<italic toggle="yes">Nemo</italic>), corresponding those shown above for bird <italic toggle="yes">Four</italic>.</p></sec><sec id="s3b" hwp:id="sec-9"><label>3.2</label><title hwp:id="title-12">Accounting for the effects of body roll: extended calculation</title><p hwp:id="p-62">In the analysis so far, we have assumed that the birds are not rolling during flight, i.e. that the wingtips are in the horizontal plane when they are fully extended. This assumption is quite valid for the flights we have filmed and reconstructed: the birds displayed very little roll throughout their flight, as evinced by the fact that, when the wings were outstretched, the two wingtips were approximately equidistant from the head in all video frames. However, our theory can be extended to take body roll into account – when this is significant – and continue to obtain accurate estimates of the 3D trajectories, as well as the roll angles. The essential elements of the procedure are described briefly below, and the complete general derivation is provided in the Supplementary Information (Section B).</p><p hwp:id="p-63">The basic principle underlying the approach is outlined in <xref rid="fig11" ref-type="fig" hwp:id="xref-fig-11-1" hwp:rel-id="F11">Figure 11</xref>, which illustrates a simplified case in which the midpoint O between the extended wingtips is directly under the camera, i.e. in line with the camera’s optic axis. During a roll, the line connecting the extended wingtips is not horizontal. Therefore, in the camera image the angles ϕ<sub>1</sub> and ϕ<sub>2</sub> subtended by the two wings will not be equal, because the right wingtip (in this case) is higher than the left wingtip. These angles can be computed from the projections on the grid floor of the images of the two wingtips (R,L), and the projection of the point (O), which is the point on the bird that is midway between the extended wingtips. When the bird is not rolling the extended wingtips will lie in a horizontal plane, and the image of O in the camera will be midway between the images of the extended wingtips, because ϕ<sub>1</sub> = ϕ<sub>2</sub>. However, when the bird is rolling, ϕ<sub>1</sub> ≠ ϕ<sub>2</sub> and the image of O will not be midway between the images of the extended wingtips. ϕ<sub>1</sub> and ϕ <sub>2</sub> can be measured and used to calculate the roll angle. In the camera image, O is determined as the point where the straight line connecting the wingtips intersects the longitudinal axis of the thorax (see <xref rid="fig13" ref-type="fig" hwp:id="xref-fig-12-1" hwp:rel-id="F12">Figure 13c</xref>). We shall hereafter refer to O as the ‘thorax point’. From the projected locations of R, L and O on the floor grid, the height of O above the ground (h) and the angle of roll (α) can be calculated as shown below. This calculation distinguishes between changes in roll and changes in height, because it evaluates the distances of the projected wingtips <italic toggle="yes">separately</italic> for the left and right wings: these distances are not equal when the bird rolls.</p><fig id="fig11" position="float" fig-type="figure" orientation="portrait" hwp:id="F11" hwp:rev-id="xref-fig-11-1 xref-fig-11-2 xref-fig-11-3 xref-fig-11-4"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG11</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F11</object-id><object-id pub-id-type="publisher-id">fig11</object-id><label>Figure 11</label><caption hwp:id="caption-11"><p hwp:id="p-64">Illustration of calculation of bird height (h) and roll angle (α) for a simplified case in which the midpoint of the wingspan is directly below the camera’s optical axis. The known wingspan of the bird is 2r, and the camera is at a known height H above the floor.</p></caption><graphic xlink:href="340232v2_fig11" position="float" orientation="portrait" hwp:id="graphic-21"/></fig><fig id="fig13" position="float" fig-type="figure" orientation="portrait" hwp:id="F12" hwp:rev-id="xref-fig-12-1 xref-fig-12-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG13</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F12</object-id><object-id pub-id-type="publisher-id">fig13</object-id><label>Figure 13</label><caption hwp:id="caption-12"><p hwp:id="p-65">Examples of images acquired by the overhead camera. (a) Bird height 158mm, roll 0 deg; (b) Bird height 158mm, roll +26 deg; (c) Bird height 157mm, roll −22.5 deg; (d) Bird height 205 mm, roll +51 deg. Heights refer to the height of the thorax point O, as illustrated in (c), and in <xref ref-type="fig" rid="fig11" hwp:id="xref-fig-11-2" hwp:rel-id="F11">Figures 11</xref>, S7 and S8. The roll angle is positive when the right wingtip is higher than the left wingtip, and vice versa.</p></caption><graphic xlink:href="340232v2_fig13" position="float" orientation="portrait" hwp:id="graphic-22"/></fig><p hwp:id="p-66">From <xref rid="fig11" ref-type="fig" hwp:id="xref-fig-11-3" hwp:rel-id="F11">Figure 11</xref> we have
<disp-formula id="eqn11" hwp:id="disp-formula-11" hwp:rev-id="xref-disp-formula-11-1">
<alternatives hwp:id="alternatives-11"><graphic xlink:href="340232v2_eqn11.gif" position="float" orientation="portrait" hwp:id="graphic-23"/></alternatives>
</disp-formula>
<disp-formula id="eqn12" hwp:id="disp-formula-12" hwp:rev-id="xref-disp-formula-12-1">
<alternatives hwp:id="alternatives-12"><graphic xlink:href="340232v2_eqn12.gif" position="float" orientation="portrait" hwp:id="graphic-24"/></alternatives>
</disp-formula>
so that
<disp-formula id="eqn13" hwp:id="disp-formula-13">
<alternatives hwp:id="alternatives-13"><graphic xlink:href="340232v2_eqn13.gif" position="float" orientation="portrait" hwp:id="graphic-25"/></alternatives>
</disp-formula>
We can also write
<disp-formula id="eqn14" hwp:id="disp-formula-14">
<alternatives hwp:id="alternatives-14"><graphic xlink:href="340232v2_eqn14.gif" position="float" orientation="portrait" hwp:id="graphic-26"/></alternatives>
</disp-formula>
and
<disp-formula id="eqn15" hwp:id="disp-formula-15">
<alternatives hwp:id="alternatives-15"><graphic xlink:href="340232v2_eqn15.gif" position="float" orientation="portrait" hwp:id="graphic-27"/></alternatives>
</disp-formula>
Thus,
<disp-formula id="eqn16" hwp:id="disp-formula-16">
<alternatives hwp:id="alternatives-16"><graphic xlink:href="340232v2_eqn16.gif" position="float" orientation="portrait" hwp:id="graphic-28"/></alternatives>
</disp-formula>
From triangle similarity we have
<disp-formula id="eqn17" hwp:id="disp-formula-17">
<alternatives hwp:id="alternatives-17"><graphic xlink:href="340232v2_eqn17.gif" position="float" orientation="portrait" hwp:id="graphic-29"/></alternatives>
</disp-formula>
Equating (13) and (16) we obtain
<disp-formula id="eqn18" hwp:id="disp-formula-18">
<alternatives hwp:id="alternatives-18"><graphic xlink:href="340232v2_eqn18.gif" position="float" orientation="portrait" hwp:id="graphic-30"/></alternatives>
</disp-formula>
which gives
<disp-formula id="eqn19" hwp:id="disp-formula-19">
<alternatives hwp:id="alternatives-19"><graphic xlink:href="340232v2_eqn19.gif" position="float" orientation="portrait" hwp:id="graphic-31"/></alternatives>
</disp-formula>
or
<disp-formula id="eqn20" hwp:id="disp-formula-20">
<alternatives hwp:id="alternatives-20"><graphic xlink:href="340232v2_eqn20.gif" position="float" orientation="portrait" hwp:id="graphic-32"/></alternatives>
</disp-formula>
from which we obtain
<disp-formula id="eqn21" hwp:id="disp-formula-21" hwp:rev-id="xref-disp-formula-21-1">
<alternatives hwp:id="alternatives-21"><graphic xlink:href="340232v2_eqn21.gif" position="float" orientation="portrait" hwp:id="graphic-33"/></alternatives>
</disp-formula>
Thus, the roll angle α can be evaluated from (<xref ref-type="disp-formula" rid="eqn21" hwp:id="xref-disp-formula-21-1" hwp:rel-id="disp-formula-21">21</xref>), using (<xref ref-type="disp-formula" rid="eqn11" hwp:id="xref-disp-formula-11-1" hwp:rel-id="disp-formula-11">11</xref>) and (<xref ref-type="disp-formula" rid="eqn12" hwp:id="xref-disp-formula-12-1" hwp:rel-id="disp-formula-12">12</xref>) to calculate ∅<sub>1</sub> and ∅<sub>2</sub>. Now, considering the total length AB, we have
<disp-formula id="eqn22" hwp:id="disp-formula-22">
<alternatives hwp:id="alternatives-22"><graphic xlink:href="340232v2_eqn22.gif" position="float" orientation="portrait" hwp:id="graphic-34"/></alternatives>
</disp-formula>
Then, from triangle similarity we have
<disp-formula id="eqn23" hwp:id="disp-formula-23">
<alternatives hwp:id="alternatives-23"><graphic xlink:href="340232v2_eqn23.gif" position="float" orientation="portrait" hwp:id="graphic-35"/></alternatives>
</disp-formula>
from which we solve for <italic toggle="yes">h</italic> to obtain
<disp-formula id="eqn24" hwp:id="disp-formula-24" hwp:rev-id="xref-disp-formula-24-1">
<alternatives hwp:id="alternatives-24"><graphic xlink:href="340232v2_eqn24.gif" position="float" orientation="portrait" hwp:id="graphic-36"/></alternatives>
</disp-formula>
Since X and Y are the projections of the right and left wingtips on the floor, the distance [XY] can be calculated, and <italic toggle="yes">h</italic> can be evaluated using (<xref ref-type="disp-formula" rid="eqn24" hwp:id="xref-disp-formula-24-1" hwp:rel-id="disp-formula-24">24</xref>).</p><p hwp:id="p-67">Note that <xref rid="fig11" ref-type="fig" hwp:id="xref-fig-11-4" hwp:rel-id="F11">Figure 11</xref> illustrates a very simple case, for the purpose of conveying the basic approach to the calculation. In the Supplementary Information (Section B) we derive an extension of this calculation for a general case in which the bird can be at any 3D location. The extended calculation delivers the height of the bird, as well as the roll angle. Once the height is known the 3D co-ordinates of the head can computed as before, following the procedure described in <xref ref-type="sec" rid="s2a" hwp:id="xref-sec-3-1" hwp:rel-id="sec-3">Section 2.1</xref> [<xref ref-type="disp-formula" rid="eqn10" hwp:id="xref-disp-formula-10-2" hwp:rel-id="disp-formula-10">equation (10)</xref>].</p></sec><sec id="s3c" hwp:id="sec-10"><label>3.3</label><title hwp:id="title-13">Validation of extended calculation</title><p hwp:id="p-68">We have validated the extended calculation, which accounts for body roll, by using a model bird in a scaled-down arena with an overhead camera and a calibration grid on the floor, A calibrated platform was used to position the model bird at 20 different 3D locations and flight directions, at various known roll angles and heights above the floor (<xref rid="fig12" ref-type="fig" hwp:id="xref-fig-13-1" hwp:rel-id="F13">Figure 12</xref>).</p><fig id="fig12" position="float" fig-type="figure" orientation="portrait" hwp:id="F13" hwp:rev-id="xref-fig-13-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG12</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F13</object-id><object-id pub-id-type="publisher-id">fig12</object-id><label>Figure 12</label><caption hwp:id="caption-13"><p hwp:id="p-69">Setup for validation of extended calculation, which accounts for body roll. The model bird, with a wingspan of 180 mm, is mounted on a platform whose height and tilt (roll) can be set to calibrated values using the height scale and the protractor. The size of the floor grid is 408 x 260 mm and the individual checks are 26.0 x 25.5 mm. The overhead camera is positioned above the center of the grid, with the nodal point of its lens at a height of 448 mm.</p></caption><graphic xlink:href="340232v2_fig12" position="float" orientation="portrait" hwp:id="graphic-37"/></fig><p hwp:id="p-70">Four examples of the images captured by the overhead camera are shown in <xref rid="fig13" ref-type="fig" hwp:id="xref-fig-12-2" hwp:rel-id="F12">Figure 13</xref>. <xref rid="fig14" ref-type="fig" hwp:id="xref-fig-14-1" hwp:rel-id="F14">Figure 14</xref> compares the heights and roll angles derived from the extended calculation with the true (ground truth) values, for each of the 20 configurations. It is evident that the extended analysis delivers accurate estimates of the height of the bird irrespective of body roll, as well as accurate estimates of the roll angle.</p><fig id="fig14" position="float" fig-type="figure" orientation="portrait" hwp:id="F14" hwp:rev-id="xref-fig-14-1 xref-fig-14-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;340232v2/FIG14</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F14</object-id><object-id pub-id-type="publisher-id">fig14</object-id><label>Figure 14</label><caption hwp:id="caption-14"><p hwp:id="p-71">Comparison of true heights and roll angles with computed heights and roll angles for test examples in which the model bird was positioned at 20 different 3D locations within the arena, facing various directions, and at different heights and roll angles.</p></caption><graphic xlink:href="340232v2_fig14" position="float" orientation="portrait" hwp:id="graphic-38"/></fig><p hwp:id="p-72">For the results shown in <xref rid="fig14" ref-type="fig" hwp:id="xref-fig-14-2" hwp:rel-id="F14">Figure 14</xref>, the mean and RMS errors in the calculated heights are 0.06 mm and 2.3 mm respectively, and the mean and RMS errors in the calculated roll angles are −0.4 deg and 1.7 deg respectively.</p><p hwp:id="p-73">While the real birds did not display significant body rolls during their flights in our experimental tunnel, the validation of our extended calculation using the model bird demonstrates that this procedure can be applied to calculate the true height (and the 3D coordinates of the thorax point and the head) of a bird even when its body is rolling, and to compute the roll angle.</p></sec></sec><sec id="s4" hwp:id="sec-11"><label>4.</label><title hwp:id="title-14">D<sc>iscussion</sc></title><p hwp:id="p-74">This study has described a simple, inexpensive method for reconstructing the flight trajectories of birds in 3D, using a single video camera. The advantages of the method are:</p><list list-type="roman-lower" hwp:id="list-2"><list-item hwp:id="list-item-11"><p hwp:id="p-75">The technique does not use a conventional stereo-based approach. Therefore, it does not require complex calibration procedures involving capturing views of a checkerboard at various positions and orientations, which does not always guarantee accurate localisation in all regions of the experimental space.</p></list-item><list-item hwp:id="list-item-12"><p hwp:id="p-76">The technique does not need feature correspondences to be determined across video frames from two or more cameras.</p></list-item><list-item hwp:id="list-item-13"><p hwp:id="p-77">The grid marker on the floor provides a calibration of the camera geometry and accounts for all of the distortions in the camera optics. There is no need to assume that the camera can be approximated by a pinhole camera, or by any other specific optical geometry. This calibration is a one-off procedure that can be used for the rest of the lifetime of the camera/lens combination, provided the optics are not altered.</p></list-item><list-item hwp:id="list-item-14"><p hwp:id="p-78">Once the calibration has been performed, the calibration grid can be removed or covered (if this is necessary to prevent its potential influence on the behaviour of the birds in the experiments).</p></list-item><list-item hwp:id="list-item-15"><p hwp:id="p-79">When a bird glides with its wings outstretched, its height (and therefore the 3D coordinates of the wingtips, the thorax point and the head) can be reconstructed in every frame without requiring any interpolation.</p></list-item><list-item hwp:id="list-item-16"><p hwp:id="p-80">Moving the camera to a different location does not require recalibration. 3D trajectories of birds can continue to be reconstructed with reference to the new optical axis of the camera and the new plane of the (internally stored) calibration grid, as long as the lines joining the wingtips of the bird at each wing extension are parallel to the plane of the calibration grid, as was the case during the original calibration. Thus, in principle, the camera that was calibrated in our experiments using the calibration grid on the floor, can also be used to reconstruct the trajectories of birds in outdoor flight by facing the camera upwards and performing the reconstruction relative to the same calibration grid. Trajectory reconstruction is possible even if a bird is located on the opposite side of the calibration grid – the geometry and interpolation underlying the reconstruction will be the same. This is a major attribute of the system, because - unlike systems that use stereo or multiple cameras – it does not need to be recalibrated every time it is moved to a new location.</p></list-item><list-item hwp:id="list-item-17"><p hwp:id="p-81">Because the method is computationally simple, it can be applied in closed-loop experimental paradigms in which visual stimuli need to be modified in real time in response to the bird’s flight, as is now being done with some animals (e.g. <xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">Stowers et al., 2017</xref>).</p></list-item><list-item hwp:id="list-item-18"><p hwp:id="p-82">The system is compact, portable, and easily deployed in the field.</p></list-item></list><p hwp:id="p-83">The limitations of the method are:</p><list list-type="roman-lower" hwp:id="list-3"><list-item hwp:id="list-item-19"><p hwp:id="p-84">We have assumed that the wings are fully extended at each extension, and that the tip-to-tip distance at these extensions is always equal to the measured wingspan. Variability in the wingtip distances from extension to extension (which may occur during certain manoeuvres) will introduce errors in the reconstruction of the 3D trajectory.</p></list-item><list-item hwp:id="list-item-20"><p hwp:id="p-85">The calibration grid on the floor grid must cover a sufficiently large area to enable projection of the wingtips on to the floor at all possible bird positions. This could be a problem when the bird is flying close to the ceiling or to one of the walls of the tunnel (or chamber), as it would require extrapolation of the grid beyond the floor of the chamber. Grid extrapolation can be carried out, but it requires assumptions to be made about the unknown optical distortions in the extrapolated regions of the grid. The calibration grid does not need to be on the floor: it can be in a parallel plane that is much closer to the camera – for example, a few centimetres away. In this case the grid can be considerably smaller, but must be large enough to span the entire visual field of the camera.</p></list-item><list-item hwp:id="list-item-21"><p hwp:id="p-86">The method requires selection of the <italic toggle="yes">Wex</italic> frames in the video sequence, determination of the pixel co-ordinates of the left and right wingtips in each of the <italic toggle="yes">Wex</italic> frames, and determination of the pixel co-ordinates of the head in each frame of the video sequence. While we have carried out all of these operations manually, they are tedious and time-consuming. Automated tracking and digitisation of the wingtips and the head in the video sequence can be incorporated as an additional ‘front end’ to the system, which we are currently exploring.</p></list-item><list-item hwp:id="list-item-22"><p hwp:id="p-87">The technique delivers true altitude measurements only at each full wing extension. Altitudes at the intermediate frames are obtained by linear (or spline-based) interpolation. These interpolated heights can be combined with the digitized image position of the head in each frame to obtain a continuous, frame-by-frame 3D trajectory of the bird’s head. It is important to note that the X and Y positions of the bird’s head are tracked and reconstructed by using new information from <italic toggle="yes">every</italic> frame. The results should be reasonably accurate, provided that the bird’s altitude varies smoothly between successive wing extensions. This is very likely to be the case in cruising flight, but may not apply during flight in densely cluttered environments which may entail abrupt changes of altitude as well as variations in the wing kinematics.</p></list-item></list><p hwp:id="p-88">Potential future applications of the method presented in this paper include:</p><list list-type="roman-lower" hwp:id="list-4"><list-item hwp:id="list-item-23"><p hwp:id="p-89">Tracking of birds in natural outdoor environments by using an upward-facing wide-angle camera, as discussed briefly above. The species of the bird would have to be known, however, in order to use an estimate of its wingspan.</p></list-item><list-item hwp:id="list-item-24"><p hwp:id="p-90">Reconstruction of 3D flight trajectories of airplanes. In such an application, the 3D coordinates of the airplane and its roll angle can be estimated in every frame without any need for interpolation, because the wingspan is constant (as in a gliding bird). Again, the model of the aircraft would need to be known or identified, in order to use an estimate of its wingspan.</p></list-item></list></sec><sec sec-type="supplementary-material" hwp:id="sec-12"><title hwp:id="title-15">Supporting information</title><supplementary-material position="float" orientation="portrait" hwp:id="DC1"><object-id pub-id-type="other" hwp:sub-type="slug">DC1</object-id><label>Supplementary Information file</label><media xlink:href="supplements/340232_file02.docx" position="float" orientation="portrait" hwp:id="media-1"/></supplementary-material></sec></body><back><ref-list hwp:id="ref-list-1"><title hwp:id="title-16">R<sc>eferences</sc></title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1"><citation publication-type="book" citation-type="book" ref:id="340232v2.1" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Bhagavatula P."><surname>Bhagavatula</surname>, <given-names>P.</given-names></string-name> (<year>2011</year>). <chapter-title>Visually guided flight in birds using the budgerigar (Melopsittacus undulatus) as a model system</chapter-title>. <source hwp:id="source-1">Ph.D</source>., <publisher-name>Australian National University</publisher-name>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Bouten W."><surname>Bouten</surname>, <given-names>W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Baaij E.W."><surname>Baaij</surname>, <given-names>E.W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Shamoun-Baranes J."><surname>Shamoun-Baranes</surname>, <given-names>J.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Camphuysen K.C.J."><surname>Camphuysen</surname>, <given-names>K.C.J.</given-names></string-name> (<year>2013</year>). <article-title hwp:id="article-title-2">A flexible GPS tracking system for studying bird behaviour at multiple scales</article-title>. <source hwp:id="source-2">Journal of Ornithology</source> <volume>154</volume>(<issue>2</issue>), <fpage>571</fpage>–<lpage>580</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s10336-012-0908-1</pub-id>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Cavagna A."><surname>Cavagna</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Giardina I."><surname>Giardina</surname>, <given-names>I.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Orlandi A."><surname>Orlandi</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Parisi G."><surname>Parisi</surname>, <given-names>G.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Procaccini A."><surname>Procaccini</surname>, <given-names>A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Viale M."><surname>Viale</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal> (<year>2008</year>). <article-title hwp:id="article-title-3">The STARFLAG handbook on collective animal behaviour: 1. Empirical methods</article-title>. <source hwp:id="source-3">Animal Behaviour</source> <volume>76</volume>, <fpage>217</fpage>–<lpage>236</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.anbehav.2008.02.002</pub-id>.</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Dakin R."><surname>Dakin</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fellows T.K."><surname>Fellows</surname>, <given-names>T.K.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Altshuler D.L."><surname>Altshuler</surname>, <given-names>D.L.</given-names></string-name> (<year>2016</year>). <article-title hwp:id="article-title-4">Visual guidance of forward flight in hummingbirds reveals control based on image features instead of pattern velocity</article-title>. <source hwp:id="source-4">Proceedings of the National Academy of Sciences of the United States of America</source> <volume>113</volume>(<issue>31</issue>), <fpage>8849</fpage>–<lpage>8854</lpage>. doi: <pub-id pub-id-type="doi">10.1073/pnas.1603221113</pub-id>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="de Margerie E."><surname>de Margerie</surname>, <given-names>E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Simonneau M."><surname>Simonneau</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Caudal J.P."><surname>Caudal</surname>, <given-names>J.P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Houdelier C."><surname>Houdelier</surname>, <given-names>C.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Lumineau S."><surname>Lumineau</surname>, <given-names>S.</given-names></string-name> (<year>2015</year>). <article-title hwp:id="article-title-5">3D tracking of animals in the field using rotational stereo videography</article-title>. <source hwp:id="source-5">Journal of Experimental Biology</source> <volume>218</volume>(<issue>16</issue>), <fpage>2496</fpage>–<lpage>2504</lpage>. doi: <pub-id pub-id-type="doi">10.1242/jeb.118422</pub-id>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Deetjen M.E."><surname>Deetjen</surname>, <given-names>M.E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Biewener A.A."><surname>Biewener</surname>, <given-names>A.A.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Lentink D."><surname>Lentink</surname>, <given-names>D.</given-names></string-name> (<year>2017</year>). <article-title hwp:id="article-title-6">High-speed surface reconstruction of a flying bird using structured light</article-title>. <source hwp:id="source-6">Journal of Experimental Biology</source> <volume>220</volume>(<issue>11</issue>), <fpage>1956</fpage>–<lpage>1961</lpage>. doi: <pub-id pub-id-type="doi">10.1242/jeb.149708</pub-id>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Fontaine E.I."><surname>Fontaine</surname>, <given-names>E.I.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zabala F."><surname>Zabala</surname>, <given-names>F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Dickinson M.H."><surname>Dickinson</surname>, <given-names>M.H.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Burdick J.W."><surname>Burdick</surname>, <given-names>J.W.</given-names></string-name> (<year>2009</year>). <article-title hwp:id="article-title-7">Wing and body motion during flight initiation in Drosophila revealed by automated visual tracking</article-title>. <source hwp:id="source-7">Journal of Experimental Biology</source> <volume>212</volume>(<issue>9</issue>), <fpage>1307</fpage>–<lpage>1323</lpage>. doi: <pub-id pub-id-type="doi">10.1242/jeb.025379</pub-id>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Frost B.J."><surname>Frost</surname>, <given-names>B.J.</given-names></string-name> (<year>2009</year>). <article-title hwp:id="article-title-8">Bird head stabilization</article-title>. <source hwp:id="source-8">Curr Biol</source> <volume>19</volume>(<issue>8</issue>), <fpage>R315</fpage>–<lpage>316</lpage>. doi: S0960-9822(09)00668-X [pii] <pub-id pub-id-type="doi">10.1016/j.cub.2009.02.002</pub-id>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Goller B."><surname>Goller</surname>, <given-names>B.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Altshuler D.L."><surname>Altshuler</surname>, <given-names>D.L.</given-names></string-name> (<year>2014</year>). <article-title hwp:id="article-title-9">Hummingbirds control hovering flight by stabilizing visual motion</article-title>. <source hwp:id="source-9">Proceedings of the National Academy of Sciences of the United States of America</source> <volume>111</volume>(<issue>51</issue>), <fpage>18375</fpage>–<lpage>18380</lpage>. doi: <pub-id pub-id-type="doi">10.1073/pnas.1415975111</pub-id>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><citation publication-type="book" citation-type="book" ref:id="340232v2.10" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Hartley R."><surname>Hartley</surname>, <given-names>R.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Zisserman A."><surname>Zisserman</surname>, <given-names>A.</given-names></string-name> (<year>2003</year>). <source hwp:id="source-10">Multiple View Geometry in Computer Vision</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Cambridge University Press</publisher-name>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Hedrick T.L."><surname>Hedrick</surname>, <given-names>T.L.</given-names></string-name> (<year>2008</year>). <article-title hwp:id="article-title-10">Software techniques for two-and three-dimensional kinematic measurements of biological and biomimetic systems</article-title>. <source hwp:id="source-11">Bioinspiration &amp; Biomimetics</source> <volume>3</volume>(<issue>3</issue>). doi: Artn 034001 <pub-id pub-id-type="doi">10.1088/1748-3182/3/3/034001</pub-id>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1 xref-ref-12-2"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.12" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Jackson B.E."><surname>Jackson</surname>, <given-names>B.E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Evangelista D.J."><surname>Evangelista</surname>, <given-names>D.J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Ray D.D."><surname>Ray</surname>, <given-names>D.D.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Hedrick T.L."><surname>Hedrick</surname>, <given-names>T.L.</given-names></string-name> (<year>2016</year>). <article-title hwp:id="article-title-11">3D for the people: multi-camera motion capture in the field with consumer-grade cameras and open source software</article-title>. <source hwp:id="source-12">Biology Open</source> <volume>5</volume>(<issue>9</issue>), <fpage>1334</fpage>–<lpage>1342</lpage>. doi: <pub-id pub-id-type="doi">10.1242/bio.018713</pub-id>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Macfarlane N.B.W."><surname>Macfarlane</surname>, <given-names>N.B.W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Howland J.C."><surname>Howland</surname>, <given-names>J.C.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jensen F.H."><surname>Jensen</surname>, <given-names>F.H.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Tyack P.L."><surname>Tyack</surname>, <given-names>P.L.</given-names></string-name> (<year>2015</year>). <article-title hwp:id="article-title-12">A 3D stereo camera system for precisely positioning animals in space and time</article-title>. <source hwp:id="source-13">Behavioral Ecology and Sociobiology</source> <volume>69</volume>(<issue>4</issue>), <fpage>685</fpage>–<lpage>693</lpage>. doi: <pub-id pub-id-type="doi">10.1007/s00265-015-1890-4</pub-id>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1 xref-ref-14-2"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Ros I.G."><surname>Ros</surname>, <given-names>I.G.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bhagavatula P.S."><surname>Bhagavatula</surname>, <given-names>P.S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Lin H.T."><surname>Lin</surname>, <given-names>H.T.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Biewener A.A."><surname>Biewener</surname>, <given-names>A.A.</given-names></string-name> (<year>2017</year>). <article-title hwp:id="article-title-13">Rules to fly by: pigeons navigating horizontal obstacles limit steering by selecting gaps most aligned to their flight direction</article-title>. <source hwp:id="source-14">Interface Focus</source> <volume>7</volume>(<issue>1</issue>). doi: ARTN 20160093 <pub-id pub-id-type="doi">10.1098/rsfs.2016.0093</pub-id>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1 xref-ref-15-2"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.15" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Schiffner I."><surname>Schiffner</surname>, <given-names>I.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Vo H.D."><surname>Vo</surname>, <given-names>H.D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bhagavatula P.S."><surname>Bhagavatula</surname>, <given-names>P.S.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Srinivasan M.V."><surname>Srinivasan</surname>, <given-names>M.V.</given-names></string-name> (<year>2014</year>). <article-title hwp:id="article-title-14">Minding the gap: in-flight body awareness in birds</article-title>. <source hwp:id="source-15">Frontiers in Zoology</source> <volume>11</volume>. doi: ARTN 64 <pub-id pub-id-type="doi">10.1186/s12983-014-0064-y</pub-id>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Shelton R.M."><surname>Shelton</surname>, <given-names>R.M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jackson B.E."><surname>Jackson</surname>, <given-names>B.E.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Hedrick T.L."><surname>Hedrick</surname>, <given-names>T.L.</given-names></string-name> (<year>2014</year>). <article-title hwp:id="article-title-15">The mechanics and behavior of cliff swallows during tandem flights</article-title>. <source hwp:id="source-16">Journal of Experimental Biology</source> <volume>217</volume>(<issue>15</issue>), <fpage>2717</fpage>–<lpage>2725</lpage>. doi: <pub-id pub-id-type="doi">10.1242/jeb.101329</pub-id>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Srinivasan M.V."><surname>Srinivasan</surname>, <given-names>M.V.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Zhang S.W."><surname>Zhang</surname>, <given-names>S.W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Chahl J.S."><surname>Chahl</surname>, <given-names>J.S.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Barth E."><surname>Barth</surname>, <given-names>E.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Venkatesh S."><surname>Venkatesh</surname>, <given-names>S.</given-names></string-name> (<year>2000</year>). <article-title hwp:id="article-title-16">How honeybees make grazing landings on flat surfaces</article-title>. <source hwp:id="source-17">Biological Cybernetics</source> <volume>83</volume>(<issue>3</issue>), <fpage>171</fpage>–<lpage>183</lpage>.</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Stowers J.R."><surname>Stowers</surname>, <given-names>J.R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hofbauer M."><surname>Hofbauer</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bastien R."><surname>Bastien</surname>, <given-names>R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Greissner J."><surname>Greissner</surname>, <given-names>J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Higgins P."><surname>Higgins</surname>, <given-names>P.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Farooqui S."><surname>Farooqui</surname>, <given-names>S.</given-names></string-name>, <etal>et al.</etal> (<year>2017</year>). <article-title hwp:id="article-title-17">Virtual reality for freely moving animals</article-title>. <source hwp:id="source-18">Nature Methods</source>. doi: <pub-id pub-id-type="doi">10.1038/nmeth.4399</pub-id>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Straw A.D."><surname>Straw</surname>, <given-names>A.D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Branson K."><surname>Branson</surname>, <given-names>K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Neumann T.R."><surname>Neumann</surname>, <given-names>T.R.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Dickinson M.H."><surname>Dickinson</surname>, <given-names>M.H.</given-names></string-name> (<year>2011</year>). <article-title hwp:id="article-title-18">Multi-camera real-time three-dimensional tracking of multiple flying animals</article-title>. <source hwp:id="source-19">Journal of the Royal Society Interface</source> <volume>8</volume>(<issue>56</issue>), <fpage>395</fpage>–<lpage>409</lpage>. doi: <pub-id pub-id-type="doi">10.1098/rsif.2010.0230</pub-id>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Theriault D.H."><surname>Theriault</surname>, <given-names>D.H.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Fuller N.W."><surname>Fuller</surname>, <given-names>N.W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Jackson B.E."><surname>Jackson</surname>, <given-names>B.E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bluhm E."><surname>Bluhm</surname>, <given-names>E.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Evangelista D."><surname>Evangelista</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Wu Z."><surname>Wu</surname>, <given-names>Z.</given-names></string-name>, <etal>et al.</etal> (<year>2014</year>). <article-title hwp:id="article-title-19">A protocol and calibration method for accurate multi-camera field videography</article-title>. <source hwp:id="source-20">Journal of Experimental Biology</source> <volume>217</volume>(<issue>11</issue>), <fpage>1843</fpage>–<lpage>1848</lpage>. doi: <pub-id pub-id-type="doi">10.1242/jeb.100529</pub-id>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Tobalske B.W."><surname>Tobalske</surname>, <given-names>B.W.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Dial K.B."><surname>Dial</surname>, <given-names>K.B.</given-names></string-name> (<year>1996</year>). <article-title hwp:id="article-title-20">Flight kinematics of black-billed magpies and pigeons over a wide range of speeds</article-title>. <source hwp:id="source-21">Journal of Experimental Biology</source> <volume>199</volume>, <fpage>263</fpage>–<lpage>280</lpage>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Tobalske B.W."><surname>Tobalske</surname>, <given-names>B.W.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Warrick D.R."><surname>Warrick</surname>, <given-names>D.R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Clark C.J."><surname>Clark</surname>, <given-names>C.J.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Powers D.R."><surname>Powers</surname>, <given-names>D.R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hedrick T.L."><surname>Hedrick</surname>, <given-names>T.L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hyder G.A."><surname>Hyder</surname>, <given-names>G.A.</given-names></string-name>, <etal>et al.</etal> (<year>2007</year>). <article-title hwp:id="article-title-21">Three-dimensional kinematics of hummingbird flight</article-title>. <source hwp:id="source-22">Journal of Experimental Biology</source> <volume>210</volume>(<issue>13</issue>), <fpage>2368</fpage>–<lpage>2382</lpage>. doi: <pub-id pub-id-type="doi">10.1242/jeb.005686</pub-id>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1 xref-ref-23-2"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Troje N.F."><surname>Troje</surname>, <given-names>N.F.</given-names></string-name> (<year>2002</year>). <article-title hwp:id="article-title-22">Decomposing biological motion: A framework for analysis and synthesis of human gait patterns</article-title>. <source hwp:id="source-23">Journal of Vision</source> <volume>2</volume>(<issue>5</issue>), <fpage>371</fpage>–<lpage>387</lpage>. doi: <pub-id pub-id-type="doi">10.1167/2.5.2</pub-id>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1 xref-ref-24-2 xref-ref-24-3"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Vo H.D."><surname>Vo</surname>, <given-names>H.D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schiffner I."><surname>Schiffner</surname>, <given-names>I.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Srinivasan M.V."><surname>Srinivasan</surname>, <given-names>M.V.</given-names></string-name> (<year>2016</year>). <article-title hwp:id="article-title-23">Anticipatory Manoeuvres in Bird Flight</article-title>. <source hwp:id="source-24">Scientific Reports</source> <volume>6</volume>. doi: ARTN 27591 <pub-id pub-id-type="doi">10.1038/srep27591</pub-id>.</citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Warrick D.R."><surname>Warrick</surname>, <given-names>D.R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Bundle M.W."><surname>Bundle</surname>, <given-names>M.W.</given-names></string-name>, and <string-name name-style="western" hwp:sortable="Dial K.P."><surname>Dial</surname>, <given-names>K.P.</given-names></string-name> (<year>2002</year>). <article-title hwp:id="article-title-24">Bird maneuvering flight: blurred bodies, clear heads</article-title>. <source hwp:id="source-25">Integr Comp Biol</source> <volume>42</volume>(<issue>1</issue>), <fpage>141</fpage>–<lpage>148</lpage>. doi: <pub-id pub-id-type="doi">10.1093/icb/42.1.141</pub-id>.</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1"><citation publication-type="journal" citation-type="journal" ref:id="340232v2.26" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Zeil J."><surname>Zeil</surname>, <given-names>J.</given-names></string-name> (<year>1993</year>). <article-title hwp:id="article-title-25">Orientation Flights of Solitary Wasps (Cerceris, Sphecidae, Hymenoptera) .1. Description of Flight</article-title>. <source hwp:id="source-26">Journal of Comparative Physiology a-Sensory Neural and Behavioral Physiology</source> <volume>172</volume>(<issue>2</issue>), <fpage>189</fpage>-<lpage>205</lpage>. doi: Doi <pub-id pub-id-type="doi">10.1007/Bf00189396</pub-id>.</citation></ref></ref-list><ack hwp:id="ack-1"><title hwp:id="title-17">Acknowledgements</title><p hwp:id="p-91">This work was funded by the ARC Centre of Excellence in Vision Science (Grant CEO561903), ARC Discovery Grant DP 110103277, a Human Frontiers in Science Grant RGP0003/2013, a Queensland Premier’s Fellowship, and an ARC Distinguished Outstanding Researcher Award (DP140100914) to MVS.</p></ack><sec id="s5" hwp:id="sec-13"><title hwp:id="title-18">Author contributions</title><p hwp:id="p-92"><italic toggle="yes">MVS:</italic> Conceptualization, data analysis, modeling and writing</p><p hwp:id="p-93"><italic toggle="yes">HD Vo:</italic> Conduct of experiments, data collection and analysis, and writing</p><p hwp:id="p-94"><italic toggle="yes">I Schiffner:</italic> Conduct of experiments, data collection and analysis, and writing</p></sec></back></article>
