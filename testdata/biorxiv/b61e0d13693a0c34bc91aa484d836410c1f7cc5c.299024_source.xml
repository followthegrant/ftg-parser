<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/299024</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;299024</article-id><article-id pub-id-type="other" hwp:sub-type="slug">299024</article-id><article-id pub-id-type="other" hwp:sub-type="tag">299024</article-id><article-version>1.1</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Neuroscience" hwp:journal="biorxiv"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">word2brain</article-title></title-group><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-4955-9150</contrib-id><name name-style="western" hwp:sortable="Nunes Abraham"><surname>Nunes</surname><given-names>Abraham</given-names></name><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-4955-9150"/></contrib><aff hwp:id="aff-1"><institution hwp:id="institution-1">Faculty of Computer Science &amp; Department of Psychiatry Dalhousie University</institution>, Halifax, NS, <email hwp:id="email-1">nunes@dal.ca</email></aff></contrib-group><pub-date pub-type="epub-original" hwp:start="2018"><year>2018</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2018-04-11T02:27:28-07:00">
    <day>11</day><month>4</month><year>2018</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2018-04-11T02:27:28-07:00">
    <day>11</day><month>4</month><year>2018</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2018-04-11T02:32:50-07:00">
    <day>11</day><month>4</month><year>2018</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2018-04-11T02:32:50-07:00">
    <day>11</day><month>4</month><year>2018</year>
  </pub-date><elocation-id>299024</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2018-04-10"><day>10</day><month>4</month><year>2018</year></date>
<date date-type="rev-recd" hwp:start="2018-04-10"><day>10</day><month>4</month><year>2018</year></date>
<date date-type="accepted" hwp:start="2018-04-11"><day>11</day><month>4</month><year>2018</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2018, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2018</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="license-1"><p hwp:id="p-1">This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by-nc-nd/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></p></license></permissions><self-uri xlink:href="299024.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2019/pdf/299024v1.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="299024.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2019/abstracts/299024v1/299024v1.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2019/fulltext/299024v1/299024v1.htslp"/><abstract hwp:id="abstract-1"><title hwp:id="title-1">Abstract</title><p hwp:id="p-2">Mapping brain functions to their underlying neural substrates is a central goal of cognitive neuroscience. Functional magnetic resonance imaging (fMRI) has proven indispensable in this endeavour. Recently, there has been growing interest in tackling this problem by mapping semantic concepts onto brain regions using repositories of images and text from the neuroimaging literature. However, no study has thus far approached this problem using (dense) vector representations of words. Using data from the Neurosynth database, we sought to develop a model that could (A) capture local correlations between words in text, as well as topics, (B) capture representation of distributed brain networks in relation to word embeddings, and (C) generate synthetic images given word inputs. We show that jointly embedding words and brain imaging data on a vector space can yield semantic representations that sensibly relate concepts across biological, psychological, and observational levels of analysis. Moreover, our proposed model makes no assumption about spatial orientation of fMRI voxels, which allows for embedding of distributed brain networks onto the semantic space. We demonstrate this capability by generating synthetic brain activation vectors from word inputs. Our model has the potential to advance neuroimaging meta-analysis as well as contextual word-embedding methods more broadly.</p></abstract><counts><page-count count="18"/></counts></article-meta></front><body><sec id="s1" hwp:id="sec-1"><label>1</label><title hwp:id="title-2">Introduction</title><p hwp:id="p-3">The clinical neurosciences are relatively underdeveloped compared to specialties such as cardiology. The most important limiting factor is arguably that we have no working model of how psychological and behavioural phenomena are generated by underlying neural computations. Cardiologists can listen to the heart or look at imaging and identify the patient’s likely symptoms, and then tailor therapy or design research trials based on physiological reasoning. This is made possible by considering the circulatory system as an instance of a fluid-dynamical system driven by a pump. Since the heart’s function is mechanical, then observations of its mechanics can be directly input into a doctor’s internal model of the patient’s circulatory system, and consequences accurately predicted. But what of the brain? We know it is an information processing device, but a generalizable and consistent conceptual model that links neural function to behavioural output has remained elusive for all but the most simple motor and sensory functions.</p><p hwp:id="p-4">Functional magnetic resonance imaging (fMRI) has provided insights into the putative roles many brain regions; while some appear to serve relatively specific roles [<xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">Levy and Glimcher, 2012</xref>], others are ostensibly involved in many behavioural phenomena and illnesses [<xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">Goodkind et al., 2015</xref>, <xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">Stalnaker et al., 2015</xref>]. This mixture of redundancy and specificity have challenged our ability to develop coherent mechanistic models of brain function. Notwithstanding these problems, neuroscience holds as a core assumption that some mapping from neural activation space to that of behavioural function exists [<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">Churchland and Sejnowski, 1992</xref>].</p><p hwp:id="p-5">The difficulty in finding this mapping may be due in part to the constraint that individual studies necessarily approach a narrow aspect of brain/psychological function using subdomain-specific tools and terminology. Each fMRI research study thus provides a small amount of data to a sparsely populated corpus of cognitive neuroimaging literature. For this reason, it has been of great interest to pool data for meta-analysis. One such effort has been that of the Neurosynth database [<xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">Yarkoni et al., 2011</xref>], which has automated the extraction of fMRI activation maps from published literature, and linked these to respective studies’ abstracts. More specifically, each of the &gt;11,000 aggregated studies in the Neurosynth database has text from the study’s abstract, as well as <italic toggle="yes">xyz</italic> coordinates (in a standardized reference space) of fMRI activations. Such data are an important resource for the pursuit of a mapping between neural and psychological spaces.</p><p hwp:id="p-6">Indeed, the Nerosynth database begs the question of whether semantic content of research abstracts can be mapped onto brain imaging data from the respective studies. Several authors have approached this question, and we review their work in Subsection 2.1. We will show that there remain two limitations in the employed methods. The first is that the language models employed have been count based, rather than based on vector representations. The second is that these models have not been able to model brain networks (which are spatially distributed), jointly with the semantic representations.</p><p hwp:id="p-7">Thus, the present study seeks to learn a vector-representation of semantic concepts in the Neurosynth abstract database. In Subsection 2.2 we review a popular method for learning vector representations of words. In Subsection 2.3 we present a simple method for combining the vector-representations of words with neuroimaging data such that (A) a joint neural-linguistic vector representation is learned that (B) allows for representation of long-range brain-network activations in the semantic embedding space. We show that our method generates a sensible semantic embedding that sensibly relates concepts across biological, psychological, and observational levels of analysis.</p></sec><sec id="s2" hwp:id="sec-2"><label>2</label><title hwp:id="title-3">Background</title><sec id="s2a" hwp:id="sec-3"><label>2.1</label><title hwp:id="title-4">Previous Approaches to the Neurosynth Dataset</title><p hwp:id="p-8">Neurosynth was introduced by Yarkoni et al. [2011]. It is an open database summarizing data from &gt;11,000 fMRI studies. While there are many aspects to the Neurosynth repository, we focus on two elements. First, each study in the database is indexed by a PubMed identification number, which facilitates access to the study’s published abstract. Second, Neurosynth has parsed original articles for each study and extracted brain activation coordinates (corresponding to individual voxels in standardized reference spaces).</p><p hwp:id="p-9">There have been several approaches to modeling the relationship between sudies’ brain images and the language in their scientific abstracts. The first notable approach was that of Poldrack et al. [2012], who applied Latent Dirichlet Allocation (LDA; Blei et al. [2003]) to the abstract data and then correlated the inferred topic sets with the neural activation coordinates of constituent studies. In LDA, one assumes each document is a distribution over topics, and that each document is a distribution over words. Poldrack et al. [2012] first applied LDA to the text topics the corpus. To determine the association between topics and voxels, the authors performed a chi-square test for each voxel in a given study against a binary indicator of whether that study loaded onto a given topic. This model measured association between topic loading and voxel activation, but in the process necessarily lost generative capacity.</p><p hwp:id="p-10">An important limitation of this study was that they did not model activations jointly with the text. To address this, Rubin et al. [2016] later introduced Generalized-Correspondence Latent Dirichlet Allocation (GC-LDA), in which the topics in an LDA were defined as elliptical volumes in the brain (in the same <italic toggle="yes">xyz</italic> coordinates as the reported activations). The GC-LDA model thus defines brain volumes as probability distributions over words (i.e. those in abstracts of studies reporting neural activation coordinates), and documents as probability distributions over brain areas. Using deep restricted Boltzmann machines, Monti et al. [2016] also address this limitation by jointly modelling word counts with brain activation vectors.</p><p hwp:id="p-11">Although the GC-LDA and restricted Boltzmann machine approaches tackled the joint modeling of neural activations and psychological phenomena (insofar as the latter can be captured by words of abstract text), there are several important limitations. Both models—by virtue of using total word count— could not capture local context of individual words in an abstract. This is important because there may be individual semantic meanings found in different local contexts within an abstract. In addition, LDA is limited in its ability to capture correlations between topics, owing to the nature of the Dirichlet prior. This would, for example, limit our ability to note the high correlation between topics such as eating-related behaviours and addiction [<xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">Gearhardt and Potenza, 2013</xref>, <xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">Volkow et al., 2013</xref>, <xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">2017</xref>], unless they were included within a single topic. GC-LDA inherits LDA’s limitation with correlated topics. However, in this case it would preclude modeling of brain networks, since topics in GC-LDA are defined as contiguous (Gaussian) volumes. This is a significant limitation since it is likely that most psychological and behavioural functions of interest involve network-level computations [<xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">Petersen and Sporns, 2015</xref>, <xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">Sporns, 2013</xref>].</p></sec><sec id="s2b" hwp:id="sec-4" hwp:rev-id="xref-sec-4-1"><label>2.2</label><title hwp:id="title-5">The GloVe Algorithm and Vector Representations of Words</title><p hwp:id="p-12">Vector representations of words offer an important advantage over the whole-document bag of words models implemented in the prior approaches to Neurosynth. Specifically, vector representations model words in terms of how they are distributed in the context of other locally occurring tokens. This is particularly important for our domain of analysis. For instance, one expects to encounter the word “drug” often in neuroimaging literature, but its meaning will vary depending on whether it is in the context of the words “[drug] addiction” or “clinical [drug] trial.” The traditional topic models would suffer particularly in cases where a drug (medication) trial was being conducted for treatment of (illicit) drug addiction. Moreover, since neuroscience is a highly interdisciplinary field, one would expect to encounter multiple semantic concepts within a single abstract. While a detailed review of vector representations of words is beyond the scope of our paper, we focus on the <italic toggle="yes">Global Vectors for Word Representation</italic> (GloVe) model [<xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">Pennington et al., 2014</xref>], which we employ herein.</p><p hwp:id="p-13">The GloVe model was introduced by Pennington et al. [2014] by the justification that word co-occurrences provide the most meaningful source of information for unsupervised learning. Rather than implementing learning at each step of movement of a sliding window over the corpus, as in the word2vec models [<xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">Mikolov et al., 2013a</xref>,b], the GloVe model tallies the co-occurrence of words up front (within windows of a fixed size). It is with these co-occurrence tallies that the GloVe model’s word vectors are subsequently fit. Due to space constraints, we present only the highlights of their model relevant for implementation (the reader is directed to the original paper for full details and an interesting analysis).</p><p hwp:id="p-14">At the center of the GloVe model is a word co-occurrence matrix <inline-formula hwp:id="inline-formula-1"><alternatives hwp:id="alternatives-1"><inline-graphic xlink:href="299024_inline1.gif" hwp:id="inline-graphic-1"/></alternatives></inline-formula> where <italic toggle="yes">n</italic><sub><italic toggle="yes">v</italic></sub> is the size of the vocabulary.</p><p hwp:id="p-15">The entry <italic toggle="yes">x</italic><sub><italic toggle="yes">ij</italic></sub> of <bold>X</bold> denotes the number of times word <italic toggle="yes">i</italic> was encountered in the context of word <italic toggle="yes">j</italic>. We denote the set of all contexts in the corpus as <italic toggle="yes">C</italic>, the set of all contexts of word <italic toggle="yes">j</italic> as <italic toggle="yes">C</italic>(<italic toggle="yes">j</italic>), and a single <italic toggle="yes">instance</italic> of a context of word <italic toggle="yes">j</italic> as <italic toggle="yes">c</italic>(<italic toggle="yes">j</italic>). The co-occurrence matrix <bold>X</bold> is thus computed as
<disp-formula id="eqn1" hwp:id="disp-formula-1">
<alternatives hwp:id="alternatives-2"><graphic xlink:href="299024_eqn1.gif" position="float" orientation="portrait" hwp:id="graphic-1"/></alternatives>
</disp-formula>
where <italic toggle="yes"><bold>I</bold></italic>(·) is an indicator function taking a value of 1 if <italic toggle="yes">i</italic> is in the specific context <italic toggle="yes">c(j),</italic> and 0 otherwise. Letting <inline-formula hwp:id="inline-formula-2"><alternatives hwp:id="alternatives-3"><inline-graphic xlink:href="299024_inline2.gif" hwp:id="inline-graphic-2"/></alternatives></inline-formula> be the set defining our vocabulary, the total number of words co-occurring with <italic toggle="yes">j</italic> is thus
<disp-formula id="eqn2" hwp:id="disp-formula-2">
<alternatives hwp:id="alternatives-4"><graphic xlink:href="299024_eqn2.gif" position="float" orientation="portrait" hwp:id="graphic-2"/></alternatives>
</disp-formula>
and the probability of encountering word <italic toggle="yes">i</italic> given <italic toggle="yes">c</italic>(<italic toggle="yes">j</italic>) is
<disp-formula id="eqn3" hwp:id="disp-formula-3">
<alternatives hwp:id="alternatives-5"><graphic xlink:href="299024_eqn3.gif" position="float" orientation="portrait" hwp:id="graphic-3"/></alternatives>
</disp-formula></p><p hwp:id="p-16">Since the matrix <bold>X</bold> is symmetrical, we can simplify our notation by stating that <italic toggle="yes">P</italic>(<italic toggle="yes">i</italic>|<italic toggle="yes">c</italic>(<italic toggle="yes">j</italic>)) = <italic toggle="yes">P</italic>(<italic toggle="yes">i</italic>|<italic toggle="yes">j</italic>). Now considering two different words <italic toggle="yes">i</italic> and <italic toggle="yes">k,</italic> each of which may occur in the context <italic toggle="yes">c</italic>(<italic toggle="yes">j</italic>), we can define a ratio of the posterior probabilities of <italic toggle="yes">i</italic> and <italic toggle="yes">k</italic>, given <italic toggle="yes">j</italic>:
<disp-formula id="eqn4" hwp:id="disp-formula-4" hwp:rev-id="xref-disp-formula-4-1">
<alternatives hwp:id="alternatives-6"><graphic xlink:href="299024_eqn4.gif" position="float" orientation="portrait" hwp:id="graphic-4"/></alternatives>
</disp-formula>
which should be large if <italic toggle="yes">i</italic> is semantically more similar to <italic toggle="yes">j</italic> than <italic toggle="yes">k</italic>, and small when the opposite is true. In cases where <italic toggle="yes">i</italic> and <italic toggle="yes">k</italic> are semantically similar, then this ratio should approach 1. Pennington et al. [2014] define the goal of learning a parameterized function <italic toggle="yes">f</italic> (·) mapping from a space <inline-formula hwp:id="inline-formula-3"><alternatives hwp:id="alternatives-7"><inline-graphic xlink:href="299024_inline3.gif" hwp:id="inline-graphic-3"/></alternatives></inline-formula> of latent parameters to the space of these word co-occurrences. For the triad <italic toggle="yes">i, j, k</italic> from <xref ref-type="disp-formula" rid="eqn4" hwp:id="xref-disp-formula-4-1" hwp:rel-id="disp-formula-4">Equation 4</xref>, Pennington et al. [2014] specified the following general model:</p><disp-formula id="eqn5" hwp:id="disp-formula-5">
<alternatives hwp:id="alternatives-8"><graphic xlink:href="299024_eqn5.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives>
</disp-formula><p hwp:id="p-17">Assuming <italic toggle="yes">f</italic> (·) defines a structure-preserving mapping between the groups (ℝ, +) and (ℝ, ×) we can see that <inline-formula hwp:id="inline-formula-4"><alternatives hwp:id="alternatives-9"><inline-graphic xlink:href="299024_inline4.gif" hwp:id="inline-graphic-4"/></alternatives></inline-formula> and <italic toggle="yes">f</italic> (·) can be further refined to
<disp-formula hwp:id="disp-formula-6">
<alternatives hwp:id="alternatives-10"><graphic xlink:href="299024_ueqn1.gif" position="float" orientation="portrait" hwp:id="graphic-6"/></alternatives>
</disp-formula>
for which Pennington et al. [2014] identify a clear definition for <italic toggle="yes">f</italic> (·) as the exponential function. From this, we proceed to define the inner product term for <italic toggle="yes">i</italic> and <italic toggle="yes">j</italic>,
<disp-formula hwp:id="disp-formula-7">
<alternatives hwp:id="alternatives-11"><graphic xlink:href="299024_ueqn2.gif" position="float" orientation="portrait" hwp:id="graphic-7"/></alternatives>
</disp-formula>
which can be made easier to work with by (A) accounting for the log-sum term in a bias term <italic toggle="yes">b</italic><sub><italic toggle="yes">i</italic></sub>, and (B) adding a bias <inline-formula hwp:id="inline-formula-5"><alternatives hwp:id="alternatives-12"><inline-graphic xlink:href="299024_inline5.gif" hwp:id="inline-graphic-5"/></alternatives></inline-formula> corresponding to the context parameters <inline-formula hwp:id="inline-formula-6"><alternatives hwp:id="alternatives-13"><inline-graphic xlink:href="299024_inline6.gif" hwp:id="inline-graphic-6"/></alternatives></inline-formula>. The resulting model is
<disp-formula id="eqn6" hwp:id="disp-formula-8">
<alternatives hwp:id="alternatives-14"><graphic xlink:href="299024_eqn6.gif" position="float" orientation="portrait" hwp:id="graphic-8"/></alternatives>
</disp-formula>
which is trained as a weighted least squares model under the following loss function:
<disp-formula id="eqn7" hwp:id="disp-formula-9" hwp:rev-id="xref-disp-formula-9-1">
<alternatives hwp:id="alternatives-15"><graphic xlink:href="299024_eqn7.gif" position="float" orientation="portrait" hwp:id="graphic-9"/></alternatives>
</disp-formula>
where <bold>W</bold> ∈ ℝ<sup><italic toggle="yes">n</italic><sub><italic toggle="yes">v</italic></sub> × <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub></sup> and <inline-formula hwp:id="inline-formula-7"><alternatives hwp:id="alternatives-16"><inline-graphic xlink:href="299024_inline7.gif" hwp:id="inline-graphic-7"/></alternatives></inline-formula> are the target word and context embedding matrices, respectively, and <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub> is the dimensionality of the latent space. Pennington et al. [2014] implemented add-one smoothing to the logarithmic term and specified the weight function <italic toggle="yes">g</italic>(<italic toggle="yes">·</italic>) as follows:</p><disp-formula id="eqn8" hwp:id="disp-formula-10" hwp:rev-id="xref-disp-formula-10-1">
<alternatives hwp:id="alternatives-17"><graphic xlink:href="299024_eqn8.gif" position="float" orientation="portrait" hwp:id="graphic-10"/></alternatives>
</disp-formula><p hwp:id="p-18">In <xref ref-type="disp-formula" rid="eqn8" hwp:id="xref-disp-formula-10-1" hwp:rel-id="disp-formula-10">Equation 8</xref>, the parameters <italic toggle="yes">ξ</italic> and <italic toggle="yes">α</italic> are specified <italic toggle="yes">a priori</italic>. Since some word pairings will co-occur far more often than others, one truncates their influence by clipping <bold>X</bold> at the value of <italic toggle="yes">ξ</italic>. The parameter <italic toggle="yes">α</italic> controls the curvature of the weighting function below <italic toggle="yes">ξ</italic>. Pennington et al. [2014] set these parameters to <italic toggle="yes">ξ</italic> = 100 and <italic toggle="yes">α</italic> = 3/4, which we also use in our analysis.</p><p hwp:id="p-19">The strength of this model is that after training, the matrix <bold>W</bold> represents each word from the underlying corpus in a continuous <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub> dimensional space. Perhaps more importantly is that a coherent measure of distance—the dot product—exists between words embedded in this vector space.</p></sec><sec id="s2c" hwp:id="sec-5"><label>2.3</label><title hwp:id="title-6">Embedding Words on Brain Activations</title><p hwp:id="p-20">The GloVe method does not readily admit application to neuroimaging data. While one could forsee joint representation of neural activation coordinates in the space <inline-formula hwp:id="inline-formula-8"><alternatives hwp:id="alternatives-18"><inline-graphic xlink:href="299024_inline8.gif" hwp:id="inline-graphic-8"/></alternatives></inline-formula>, we propose a simpler approach.</p><p hwp:id="p-21">The brain imaging data for the <italic toggle="yes">d</italic><sup><italic toggle="yes">th</italic></sup> study in the Neurosynth dataset is a 228,453 × 1 binary vector <bold>m</bold><sup>(<italic toggle="yes">d</italic>)</sup>, where each unit is a voxel in the standardized Montreal Neurological Institute (MNI) space. We are interested in the degree to which words map onto individual voxels. We formulate this problem as follows.</p><p hwp:id="p-22">We are given a word vector for document <italic toggle="yes">d</italic>, which is the sum of all embedded words in that abstract, <inline-formula hwp:id="inline-formula-9"><alternatives hwp:id="alternatives-19"><inline-graphic xlink:href="299024_inline9.gif" hwp:id="inline-graphic-9"/></alternatives></inline-formula> and a brain activation vector <inline-formula hwp:id="inline-formula-10"><alternatives hwp:id="alternatives-20"><inline-graphic xlink:href="299024_inline10.gif" hwp:id="inline-graphic-10"/></alternatives></inline-formula>. Since it is binary, we can view the outer product m<sup><italic toggle="yes">(d)</italic></sup>w<sup><italic toggle="yes">(d)</italic></sup><sup>⊤</sup> as effectively modeling a a “gating” effect of m<sup>(<italic toggle="yes">d</italic>)</sup> on w<sup>(<italic toggle="yes">d</italic>)</sup>. That is, if element <inline-formula hwp:id="inline-formula-11"><alternatives hwp:id="alternatives-21"><inline-graphic xlink:href="299024_inline11.gif" hwp:id="inline-graphic-11"/></alternatives></inline-formula> is nonzero, but is multiplied against an inactive voxel <inline-formula hwp:id="inline-formula-12"><alternatives hwp:id="alternatives-22"><inline-graphic xlink:href="299024_inline12.gif" hwp:id="inline-graphic-12"/></alternatives></inline-formula> that component of the embedded word is nullified. Conversely, <inline-formula hwp:id="inline-formula-13"><alternatives hwp:id="alternatives-23"><inline-graphic xlink:href="299024_inline13.gif" hwp:id="inline-graphic-13"/></alternatives></inline-formula> and <inline-formula hwp:id="inline-formula-14"><alternatives hwp:id="alternatives-24"><inline-graphic xlink:href="299024_inline14.gif" hwp:id="inline-graphic-14"/></alternatives></inline-formula> is large, and this pairing is encountered across many documents, that would suggest that the <italic toggle="yes">j</italic><sup><italic toggle="yes">th</italic></sup> brain voxel has a strong influence the <italic toggle="yes">i</italic><sup><italic toggle="yes">th</italic></sup> component of the word embedding space.</p><p hwp:id="p-23">We compute an association matrix <bold>C</bold> ∈ ℝ<sup><italic toggle="yes">n</italic><sub><italic toggle="yes">m</italic></sub> × <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub></sup> by summing these outer products over all studies
<disp-formula id="eqn9" hwp:id="disp-formula-11">
<alternatives hwp:id="alternatives-25"><graphic xlink:href="299024_eqn9.gif" position="float" orientation="portrait" hwp:id="graphic-11"/></alternatives>
</disp-formula>
which we then submit to an (economical) singular value decomposition <bold>C</bold> = <bold>USV</bold><sup>⊤</sup>. This SVD is economical in the sense that U ∈ ℝ<sup><italic toggle="yes">n</italic><sub><italic toggle="yes">m</italic></sub> × <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub></sup> are the first <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub> eigenvectors of <bold>CC</bold><sup>⊤</sup>, <bold>V</bold> ∈ ℝ<sup><italic toggle="yes">n</italic><sub><italic toggle="yes">m</italic></sub> × <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub></sup> are the eigenvectors of <bold>C</bold><sup>⊤</sup><bold>C</bold>,and <bold>S</bold> is a diagonal matrix with the square roots of the first <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub> eigenvalues of both <bold>C</bold><sup>⊤</sup><bold>C</bold> and <bold>CC</bold><sup>⊤</sup>.</p><p hwp:id="p-24">While <xref ref-type="disp-formula" rid="eqn12" hwp:id="xref-disp-formula-14-1" hwp:rel-id="disp-formula-14">Equation 12</xref> computes <bold>C</bold> using document vectors, this is essentially a weighting of <bold>C</bold> by the number of times a given word was used in the corpus. Formally, consider a corpus of size <italic toggle="yes">n</italic><sub><italic toggle="yes">d</italic></sub>, where the <italic toggle="yes">d</italic><sup><italic toggle="yes">th</italic></sup> document consists of <italic toggle="yes">n</italic><sub><italic toggle="yes">t</italic></sub> ordered tokens (words) <inline-formula hwp:id="inline-formula-15"><alternatives hwp:id="alternatives-26"><inline-graphic xlink:href="299024_inline15.gif" hwp:id="inline-graphic-15"/></alternatives></inline-formula> then each word’s corresponding embedded representation is <inline-formula hwp:id="inline-formula-16"><alternatives hwp:id="alternatives-27"><inline-graphic xlink:href="299024_inline16.gif" hwp:id="inline-graphic-16"/></alternatives></inline-formula> which we denote as <inline-formula hwp:id="inline-formula-17"><alternatives hwp:id="alternatives-28"><inline-graphic xlink:href="299024_inline17.gif" hwp:id="inline-graphic-17"/></alternatives></inline-formula> We define the document vector as</p><disp-formula id="eqn10" hwp:id="disp-formula-12" hwp:rev-id="xref-disp-formula-12-1 xref-disp-formula-12-2">
<alternatives hwp:id="alternatives-29"><graphic xlink:href="299024_eqn10.gif" position="float" orientation="portrait" hwp:id="graphic-12"/></alternatives>
</disp-formula><p hwp:id="p-25">Substituting <xref ref-type="disp-formula" rid="eqn10" hwp:id="xref-disp-formula-12-1" hwp:rel-id="disp-formula-12">Equation 10</xref> into 12, we therefore see that</p><disp-formula id="eqn11" hwp:id="disp-formula-13">
<alternatives hwp:id="alternatives-30"><graphic xlink:href="299024_eqn11.gif" position="float" orientation="portrait" hwp:id="graphic-13"/></alternatives>
</disp-formula><disp-formula id="eqn12" hwp:id="disp-formula-14" hwp:rev-id="xref-disp-formula-14-1 xref-disp-formula-14-2">
<alternatives hwp:id="alternatives-31"><graphic xlink:href="299024_eqn12.gif" position="float" orientation="portrait" hwp:id="graphic-14"/></alternatives>
</disp-formula><p hwp:id="p-26">This approach is intuitively understood as involving two steps. First, the construction of <bold>C</bold> measures the movement of a vector in the word embedding space caused by activating a brain voxel (loosely speaking). In other words, one can think of brain activation patterns as warping the embedding space. One can view this warping as injection of real-world context into the semantic space. The second step of our approach is to calculate basis vectors for this joint neural-linguistic space, thereby “reshaping” it in a way that respects both the semantic relationshps between words, as well as those semantic relationships to the underlying substrate of their meaning: the brain’s activation patterns.</p><p hwp:id="p-27">In addition to the advantage of being able to capture the local context of words through GloVe, our proposed model consists only of linear operations. Consequently, it becomes easy to map between word vectors, document vectors, and brain activation vectors. This facilitates interpretability and computational efficiency. Despite linearity in operations, our model also advances on previous approaches to the Neurosynth dataset by being the first to reasonably account for distributed network-level brain activations jointly with semantic word representations.</p></sec></sec><sec id="s3" hwp:id="sec-6"><label>3</label><title hwp:id="title-7">Methods</title><p hwp:id="p-28">This section will guide the reader through the experimental workflow depicted in <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1</xref>. For parsimony, we describe details of the parameters for our implementations in Appendix A.</p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1:</label><caption hwp:id="caption-1"><p hwp:id="p-29">Methodological workflow. <italic toggle="yes">Symbols:</italic> association matrix <bold>C</bold>, which is the sum of outer products of each study’s neural activation vector and a document vector; neuroimaging activation matrix <bold>M</bold>, which carries a vector representation of the brain imaging data for each study; word embedding matrix <bold>W</bold>; matrix of document vectors (in rows) <bold>D</bold>. <italic toggle="yes">Abbreviations:</italic> functional magnetic resonance imaging (fMRI), singular value decomposition (SVD), t-distributed Stochastic Neighbour Embedding (t-SNE).</p></caption><graphic xlink:href="299024_fig1" position="float" orientation="portrait" hwp:id="graphic-15"/></fig><sec id="s3a" hwp:id="sec-7"><label>3.1</label><title hwp:id="title-8">Dataset</title><p hwp:id="p-30">Data were obtained using the neurosynth package<xref ref-type="fn" rid="fn1" hwp:id="xref-fn-1-1" hwp:rel-id="fn-1"><sup>1</sup></xref> for Python. Abstracts for 11,404 studies were downloaded. Preprocessing of abstract text was done using the nltk package in Python. Studies where neural activation coordinates were reported in an unknown space were removed (this included 1328 studies), leaving 10077 studies remaining. We first tokenized the abstracts into sentences, and then to words within sentences. Stop words and punctuation were removed, and text was converted to lower case. The original dataset included lists of authors; we removed names of the authors in cases where they appeared in an abstract of which they were an author. Other instances of names were left in place, since these may represent eponymous concepts such as “Wernicke” (an area of the brain, as well as a type of encephalopathy). Stopword and author name removal were done to reduce the dimensionality of word vectors, which are of the size of the vocabulary.</p><p hwp:id="p-31">We computed descriptive statistics for these data, including total word, unique word, and sentence counts, as well as means and quantiles for these variables across studies. We summarized the total number of brain activations and the distribution thereof in a similar fashion.</p></sec><sec id="s3b" hwp:id="sec-8"><label>3.2</label><title hwp:id="title-9">Embeddings and Decompositions Thereof</title><p hwp:id="p-32">For each of the 23,273 terms in the dataset, we created a co-occurrence matrix <bold>X</bold> ∈ ℝ<sup><italic toggle="yes">n</italic><sub><italic toggle="yes">v</italic></sub> × <italic toggle="yes">n</italic><sub><italic toggle="yes">v</italic></sub></sup>, where entry <italic toggle="yes">x</italic><sub><italic toggle="yes">ij</italic></sub> represents the number of times term <italic toggle="yes">i</italic> was encountered in the context of term <italic toggle="yes">j</italic>. We defined contexts as windows of 5 words. This was implemented using the skip-gram function in the Natural Language Toolkit (nltk) package, which extracted all bi-grams within the defined 5-word window; the co-occurrences defined by these bigrams were then tallied into <bold>X</bold>. We then computed a vector embedding of words <bold>W</bold> ∈ ℝ<sup><italic toggle="yes">n</italic><sub><italic toggle="yes">v</italic></sub> × <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub></sup>—where <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub> = 100 is the dimensionality of the embedding space—using the approach outlined in <xref ref-type="sec" rid="s2b" hwp:id="xref-sec-4-1" hwp:rel-id="sec-4">Section 2.2</xref>. Our implementation was built in TensorFlow v.1.5 [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">Abadi et al., 2015</xref>], wherein optimization of the loss function (<xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-9-1" hwp:rel-id="disp-formula-9">Equation 7</xref>) was done with stochastic gradient descent using the ADAM optimizer [<xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">Kingma and Ba, 2015</xref>].</p><p hwp:id="p-33">After obtaining word embeddings, we computed document vectors for each study (as shown in <xref ref-type="disp-formula" rid="eqn10" hwp:id="xref-disp-formula-12-2" hwp:rel-id="disp-formula-12">Equation 10</xref>) and concatenated these into a matrix <bold>D</bold> ∈ ℝ<sup><italic toggle="yes">n</italic><sub><italic toggle="yes">d</italic></sub> × <italic toggle="yes">n</italic><sub><italic toggle="yes">z</italic></sub>. With this matrix and the <italic toggle="yes">n</italic><sub><italic toggle="yes">m</italic></sub> × <italic toggle="yes">n</italic><sub><italic toggle="yes">d</italic></sub></sup> matrix of brain activations M, we then computed the joint linguistic-neural association matrix <bold>C</bold> as shown in <xref ref-type="disp-formula" rid="eqn12" hwp:id="xref-disp-formula-14-2" hwp:rel-id="disp-formula-14">Equation 12</xref>.</p><p hwp:id="p-34">The following singular value decomposition was performed on the word embedding matrix <bold>W</bold> (from the abstracts only):</p><disp-formula id="eqn13" hwp:id="disp-formula-15">
<alternatives hwp:id="alternatives-32"><graphic xlink:href="299024_eqn13.gif" position="float" orientation="portrait" hwp:id="graphic-16"/></alternatives>
</disp-formula><p hwp:id="p-35">The first two components of <bold>U</bold><sub><italic toggle="yes">w</italic></sub> represent the projection of word vectors onto a 2-dimensional latent space defined by the SVD. For the joint linguistic-neural association matrix <bold>C</bold>, we performed the following SVD
<disp-formula id="eqn14" hwp:id="disp-formula-16">
<alternatives hwp:id="alternatives-33"><graphic xlink:href="299024_eqn14.gif" position="float" orientation="portrait" hwp:id="graphic-17"/></alternatives>
</disp-formula>
which defined a latent space onto which we projected <bold>W</bold> through the eigenvectors of the word embedding dimension, <bold>V</bold><sub><italic toggle="yes">c</italic></sub>. The first two components of <bold>U</bold><sub><italic toggle="yes">c</italic></sub> define a mapping from the space of voxels to this 2-dimensional space.</p></sec><sec id="s3c" hwp:id="sec-9"><label>3.3</label><title hwp:id="title-10">Comparison of the Latent Spaces</title><p hwp:id="p-36">We seek to compare how words segregate when projected onto a coordinate system defined only by those words, here <bold>V</bold><sub><italic toggle="yes">w</italic></sub>, and when they are projected onto a coordinate system defined by both words and associated brain activity, here defined by <bold>V</bold><sub><italic toggle="yes">c</italic></sub>. To do this, we evaluated how well words in <bold>W</bold> clustered when projected onto each of these respective spaces. This was done using hierarchical clustering with Ward linkage. We repeated this procedure while varying the number of clusters between 2 and 20. Since we had no labels for clusters <italic toggle="yes">a priori,</italic> the clustering performance was measured according to the silhouette score [<xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">Rousseeuw, 1987</xref>]. The result with the highest silhouette score was accepted as the final clustering, and a visualization of the stratified embedding presented.</p><sec id="s3d" hwp:id="sec-10"><label>3.4</label><title hwp:id="title-11">Generating Synthetic Brain Images from Text</title><p hwp:id="p-37">We sought to evaluate the generative performance of our model by creating a function, <monospace>word2brain</monospace>, which takes a string of <italic toggle="yes">n</italic> words as an argument and generates a brain activation vector representing the hypothesized areas of activity given a description provided by those words. This was done by projecting the corresponding dense representation of each word supplied to the model onto the joint neural-linguistic embedding space, and subsequently projecting it back onto the <italic toggle="yes">n</italic><sub><italic toggle="yes">m</italic></sub> dimensional space of brain activation vectors. We visualize some examples using thresholded and unthresholded maps; the nilearn package [<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">Abraham et al., 2014</xref>] was implemented for this purpose. The thresholded maps were plotted to determine whether key areas, such as the nucleus accumbens in addiction, could be identified. Unthresholded maps were plotted in order to examine the model’s ability to capture the general network associated with a given set of input words. The dimensionality of the joint embedding space was restricted to 10 (i.e. the first 10 principal components), although more or less could be used.</p></sec><sec id="s3e" hwp:id="sec-11"><label>3.5</label><title hwp:id="title-12">Interactive Visualization</title><p hwp:id="p-38">After performing the above analyses, we projected the document vectors <bold>D</bold> onto the space defined by the joint linguistic-neural representation, and subsequently ran t-Stochastic Neighbour Embedding [<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">Van Der Maaten and Hinton, 2008</xref>]. The results were submitted to the hierarchical clustering procedure described above and visual-ized with the Bokeh package in Python [<xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">Bokeh Development Team, 2014</xref>]. An interactive version is available at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.abrahamnunes.com/plots/brainclusters/main.html" ext-link-type="uri" xlink:href="http://www.abrahamnunes.com/plots/brainclusters/main.html" hwp:id="ext-link-2">http://www.abrahamnunes.com/plots/brainclusters/main.html</ext-link>, where the reader can explore how different studies are distributed along the joint linguistic-neural manifold.</p></sec></sec></sec><sec id="s4" hwp:id="sec-12"><label>4</label><title hwp:id="title-13">Results</title><p hwp:id="p-39">We began by evaluating the descriptive statistics of the Neurosynth dataset, which we present in <xref rid="tbl1" ref-type="table" hwp:id="xref-table-wrap-1-1" hwp:rel-id="T1">Table 1</xref>. The vocab-ulary size in the present study was 23,273 and the total number of words in the corpus was 1,320,187. Each abstract had an average of 90 unique words (equal to median, 2.5th-97.5th quantiles=56.0-127.0; we use this quantile range henceforth). Each abstract had a mean of 8.8 sentences (median=9.0, 5.0-14.0), amounting to a total 88,669 sentences over the dataset. There were a total of 33,035,837 activated voxels reported in the dataset (i.e. number of non-zero elements of the matrix M). The average number of these entries for a given study was 3728.34 and ranged between 245.0 and 11440.5 (2.5% and 97.5% quartiles, respectively).</p><table-wrap id="tbl1" orientation="portrait" position="float" hwp:id="T1" hwp:rev-id="xref-table-wrap-1-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/TBL1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T1</object-id><object-id pub-id-type="publisher-id">tbl1</object-id><label>Table 1:</label><caption hwp:id="caption-2"><p hwp:id="p-40">Descriptive statistics for the Neurosynth Dataset. * Those studies reporting activations in an unidentified coordinate system were excluded (N=1328). <italic toggle="yes">Abbreviations:</italic> Montreal Neurological Institute (MNI)</p></caption><graphic xlink:href="299024_tbl1" position="float" orientation="portrait" hwp:id="graphic-18"/></table-wrap><sec id="s4a" hwp:id="sec-13"><label>4.1</label><title hwp:id="title-14">Structure of the Embedding Space</title><p hwp:id="p-41">The results of hierarchical clustering on words projected onto the principal components of <bold>W</bold> and <bold>C</bold> are presented in <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2</xref>. The best clustering performance was demonstrated by projection of words onto a space defined by the first two principal components of the joint neural-linguistic association matrix (silhouette score=0.46 for 2 cluster solution). We plot the projections in <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figures 3</xref>, <xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-1" hwp:rel-id="F4">4</xref>, and <xref rid="fig5" ref-type="fig" hwp:id="xref-fig-5-1" hwp:rel-id="F5">5</xref>. These figures show that defining the semantic manifold with input from the brain activation vectors enhances the quality of semantic clusters on both quantitative (as per <xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2</xref>) and qualitative grounds (as evinced through exploration of the embeddings). This is further supported by the data shown in <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-1" hwp:rel-id="F6">Figure 6</xref>, which shows how the 100-dimensional axes in the original space of <bold>W</bold> project onto the first two principal axes of C, in comparison to their projection onto the principal components of <bold>W</bold> alone.</p><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2:</label><caption hwp:id="caption-3"><p hwp:id="p-42">Silhouette scores computed for varying numbers of proposed clusters using (A) words projected onto a decomposition of the word embedding matrix <bold>W</bold> alone, shown with grey bars, and (B) a decomposition of the joint neural-linguistic association matrix, shown with black bars.</p></caption><graphic xlink:href="299024_fig2" position="float" orientation="portrait" hwp:id="graphic-19"/></fig><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3:</label><caption hwp:id="caption-4"><p hwp:id="p-43">These are two plots of the projection of word vectors onto their first 2 principal components. Each point is a single word. The blue and orange colouring corresponds to the best-fit clusters on this space. We have highlighted the co-location of several words in the main clusters. Note that they lack semantic similar-ity, and also seem to have few brain related words. An interactive version of this visualization can be found at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://abrahamnunes.com/plots/brainclusters/main.html" ext-link-type="uri" xlink:href="http://abrahamnunes.com/plots/brainclusters/main.html" hwp:id="ext-link-3">http://abrahamnunes.com/plots/brainclusters/main.html</ext-link>.</p></caption><graphic xlink:href="299024_fig3" position="float" orientation="portrait" hwp:id="graphic-20"/></fig><fig id="fig4" position="float" fig-type="figure" orientation="portrait" hwp:id="F4" hwp:rev-id="xref-fig-4-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4:</label><caption hwp:id="caption-5"><p hwp:id="p-44">These are two plots of the projection of word vectors onto the first 2 principal components defined by the joint neural-linguistic association matrix <bold>C</bold>. Each point is a single word. The blue and orange colouring corresponds to the best-fit clusters on this space. We have highlighted the co-location of several words in the main clusters. Compare these results to those of <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Figure 3</xref>. Here, to the far left, we see that the two most extreme words in that direction are “brain” and “activity,” which are arguably the most obviously related words for fMRI research. Conversely, in the orange cluster, we see several words that are ostensibly unrelated to neuroimaging (although we show “pharmacoimaging” as an example here of one potential erroneous projection). <ext-link l:rel="related" l:ref-type="uri" l:ref="http://abrahamnunes.com/plots/brainclusters/main.html" ext-link-type="uri" xlink:href="http://abrahamnunes.com/plots/brainclusters/main.html" hwp:id="ext-link-4">http://abrahamnunes.com/plots/brainclusters/main.html</ext-link>.</p></caption><graphic xlink:href="299024_fig4" position="float" orientation="portrait" hwp:id="graphic-21"/></fig><fig id="fig5" position="float" fig-type="figure" orientation="portrait" hwp:id="F5" hwp:rev-id="xref-fig-5-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/FIG5</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F5</object-id><object-id pub-id-type="publisher-id">fig5</object-id><label>Figure 5:</label><caption hwp:id="caption-6"><p hwp:id="p-45">These are two plots of the projection of word vectors onto the first 2 principal components defined by the joint neural-linguistic association matrix <bold>C</bold>. Each point is a single word. The blue and orange colouring corresponds to the best-fit clusters on this space. We have highlighted the co-location of several words in the main clusters. Compare these results to those of <xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Figure 3</xref>. Here, we see that our model has captured one of the most famous findings in functional neuroimaging, which is the relationship between the ventromedial prefrontal cortex (vmpfc) and value [<xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-2" hwp:rel-id="ref-10">Levy and Glimcher, 2012</xref>], along with major depressive disorder (mdd), and negativity (ostensibly negativity in value!). We also see that words related to language co-locate to the lower left. <ext-link l:rel="related" l:ref-type="uri" l:ref="http://abrahamnunes.com/plots/brainclusters/main.html" ext-link-type="uri" xlink:href="http://abrahamnunes.com/plots/brainclusters/main.html" hwp:id="ext-link-5">http://abrahamnunes.com/plots/brainclusters/main.html</ext-link>.</p></caption><graphic xlink:href="299024_fig5" position="float" orientation="portrait" hwp:id="graphic-22"/></fig><fig id="fig6" position="float" fig-type="figure" orientation="portrait" hwp:id="F6" hwp:rev-id="xref-fig-6-1 xref-fig-6-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/FIG6</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F6</object-id><object-id pub-id-type="publisher-id">fig6</object-id><label>Figure 6:</label><caption hwp:id="caption-7"><p hwp:id="p-46">The principal components of the 100-dimensional embedding space. The uppermost row of plots represents the embedding space of words alone, whereas the bottom four plots show the space for a representation learned from decomposition of a joint neural-linguistic association matrix <bold>C</bold>. In each plot, we projected a word onto the defined space, and coloured each point according to how aligned that word is with that dimension of the embedding. Yellow indicates positive correlation, while dark blue denotes anticorrelation with a given direction.</p></caption><graphic xlink:href="299024_fig6" position="float" orientation="portrait" hwp:id="graphic-23"/></fig><p hwp:id="p-47">The plot of <xref rid="fig6" ref-type="fig" hwp:id="xref-fig-6-2" hwp:rel-id="F6">Figure 6</xref> indeed shows that the brain activation data reshape the word embedding space to segregate brain-related and non-brain related words. However, it is clear that beyond spreading along the first principal component, there is a further separation of semantic concepts along the second component. Moreover, this spread appears predom-inant in the brain-related words. To investigate this further, we projected (A) the brain activation matrix <bold>M</bold> and (B) the embedded words <bold>W</bold> onto the first two principal components of <bold>C</bold>. We plot each of the voxels as a point on the scatter plots of <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-1" hwp:rel-id="F7">Figure 7</xref>. The projection of words onto this same space is represented by the dot colour, where red indicates that the word vector is oriented in the same direction as the voxels denoted by those points.</p><fig id="fig7" position="float" fig-type="figure" orientation="portrait" hwp:id="F7" hwp:rev-id="xref-fig-7-1 xref-fig-7-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/FIG7</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F7</object-id><object-id pub-id-type="publisher-id">fig7</object-id><label>Figure 7:</label><caption hwp:id="caption-8"><p hwp:id="p-48">Projection of brain voxels onto the joint neural-linguistic space defined by the decomposition of <bold>C</bold>. Each plot shows the correlation of the projection of a word from our corpus onto this space. Note that the effect of the brain voxels is to further separate the semantic space ostensibly into emotional and unemotional domains.</p></caption><graphic xlink:href="299024_fig7" position="float" orientation="portrait" hwp:id="graphic-24"/></fig><fig id="fig8" position="float" fig-type="figure" orientation="portrait" hwp:id="F8"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/FIG8</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F8</object-id><object-id pub-id-type="publisher-id">fig8</object-id><label>Figure 8:</label><caption hwp:id="caption-9"><p hwp:id="p-49">Activation maps synthesized from our model given the inputs of three words. The left column shows thresholded statistical maps centered at (from top to bottom) the nucleus accumbens, the amygdala, and the hippocampus. The right column shows unthresholded statistical maps, where deeper red indicates greater association, and blue rep-resents anticorrelation.</p></caption><graphic xlink:href="299024_fig8" position="float" orientation="portrait" hwp:id="graphic-25"/></fig></sec><sec id="s4b" hwp:id="sec-14"><label>4.2</label><title hwp:id="title-15">Generating Brain Images from Word Vectors</title><p hwp:id="p-50">The data in <xref rid="fig7" ref-type="fig" hwp:id="xref-fig-7-2" hwp:rel-id="F7">Figure 7</xref> suggest that some semantic mapping between word vectors and activity at brain voxels may exist. We therefore asked whether supplying a set of words to our model—that is, passing these words through the embedding space and onto the space of brain activation vectors—could generate statistical activation maps that correspond sensibly with known neurobiological relationships. Indeed, we found this to be the case. Some examples of these generated images are shown in <xref rid="fig9" ref-type="fig" hwp:id="xref-fig-9-1" hwp:rel-id="F9">Figure 9</xref>.</p><fig id="fig9" position="float" fig-type="figure" orientation="portrait" hwp:id="F9" hwp:rev-id="xref-fig-9-1 xref-fig-9-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/FIG9</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F9</object-id><object-id pub-id-type="publisher-id">fig9</object-id><label>Figure 9:</label><caption hwp:id="caption-10"><p hwp:id="p-51">Examples of study coordinates on the joint linguistic-neural embedding space. Due to file size limita-tions, we show only two instances here. Further exploration of an interactive version of this plot can be done at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.abrahamnunes.com/plots/brainclusters/main.html" ext-link-type="uri" xlink:href="http://www.abrahamnunes.com/plots/brainclusters/main.html" hwp:id="ext-link-6">http://www.abrahamnunes.com/plots/brainclusters/main.html</ext-link>.</p></caption><graphic xlink:href="299024_fig9" position="float" orientation="portrait" hwp:id="graphic-26"/></fig></sec><sec id="s4c" hwp:id="sec-15"><label>4.3</label><title hwp:id="title-16">Clustering of the Neuroimaging Literature</title><p hwp:id="p-52">We projected the document vectors onto the joint neural-linguistic space, and further performed t-SNE in order to enhance visualization of those data. We show examples in <xref rid="fig9" ref-type="fig" hwp:id="xref-fig-9-2" hwp:rel-id="F9">Figure 9</xref>, and provide an interactive example at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.abrahamnunes.com/plots/brainclusters/main.html" ext-link-type="uri" xlink:href="http://www.abrahamnunes.com/plots/brainclusters/main.html" hwp:id="ext-link-7">http://www.abrahamnunes.com/plots/brainclusters/main.html</ext-link>.</p></sec></sec><sec id="s5" hwp:id="sec-16"><label>5</label><title hwp:id="title-17">Discussion</title><p hwp:id="p-53">We have shown that word embeddings combined with brain activation data can provide meaningful and interesting representations of semantic information in the cognitive neuroscience literature. Moreover, these representations are sufficiently powerful to generate hypothetical brain activation patterns given a set of input words. Our study makes important contributions both to research about the cognitive neuroscience domain, as well as to research on word embeddings.</p><p hwp:id="p-54">First, we have shown that meaningful semantic relationships in neuroimaging research abstracts are suitable for vector space representations. This contributes to the body of knowledge for which Poldrack et al. [2012], Rubin et al. [2016], Alhazmi et al. [2017], Monti et al. [2016] and others have laid a foundation. Specifically, the existing approaches have been based on count based representations of words, which could not account for correlations between words in a local context, and in the case of LDA could not account for topic level correlations. In terms of the GC-LDA model of Rubin et al. [2016]—where topics were defined as brain volumes—this would preclude modeling network effects, since the topics were contiguous brain regions. While our GloVe-based approach bears some resemblance to latent semantic analysis [<xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-2" hwp:rel-id="ref-14">Pennington et al., 2014</xref>], which was applied to Neurosynth by Alhazmi et al. [2017], that study, too, considered a single document as a bag of words. Our method introduces one important difference (with respect to the language model), which is that a document is considered to be a sum of vectors in a vector space within which correlation between individual words can be captured.</p><p hwp:id="p-55">There may be an interesting geometrical interpretation of why the vector space model works well in comparison to count-based methods. From the perspective of defining a manifold onto which neuroimaging activation vectors can be projected, the whole-document bag of words representation assumes that space to be separable along axes defined by each unique token. Geometrically, one can think about a set of <italic toggle="yes">k</italic> words defining <italic toggle="yes">k</italic> fixed search directions in some “true” semantic space Ω ⊂ ℝ<sup>|Ω|</sup> with dimensionality |Ω|. We assume that brain activation vectors are—in the ground truth—projected by some mapping onto Ω, and the goal of analyses such as ours and those of Alhazmi et al. [2017], Poldrack et al. [2012], and Rubin et al. [2016] is, loosely speaking, to learn about these projections. We do this by evaluating the degree to which brain activation vectors and words co-align, with the assumption that this provides some information about Ω.</p><p hwp:id="p-56">Unfortunately, it is unlikely <italic toggle="yes">a priori</italic> that a set of <inline-formula hwp:id="inline-formula-18"><alternatives hwp:id="alternatives-34"><inline-graphic xlink:href="299024_inline18.gif" hwp:id="inline-graphic-18"/></alternatives></inline-formula> words, taken individually as fixed search directions, would form a positive basis for Ω if used in a count-based representation. If a count-based representation of <inline-formula hwp:id="inline-formula-19"><alternatives hwp:id="alternatives-35"><inline-graphic xlink:href="299024_inline19.gif" hwp:id="inline-graphic-19"/></alternatives></inline-formula> formed a positive basis for Ω, then any brain vector projected onto Ω would have a component fall in a half-space spanned by two word vectors, and thereby demonstrate some projection onto those words. For word-count representations, which are only meaningful if positive, we would would require at minimum |Ω| + 1 words to form a positive spanning set of search directions, and to be complete 2|Ω| words would be required (i.e. one word to search in a given direction, and another to search in the opposite direction). Conversely, with vector representations of words, anticorrelation is meaningful, which enables a single word to capture relevant semantic projections in Ω, bidirectionally. Finally, since vector representations of words can be correlated with each other and be of different lengths, there is a greater potential for defining complex search trajectories in Ω, and thereby improving the chances of capturing semantic information about brain activation patterns using linguistic data.</p><p hwp:id="p-57">We have also shown that including real world context—that is, information about the actual subject matter of discourse—can improve the latent embedding space’s ability to capture relevant semantic structure. This was shown by the superior clustering performance with the joint neural-linguistic representation, compared to that observed with word embeddings considered alone. To our knowledge, this effect has not yet been shown in the literature. Given that the word embeddings were initially learned from the text data alone, our results do not suggest that inclusion of brain imaging data in the embedding process shows its effects on parameter optimization. Indeed, the same vector representations of words were used for both singular value decompositions in our analysis. What this suggests is that inclusion of the brain imaging data altered the shape of the manifold onto which the word vectors were projected. The resulting distributions of word vectors on this manifold were clearly superior in terms of both quantitative and qualitative measures of the sensibility of semantic clusters. More generally, our results may suggest that vector space models of semantics could benefit from including auxiliary data concerning the subject matter of the text from which those embeddings were learned. Future work should investigate whether this applies to the inclusion of multiple forms of auxiliary data; for analyses of Neurosynth, this may include merger of neurogenetic data from other repositories.</p><p hwp:id="p-58">Our study is not free of limitations. First, we did not conduct a systematic analysis of hyperparameter settings for our models. This is largely due to the lack of clear guidelines or performance metrics that define a good embedding fit. Consequently, the hyperparameter tuning for these models is somewhat idiosyncratic. We opted to maintain consis-tency with previous literature, and indeed those choices performed satisfactorily. Future work should systematically explore the effects of hyperparameter tuning on GloVe embeddings. Another limitation is that we did not compare the joint linguistic-neural embedding against a latent representation of neural activations alone. This was omitted on account of the size of the document by voxel brain activation matrix, which precluded feasible implementation of sin-gular value decomposition. These results would not have undermined the present study’s data, but could contribute to further understanding of how contextual information provided by the brain imaging data shape the embedding space; in future work we will consider application of matrix factorization approaches that facilitate subsampling in order to perform this comparison.</p><p hwp:id="p-59">Notwithstanding these limitations, our study’s first strength is in the simplicity of our model. Being entirely linear, it enables mapping from word vectors to brain images, and has the potential for enabling automated captioning of brain images (an important target for future work). This carries significance for the future of neuroimaging meta-analysis. Current meta-analytic approaches rely on measuring some intersection of activations between studies that include some given linguistic term; our approach enables sampling of new hypothetical images from an underlying semantic space that incorporates information from the corpus of neuroimaging literature.</p><p hwp:id="p-60">Our study’s second strength is the detailed analysis regarding the underlying model mechanics. Specifically, we were able to provide empirical rationales for both (A) the effectiveness, and (B) mechanism of action, of joint embeddings compared to word-embeddings alone. Future work should focus on development of measures for uncertainty of vector-space representations (i.e. probabilistic word embedding models), as well as methods to improve the quality of image sampling from the embedding space.</p><sec id="s5a" hwp:id="sec-17"><label>5.1</label><title hwp:id="title-18">Conclusions</title><p hwp:id="p-61">In conclusion, we have shown that a vector space representation of linguistic data from scientific abstracts of functional brain imaging research—when combined into a joint embedding with brain imaging data themselves—can offer a rich and sensible distribution of semantic concepts that span biological, psychological, and behavioural levels of analysis. Moreover, we have shown that these representations can (A) capture correlations between words and (B) adequately represent documents and higher order topics through simple arithmetic operations. Our analysis suggests that the joint neural-linguistic embedding approach functions because the real-world contextual data reshapes the manifold onto which linguistic vector representations are projected. This approach not only shows interesting clustering of words, brain voxels, and documents, but can also generate synthetic brain images that would be expected given a set of words. Future work should consider methods to optimize the hyperparameters of this approach, generate probabilistic embeddings, and incorporate multiple forms of biological data in the embedding process.</p></sec></sec></body><back><ack hwp:id="ack-1"><title hwp:id="title-19">Acknowledgments</title><p hwp:id="p-62">Dr. Sageev Oore provided helpful questions and feedback during the brainstorming stage, regarding potential exten-sions to GC-LDA.</p></ack><ref-list hwp:id="ref-list-1"><title hwp:id="title-20">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1 xref-ref-1-2"><citation publication-type="other" citation-type="journal" ref:id="299024v1.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Abadi M."><given-names>M.</given-names> <surname>Abadi</surname></string-name>, <string-name name-style="western" hwp:sortable="Agarwal A."><given-names>A.</given-names> <surname>Agarwal</surname></string-name>, <string-name name-style="western" hwp:sortable="Barham P."><given-names>P.</given-names> <surname>Barham</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-2">TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems</article-title>. arXiv:<pub-id pub-id-type="arxiv">1603.04467v2</pub-id>, page <fpage>19</fpage>, <year>2015</year>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Abraham A."><given-names>A.</given-names> <surname>Abraham</surname></string-name>, <string-name name-style="western" hwp:sortable="Pedregosa F."><given-names>F.</given-names> <surname>Pedregosa</surname></string-name>, <string-name name-style="western" hwp:sortable="Eickenberg M."><given-names>M.</given-names> <surname>Eickenberg</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-3">Machine learning for neuroimaging with scikit-learn</article-title>. <source hwp:id="source-1">Frontiers in Neuroinformatics</source>, <volume>8</volume>:<fpage>14</fpage>, <year>2014</year>. ISSN <issn>1662-5196</issn>.</citation></ref><ref id="c3" hwp:id="ref-3"><citation publication-type="other" citation-type="journal" ref:id="299024v1.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Alhazmi F."><given-names>F.</given-names> <surname>Alhazmi</surname></string-name>, <string-name name-style="western" hwp:sortable="Beaton D."><given-names>D.</given-names> <surname>Beaton</surname></string-name>, and <string-name name-style="western" hwp:sortable="Abdi H."><given-names>H.</given-names> <surname>Abdi</surname></string-name>. <article-title hwp:id="article-title-4">The latent semantic space and corresponding brain regions of the functional neuroimaging literature via neurosynth</article-title>. <source hwp:id="source-2">bioRxiv</source>, <year>2017</year>. doi: <pub-id pub-id-type="doi">10.1101/157826</pub-id>.</citation></ref><ref id="c4" hwp:id="ref-4"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Blei D.M."><given-names>D.M.</given-names> <surname>Blei</surname></string-name>, <string-name name-style="western" hwp:sortable="Ng A.Y."><given-names>A.Y.</given-names> <surname>Ng</surname></string-name>, and <string-name name-style="western" hwp:sortable="Jordan M.I."><given-names>M.I.</given-names> <surname>Jordan</surname></string-name>. <article-title hwp:id="article-title-5">Latent Dirichlet Allocation</article-title>. <source hwp:id="source-3">Journal of Machine Learning Research</source>, <volume>3</volume>:<fpage>993</fpage>–<lpage>1022</lpage>, <year>2003</year>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1"><citation publication-type="website" citation-type="web" ref:id="299024v1.5" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-5"><collab hwp:id="collab-1">Bokeh Development Team</collab>. <source hwp:id="source-4">Bokeh: Python library for interactive visualization</source>, <year>2014</year>. URL <ext-link l:rel="related" l:ref-type="uri" l:ref="http://www.bokeh.pydata.org" ext-link-type="uri" xlink:href="http://www.bokeh.pydata.org" hwp:id="ext-link-8">http://www.bokeh.pydata.org</ext-link>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1"><citation publication-type="book" citation-type="book" ref:id="299024v1.6" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Churchland P.S."><given-names>P.S.</given-names> <surname>Churchland</surname></string-name> and <string-name name-style="western" hwp:sortable="Sejnowski T.J."><given-names>T.J.</given-names> <surname>Sejnowski</surname></string-name>. <source hwp:id="source-5">The Computational Brain</source>. <publisher-name>MIT Press</publisher-name>, <publisher-loc>Cambridge, Massachusetts</publisher-loc>, <year>1992</year>. ISBN <isbn>9780262031882</isbn>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Gearhardt A.N."><given-names>A.N.</given-names> <surname>Gearhardt</surname></string-name> and <string-name name-style="western" hwp:sortable="Potenza M.N."><given-names>M.N.</given-names> <surname>Potenza</surname></string-name>. <article-title hwp:id="article-title-6">Common Neural Mechanisms in Obesity and Drug Addiction</article-title>. <source hwp:id="source-6">Biological Research on Addiction</source>, <volume>2</volume>:<fpage>425</fpage>–<lpage>429</lpage>, <year>2013</year>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Goodkind M."><given-names>M.</given-names> <surname>Goodkind</surname></string-name>, <string-name name-style="western" hwp:sortable="Eickhoff S.B."><given-names>S.B.</given-names> <surname>Eickhoff</surname></string-name>, <string-name name-style="western" hwp:sortable="Oathes D.J."><given-names>D.J.</given-names> <surname>Oathes</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-7">Identification of a Common Neurobiological Substrate for Mental Illness</article-title>. <source hwp:id="source-7">JAMA Psychiatry</source>, <volume>5797</volume>(<issue>4</issue>):<fpage>1</fpage>–<lpage>11</lpage>, <year>2015</year>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.9" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Kingma D.P."><given-names>D.P.</given-names> <surname>Kingma</surname></string-name> and <string-name name-style="western" hwp:sortable="Ba J.L."><given-names>J.L.</given-names> <surname>Ba</surname></string-name>. <article-title hwp:id="article-title-8">Adam: a Method for Stochastic Optimization</article-title>. <source hwp:id="source-8">International Conference on Learning Representations 2015</source>, pages <fpage>1</fpage>–<lpage>15</lpage>, <year>2015</year>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1 xref-ref-10-2"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.10" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Levy D.J."><given-names>D.J.</given-names> <surname>Levy</surname></string-name> and <string-name name-style="western" hwp:sortable="Glimcher P.W."><given-names>P.W.</given-names> <surname>Glimcher</surname></string-name>. <article-title hwp:id="article-title-9">The root of all value: A neural common currency for choice</article-title>. <source hwp:id="source-9">Current Opinion in Neurobiology</source>, <volume>22</volume>(<issue>6</issue>):<fpage>1027</fpage>–<lpage>1038</lpage>, <year>2012</year>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.11" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Mikolov T."><given-names>T.</given-names> <surname>Mikolov</surname></string-name>, <string-name name-style="western" hwp:sortable="Chen K."><given-names>K.</given-names> <surname>Chen</surname></string-name>, <string-name name-style="western" hwp:sortable="Corrado G."><given-names>G.</given-names> <surname>Corrado</surname></string-name>, and <string-name name-style="western" hwp:sortable="Dean J."><given-names>J.</given-names> <surname>Dean</surname></string-name>. <article-title hwp:id="article-title-10">Distributed representations of words and phrases and their compositionality</article-title>. In <source hwp:id="source-10">NIPS</source>, pages <fpage>1</fpage>–<lpage>9</lpage>, <year>2013a</year>.</citation></ref><ref id="c12" hwp:id="ref-12"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.12" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Mikolov T."><given-names>T.</given-names> <surname>Mikolov</surname></string-name>, <string-name name-style="western" hwp:sortable="Chen K."><given-names>K.</given-names> <surname>Chen</surname></string-name>, <string-name name-style="western" hwp:sortable="Corrado G."><given-names>G.</given-names> <surname>Corrado</surname></string-name>, and <string-name name-style="western" hwp:sortable="Dean J."><given-names>J.</given-names> <surname>Dean</surname></string-name>. <article-title hwp:id="article-title-11">Efficient Estimation of Word Representations in Vector Space</article-title>. <source hwp:id="source-11">Arxiv</source>, pages <fpage>1</fpage>–<lpage>12</lpage>, <year>2013b</year>.</citation></ref><ref id="c13" hwp:id="ref-13"><citation publication-type="other" citation-type="journal" ref:id="299024v1.13" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Monti R."><given-names>R.</given-names> <surname>Monti</surname></string-name>, <string-name name-style="western" hwp:sortable="Lorenz R."><given-names>R.</given-names> <surname>Lorenz</surname></string-name>, <string-name name-style="western" hwp:sortable="Leech R."><given-names>R.</given-names> <surname>Leech</surname></string-name>, <string-name name-style="western" hwp:sortable="Anagnostopoulos C."><given-names>C.</given-names> <surname>Anagnostopoulos</surname></string-name>, and <string-name name-style="western" hwp:sortable="Montana G."><given-names>G.</given-names> <surname>Montana</surname></string-name>. <article-title hwp:id="article-title-12">Text-mining the neurosynth corpus using deep boltzmann machines</article-title>. In <source hwp:id="source-12">PRNI 2016 - 6th International Workshop on Pattern Recognition in Neuroimaging</source>, <year>2016</year>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1 xref-ref-14-2"><citation publication-type="other" citation-type="journal" ref:id="299024v1.14" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Pennington J."><given-names>J.</given-names> <surname>Pennington</surname></string-name>, <string-name name-style="western" hwp:sortable="Socher R."><given-names>R.</given-names> <surname>Socher</surname></string-name>, and <string-name name-style="western" hwp:sortable="Manning C."><given-names>C.</given-names> <surname>Manning</surname></string-name>. <article-title hwp:id="article-title-13">Glove: Global Vectors for Word Representation</article-title>. In <source hwp:id="source-13">Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</source>, pages <fpage>1532</fpage>–<lpage>1543</lpage>, <year>2014</year>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.15" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Petersen S.E."><given-names>S.E.</given-names> <surname>Petersen</surname></string-name> and <string-name name-style="western" hwp:sortable="Sporns O."><given-names>O.</given-names> <surname>Sporns</surname></string-name>. <article-title hwp:id="article-title-14">Brain Networks and Cognitive Architectures</article-title>. <source hwp:id="source-14">Neuron</source>, <volume>88</volume>(<issue>1</issue>):<fpage>207</fpage>–<lpage>219</lpage>, <year>2015</year>.</citation></ref><ref id="c16" hwp:id="ref-16"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.16" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Poldrack R.A."><given-names>R.A.</given-names> <surname>Poldrack</surname></string-name>, <string-name name-style="western" hwp:sortable="Mumford J.A."><given-names>J.A.</given-names> <surname>Mumford</surname></string-name>, <string-name name-style="western" hwp:sortable="Schonberg T."><given-names>T.</given-names> <surname>Schonberg</surname></string-name>, <string-name name-style="western" hwp:sortable="Kalar D."><given-names>D.</given-names> <surname>Kalar</surname></string-name>, <string-name name-style="western" hwp:sortable="Barman B."><given-names>B.</given-names> <surname>Barman</surname></string-name>, and <string-name name-style="western" hwp:sortable="Yarkoni T."><given-names>T.</given-names> <surname>Yarkoni</surname></string-name>. <article-title hwp:id="article-title-15">Discovering Relations Between Mind, Brain, and Mental Disorders Using Topic Mapping</article-title>. <source hwp:id="source-15">PLoS Computational Biology</source>, <volume>8</volume>(<issue>10</issue>), <year>2012</year>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Rousseeuw P.J."><given-names>P.J.</given-names> <surname>Rousseeuw</surname></string-name>. <article-title hwp:id="article-title-16">Silhouettes: A graphical aid to the interpretation and validation of cluster analysis</article-title>. <source hwp:id="source-16">Journal of Computational and Applied Mathematics</source>, <volume>20</volume>:<fpage>53</fpage>–<lpage>65</lpage>, <year>1987</year>.</citation></ref><ref id="c18" hwp:id="ref-18"><citation publication-type="book" citation-type="book" ref:id="299024v1.18" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Rubin T.N."><given-names>T.N.</given-names> <surname>Rubin</surname></string-name>, <string-name name-style="western" hwp:sortable="Koyejo O."><given-names>O.</given-names> <surname>Koyejo</surname></string-name>, <string-name name-style="western" hwp:sortable="Jones M.N."><given-names>M.N.</given-names> <surname>Jones</surname></string-name>, and <string-name name-style="western" hwp:sortable="Yarkoni T."><given-names>T.</given-names> <surname>Yarkoni</surname></string-name>. <chapter-title>Generalized Correspondence-LDA Models (GC-LDA) for Identifying Functional Regions in the Brain</chapter-title>. pages <fpage>1118</fpage>–<lpage>1126</lpage>. <publisher-name>Curran Associates, Inc</publisher-name>., <year>2016</year>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Sporns O."><given-names>O.</given-names> <surname>Sporns</surname></string-name>. <article-title hwp:id="article-title-17">Network attributes for segregation and integration in the human brain</article-title>. <source hwp:id="source-17">Current Opinion in Neurobiology</source>, <volume>23</volume>(<issue>2</issue>):<fpage>162</fpage>–<lpage>171</lpage>, <year>2013</year>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Stalnaker T."><given-names>T.</given-names> <surname>Stalnaker</surname></string-name>, <string-name name-style="western" hwp:sortable="Cooch N.K."><given-names>N.K.</given-names> <surname>Cooch</surname></string-name>, and <string-name name-style="western" hwp:sortable="Schoenbaum G."><given-names>G.</given-names> <surname>Schoenbaum</surname></string-name>. <article-title hwp:id="article-title-18">What the orbitofrontal cortex does not do</article-title>. <source hwp:id="source-18">Nature Neuroscience</source>, <volume>18</volume> (<issue>5</issue>):<fpage>620</fpage>–<lpage>627</lpage>, <year>2015</year>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Van Der Maaten L.J.P."><given-names>L.J.P.</given-names> <surname>Van Der Maaten</surname></string-name> and <string-name name-style="western" hwp:sortable="Hinton G.E."><given-names>G.E.</given-names> <surname>Hinton</surname></string-name>. <article-title hwp:id="article-title-19">Visualizing high-dimensional data using t-sne</article-title>. <source hwp:id="source-19">Journal of Machine Learning Research</source>, <volume>9</volume>:<fpage>2579</fpage>–<lpage>2605</lpage>, <year>2008</year>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Volkow N.D."><given-names>N.D.</given-names> <surname>Volkow</surname></string-name>, <string-name name-style="western" hwp:sortable="Wang G."><given-names>G.</given-names> <surname>Wang</surname></string-name>, <string-name name-style="western" hwp:sortable="Tomasi D."><given-names>D.</given-names> <surname>Tomasi</surname></string-name>, and <string-name name-style="western" hwp:sortable="Ruben D. Baler"><surname>Ruben</surname> <given-names>D. Baler</given-names></string-name>. <article-title hwp:id="article-title-20">The Addictive Dimensionality of Obesity</article-title>. <source hwp:id="source-20">Biological Psychiatry</source>, <volume>73</volume>(<issue>9</issue>):<fpage>811</fpage>–<lpage>818</lpage>, <year>2013</year>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Volkow N.D."><given-names>N.D.</given-names> <surname>Volkow</surname></string-name>, <string-name name-style="western" hwp:sortable="Wise R.A."><given-names>R.A.</given-names> <surname>Wise</surname></string-name>, and <string-name name-style="western" hwp:sortable="Baler R."><given-names>R.</given-names> <surname>Baler</surname></string-name>. <article-title hwp:id="article-title-21">The dopamine motive system: Implications for drug and food addiction</article-title>. <source hwp:id="source-21">Nature Reviews Neuroscience</source>, <volume>18</volume>(<issue>12</issue>):<fpage>741</fpage>–<lpage>752</lpage>, <year>2017</year>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1"><citation publication-type="journal" citation-type="journal" ref:id="299024v1.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Yarkoni T."><given-names>T.</given-names> <surname>Yarkoni</surname></string-name>, <string-name name-style="western" hwp:sortable="Poldrack R.A."><given-names>R.A.</given-names> <surname>Poldrack</surname></string-name>, <string-name name-style="western" hwp:sortable="Nichols T.E."><given-names>T.E.</given-names> <surname>Nichols</surname></string-name>, <string-name name-style="western" hwp:sortable="Van Essen D.C."><given-names>D.C.</given-names> <surname>Van Essen</surname></string-name>, and <string-name name-style="western" hwp:sortable="Wager T.D."><given-names>T.D.</given-names> <surname>Wager</surname></string-name>. <article-title hwp:id="article-title-22">Large-scale automated synthesis of human functional neuroimaging data</article-title>. <source hwp:id="source-22">Nature Methods</source>, <volume>8</volume>(<issue>8</issue>):<fpage>665</fpage>–<lpage>670</lpage>, <year>2011</year>.</citation></ref></ref-list><sec sec-type="display-objects" id="s6" hwp:id="sec-18"><title hwp:id="title-21">A Experimental Parameters</title><table-wrap id="tbl2" orientation="portrait" position="float" hwp:id="T2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;299024v1/TBL2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">T2</object-id><object-id pub-id-type="publisher-id">tbl2</object-id><label>Table 2:</label><caption hwp:id="caption-11"><p hwp:id="p-63">Experimental parameters and rationales. Items marked with <sup><italic toggle="yes">TF</italic></sup> were implemented in TensorFlow v1.4 [<xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-2" hwp:rel-id="ref-1">Abadi et al., 2015</xref>]. For pre-packaged implementations listed here, default parameters were used unless otherwise stated.</p></caption><graphic xlink:href="299024_tbl2" position="float" orientation="portrait" hwp:id="graphic-27"/></table-wrap></sec><fn-group hwp:id="fn-group-1"><fn id="fn1" hwp:id="fn-1" hwp:rev-id="xref-fn-1-1"><p hwp:id="p-64"><ext-link l:rel="related" l:ref-type="uri" l:ref="https://github.com/neurosynth/neurosynth" ext-link-type="uri" xlink:href="https://github.com/neurosynth/neurosynth" hwp:id="ext-link-9">https://github.com/neurosynth/neurosynth</ext-link></p></fn></fn-group></back></article>
