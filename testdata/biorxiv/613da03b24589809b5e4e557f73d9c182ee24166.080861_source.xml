<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/080861</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;080861v1</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;080861</article-id><article-id pub-id-type="other" hwp:sub-type="slug">080861</article-id><article-id pub-id-type="other" hwp:sub-type="tag">080861</article-id><article-version>1.1</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Neuroscience" hwp:journal="biorxiv"><subject>Neuroscience</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">A cryptography-based approach for movement decoding</article-title></title-group><author-notes hwp:id="author-notes-1"><corresp id="cor1" hwp:id="corresp-1" hwp:rev-id="xref-corresp-1-1"><label>*</label>Corresponding author: <email hwp:id="email-1">edyer@ric.org</email></corresp></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" corresp="yes" hwp:id="contrib-1"><contrib-id contrib-id-type="orcid" authenticated="false">http://orcid.org/0000-0002-6962-524X</contrib-id><name name-style="western" hwp:sortable="Dyer Eva L."><surname>Dyer</surname><given-names>Eva L.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-1" hwp:rel-id="aff-2">2</xref><xref ref-type="corresp" rid="cor1" hwp:id="xref-corresp-1-1" hwp:rel-id="corresp-1">*;</xref><object-id pub-id-type="other" hwp:sub-type="orcid" xlink:href="http://orcid.org/0000-0002-6962-524X"/></contrib><contrib contrib-type="author" hwp:id="contrib-2"><name name-style="western" hwp:sortable="Azar Mohammad Gheshlaghi"><surname>Azar</surname><given-names>Mohammad Gheshlaghi</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-2" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-2" hwp:rel-id="aff-2">2</xref></contrib><contrib contrib-type="author" hwp:id="contrib-3"><name name-style="western" hwp:sortable="Fernandes Hugo L."><surname>Fernandes</surname><given-names>Hugo L.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-3" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-3" hwp:rel-id="aff-2">2</xref></contrib><contrib contrib-type="author" hwp:id="contrib-4"><name name-style="western" hwp:sortable="Perich Matthew G."><surname>Perich</surname><given-names>Matthew G.</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-1" hwp:rel-id="aff-3">3</xref></contrib><contrib contrib-type="author" hwp:id="contrib-5"><name name-style="western" hwp:sortable="Naufel Stephanie"><surname>Naufel</surname><given-names>Stephanie</given-names></name><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-2" hwp:rel-id="aff-3">3</xref></contrib><contrib contrib-type="author" hwp:id="contrib-6"><name name-style="western" hwp:sortable="Miller Lee"><surname>Miller</surname><given-names>Lee</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-4" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a3" hwp:id="xref-aff-3-3" hwp:rel-id="aff-3">3</xref></contrib><contrib contrib-type="author" hwp:id="contrib-7"><name name-style="western" hwp:sortable="Körding Konrad P."><surname>Körding</surname><given-names>Konrad P.</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-5" hwp:rel-id="aff-1">1</xref><xref ref-type="aff" rid="a2" hwp:id="xref-aff-2-4" hwp:rel-id="aff-2">2</xref></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1 xref-aff-1-2 xref-aff-1-3 xref-aff-1-4 xref-aff-1-5"><label>1</label><institution hwp:id="institution-1">Dept. of Physical Medicine and Rehabilitation, Northwestern University</institution>, Chicago, IL</aff><aff id="a2" hwp:id="aff-2" hwp:rev-id="xref-aff-2-1 xref-aff-2-2 xref-aff-2-3 xref-aff-2-4"><label>2</label><institution hwp:id="institution-2">Sensory Motor Performance Program, Rehabilitation Institute of Chicago,</institution> Chicago, IL</aff><aff id="a3" hwp:id="aff-3" hwp:rev-id="xref-aff-3-1 xref-aff-3-2 xref-aff-3-3"><label>3</label><institution hwp:id="institution-3">Dept. of Biomedical Engineering, Northwestern University</institution>, Evanston, IL</aff></contrib-group><pub-date pub-type="epub-original" hwp:start="2016"><year>2016</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2016-10-14T10:16:08-07:00">
    <day>14</day><month>10</month><year>2016</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2016-10-14T10:16:08-07:00">
    <day>14</day><month>10</month><year>2016</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2016-10-14T10:25:20-07:00">
    <day>14</day><month>10</month><year>2016</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2016-10-14T10:25:20-07:00">
    <day>14</day><month>10</month><year>2016</year>
  </pub-date><elocation-id>080861</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2016-10-13"><day>13</day><month>10</month><year>2016</year></date>
<date date-type="accepted" hwp:start="2016-10-14"><day>14</day><month>10</month><year>2016</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">© 2016, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2016</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="license-1"><p hwp:id="p-1">This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by-nc-nd/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></p></license></permissions><self-uri xlink:href="080861.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2019/pdf/080861v1.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="080861.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2019/abstracts/080861v1/080861v1.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2019/fulltext/080861v1/080861v1.htslp"/><abstract hwp:id="abstract-1"><p hwp:id="p-2">Brain decoders use neural recordings to infer a user’s activity or intent. To train a decoder, we generally need infer the variables of interest (covariates) using simultaneously measured neural activity. However, there are many cases where this approach is not possible. Here we overcome this problem by introducing a fundamentally new approach for decoding called distribution alignment decoding (DAD). We use the statistics of movement, much like cryptographers use the statistics of language, to find a mapping between neural activity and motor variables. DAD learns a linear decoder which aligns the distribution of its output with the typical distribution of motor outputs by minimizing their KL-divergence. We apply our approach to a two datasets collected from the motor cortex of non-human primates (NHPs): a reaching task and an isometric force production task. We study the performance of DAD and find regimes where DAD provides comparable and in some cases, better performance than a typical supervised decoder. As DAD does not rely on the ability to record motor-related outputs, it promises to broaden the set of potential applications of brain decoding.</p></abstract><counts><page-count count="18"/></counts></article-meta></front><body><sec id="s1" hwp:id="sec-1"><title hwp:id="title-1">Introduction</title><p hwp:id="p-3">The aim of brain decoding methods is to infer the relationship between brain activity and a co-variate of interest. By measuring neural activity, one can infer what someone is viewing<sup><xref ref-type="bibr" rid="c1" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">1</xref>,<xref ref-type="bibr" rid="c2" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">2</xref></sup>, what word they are thinking about<sup><xref ref-type="bibr" rid="c3" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">3</xref>,<xref ref-type="bibr" rid="c4" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">4</xref></sup>, or their movements<sup><xref ref-type="bibr" rid="c5" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">5</xref>,<xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">6</xref></sup>. Decoding approaches can also be used to elucidate the link between external factors (stimuli) and the brain, which is essential for under-standing how the brain encodes information. In all of these settings, training data are collected by simultaneously recording brain activity along with the covariates that we wish to predict.</p><p hwp:id="p-4">In many situations, obtaining simultaneous recordings of both neural activity and the covariates of interest is challenging, expensive, or impossible<sup><xref ref-type="bibr" rid="c7" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">7</xref></sup>. This includes settings where complex task variables are hard to track and also cases where the user cannot generate training data (e.g., when a user is paralyzed). In these situations, there must be an alternative to applying a supervised approach to learn a mapping between neural activity and the underlying covariates that we wish to predict<sup><xref ref-type="bibr" rid="c8" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">8</xref></sup>.</p><p hwp:id="p-5">To train a decoder without simultaneous measurements of neural activity and covariates of interest, we looked to cryptography for inspiration. When code breakers crack a cypher, they leverage prior information about the distribution of both individual characters and their joint statistics<sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">9</xref>,<xref ref-type="bibr" rid="c10" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">10</xref></sup>. For example, the probability of observing a written ‘E’ is much higher than the probability of observing a ‘Z’. Using such information, Alan Turing and his Bletchley Park team cracked the World War II German Enigma code by exploiting the distribution of words known to appear in encrypted messages from their enemies. The key idea underlying this type of code-breaking strategy is to learn a mapping from the encrypted to decrypted text that produces a distribution with structure similar to what we expect based upon prior knowledge. Here, we ask if the same concept could be used to learn a mapping from neural activity to motor outputs.</p><p hwp:id="p-6">We will highlight this concept with a movement example, where the aim is to decode the 2D velocity of a user’s hand from recorded neural activity. If the decoder is tuned correctly, the distribution of the decoded movement variables (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Fig. 1a</xref>, orange) should roughly match the distribution of the kinematics of the actual movement<sup><xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">11</xref></sup> (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-2" hwp:rel-id="F1">Fig. 1a</xref>, yellow). If the decoder is not correct, then its output would produce a different distribution (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-3" hwp:rel-id="F1">Fig. 1a</xref>, red). We will also do an analogous analysis for an isometric task, where the variable of interest is force, showing the applicability of our method to other motor-related variables. In cryptography, breaking a cypher is easier when the underlying signal is highly structured<sup><xref ref-type="bibr" rid="c9" hwp:id="xref-ref-9-2" hwp:rel-id="ref-9">9</xref></sup>. There is some evidence that natural movements, such as eating, running, and dancing, exhibit a great deal of structure and regularity<sup><xref ref-type="bibr" rid="c12" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">12</xref></sup>. The existence of such structure in natural movements suggests that deviations from the typical movement distribution could be statistically detected. Aligning the distribution of predicted movements with a prior over movements may provide a way of relating neural activity and movement without the need to measure them simultaneously.</p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1 xref-fig-1-2 xref-fig-1-3 xref-fig-1-4 xref-fig-1-5 xref-fig-1-6 xref-fig-1-7 xref-fig-1-8 xref-fig-1-9"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;080861v1/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label>Figure 1:</label><caption hwp:id="caption-1"><title hwp:id="title-2">Decoding structured movements with distribution alignment.</title><p hwp:id="p-7">In (a), we show a schematic of hand trajectories of different tasks. For each task (feeding, running, reaching), the hand moves along a subspace within the space of all 3D movements. The distribution of hand movements for each task is highly structured and anisotropic and varies across different tasks. In (b), kinematics data from Subject M (left) and Subject C (right), displayed as scatterplot data with the target directions displayed as different colors and on the bottom, the corresponding heatmaps (distribution estimates). In (c), we demonstrate the idea behind distribution alignment on two permuted sets of training and test kinematics from Subject M. The KL-divergence is displayed as a function of the rotation angle used for alignment in 2D. The correct solution (ground truth), min-KL predicted solution (R<sup>2</sup> = 0.996), four non-optimal rotations/reflections are displayed. A prior movement distribution from the same subject is shown in (b). Note that due to the fact that this reflections of this task are roughly equivalent, the first local minima (1) of the KL-divergence is a flipped-version of the correct solution.</p></caption><graphic xlink:href="080861_fig1" position="float" orientation="portrait" hwp:id="graphic-1"/></fig><p hwp:id="p-8">Here we introduce an approach for movement decoding called distribution alignment decoding (DAD), that exploits the structure of natural movements to find a mapping between neural activity and movement. Our approach leverages the fact that low-dimensional representations of populations of motor neurons have the same shape (distribution) as the motor outputs <sup><xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">13</xref>,<xref ref-type="bibr" rid="c14" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">14</xref></sup>. Thus, in order to find a decoder with output that matches a prior distribution of movements, we only need to find a low-dimensional representation of the neural data that matches this movement distribution. We do this by learning a decoder that minimizes the deviation (KL-divergence) between the distribution of projected (low dimensional) neural activities and kinematics.</p><p hwp:id="p-9">We applied DAD to neural datasets collected from the primary motor cortex (M1) of three non-human primates (NHPs) performing either a reaching task or a task to produce isometric force about the wrist. When the covariates of interest are linearly embedded in the neural activity, DAD can be used to predict motor outputs without knowing the correspondence between training and test data. Our results suggest that it is possible to decode brain activity without the need to observe the covariates that we want to predict. Thus our approach can also be used to decode the neural activity of one subject based upon distribution of motor outputs collected from another subject— this is useful in settings where we have no previous motor data from a subject. Lastly, when a small amount of supervised data is available, we can combine the outputs of DAD and the supervised decoder to improve supervised approaches.</p></sec><sec id="s2" hwp:id="sec-2"><title hwp:id="title-3">Results</title><p hwp:id="p-10">DAD projects the neural data into a low-dimensional space, and then finds a mapping of the resulting data into movement space so that the resulting distributions are as similar as possible. To evaluate its performance, we measured populations of neurons in the arm and hand areas of the primary motor cortex (M1) from three NHPs while they performed different motor tasks. We studied data from two motor tasks: a standard reaching task (Subjects M and C) and an isometric wrist force production task (Subject J). In addition, we collected samples of the covariates of interest in both tasks. In the case of the reaching task, we recorded the position and velocity of each subject’s hand. For the isometric task, we measured the forces about the wrist. To produce non-isotropic datasets with meaningful structure, we subsampled our data to remove a few target directions (see <xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-4" hwp:rel-id="F1">Fig. 1</xref> for details on this choice). This way we have a non-isotropic movement distribution that we can align with the equally non-isotropic distribution of neural activities to test the performance of DAD.</p><p hwp:id="p-11">The kinematics of the reaching task, as performed by different subjects (M and C), showed high degrees of similarity when aggregated over a large number of trials (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-5" hwp:rel-id="F1">Fig. 1b</xref>). We computed the distribution of both subject’s movements using a non-parametric nearest neighbor approach for density estimation and found that the distributions are extremely similar. The similarity between the distribution of different subjects’ movements suggests that our approach could be applied to decode neural data using training kinematics from another subject, which can be useful when no supervised training data is available for a particular subject.</p><p hwp:id="p-12">To confirm that our method can, in principle, align low-dimensional data, we tested our approach on the 2D kinematics data from subject M (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-6" hwp:rel-id="F1">Fig. 1c</xref>). Our alignment procedure computes the KL-divergence between the training distribution and a transformed version of the target distribution. DAD returns the alignment that minimizes the KL-divergence between the training and test. The resulting alignments provide decoders with good prediction accuracy (as measured by R<sup>2</sup>). Thus the KL-divergence provides a measure for aligning two distributions and can be used to solve our alignment problem.</p><p hwp:id="p-13">Distribution alignment is relatively easy when the training and test distributions have similar structure. However, low-dimensional embeddings of neural activity can be quite noisy, therefore it is important to first verify that the task structure is apparent in the embeddings. We applied a variety of linear and nonlinear dimensionality reduction techniques<sup><xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">15</xref>,<xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">16</xref></sup> to embed the neural data (see Methods). In the case of both subjects M and J, we found certain directions of movement (M) and force production (J), that produce neural embeddings that lie on a cone in 3D (<xref rid="fig2" ref-type="fig" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Fig. 2c</xref>). Moreover, we find that the structure of the individual movement directions is also preserved in these embeddings. When we applied the same approach to neural data collected from Subject C, we couldn’t find any discernible structure that could be used to align it with the target distribution. As we highlight in the discussion, the failure mode of DAD is typically the failure of dimensionality reduction algorithms to find the dimensions that contain the relevant signals. We therefore did not use Subject C’s neural activity for decoding, however, but we did use this subject’s kinematic data as a prior over movement. Our analysis suggests that dimensionality reduction can be used to first embed the neural data into a space where it can then be more easily aligned.</p><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;080861v1/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label>Figure 2:</label><caption hwp:id="caption-2"><title hwp:id="title-4">Overview of Distribution Alignment Decoding (DAD) Approach.</title><p hwp:id="p-14">In (a), we depict a subject carrying out a reaching task and show the resulting 3D kinematics associated with this task. The subject’s movements produce datasets with the (top) 2D kinematics of the task and (bottom) 3D movement data when augmented with speed as a covariate. (c) Neural activity in the form of spikes are mapped into a 2D predicted-movement space using factor analysis. DAD then finds an affine mapping that aligns the projected neural activity (embedding) with the prior distribution of kinematics. (d) We show the results of our alignment procedure in 3D, (left) the target distribution (red <italic toggle="yes">◦</italic>), (middle), the aligned neural data (blue ∗) overlaid on the target (mid), and the aligned distributions when projected into 2D.</p></caption><graphic xlink:href="080861_fig2" position="float" orientation="portrait" hwp:id="graphic-2"/></fig><sec id="s2a" hwp:id="sec-3"><title hwp:id="title-5">Performance on reaching tasks</title><p hwp:id="p-15">To start, we analyzed neural data from Subject M during a reaching task. We explored three different training scenarios to test DAD: (i) a <italic toggle="yes">within-subject</italic> setting, where all of the training kinematics are from Subject M (DAD-M), (ii) a <italic toggle="yes">combined-subject</italic> setting, where the training kinematics contains samples from both M and C (DAD-MC), and (iii) an <italic toggle="yes">across-subject</italic> setting, where the training data is only from C (DAD-C). As DAD is relatively insensitive to the specific training distribution, we find that the alignments we obtain for the across- and combined-subject setting are often similar to the within-subject case (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Fig. 3a</xref>). However, when there is little training data, we find that adding training data from different subjects can improve the performance of the decoder (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Fig. 3b</xref>).</p><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2 xref-fig-3-3 xref-fig-3-4 xref-fig-3-5 xref-fig-3-6 xref-fig-3-7"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;080861v1/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label>Figure 3:</label><caption hwp:id="caption-3"><title hwp:id="title-6">Comparison of decoding performance for reaching tasks.</title><p hwp:id="p-16">We compare the performance of DAD with a supervised decoder (Sup) trained on simultaneously collected neural and kinematics data and an oracle estimate (optimal linear 2D decoder). In (a), we show the result of DAD-M (train and test on M), DAD-MC (train on M,C and test on M), and DAD-C (train on C and test on M), when 20% of the dataset is provided for training. The prediction accuracy for DAD in all three cases is R<sup>2</sup> = 0.627. The supervised decoder obtains a R<sup>2</sup> = 0.572 and the oracle estimate is R<sup>2</sup> = 0.781. In (b), we provide performance comparisons for supervised approaches (in shaded green regions) and DAD (in shaded purple regions) for different amounts of training and test data. We display boxplots of the R<sup>2</sup> values for DAD, a supervised decoder (Sup), the average between the predictions of Sup and DAD-M (Sup+DAD), and the oracle, as we increase the amount of test data. Each boxplot shows the results over 20 trials, the median is displayed as a red line in each box, the edges of the box represent the 25% and 75% percentile, the whiskers indicate the range of the data not considered an outlier, and the outliers are displayed in red (x). In (c), we show the time-varying decoding performance of DAD-M and the supervised decoder (Sup) overlaid on the ground truth kinematics (200 ms time bins).</p></caption><graphic xlink:href="080861_fig3" position="float" orientation="portrait" hwp:id="graphic-3"/></fig><p hwp:id="p-17">To compare DAD with a supervised decoder (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-3" hwp:rel-id="F3">Fig. 3b-c</xref>), we randomly partitioned the data into training and test sets and give both decoders access to both. Before seeing the test set, DAD is only provided the kinematics from the training set, while the supervised decoder has access to both movement kinematics and neural activity. During the test phase, DAD uses the training kinematics and the neural test set to learn a decoder. For our comparisons, we trained a supervised decoder with 10-fold cross-validation to fit the regularization parameter (see <xref rid="eqn2" ref-type="disp-formula" hwp:id="xref-disp-formula-2-1" hwp:rel-id="disp-formula-2">Eqn. 2</xref> in Methods). In addition to a supervised decoder, we also compare with an oracle that finds the best possible 2D linear embedding that can be obtained for the test set. It is important to note that the so-called oracle decoder is impossible to obtain in any practical situation and only serves as a measure of the upper bound over the set of possible linear decoders.</p><p hwp:id="p-18">We studied the performance of DAD as we varied the relative proportion of training and test samples. In our evaluations, we applied DAD to neural data from Subject M, using kinematics training datasets from the same subject (M), another subject (C), and from both (MC). We observe an interesting asymmetry in the performance of DAD versus supervised methods due to the way they are trained. In particular, we find that when the decoder is given access to a small amount of training data, DAD consistently outperforms supervised approaches and has smaller variance in its prediction accuracy (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-4" hwp:rel-id="F3">Fig. 3b</xref>). This is due to the fact that when there is little training data, DAD can still use the test data to improve its final alignment. However, as we increase the amount of training data, supervised approaches perform on average, slightly better than DAD. We average the outputs of DAD and the supervised decoder (Sup+DAD) and find that the combination often improves over the individual performance of each. These results are further confirmed by examining the time-varying decoding of the kinematics (over 200 ms time bins) in both the x and y directions (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-5" hwp:rel-id="F3">Fig. 3c</xref>). Our results suggest that DAD can be used in settings where little training data is available and in across-subject settings, where no previous movement data is recorded from a subject.</p></sec><sec id="s2b" hwp:id="sec-4"><title hwp:id="title-7">Performance on isometric force production tasks</title><p hwp:id="p-19">To test the performance of DAD on a different motor task, we applied it to neural recordings from another subject (Subject J) performing an isometric force production task. The subject’s hand was fixed and thus the measured covariates that we aim to decode are the 2D forces applied at the wrist. When we isolated the neural activity to time points right after the ‘Go’ cue (indicating that the subject should begin force production), we observed clear embeddings of neural data (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Fig. 4a</xref>) that resemble the task structure. However, the size of the dataset is much smaller, and thus our embeddings are not as stable across multiple random partitions of the dataset. Our results for Subject J suggest that certain directions of force-production in an isometric task can also be decoded using DAD. DAD thus holds promise for a variety of motor tasks.</p><fig id="fig4" position="float" fig-type="figure" orientation="portrait" hwp:id="F4" hwp:rev-id="xref-fig-4-1 xref-fig-4-2 xref-fig-4-3 xref-fig-4-4 xref-fig-4-5"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;080861v1/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label>Figure 4:</label><caption hwp:id="caption-4"><title hwp:id="title-8">Prediction accuracy increases with population size.</title><p hwp:id="p-20">In (a), we show the results of DAD on an isometric task, where we record forces applied to the wrist to move a cursor to different targets. Along the top row, we display the training kinematics (used to estimate the prior distribution) and the test kinematics (ground truth). Along the bottom row, we show the output of our cone alignment procedure (3D embedding) and our final 2D estimate (R<sup>2</sup> = 0.51). We observe that DAD indeed finds the correct 3D alignment and then the final 2D rotation to align the datasets. In (b), we visualize the accuracy of DAD on synthetic data as we increase the numbers of neurons in our model. We display the trimmed mean of the R<sup>2</sup> values (the top and bottom 10% of trials are removed) obtained for DAD and the oracle, averaged over 100 trials. Below, we show examples of alignments obtained as we increase the number of neurons in our synthetic model. Examples of training and test kinematics are also shown.</p></caption><graphic xlink:href="080861_fig4" position="float" orientation="portrait" hwp:id="graphic-4"/></fig></sec><sec id="s2c" hwp:id="sec-5"><title hwp:id="title-9">Synthetic experiments</title><p hwp:id="p-21">In some of our experiments with real data, the low-dimensional projections of neural data become (nonlinearly) warped (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-6" hwp:rel-id="F3">Fig. 3a</xref>). Thus, to explore the relationship between the embeddings and the size of the neural population, we create data generated from a population of synthetic neurons with bio-realistic tuning properties. More concretely, we create synthetic data by generating a population of neurons with tuning curves drawn from a distribution of parameters designed to match the real datasets (see Methods).</p><p hwp:id="p-22">Using this synthetic model, we studied the impact of both the number of neurons and time points used for dimensionality reduction and alignment (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-2" hwp:rel-id="F4">Fig. 4b</xref>). We compare the performance of DAD with that of the oracle decoder which has access to both the neural activity and kinematics of the test set. As expected, as the number of neurons increases, the performance accuracy increases as well. For this model, DAD performs as well as the oracle (best 2D linear fit) for populations with roughly 1,000 neurons. This model appears to align nicely with our results on real data; for populations of 100-200 neurons (typical recording sizes), the average R<sup>2</sup> is around 0.6-0.7 (R<sup>2</sup>=0.62 and R<sup>2</sup>=0.78 for d = 128 and 256 neurons, respectively). Thus this suggests that with recordings from even larger populations, distribution alignment will become even more accurate.</p></sec></sec><sec id="s3" hwp:id="sec-6"><title hwp:id="title-10">Discussion</title><p hwp:id="p-23">In this paper, we introduced DAD, a cryptography inspired approach for brain decoding. In the context of motor decoding, we show how DAD can be used to learn a decoder by minimizing the divergence between the distribution of motor outputs and a projected distribution of neural activity. Thus, instead of requiring access to simultaneous recordings of neural activity and motor outputs, our approach relies on the structure and regularities of movement and the fact that this structure is preserved in low-dimensional projections of neural activity of the motor cortex. We find that the algorithm works well on simulated data, as well as two datasets collected from motor cortex.</p><p hwp:id="p-24">One assumption that is integral to our approach is that the variables of interest, e.g. the low-dimensional velocities or forces, appear in the set of the first few components of a dimensionality reduction algorithm. We initially assumed this would be true, as cosine tuning is one of the most frequently described properties of motor cortex activity <sup><xref ref-type="bibr" rid="c17" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">17</xref></sup>. However, this assumption is not true for many datasets, and hence DAD can not be applied. If motor cortex primarily deals with movement vectors, why do they not consistently show up in the first principal components? Despite actively analyzing the data, we can not currently answer this question. This is a very interesting finding as it suggests that there are important features of neural activity that we do not understand. A better understanding of the relevant variables could make DAD work dramatically better and for more datasets.</p><p hwp:id="p-25">Our approach assumes that there exists a linear transformation between projected neural activity and the distribution of movements. However, this assumption often does not hold in practice <sup><xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">18</xref></sup>. This is likely why we observe that the fine-scale structure of the predicted kinematics within each target direction is warped (<xref rid="fig3" ref-type="fig" hwp:id="xref-fig-3-7" hwp:rel-id="F3">Fig. 3a</xref>). An exciting line of future research would be to extend our approach to incorporate non-linearities. One possibility would be to explore the use of mixture models<sup><xref ref-type="bibr" rid="c19" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">19</xref></sup> to model the low-dimensional structure of the data, instead of using a single subspace model with PCA or factor analysis. Kernel methods<sup><xref ref-type="bibr" rid="c20" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">20</xref></sup> could also be used to lift the neural data to a higher-dimensional space where there exists a linear relationship between the neural activity and the low-dimensional kinematics. With approaches that address the non-linearity of the data, the underlying structure of movement contained in the neural data can be preserved, thus leading to an improvement in the prediction accuracy of the decoder.</p><p hwp:id="p-26">To guarantee a unique solution for the problem of distribution alignment, the distribution of movements must be anisotropic (no rotational or reflection symmetry). However, in many laboratory tasks such as center-out-reaching tasks, this assumption is often violated. Here, we circumvent this problem by subsampling the dataset. This introduces asymmetries into the motor task and, in turn, guarantees the uniqueness of the resulting solution. While requiring non-isotropic movements is clearly a drawback of our approach, natural movement tasks<sup><xref ref-type="bibr" rid="c11" hwp:id="xref-ref-11-2" hwp:rel-id="ref-11">11</xref>,<xref ref-type="bibr" rid="c21" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">21</xref></sup> (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-7" hwp:rel-id="F1">Fig. 1a</xref>) are more likely to produce non-isotropic distributions. Moreover, in the case of isotropic distributions where multiple alignments exist, we can potentially use prior knowledge of the decoder or feedback from the user, to rule out incorrect alignments. Since natural movements typically exhibit asymmetries, we expect that our approach can be applied to decode motor variables in a wide range of tasks.</p><p hwp:id="p-27">While our results demonstrate that DAD can achieve comparable performance to that of a regularized linear decoder trained with cross-validation, state-of-the-art decoders use additional information to improve the decoder’s performance, e.g. modeling non-linearity in neural firing rates (e.g., Poisson models)<sup><xref ref-type="bibr" rid="c18" hwp:id="xref-ref-18-2" hwp:rel-id="ref-18">18</xref>,<xref ref-type="bibr" rid="c22" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">22</xref></sup>, target information<sup><xref ref-type="bibr" rid="c6" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">6</xref></sup>, smooth temporal structure<sup><xref ref-type="bibr" rid="c23" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">23</xref></sup>, and the drift of neural properties<sup><xref ref-type="bibr" rid="c24" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">24</xref>,<xref ref-type="bibr" rid="c25" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">25</xref></sup>. Since we do not leverage such improvements, using additional structure is likely to improve the performance of a supervised approach. Similarly, the performance of DAD could be significantly improved using the same ideas. One such improvement would be to incorporate temporal structure by stacking recordings from consecutive time steps together and then aligning the distributions of these augmented vectors. We expect that by incorporating temporal structure, as well as other insights gleaned from studies of the low-dimensional structure of neural populations<sup><xref ref-type="bibr" rid="c26" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">26</xref>–<xref ref-type="bibr" rid="c28" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">28</xref></sup>, the performance of DAD will be further improved.</p><p hwp:id="p-28">We solve the decoding problem by exploiting the known structure of movements to learn a decoder that produces outputs that are aligned with this structure and thus demonstrate one way in which cryptography might applied to brain decoding. The approach we used here is quite simple, but we imagine that more sophisticated code breaking strategies could be used in this and other brain decoding scenarios (beyond movement). Thus, ideas from cryptography and distribution alignment promise to enable a broad range of approaches into brain decoding and new insights into how to crack the neural code.</p></sec><sec id="s4" hwp:id="sec-7"><title hwp:id="title-11">Methods</title><sec id="s4a" hwp:id="sec-8"><title hwp:id="title-12">Data collection</title><p hwp:id="p-29">Neural and behavioral data were collected from three rhesus macaque monkeys (we refer to them as Subject M, C, and J). All surgical and experimental procedures were approved by the Northwestern University Animal Care and Use Committee, and were consistent with the National Institutes of Health Guide for the Care and Use of Laboratory Animals.</p><p hwp:id="p-30">In the first experiment (Subject M and C), the subjects performed a standard delayed center-out movement paradigm (reaching experiment). The subjects were seated in a primate chair and grasped a handle of a custom 2-D planar manipulandum that controlled a computer cursor on a screen. The subject began each trial by moving to a 2 × 2 × 2 cm target in the center of the workspace. The subject was then required to hold for 500 – 1500 ms before another 2 cm target was randomly displayed in one of eight outer positions regularly spaced at a radial distance of 8 cm. For Subject M, this is followed by another variable delay period of 500 – 1500 ms to plan the movement before an auditory ‘Go’ cue. The sessions with Subject C omitted this instructed delay period and the ‘Go’ cue was provided when the outer target appeared. The subjects were required to reach to the target within 1000 – 1300 ms and hold within it for 500 ms to receive an auditory success tone and a liquid reward.</p><p hwp:id="p-31">In the second experiment (Subject J), the subject performed a center-out isometric task. The hand was placed in a box attached to a 6-axis force-torque sensor (JR3, Inc, Woodland, CA), and the subject applied force about the wrist to move a cursor on a screen. The position of the cursor was linearly related to the applied force. The subject began each trial by keeping the hand relaxed so that the cursor rested on a start target on the screen. After staying in that target for 200 – 1000 ms, a second target appeared and the subject was required to apply force to reach this target within a period of 2000 ms. There was no delay period in this task, therefore the subject could go to the target as soon as it appeared. The subject was then required to hold within this target for 500 ms to receive an auditory success tone and liquid reward.</p><p hwp:id="p-32">After the subjects received extensive training in each task, we surgically implanted a 100-electrode array with 1.5 mm shaft length (Blackrock Microsystems, Salt Lake City) in the primary motor cortex (M1) of each subject. We placed the subjects under isoflurane anesthesia and opened a small craniotomy above the motor cortex. We localized primary motor cortex using both visual landmarks and intracortical microstimulation to identify the arm region in Subjects M and C, and the hand region in Subject J. The arrays were then inserted pneumatically. During the behavioral experiments, we acquired neural data using a Blackrock Microsystems Cerebus system. The cortical signals were amplified and band-pass filtered (250 to 5000 Hz). To record the spiking activity of single neural units, we identified threshold crossings of six times the root-mean square (RMS) noise on each of the 96 recording channels and recorded spike times and brief waveform snippets surrounding the threshold crossings. For the first experiment, we recorded kinematic data from the robot handle at 1000 Hz using encoders in the manipulandum. For the second experiment, we recorded force data from the isometric box at 2000 Hz using the force-torque sensor. After each session, we sorted the neural waveform data using Offline Sorter (Plexon, Inc, Dallas, TX) to identify single neurons and discarded all waveforms believed to be multi-unit activity.</p></sec><sec id="s4b" hwp:id="sec-9"><title hwp:id="title-13">Data preparation</title><p hwp:id="p-33">After sorting the spike data, we estimated the firing rate of a neuron by binning the spike trains into non-overlapping windows of equal size. For the reaching task, we observed sparse firing rates and thus, we bin the data into 200 ms time bins and use data from the time that the ‘Go’ cue is given, to the end of the trial. For the isometric task, we used 50 ms time bins and restricted our analysis to a small time window immediately following the ‘Go’ cue (50 – 200 ms after the cue). The main neural dataset used in the paper (Subject M) contained <italic toggle="yes">d</italic> = 164 neurons and <italic toggle="yes">T</italic> = 1027 time points (across all eight reach directions). The dataset in <xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-3" hwp:rel-id="F4">Fig. 4</xref> from Subject J, contained <italic toggle="yes">d</italic> = 67 neurons and <italic toggle="yes">T</italic> = 550 time points. To test the generalization of DAD to training sets from different subjects, we also used kinematics samples from Subject C, resulting in a dataset of size <italic toggle="yes">T</italic> = 803.</p></sec><sec id="s4c" hwp:id="sec-10"><title hwp:id="title-14">Creating asymmetric tasks</title><p hwp:id="p-34">For all of our experiments, we subsampled both datasets by removing directions of movement or force-production to produce datasets that were non-isotropic (asymmetric and non-reflective) and thus more representative of everyday tasks. To do this, we examined embeddings of the data to find directions of movement that are well represented by the neural data. Once we found these directions, we then sub-selected the entire movement and neural data to use only the trials in the selected directions. This approach is necessary to produce distributions that can be aligned with DAD.</p></sec><sec id="s4d" hwp:id="sec-11"><title hwp:id="title-15">Basics of movement decoding</title><p hwp:id="p-35">Before diving into DAD, we first need to define the variables for our decoding problem. Let <bold>y</bold><sub><italic toggle="yes">i</italic></sub> ∈ ℝ<sup><italic toggle="yes">d</italic></sup> denote the firing rate of <italic toggle="yes">d</italic> neurons at the <italic toggle="yes">i</italic><sup>th</sup> point in time (sample). The time-varying neural activity of a population of <italic toggle="yes">d</italic> neurons can be represented as a matrix <bold>Y</bold> of size <italic toggle="yes">d</italic> × <italic toggle="yes">T</italic> by stacking the neural activity vectors {<bold>y</bold><sub>1</sub>, <bold>y</bold><sub>2</sub>, …, <bold>y</bold><sub><italic toggle="yes">T</italic></sub>} into the columns of <bold>Y</bold>. The aim of movement decoding is to make use of the measured firing rates of a population to estimate the intended velocity vector <inline-formula hwp:id="inline-formula-1"><alternatives hwp:id="alternatives-1"><inline-graphic xlink:href="080861_inline1.gif" hwp:id="inline-graphic-1"/></alternatives></inline-formula> at the <italic toggle="yes">i</italic><sup>th</sup> point in time, where each entry of <inline-formula hwp:id="inline-formula-2"><alternatives hwp:id="alternatives-2"><inline-graphic xlink:href="080861_inline2.gif" hwp:id="inline-graphic-2"/></alternatives></inline-formula> corresponds to the Cartesian velocities of movement in the <italic toggle="yes">xy</italic>-plane. Ultimately, our objective will be to map the neural activities to the space of decoded movements.</p><p hwp:id="p-36">A large body of work has demonstrated that the relationship between the instantaneous velocity vector <inline-formula hwp:id="inline-formula-3"><alternatives hwp:id="alternatives-3"><inline-graphic xlink:href="080861_inline3.gif" hwp:id="inline-graphic-3"/></alternatives></inline-formula> and the neural activity signal <bold>y</bold><sub><italic toggle="yes">i</italic></sub> in the motor cortex area M1 is approximately linear<sup><xref ref-type="bibr" rid="c29" hwp:id="xref-ref-29-1" hwp:rel-id="ref-29">29</xref>–<xref ref-type="bibr" rid="c31" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">31</xref></sup>. More recently, studies have shown that neurons are also tuned to to the magnitude of the 2D velocities<sup><xref ref-type="bibr" rid="c13" hwp:id="xref-ref-13-2" hwp:rel-id="ref-13">13</xref></sup>. Thus the kinematics and their magnitude, at the <italic toggle="yes">i</italic><sup>th</sup> point in time, can be decoded as <bold>v</bold><sub><italic toggle="yes">i</italic></sub> = <bold>Hy</bold><sub><italic toggle="yes">i</italic></sub>, where <bold>H</bold> is a 3 × <italic toggle="yes">d</italic> matrix and <bold>v</bold><sub><italic toggle="yes">i</italic></sub> ∈ ℝ<sup>3</sup> includes the magnitude of the kinematics as its third dimension.</p><p hwp:id="p-37">In general, the right matrix for decoding (<bold>H</bold>) is unknown and must be estimated from neural and kinematics recordings. Here we assume that this linear model is time-invariant, and thus we can also write this model in matrix form as
<disp-formula id="eqn1" hwp:id="disp-formula-1" hwp:rev-id="xref-disp-formula-1-1 xref-disp-formula-1-2">
<alternatives hwp:id="alternatives-4"><graphic xlink:href="080861_eqn1.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives>
</disp-formula>
where <bold>V</bold> is a 3 × <italic toggle="yes">T</italic> matrix that contains the kinematics associated with the observed neural activities. When we have access to simultaneous recordings of kinematics <bold>V</bold> and the neural activity <bold>Y</bold>, this information can be used to estimate the matrix <bold>H</bold> (<xref ref-type="disp-formula" rid="eqn1" hwp:id="xref-disp-formula-1-1" hwp:rel-id="disp-formula-1">Eqn. 1</xref>). One way of solving this problem is to find a regularized least-squares estimate which minimizes the following loss function
<disp-formula id="eqn2" hwp:id="disp-formula-2" hwp:rev-id="xref-disp-formula-2-1">
<alternatives hwp:id="alternatives-5"><graphic xlink:href="080861_eqn2.gif" position="float" orientation="portrait" hwp:id="graphic-6"/></alternatives>
</disp-formula>
where <inline-formula hwp:id="inline-formula-4"><alternatives hwp:id="alternatives-6"><inline-graphic xlink:href="080861_inline4.gif" hwp:id="inline-graphic-4"/></alternatives></inline-formula> is the Frobenius norm and <italic toggle="yes">λ</italic> ≥ 0 is a user specified regularization parameter. This loss function defines the interplay between an error term and a term favoring simpler solutions.</p></sec><sec id="s4e" hwp:id="sec-12"><title hwp:id="title-16">Distribution alignment decoding (DAD) approach</title><p hwp:id="p-38">In contrast to the standard paradigm described above, we now consider the setting where we acquire <italic toggle="yes">N</italic> samples of the kinematics <bold>V</bold> ∈ ℝ<sup>3×<italic toggle="yes">N</italic></sup> separately from neural activity. Take for instance the case where we have recorded the kinematics from multiple users doing the same task and then, at a later time, we collect neural activity <bold>Y</bold> ∈ ℝ<sup><italic toggle="yes">d</italic>×<italic toggle="yes">T</italic></sup> from a new user performing the same task. Since the kinematics <bold>V</bold> and neural activity <bold>Y</bold> are recorded at different times and are potentially of unequal dimension, determining the linear model <bold>H</bold> cannot be done by solving <xref ref-type="disp-formula" rid="eqn1" hwp:id="xref-disp-formula-1-2" hwp:rel-id="disp-formula-1">Eqn. 1</xref>. Even if the datasets contain the same number of samples (i.e. <italic toggle="yes">N</italic> = <italic toggle="yes">T</italic>), finding correspondence between the columns of <bold>V</bold> and the columns of <bold>Y</bold> is a NP hard problem<sup><xref ref-type="bibr" rid="c32" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">32</xref></sup>.</p><p hwp:id="p-39">Rather than tackling the problem of finding correspondence between the two datasets, we can leverage the fact that the underlying distributions of samples in both spaces have similar structures to find a linear mapping that aligns the two. A natural framing of this problem is to find the best linear embedding of the neural data which minimizes the KL-divergence between the predicted distribution of kinematics (<italic toggle="yes">q</italic>) and the prior distribution of recorded kinematics (<italic toggle="yes">p</italic>). More formally, assume that the set of samples {<bold>v</bold><sub>1</sub>, <bold>v</bold><sub>2</sub>, …, <bold>v</bold><sub><italic toggle="yes">N</italic></sub>} are drawn from a distribution <italic toggle="yes">p</italic> and that the pre-dicted kinematics vectors <inline-formula hwp:id="inline-formula-5"><alternatives hwp:id="alternatives-7"><inline-graphic xlink:href="080861_inline5.gif" hwp:id="inline-graphic-5"/></alternatives></inline-formula> are drawn from a distribution <italic toggle="yes">q</italic>. To estimate <bold>H</bold>, our goal is to find a solution to the following optimization problem:
<disp-formula id="eqn3" hwp:id="disp-formula-3" hwp:rev-id="xref-disp-formula-3-1 xref-disp-formula-3-2 xref-disp-formula-3-3">
<alternatives hwp:id="alternatives-8"><graphic xlink:href="080861_eqn3.gif" position="float" orientation="portrait" hwp:id="graphic-7"/></alternatives>
</disp-formula>
where the random variable <bold>x</bold> <italic toggle="yes">∈</italic> ℝ<sup>3</sup> is drawn from the distribution <italic toggle="yes">p</italic>. By minimizing the KL-divergence, our approach essentially finds an affine transformation which maximizes the similarity between the distribution of transformed neural activity and prior distribution of kinematics.</p><p hwp:id="p-40">In general, solving the problem in <xref ref-type="disp-formula" rid="eqn3" hwp:id="xref-disp-formula-3-1" hwp:rel-id="disp-formula-3">Eqn. 3</xref> is intractable, due to the fact that the KL-divergence can be a non-convex and non-differentiable function of <bold>H</bold>. However, we can exploit the fact that, without substantial loss of information, <bold>Y</bold> can be projected into a lower-dimensional space where solving this problem is possible. We denote the resulting projected neural activities and the corresponding (low-d) decoder as <bold>Y</bold><sub><italic toggle="yes">ℓ</italic></sub> and <bold>H</bold><sub><italic toggle="yes">ℓ</italic></sub>, respectively. When the mapping between <bold>Y</bold> and <bold>V</bold> is linear, the problem of distribution alignment can be reduced to finding the best linear transformation <bold>H</bold><sub><italic toggle="yes">ℓ</italic></sub> such that the KL-divergence between the distribution of observed kinematics <italic toggle="yes">p</italic> and predicted kinematics <italic toggle="yes">q</italic> is minimized. In a lower dimensional space, the alignment between the distributions of neural data and kinematics is feasible. To solve our low-dimensional alignment problem, DAD combines the benefits of fast closest point matching strategies<sup><xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">33</xref></sup> with the use of the KL-divergence as a metric for alignment.</p></sec><sec id="s4f" hwp:id="sec-13"><title hwp:id="title-17">Computing the KL-divergence</title><p hwp:id="p-41">To measure the KL-divergence between the distributions <italic toggle="yes">p</italic> (target) and <italic toggle="yes">q</italic> (source) in <xref ref-type="disp-formula" rid="eqn3" hwp:id="xref-disp-formula-3-2" hwp:rel-id="disp-formula-3">Eqn. 3</xref>, we adopt a non-parametric approach that allows us to obtain an accurate estimate of these distributions without making any restrictive assumption on the form of either distribution. In particular, we rely on the popular <italic toggle="yes">k</italic>-nearest neighbors (KNN) density estimation algorithm<sup><xref ref-type="bibr" rid="c34" hwp:id="xref-ref-34-1" hwp:rel-id="ref-34">34</xref>,<xref ref-type="bibr" rid="c35" hwp:id="xref-ref-35-1" hwp:rel-id="ref-35">35</xref></sup>, which estimates a distribution using only distances between the samples and their <italic toggle="yes">k</italic><sup>th</sup> nearest neighbor. To make this concrete, we define the distance between a vector x and a matrix <bold>A</bold> as <italic toggle="yes">ρ</italic><sub><italic toggle="yes">k</italic></sub>(<bold>x</bold>, <bold>A</bold>) = ||<bold>x</bold> – <bold>a</bold><sub><italic toggle="yes">k</italic></sub>||<sub>2</sub>, where <bold>a</bold><sub><italic toggle="yes">k</italic></sub> is the <italic toggle="yes">k</italic><sup>th</sup> nearest neighbor to x contained in the columns of <bold>A</bold>. The value of the empirical distribution <italic toggle="yes">p</italic> at <bold>v</bold><sub><italic toggle="yes">i</italic></sub> is then estimated using the following consistent estimator<sup><xref ref-type="bibr" rid="c34" hwp:id="xref-ref-34-2" hwp:rel-id="ref-34">34</xref></sup>:
<disp-formula hwp:id="disp-formula-4">
<alternatives hwp:id="alternatives-9"><graphic xlink:href="080861_ueqn1.gif" position="float" orientation="portrait" hwp:id="graphic-8"/></alternatives>
</disp-formula></p><p hwp:id="p-42">We partition the 3D space and then compute this quantity for every grid point. After computing the 3D density, we normalize to obtain a proper probability distribution over the space of grid points. Note that the intuition behind this approach is that in regions where we have higher density of samples, the k-nearest distance <italic toggle="yes">ρ</italic><sub><italic toggle="yes">k</italic></sub>(<bold>v</bold><sub><italic toggle="yes">i</italic></sub>, <bold>V</bold>) will be small and thus, the probability of generating a sample at this location is large. In practice, we set <inline-formula hwp:id="inline-formula-6"><alternatives hwp:id="alternatives-10"><inline-graphic xlink:href="080861_inline6.gif" hwp:id="inline-graphic-6"/></alternatives></inline-formula> which guarantees that the estimates of <italic toggle="yes">p</italic> will asymptotically converge to the exact point estimates of the distribution since <italic toggle="yes">ρ</italic><sub><italic toggle="yes">k</italic></sub> converges to 0 as <italic toggle="yes">N</italic> → +∞ <sup><xref ref-type="bibr" rid="c34" hwp:id="xref-ref-34-3" hwp:rel-id="ref-34">34</xref></sup>.</p><p hwp:id="p-43">To estimate the distribution of the predicted kinematics <inline-formula hwp:id="inline-formula-7"><alternatives hwp:id="alternatives-11"><inline-graphic xlink:href="080861_inline7.gif" hwp:id="inline-graphic-7"/></alternatives></inline-formula> from the projected neural activities <bold>Y</bold><sub><italic toggle="yes">ℓ</italic></sub>, we again use the same nearest neighbor approach. Assuming that we have an estimate for <bold>H</bold><sub><italic toggle="yes">ℓ</italic></sub> and <bold>Y</bold><sub><italic toggle="yes">ℓ</italic></sub>, the empirical distribution of the predicted dynamics is given by <inline-formula hwp:id="inline-formula-8"><alternatives hwp:id="alternatives-12"><inline-graphic xlink:href="080861_inline8.gif" hwp:id="inline-graphic-8"/></alternatives></inline-formula>. As with <italic toggle="yes">p</italic>, we compute this quantity for all <italic toggle="yes">D</italic> grid points and then normalize to produce a probability distribution of these points.</p><p hwp:id="p-44">Once we compute the empirical distributions <italic toggle="yes">p</italic> and <italic toggle="yes">q</italic> over a fixed 3D grid {s<sub>1</sub>, …, s<sub><italic toggle="yes">D</italic></sub>}, we can use the following formula to estimate the KL-divergence:
<disp-formula hwp:id="disp-formula-5">
<alternatives hwp:id="alternatives-13"><graphic xlink:href="080861_ueqn2.gif" position="float" orientation="portrait" hwp:id="graphic-9"/></alternatives>
</disp-formula></p><p hwp:id="p-45">Upon estimating the probability distributions <italic toggle="yes">p</italic> and <italic toggle="yes">q</italic>, our aim is to find the best <bold>H</bold><sub><italic toggle="yes">ℓ</italic></sub> that minimizes their divergence. Solving this problem is intractable for large dimensions since the computational cost of solving <xref ref-type="disp-formula" rid="eqn3" hwp:id="xref-disp-formula-3-3" hwp:rel-id="disp-formula-3">Eqn. 3</xref> scales exponentially with the dimension of the problem. Luckily, since the dimension of the task is small, it is possible to efficiently solve this optimization problem.</p></sec><sec id="s4g" hwp:id="sec-14"><title hwp:id="title-18">Alignment algorithm</title><p hwp:id="p-46">After reducing the dimensionality of the neural data, our alignment method consists of two main steps: 3D alignment (using a cone prior to regularize our problem) and then a fine-scale alignment in 2D. Both steps rely on the KL-divergence to measure the goodness of fit.</p><p hwp:id="p-47">To align the datasets in 3D, we start by applying a 3D rotation to the source distribution (projected neural data) to initialize our search. After applying a 3D rotation, we apply an iterative closest point (ICP) algorithm<sup><xref ref-type="bibr" rid="c33" hwp:id="xref-ref-33-2" hwp:rel-id="ref-33">33</xref></sup> to quickly match the two sets of points. This ICP step is important for finding the translation of the point clouds needed to obtain alignment. After aligning the datasets with ICP, we measure the KL-divergence between the target distribution and the alignment (when initializing with a 3D rotation). We repeat these steps over the space of 3D rotations (coarse grid search is sufficient) and measure the KL-divergence between each possible rotation and alignment. The alignment with minimal KL-divergence is selected as the output of our 3D alignment procedure.</p><p hwp:id="p-48">After finding a 3D alignment, we often need to refine the estimate further. Thus we select the first two coordinates from our 3D embedding, which if the 3D alignment is done correctly, maps the data into the correct plane where the movement directions are visible. We then apply a similar alignment procedure in 2D, where we perform an exhaustive search over the rotation angle (2D) from 0-360 degrees and over two scaling parameters to define the skew of the data. We finally return the 2D embedding that minimizes the KL divergence between the target and source data.</p></sec><sec id="s4h" hwp:id="sec-15"><title hwp:id="title-19">Dimensionality reduction</title><p hwp:id="p-49">To quickly assess the low-dimensional structure of the data, we designed a module to pre-processes the neural data and apply a variety of dimensionality reduction techniques to the data. Using a Matlab toolbox for dimensionality reduction<sup><xref ref-type="bibr" rid="c15" hwp:id="xref-ref-15-2" hwp:rel-id="ref-15">15</xref></sup>, we applied PCA, factor analysis (FA), Isomap<sup><xref ref-type="bibr" rid="c36" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">36</xref></sup>, tSNE, SNE, Probabilistic PCA, and others. In addition, we also applied a Matlab toolbox for neural data analysis which implements generalized PCA<sup><xref ref-type="bibr" rid="c16" hwp:id="xref-ref-16-2" hwp:rel-id="ref-16">16</xref></sup>, using an exponential link function. We applied these techniques to our data and visually inspected the resulting embeddings to ensure that the task structure is indeed visible in the data. Note that this step can be done in a completely unsupervised way. After triaging the data to find embeddings with clear low-dimensional structure, we then applied DAD to align the neural data onto a prior movement distribution for the task. In our evaluations, we used factor analysis (FA) for all of the real motor datasets and used PCA for our synthetic experiments, as we found the more accurate and consistent embeddings with these methods.</p></sec><sec id="s4i" hwp:id="sec-16"><title hwp:id="title-20">Incorporating prior knowledge into our alignment procedure</title><p hwp:id="p-50">Due to the non-convexity of our KL-divergence minimization problem (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-8" hwp:rel-id="F1">Fig. 1b</xref>), it is important to use our prior knowledge about the shape of the target distribution in our optimization procedure<sup><xref ref-type="bibr" rid="c37" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">37</xref></sup>. We thus leverage the fact that the support of the distribution (regions with non-zero probability) lie near a cone in 3D. We confirm this shape both in the 3D projections of neural activity and also in the target kinematics when we take into account the magnitude of 2D kinematics as a third covariate in our linear model (<xref rid="fig1" ref-type="fig" hwp:id="xref-fig-1-9" hwp:rel-id="F1">Fig. 1d</xref>). Thus we can use this fact to improve the accuracy and efficiency of our alignment procedure by regularizing our KL-divergence problem and minimizing the number of possible local minima in our search. In practice, this means we leverage the bounded support of the distribution to appropriately rescale and then find a translation and scaling for distribution alignment.</p></sec><sec id="s4j" hwp:id="sec-17"><title hwp:id="title-21">Using noise to improve shape matching</title><p hwp:id="p-51">Our approach for shape matching via KL-divergence minimization seems to hold up well against synthetic data. However, when dealing with real neural datasets, we are sometimes faced with that problem that our target (clean) and source (messy) distributions do not look similar enough. Thus, when the size of the datasets are not matched, we create a blurred and oversampled version of our (clean) target kinematics data by replicating each data point and adding a small amount of Gaussian noise to each of these replicas. Our blurring procedure can be used to produce a better match between the clean target and messy source distributions.</p></sec><sec id="s4k" hwp:id="sec-18"><title hwp:id="title-22">Synthetic model</title><p hwp:id="p-52">When simulating neural activity, the firing rate of the <italic toggle="yes">n</italic><sup>th</sup> neuron at the <italic toggle="yes">t</italic><sup>th</sup> time point is given by
<disp-formula hwp:id="disp-formula-6">
<alternatives hwp:id="alternatives-14"><graphic xlink:href="080861_ueqn3.gif" position="float" orientation="portrait" hwp:id="graphic-10"/></alternatives>
</disp-formula>
where <italic toggle="yes">θ</italic><sup><italic toggle="yes">n</italic></sup> is the preferred direction of the <italic toggle="yes">n</italic><sup>th</sup> neuron, <italic toggle="yes">θ</italic><sup><italic toggle="yes">t</italic></sup> = tan<sup><italic toggle="yes">−</italic>1</sup>(<italic toggle="yes">v</italic><sub><italic toggle="yes">x,t</italic></sub>/<italic toggle="yes">v</italic><sub><italic toggle="yes">y,t</italic></sub>) is the direction of the movement at the <italic toggle="yes">t</italic><sup>th</sup> time point, <italic toggle="yes">v</italic><sub><italic toggle="yes">x,t</italic></sub> is the velocity in the x-direction at time t, <italic toggle="yes">v</italic><sub><italic toggle="yes">y,t</italic></sub> is the velocity in the y-direction at time t, and <italic toggle="yes">α</italic><sub><italic toggle="yes">n</italic></sub> and <italic toggle="yes">β</italic><sub><italic toggle="yes">n</italic></sub> are scalars which shift and modulate the firing rate, respectively. To generate spikes for a population of size <italic toggle="yes">N</italic>, we generate Poisson random variables according to the firing rates {<italic toggle="yes">f</italic><sub>1</sub>, …, <italic toggle="yes">f</italic><sub><italic toggle="yes">N</italic></sub>}. In our simulations (<xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-4" hwp:rel-id="F4">Fig. 4</xref>), we set the baseline <italic toggle="yes">α</italic><sub><italic toggle="yes">n</italic></sub> = 2, for all neurons (<italic toggle="yes">∀n</italic>) and set the modulation term <inline-formula hwp:id="inline-formula-9"><alternatives hwp:id="alternatives-15"><inline-graphic xlink:href="080861_inline9.gif" hwp:id="inline-graphic-9"/></alternatives></inline-formula> where <inline-formula hwp:id="inline-formula-10"><alternatives hwp:id="alternatives-16"><inline-graphic xlink:href="080861_inline10.gif" hwp:id="inline-graphic-10"/></alternatives></inline-formula></p></sec><sec id="s4l" hwp:id="sec-19"><title hwp:id="title-23">Code availability and reproducibility</title><p hwp:id="p-53">All of the code and scripts to generate figures are located at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://github.com/KordingLab/DAD" ext-link-type="uri" xlink:href="http://github.com/KordingLab/DAD" hwp:id="ext-link-2">http://github.com/KordingLab/DAD</ext-link>. To generate the figures in this paper, we used neural data from Subject M and J, and motor variables from Subject’s M, C, and J. When applying DAD, there are a few parameters that we vary when processing the data and use later in alignment. The parameters are passed into the opts structure into the main wrapper function ‘runDAD.m’.</p><list list-type="bullet" hwp:id="list-1"><list-item hwp:id="list-item-1"><title hwp:id="title-24">Size of grid search:</title><p hwp:id="p-54">This parameter controls the number of 3D rotations to test as initial points in the 3D alignment step. We observe that a relatively coarse search is fine, we set this parameter to 3 (to generate 27 different angles in 3D) in all of the analysis in this paper.</p></list-item><list-item hwp:id="list-item-2"><title hwp:id="title-25">Noise variance:</title><p hwp:id="p-55">This parameter controls the variance of any noise added to the training distribution. We need to set this when the neural embeddings are very noisy and the matching procedure is not effective enough. In our experiments on Subject M, we do not add noise to the training data. For Subject J’s data, we often need to add some amount of noise—the results in <xref rid="fig4" ref-type="fig" hwp:id="xref-fig-4-5" hwp:rel-id="F4">Fig. 4</xref> were generated by setting the variance to 0.1.</p></list-item><list-item hwp:id="list-item-3"><title hwp:id="title-26">Dimensionality reduction:</title><p hwp:id="p-56">Our code allows the user to specify the different dimensionality reduction methods they wish to test. To produce the results in the paper, we used factor analysis (FA) for all of our experiments on real data and PCA for our synthetic experiments.</p></list-item></list></sec></sec></body><back><ref-list hwp:id="ref-list-1"><title hwp:id="title-27">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1"><label>1.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Kay KN"><given-names>KN</given-names> <surname>Kay</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-2">Identifying natural images from human brain activity</article-title>. <source hwp:id="source-1">Nature</source>, <volume>452</volume>(<issue>7185</issue>):<fpage>352</fpage>–<lpage>355</lpage>, <year>2008</year>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1"><label>2.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Cowen AS"><given-names>AS</given-names> <surname>Cowen</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-3">Neural portraits of perception: reconstructing face images from evoked brain activity</article-title>. <source hwp:id="source-2">Neuroimage</source>, <volume>94</volume>:<fpage>12</fpage>–<lpage>22</lpage>, <year>2014</year>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><label>3.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Mitchell TM"><given-names>TM</given-names> <surname>Mitchell</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-4">Predicting human brain activity associated with the meanings of nouns</article-title>. <source hwp:id="source-3">Science</source>, <volume>320</volume>(<issue>5880</issue>):<fpage>1191</fpage>–<lpage>1195</lpage>, <year>2008</year>.</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1"><label>4.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Haynes J"><given-names>J</given-names> <surname>Haynes</surname></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-5">Decoding mental states from brain activity in humans</article-title>. <source hwp:id="source-4">Nat Rev Neurosci</source>, <volume>7</volume>(<issue>7</issue>):<fpage>523</fpage>–<lpage>534</lpage>, <year>2006</year>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1"><label>5.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Serruya MD"><given-names>MD</given-names> <surname>Serruya</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-6">Brain-machine interface: Instant neural control of a movement signal</article-title>. <source hwp:id="source-5">Nature</source>, <volume>416</volume>(<issue>6877</issue>):<fpage>141</fpage>–<lpage>142</lpage>, <year>2002</year>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2"><label>6.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Kemere C"><given-names>C</given-names> <surname>Kemere</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-7">Model-based neural decoding of reaching movements: a maximum likelihood approach</article-title>. <source hwp:id="source-6">IEEE Trans Biomed Eng</source>, <volume>51</volume>(<issue>6</issue>):<fpage>925</fpage>–<lpage>932</lpage>, <year>2004</year>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1"><label>7.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Tkach D"><given-names>D</given-names> <surname>Tkach</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-8">Observation-based learning for brain–machine interfaces</article-title>. <source hwp:id="source-7">Curr Opin Neurobiol</source>, <volume>18</volume>(<issue>6</issue>):<fpage>589</fpage>–<lpage>594</lpage>, <year>2008</year>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><label>8.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Donoghue JP"><given-names>JP</given-names> <surname>Donoghue</surname></string-name>. <article-title hwp:id="article-title-9">Connecting cortex to machines: recent advances in brain interfaces</article-title>. <source hwp:id="source-8">Nat Neurosci</source>, <volume>5</volume>:<fpage>1085</fpage>–<lpage>1088</lpage>, <year>2002</year>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1 xref-ref-9-2"><label>9.</label><citation publication-type="book" citation-type="book" ref:id="080861v1.9" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Bose R"><given-names>R</given-names> <surname>Bose</surname></string-name>. <source hwp:id="source-9">Information theory, coding and cryptography</source>. <publisher-name>McGraw-Hill Education</publisher-name>, <year>2008</year>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1"><label>10.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.10" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Chaudhari MP"><given-names>MP</given-names> <surname>Chaudhari</surname></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-10">A survey on cryptography algorithms</article-title>. <source hwp:id="source-10">International Journal of Advance Research in Computer Science and Management Studies</source>, <volume>2</volume>(<issue>3</issue>), <year>2014</year>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1 xref-ref-11-2"><label>11.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Ingram JN"><given-names>JN</given-names> <surname>Ingram</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-11">The statistics of natural hand movements</article-title>. <source hwp:id="source-11">Exp Brain Res</source>, <volume>188</volume>(<issue>2</issue>):<fpage>223</fpage>–<lpage>236</lpage>, <year>2008</year>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1"><label>12.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.12" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Belić JJ"><given-names>JJ</given-names> <surname>Belić</surname></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-12">Decoding of human hand actions to handle missing limbs in neuroprosthetics</article-title>. <source hwp:id="source-12">Front Comp Neuro</source>, <volume>9</volume>, <year>2015</year>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1 xref-ref-13-2"><label>13.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Stevenson IH"><given-names>IH</given-names> <surname>Stevenson</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-13">Functional connectivity and tuning curves in populations of simultaneously recorded neurons</article-title>. <source hwp:id="source-13">PLoS Comput Biol</source>, <volume>8</volume>(<issue>11</issue>):<fpage>e1002775</fpage>, <year>2012</year>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><label>14.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Cunningham JP"><given-names>JP</given-names> <surname>Cunningham</surname></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-14">Dimensionality reduction for large-scale neural recordings</article-title>. <source hwp:id="source-14">Nat Neurosci</source>, <volume>17</volume>(<issue>11</issue>):<fpage>1500</fpage>–<lpage>1509</lpage>, <year>2014</year>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1 xref-ref-15-2"><label>15.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.15" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Van Der Maaten L"><given-names>L</given-names> <surname>Van Der Maaten</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-15">Dimensionality reduction: a comparative review</article-title>. <source hwp:id="source-15">J Mach Learn Res</source>, <volume>10</volume>:<fpage>66</fpage>–<lpage>71</lpage>, <year>2009</year>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1 xref-ref-16-2"><label>16.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.16" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Macke JH"><given-names>JH</given-names> <surname>Macke</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-16">Empirical models of spiking in neural populations</article-title>. In <source hwp:id="source-16">Proc Adv Neural Proc Sys</source>, <fpage>1350</fpage>–<lpage>1358</lpage>. <year>2011</year>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><label>17.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Georgopoulos AP"><given-names>AP</given-names> <surname>Georgopoulos</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-17">Neuronal population coding of movement direction</article-title>. <source hwp:id="source-17">Science</source>, <volume>233</volume>(<issue>4771</issue>):<fpage>1416</fpage>–<lpage>1419</lpage>, <year>1986</year>.</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1 xref-ref-18-2"><label>18.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.18" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Pillow JW"><given-names>JW</given-names> <surname>Pillow</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-18">Spatio-temporal correlations and visual signaling in a complete neuronal population</article-title>. <source hwp:id="source-18">Nature</source>, <volume>454</volume>(<issue>7207</issue>):<fpage>995</fpage>–<lpage>999</lpage>, <year>2008</year>.</citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1"><label>19.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.19" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Dyer EL"><given-names>EL</given-names> <surname>Dyer</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-19">Greedy feature selection for subspace clustering</article-title>. <source hwp:id="source-19">J Mach Learn Res</source>, <volume>14</volume>(<issue>1</issue>):<fpage>2487</fpage>–<lpage>2517</lpage>, <year>2013</year>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><label>20.</label><citation publication-type="book" citation-type="book" ref:id="080861v1.20" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Schölkopf B"><given-names>B</given-names> <surname>Schölkopf</surname></string-name>, <etal>et al.</etal> <source hwp:id="source-20">Kernel methods in computational biology.</source> <publisher-name>MIT Press</publisher-name>, <year>2004</year>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1"><label>21.</label><citation publication-type="other" citation-type="journal" ref:id="080861v1.21" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Ejaz N"><given-names>N</given-names> <surname>Ejaz</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-20">Hand use predicts the structure of representations in sensorimotor cortex</article-title>. <source hwp:id="source-21">Nat neurosci</source>, <year>2015</year>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><label>22.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Fernandes HL"><given-names>HL</given-names> <surname>Fernandes</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-21">Saliency and saccade encoding in the frontal eye field during natural scene search</article-title>. <source hwp:id="source-22">Cereb Cortex</source>, <volume>24</volume>(<issue>12</issue>):<fpage>3232</fpage>–<lpage>3245</lpage>, <year>2014</year>.</citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1"><label>23.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.23" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Yu BM"><given-names>BM</given-names> <surname>Yu</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-22">Gaussian-process factor analysis for low-dimensional single-trial analysis of neural population activity</article-title>. In <source hwp:id="source-23">Proc Adv Neural Proc Sys</source>, <fpage>1881</fpage>–<lpage>1888</lpage>. <year>2009</year>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1"><label>24.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.24" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Rokni U"><given-names>U</given-names> <surname>Rokni</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-23">Motor learning with unstable neural representations</article-title>. <source hwp:id="source-24">Neuron</source>, <volume>54</volume>(<issue>4</issue>):<fpage>653</fpage>–<lpage>666</lpage>, <year>2007</year>.</citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1"><label>25.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Li Z"><given-names>Z</given-names> <surname>Li</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-24">Adaptive decoding for brain-machine interfaces through bayesian parameter updates</article-title>. <source hwp:id="source-25">Neural Comput</source>, <volume>23</volume>(<issue>12</issue>):<fpage>3162</fpage>–<lpage>3204</lpage>, <year>2011</year>.</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1"><label>26.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.26" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Lakshmanan KC"><given-names>KC</given-names> <surname>Lakshmanan</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-25">Extracting low-dimensional latent structure from time series in the presence of delays</article-title>. <source hwp:id="source-26">Neural Comput</source>, <year>2015</year>.</citation></ref><ref id="c27" hwp:id="ref-27"><label>27.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.27" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="Kobak D"><given-names>D</given-names> <surname>Kobak</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-26">Demixed principal component analysis of neural population data</article-title>. <source hwp:id="source-27">eLife</source>, <volume>5</volume>:<fpage>e10989</fpage>, <year>2016</year>.</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1"><label>28.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.28" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="Kao JC"><given-names>JC</given-names> <surname>Kao</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-27">Single-trial dynamics of motor cortex and their applications to brain-machine interfaces</article-title>. <source hwp:id="source-28">Nat Commun</source>, <volume>6</volume>, <year>2015</year>.</citation></ref><ref id="c29" hwp:id="ref-29" hwp:rev-id="xref-ref-29-1"><label>29.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.29" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="Ashe J"><given-names>J</given-names> <surname>Ashe</surname></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-28">Movement parameters and neural activity in motor cortex and area 5</article-title>. <source hwp:id="source-29">Cereb Cortex</source>, <volume>4</volume>(<issue>6</issue>):<fpage>590</fpage>–<lpage>600</lpage>, <year>1994</year>.</citation></ref><ref id="c30" hwp:id="ref-30"><label>30.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.30" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="Averbeck BB"><given-names>BB</given-names> <surname>Averbeck</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-29">Parietal representation of hand velocity in a copy task</article-title>. <source hwp:id="source-30">J Neurophysio</source>, <volume>93</volume>(<issue>1</issue>):<fpage>508</fpage>–<lpage>518</lpage>, <year>2005</year>.</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1"><label>31.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="Stevenson IH"><given-names>IH</given-names> <surname>Stevenson</surname></string-name>, <etal>et al.</etal> <source hwp:id="source-31">Statistical assessment of the stability of neural movement representations</source>. <volume>106</volume>(<issue>2</issue>):<fpage>764</fpage>–<lpage>774</lpage>, <year>2011</year>.</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1"><label>32.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.32" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="Jagabathula S"><given-names>S</given-names> <surname>Jagabathula</surname></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-30">Inferring rankings using constrained sensing</article-title>. <source hwp:id="source-32">IEEE Trans Inform Theory</source>, <volume>57</volume>(<issue>11</issue>):<fpage>7288</fpage>–<lpage>7306</lpage>, <year>2011</year>.</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1 xref-ref-33-2"><label>33.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.33" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Bergström P"><given-names>P</given-names> <surname>Bergström</surname></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-31">Robust registration of point sets using iteratively reweighted least squares</article-title>. <source hwp:id="source-33">Comput Optim Appl</source>, <volume>58</volume>(<issue>3</issue>):<fpage>543</fpage>–<lpage>561</lpage>, <year>2014</year>.</citation></ref><ref id="c34" hwp:id="ref-34" hwp:rev-id="xref-ref-34-1 xref-ref-34-2 xref-ref-34-3"><label>34.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.34" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Póczos B"><given-names>B</given-names> <surname>Póczos</surname></string-name> <etal>et al.</etal> <article-title hwp:id="article-title-32">On the estimation of alpha-divergences</article-title>. In <source hwp:id="source-34">Proc. Int. Conf. Art. Intell. Stat. (AISTATS)</source>, <fpage>609</fpage>–<lpage>617</lpage>. <year>2011</year>.</citation></ref><ref id="c35" hwp:id="ref-35" hwp:rev-id="xref-ref-35-1"><label>35.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.35" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Loftsgaarden DO"><given-names>DO</given-names> <surname>Loftsgaarden</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-33">A nonparametric estimate of a multivariate density function</article-title>. <source hwp:id="source-35">Ann Math Stat</source>, <volume>36</volume>(<issue>3</issue>):<fpage>1049</fpage>–<lpage>1051</lpage>, <year>1965</year>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1"><label>36.</label><citation publication-type="journal" citation-type="journal" ref:id="080861v1.36" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Tenenbaum JB"><given-names>JB</given-names> <surname>Tenenbaum</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-34">A global geometric framework for nonlinear dimensionality reduction</article-title>. <source hwp:id="source-36">science</source>, <volume>290</volume>(<issue>5500</issue>):<fpage>2319</fpage>–<lpage>2323</lpage>, <year>2000</year>.</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1"><label>37.</label><citation publication-type="other" citation-type="journal" ref:id="080861v1.37" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Hasanbelliu E"><given-names>E</given-names> <surname>Hasanbelliu</surname></string-name>, <etal>et al.</etal> <article-title hwp:id="article-title-35">Information theoretic shape matching</article-title>. <year>2014</year>.</citation></ref></ref-list></back></article>
