<article article-type="article" specific-use="production" xml:lang="en" xmlns:hw="org.highwire.hpp" xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:ali="http://www.niso.org/schemas/ali/1.0/" xmlns:ref="http://schema.highwire.org/Reference" xmlns:hwp="http://schema.highwire.org/Journal" xmlns:l="http://schema.highwire.org/Linking" xmlns:r="http://schema.highwire.org/Revision" xmlns:x="http://www.w3.org/1999/xhtml" xmlns:app="http://www.w3.org/2007/app" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:nlm="http://schema.highwire.org/NLM/Journal" xmlns:a="http://www.w3.org/2005/Atom" xmlns:c="http://schema.highwire.org/Compound" xmlns:hpp="http://schema.highwire.org/Publishing"><front><journal-meta><journal-id journal-id-type="hwp">biorxiv</journal-id><journal-id journal-id-type="publisher-id">BIORXIV</journal-id><journal-title>bioRxiv</journal-title><abbrev-journal-title abbrev-type="publisher">bioRxiv</abbrev-journal-title><publisher><publisher-name>Cold Spring Harbor Laboratory</publisher-name></publisher></journal-meta><article-meta><article-id pub-id-type="doi">10.1101/057208</article-id><article-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;057208v1</article-id><article-id pub-id-type="other" hwp:sub-type="pisa-master">biorxiv;057208</article-id><article-id pub-id-type="other" hwp:sub-type="slug">057208</article-id><article-id pub-id-type="other" hwp:sub-type="tag">057208</article-id><article-version>1.1</article-version><article-categories><subj-group subj-group-type="author-type"><subject>Regular Article</subject></subj-group><subj-group subj-group-type="heading"><subject>New Results</subject></subj-group><subj-group subj-group-type="hwp-journal-coll" hwp:journal-coll-id="Animal Behavior and Cognition" hwp:journal="biorxiv"><subject>Animal Behavior and Cognition</subject></subj-group></article-categories><title-group><article-title hwp:id="article-title-1">On the optimal response vigor and choice under variable motivational drives</article-title></title-group><author-notes hwp:id="author-notes-1"><fn id="n1" hwp:id="fn-1"><p hwp:id="p-1">Email: <email hwp:id="email-1">amir.dezfouli@nicta.com.au</email></p></fn><fn id="n2" fn-type="author-notes" hwp:id="fn-2"><p hwp:id="p-2">Address: Level 5, 13 Garden Street, Eveleigh, NSW 2015, Australia</p></fn></author-notes><contrib-group hwp:id="contrib-group-1"><contrib contrib-type="author" corresp="yes" hwp:id="contrib-1"><name name-style="western" hwp:sortable="Dezfouli Amir"><surname>Dezfouli</surname><given-names>Amir</given-names></name><xref ref-type="aff" rid="a1" hwp:id="xref-aff-1-1" hwp:rel-id="aff-1"/></contrib><aff id="a1" hwp:id="aff-1" hwp:rev-id="xref-aff-1-1"><institution hwp:id="institution-1">National ICT Australia (NICTA)</institution>.</aff></contrib-group><pub-date pub-type="epub-original" hwp:start="2016"><year>2016</year></pub-date><pub-date pub-type="hwp-created" hwp:start="2016-06-05T17:27:14-07:00">
    <day>5</day><month>6</month><year>2016</year>
  </pub-date><pub-date pub-type="hwp-received" hwp:start="2016-06-05T17:27:14-07:00">
    <day>5</day><month>6</month><year>2016</year>
  </pub-date><pub-date pub-type="epub" hwp:start="2016-06-05T18:25:14-07:00">
    <day>5</day><month>6</month><year>2016</year>
  </pub-date><pub-date pub-type="epub-version" hwp:start="2016-06-05T18:25:14-07:00">
    <day>5</day><month>6</month><year>2016</year>
  </pub-date><elocation-id>057208</elocation-id><history hwp:id="history-1">
<date date-type="received" hwp:start="2016-06-05"><day>05</day><month>6</month><year>2016</year></date>
<date date-type="accepted" hwp:start="2016-06-05"><day>05</day><month>6</month><year>2016</year></date>
</history><permissions><copyright-statement hwp:id="copyright-statement-1">Â© 2016, Posted by Cold Spring Harbor Laboratory</copyright-statement><copyright-year>2016</copyright-year><license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by/4.0/" hwp:id="license-1"><p hwp:id="p-3">This pre-print is available under a Creative Commons License (Attribution 4.0 International), CC BY 4.0, as described at <ext-link l:rel="related" l:ref-type="uri" l:ref="http://creativecommons.org/licenses/by/4.0/" ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by/4.0/" hwp:id="ext-link-1">http://creativecommons.org/licenses/by/4.0/</ext-link></p></license></permissions><self-uri xlink:href="057208.pdf" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/abstract" xlink:role="abstract" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:href="file:/content/biorxiv/vol0/issue2019/pdf/057208v1.pdf" hwp:variant="yes" content-type="pdf" xlink:role="full-text"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/full-text" xlink:role="full-text" content-type="xhtml+xml" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/source" xlink:role="source" content-type="xml" xlink:show="none" hwp:variant="yes"/><self-uri l:ref="forthcoming:yes" c:role="http://schema.highwire.org/variant/original" xlink:role="original" content-type="xml" xlink:show="none" hwp:variant="yes" xlink:href="057208.xml"/><self-uri content-type="abstract" xlink:href="file:/content/biorxiv/vol0/issue2019/abstracts/057208v1/057208v1.htslp"/><self-uri content-type="fulltext" xlink:href="file:/content/biorxiv/vol0/issue2019/fulltext/057208v1/057208v1.htslp"/><abstract hwp:id="abstract-1"><p hwp:id="p-4">Within a rational framework, a decision-maker selects actions based on the reward-maximisation principle, i.e., acquiring the highest amount of reward with the lowest cost. Action selection can be divided into two dimensions: (i) selecting an action among several alternatives, and (ii) choosing the response vigor, i.e., how fast the selected action should be executed. Previous works have addressed the computational substrates of such a selection process under the assumption that outcome values are stationary and do not change during the course of a session. This assumption does not hold when the motivational drive of the decision-maker is variable, because it leads to changes in the values of the outcomes, e.g., satiety decreases the value of the outcome. Here, we utilize an optimal control framework and derive the optimal choice and response vigor under different experimental conditions. The results imply that, in contrast to previous suggestions, even under conditions that the values of the outcomes are changing during the session, the optimal response rate in an instrumental conditioning experiment is a constant response rate rather than decreasing. Furthermore, we prove that the uncertainty of the decision-maker about the duration of the session explains the commonly observed decrease in response rates within a session. We also show that when the environment consists of multiple outcomes, the model explains probability matching as well as maximisation choice strategies. These results, therefore, provide a quantitative analysis of optimal choice and response vigor under variable motivational drive, and provide predictions for future testing.</p></abstract><kwd-group kwd-group-type="author" hwp:id="kwd-group-1"><title hwp:id="title-1"><italic toggle="yes">Keywords</italic></title><kwd hwp:id="kwd-1">choice</kwd><kwd hwp:id="kwd-2">responser vigor</kwd><kwd hwp:id="kwd-3">reward learning</kwd><kwd hwp:id="kwd-4">optimal actions</kwd></kwd-group><counts><page-count count="16"/></counts></article-meta></front><body><sec id="s1" hwp:id="sec-1"><title hwp:id="title-2">Introduction</title><p hwp:id="p-5">According to the normative theories of decision-making, actions made by humans and animals are chosen with the aim of earning the maximum amount of future rewards while incurring the lowest cost (<xref rid="c35" ref-type="bibr" hwp:id="xref-ref-35-1" hwp:rel-id="ref-35">Neumann &amp; Morgenstern, 1947</xref>). Within such theories, individuals optimize their actions by learning about their surrounding environment and in order to satisfy their long-term objectives. Such a problem, i.e., finding the optimal actions, is argued to have two aspects: (1) choice, i.e., which action among several alternatives should be selected, (2) response vigor, i.e., how fast the selected action should be executed. For example for a rat in a Skinner box with two levers, where pressing each lever delivers a reward with a certain probability, the problem of finding the optimal actions involves selecting a lever (choice) and deciding about the response rate on the chosen lever (response vigor). High response rates can have high costs (e.g., in terms of energy consumption), while on the other hand a low response rate implies an opportunity cost since the experiment session may end before the animal has earned enough reward. Optimal actions provide the right balance between these two factors, and based on the reinforcement-learning (RL) framework and methods from optimal control theory, characteristics of the optimal actions and their consistency with the experimental studies have been elaborated in previous works (<xref rid="c6" ref-type="bibr" hwp:id="xref-ref-6-1" hwp:rel-id="ref-6">Dayan, 2012</xref>; <xref rid="c36" ref-type="bibr" hwp:id="xref-ref-36-1" hwp:rel-id="ref-36">Niv, Daw, Joel, &amp; Dayan, 2007</xref>; <xref rid="c43" ref-type="bibr" hwp:id="xref-ref-43-1" hwp:rel-id="ref-43">Salimpour &amp; Shadmehr, 2014</xref>).</p><p hwp:id="p-6">A major assumption in the previous models is that the values of the outcomes are stationary, and they do not change on-line in the course of a decision-making session. To see the limitations of such an assumption, imagine the rat is in a Skinner box and has started to earn outcomes (e.g., food pellets) by taking actions. One can assume that as a result of consuming rewards the motivation of the animal for earning more outcomes will decrease (e.g., because of satiety effects) and, therefore, the outcomes earned will have a lower value, which can potentially affect the optimal choice and vigor (<xref rid="c22" ref-type="bibr" hwp:id="xref-ref-22-1" hwp:rel-id="ref-22">Killeen, 1995b</xref>). Such effects, however, are not incorporated in previous models of response vigor, and it is assumed that the value of the outcomes is constant during the course of the decision-making session. On the other hand, the effect of such motivational changes on the choice between actions has been addressed in some previous models (<xref rid="c18" ref-type="bibr" hwp:id="xref-ref-18-1" hwp:rel-id="ref-18">Keramati, 2011</xref>; <xref rid="c19" ref-type="bibr" hwp:id="xref-ref-19-1" hwp:rel-id="ref-19">Keramati &amp; Gutkin, 2014</xref>), however, their role in determining the response vigor has not yet been investigated. Here, building upon the previous works, we formulate the problem of response vigor and choice under changing motivational drives in an optimal control framework, and we derive the optimal response vigor and choice strategy under different conditions. We will show that even when the motivational drives are changing, the optimal response rate in an instrumental conditioning experiment is a constant response rate, and then we will elaborate how this prediction can be reconciled with the experimental data. The optimal predictions under different choice situations is also explored, and their relation to the empirical evidence is investigated.</p></sec><sec id="s2" hwp:id="sec-2"><title hwp:id="title-3">The Model</title><sec id="s2a" hwp:id="sec-3"><title hwp:id="title-4">The reward</title><p hwp:id="p-7">It is assumed that at each point in time the decision-maker has a position in the outcome space denoted by <italic toggle="yes">x<sub>t</sub></italic>, which represents the amount of outcomes gained up to time <italic toggle="yes">t</italic>. For example, if the outcome is water, <italic toggle="yes">x</italic><sub><italic toggle="yes">t</italic></sub> = 1 indicates that one unit of water has been gained up to time <italic toggle="yes">t</italic>. For simplicity, we assume that only one outcome is available, and thus the outcome space is one dimensional. In the next sections the model will be extended to the environments with multiple outcomes. The rate of outcome earning is denoted by <italic toggle="yes">v</italic><sub><italic toggle="yes">t</italic></sub>, which represents how fast the decision-maker is moving in the outcome space (i.e., the velocity in the outcome space); for example if a rat is earning one unit of an outcome per unit of time then <italic toggle="yes">v</italic><sub><italic toggle="yes">t</italic></sub> = 1. Furthermore, we assume that there exists a <italic toggle="yes">reward field,</italic> denoted by <italic toggle="yes">A<sub>x,t</sub></italic>, which represents the per unit value of the outcome for the decision-maker. For example if the outcome is food pellets, then <italic toggle="yes">A<sub>x,t</sub></italic> represents the value of one unit of the food pellet at time <italic toggle="yes">t</italic>, given that the decision-maker has already earned <italic toggle="yes">x</italic> units of food pellets. As such, <italic toggle="yes">A<sub>x,t</sub></italic> is a function of both time and the amount of outcome earned. This represents the fact that (i) the reward can change as a result of consuming previous outcomes (dependency on <italic toggle="yes">x</italic>); for example the reward of food pellets can decrease as an animal consumes more outcomes and becomes sated, and (ii) the reward of an outcome can change purely by the passage of time, as for example an animal can get more hungry by the passage of time, and therefore the reward of food pellets will increase (dependency on <italic toggle="yes">t</italic>).</p><p hwp:id="p-8">In general, we assume that <italic toggle="yes">A<sub>x,t</sub></italic> has two properties:
<disp-formula id="eqn1" hwp:id="disp-formula-1" hwp:rev-id="xref-disp-formula-1-1 xref-disp-formula-1-2"><alternatives hwp:id="alternatives-1"><graphic xlink:href="057208_eqn1.gif" position="float" orientation="portrait" hwp:id="graphic-1"/></alternatives></disp-formula>
which entails that the values of the outcomes decrease as more outcomes are earned. Secondly, we assume that:
<disp-formula id="eqn2" hwp:id="disp-formula-2" hwp:rev-id="xref-disp-formula-2-1 xref-disp-formula-2-2 xref-disp-formula-2-3 xref-disp-formula-2-4"><alternatives hwp:id="alternatives-2"><graphic xlink:href="057208_eqn2.gif" position="float" orientation="portrait" hwp:id="graphic-2"/></alternatives></disp-formula>
which entails that the values of outcomes do not decrease with the passage of time. This term, for instance, corresponds to the metabolic rate of the decision-maker. Given the reward field <italic toggle="yes">A</italic><sub><italic toggle="yes">x,t</italic></sub>, the reward of gaining <italic toggle="yes">Î´x</italic> units of outcome will be <italic toggle="yes">A</italic><sub><italic toggle="yes">x,t</italic></sub><italic toggle="yes">Î´x.</italic></p><p hwp:id="p-9">The dependency of the reward field on the amount of outcome earned is indirect and it is through the motivational drive. In a computational model based on <bold>RL</bold> framework, <xref rid="c19" ref-type="bibr" hwp:id="xref-ref-19-2" hwp:rel-id="ref-19">Keramati and Gutkin (2014)</xref> provided a quantitative link between reward and motivation. In line with <xref rid="c15" ref-type="bibr" hwp:id="xref-ref-15-1" hwp:rel-id="ref-15">Hull (1943)</xref>, they conceptualized the motivational drive as the deviations of the <italic toggle="yes">internal states</italic> of a decision-maker from their homeostatic set-points. For example, letâs assume that there is only one internal state, say hunger, where <italic toggle="yes">H</italic> denotes its homeostatic set-point, and there is an outcome which consuming each unit of it satisfies <italic toggle="yes">l</italic> units of the internal state. In this condition, the motivational drive at point <italic toggle="yes">x</italic>, denoted by <italic toggle="yes">D<sub>x</sub>,</italic> will be:
<disp-formula id="eqn3" hwp:id="disp-formula-3" hwp:rev-id="xref-disp-formula-3-1"><alternatives hwp:id="alternatives-3"><graphic xlink:href="057208_eqn3.gif" position="float" orientation="portrait" hwp:id="graphic-3"/></alternatives></disp-formula>
</p><p hwp:id="p-10"><xref rid="c19" ref-type="bibr" hwp:id="xref-ref-19-3" hwp:rel-id="ref-19">Keramati and Gutkin (2014)</xref> showed that such a definition of the motivational drive has implications that are consistent with the behavioral evidence. According to the framework, the reward generated by earning <italic toggle="yes">Î´x</italic> units of the outcome is proportional to the change in the motivational drive, which can be expressed as:
<disp-formula id="eqn4" hwp:id="disp-formula-4"><alternatives hwp:id="alternatives-4"><graphic xlink:href="057208_eqn4.gif" position="float" orientation="portrait" hwp:id="graphic-4"/></alternatives></disp-formula>
The above equation will be used for linking the consumption of outcomes to the changes in the motivational drive and the reward field.</p></sec><sec id="s2b" hwp:id="sec-4"><title hwp:id="title-5">The cost</title><p hwp:id="p-11">Using RL framework, previous studies have derived the optimal choice and response vigor in instrumental conditioning experiments, in which an animal is required to press a lever to earn rewards (<xref rid="c6" ref-type="bibr" hwp:id="xref-ref-6-2" hwp:rel-id="ref-6">Dayan, 2012</xref>; <xref rid="c36" ref-type="bibr" hwp:id="xref-ref-36-2" hwp:rel-id="ref-36">Niv et al., 2007</xref>). The optimal rate is argued to be the result of a trade-off between two factors: the cost of lever presses, and the opportunity cost of a certain response rate. The cost component is expressed as a function of the delay between consecutive lever presses. That is, if the previous lever press has occurred <italic toggle="yes">Ï</italic> time steps ago, then the cost of the current lever press will be:
<disp-formula id="eqn5" hwp:id="disp-formula-5" hwp:rev-id="xref-disp-formula-5-1 xref-disp-formula-5-2 xref-disp-formula-5-3"><alternatives hwp:id="alternatives-5"><graphic xlink:href="057208_eqn5.gif" position="float" orientation="portrait" hwp:id="graphic-5"/></alternatives></disp-formula>
where <italic toggle="yes">a</italic> and <italic toggle="yes">b</italic> are constants. <italic toggle="yes">b</italic> is the constant cost of each lever press, which is independent of the delay between lever presses. The factor <italic toggle="yes">a</italic>, on the other hand, controls the rate-dependent component of the cost. According to the above relation, the higher the delay between lever presses the lower the cost will be. However, a long delay has an opportunity cost, i.e., by waiting a long time the animal is missing an opportunity to earn rewards that potentially could be obtained during the delay between presses. The optimal rate, therefore, will be determined by a trade-off between the cost of a certain response rate and its opportunity cost.</p><p hwp:id="p-12">In the above framework, the target of the decision-making process is to find the optimal value of <italic toggle="yes">Ï</italic>. Here, we express the cost as a function of the rate of outcome earning instead of the rate of action executions. We denote the cost function with <italic toggle="yes">K<sub>v</sub></italic>, which indicates the cost of earning one unit of the outcome at rate <italic toggle="yes">v</italic>. In the case of a fixed-ratio (FR) schedule of reinforcement, in which the decision-maker is required to perform exactly <italic toggle="yes">k</italic> responses in order to earn an outcome, or in the case of a random-ratio (RR) or a variable ratio (VR) schedule, in which the decision-maker is required to perform on average <italic toggle="yes">k</italic> responses to earn an outcome, the cost defined in <xref ref-type="disp-formula" rid="eqn5" hwp:id="xref-disp-formula-5-1" hwp:rel-id="disp-formula-5">equation 5</xref> will be equivalent to:
<disp-formula id="eqn6" hwp:id="disp-formula-6" hwp:rev-id="xref-disp-formula-6-1 xref-disp-formula-6-2 xref-disp-formula-6-3 xref-disp-formula-6-4"><alternatives hwp:id="alternatives-6"><graphic xlink:href="057208_eqn6.gif" position="float" orientation="portrait" hwp:id="graphic-6"/></alternatives></disp-formula>
See Appendix A for the proof. In general, we assume that <italic toggle="yes">Kv</italic> satisfies the following relation:
<disp-formula id="eqn7" hwp:id="disp-formula-7" hwp:rev-id="xref-disp-formula-7-1 xref-disp-formula-7-2 xref-disp-formula-7-3"><alternatives hwp:id="alternatives-7"><graphic xlink:href="057208_eqn7.gif" position="float" orientation="portrait" hwp:id="graphic-7"/></alternatives></disp-formula>
</p><p hwp:id="p-13">The above relation is required for deriving the results provided in the next sections. For example in the case of the cost function defined in <xref ref-type="disp-formula" rid="eqn6" hwp:id="xref-disp-formula-6-1" hwp:rel-id="disp-formula-6">equation 6</xref>, the above relation requires that <italic toggle="yes">ak<sup>2</sup></italic> &gt; 0, which implies that in the experiment at least one response should be required to earn an outcome (<italic toggle="yes">k</italic> &gt; 0), and the cost of earning outcomes should be non-zero (<italic toggle="yes">a</italic> &gt; 0).</p><p hwp:id="p-14">Given <italic toggle="yes">K<sub>v</sub></italic>, the cost of gaining <italic toggle="yes">Î´x</italic> units of outcome will be<italic toggle="yes">K<sub>v</sub>Î´x</italic>.</p></sec><sec id="s2c" hwp:id="sec-5"><title hwp:id="title-6">The value</title><p hwp:id="p-15">Based on the definition of the reward and the cost, the net amount of reward earned at each time step will be the reward earned (<italic toggle="yes">vA<sub>x,t</sub></italic>) minus its cost (<italic toggle="yes">vK<sub>v</sub></italic>). We denote this quantity by <italic toggle="yes">L</italic>:
<disp-formula id="eqn8" hwp:id="disp-formula-8" hwp:rev-id="xref-disp-formula-8-1 xref-disp-formula-8-2 xref-disp-formula-8-3"><alternatives hwp:id="alternatives-8"><graphic xlink:href="057208_eqn8.gif" position="float" orientation="portrait" hwp:id="graphic-8"/></alternatives></disp-formula>
</p><p hwp:id="p-16">Now letâs assume that a decision-maker starts at point xo in the outcome space, and the total duration of the experiment session is <italic toggle="yes">T</italic>. We denote the total reward gained in this period with <italic toggle="yes">S</italic> <sub>0,<italic toggle="yes">T</italic></sub>, which is the sum of the net rewards earned at each point in time:
<disp-formula id="eqn9" hwp:id="disp-formula-9"><alternatives hwp:id="alternatives-9"><graphic xlink:href="057208_eqn9.gif" position="float" orientation="portrait" hwp:id="graphic-9"/></alternatives></disp-formula>
</p><p hwp:id="p-17">The quantity <italic toggle="yes">S</italic> <sub>0,<italic toggle="yes">T</italic></sub> is called the <italic toggle="yes">value</italic> function, and the goal of the decision-maker is to find the optimal rate of outcome earning that yields the highest value (<italic toggle="yes">S</italic> <sub>0,<italic toggle="yes">T</italic></sub>). The optimal rates can be found using different variational calculus methods such as the Eular-Lagrange equation, or the Hamilton-Jacobi-Bellman equation (<xref rid="c24" ref-type="bibr" hwp:id="xref-ref-24-1" hwp:rel-id="ref-24">Liberzon, 2011</xref>). Here we use the Eular-Lagrange form, which sets a necessary condition for <italic toggle="yes">Î´S</italic> = 0:
<disp-formula id="eqn10" hwp:id="disp-formula-10" hwp:rev-id="xref-disp-formula-10-1"><alternatives hwp:id="alternatives-10"><graphic xlink:href="057208_eqn10.gif" position="float" orientation="portrait" hwp:id="graphic-10"/></alternatives></disp-formula>
which implies that:
<disp-formula id="eqn11" hwp:id="disp-formula-11" hwp:rev-id="xref-disp-formula-11-1 xref-disp-formula-11-2 xref-disp-formula-11-3 xref-disp-formula-11-4 xref-disp-formula-11-5 xref-disp-formula-11-6 xref-disp-formula-11-7"><alternatives hwp:id="alternatives-11"><graphic xlink:href="057208_eqn11.gif" position="float" orientation="portrait" hwp:id="graphic-11"/></alternatives></disp-formula>
</p><p hwp:id="p-18">See Appendix A for the proof. Furthermore, since the endpoint of the trajectory is free (the amount of outcomes that can be gained during a session is not limited, but the duration of the session is limited to <italic toggle="yes">T</italic>), the optimal trajectory will also satisfy the transversality conditions:
<disp-formula id="eqn12" hwp:id="disp-formula-12" hwp:rev-id="xref-disp-formula-12-1 xref-disp-formula-12-2"><alternatives hwp:id="alternatives-12"><graphic xlink:href="057208_eqn12.gif" position="float" orientation="portrait" hwp:id="graphic-12"/></alternatives></disp-formula>
where as mentioned <italic toggle="yes">T</italic> is the total session duration. We will use <xref ref-type="disp-formula" rid="eqn11" hwp:id="xref-disp-formula-11-1" hwp:rel-id="disp-formula-11">equation 11,12</xref> in order to derive the optimal response rates in different conditions.</p></sec></sec><sec id="s3" hwp:id="sec-6"><title hwp:id="title-7">Optimal response vigor</title><p hwp:id="p-19">In this section, we analyze the optimal response vigor in the condition that there is only one outcome and one response available in the environment, i.e., the outcome space has only one dimension. The analysis is divided into two sections. In the first section, the decision-maker assumes that the duration of the session is fixed, which will be extended in the next section to the conditions that the decision-maker assumes a probabilistic distribution over the session length.</p><sec id="s3a" hwp:id="sec-7"><title hwp:id="title-8">Fixed session duration</title><p hwp:id="p-20">The optimal rate of outcome earning should satisfy <xref ref-type="disp-formula" rid="eqn11" hwp:id="xref-disp-formula-11-2" hwp:rel-id="disp-formula-11">equation 11</xref>. In the equation, the term â<italic toggle="yes">A<sub>x,t</sub></italic>/â<italic toggle="yes">t</italic> is the time-dependent change in the value of the outcome, and the term <italic toggle="yes">dv/dt</italic> is the rate of change in the rate of outcome earning. In the particular case that the time-dependent change in the outcome reward is negligible â<italic toggle="yes">A<sub>x,t</sub></italic>/â<italic toggle="yes">t</italic> = 0, then the only valid solution to <xref ref-type="disp-formula" rid="eqn11" hwp:id="xref-disp-formula-11-3" hwp:rel-id="disp-formula-11">equation 11</xref> is <italic toggle="yes">dv/dt</italic> = 0 (see Appendix A). Thus, the optimal rate of outcome earning (and the optimal response rate) is constant throughout the session. This relation holds even in the condition that the reward of the outcome decreases throughout the session as a result of earning outcomes, e.g., because of the satiety effect. The following theorem summarizes this result:
<statement id="theorem1" hwp:id="statement-1" hwp:rev-id="xref-statement-1-1 xref-statement-1-2 xref-statement-1-3 xref-statement-1-4 xref-statement-1-5 xref-statement-1-6 xref-statement-1-7"><label>Theorem 1</label><p hwp:id="p-21"><italic toggle="yes">If the reward field and the cost function satisfy <xref ref-type="disp-formula" rid="eqn2" hwp:id="xref-disp-formula-2-1" hwp:rel-id="disp-formula-2">equation 2</xref> and 7, then the optimal rate of outcome earning will be non-decreasing</italic> (<italic toggle="yes">dv</italic>/<italic toggle="yes">dt</italic> â¥ 0). <italic toggle="yes">In the special casethat the time-dependent change in the reward field is zero</italic> (â<italic toggle="yes">A<sub>x,t</sub></italic>/â<italic toggle="yes">t</italic> = 0), <italic toggle="yes">then the optimal rate of outcome earning is a constant rate</italic> (<italic toggle="yes">dv</italic>/<italic toggle="yes">dt</italic> = 0). <italic toggle="yes">Furthermore, the optimal rate v</italic>* <italic toggle="yes">satisfies the following equation:</italic></p></statement>
<disp-formula id="eqn13" hwp:id="disp-formula-13" hwp:rev-id="xref-disp-formula-13-1 xref-disp-formula-13-2"><alternatives hwp:id="alternatives-13"><graphic xlink:href="057208_eqn13.gif" position="float" orientation="portrait" hwp:id="graphic-13"/></alternatives></disp-formula>
</p><p hwp:id="p-22">See Appendix A for the proof. As an intuitive explanation for why the constant rate is optimal, imagine a decision-maker who chooses a non-constant rate of outcome earning, and it earns in total <italic toggle="yes">x<sub>T</sub></italic> amount of outcome during the session. If instead of the non-constant rate, the decision-maker selects the constant rate <italic toggle="yes">v</italic> = <italic toggle="yes">x<sub>T</sub>/T</italic>, then the amount of outcome earned will be the same as before; however, the cost paid during the session will be lower because the cost is a quadratic function of the outcome rate, and therefore, it is better to earn outcomes at a constant rate.</p><p hwp:id="p-23">As an example, letâs assume that there is one internal state, say hungry, and the motivational drive, and the cost function are the ones defined in <xref ref-type="disp-formula" rid="eqn3" hwp:id="xref-disp-formula-3-1" hwp:rel-id="disp-formula-3">equation 3</xref> and 6. Using <xref ref-type="statement" rid="theorem1" hwp:id="xref-statement-1-1" hwp:rel-id="statement-1">Theorem 1</xref> the optimal rate of outcome earning will be<sup><xref ref-type="fn" rid="fn1" hwp:id="xref-fn-3-1" hwp:rel-id="fn-3">1</xref></sup>:
<disp-formula id="eqn14" hwp:id="disp-formula-14" hwp:rev-id="xref-disp-formula-14-1 xref-disp-formula-14-2 xref-disp-formula-14-3 xref-disp-formula-14-4 xref-disp-formula-14-5 xref-disp-formula-14-6 xref-disp-formula-14-7"><alternatives hwp:id="alternatives-14"><graphic xlink:href="057208_eqn14.gif" position="float" orientation="portrait" hwp:id="graphic-14"/></alternatives></disp-formula></p><p hwp:id="p-24">The response rate, in the case of the FR schedule can be obtained by multiplying the outcome rate by a factor of <italic toggle="yes">k</italic>, the number of responses required to earn an outcome:
<disp-formula id="eqn15" hwp:id="disp-formula-15" hwp:rev-id="xref-disp-formula-15-1"><alternatives hwp:id="alternatives-15"><graphic xlink:href="057208_eqn15.gif" position="float" orientation="portrait" hwp:id="graphic-15"/></alternatives></disp-formula>
</p><p hwp:id="p-25"><xref ref-type="disp-formula" rid="eqn14" hwp:id="xref-disp-formula-14-1" hwp:rel-id="disp-formula-14">Equation 14</xref> and 15 layout a quantitative relation between various parameters, and the optimal rate of outcome earning (<xref ref-type="disp-formula" rid="eqn14" hwp:id="xref-disp-formula-14-2" hwp:rel-id="disp-formula-14">equation 14</xref>), and the optimal rate of responding (<xref ref-type="disp-formula" rid="eqn15" hwp:id="xref-disp-formula-15-1" hwp:rel-id="disp-formula-15">equation 15</xref>), which can be compared against experimental evidence. Unfortunately, experimental data on the effects of different parameters on response rates are not consistent across studies, making it hard to compare the optimal actions with empirical data. Besides that, there is a further complexity due to the inconsistency in how different experiments have calculated response rates. In general, in an instrumental conditioning experiment, the duration of the session can be divided into three sections: (i) outcome handling/consumption time, which refers to the time that an animal spends on consuming the outcome, (ii) <italic toggle="yes">post-reinforcer pause</italic>, which refers to a pause after consuming the outcome and before starting to make responses (e.g., lever presses). Such a pause is consistently reported in previous studies using the FR schedule, (iii) <italic toggle="yes">run time</italic>, which refers to the time spent on making responses (e..g, lever presses). Experimental manipulations have been shown to have different effects on the duration of these three sections of the session, and whether each of these sections are included when calculating the response rates can affect the measurement of the results. In the following sections, we briefly review the currently available data from instrumental conditioning experiments and their relation with the predictions of the model.</p><p hwp:id="p-26"><bold>The effect of response cost</bold> (<italic toggle="yes">a</italic> <bold>and</bold> <italic toggle="yes">b</italic>). Experimental studies in rats in a FR schedule (<xref rid="c3" ref-type="bibr" hwp:id="xref-ref-3-1" hwp:rel-id="ref-3">Alling &amp; Poling, 1995</xref>), indicate that increasing the force required to make responses causes increases in both inter-response time and post-reinforcement pause. The same trend has been reported in Squirrel monkey (<xref rid="c2" ref-type="bibr" hwp:id="xref-ref-2-1" hwp:rel-id="ref-2">Adair &amp; Wright, 1976</xref>). Consistently, the present model implies that increases in the cost of responses, for example by increasing the effort required to press the lever (increases in <italic toggle="yes">a</italic> and <italic toggle="yes">b</italic>), lead to a lower rate of outcome earning and a lower rate of responses (<xref ref-type="fig" rid="fig1" hwp:id="xref-fig-1-1" hwp:rel-id="F1">Figure 1</xref>).</p><p hwp:id="p-27"><bold>The effect of ratio-requirement</bold> (<italic toggle="yes">k</italic>). Experimental studies mainly imply that the rate of outcome earning decreases with increases in the ratio-requirement (<xref rid="c1" ref-type="bibr" hwp:id="xref-ref-1-1" hwp:rel-id="ref-1">Aberman &amp; Salamone, 1999;</xref> <xref rid="c4" ref-type="bibr" hwp:id="xref-ref-4-1" hwp:rel-id="ref-4">Barofsky &amp; Hurwitz, 1968</xref>), which is consistent with the general trend of the optimal rate of outcome earning implied by the present model (as suggested by <xref ref-type="disp-formula" rid="eqn14" hwp:id="xref-disp-formula-14-3" hwp:rel-id="disp-formula-14">equation 14</xref>).</p><p hwp:id="p-28">Experimental studies on the rate of responses, in the FR schedule, indicate that the post-reinforcer pause increases with increases in the ratio-requirement (<xref rid="c10" ref-type="bibr" hwp:id="xref-ref-10-1" hwp:rel-id="ref-10">Ferster &amp; Skinner, 1957</xref>, Figure 23)(<xref rid="c9" ref-type="bibr" hwp:id="xref-ref-9-1" hwp:rel-id="ref-9">Felton &amp; Lyon, 1966;</xref> <xref rid="c39" ref-type="bibr" hwp:id="xref-ref-39-1" hwp:rel-id="ref-39">Powell, 1968;</xref> <xref rid="c41" ref-type="bibr" hwp:id="xref-ref-41-1" hwp:rel-id="ref-41">Premack, Schaeffer, &amp; Hundt, 1964</xref>). In terms of the overall response rates, some experiments report that response rates increase with increases in the ratio-requirement up to a point and beyond that point the response rates will start to decrease, in rats (<xref rid="c4" ref-type="bibr" hwp:id="xref-ref-4-2" hwp:rel-id="ref-4">Barofsky &amp; Hurwitz, 1968;</xref> <xref rid="c17" ref-type="bibr" hwp:id="xref-ref-17-1" hwp:rel-id="ref-17">Kelsey &amp; Allison, 1976;</xref> <xref rid="c26" ref-type="bibr" hwp:id="xref-ref-26-1" hwp:rel-id="ref-26">Mazur, 1982</xref>), pigeons (<xref rid="c5" ref-type="bibr" hwp:id="xref-ref-5-1" hwp:rel-id="ref-5">Baum, 1993</xref>) and mice (<xref rid="c13" ref-type="bibr" hwp:id="xref-ref-13-1" hwp:rel-id="ref-13">Greenwood, Quartermain, Johnson, Cruce,&amp; Hirsch, 1974</xref>), although other studies have reported inconsistent results in pigeons (<xref rid="c39" ref-type="bibr" hwp:id="xref-ref-39-2" hwp:rel-id="ref-39">Powell, 1968</xref>), or a decreasing trend of response rates with increases in the ratio-requirement (<xref rid="c9" ref-type="bibr" hwp:id="xref-ref-9-2" hwp:rel-id="ref-9">Felton &amp; Lyon, 1966;</xref> <xref rid="c11" ref-type="bibr" hwp:id="xref-ref-11-1" hwp:rel-id="ref-11">Foster, Blackman, &amp; Temple, 1997</xref>). The inconsistency is partly due to the way that the response rates are calculated in different studies; for example in some studies the outcome handling and the consumption time are not excluded when calculating response rates (<xref rid="c4" ref-type="bibr" hwp:id="xref-ref-4-3" hwp:rel-id="ref-4">Barofsky &amp; Hurwitz, 1968</xref>), in contrast to the other studies (<xref rid="c11" ref-type="bibr" hwp:id="xref-ref-11-2" hwp:rel-id="ref-11">Foster et al., 1997</xref>). As such any implication of the experimental data about the relationship between response rates and the ratio-requirement is not conclusive.</p><fig id="fig1" position="float" fig-type="figure" orientation="portrait" hwp:id="F1" hwp:rev-id="xref-fig-1-1"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;057208v1/FIG1</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F1</object-id><object-id pub-id-type="publisher-id">fig1</object-id><label><italic toggle="yes">Figure 1</italic>.</label><caption hwp:id="caption-1"><p hwp:id="p-29">Effect of response cost on response rates. (a) Empirical data. Inter-response intervals when the force required to make a reponse is manipulated. Figure is adopted from <xref rid="c2" ref-type="bibr" hwp:id="xref-ref-2-2" hwp:rel-id="ref-2">Adair and Wright (1976)</xref>. (b) Model prediction. Interresponse interval (equal to the inverse of response rates) as a function of cost of responses (b). Parameter values used for the simulation are <italic toggle="yes">T</italic> = 50, <italic toggle="yes">k</italic> = 1, <italic toggle="yes">l</italic> = 1, <italic toggle="yes">a</italic> = 1, <italic toggle="yes">H</italic> = 8.</p></caption><graphic xlink:href="057208_fig1" position="float" orientation="portrait" hwp:id="graphic-16"/></fig><p hwp:id="p-30">With regard to the present model, it predicts the relationship between response rates and the ratio-requirement is an inverted U-shaped pattern (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-1" hwp:rel-id="F2">Figure 2a</xref>), consistent with some of the studies mentioned before. The exact relationship between the two factors depends on the value of the parameters. Generally speaking, if the rate-dependent cost of the responses is negligible (<italic toggle="yes">a</italic> = 0), the response rates will peak at <italic toggle="yes">k</italic> = <italic toggle="yes">Hl</italic> = (2<italic toggle="yes">b</italic>) and will start to decrease after that. As such, the prediction of the model can be consistent with the experiments mentioned before, depending on the initial motivational drive (<italic toggle="yes">H</italic>), the constant cost of responses (<italic toggle="yes">b</italic>), and the range of tested ratio-requirements.</p><fig id="fig2" position="float" fig-type="figure" orientation="portrait" hwp:id="F2" hwp:rev-id="xref-fig-2-1 xref-fig-2-2 xref-fig-2-3"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;057208v1/FIG2</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F2</object-id><object-id pub-id-type="publisher-id">fig2</object-id><label><italic toggle="yes">Figure 2</italic>.</label><caption hwp:id="caption-2"><p hwp:id="p-31">(a) The effect of ratio-requirement on the response rates. Parameters used for the simulations are <italic toggle="yes">T</italic> = 50, <italic toggle="yes">l</italic> = 1, <italic toggle="yes">a</italic> = 0:3, <italic toggle="yes">b</italic> = 0:05, <italic toggle="yes">H</italic> = 100. (b) The effect of the initial motivational drive on response rates. Parameters used are <italic toggle="yes">T</italic> = 50, <italic toggle="yes">k</italic> = 1, <italic toggle="yes">l</italic> = 1, <italic toggle="yes">a</italic> = 0:3, <italic toggle="yes">b</italic> = 0:05. (c) The effect of the reward magnitude on response rates. Parameters used are <italic toggle="yes">T</italic> = 50, <italic toggle="yes">k</italic> = 1, <italic toggle="yes">a</italic> = 0:1, <italic toggle="yes">b</italic> = 0:1, <italic toggle="yes">H</italic> = 100.</p></caption><graphic xlink:href="057208_fig2" position="float" orientation="portrait" hwp:id="graphic-17"/></fig><p hwp:id="p-32"><bold>The Effect of initial motivational drive</bold> (<italic toggle="yes">H</italic>). Experimental studies in the case of a FR schedule suggest that response rates increase with increases in deprivation levels (<xref rid="c10" ref-type="bibr" hwp:id="xref-ref-10-2" hwp:rel-id="ref-10">Ferster &amp; Skinner, 1957</xref>, Chapter 4)(<xref rid="c45" ref-type="bibr" hwp:id="xref-ref-45-1" hwp:rel-id="ref-45">Sidman &amp; Stebbins, 1954</xref>). However, such increases are mainly due to decreases in the post-reinforcement pauses, and not due to the increases in actual rate of responses after the pause (see (<xref rid="c38" ref-type="bibr" hwp:id="xref-ref-38-1" hwp:rel-id="ref-38">Pear, 2001</xref>, Page 289) for a review of other reinforcer schedules). Consistently, the model predicts that with increases in the initial motivational drive (<italic toggle="yes">H</italic>), the rate of responses and outcome earning will increase (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-2" hwp:rel-id="F2">Figure 2b</xref>).</p><p hwp:id="p-33"><bold>The effect of reward magnitude</bold> (<italic toggle="yes">l</italic>). Some studies show that post-reinforcement pauses increase as the magnitude of the reward increases (<xref rid="c40" ref-type="bibr" hwp:id="xref-ref-40-1" hwp:rel-id="ref-40">Powell, 1969</xref>), while other studies conclude that the post-reinforcement pause decreases (<xref rid="c25" ref-type="bibr" hwp:id="xref-ref-25-1" hwp:rel-id="ref-25">Lowe, Davey, &amp; Harzem, 1974</xref>), although in the later study the magnitude of the reward is manipulated within a session and a follow-up study showed that at the steady state, the post-reinforcement pause increases with increases in the magnitude of the reward (<xref rid="c33" ref-type="bibr" hwp:id="xref-ref-33-1" hwp:rel-id="ref-33">Meunier &amp; Starratt, 1979</xref>). The reward magnitude, however, does not have a reliable effect on the overall response rates (<xref rid="c16" ref-type="bibr" hwp:id="xref-ref-16-1" hwp:rel-id="ref-16">Keesey &amp; Kling, 1961;</xref> <xref rid="c25" ref-type="bibr" hwp:id="xref-ref-25-2" hwp:rel-id="ref-25">Lowe et al., 1974;</xref> <xref rid="c40" ref-type="bibr" hwp:id="xref-ref-40-2" hwp:rel-id="ref-40">Powell, 1969</xref>). Regarding the prediction of the model, the effect of the reward magnitude on the outcome and response rates is an inverted U-shaped relationship (<xref ref-type="fig" rid="fig2" hwp:id="xref-fig-2-3" hwp:rel-id="F2">Figure 2c</xref>), with the peak at <italic toggle="yes">l</italic> = 2<italic toggle="yes">bk</italic>/<italic toggle="yes">H</italic> (assuming <italic toggle="yes">a</italic> = 0), and therefore depending on the value of the parameters the predictions of the model can be consistent with the experimental data.</p><p hwp:id="p-34"><bold>Within session pattern of responses</bold>. It has been established that in various schedules of reinforcement (<xref rid="c29" ref-type="bibr" hwp:id="xref-ref-29-1" hwp:rel-id="ref-29">McSweeney &amp; Hinson, 1992;</xref> <xref rid="c32" ref-type="bibr" hwp:id="xref-ref-32-1" hwp:rel-id="ref-32">McSweeney, Weatherly, &amp; Swindell, 1995</xref>), including the VR schedule (<xref rid="c31" ref-type="bibr" hwp:id="xref-ref-31-1" hwp:rel-id="ref-31">McSweeney, Roll, &amp; Weatherly, 1994</xref>), the rate of responses within a session has a particular pattern: the response rate reaches its maximum within a short delay after the session starts (warmup period), and then it gradually decreases toward the end of the session (<xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-1" hwp:rel-id="F3">Figure 3a</xref>). <xref rid="c20" ref-type="bibr" hwp:id="xref-ref-20-1" hwp:rel-id="ref-20">Killeen (1994)</xref> proposed a mathematical description of this phenomenon, which can be expressed as follows (<xref rid="c23" ref-type="bibr" hwp:id="xref-ref-23-1" hwp:rel-id="ref-23">Killeen &amp; Sitomer, 2003</xref>):
<disp-formula id="eqn16" hwp:id="disp-formula-16"><alternatives hwp:id="alternatives-16"><graphic xlink:href="057208_eqn16.gif" position="float" orientation="portrait" hwp:id="graphic-18"/></alternatives></disp-formula>
where <italic toggle="yes">Î²</italic> is the response rate, <italic toggle="yes">Î´</italic> is the minimum delay between responses, <italic toggle="yes">r</italic> is the rate of outcome earning, and Â± is called <italic toggle="yes">specific activation</italic><sup><xref ref-type="fn" rid="fn2" hwp:id="xref-fn-4-1" hwp:rel-id="fn-4">2</xref></sup>. The model suggests that as the decision-maker earns outcomes during the session, the value of <italic toggle="yes">Î±</italic> gradually decreases because of the satiety effect, which will cause decreases in response rates. Here satiety refers to both post-ingestive factors (such as blood glucose level; <xref rid="c21" ref-type="bibr" hwp:id="xref-ref-21-1" hwp:rel-id="ref-21">Killeen (1995a)</xref>) and/or pre-ingestive factors (for example sensory specific satiety; <xref rid="c28" ref-type="bibr" hwp:id="xref-ref-28-1" hwp:rel-id="ref-28">McSweeney (2004)</xref>). This model has been shown to provide a quantitative match to the experimental data. This explanation, however, is not consistent with <xref ref-type="statement" rid="theorem1" hwp:id="xref-statement-1-2" hwp:rel-id="statement-1">Theorem 1</xref>, which posits that even in the condition that the motivational drive is changing within a session the optimal response rate is non-decreasing throughout the session, and, therefore, according to the present model the cause underlying the decreases in within-session response rates cannot be purely the changes in the motivational drive.</p><fig id="fig3" position="float" fig-type="figure" orientation="portrait" hwp:id="F3" hwp:rev-id="xref-fig-3-1 xref-fig-3-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;057208v1/FIG3</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F3</object-id><object-id pub-id-type="publisher-id">fig3</object-id><label><italic toggle="yes">figure 3</italic>.</label><caption hwp:id="caption-3"><p hwp:id="p-35">The pattern of within-session response rates. (a) Experimental data. The rate of responding per minute during successive intervals (each interval is 5 minutes) in a variable ratio (VR) schedule. The figure is adopted from <xref rid="c31" ref-type="bibr" hwp:id="xref-ref-31-2" hwp:rel-id="ref-31">McSweeney et al. (1994)</xref>. (b) Theoretical pattern of within-session responses predicted by the model. Parameters used for the simulations are <italic toggle="yes">k</italic> = 15, <italic toggle="yes">l</italic> = 0.1, <italic toggle="yes">a</italic> = 0.002, <italic toggle="yes">b</italic> = 0.1, <italic toggle="yes">H</italic> = 900.</p></caption><graphic xlink:href="057208_fig3" position="float" orientation="portrait" hwp:id="graphic-19"/></fig><p hwp:id="p-36">The optimal response rates provided by <xref ref-type="statement" rid="theorem1" hwp:id="xref-statement-1-3" hwp:rel-id="statement-1">Theorem 1</xref> are not consistent with the behavioral observations showing that the rate of responses for earning an outcome in actual fact decrease, and therefore, there is a clear inconsistency between predictions of the model and empirical data. Based on this, some of the assumptions made to develop the model should be violated by the decision-maker. The form of the cost and, reward functions is reasonably general. However, we assumed that the duration of the session, <italic toggle="yes">T</italic>, is fixed and known by the decision-maker. In the next section, we show that relaxing this assumption to the condition that the decision-maker is uncertain about the duration of the session will lead to predictions similar to the experimental data.</p></sec><sec id="s3b" hwp:id="sec-8"><title hwp:id="title-9">Uncertain session duration</title><p hwp:id="p-37">In the previous sections we considered conditions in which the duration of the session was fixed and known by the decision-maker. In this section we focus on the conditions that the decision-maker is uncertain about the session duration, i.e., the session duration follows a probability distribution function, that we denote by <italic toggle="yes">p</italic>(<italic toggle="yes">T</italic>). Under this assumption, the value of a trajectory starting at time <italic toggle="yes">t</italic> = 0 will be:
<disp-formula id="eqn17" hwp:id="disp-formula-17" hwp:rev-id="xref-disp-formula-17-1"><alternatives hwp:id="alternatives-17"><graphic xlink:href="057208_eqn17.gif" position="float" orientation="portrait" hwp:id="graphic-20"/></alternatives></disp-formula>
where <italic toggle="yes">E</italic> is the expectation. The value, therefore, is the average of the value of all the trajectories starting from point <italic toggle="yes">t</italic> = 0 and ending at time <italic toggle="yes">t</italic> = <italic toggle="yes">T</italic>, for all <italic toggle="yes">T</italic> &gt; 0, weighted by the probability that the session will end at time <italic toggle="yes">T</italic>. The optimal trajectory that maximizes the above value is presented in Appendix A. However, here we use a more intuitive approximation of the above value function:
<disp-formula id="eqn18" hwp:id="disp-formula-18"><alternatives hwp:id="alternatives-18"><graphic xlink:href="057208_eqn18.gif" position="float" orientation="portrait" hwp:id="graphic-21"/></alternatives></disp-formula>
which implies that the decision-maker calculates the values based on the assumption that the session will end at <italic toggle="yes">t</italic> = <italic toggle="yes">E</italic>[<italic toggle="yes">T</italic>], i.e., it sets an expectation on how long the session will last and calculates the optimal response rates based on that expectation. Based on this, if <italic toggle="yes">t</italic>â time step has passed since the beginning of the session, the value of the rest of the session
will be as follows:
<disp-formula id="eqn19" hwp:id="disp-formula-19"><alternatives hwp:id="alternatives-19"><graphic xlink:href="057208_eqn19.gif" position="float" orientation="portrait" hwp:id="graphic-22"/></alternatives></disp-formula>
The following theorem maintains that the optimal rate of outcome earning that maximizes <italic toggle="yes">S</italic> <sub><italic toggle="yes">t</italic>â</sub> is a decreasing function of <italic toggle="yes">t</italic>â:
<statement id="theorem2" hwp:id="statement-2" hwp:rev-id="xref-statement-2-1 xref-statement-2-2"><label>Theorem 2</label><p hwp:id="p-38"><italic toggle="yes">Given the following value function:</italic>
<disp-formula id="eqn20" hwp:id="disp-formula-20"><alternatives hwp:id="alternatives-20"><graphic xlink:href="057208_eqn20.gif" position="float" orientation="portrait" hwp:id="graphic-23"/></alternatives></disp-formula>
<italic toggle="yes">and assuming that (i) the reward field and cost function satisfy <xref ref-type="disp-formula" rid="eqn2" hwp:id="xref-disp-formula-2-2" hwp:rel-id="disp-formula-2">equation 2</xref> and <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-1" hwp:rel-id="disp-formula-7">7</xref> (ii) the time dependent change in the reward field is zero</italic> (â<italic toggle="yes">A<sub>x,t</sub></italic>/â<italic toggle="yes">t</italic> = 0), <italic toggle="yes">and (iii) the probability that the session ends at each point in time is non-zero</italic> (<italic toggle="yes">p</italic>(<italic toggle="yes">T</italic>) &gt; 0), <italic toggle="yes">then the optimal rate of outcome earning is a decreasing function of t</italic>â:
<disp-formula id="eqn21" hwp:id="disp-formula-21"><alternatives hwp:id="alternatives-21"><graphic xlink:href="057208_eqn21.gif" position="float" orientation="portrait" hwp:id="graphic-24"/></alternatives></disp-formula>
</p></statement>
</p><p hwp:id="p-39">See Appendix A for the proof. As an intuitive explanation, it is apparent from <xref ref-type="disp-formula" rid="eqn14" hwp:id="xref-disp-formula-14-4" hwp:rel-id="disp-formula-14">equation 14</xref> that the optimal rate of outcome earning is a decreasing function of the session length, i.e., when the session duration is long the decision-maker can take its time and earn outcomes more slowly. On the other hand, when the decision-maker is uncertain about the session duration, as time passes within the session the decision-makerâs expectation of the session duration increases. This phenomenon, which has been previously elaborated within
the context of delay gratification (<xref rid="c27" ref-type="bibr" hwp:id="xref-ref-27-1" hwp:rel-id="ref-27">McGuire &amp; Kable, 2013;</xref> <xref rid="c42" ref-type="bibr" hwp:id="xref-ref-42-1" hwp:rel-id="ref-42">Rachlin, 2000</xref>), is more significant if the decision-maker assumes a heavy-tail distribution over <italic toggle="yes">T</italic>. In this condition as the time passes, the decision-maker will expect the session to last longer. This property, in addition to the fact that the optimal response rate is a decreasing function of the session duration, entails that as the time passes the optimal response rate will decrease. Based on this explanation, what underlies decrements in response rates within a session, in a normative perspective, is in fact the uncertainty in the duration of the session, and not the satiety effect.</p><p hwp:id="p-40">For the simulation of the model, following <xref rid="c27" ref-type="bibr" hwp:id="xref-ref-27-2" hwp:rel-id="ref-27">McGuire and Kable (2013)</xref>, we characterized the session duration using a Generalized Pareto distribution. Simulations of the model are depicted in <xref ref-type="fig" rid="fig3" hwp:id="xref-fig-3-2" hwp:rel-id="F3">Figure 3b</xref>, which shows that as time passes the optimal rate of responses decreases, consistent with the experimental data (see Appendix A for details).</p></sec></sec><sec id="s4" hwp:id="sec-9"><title hwp:id="title-10">Optimal choice and response vigor</title><p hwp:id="p-41">In the previous sections we assumed that the environment contained only one outcome, and the decision-maker only needed to decide about the response rates along one dimension. In this section we assume that there are multiple outcomes available in the environment, and the decision-maker needs to make decisions about the response rates along each outcome dimension. The position of the decision-maker instead of being a scalar will be a vector, denoted by <bold>x</bold>,which represents the amount of outcomes earned along each outcome dimension. Similarly, the reward field, <italic toggle="yes">A</italic><sub>x,<italic toggle="yes">t</italic></sub>, will be a vector, where each element of the vector denotes the amount of reward generated by earning a unit of the outcome along the corresponding dimension. As such, the total amount of reward earned by earning <italic toggle="yes">Î´</italic><bold>x</bold> outcome will be <italic toggle="yes">Î´</italic>x<sub>1</sub>[<italic toggle="yes">A</italic><sub>x,<italic toggle="yes">t</italic></sub>]<sub>1</sub> + <italic toggle="yes">Î´</italic>x<sub>2</sub>[<italic toggle="yes">A</italic><sub>x,<italic toggle="yes">t</italic></sub>]<sub>2</sub> +â¦, which can be summarized as <italic toggle="yes">Î´</italic><bold>x</bold>.<italic toggle="yes">A</italic><sub>x,<italic toggle="yes">t</italic></sub>. Similarly, the cost of earning outcomes will be a vector, where each element of the vector represents the cost of earning the corresponding outcome at the corresponding rate. Therefore the cost of earning <italic toggle="yes">Î´</italic><bold>x</bold> amounts of outcome will be <italic toggle="yes">Î´</italic><bold>x</bold>.<italic toggle="yes">K</italic><sub>v</sub>. The net amount of reward will be:
<disp-formula id="eqn22" hwp:id="disp-formula-22"><alternatives hwp:id="alternatives-22"><graphic xlink:href="057208_eqn22.gif" position="float" orientation="portrait" hwp:id="graphic-25"/></alternatives></disp-formula>
and the optimal trajectory will satisfy the Eular-Lagrange equation along each outcome dimension:
<disp-formula id="eqn23" hwp:id="disp-formula-23" hwp:rev-id="xref-disp-formula-23-1"><alternatives hwp:id="alternatives-23"><graphic xlink:href="057208_eqn23.gif" position="float" orientation="portrait" hwp:id="graphic-26"/></alternatives></disp-formula>
Furthermore since the end point of the trajectory is free (the total amount of outcomes is not fixed) we have:
<disp-formula id="eqn24" hwp:id="disp-formula-24" hwp:rev-id="xref-disp-formula-24-1 xref-disp-formula-24-2 xref-disp-formula-24-3 xref-disp-formula-24-4"><alternatives hwp:id="alternatives-24"><graphic xlink:href="057208_eqn24.gif" position="float" orientation="portrait" hwp:id="graphic-27"/></alternatives></disp-formula></p><p hwp:id="p-42">Here for simplicity we make the assumption that the cost of earning outcomes along each dimension is independent of the outcome rate on other dimensions, i.e.,
<disp-formula id="eqn25" hwp:id="disp-formula-25" hwp:rev-id="xref-disp-formula-25-1 xref-disp-formula-25-2 xref-disp-formula-25-3"><alternatives hwp:id="alternatives-25"><graphic xlink:href="057208_eqn25.gif" position="float" orientation="portrait" hwp:id="graphic-28"/></alternatives></disp-formula></p><p hwp:id="p-43">The above assumption implies that changing the rate of outcome along one outcome dimension will not affect the cost of earning outcomes along other dimensions. We will relax this assumption in the following sections. Under this assumption, the optimal speed will satisfy the following equation:
<disp-formula id="eqn26" hwp:id="disp-formula-26" hwp:rev-id="xref-disp-formula-26-1 xref-disp-formula-26-2"><alternatives hwp:id="alternatives-26"><graphic xlink:href="057208_eqn26.gif" position="float" orientation="portrait" hwp:id="graphic-29"/></alternatives></disp-formula>
where â is the entrywise Hadamard product. See Appendix B for the proof.</p><p hwp:id="p-44">To get a better intuition about the above equation and the optimal trajectory, here we present a geometrical interpretation. Let us assume that the cost function has the form indicated in <xref ref-type="disp-formula" rid="eqn6" hwp:id="xref-disp-formula-6-2" hwp:rel-id="disp-formula-6">equation 6</xref>, and also the time dependent changes in <italic toggle="yes">A</italic><sub>x,<italic toggle="yes">t</italic></sub> are negligible (â<italic toggle="yes">A<sub>x,t</sub></italic>/â<italic toggle="yes">t</italic> = 0). Under these conditions, if the outcome space is three dimensional, then <xref ref-type="disp-formula" rid="eqn26" hwp:id="xref-disp-formula-26-1" hwp:rel-id="disp-formula-26">equation 26</xref> will be:
<disp-formula id="eqn27" hwp:id="disp-formula-27" hwp:rev-id="xref-disp-formula-27-1 xref-disp-formula-27-2 xref-disp-formula-27-3"><alternatives hwp:id="alternatives-27"><graphic xlink:href="057208_eqn27.gif" position="float" orientation="portrait" hwp:id="graphic-30"/></alternatives></disp-formula>
where Ã is the cross product, <bold>B</bold> is the curl of the reward field (<bold>B</bold> = <monospace>curl</monospace><italic toggle="yes">A</italic><sub>x,<italic toggle="yes">t</italic></sub>), and <italic toggle="yes">m</italic> = 2<italic toggle="yes">ak</italic><sup>2</sup>.<sup><xref ref-type="fn" rid="fn3" hwp:id="xref-fn-5-1" hwp:rel-id="fn-5">3</xref></sup> Based on <xref ref-type="disp-formula" rid="eqn27" hwp:id="xref-disp-formula-27-1" hwp:rel-id="disp-formula-27">equation 27</xref> the trajectory that the decision-maker takes in the outcome space can have two different forms, depending on whether <bold>B</bold> is zero. We will show in the next section that whenever the reward field is conservative (i.e., outcomes are substitutable for each other), then <bold>B</bold> will be zero and therefore the rate of earning outcomes will be constant throughout the session (<italic toggle="yes">dv/dt</italic> = 0). In contrast, in the condition that the reward field is non-conservative (i.e., outcomes are not substitutable for each other), <bold>B</bold> will be non-zero, and based on <xref ref-type="disp-formula" rid="eqn27" hwp:id="xref-disp-formula-27-2" hwp:rel-id="disp-formula-27">equation 27</xref>, the change in the rate of outcome earning will be perpendicular to the current rate of outcome earning. It can be shown that in this condition the decision-maker will take a circular trajectory in the outcome space (more details are provided in the next sections). Each of these two conditions are analyzed in turn in the next two sections.</p><sec id="s4a" hwp:id="sec-10"><title hwp:id="title-11">Conservative reward field</title><p hwp:id="p-45">In line with the previous sections, letâs assume that <italic toggle="yes">D</italic><sub>x</sub> represents the motivational drive, and the amount of reward that consuming each outcome produces is equal to the amount of change that it makes in the motivational drive:
<disp-formula id="eqn28" hwp:id="disp-formula-28" hwp:rev-id="xref-disp-formula-28-1 xref-disp-formula-28-2 xref-disp-formula-28-3 xref-disp-formula-28-4 xref-disp-formula-28-5"><alternatives hwp:id="alternatives-28"><graphic xlink:href="057208_eqn28.gif" position="float" orientation="portrait" hwp:id="graphic-31"/></alternatives></disp-formula>
where <italic toggle="yes">D</italic><sub>x</sub> is a scalar field. We maintain the following theorem:
<statement id="theorem3" hwp:id="statement-3" hwp:rev-id="xref-statement-3-1 xref-statement-3-2"><label><bold>Theorem 3</bold></label><p hwp:id="p-46"><italic toggle="yes">If the reward field is conservative, i.e., there exists a scalar field <italic toggle="yes">D</italic><sub>x</sub> such that <xref ref-type="disp-formula" rid="eqn28" hwp:id="xref-disp-formula-28-1" hwp:rel-id="disp-formula-28">equation 28</xref> satisfies, and assuming that the time-dependent term of the reward field is zero</italic> (â<italic toggle="yes">A<sub>x,t</sub></italic>/â<italic toggle="yes">t</italic> = 0), <italic toggle="yes">then the optimal rate of earning outcomes will be constant</italic> (<italic toggle="yes">d</italic>v/<italic toggle="yes">dt</italic> = 0), <italic toggle="yes">and it satisfies the following equation:</italic>
<disp-formula id="eqn29" hwp:id="disp-formula-29" hwp:rev-id="xref-disp-formula-29-1"><alternatives hwp:id="alternatives-29"><graphic xlink:href="057208_eqn29.gif" position="float" orientation="portrait" hwp:id="graphic-32"/></alternatives></disp-formula>
See Appendix B for the proof.</p></statement>
</p><p hwp:id="p-47">Therefore, if a reward field is conservative, then the optimal rate of earning outcomes is a constant rate. In the special case that the environment consists of two outcomes, the reward field being conservative implies that:
<disp-formula id="eqn30" hwp:id="disp-formula-30"><alternatives hwp:id="alternatives-30"><graphic xlink:href="057208_eqn30.gif" position="float" orientation="portrait" hwp:id="graphic-33"/></alternatives></disp-formula>
which suggests that the amount of decrement in the reward of the first outcome due to the consumption of the second outcome (â[<italic toggle="yes">A<sub>x,t</sub></italic>]<sub>1</sub>/â<italic toggle="yes">x<sub>2</sub></italic>), is equal to the decrement in the reward of the second outcome due to the consumption of the first outcome (â[<italic toggle="yes">A<sub>x,t</sub></italic>]<sub>2</sub>/â<italic toggle="yes">x<sub>1</sub></italic>); in other words, the reward field being conservative implies that the two outcomes have <italic toggle="yes">the same degree of substitutability for each other</italic>.</p><p hwp:id="p-48">As an example, assume that the outcome space is two dimensional, and both outcomes satisfy the same internal state, say hunger. Consuming one unit of the first outcome decreases hunger by one unit, but consuming one unit of the second outcome reduces hunger by <italic toggle="yes">l</italic> units. As such, the motivationa<italic toggle="yes">l</italic> drive will be as follows:
<disp-formula id="eqn31" hwp:id="disp-formula-31"><alternatives hwp:id="alternatives-31"><graphic xlink:href="057208_eqn31.gif" position="float" orientation="portrait" hwp:id="graphic-34"/></alternatives></disp-formula>
where <italic toggle="yes">H</italic> is the homeostatic set-point of hunger. Using <xref ref-type="disp-formula" rid="eqn28" hwp:id="xref-disp-formula-28-2" hwp:rel-id="disp-formula-28">equation 28</xref> we have:
<disp-formula id="eqn32" hwp:id="disp-formula-32" hwp:rev-id="xref-disp-formula-32-1"><alternatives hwp:id="alternatives-32"><graphic xlink:href="057208_eqn32.gif" position="float" orientation="portrait" hwp:id="graphic-35"/></alternatives></disp-formula>
Based on <xref ref-type="statement" rid="theorem3" hwp:id="xref-statement-3-1" hwp:rel-id="statement-3">Theorem 3</xref>, <bold>B</bold> will be zero (â<italic toggle="yes">A</italic><sub>1</sub>.â<italic toggle="yes">x</italic><sub>2</sub> = â<italic toggle="yes">A</italic><sub>2</sub>/â<italic toggle="yes">x</italic><sub>1</sub>) implying that the outcomes have substitutability for each other, and the response rate along each outcome dimension will be:
<disp-formula id="eqn33" hwp:id="disp-formula-33"><alternatives hwp:id="alternatives-33"><graphic xlink:href="057208_eqn33.gif" position="float" orientation="portrait" hwp:id="graphic-36"/></alternatives></disp-formula>
where <italic toggle="yes">m</italic> = 2<italic toggle="yes">ak</italic><sup>2</sup> and for simplicity it is assumed that <italic toggle="yes">b</italic> = 0. The above relation shows that the rate of earning each outcome is proportional to its rewarding effect, and inversely related to the cost of earning the outcome. Similar results can be obtained in the condition that the reward properties of the outcomes are the same, but the costs of earning the outcomes are different. For example, under a concurrent FR schedule in which an anima<italic toggle="yes">l</italic> needs to make <italic toggle="yes">k</italic> responses on one of the levers to earn outcomes, and <italic toggle="yes">lk</italic> responses on the other lever to earn the same outcome, the optimal rate of earning outcomes will be as follows:
<disp-formula id="eqn34" hwp:id="disp-formula-34"><alternatives hwp:id="alternatives-34"><graphic xlink:href="057208_eqn34.gif" position="float" orientation="portrait" hwp:id="graphic-37"/></alternatives></disp-formula>
and the rate for each response will be:
<disp-formula id="eqn35" hwp:id="disp-formula-35" hwp:rev-id="xref-disp-formula-35-1"><alternatives hwp:id="alternatives-35"><graphic xlink:href="057208_eqn35.gif" position="float" orientation="portrait" hwp:id="graphic-38"/></alternatives></disp-formula>
which states that the rate of responding for the first outcome (the outcome with the lower ratio-requirement) is <italic toggle="yes">l</italic> times greater than the second outcome. These results are generally in line with the probability matching notion, which states that a decision-maker allocates responses to outcomes based on the ratio of responses required for each outcome (<xref rid="c8" ref-type="bibr" hwp:id="xref-ref-8-1" hwp:rel-id="ref-8">Estes, 1950</xref>). Probability matching is generally considered as a violation of the rational choice theory, since within this theory it is expected that a decision-maker exclusively works for the outcome with the higher probability (the lower ratio requirement). However, based on the model proposed here, <italic toggle="yes">probability matching</italic> is the optimal strategy and therefore consistent with rational decision-making.</p><p hwp:id="p-49">The above results, in fact, stem from the assumption that the cost of earning each outcome only depends on the rate of outcome earning in the same dimension, as expressed in <xref ref-type="disp-formula" rid="eqn25" hwp:id="xref-disp-formula-25-1" hwp:rel-id="disp-formula-25">equation 25</xref>. That is, the total cost of earning outcomes at rates <italic toggle="yes">v</italic><sub>1</sub> and <italic toggle="yes">v</italic><sub>2</sub> will be <inline-formula hwp:id="inline-formula-1"><alternatives hwp:id="alternatives-36"><inline-graphic xlink:href="057208_inline1.gif" hwp:id="inline-graphic-1"/></alternatives></inline-formula>, which implies that changing the response rate for one of the outcomes will not affect the cost of earning the other outcomes. As an example, imagine a concurrent instrumental conditioning experiment in which there are two levers available (left lever and right lever) and each lever leads to a different outcome. Here, the independence assumption entails that the cost of the current right lever press is determined by the time elapsed since the last right lever press and it does not matter whether there was a left lever press in between. Alternatively, one can assume what determines the cost is the delay between subsequent responses, either for the same or for a different outcome, i.e., the cost is proportional to the rate of earning all of the outcomes, and therefore, the cost takes the form <inline-formula hwp:id="inline-formula-2"><alternatives hwp:id="alternatives-37"><inline-graphic xlink:href="057208_inline2.gif" hwp:id="inline-graphic-2"/></alternatives></inline-formula>. This alternative captures the fact that the cost is a function of the delay between subsequent responses, either for the same or for a different outcome. In this condition <xref ref-type="disp-formula" rid="eqn25" hwp:id="xref-disp-formula-25-2" hwp:rel-id="disp-formula-25">equation 25</xref> does not hold anymore and the cost of earning outcomes will not be independent. Such a cost function can be achieved by defining the cost as follows:
<disp-formula id="eqn36" hwp:id="disp-formula-36" hwp:rev-id="xref-disp-formula-36-1"><alternatives hwp:id="alternatives-38"><graphic xlink:href="057208_eqn36.gif" position="float" orientation="portrait" hwp:id="graphic-39"/></alternatives></disp-formula>
Given the above cost function, the optimal strategy is <italic toggle="yes">maximisation</italic>, i.e., to take the action with the higher reward (lower ratio-requirement), and to stop taking the other action:
<disp-formula id="eqn37" hwp:id="disp-formula-37" hwp:rev-id="xref-disp-formula-37-1 xref-disp-formula-37-2"><alternatives hwp:id="alternatives-39"><graphic xlink:href="057208_eqn37.gif" position="float" orientation="portrait" hwp:id="graphic-40"/></alternatives></disp-formula>
See Conservative reward field for the proof.</p><p hwp:id="p-50">Therefore, whether the rate of outcome earning reflects probability matching or maximization strategy, depends on the cost function, and seemingly in the instrumental conditioning experiments, the cost that reflects the maximization strategy is better applicable. Regarding the experimental evidence, within the concurrent instrumental conditioning experiments, evidence in pigeons tested under the VR schedule (<xref rid="c14" ref-type="bibr" hwp:id="xref-ref-14-1" hwp:rel-id="ref-14">Herrnstein &amp; Loveland, 1975</xref>) is in-line with the maximization strategy, and consistent with the prediction of the model. Within a wider scope of the decision-making tasks, some studies are consistent with the probability matching notion (<xref rid="c12" ref-type="bibr" hwp:id="xref-ref-12-1" hwp:rel-id="ref-12">Grant, Hake, &amp; Hornseth, 1951</xref>) (see <xref rid="c47" ref-type="bibr" hwp:id="xref-ref-47-1" hwp:rel-id="ref-47">Vulkan (2000)</xref> for a review), while other studies provide evidence in-line with the maximization strategy (<xref rid="c7" ref-type="bibr" hwp:id="xref-ref-7-1" hwp:rel-id="ref-7">Edwards, 1961;</xref> <xref rid="c34" ref-type="bibr" hwp:id="xref-ref-34-1" hwp:rel-id="ref-34">Myers, Reilly, &amp; Taub, 1961;</xref> <xref rid="c44" ref-type="bibr" hwp:id="xref-ref-44-1" hwp:rel-id="ref-44">Shanks, Tunney, &amp; McCarthy, 2002;</xref> <xref rid="c46" ref-type="bibr" hwp:id="xref-ref-46-1" hwp:rel-id="ref-46">Siegel &amp; Goldstein, 1959</xref>). Here, in most of the experiments the decision-making task used involves making a single choice (e.g., single button press) and receiving the feedback immediately (about whether the choice is rewarded), and after that the next trial starts. Such disjoint actions are unlikely to convey a rate-dependent cost, and, therefore, the structure of such studies do not readily fit in the model proposed here.</p></sec><sec id="s4b" hwp:id="sec-11"><title hwp:id="title-12">Non-conservative reward field</title><p hwp:id="p-51">In this section we assume that the reward field is nonconservative, i.e., there does not exist a scalar field <italic toggle="yes">D</italic><sub>x</sub> such that <italic toggle="yes">A</italic><sub>x,<italic toggle="yes">t</italic></sub> satisfies <xref ref-type="disp-formula" rid="eqn28" hwp:id="xref-disp-formula-28-3" hwp:rel-id="disp-formula-28">equation 28</xref>. An example will be when the amount of reward that consuming an outcome produces is greater or smaller than the change in the motivational drive. For example, assume that there are two outcomes available, and the consumption of both outcomes has a similar effect on the motivational drive:
<disp-formula id="eqn38" hwp:id="disp-formula-38"><alternatives hwp:id="alternatives-40"><graphic xlink:href="057208_eqn38.gif" position="float" orientation="portrait" hwp:id="graphic-41"/></alternatives></disp-formula>
but the reward that the second outcome generates is <italic toggle="yes">l</italic> times larger than the change it creates in the motivational drive:
<disp-formula id="eqn39" hwp:id="disp-formula-39" hwp:rev-id="xref-disp-formula-39-1"><alternatives hwp:id="alternatives-41"><graphic xlink:href="057208_eqn39.gif" position="float" orientation="portrait" hwp:id="graphic-42"/></alternatives></disp-formula>
In this condition, â[<italic toggle="yes">A</italic><sub>x,<italic toggle="yes">t</italic></sub>]<sub>1</sub>/â<italic toggle="yes">x</italic><sub>2</sub> = 1 and â[<italic toggle="yes">A</italic><sub>x,<italic toggle="yes">t</italic></sub>]<sub>2</sub>/â<italic toggle="yes">x</italic><sub>1</sub> = <italic toggle="yes">l</italic>, and therefore the reward of the second outcome due to the consumption of the first outcome decreases more sharply than the reward of the first outcome would, due to the consumption of the second outcome. The reward field will be nonconservative and we have <bold>B</bold> = curl<italic toggle="yes">A</italic><sub>x,<italic toggle="yes">t</italic></sub> = (0, 0, 1 â <italic toggle="yes">l</italic>), which will make the decision-maker take a circular trajectory in the outcome space. The exact characteristics of the optimal trajectory depend on the session duration and factor <italic toggle="yes">l</italic>, which is stated in the following theorem:
<statement id="theorem4" hwp:id="statement-4" hwp:rev-id="xref-statement-4-1 xref-statement-4-2 xref-statement-4-3 xref-statement-4-4"><label><bold>Theorem 4</bold></label><p hwp:id="p-52"><italic toggle="yes">If the reward field follows <xref ref-type="disp-formula" rid="eqn39" hwp:id="xref-disp-formula-39-1" hwp:rel-id="disp-formula-39">equation 39</xref> and the cost is as follows:</italic>
<disp-formula id="eqn40" hwp:id="disp-formula-40"><alternatives hwp:id="alternatives-42"><graphic xlink:href="057208_eqn40.gif" position="float" orientation="portrait" hwp:id="graphic-43"/></alternatives></disp-formula>
<italic toggle="yes">then the optimal trajectory in the outcome space will be:</italic>
<disp-formula id="eqn41" hwp:id="disp-formula-41"><alternatives hwp:id="alternatives-43"><graphic xlink:href="057208_eqn41.gif" position="float" orientation="portrait" hwp:id="graphic-44"/></alternatives></disp-formula>
<italic toggle="yes">where</italic>
<disp-formula id="eqn42" hwp:id="disp-formula-42"><alternatives hwp:id="alternatives-44"><graphic xlink:href="057208_eqn42.gif" position="float" orientation="portrait" hwp:id="graphic-45"/></alternatives></disp-formula></p></statement>
See Appendix B for the proof and more details about the optimal trajectory.</p><p hwp:id="p-53">The above theorem implies that when the duration of the session is short (<italic toggle="yes">T</italic> &lt; <italic toggle="yes">T<sub>c</sub></italic>), then the trajectory in the outcome space is composed of a single segment, which is an arc of a circle. The response rate for both outcomes will be non-zero, and initially <italic toggle="yes">v</italic><sub>2</sub> &gt; <italic toggle="yes">lv</italic><sub>1</sub>, but at the end of the session the rate of earning the outcomes will be proportional to their reward effects (<italic toggle="yes">v</italic><sub>2</sub> = <italic toggle="yes">lv</italic><sub>1</sub>), as indicated by <xref ref-type="disp-formula" rid="eqn35" hwp:id="xref-disp-formula-35-1" hwp:rel-id="disp-formula-35">equation 35</xref> (<xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-1" hwp:rel-id="F4">Figure 4a,b</xref>). When the session duration is long, the trajectory in the outcome space will be composed of two segments. In the initial segment, the response rate for the outcome with the lower reward effect will be zero, and the decision-maker only works for the outcome with the higher reward effect. This segment continues until the time remaining to the end of the session is less than <italic toggle="yes">T<sub>c</sub></italic>. After this time the second segment starts, which is an arc of a circle (<xref ref-type="fig" rid="fig4" hwp:id="xref-fig-4-2" hwp:rel-id="F4">Figure 4c</xref>).</p><p hwp:id="p-54">A test of the prediction of <xref ref-type="statement" rid="theorem4" hwp:id="xref-statement-4-1" hwp:rel-id="statement-4">Theorem 4</xref>, would be an experiment with two outcomes corresponding to the same food (and therefore having the same impact on the motivational drive) but with different levels of the desirability (e.g., two different flavors), and, therefore, having a different reward effect. We were not able to find such an experiment in the instrumental conditioning literature and, therefore, the prediction of <xref ref-type="statement" rid="theorem4" hwp:id="xref-statement-4-2" hwp:rel-id="statement-4">Theorem 4</xref> Theorem 4 will be left for future testing.</p></sec></sec><sec id="s5" hwp:id="sec-12"><title hwp:id="title-13">Discussion</title><p hwp:id="p-55">We formulated the problem of finding the optimal choice and response vigor in an optimal control framework by introducing the novel concept of reward field and using variational calculus methods. This formulation allowed us to derive the analytical solutions of the optimal rate of outcome earning in a wide range of experimental conditions. The analysis was divided into two sections: (1) the situations in which the environment contains only one outcome, and (2) the situations in which multiple outcomes can be earned in the environment. In the first condition, the results indicate that if the session duration is deterministic and known by the decision-maker, then the optimal rate of outcome earning is a constant rate throughout the session. Although these results are consistent with the majority of empirical results, they are inconsistent with the studies showing that the response rates decrease throughout an experiment session. We further showed that the uncertainty of the decision-maker about the session duration can explain this effect. In the conditions that the environment contains multiple outcomes, the results indicate that the optimal trajectory in the outcome space can take two different forms: (1) if the outcomes in the environment are substitutable for each other (equivalent to the reward field being conservative) then the optimal trajectory is a straight line in the outcome space; we discussed that these results are consistent with both probability matching and maximization notions of decision-making; (2) if the outcomes in the environment are not substitutable for each other, then the optimal trajectory is a straight line followed by a circular trajectory. To our knowledge, these results are the first analytical solution to the problem of choice and response vigor in the condition that the values of the outcomes can vary in the decision-making session.</p><fig id="fig4" position="float" fig-type="figure" orientation="portrait" hwp:id="F4" hwp:rev-id="xref-fig-4-1 xref-fig-4-2"><object-id pub-id-type="other" hwp:sub-type="pisa">biorxiv;057208v1/FIG4</object-id><object-id pub-id-type="other" hwp:sub-type="slug">F4</object-id><object-id pub-id-type="publisher-id">fig4</object-id><label><italic toggle="yes">Figure 4</italic>.</label><caption hwp:id="caption-4"><p hwp:id="p-56">The optimal trajectories in the outcome space when the reward field is non-conservative. o1 and o2 are two different outcomes, where the amount of reward that <italic toggle="yes">o</italic><sub>2</sub> generates is larger than the decrement it creates in the motivational drive. Parameters used for simulations are <italic toggle="yes">k</italic> = 1, <italic toggle="yes">l</italic> = 1.1, <italic toggle="yes">a</italic> = 1, <italic toggle="yes">b</italic> = 0, <italic toggle="yes">H</italic> = 100, <italic toggle="yes">m</italic> = 2<italic toggle="yes">ak</italic><sup>2</sup> (a) Short session duration <italic toggle="yes">T</italic> = 7. (b) Medium session duration <italic toggle="yes">T</italic> = <italic toggle="yes">T<sub>c</sub></italic> â 14.75. (c) Long session duration <italic toggle="yes">T</italic> = 23.</p></caption><graphic xlink:href="057208_fig4" position="float" orientation="portrait" hwp:id="graphic-46"/></fig><p hwp:id="p-57">There are two significant differences between the model proposed here and the previous models of response vigor (<xref rid="c6" ref-type="bibr" hwp:id="xref-ref-6-3" hwp:rel-id="ref-6">Dayan, 2012;</xref> <xref rid="c36" ref-type="bibr" hwp:id="xref-ref-36-3" hwp:rel-id="ref-36">Niv et al., 2007</xref>). Firstly, although the effect of between-session changes in the motivational drive on response vigor has been addressed in the previous models (<xref rid="c37" ref-type="bibr" hwp:id="xref-ref-37-1" hwp:rel-id="ref-37">Niv, Joel, &amp; Dayan, 2006</xref>), the effects of the on-line changes in the motivational drive within a session are not addressed in the previous works, which we address in this model. Secondly, previous works conceptualized the structure of the task as a semi-Markov decision process, and derived the optimal actions that maximize the average reward per unit of time (average reward). Here, we used a variational analysis to calculate the optimal actions that maximize the reward earned within the session. One benefit of the approach taken in the previous works is that it extends naturally to a wide range of instrumental conditioning schedules such as interval schedules, while the extension of the model proposed here to the case of interval schedules is not trivial. Optimizing the average reward (as adopted in the previous works) is equivalent to the maximization of the reward in an infinite-horizon time scale, i.e., the session duration is unlimited; in contrast, the model used here explicitly represents the duration of the session, which as we showed plays an important role in the pattern of responses.</p><p hwp:id="p-58">We assumed that the cost is only a function of the rate of earning outcomes, and it is time-independent (â<italic toggle="yes">k</italic><sub>v</sub>/â<sub><italic toggle="yes">t</italic></sub> = 0). However, in general one can assume that as time passes within a session, the cost of taking actions will be increased because of factors such as effector fatigue. Here we made the time-independence assumption based on previous studies that showed factors such as effector fatigue have a negligible effect on response rates (<xref rid="c30" ref-type="bibr" hwp:id="xref-ref-30-1" hwp:rel-id="ref-30">McSweeney, Hinson, &amp; Cannon, 1996</xref>). Similarly, in the derivation of <xref ref-type="statement" rid="theorem2" hwp:id="xref-statement-2-1" hwp:rel-id="statement-2">Theorem 2â4</xref> we assumed that the time-dependent component of the reward field is zero (â<italic toggle="yes">A<sub>x,t</sub></italic>/â<italic toggle="yes">t</italic> = 0), which seems to be a reasonable assumption, given the typical duration of an instrumental conditioning experiment.</p><p hwp:id="p-59">The value of the outcomes can change because of factors other than changes in the motivational drive, such as specific satiety. In fact, the definition of the reward field is general and as long as it satisfies <xref ref-type="disp-formula" rid="eqn1" hwp:id="xref-disp-formula-1-1" hwp:rel-id="disp-formula-1">equation 1</xref> and <xref ref-type="disp-formula" rid="eqn2" hwp:id="xref-disp-formula-2-3" hwp:rel-id="disp-formula-2">2</xref>, the results obtained will be valid, irrespective of whether the underlying reason in the variability of the reward field is the motivational drive or other factors. Here, the reason that we used the motivational drive as the underlying cause of changes in the outcome values was because of the existence of the previous studies that link the quantity of outcome consumption to the reward of outcomes (<xref rid="c19" ref-type="bibr" hwp:id="xref-ref-19-4" hwp:rel-id="ref-19">Keramati &amp; Gutkin, 2014</xref>); however, the model is general and can be applied to any other source hat can cause changes in the value of the outcomes.</p></sec></body><back><ack hwp:id="ack-1"><title hwp:id="title-14">Disclosures and Acknowledgments</title><p hwp:id="p-60">NICTA is funded by the Australian Government as represented by the Dept. of Communications and the ARC through the ICT Centre of Excellence program. The funding source had no other role other than financial support.</p><p hwp:id="p-61">All authors contributed in a significant way to the manuscript and that all authors have read and approved the final manuscript.</p><p hwp:id="p-62">The author declares that the research was conducted in the absence of any commercial or financial relationships that could be construed as a potential conflict of interest.</p></ack><ref-list hwp:id="ref-list-1"><title hwp:id="title-15">References</title><ref id="c1" hwp:id="ref-1" hwp:rev-id="xref-ref-1-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.1" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-1"><string-name name-style="western" hwp:sortable="Aberman J. E."><surname>Aberman</surname>, <given-names>J. E.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Salamone J. D."><surname>Salamone</surname>, <given-names>J. D.</given-names></string-name> (<year>1999</year>). <article-title hwp:id="article-title-2">Nucleus accumbens dopamine depletions make rats more sensitive to high ratio requirements but do not impair primary food reinforcement</article-title>. <source hwp:id="source-1">Neuroscience</source>, <volume>92</volume>(<issue>2</issue>), <fpage>545</fpage>â<lpage>52</lpage>.</citation></ref><ref id="c2" hwp:id="ref-2" hwp:rev-id="xref-ref-2-1 xref-ref-2-2"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.2" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-2"><string-name name-style="western" hwp:sortable="Adair E. R."><surname>Adair</surname>, <given-names>E. R.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Wright B. A."><surname>Wright</surname>, <given-names>B. A.</given-names></string-name> (<year>1976</year>). <article-title hwp:id="article-title-3">Behavioral thermoregulation in the squirrel monkey when response effort is varied</article-title>. <source hwp:id="source-2">Journal of Comparative and Physiological Psychology</source>, <volume>90</volume>(<issue>2</issue>), <fpage>179</fpage>.</citation></ref><ref id="c3" hwp:id="ref-3" hwp:rev-id="xref-ref-3-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.3" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-3"><string-name name-style="western" hwp:sortable="Alling K."><surname>Alling</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Poling A."><surname>Poling</surname>, <given-names>A.</given-names></string-name> (<year>1995</year>, may). <article-title hwp:id="article-title-4">The effects of differing response-force requirements on fixed-ratio responding of rats</article-title>. <source hwp:id="source-3">Journal of the experimental analysis of behavior</source>, <volume>63</volume>(<issue>3</issue>), <fpage>331</fpage>â<lpage>46</lpage>.</citation></ref><ref id="c4" hwp:id="ref-4" hwp:rev-id="xref-ref-4-1 xref-ref-4-2 xref-ref-4-3"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.4" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-4"><string-name name-style="western" hwp:sortable="Barofsky I."><surname>Barofsky</surname>, <given-names>I.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Hurwitz D."><surname>Hurwitz</surname>, <given-names>D.</given-names></string-name> (<year>1968</year>). <article-title hwp:id="article-title-5">Within ratio responding during fixed ratio performance</article-title>. <source hwp:id="source-4">Psychonomic Science</source>, <volume>11</volume>(<issue>7</issue>), <fpage>263</fpage>â<lpage>264</lpage>.</citation></ref><ref id="c5" hwp:id="ref-5" hwp:rev-id="xref-ref-5-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.5" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-5"><string-name name-style="western" hwp:sortable="Baum W. M."><surname>Baum</surname>, <given-names>W. M.</given-names></string-name> (<year>1993</year>). <article-title hwp:id="article-title-6">Performances on ratio and interval schedules of reinforcement: Data and theory</article-title>. <source hwp:id="source-5">Journal of the Experimental Analysis of Behavior</source>, <volume>59</volume>(<issue>2</issue>), <fpage>245</fpage>.</citation></ref><ref id="c6" hwp:id="ref-6" hwp:rev-id="xref-ref-6-1 xref-ref-6-2 xref-ref-6-3"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.6" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-6"><string-name name-style="western" hwp:sortable="Dayan P."><surname>Dayan</surname>, <given-names>P.</given-names></string-name> (<year>2012</year>, apr). <article-title hwp:id="article-title-7">Instrumental vigour in punishment and reward</article-title>. <source hwp:id="source-6">The European journal of neuroscience</source>, <volume>35</volume>(<issue>7</issue>), <fpage>115</fpage>â<lpage>268</lpage>.</citation></ref><ref id="c7" hwp:id="ref-7" hwp:rev-id="xref-ref-7-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.7" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-7"><string-name name-style="western" hwp:sortable="Edwards W."><surname>Edwards</surname>, <given-names>W.</given-names></string-name> (<year>1961</year>). <article-title hwp:id="article-title-8">Probability learning in 1000 trials</article-title>. <source hwp:id="source-7">Journal of Experimental Psychology</source>, <volume>62</volume>(<issue>4</issue>), <fpage>385</fpage>.</citation></ref><ref id="c8" hwp:id="ref-8" hwp:rev-id="xref-ref-8-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.8" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-8"><string-name name-style="western" hwp:sortable="Estes W. K."><surname>Estes</surname>, <given-names>W. K.</given-names></string-name> (<year>1950</year>). <article-title hwp:id="article-title-9">Toward a statistical theory of learning</article-title>. <source hwp:id="source-8">Psychological review</source>, <volume>57</volume>(<issue>2</issue>), <fpage>94</fpage>.</citation></ref><ref id="c9" hwp:id="ref-9" hwp:rev-id="xref-ref-9-1 xref-ref-9-2"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.9" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-9"><string-name name-style="western" hwp:sortable="Felton M."><surname>Felton</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Lyon D. O."><surname>Lyon</surname>, <given-names>D. O.</given-names></string-name> (<year>1966</year>). <article-title hwp:id="article-title-10">The post-reinforcement pause</article-title>. <source hwp:id="source-9">Journal of the Experimental Analysis of Behavior</source>, <volume>9</volume>(<issue>2</issue>), <fpage>131</fpage>â<lpage>134</lpage>.</citation></ref><ref id="c10" hwp:id="ref-10" hwp:rev-id="xref-ref-10-1 xref-ref-10-2"><citation publication-type="book" citation-type="book" ref:id="057208v1.10" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-10"><string-name name-style="western" hwp:sortable="Ferster C. B."><surname>Ferster</surname>, <given-names>C. B.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Skinner B. F."><surname>Skinner</surname>, <given-names>B. F.</given-names></string-name> (<year>1957</year>). <source hwp:id="source-10">Schedules of reinforcement</source>.<publisher-name>Prentice-hall inc</publisher-name>.</citation></ref><ref id="c11" hwp:id="ref-11" hwp:rev-id="xref-ref-11-1 xref-ref-11-2"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.11" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-11"><string-name name-style="western" hwp:sortable="Foster M."><surname>Foster</surname>, <given-names>M.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Blackman K."><surname>Blackman</surname>, <given-names>K.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Temple W."><surname>Temple</surname>, <given-names>W.</given-names></string-name> (<year>1997</year>). <article-title hwp:id="article-title-11">Open versus closed economies: performance of domestic hens under fixed ratio schedules</article-title>. <source hwp:id="source-11">Journal of the Experimental Analysis of Behavior</source>, <volume>67</volume>(<issue>1</issue>), <fpage>67</fpage>.</citation></ref><ref id="c12" hwp:id="ref-12" hwp:rev-id="xref-ref-12-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.12" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-12"><string-name name-style="western" hwp:sortable="Grant D. A."><surname>Grant</surname>, <given-names>D. A.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hake H. W."><surname>Hake</surname>, <given-names>H. W.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Hornseth J. P."><surname>Hornseth</surname>, <given-names>J. P.</given-names></string-name> (<year>1951</year>). <article-title hwp:id="article-title-12">Acquisition and extinction of a verbal conditioned response with differing percentages of reinforcement</article-title>. <source hwp:id="source-12">Journal of experimental psychology</source>, <volume>42</volume>(<issue>1</issue>), <fpage>1</fpage>.</citation></ref><ref id="c13" hwp:id="ref-13" hwp:rev-id="xref-ref-13-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.13" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-13"><string-name name-style="western" hwp:sortable="Greenwood M. R."><surname>Greenwood</surname>, <given-names>M. R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Quartermain D."><surname>Quartermain</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Johnson P. R."><surname>Johnson</surname>, <given-names>P. R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Cruce J. A."><surname>Cruce</surname>, <given-names>J. A.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Hirsch J."><surname>Hirsch</surname>, <given-names>J.</given-names></string-name> (<year>1974</year>, nov). <article-title hwp:id="article-title-13">Food motivated behavior in genetically obese and hypothalamic-hyperphagic rats and mice</article-title>. <source hwp:id="source-13">Physiology &amp; behavior</source>, <volume>13</volume>(<issue>5</issue>), <fpage>687</fpage>â<lpage>92</lpage>.</citation></ref><ref id="c14" hwp:id="ref-14" hwp:rev-id="xref-ref-14-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.14" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-14"><string-name name-style="western" hwp:sortable="Herrnstein R. J."><surname>Herrnstein</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Loveland D. H."><surname>Loveland</surname>, <given-names>D. H.</given-names></string-name> (<year>1975</year>). <article-title hwp:id="article-title-14">Maximizing and matching on concurrent ratio schedules</article-title>. <source hwp:id="source-14">Journal of the experimental analysis of behavior</source>, <volume>24</volume>(<issue>1</issue>), <fpage>107</fpage>.</citation></ref><ref id="c15" hwp:id="ref-15" hwp:rev-id="xref-ref-15-1"><citation publication-type="book" citation-type="book" ref:id="057208v1.15" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-15"><string-name name-style="western" hwp:sortable="Hull C. L."><surname>Hull</surname>, <given-names>C. L.</given-names></string-name> (<year>1943</year>). <source hwp:id="source-15">Principles of Behavior</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Appleton-Century</publisher-name>.</citation></ref><ref id="c16" hwp:id="ref-16" hwp:rev-id="xref-ref-16-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.16" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-16"><string-name name-style="western" hwp:sortable="Keesey R. E."><surname>Keesey</surname>, <given-names>R. E.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Kling J. W."><surname>Kling</surname>, <given-names>J. W.</given-names></string-name> (<year>1961</year>). <article-title hwp:id="article-title-15">Amount of reinforcement and free-operant responding</article-title>. <source hwp:id="source-16">Journal of the Experimental analysis of behavior</source>, <volume>4</volume>(<issue>2</issue>), <fpage>125</fpage>â<lpage>132</lpage>.</citation></ref><ref id="c17" hwp:id="ref-17" hwp:rev-id="xref-ref-17-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.17" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-17"><string-name name-style="western" hwp:sortable="Kelsey J. E."><surname>Kelsey</surname>, <given-names>J. E.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Allison J."><surname>Allison</surname>, <given-names>J.</given-names></string-name> (<year>1976</year>). <article-title hwp:id="article-title-16">Fixed-ratio lever pressing by VMH rats: Work vs accessibility of sucrose reward</article-title>. <source hwp:id="source-17">Physiology &amp; behavior</source>, <volume>17</volume>(<issue>5</issue>), <fpage>749</fpage>â<lpage>754</lpage>.</citation></ref><ref id="c18" hwp:id="ref-18" hwp:rev-id="xref-ref-18-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.18" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-18"><string-name name-style="western" hwp:sortable="Keramati M."><surname>Keramati</surname>, <given-names>M.</given-names></string-name> (<year>2011</year>). <source hwp:id="source-18">A Reinforcement Learning Theory for Homeostatic Regulationâ¥</source></citation></ref><ref id="c19" hwp:id="ref-19" hwp:rev-id="xref-ref-19-1 xref-ref-19-2 xref-ref-19-3 xref-ref-19-4"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.19" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-19"><string-name name-style="western" hwp:sortable="Keramati M."><surname>Keramati</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Gutkin B."><surname>Gutkin</surname>, <given-names>B.</given-names></string-name> (<year>2014</year>). <article-title hwp:id="article-title-17">Homeostatic reinforcement learning for integrating reward collection and physiological stability</article-title>. <source hwp:id="source-19">eLife</source>, <fpage>3</fpage>.</citation></ref><ref id="c20" hwp:id="ref-20" hwp:rev-id="xref-ref-20-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.20" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-20"><string-name name-style="western" hwp:sortable="Killeen P. R."><surname>Killeen</surname>, <given-names>P. R.</given-names></string-name> (<year>1994</year>, feb). <article-title hwp:id="article-title-18">Mathematical principles of reinforcement</article-title>. <source hwp:id="source-20">Behavioral and Brain Sciences</source>, <volume>17</volume>, <fpage>105</fpage>â<lpage>172</lpage>.</citation></ref><ref id="c21" hwp:id="ref-21" hwp:rev-id="xref-ref-21-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.21" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-21"><string-name name-style="western" hwp:sortable="Killeen P. R."><surname>Killeen</surname>, <given-names>P. R.</given-names></string-name> (<year>1995a</year>). <article-title hwp:id="article-title-19">Economics, ecologics, and mechanics: The dynamics of responding under conditions of varying motivation</article-title>. <source hwp:id="source-21">Journal of the Experimental Analysis of Behavior</source>, <volume>64</volume>(<issue>3</issue>), <fpage>405</fpage>â<lpage>431</lpage>.</citation></ref><ref id="c22" hwp:id="ref-22" hwp:rev-id="xref-ref-22-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.22" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-22"><string-name name-style="western" hwp:sortable="Killeen P. R."><surname>Killeen</surname>, <given-names>P. R.</given-names></string-name> (<year>1995b</year>, nov). <article-title hwp:id="article-title-20">Economics, ecologics, and mechanics: The dynamics of responding under conditions of varying motivation</article-title>. <source hwp:id="source-22">Journal of the Experimental Analysis of Behavior</source>, <volume>64</volume>(<issue>3</issue>), <fpage>405</fpage>â<lpage>431</lpage>. <pub-id pub-id-type="doi" specific-use="metadata">10.1901/jeab.1995.64-405</pub-id></citation></ref><ref id="c23" hwp:id="ref-23" hwp:rev-id="xref-ref-23-1 xref-ref-23-2"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.23" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-23"><string-name name-style="western" hwp:sortable="Killeen P. R."><surname>Killeen</surname>, <given-names>P. R.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Sitomer M. T."><surname>Sitomer</surname>, <given-names>M. T.</given-names></string-name> (<year>2003</year>, apr). <article-title hwp:id="article-title-21">MPR</article-title>. <source hwp:id="source-23">Behavioural Processes</source>, <volume>62</volume>(<issue>1â3</issue>), <fpage>49</fpage>â<lpage>64</lpage>.</citation></ref><ref id="c24" hwp:id="ref-24" hwp:rev-id="xref-ref-24-1"><citation publication-type="book" citation-type="book" ref:id="057208v1.24" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-24"><string-name name-style="western" hwp:sortable="Liberzon D."><surname>Liberzon</surname>, <given-names>D.</given-names></string-name> (<year>2011</year>). <source hwp:id="source-24">Calculus of Variations and Optimal Control Theory: A Concise Introduction</source>. <publisher-name>Princeton University Press</publisher-name>.</citation></ref><ref id="c25" hwp:id="ref-25" hwp:rev-id="xref-ref-25-1 xref-ref-25-2"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.25" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-25"><string-name name-style="western" hwp:sortable="Lowe C. F."><surname>Lowe</surname>, <given-names>C. F.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Davey G. C. L."><surname>Davey</surname>, <given-names>G. C. L.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Harzem P."><surname>Harzem</surname>, <given-names>P.</given-names></string-name> (<year>1974</year>). <article-title hwp:id="article-title-22">Effects of reinforcement magnitude on interval and ratio schedules</article-title>. <source hwp:id="source-25">Journal of the Experimental analysis of behavior</source>, <volume>22</volume>(<issue>3</issue>), <fpage>553</fpage>â<lpage>560</lpage>.</citation></ref><ref id="c26" hwp:id="ref-26" hwp:rev-id="xref-ref-26-1"><citation publication-type="book" citation-type="book" ref:id="057208v1.26" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-26"><string-name name-style="western" hwp:sortable="Mazur J. E."><surname>Mazur</surname>, <given-names>J. E.</given-names></string-name> (<year>1982</year>). <chapter-title>A molecular approach to ratio schedule performance</chapter-title>. In <person-group person-group-type="editor" hwp:id="person-group-1"><string-name name-style="western" hwp:sortable="Commons M. L."><given-names>M. L.</given-names> <surname>Commons</surname></string-name>, <string-name name-style="western" hwp:sortable="Herrnstein R. J."><given-names>R. J.</given-names> <surname>Herrnstein</surname></string-name>, &amp; <string-name name-style="western" hwp:sortable="Rachlin H."><given-names>H.</given-names> <surname>Rachlin</surname></string-name></person-group> (Eds.), <source hwp:id="source-26">Quantitative analyses of behavior vol. 2: Matching and maximizing accounts</source>. <publisher-loc>Ballinger</publisher-loc>.</citation></ref><ref id="c27" hwp:id="ref-27" hwp:rev-id="xref-ref-27-1 xref-ref-27-2 xref-ref-27-3"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.27" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-27"><string-name name-style="western" hwp:sortable="McGuire J. T."><surname>McGuire</surname>, <given-names>J. T.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Kable J. W."><surname>Kable</surname>, <given-names>J. W.</given-names></string-name> (<year>2013</year>, apr). <article-title hwp:id="article-title-23">Rational temporal predictions can underlie apparent failures to delay gratification</article-title>. <source hwp:id="source-27">Psychological review</source>, <volume>120</volume>(<issue>2</issue>), <fpage>395</fpage>â<lpage>410</lpage>.</citation></ref><ref id="c28" hwp:id="ref-28" hwp:rev-id="xref-ref-28-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.28" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-28"><string-name name-style="western" hwp:sortable="McSweeney F. K."><surname>McSweeney</surname>, <given-names>F. K.</given-names></string-name> (<year>2004</year>). <article-title hwp:id="article-title-24">Dynamic changes in reinforcer effectiveness: Satiation and habituation have different implications for theory and practice</article-title>. <source hwp:id="source-28">The Behavior Analyst</source>, <volume>27</volume>(<issue>2</issue>), <fpage>171</fpage>â<lpage>188</lpage>.</citation></ref><ref id="c29" hwp:id="ref-29" hwp:rev-id="xref-ref-29-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.29" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-29"><string-name name-style="western" hwp:sortable="McSweeney F. K."><surname>McSweeney</surname>, <given-names>F. K.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Hinson J. M."><surname>Hinson</surname>, <given-names>J. M.</given-names></string-name> (<year>1992</year>, jul). <article-title hwp:id="article-title-25">Patterns of responding within sessions</article-title>. <source hwp:id="source-29">Journal of the Experimental Analysis of Behavior</source>, <volume>58</volume>(<issue>1</issue>), <fpage>19</fpage>â<lpage>36</lpage>.</citation></ref><ref id="c30" hwp:id="ref-30" hwp:rev-id="xref-ref-30-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.30" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-30"><string-name name-style="western" hwp:sortable="McSweeney F. K."><surname>McSweeney</surname>, <given-names>F. K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Hinson J. M."><surname>Hinson</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Cannon C. B."><surname>Cannon</surname>, <given-names>C. B.</given-names></string-name> (<year>1996</year>). <article-title hwp:id="article-title-26">Sensitization-habituation may occur during operant conditioning</article-title>. <source hwp:id="source-30">Psychological Bulletin</source>, <volume>120</volume>(<issue>2</issue>), <fpage>256</fpage>.</citation></ref><ref id="c31" hwp:id="ref-31" hwp:rev-id="xref-ref-31-1 xref-ref-31-2"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.31" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-31"><string-name name-style="western" hwp:sortable="McSweeney F. K."><surname>McSweeney</surname>, <given-names>F. K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Roll J. M."><surname>Roll</surname>, <given-names>J. M.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Weatherly J. N."><surname>Weatherly</surname>, <given-names>J. N.</given-names></string-name> (<year>1994</year>, jul). <article-title hwp:id="article-title-27">Within-session changes in responding during several simple schedules</article-title>. <source hwp:id="source-31">Journal of the Experimental Analysis of Behavior</source>, <volume>62</volume>(<issue>1</issue>), <fpage>109</fpage>â<lpage>132</lpage>.</citation></ref><ref id="c32" hwp:id="ref-32" hwp:rev-id="xref-ref-32-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.32" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-32"><string-name name-style="western" hwp:sortable="McSweeney F. K."><surname>McSweeney</surname>, <given-names>F. K.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Weatherly J. N."><surname>Weatherly</surname>, <given-names>J. N.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Swindell S."><surname>Swindell</surname>, <given-names>S.</given-names></string-name> (<year>1995</year>, jul). <article-title hwp:id="article-title-28">Within-session changes in key and lever pressing for water during several multiple variable-interval schedules</article-title>. <source hwp:id="source-32">Journal of the Experimental Analysis of Behavior</source>, <volume>64</volume>(<issue>1</issue>), <fpage>75</fpage>â<lpage>94</lpage>.</citation></ref><ref id="c33" hwp:id="ref-33" hwp:rev-id="xref-ref-33-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.33" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-33"><string-name name-style="western" hwp:sortable="Meunier G. F."><surname>Meunier</surname>, <given-names>G. F.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Starratt C."><surname>Starratt</surname>, <given-names>C.</given-names></string-name> (<year>1979</year>). <article-title hwp:id="article-title-29">On the magnitude of reinforcement and fixed-ratio behavior</article-title>. <source hwp:id="source-33">Bulletin of the Psycho-nomic Society</source>, <volume>13</volume>(<issue>6</issue>), <fpage>355</fpage>â<lpage>356</lpage>.</citation></ref><ref id="c34" hwp:id="ref-34" hwp:rev-id="xref-ref-34-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.34" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-34"><string-name name-style="western" hwp:sortable="Myers J. L."><surname>Myers</surname>, <given-names>J. L.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Reilly R. E."><surname>Reilly</surname>, <given-names>R. E.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Taub H. A."><surname>Taub</surname>, <given-names>H. A.</given-names></string-name> (<year>1961</year>). <article-title hwp:id="article-title-30">Differential cost, gain, and relative frequency of reward in a sequential choice situation</article-title>. <source hwp:id="source-34">Journal of experimental Psychology</source>, <volume>62</volume>(<issue>4</issue>), <fpage>357</fpage>.</citation></ref><ref id="c35" hwp:id="ref-35" hwp:rev-id="xref-ref-35-1"><citation publication-type="book" citation-type="book" ref:id="057208v1.35" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-35"><string-name name-style="western" hwp:sortable="Neumann L. J."><surname>Neumann</surname>, <given-names>L. J.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Morgenstern O."><surname>Morgenstern</surname>, <given-names>O.</given-names></string-name> (<year>1947</year>). <source hwp:id="source-35">Theory of games and economic behavior</source> (Vol. <volume>60</volume>). <publisher-name>Princeton university press Princeton</publisher-name>.</citation></ref><ref id="c36" hwp:id="ref-36" hwp:rev-id="xref-ref-36-1 xref-ref-36-2 xref-ref-36-3"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.36" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-36"><string-name name-style="western" hwp:sortable="Niv Y."><surname>Niv</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Daw N. D."><surname>Daw</surname>, <given-names>N. D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Joel D."><surname>Joel</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Dayan P."><surname>Dayan</surname>, <given-names>P.</given-names></string-name> (<year>2007</year>, apr). <article-title hwp:id="article-title-31">Tonic dopamine: opportunity costs and the control of response vigor</article-title>. <source hwp:id="source-36">Psychopharmacology</source>, <volume>191</volume>(<issue>3</issue>), <fpage>507</fpage>â<lpage>20</lpage>.</citation></ref><ref id="c37" hwp:id="ref-37" hwp:rev-id="xref-ref-37-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.37" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-37"><string-name name-style="western" hwp:sortable="Niv Y."><surname>Niv</surname>, <given-names>Y.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Joel D."><surname>Joel</surname>, <given-names>D.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Dayan P."><surname>Dayan</surname>, <given-names>P.</given-names></string-name> (<year>2006</year>, aug). <article-title hwp:id="article-title-32">A normative perspective on motivation</article-title>. <source hwp:id="source-37">Trends in cognitive sciences</source>, <volume>10</volume>(<issue>8</issue>), <fpage>375</fpage>â<lpage>81</lpage>. <pub-id pub-id-type="doi" specific-use="metadata">10.1016/j.tics.2006.06.010</pub-id></citation></ref><ref id="c38" hwp:id="ref-38" hwp:rev-id="xref-ref-38-1"><citation publication-type="book" citation-type="book" ref:id="057208v1.38" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-38"><string-name name-style="western" hwp:sortable="Pear J."><surname>Pear</surname>, <given-names>J.</given-names></string-name> (<year>2001</year>). <source hwp:id="source-38">The science of learning</source>. <publisher-name>Psychology Press</publisher-name>.</citation></ref><ref id="c39" hwp:id="ref-39" hwp:rev-id="xref-ref-39-1 xref-ref-39-2"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.39" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-39"><string-name name-style="western" hwp:sortable="Powell R. W."><surname>Powell</surname>, <given-names>R. W.</given-names></string-name> (<year>1968</year>). <article-title hwp:id="article-title-33">The effect of small sequential changes in fixed-ratio size upon the post-reinforcement pause</article-title>. <source hwp:id="source-39">Journal of the Experimental Analysis of Behavior</source>, <volume>11</volume>(<issue>5</issue>), <fpage>589</fpage>â<lpage>593</lpage>.</citation></ref><ref id="c40" hwp:id="ref-40" hwp:rev-id="xref-ref-40-1 xref-ref-40-2"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.40" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-40"><string-name name-style="western" hwp:sortable="Powell R. W."><surname>Powell</surname>, <given-names>R. W.</given-names></string-name> (<year>1969</year>). <article-title hwp:id="article-title-34">The effect of reinforcement magnitude upon responding under fixed-ratio schedules</article-title>. <source hwp:id="source-40">Journal of the Experimental Analysis of Behavior</source>, <volume>12</volume>(<issue>4</issue>), <fpage>605</fpage>â<lpage>608</lpage>.</citation></ref><ref id="c41" hwp:id="ref-41" hwp:rev-id="xref-ref-41-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.41" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-41"><string-name name-style="western" hwp:sortable="Premack D."><surname>Premack</surname>, <given-names>D.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Schaeffer R. W."><surname>Schaeffer</surname>, <given-names>R. W.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Hundt A."><surname>Hundt</surname>, <given-names>A.</given-names></string-name> (<year>1964</year>). <article-title hwp:id="article-title-35">Reinforcement of drinking by running: effect of fixed ratio and reinforcement time</article-title>. <source hwp:id="source-41">Journal of the experimental analysis of behavior</source>, <volume>7</volume>(<issue>1</issue>), <fpage>91</fpage>â<lpage>96</lpage>.</citation></ref><ref id="c42" hwp:id="ref-42" hwp:rev-id="xref-ref-42-1"><citation publication-type="book" citation-type="book" ref:id="057208v1.42" ref:linkable="no" ref:use-reference-as-is="yes" hwp:id="citation-42"><string-name name-style="western" hwp:sortable="Rachlin H."><surname>Rachlin</surname>, <given-names>H.</given-names></string-name> (<year>2000</year>). <source hwp:id="source-42">The Science of Self-Control</source>. <publisher-name>Harvard University Press</publisher-name>.</citation></ref><ref id="c43" hwp:id="ref-43" hwp:rev-id="xref-ref-43-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.43" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-43"><string-name name-style="western" hwp:sortable="Salimpour Y."><surname>Salimpour</surname>, <given-names>Y.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Shadmehr R."><surname>Shadmehr</surname>, <given-names>R.</given-names></string-name> (<year>2014</year>, jan). <article-title hwp:id="article-title-36">Motor costs and the coordination of the two arms</article-title>. <source hwp:id="source-43">The Journal of neuroscience: the official journal of the Society for Neuroscience</source>, <volume>34</volume>(<issue>5</issue>), <fpage>1806</fpage>â<lpage>18</lpage>.</citation></ref><ref id="c44" hwp:id="ref-44" hwp:rev-id="xref-ref-44-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.44" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-44"><string-name name-style="western" hwp:sortable="Shanks D. R."><surname>Shanks</surname>, <given-names>D. R.</given-names></string-name>, <string-name name-style="western" hwp:sortable="Tunney R. J."><surname>Tunney</surname>, <given-names>R. J.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="McCarthy J. D."><surname>McCarthy</surname>, <given-names>J. D.</given-names></string-name> (<year>2002</year>). <article-title hwp:id="article-title-37">A re-examination of probability matching and rational choice</article-title>. <source hwp:id="source-44">Journal of Behavioral Decision Making</source>, <volume>15</volume>(<issue>3</issue>), <fpage>233</fpage>â<lpage>250</lpage>.</citation></ref><ref id="c45" hwp:id="ref-45" hwp:rev-id="xref-ref-45-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.45" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-45"><string-name name-style="western" hwp:sortable="Sidman M."><surname>Sidman</surname>, <given-names>M.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Stebbins W. C."><surname>Stebbins</surname>, <given-names>W. C.</given-names></string-name> (<year>1954</year>). <article-title hwp:id="article-title-38">Satiation effects under fixed-ratio schedules of reinforcement</article-title>. <source hwp:id="source-45">Journal of Comparative and Physiological Psychology</source>, <volume>47</volume>(<issue>2</issue>), <fpage>114</fpage>.</citation></ref><ref id="c46" hwp:id="ref-46" hwp:rev-id="xref-ref-46-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.46" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-46"><string-name name-style="western" hwp:sortable="Siegel S."><surname>Siegel</surname>, <given-names>S.</given-names></string-name>, &amp; <string-name name-style="western" hwp:sortable="Goldstein D. A."><surname>Goldstein</surname>, <given-names>D. A.</given-names></string-name> (<year>1959</year>). <article-title hwp:id="article-title-39">Decision-making behavior in a two-choice uncertain outcome situation</article-title>. <source hwp:id="source-46">Journal of Experimental Psychology</source>, <volume>57</volume>(<issue>1</issue>), <fpage>37</fpage>.</citation></ref><ref id="c47" hwp:id="ref-47" hwp:rev-id="xref-ref-47-1"><citation publication-type="journal" citation-type="journal" ref:id="057208v1.47" ref:linkable="yes" ref:use-reference-as-is="yes" hwp:id="citation-47"><string-name name-style="western" hwp:sortable="Vulkan N."><surname>Vulkan</surname>, <given-names>N.</given-names></string-name> (<year>2000</year>). <article-title hwp:id="article-title-40">An economistâs perspective on probability matching</article-title>. <source hwp:id="source-47">Journal of economic surveys</source>, <volume>14</volume>(<issue>1</issue>), <fpage>101</fpage>â<lpage>118</lpage>.</citation></ref></ref-list><app-group hwp:id="app-group-1"><app id="app1" hwp:id="app-1"><label>Appendix A</label><title hwp:id="title-16">Optimal trajectory in a single dimensional outcome space</title><p hwp:id="p-63"><bold>Derivation of cost earning outcomes</bold>. The aim is to derive <xref ref-type="disp-formula" rid="eqn6" hwp:id="xref-disp-formula-6-3" hwp:rel-id="disp-formula-6">equation 6</xref> from <xref ref-type="disp-formula" rid="eqn5" hwp:id="xref-disp-formula-5-2" hwp:rel-id="disp-formula-5">equation 5</xref> under the assumption that <italic toggle="yes">k</italic> responses are required to earn one unit of the outcome.</p><p hwp:id="p-64"><italic toggle="yes">K<sub>v</sub></italic> is the cost of earning one unit of outcome at rate <italic toggle="yes">v</italic>. Earning the outcome at rate <italic toggle="yes">v</italic> implies that the time it takes to earn the outcome is 1/<italic toggle="yes">v</italic>, and since <italic toggle="yes">k</italic> responses have been executed in this period, the delay between responses is:
<disp-formula id="eqn43" hwp:id="disp-formula-43"><alternatives hwp:id="alternatives-45"><graphic xlink:href="057208_eqn43.gif" position="float" orientation="portrait" hwp:id="graphic-47"/></alternatives></disp-formula>
and therefore using <xref ref-type="disp-formula" rid="eqn5" hwp:id="xref-disp-formula-5-3" hwp:rel-id="disp-formula-5">equation 5</xref>, the cost of making one response will be <italic toggle="yes">akv</italic> + <italic toggle="yes">b</italic>. Since <italic toggle="yes">k</italic> responses are required for earning one unit of the outcome, the total cost will be <italic toggle="yes">k</italic> times the cost of one response:
<disp-formula id="eqn44" hwp:id="disp-formula-44"><alternatives hwp:id="alternatives-46"><graphic xlink:href="057208_eqn44.gif" position="float" orientation="portrait" hwp:id="graphic-48"/></alternatives></disp-formula>
which is equivalent to <xref ref-type="disp-formula" rid="eqn6" hwp:id="xref-disp-formula-6-4" hwp:rel-id="disp-formula-6">equation 6</xref>.</p><p hwp:id="p-65">In the case of non-deterministic schedules such as VR and RR schedules of reinforcement, the effect of actions on the rate of outcome earning will be non-deterministic, and therefore, the net reward (<italic toggle="yes">L</italic>) should be defined based on the expected rewards and costs:
<disp-formula id="eqn45" hwp:id="disp-formula-45" hwp:rev-id="xref-disp-formula-45-1 xref-disp-formula-45-2"><alternatives hwp:id="alternatives-47"><graphic xlink:href="057208_eqn45.gif" position="float" orientation="portrait" hwp:id="graphic-49"/></alternatives></disp-formula>
</p><p hwp:id="p-66">In the main text and in the following sections we use <italic toggle="yes">v</italic> instead of <italic toggle="yes">E</italic>[<italic toggle="yes">v</italic>] for simplicity of notation. Given this, the aim is to show that <xref ref-type="disp-formula" rid="eqn45" hwp:id="xref-disp-formula-45-1" hwp:rel-id="disp-formula-45">equation 45</xref> is equivalent to <xref ref-type="disp-formula" rid="eqn8" hwp:id="xref-disp-formula-8-1" hwp:rel-id="disp-formula-8">equation 8</xref>. The second term in <xref ref-type="disp-formula" rid="eqn45" hwp:id="xref-disp-formula-45-2" hwp:rel-id="disp-formula-45">equation 45</xref>, i.e., <italic toggle="yes">E</italic>[<italic toggle="yes">v</italic>]<italic toggle="yes">A</italic><sub><italic toggle="yes">x,t</italic></sub>, will be equivalent to <italic toggle="yes">vA<sub>x,t</sub></italic> mentioned in <xref ref-type="disp-formula" rid="eqn8" hwp:id="xref-disp-formula-8-2" hwp:rel-id="disp-formula-8">equation 8</xref>. For the first term, i.e., <italic toggle="yes">E</italic>[<italic toggle="yes">vK</italic><sub><italic toggle="yes">v</italic></sub>], we maintain that:
<disp-formula id="eqn46" hwp:id="disp-formula-46" hwp:rev-id="xref-disp-formula-46-1"><alternatives hwp:id="alternatives-48"><graphic xlink:href="057208_eqn46.gif" position="float" orientation="portrait" hwp:id="graphic-50"/></alternatives></disp-formula>
</p><p hwp:id="p-67">To show the above relation, letâs assume the subject performs <italic toggle="yes">N</italic> responses, and receives <italic toggle="yes">r</italic> outcomes. Since according to the definition of RR and VR schedules, out of <italic toggle="yes">N</italic> responses on average <italic toggle="yes">N</italic>=<italic toggle="yes">k</italic> will be rewarded, we have <italic toggle="yes">E</italic>[<italic toggle="yes">r</italic>] = <italic toggle="yes">N/k</italic> and the expected rate of outcome earning will be:
<disp-formula id="eqn47" hwp:id="disp-formula-47"><alternatives hwp:id="alternatives-49"><graphic xlink:href="057208_eqn47.gif" position="float" orientation="portrait" hwp:id="graphic-51"/></alternatives></disp-formula>
Therefore:
<disp-formula id="eqn48" hwp:id="disp-formula-48"><alternatives hwp:id="alternatives-50"><graphic xlink:href="057208_eqn48.gif" position="float" orientation="portrait" hwp:id="graphic-52"/></alternatives></disp-formula>
which proves <xref ref-type="disp-formula" rid="eqn46" hwp:id="xref-disp-formula-46-1" hwp:rel-id="disp-formula-46">equation 46</xref>.</p><p hwp:id="p-68"><bold>Fixed session duration</bold>. The aim is to derive <xref ref-type="disp-formula" rid="eqn11" hwp:id="xref-disp-formula-11-4" hwp:rel-id="disp-formula-11">equation 11</xref> and also to provide a proof for <xref ref-type="statement" rid="theorem1" hwp:id="xref-statement-1-4" hwp:rel-id="statement-1">theorem 1</xref>. By substituting <xref ref-type="disp-formula" rid="eqn8" hwp:id="xref-disp-formula-8-3" hwp:rel-id="disp-formula-8">equation 8</xref> in <xref ref-type="disp-formula" rid="eqn10" hwp:id="xref-disp-formula-10-1" hwp:rel-id="disp-formula-10">equation 10</xref> we will have:
<disp-formula id="eqn49" hwp:id="disp-formula-49" hwp:rev-id="xref-disp-formula-49-1"><alternatives hwp:id="alternatives-51"><graphic xlink:href="057208_eqn49.gif" position="float" orientation="portrait" hwp:id="graphic-53"/></alternatives></disp-formula>
The term <italic toggle="yes">dA<sub>x,t</sub></italic>/<italic toggle="yes">dt</italic> has two components: the first component is the change in <italic toggle="yes">A<sub>x,t</sub></italic> due to the change in <italic toggle="yes">x</italic> and the second component is due to the time-dependent changes in <italic toggle="yes">A<sub>x,t</sub></italic>:
<disp-formula id="eqn50" hwp:id="disp-formula-50" hwp:rev-id="xref-disp-formula-50-1"><alternatives hwp:id="alternatives-52"><graphic xlink:href="057208_eqn50.gif" position="float" orientation="portrait" hwp:id="graphic-54"/></alternatives></disp-formula>
Furthermore we have:
<disp-formula id="eqn51" hwp:id="disp-formula-51"><alternatives hwp:id="alternatives-53"><graphic xlink:href="057208_eqn51.gif" position="float" orientation="portrait" hwp:id="graphic-55"/></alternatives></disp-formula>
and similarly:
<disp-formula id="eqn52" hwp:id="disp-formula-52"><alternatives hwp:id="alternatives-54"><graphic xlink:href="057208_eqn52.gif" position="float" orientation="portrait" hwp:id="graphic-56"/></alternatives></disp-formula>
Substituting <xref ref-type="disp-formula" rid="eqn50" hwp:id="xref-disp-formula-50-1" hwp:rel-id="disp-formula-50">equations 50,51</xref> and 52 in <xref ref-type="disp-formula" rid="eqn49" hwp:id="xref-disp-formula-49-1" hwp:rel-id="disp-formula-49">equation 49</xref> yields:
<disp-formula id="eqn53" hwp:id="disp-formula-53"><alternatives hwp:id="alternatives-55"><graphic xlink:href="057208_eqn53.gif" position="float" orientation="portrait" hwp:id="graphic-57"/></alternatives></disp-formula>
which is equivalent to <xref ref-type="disp-formula" rid="eqn11" hwp:id="xref-disp-formula-11-5" hwp:rel-id="disp-formula-11">equation 11</xref>. Given <xref ref-type="disp-formula" rid="eqn2" hwp:id="xref-disp-formula-2-4" hwp:rel-id="disp-formula-2">equations 2, 7</xref> and 11 we will have:
<disp-formula id="eqn54" hwp:id="disp-formula-54"><alternatives hwp:id="alternatives-56"><graphic xlink:href="057208_eqn54.gif" position="float" orientation="portrait" hwp:id="graphic-58"/></alternatives></disp-formula>
which proves the first part of <xref ref-type="statement" rid="theorem1" hwp:id="xref-statement-1-5" hwp:rel-id="statement-1">Theorem 1</xref>. Assuming that â<italic toggle="yes">A<sub>x,t</sub></italic>/â<italic toggle="yes">t</italic> = 0, we are interested to find solutions to <xref ref-type="disp-formula" rid="eqn11" hwp:id="xref-disp-formula-11-6" hwp:rel-id="disp-formula-11">equation 11</xref> and 12. One of the solutions to <xref ref-type="disp-formula" rid="eqn11" hwp:id="xref-disp-formula-11-7" hwp:rel-id="disp-formula-11">equation 11</xref> is <italic toggle="yes">dv/dt</italic> = 0, and the other solution is:
<disp-formula id="eqn55" hwp:id="disp-formula-55"><alternatives hwp:id="alternatives-57"><graphic xlink:href="057208_eqn55.gif" position="float" orientation="portrait" hwp:id="graphic-59"/></alternatives></disp-formula>
which is inconsistent with <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-2" hwp:rel-id="disp-formula-7">equation 7</xref>, and thus the only solution is <italic toggle="yes">dv/dt</italic> = 0. Given that the rate is constant we have <italic toggle="yes">xT</italic> = <italic toggle="yes">vT</italic>, which by substituting in yields <xref ref-type="disp-formula" rid="eqn12" hwp:id="xref-disp-formula-12-1" hwp:rel-id="disp-formula-12">equation 12</xref>, <xref ref-type="disp-formula" rid="eqn13" hwp:id="xref-disp-formula-13-1" hwp:rel-id="disp-formula-13">equation 13</xref> which proves the second part of <xref ref-type="statement" rid="theorem1" hwp:id="xref-statement-1-6" hwp:rel-id="statement-1">Theorem 1</xref>.</p><p hwp:id="p-69"><bold>Uncertain session duration</bold>. Here we aim to derive the optimal trajectory when the duration of the session is probabilistic. The value function defined in <xref ref-type="disp-formula" rid="eqn17" hwp:id="xref-disp-formula-17-1" hwp:rel-id="disp-formula-17">equation 17</xref> is as follows:
<disp-formula id="eqn56" hwp:id="disp-formula-56"><alternatives hwp:id="alternatives-58"><graphic xlink:href="057208_eqn56.gif" position="float" orientation="portrait" hwp:id="graphic-60"/></alternatives></disp-formula>
where <italic toggle="yes">F<sub>T</sub></italic> is the cumulative probability distribution of <italic toggle="yes">T</italic>, and
<disp-formula id="eqn57" hwp:id="disp-formula-57"><alternatives hwp:id="alternatives-59"><graphic xlink:href="057208_eqn57.gif" position="float" orientation="portrait" hwp:id="graphic-61"/></alternatives></disp-formula>
Using the Eular-Lagrange equation, the stationary solutionfor <italic toggle="yes">S</italic>â will be:
<disp-formula id="eqn58" hwp:id="disp-formula-58"><alternatives hwp:id="alternatives-60"><graphic xlink:href="057208_eqn58.gif" position="float" orientation="portrait" hwp:id="graphic-62"/></alternatives></disp-formula>
In the next section we provide an alternative method for approximating the optimal actions under uncertain session duration.</p><p hwp:id="p-70">Expectation of session duration. The aim is to prove <xref ref-type="statement" rid="theorem2" hwp:id="xref-statement-2-2" hwp:rel-id="statement-2">Theorem 2</xref>, and also to provide the details of the simulations. Assuming that the total session duration (<italic toggle="yes">T</italic>) has the probability density function <italic toggle="yes">f(T)</italic> and that <italic toggle="yes">f(T)</italic> &gt; 0, here we show that the expectation of the session duration never decreases as time passes throughout the session. Letâs denote the expectation of the session duration at time <italic toggle="yes">t</italic>â with <italic toggle="yes">T</italic>â:
<disp-formula id="eqn59" hwp:id="disp-formula-59"><alternatives hwp:id="alternatives-61"><graphic xlink:href="057208_eqn59.gif" position="float" orientation="portrait" hwp:id="graphic-63"/></alternatives></disp-formula>
We have:
<disp-formula id="eqn60" hwp:id="disp-formula-60"><alternatives hwp:id="alternatives-62"><graphic xlink:href="057208_eqn60.gif" position="float" orientation="portrait" hwp:id="graphic-64"/></alternatives></disp-formula>
which implies that the expected duration of the session increases
as time passes.</p><p hwp:id="p-71">Next, we show that the optimal response rate is a decreasing function of <italic toggle="yes">t</italic>â. Based on <xref ref-type="disp-formula" rid="eqn12" hwp:id="xref-disp-formula-12-2" hwp:rel-id="disp-formula-12">equation 12</xref>, the optimal response rate satisfies the following equation:
<disp-formula id="eqn61" hwp:id="disp-formula-61"><alternatives hwp:id="alternatives-63"><graphic xlink:href="057208_eqn61.gif" position="float" orientation="portrait" hwp:id="graphic-65"/></alternatives></disp-formula>
Taking the derivative w.r.t to <italic toggle="yes">t</italic>â we get:
<disp-formula id="eqn62" hwp:id="disp-formula-62"><alternatives hwp:id="alternatives-64"><graphic xlink:href="057208_eqn62.gif" position="float" orientation="portrait" hwp:id="graphic-66"/></alternatives></disp-formula>
which given <xref ref-type="disp-formula" rid="eqn1" hwp:id="xref-disp-formula-1-2" hwp:rel-id="disp-formula-1">equations 1,60,7</xref>, and that <italic toggle="yes">v</italic> &gt; 0, and assuming â<italic toggle="yes">A<sub>x,t</sub></italic>/â<italic toggle="yes">T</italic>â² yields:
<disp-formula id="eqn63" hwp:id="disp-formula-63"><alternatives hwp:id="alternatives-65"><graphic xlink:href="057208_eqn63.gif" position="float" orientation="portrait" hwp:id="graphic-67"/></alternatives></disp-formula>
which implies that the rate of earning outcomes decreases as
time passes within a session.</p><p hwp:id="p-72">For the simulation of the model, following McGuire and <xref rid="c27" ref-type="bibr" hwp:id="xref-ref-27-3" hwp:rel-id="ref-27">Kable (2013)</xref> we assumed that <italic toggle="yes">T</italic> follows a Generalized Pareto distribution:
<disp-formula id="eqn64" hwp:id="disp-formula-64"><alternatives hwp:id="alternatives-66"><graphic xlink:href="057208_eqn64.gif" position="float" orientation="portrait" hwp:id="graphic-68"/></alternatives></disp-formula>
where <italic toggle="yes">k</italic> is a shape parameter and Ï is a scale parameter, and the third parameter (location Âµ) was assumed to be zero. Furthermore we have:
<disp-formula id="eqn65" hwp:id="disp-formula-65"><alternatives hwp:id="alternatives-67"><graphic xlink:href="057208_eqn65.gif" position="float" orientation="portrait" hwp:id="graphic-69"/></alternatives></disp-formula>
which has the following expected value:
<disp-formula id="eqn66" hwp:id="disp-formula-66"><alternatives hwp:id="alternatives-68"><graphic xlink:href="057208_eqn66.gif" position="float" orientation="portrait" hwp:id="graphic-70"/></alternatives></disp-formula>
which as we expect is an increasing function of <italic toggle="yes">t</italic>â. For the simulation of the model we assumed that <italic toggle="yes">k</italic> = 0:9 and Ï = 6, which represents that the initial expectation for the session duration is 60 minutes.</p></app><app id="app2" hwp:id="app-2"><label>Appendix B</label><title hwp:id="title-17">Optimal trajectory in a multi-dimension outcome space</title><p hwp:id="p-73">The aim is to derive the optimal trajectory in the outcome space when there are multiple outcomes available (<xref ref-type="disp-formula" rid="eqn23" hwp:id="xref-disp-formula-23-1" hwp:rel-id="disp-formula-23">equation 23</xref>). The net reward at each point in time will be:
<disp-formula id="eqn67" hwp:id="disp-formula-67" hwp:rev-id="xref-disp-formula-67-1"><alternatives hwp:id="alternatives-69"><graphic xlink:href="057208_eqn67.gif" position="float" orientation="portrait" hwp:id="graphic-71"/></alternatives></disp-formula>
The Eular-Lagrange equation implies:
<disp-formula id="eqn68" hwp:id="disp-formula-68"><alternatives hwp:id="alternatives-70"><graphic xlink:href="057208_eqn68.gif" position="float" orientation="portrait" hwp:id="graphic-72"/></alternatives></disp-formula>
and therefore we have:
<disp-formula id="eqn69" hwp:id="disp-formula-69" hwp:rev-id="xref-disp-formula-69-1"><alternatives hwp:id="alternatives-71"><graphic xlink:href="057208_eqn69.gif" position="float" orientation="portrait" hwp:id="graphic-73"/></alternatives></disp-formula>
For the right hand side we have:
<disp-formula id="eqn70" hwp:id="disp-formula-70"><alternatives hwp:id="alternatives-72"><graphic xlink:href="057208_eqn70.gif" position="float" orientation="portrait" hwp:id="graphic-74"/></alternatives></disp-formula>
We also have:
<disp-formula id="eqn71" hwp:id="disp-formula-71"><alternatives hwp:id="alternatives-73"><graphic xlink:href="057208_eqn71.gif" position="float" orientation="portrait" hwp:id="graphic-75"/></alternatives></disp-formula>
which by substitution into <xref ref-type="disp-formula" rid="eqn69" hwp:id="xref-disp-formula-69-1" hwp:rel-id="disp-formula-69">equation 69</xref> we get:
<disp-formula id="eqn72" hwp:id="disp-formula-72" hwp:rev-id="xref-disp-formula-72-1 xref-disp-formula-72-2"><alternatives hwp:id="alternatives-74"><graphic xlink:href="057208_eqn72.gif" position="float" orientation="portrait" hwp:id="graphic-76"/></alternatives></disp-formula>
</p><p hwp:id="p-74"><bold>Conservative reward field</bold>. The aim is to prove <xref ref-type="statement" rid="theorem3" hwp:id="xref-statement-3-2" hwp:rel-id="statement-3">Theorem 3</xref>, and also to derive <xref ref-type="disp-formula" rid="eqn37" hwp:id="xref-disp-formula-37-1" hwp:rel-id="disp-formula-37">equation 37</xref>. If the reward field is conservative, i.e., there exists a <italic toggle="yes">D</italic><sub>x</sub> such that <xref ref-type="disp-formula" rid="eqn28" hwp:id="xref-disp-formula-28-4" hwp:rel-id="disp-formula-28">equation 28</xref> holds, we have:
<disp-formula id="eqn73" hwp:id="disp-formula-73" hwp:rev-id="xref-disp-formula-73-1"><alternatives hwp:id="alternatives-75"><graphic xlink:href="057208_eqn73.gif" position="float" orientation="portrait" hwp:id="graphic-77"/></alternatives></disp-formula>
which is the consequence of the following:
<disp-formula id="eqn74" hwp:id="disp-formula-74"><alternatives hwp:id="alternatives-76"><graphic xlink:href="057208_eqn74.gif" position="float" orientation="portrait" hwp:id="graphic-78"/></alternatives></disp-formula>
where we used <xref ref-type="disp-formula" rid="eqn28" hwp:id="xref-disp-formula-28-5" hwp:rel-id="disp-formula-28">equation 28</xref> to derive the last equation. Based on <xref ref-type="disp-formula" rid="eqn73" hwp:id="xref-disp-formula-73-1" hwp:rel-id="disp-formula-73">equation 73</xref>, and assuming that, <xref ref-type="disp-formula" rid="eqn72" hwp:id="xref-disp-formula-72-1" hwp:rel-id="disp-formula-72">equation 72</xref> will be:
<disp-formula id="eqn75" hwp:id="disp-formula-75" hwp:rev-id="xref-disp-formula-75-1"><alternatives hwp:id="alternatives-77"><graphic xlink:href="057208_eqn75.gif" position="float" orientation="portrait" hwp:id="graphic-79"/></alternatives></disp-formula>
In the special condition that â<italic toggle="yes">K</italic><sub>v</sub>/âv is a diagonal matrix (i.e., <xref ref-type="disp-formula" rid="eqn25" hwp:id="xref-disp-formula-25-3" hwp:rel-id="disp-formula-25">equation 25</xref> holds), <xref ref-type="disp-formula" rid="eqn72" hwp:id="xref-disp-formula-72-2" hwp:rel-id="disp-formula-72">equation 72</xref> can be written as:
<disp-formula id="eqn76" hwp:id="disp-formula-76" hwp:rev-id="xref-disp-formula-76-1"><alternatives hwp:id="alternatives-78"><graphic xlink:href="057208_eqn76.gif" position="float" orientation="portrait" hwp:id="graphic-80"/></alternatives></disp-formula>
where â<italic toggle="yes">K</italic><sub>v</sub>/âv is a vector representing the diagonal terms of the matrix. For the derivation of the above equation we used the following relations:
<disp-formula id="eqn77" hwp:id="disp-formula-77"><alternatives hwp:id="alternatives-79"><graphic xlink:href="057208_eqn77.gif" position="float" orientation="portrait" hwp:id="graphic-81"/></alternatives></disp-formula>
and:
<disp-formula id="eqn78" hwp:id="disp-formula-78"><alternatives hwp:id="alternatives-80"><graphic xlink:href="057208_eqn78.gif" position="float" orientation="portrait" hwp:id="graphic-82"/></alternatives></disp-formula>
</p><p hwp:id="p-75">Given <xref ref-type="disp-formula" rid="eqn7" hwp:id="xref-disp-formula-7-3" hwp:rel-id="disp-formula-7">equation 7</xref> the only admissible solution to <xref ref-type="disp-formula" rid="eqn76" hwp:id="xref-disp-formula-76-1" hwp:rel-id="disp-formula-76">equation 76</xref> is <italic toggle="yes">dv/dt</italic> = 0, which shows that the optimal rate of earning outcomes is constant. By substituting <xref ref-type="disp-formula" rid="eqn67" hwp:id="xref-disp-formula-67-1" hwp:rel-id="disp-formula-67">equation 67</xref> in the boundary conditions implied by <xref ref-type="disp-formula" rid="eqn24" hwp:id="xref-disp-formula-24-1" hwp:rel-id="disp-formula-24">equation 24</xref> we get <xref ref-type="disp-formula" rid="eqn29" hwp:id="xref-disp-formula-29-1" hwp:rel-id="disp-formula-29">equation 29</xref>.</p><p hwp:id="p-76">If â<italic toggle="yes">K</italic><sub>v</sub>/âv is not diagonal, and it is equivalent to the cost function shown in <xref ref-type="disp-formula" rid="eqn36" hwp:id="xref-disp-formula-36-1" hwp:rel-id="disp-formula-36">equation 36</xref>, then the Lagrangian (<italic toggle="yes">L</italic>) will be as follows:
<disp-formula id="eqn79" hwp:id="disp-formula-79"><alternatives hwp:id="alternatives-81"><graphic xlink:href="057208_eqn79.gif" position="float" orientation="portrait" hwp:id="graphic-83"/></alternatives></disp-formula>
Using <xref ref-type="disp-formula" rid="eqn75" hwp:id="xref-disp-formula-75-1" hwp:rel-id="disp-formula-75">equation 75</xref> we have:
<disp-formula id="eqn80" hwp:id="disp-formula-80"><alternatives hwp:id="alternatives-82"><graphic xlink:href="057208_eqn80.gif" position="float" orientation="portrait" hwp:id="graphic-84"/></alternatives></disp-formula>
implying that
<disp-formula id="eqn81" hwp:id="disp-formula-81"><alternatives hwp:id="alternatives-83"><graphic xlink:href="057208_eqn81.gif" position="float" orientation="portrait" hwp:id="graphic-85"/></alternatives></disp-formula>
where Î² is a constant. Using boundary conditions in <xref ref-type="disp-formula" rid="eqn24" hwp:id="xref-disp-formula-24-2" hwp:rel-id="disp-formula-24">equation 24</xref> we get at time <italic toggle="yes">T</italic>:
<disp-formula id="eqn82" hwp:id="disp-formula-82"><alternatives hwp:id="alternatives-84"><graphic xlink:href="057208_eqn82.gif" position="float" orientation="portrait" hwp:id="graphic-86"/></alternatives></disp-formula>
</p><p hwp:id="p-77">Given <xref ref-type="disp-formula" rid="eqn32" hwp:id="xref-disp-formula-32-1" hwp:rel-id="disp-formula-32">equation 32</xref> and assuming that <italic toggle="yes">l</italic> â  1 the only solution to the above equation is Î² = 0, which entails that <italic toggle="yes">v</italic><sub>1</sub> = â<italic toggle="yes">v</italic><sub>2</sub>, which given the constrain that <italic toggle="yes">v</italic><sub>1</sub> â¥ 0 and <italic toggle="yes">v</italic><sub>2</sub> â¥ 0 is not an admissible solution. Assuming that v1 takes the boundary value v1 = 0, the problem degenerates into a problem involving only one outcome (since <italic toggle="yes">v</italic><sub>1</sub> = 0) which can be solved using <xref ref-type="statement" rid="theorem1" hwp:id="xref-statement-1-7" hwp:rel-id="statement-1">Theorem 1</xref>. Solving <xref ref-type="disp-formula" rid="eqn13" hwp:id="xref-disp-formula-13-2" hwp:rel-id="disp-formula-13">equation 13</xref>, assuming <italic toggle="yes">b</italic> = 0 and <italic toggle="yes">m</italic> = 2<italic toggle="yes">ak</italic><sup>2</sup>, yields <xref ref-type="disp-formula" rid="eqn37" hwp:id="xref-disp-formula-37-2" hwp:rel-id="disp-formula-37">equation 37</xref>.</p><p hwp:id="p-78"><bold>Non-conservative reward field</bold>. The aim is to prove <xref ref-type="statement" rid="theorem4" hwp:id="xref-statement-4-3" hwp:rel-id="statement-4">Theorem 4</xref>. We have:
<disp-formula id="eqn83" hwp:id="disp-formula-83"><alternatives hwp:id="alternatives-85"><graphic xlink:href="057208_eqn83.gif" position="float" orientation="portrait" hwp:id="graphic-87"/></alternatives></disp-formula>
and based on <xref ref-type="disp-formula" rid="eqn26" hwp:id="xref-disp-formula-26-2" hwp:rel-id="disp-formula-26">equation 26</xref> we get:
<disp-formula id="eqn84" hwp:id="disp-formula-84"><alternatives hwp:id="alternatives-86"><graphic xlink:href="057208_eqn84.gif" position="float" orientation="portrait" hwp:id="graphic-88"/></alternatives></disp-formula>
Defining <italic toggle="yes">w</italic> = (<italic toggle="yes">l</italic> â 1)/<italic toggle="yes">m</italic>, the solution to the above set of differential equations has the form:
<disp-formula id="eqn85" hwp:id="disp-formula-85" hwp:rev-id="xref-disp-formula-85-1 xref-disp-formula-85-2"><alternatives hwp:id="alternatives-87"><graphic xlink:href="057208_eqn85.gif" position="float" orientation="portrait" hwp:id="graphic-89"/></alternatives></disp-formula>
which is an arc of a circle centered at [<italic toggle="yes">q</italic><sub>1</sub>; <italic toggle="yes">q</italic><sub>2</sub>], and <italic toggle="yes">r</italic> and <italic toggle="yes">Î±</italic> are free parameters. The parameters can be determined using the boundary condition imposed by <xref ref-type="disp-formula" rid="eqn24" hwp:id="xref-disp-formula-24-3" hwp:rel-id="disp-formula-24">equation 24</xref>, and also assuming that the initial position is <bold>x</bold> = 0. The boundary condition in <xref ref-type="disp-formula" rid="eqn24" hwp:id="xref-disp-formula-24-4" hwp:rel-id="disp-formula-24">equation 24</xref> implies:
<disp-formula id="eqn86" hwp:id="disp-formula-86"><alternatives hwp:id="alternatives-88"><graphic xlink:href="057208_eqn86.gif" position="float" orientation="portrait" hwp:id="graphic-90"/></alternatives></disp-formula>
which implies that at the end of the trajectory the rate of earning the second outcome is <italic toggle="yes">l</italic> times larger than the first outcome. Therefore, the general from of the trajectory will be an arc starting from the origin and ending along the above direction. Given the constrain that <italic toggle="yes">v</italic> â¥ 0 only the solutions in which <italic toggle="yes">q</italic><sub>2</sub> â¤ 0 are acceptable ones (i.e., the center of the circle is below the x-axis). Solving <xref ref-type="disp-formula" rid="eqn85" hwp:id="xref-disp-formula-85-1" hwp:rel-id="disp-formula-85">equation 85</xref> for <italic toggle="yes">q</italic><sub>2</sub> â¤ 0 we get:
<disp-formula id="eqn87" hwp:id="disp-formula-87" hwp:rev-id="xref-disp-formula-87-1 xref-disp-formula-87-2"><alternatives hwp:id="alternatives-89"><graphic xlink:href="057208_eqn87.gif" position="float" orientation="portrait" hwp:id="graphic-91"/></alternatives></disp-formula>
where
<disp-formula id="eqn88" hwp:id="disp-formula-88"><alternatives hwp:id="alternatives-90"><graphic xlink:href="057208_eqn88.gif" position="float" orientation="portrait" hwp:id="graphic-92"/></alternatives></disp-formula>
and therefore <italic toggle="yes">T<sub>c</sub></italic> is independent of <italic toggle="yes">H</italic> (the initial motivational drive). As such if <italic toggle="yes">T</italic> satisfies <xref ref-type="disp-formula" rid="eqn87" hwp:id="xref-disp-formula-87-1" hwp:rel-id="disp-formula-87">equation 87</xref> then the optimal trajectory will be an arc of a circle starting from the origin. Otherwise, if <italic toggle="yes">T</italic> &gt; <italic toggle="yes">T<sub>c</sub></italic>, the optimal trajectory will be composed of two segments. In the first segment, <italic toggle="yes">v</italic><sub>1</sub> will take the boundary condition <italic toggle="yes">v</italic><sub>1</sub> = 0 and the decision-maker earns only the second outcome (the outcome with the higher reward effect). The first segment continues until the remaining time in the session satisfies <xref ref-type="disp-formula" rid="eqn87" hwp:id="xref-disp-formula-87-2" hwp:rel-id="disp-formula-87">equation 87</xref> (the remaining time is less than <italic toggle="yes">T<sub>c</sub></italic>), after which the second segment starts, which is an arc of a circle defined by <xref ref-type="disp-formula" rid="eqn85" hwp:id="xref-disp-formula-85-2" hwp:rel-id="disp-formula-85">equation 85</xref>. The rate of earning the second outcome, <italic toggle="yes">v</italic><sub>2</sub>, in the first segment of the trajectory (when <italic toggle="yes">v</italic><sub>1</sub> = 0) can be obtained by calculating the rates at the beginning of the circular segment. The initial rate at the start of the circular segment is as follows:
<disp-formula id="eqn89" hwp:id="disp-formula-89"><alternatives hwp:id="alternatives-91"><graphic xlink:href="057208_eqn89.gif" position="float" orientation="portrait" hwp:id="graphic-93"/></alternatives></disp-formula>
which implies that at the first segment of the trajectory we have:
<disp-formula id="eqn90" hwp:id="disp-formula-90"><alternatives hwp:id="alternatives-92"><graphic xlink:href="057208_eqn90.gif" position="float" orientation="portrait" hwp:id="graphic-94"/></alternatives></disp-formula>
which completes the proof of <xref ref-type="statement" rid="theorem4" hwp:id="xref-statement-4-4" hwp:rel-id="statement-4">Theorem 4</xref>.</p></app></app-group><fn-group hwp:id="fn-group-1"><fn id="fn1" hwp:id="fn-3" hwp:rev-id="xref-fn-3-1"><label>1</label><p hwp:id="p-79">In <xref ref-type="disp-formula" rid="eqn14" hwp:id="xref-disp-formula-14-5" hwp:rel-id="disp-formula-14">equation 14</xref> the optimal outcome rate is dependent on the initial drive (<italic toggle="yes">H</italic>) and the session duration (<italic toggle="yes">T</italic>), and therefore one might intuitively think that if for example half-way through the session the decision-maker re-calculates the optimal rate using <xref ref-type="disp-formula" rid="eqn14" hwp:id="xref-disp-formula-14-6" hwp:rel-id="disp-formula-14">equation 14</xref>, then it will get a different constant rate than the one it got initially at the beginning of the session, as <italic toggle="yes">H</italic> and <italic toggle="yes">T</italic> will be different from the ones at the start of the session. This argument, however, is not correct, and under the optimal rate, the motivational drive and the remaining time in the session change in opposite directions, in a way that the optimal rate remains invariant throughout the session, irrespective of what time in the session <xref ref-type="disp-formula" rid="eqn14" hwp:id="xref-disp-formula-14-7" hwp:rel-id="disp-formula-14">equation 14</xref> is calculated.</p></fn><fn id="fn2" hwp:id="fn-4" hwp:rev-id="xref-fn-4-1"><label>2</label><p hwp:id="p-80">Note that in the original notation in <xref rid="c23" ref-type="bibr" hwp:id="xref-ref-23-2" hwp:rel-id="ref-23">Killeen and Sitomer (2003)</xref>, <italic toggle="yes">Î±</italic> is denoted by <italic toggle="yes">a</italic> and Î² is denoted by <italic toggle="yes">b</italic>.</p></fn><fn id="fn3" hwp:id="fn-5" hwp:rev-id="xref-fn-5-1"><label>3</label><p hwp:id="p-81">It is interesting to note that <xref ref-type="disp-formula" rid="eqn27" hwp:id="xref-disp-formula-27-3" hwp:rel-id="disp-formula-27">equation 27</xref> in fact lays out the motion of a unit charged particle (negatively charged) with mass m in a magnetic field with magnitude <bold>B</bold>.</p></fn></fn-group></back></article>
