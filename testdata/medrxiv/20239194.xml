<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MEDRXIV</journal-id>
<journal-title-group>
<journal-title>medRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">medRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/2020.12.02.20239194</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Emergency Medicine</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Identifying those at risk of reattendance at discharge from emergency departments using explainable machine learning</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-0674-8098</contrib-id>
<name><surname>Chmiel</surname><given-names>F. P.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="author-notes" rid="n1">&#x002A;</xref>
<xref ref-type="corresp" rid="cor1">&#x0023;</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Azor</surname><given-names>M.</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Borca</surname><given-names>F.</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-9281-6095</contrib-id>
<name><surname>Boniface</surname><given-names>M. J.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-6976-1068</contrib-id>
<name><surname>Burns</surname><given-names>D. K.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Zlatev</surname><given-names>Z. D.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>White</surname><given-names>N. M.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-5249-5100</contrib-id>
<name><surname>Daniels</surname><given-names>T. W. V.</given-names></name>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Kiuber</surname><given-names>M.</given-names></name>
<xref ref-type="aff" rid="a6">6</xref>
</contrib>
<aff id="a1"><label>1</label><institution>School of Electronics and Computer Science, University of Southampton</institution>, <country>UK</country></aff>
<aff id="a2"><label>2</label><institution>University Hospitals Southampton NHS Foundation Trust</institution>, Southampton, <country>UK</country></aff>
<aff id="a3"><label>3</label><institution>Clinical Informatics Research Unit Faculty of Medicine, University of Southampton</institution>, Southampton, <country>UK</country></aff>
<aff id="a4"><label>4</label><institution>Department of Respiratory Medicine, Minerva House, University Hospital Southampton</institution>, <country>UK</country></aff>
<aff id="a5"><label>5</label><institution>School of Clinical and Experimental Sciences, Faculty of Medicine, University of Southampton, Southampton General Hospital, LF13A, South Academic Block</institution>, Southampton, <country>UK</country></aff>
<aff id="a6"><label>6</label><institution>Emergency Department, University Hospital Southampton NHS Foundation Trust</institution>, Southampton, <country>UK</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x0023;</label>Corresponding author; email: <email>f.p.chmiel@soton.ac.uk</email></corresp>
<fn id="n1"><label>&#x002A;</label><p><email>F.P.Chmiel@soton.ac.uk</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2020</year>
</pub-date>
<elocation-id>2020.12.02.20239194</elocation-id>
<history>
<date date-type="received">
<day>02</day>
<month>12</month>
<year>2020</year>
</date>
<date date-type="rev-recd">
<day>02</day>
<month>12</month>
<year>2020</year>
</date>
<date date-type="accepted">
<day>04</day>
<month>12</month>
<year>2020</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2020, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2020</copyright-year>
<license><license-p>The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.</license-p></license>
</permissions>
<self-uri xlink:href="20239194.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>ABSTRACT</title>
<p>Short-term reattendances to emergency departments are a key quality of care indicator. Identifying patients at increased risk of early reattendance can help reduce the number of patients with missed or undertreated illness or injury, and could support appropriate discharges with focused interventions. In this manuscript we present a retrospective, single-centre study where we create and evaluate a machine-learnt classifier trained to identify patients at risk of reattendance within 72 hours of discharge from an emergency department. On a patient hold-out test set, our highest performing classifier obtained an AUROC of 0.748 and an average precision of 0.250; demonstrating that machine-learning algorithms can be used to classify patients, with moderate performance, into low and high-risk groups for reattendance. In parallel to our predictive model we train an explanation model, capable of explaining predictions at an attendance level, which can be used to help inform the design of interventional strategies.</p>
</abstract>
<counts>
<page-count count="10"/>
</counts>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<notes notes-type="financial-disclosure">
<title>Funding Statement</title><p>This work was supported by The Alan Turing Institute under the EPSRC grant EP/N510129/1. We acknowledge support from the NIHR Wessex ARC.</p></notes>
<notes notes-type="disclosures">
<title>Author Declarations</title><p>I confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.</p><p>Yes</p><p>The details of the IRB/oversight body that provided approval or exemption for the research described are given below:</p><p>This work received ethics approval from the University of Southampton's Faculty of Engineering and Physical Science Research Ethics Committee (ERGO/FEPS/53164). Approval was also obtained from the NHS Health Research authority (20/HRA/1102, IRAS project ID 275577).</p><p>All necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived.</p><p>Yes</p><p>I understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).</p><p>Yes</p><p>I have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.</p><p>Yes</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>The demand for emergency departments (EDs) has been growing steadily over the last decade<sup><xref rid="c1" ref-type="bibr">1</xref>,<xref rid="c2" ref-type="bibr">2</xref></sup>, which in turn has contributed to increased overcrowding and extended waiting times. Since delays in care and overcrowding have been linked to increased rates of adverse outcomes<sup><xref rid="c3" ref-type="bibr">3</xref>,<xref rid="c4" ref-type="bibr">4</xref></sup>, it is important to investigate the most efficient ways of using the available resources and, importantly, minimise and mitigate their unnecessary use. Short-term reattendances describe the situation whereby a patient attends an emergency department (ED) within 72 hours of having been discharged. This reattendance rate will include patients with missed or undertreated illness, attendance with a new injury/illness, as well as scheduled reattendance for clinical review following an injury. Focused interventions could reduce inappropriate discharges as well as support patients at home, reducing subsequent reattendance.</p>
<p>Research has shown there are several factors indicative of short-term reattendance risk including social factors (e.g., living alone)<sup><xref rid="c5" ref-type="bibr">5</xref></sup>, depression<sup><xref rid="c6" ref-type="bibr">6</xref></sup>, initial diagnosis<sup><xref rid="c7" ref-type="bibr">7</xref></sup>, and historical emergency department usage<sup><xref rid="c8" ref-type="bibr">8</xref></sup>. Knowledge of these risk factors is important to clinical staff when planning discharge, but this is unlikely the most optimal way of determining those at risk of suffering from a significant illness following erroneous discharge or those in need of additional support in the community following discharge from an ED. Predictive models, available as a decision support tool at the point of discharge, able to reliably identify those at increased risk of short-term reattendance using known risk factors and attendance level information, may be able to significantly reduce the number of reattendances by appropriately quantifying and explaining a patient&#x2019;s risk of reattendance to clinical staff. Ultimately this would allow appropriate focussed interventions (e.g., further diagnostic tests), more informed discussions about a patients discharge plan, or support in the community for those recently discharged.</p>
<p>Machine learnt models are a class of predictive models which are particularly well positioned to add value to emergency department processes. By making use of large amounts of clinical and administrative data, these models can provide estimates of a patient&#x2019;s short-term reattendance risk<sup><xref rid="c9" ref-type="bibr">9</xref>,<xref rid="c10" ref-type="bibr">10</xref></sup>and explain the reason for the patient&#x2019;s predicted risk. Explanation is particularly important, as this could help either inform the patient care trajectory or guide the post-discharge intervention plan. In this manuscript we discuss a machine-learnt model, utilizing data extracted from historical (coded, inpatient) discharge summaries, alongside contemporary attendance recorded clinical data such as observations and results of standard triage processes, to identify patients at increased risk of short-term reattendance following an emergency department attendance. In addition to our predictive model, we construct an explanation model which allow us to evaluate the trends our model has learned and explain our model&#x2019;s prediction at an attendance level.</p>
</sec>
<sec id="s2">
<title>Methods</title>
<sec id="s2a">
<title>Dataset curation</title>
<p>The dataset features a pseudonymized version of all attendances by adults to Southampton&#x2019;s Emergency Department (University Hospitals Southampton Foundation Trust) occurring between the 1st April 2019 and the 30th of April 2020. For our study cohort, we take only attendances which resulted in discharge directly from the ED, of which there were 54,021. The core dataset includes patients&#x2019; year of birth, results of any near-patient observations recorded, and high-level information about the attendance included in the standard UK Emergency Care Data Set (ECDS, which maps to SNOMED CT diagnostic codes). The data was prospectively digitally recorded within the ED electronic patient record (EMIS Symphony). To provide the machine learning classifier with a view of patients&#x2019; medical history we make use of historical discharge summaries associated with the patient, both from the emergency department and from the patients electronic health record maintained by the University Hospitals Southampton Foundation Trust. For a given patient, from any discharge summary occurring prior to a given emergency department attendance, we make use of ICD10 coded conditions (e.g., type 2 diabetes, current smoker) and create a binary indicator which indicates whether a patient has a given condition coded in their electronic health record prior to a given ED attendance. The electronic health records used by our models are available to review by clinicians and are used in regular practice. Our model does not have access to any free text fields in the electronic health record. Previous studies have shown that (free text) clinical notes can be predictive of patient outcomes across the broader hospital network<sup><xref rid="c11" ref-type="bibr">11</xref>,<xref rid="c12" ref-type="bibr">12</xref></sup>, but including these notes was beyond the scope of our study as they would limit the explainability of our algorithms. An example of the most frequently observed conditions are presented in <xref rid="tbl1" ref-type="table">Table 1</xref>.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Most frequently occurring ICD10 codes for attendances in the training set.</title>
<p>The left column denotes the noted conditions (as specified by ICD10 codes) and the right column the number of attendances in the training set noted to have this condition. A given condition is only associated with a small fraction of attendances, but in total 38.9 &#x0025; of attendances resulting in discharge have at least one associated condition. Conditions are generated by extracting from the (ICD10) coded discharge sumaaries held in a patients electronic health record.</p></caption>
<graphic xlink:href="20239194v1_tbl1.tif"/>
</table-wrap>
</sec>
<sec id="s2b">
<title>Reattendance identification</title>
<p>Patient reattendances are identified by using the patient pseudo identifier to calculate the time to their next ED attendance. Importantly, all reattendances are considered, even if the second attendance is for a different condition to the original attendance (see Supplementary Figure 2 for further details). This is then dichotomized (less than 72 hours) to annotate each attendance with whether the discharge was followed by another attendance by the same patient within 72 hours. This formulation allowed us to frame the predictive task as a binary classification problem.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Segregation of the study data into training and the two hold-out test sets.</title>
<p>Discarded attendances were those that occurred in either the first 30 days or last 72 hours of the temporal test, to avoid information leakage between the training and temporal test set and because the reattendance status could not be robustly calculated for attendances occurring in the last 72 hours of the dataset. Reattendance rates (bottom row of shaded boxes) display the observed 72-hour reattendance rate for each cohort.</p></caption>
<graphic xlink:href="20239194v1_fig1.tif"/>
</fig>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Performance of our classifier (model p in <xref rid="tbl2" ref-type="table">Table 2</xref>) evaluated on the patient hold-out test set.</title>
<p>a) Receiving operator curve for model&#x2019;s prediction. b) Precision recall curve for predictions on test set, the dashed grey line shows the configuration evaluated in the confusion matrix in panel c. c) Confusion matrix for predictions dichotomized using a threshold chosen such that the recall is equal to 0.15 (dashed grey line in panel b). A class of &#x2018;1&#x2019; indicates the patient reattended the emergency department within 72 hours of discharge. Diagonal elements represent correct classifications and off-diagonal elemements either False positives or negatives.</p></caption>
<graphic xlink:href="20239194v1_fig2.tif"/>
</fig>
</sec>
<sec id="s2c">
<title>Predictive modelling</title>
<p>We separated our data into a training set and two independent test sets (<xref rid="fig1" ref-type="fig">Figure 1</xref>). The last 3 months of attendances (01/02/2020 to 30/04/2020, inclusive of the COVID-19 pandemic) were segregated as a temporal test set, excluding any visit which took part in either the first 30 days or the final 72 hours. These exclusions remove information leakage between the training and temporal test set and attendances where reattendance to the emergency department could not be calculated reliably (i.e., those occuring in the last 72 hours of the data extract). The remaining attendances (N=44,857) were randomly split at the patient level to create a patient-level hold test set containing attendances from 20 &#x0025; of the remaining patients. Remaining attendances (N=35,645) were used as the training and validation set. The number of patients in each respective dataset was 4,458, 7,238, and 28,951. The relation between patients in each dataset is displayed in Supplementary Figure 1, demonstrating patient exclusivity between the training set and the patient hold-out test set. The temporal test set is discussed in the Supplementary Information only.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>Performance on the validation set for models using individual features (models a-n) and sets of features (models o and p).</title>
<p>Metrics are evaluated on the training set using grouped 5-fold CV at the patient level and we report the mean of the metric across the five validation folds. All models hyperparameters were tuned as described in the methods section to optimize the CV AUROC.</p></caption>
<graphic xlink:href="20239194v1_tbl2.tif"/>
</table-wrap>
<p>As our machine-learnt classifier, we used a gradient boosted decision tree as implemented in the XGBoost framework<sup><xref rid="c16" ref-type="bibr">16</xref></sup>. Features used in modelling include : patient age (estimated from year of birth), number of emergency department attendances in the 30 days prior to the attendance, the chief complaint of the attendance (e.g., &#x2018;abdominal pain&#x2019;), the patients mode of arrival, previously described medical condition indicators, the count of the number of medical conditions a patient has, vital signs (temperature, pulse and respiration rate, systolic blood pressure, and blood oxygen saturation levels), the Manchester Triage System score, triage pain score, (coded) discharge diagnosis, and the hour of day and day of the week the attendance occurred. A full data schema is presented in Supplementary Table 1. Medical conditions associated with the patient at a given attendance were included as a one-hot-encoded feature vector, the day of the week encoded using ordinal encoding, and all other categorical variables were encoded using target encoding<sup><xref rid="c13" ref-type="bibr">13</xref></sup>. Hyperparameters were tuning using five-fold cross-validation (CV) of the training set at the patient level (the set of attendances from a unique patient appear exclusively in validation or training for each fold) using Bayesian optimization utilizing the Tree Parzen Estimator algorithm as implemented in the hyperopt Python library<sup><xref rid="c14" ref-type="bibr">14</xref>,<xref rid="c15" ref-type="bibr">15</xref></sup>. Feature selection was performed using a greedy, sequential forward selection approach. Starting with the single most predictive variable (as determined by the CV score of a model trained with a single variable only) we added another variable to the feature set, where the variable added selected was the one which increased the CV score by the largest amount. We sequentially added variables to the feature set in this manner until all variables were included in the feature set. The optimal feature set for our final model was selected by the set that yielded the highest CV score (Supplementary Table 2).</p>
<p>We evaluate our final model performance (the average output of the five models trained during cross-validation) on the two hold-out test sets. Models performance is evaluated using the Area Under the Receiving Operating Curve (AUROC) and the average precision under the precision-recall curve.</p>
</sec>
<sec id="s2d">
<title>Model explainability</title>
<p>To explain the predictions of our model we make use of the TreeExplainer algorithm in the SHAP Python library<sup><xref rid="c17" ref-type="bibr">17</xref>&#x2013;<xref rid="c19" ref-type="bibr">19</xref></sup>. TreeExplainer calculates SHAP values (i.e, Shapley values), a concept from coalitional game theory which treats predictive variables as players in a game and distributes their contribution to the predicted probability. To calculate the SHAP value for a given feature, one trains a model for each possible feature set (with and without the given feature) and calculates the mean change in the predicted probability when the feature was added to a feature set for all possible sets of features. This mean change is the SHAP value and can be negative (adding the feature predicted reduces reattendance risk) or positive (adding the feature increases the predicted reattendance risk). SHAP values are particularly powerful as they meet the four desirable theoretical conditions of an explanation algorithm and can provide instance (i.e., attendance) level explanations<sup><xref rid="c19" ref-type="bibr">19</xref></sup>. Practically, for each attendance we will have a scalar value for each variable used in the model which quantifies the contribution that variable had on the predicted reattendance risk for the given attendance, with SHAP values of larger magnitudes indicating that the relevant variable was more significant in determining the predicted reattendance risk.</p>
<p>To investigate the different explanations across the whole dataset, we project the SHAP values for all attendances into a two-dimensional (&#x2018;explanation&#x2019;) space using Uniform Manifold Approximation and Projection (UMAP)<sup><xref rid="c20" ref-type="bibr">20</xref></sup>. UMAP is a dimensionality reduction technique regularly used to visualise high-dimensional spaces in a low-dimensional embedding, such that global and local structure of the space can be explored<sup><xref rid="c21" ref-type="bibr">21</xref>,<xref rid="c22" ref-type="bibr">22</xref></sup>. Attendances which are closer in proximity in this two-dimensional space share a similar explanation for their predicted reattendance risk.</p>
</sec>
<sec id="s2e">
<title>Ethics and data governance</title>
<p>This study was approved by the University of Southampton&#x2019;s Ethics and Research governance committee (ERGO/FEPS/53164) and approval was obtained from the Health Research Authority (20/HRA/1102). Data was pseudonymized (and where appropriate linked) before being passed to the research team. The research team did not have access to the pseudonymisation key.</p>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<p>To investigate the potential of individual variables and sets of variables at predicting 72-hour reattendance we constructed a series of XGBoost models, evaluating their performance on the training set using five cross-validation as described in the Methods section, the results of this experiment are displayed in <xref rid="tbl2" ref-type="table">Table 2</xref>.</p>
<p>Seven variables (vital signs, age, Manchester Triage System score, pain score, hour of day, arrival model, and discriminator at triage) were found to be only weakly predictive of a patient&#x2019;s 72-hour reattendance risk in isolation (AUROCs between 0.5 and 0.6, <xref rid="tbl2" ref-type="table">Table 2</xref> models b-h). All other variables (<xref rid="tbl2" ref-type="table">Table 2</xref> models h-m) were found to be moderately predictive (AUROC between 0.6 and 0.70) of 72-hour reattendance risk in isolation, with the exception of the day of the week the attendance occurred, which was not predictive of outcome (model a, <xref rid="tbl2" ref-type="table">Table 2</xref>).</p>
<p>Patients condition&#x2019;s were included in two representations. The count of the number of historical conditions (model m, <xref rid="tbl2" ref-type="table">Table 2</xref>) obtained a validation AUROC of 0.658, reflecting that those with a listed condition (and therefore a historical inpatient admission) are more likely to reattend (8.8 &#x0025; (95 &#x0025; CI: 8.4-9.3 &#x0025;) reattendance rate) than those who do not (3.1 &#x0025; (95 &#x0025; CI: 2.8-3.3&#x0025;) reattendance rate). When we included the full one-hot encoded matrix denoting whether the patient had a history of the given condition, our model (model n, <xref rid="tbl2" ref-type="table">Table 2</xref>) obtained a validation AUROC of 0.671 &#x2013;higher than when our model used just the number of historical conditions. This indicates that different (medical) conditions are associated with a differing degree of reattendance risk.</p>
<p>The model that used the patient&#x2019;s ED 30-day visit count (<xref rid="tbl2" ref-type="table">Table 2</xref>, model i) exhibited a validation AUROC of 0.644, agreeing with other studies that previous emergency department usage is an important consideration when considering a patient&#x2019;s reattendance risk<sup><xref rid="c8" ref-type="bibr">8</xref></sup>. Three models (models k, j, and l, <xref rid="tbl2" ref-type="table">Table 2</xref>) make use of coded information describing the reason for the emergency department attendance, collected at three timepoints and by potentially different members of clinical and non-clinical staff. Making use of the chief complaint, collected at either the point of registration or Triage, respective validation AUROCs of 0.651 and 0.645 could be achieved. At the point of discharge, the recorded coded diagnosis obtained a validation AUROC of 0.650. This demonstrates that different diagnoses are associated with differing degrees of reattendance risk and indicates that a high-level, coded description of the patient&#x2019;s chief complaint is moderately predictive of reattendance risk, regardless of when it is recorded during the visit.</p>
<p>Finally, we investigated models using larger feature sets combining variables (models o and p in <xref rid="tbl2" ref-type="table">Table 2</xref>). Firstly, we trained a model using only the three variables which were most predictive in unison, as determined by our greedy feed forward feature selection process (see Methods and Supplementary Table 2). This model (model o in <xref rid="tbl2" ref-type="table">Table 2</xref>) used just the condition indicators, the chief complaint recorded at triage, and the number of times the patient visited the ED in the previous 30 days. Ultimately, it obtained a validation AUROC of 0.742, demonstrating that using multiple variables is more predictive of reattendance than a single variable. We also evaluated our highest performing model, as determined by our feature selection process, which used eight more of the available variables (diagnosis, condition count, hour of day, Manchester Triage Score, arrival mode, week day, triage discriminator and age). Despite using several more variables, the model&#x2019;s validation AUROC only increased to 0.753.</p>
<p>Next, we applied our final model (model p, <xref rid="tbl2" ref-type="table">Table 2</xref>) on the patient wise hold-out test set, the evaluation of which is presented in <xref rid="fig2" ref-type="fig">Figure 2</xref>. The AUROC and average precision was 0.748 and 0.250, indicating that model generalized well to samples not in the training set, maintaining its moderate performance. To demonstrate the evaluation of our model as a binary decision support tool, we display a confusion matrix for our classifier at a single configuration in <xref rid="fig2" ref-type="fig">Figure 2c</xref>. The threshold for dichotomization of the predictions was chosen such that a recall of 0.15 was obtained.</p>
<p>To investigate what our model has learned we made use of the TreeExplainer algorithm<sup><xref rid="c18" ref-type="bibr">18</xref></sup>; a demonstration of the global explanation of our reattendance model is presented in <xref rid="fig3" ref-type="fig">Figure 3</xref>. In <xref rid="fig3" ref-type="fig">Figure 3a</xref> the SHAP values (which quantify, at an instance level, the impact a given variable has on the model&#x2019;s prediction) for 10 variables are shown for each attendance (circular markers). Looking at this plot for a large number of variables allows a high level understanding of the model to be obtained: the model associates anyone with a recorded medical condition as being at increased risk of reattendance and learns that some medical conditions represent a greater reattendance risk than others, for example living alone is often associated with a higher reattendance risk than having a history of depression (last two rows of <xref rid="fig3" ref-type="fig">Figure 3a</xref>, the mean SHAP value is greater for those who live alone). In panels b and c of <xref rid="fig3" ref-type="fig">Figure 3</xref>, we plot the same information for two features (hour of day attendance occurred and 30 day visit count respectively) but in a 2D plane which allows better insight into the dependence of these variables on a patient&#x2019;s reattendance risk. The model has learned that the patient&#x2019;s risk of reattendance displays a periodic dependence (<xref rid="fig3" ref-type="fig">Figure 3b</xref>) with the hour of day the attendance occurred (vertical dispersion is the result of interactions with other variables in the dataset) and it has also learned an approximately linear dependence between a patient&#x2019;s reattendance risk and the number of times they have attended the emergency department in the last 30 days (<xref rid="fig3" ref-type="fig">Figure 3c</xref>). It is important to note that these insights do not necessarily reflect the actual risk factors for reattendance (since the model is an imperfect classifier) but only explain the trends the model has learned to make its decisions.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Explanations of model predictions using SHAP for each attendance in the patient hold-out test set.</title>
<p>a) Plot summarizing the SHAP values for ten variables for each patient in the patient test set. They are ordered by the global impact the feature has on the explanation (practically, equal to the mean absolute SHAP value of the feature across all attendances). For the binary variables (i.e., the condition indicators) this favours variables with a high number of occurrences (i.e., more common conditions), not necessarily those which have the highest reattendance risk. b) SHAP value against recorded hour of day for time of registration for a given attendance (dots). c) SHAP value against number of emergency department visits in the 30 days prior to the given attendance (dots). In panels b and c vertical dispersion is the result of interaction with other variables in the feature set. All panels are coloured by the magnitude of the respective variable for the given data point, with lighter colours indicating higher values (e.g., inspect panels b and c). Grey data points correspond to non-binary categorical variables.</p></caption>
<graphic xlink:href="20239194v1_fig3.tif"/>
</fig>
<p>We then project the explanations for all attendances into a lower-dimensional (2D) &#x2018;explanation&#x2019; space using the UMAP algorithm (see Methods for details), this projection provides insight into the different high-level groups of explanations provided by our model. The two-dimensional embedding of the attendances in the patient hold-out test set into the explanation space is visualised in <xref rid="fig4" ref-type="fig">Figure 4a</xref>. Attendances close in this space share more similar explanations for their predicted reattendance risk and we can see clear regions (colour) in the explanation space associated with increased reattendance risk. In Figures 5 b and c we display the attendances within the solid grey box, but now coloured by the number of visits in the 30 days preceding the given attendance the patient made to the emergency department and the number of medical conditions recorded in their electronic health record. Overall, this region highlights patients who are frequent attenders (number of visits in the 30 days preceding the attendance equal to 1 or more) and is separated into two sub regions: patients with a high attendance frequency (the left group in <xref rid="fig4" ref-type="fig">Figure 4b</xref>) and those who have attended once in the last 30-days and have at least one previous medical condition (the right group in <xref rid="fig4" ref-type="fig">Figure 4b</xref>).</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Embedding of the patient hold-out test set into a two-dimensional &#x2018;explanation&#x2019; space using the UMAP algorithm.</title>
<p>a) All attendances in the patient hold-out test set visualised in the explanation space, colour indicates the predicted reattendance risk for the respective attendance. Coloured rectangles highlight regions of interest. The solid grey line indicates the region of interest plotted in panels b and c. b) Attendances within the solid grey region of interest in panel a, coloured by the patient&#x2019;s 30-day visit count at the given attendance. c) Attendances within the solid grey region of interest in panel a, coloured by the patient&#x2019;s condition count at the given attendance. This embedding was created by clustering the prediction explanations (generated using the TreeExplainer algorithm) for each emergency department attendance using the UMAP algorithm. Generally, closer data points share a more similar explanation for their predicted reattendance risk.</p></caption>
<graphic xlink:href="20239194v1_fig4.tif"/>
</fig>
</sec>
<sec id="s4">
<title>Discussion</title>
<p>Our final 72-hour reattendance risk model achieved an AUROC of 0.748 and an average precision of 0.250 on a set of attendances independent to the training set. Qualitatively, our model can use a patient&#x2019;s (local) medical history and attendance level information to predict their reattendance risk with moderate performance. In parallel, we trained an explanation model, which can explain the model&#x2019;s predictions at an attendance level (<xref rid="fig3" ref-type="fig">Figure 3</xref> and Supplementary Figure 6) level. We projected the explanations into a two-dimensional space (<xref rid="fig4" ref-type="fig">Figure 4</xref>), with instances sharing similar explanations being closer in this space. Such a visualisation can be used as a tool to understand the different sub-groups at risk of reattendance, which could be used by the clinical care team to design interventions based on where a given attendance resides within the explanation space, ultimately facilitating the deployment of the machine-learnt model in a more informed manner.</p>
<p>Our final model (model p in <xref rid="tbl2" ref-type="table">Table 2</xref>) excluded two variables, pain score and measurements of vital signs. This was because while they were shown to be weakly predictive of reattendance risk in isolation (<xref rid="tbl2" ref-type="table">Table 2</xref>) they did not improve CV performance, despite increasing the model complexity, when included in models with larger numbers of variables, suggesting they are correlated to other features in the dataset. High correlation between variables is expected for clinical data, for example, one expects patient age, arrival mode, and vital signs all to latently encode the patient&#x2019;s frailty, which is known to be related to a patients reattendance risk<sup><xref rid="c23" ref-type="bibr">23</xref></sup>.</p>
<p>Interestingly, our model&#x2019;s validation performance increased when the model made use of the hour of day the attendance occurred (Supplementary Table 2). In our exploratory analysis, we found that the hour of day the attendance began displays clear correlation to the reattendance rate, with higher reattendance rates observed during the night (Supplementary Figure 3). By evaluating the observed SHAP values for the hour of day (<xref rid="fig3" ref-type="fig">Figure 3b</xref>) we can observe that our model has learned this trend, associating attendance registration during the night with a slightly higher (between zero and two percent) reattendance risk.</p>
<p>This trend could have several different origins. Firstly, we have found that the hour of day displays correlation with the reason for attendance with complaints associated with a higher risk of 72-hour reattendance more likely to present during the night alongside complaints associated with a lower risk of 72-hour reattendance less likely to present during the night. Secondly, it is reasonable that the staff fatigue and lower staffing levels could contribute to the increased reattendance for attendances occurring during the night, although we have no way of testing this hypothesis in our dataset.</p>
<p>Our model also makes use of ICD10 coded condition (e.g., type 1 diabetes, lives alone) indicators extracted from a patients electronic health record. These variables allow the model to identify medical conditions, comorbidities, and risks which are associated with increased reattendance risk and enables models to achieve moderate predictive performance (<xref rid="tbl2" ref-type="table">Table 2</xref>). Excluding the medical condition indicators and variables describing the reason for the attendance, the most important feature is the 30-day visit count which in part reflects the disproportionate use of EDs by frequent users<sup><xref rid="c24" ref-type="bibr">24</xref></sup>. In the visualisation of the attendances in the patient hold-out test set in the two-dimensional explanation space (<xref rid="fig4" ref-type="fig">Figure 4a</xref>), these frequent attenders (30 day visit count of two or more) are clearly segregated (solid grey rectangle in <xref rid="fig4" ref-type="fig">Figure 4a</xref>). Patients within this rectangle have a high chief triage complaint incidence of mental illness (7.5 &#x0025; compared to average of 2.5 &#x0025; for those not in this region), overdoses (5.6 &#x0025; compared to 2.2 &#x0025; for those not in this region), and abdominal pain (10.6 &#x0025; compared to 7.7 &#x0025; for those not in this region). This observation outlines how interventions can be designed based on explanation similarity as displayed in <xref rid="fig4" ref-type="fig">Figure 4</xref>. For example, while attendances within the solid grey box (i.e., frequent attenders) may benefit from support in the community to mitigate their reattendance risk, this will not necessarily be appropriate patients with a heighted reattendance risk but are suffering from an acute injury, associated with increased reattendance risk.</p>
<p>From a clinical perspective it is important to investigate the subset of reattendances which are also readmissions (i.e., reattendances to the emergency department which result in the patient being admitted). In these cases, there is increased risk that there was missed critical illness or injury at the initial attendance, and they are important to evaluate for clinical assurance purposes. Overall, 37.1 &#x0025; of reattendances end in readmission, resulting in a 72-hour readmission rate of 2.0 &#x0025;. Evaluating our model&#x2019;s predictions now with a target equal to whether the patient was readmitted within 72 hours we again evaluate our model and find it has an AUROC of 0.804 and an average precision of 0.087 on the hold-out patient test set. The high AUROC means the model displays high discernibility between attendances which result in readmission and those that do not. The low average precision reflects that readmissions only make up a minority fraction of reattendances and the false positive rate increases as a result of the large class imbalance. Overall, these results demonstrate our classifier can identify the subset of reattendances which are also readmissions with a similar predictive performance as reattendances which do not result in admission &#x2013; a particularly important result since these two different outcomes will likely merit different interventional strategies to reduce the risk of reattendance/readmission.</p>
<p>A limitation of our study, shared with other investigations of machine-learning use in EDs<sup><xref rid="c25" ref-type="bibr">25</xref></sup>, is that its primary data source is the structured past medical history, which is unavailable for many patients. This could lead to our model discriminating against people without a clinical history at the emergency department and associated hospital. We mitigate this through the use of visit-level information and this bias can be further reduced by linking to community datasets (e.g., GP records) to get a view of patient comorbidities. However, in a deployment scenario this bias could be minimized further by using the model as an alert tool &#x2013; its results only being displayed for patients it predicts to be at high risk of reattendance and otherwise will be entirely invisible to clinical staff who would be free to carry out standard clinical practice in cases where the alarm is not raised.</p>
<p>Practically, since the model uses only information available to clinicians at the time of the emergency department visit the model has a relatively low barrier to implementation. Despite this, it will be essential to perform prospective, randomized clinical trials of any implementation, investigating the efficacy of these predictive risk models, the associated interventions prospectively and, importantly, analysing how they impact decision making. Ultimately, deployment of a machine-learning model could eventually invalidate the model by changing the behaviours and descriptors of reattendances by altering the clinical decision made. In the short term, a relatively low-risk implementation of a machine-learnt model trained to identify patients at risk of reattendance would be in the implementation of a low-recall and high-precision alert system (for example, the configuration presented in <xref rid="fig2" ref-type="fig">Figure 2c</xref>). This would only raise alarms for the cases the model believes are at the highest risk and suggest appropiate clinically-validated intervention or additional clinical review. On average, using the configuration displayed in <xref rid="fig2" ref-type="fig">Figure 2c</xref>, this would have raised an alarm for only 1.5 &#x0025; of attendances in which a decision to discharge was made (approximately 2 times per day) and would expect to be correct approximately 50 &#x0025; of the time &#x2013; mitigating the risk of alarm fatigue and maintaining confidence in the model because of its modest precision, albeit with a limited impact because of the models low recall. As model performance improves, this configuration could be re-evaluated and changed to increase the impact of the model.</p>
<p>When considering deployment it is important to discuss the context in which these predictive models could be prospectively deployed. Our model was trained and retrospectively evaluated using data obtained local to the emergency department in Southampton, using data available to clinicians during standard clinical practice. This is clearly an advantage if the model is to be used at this location &#x2013; the biases in the data and attendance characteristics will likely reflect what the model will encounter in production. Conversely, this does mean that the model will not necessarily generalize to different EDs without first training on their local data, this will be particularily prominient in EDs with a catchment zone with very different demographics to Southampton, which would have a differing disease prevalence and characteristics at presentation to the emergency department. Despite this, since our model contains variables either in the standard UK emergency care dataset or regularily available to EDs nationally, it is possible to evaluate this model directly in other EDs with little alteration. External validation of our model using data from different EDs is essential before prospective deployment beyond the department at which the training data was sourced.</p>
</sec>
<sec id="s5">
<title>Conclusion</title>
<p>In conclusion, we have constructed and retrospectively evaluated a gradient boosted decision tree classifier capable of predicting the 72-hour reattendance risk for a patient at the point of discharge from an emergency department. The highest performing model achieved an AUROC of 0.748 and an average precision of 0.250 on a set of attendances independent to the training set. We investigated the variables most indicative of risk and showed these were patient level factors (medical history) rather than visit level variables such as recorded vital signs. We demonstrated how explainable machine learning can be used to investigate the decisions a model is making and that they could potentially be used to inform intervention design. We suggested an implementation of the algorithm in a low-recall high-precision configuration such that alarms are only raised if the model deems the patient to be at a (clinically defined) heighted risk of reattendance. External validation and prospective clinical trials of these models are essential, with considerable consideration given to the planned intervention resulting from the model&#x2019;s recommendation and the impact this would have on clinical decisions.</p>
</sec>
</body>
<back>
<sec sec-type="data-availability">
<title>Data Availability</title>
<p>The data that support the findings of this study are available from UHS, but restrictions apply to the availability of these data, which were used under license for the current study, and so are not publicly available. Data are however available from the authors upon reasonable request and with permission of UHS.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>This work was supported by The Alan Turing Institute under the EPSRC grant EP/N510129/1. We acknowledge support from the NIHR Wessex ARC.</p>
</ack>
<sec id="s6">
<title>Author contributions statement</title>
<p>FPC performed the data analysis and modelling. DKB and ZDZ discussed and commented on the analysis with FPC. NW and FPC obtained governance and ethical approval. MA and FB created the data extract. FPC, MJB and NW managed the study at the UoS. MK managed the study at UHS. FPC and MK designed the study with assistance from TWVD. MK and TWVD provided clinical guidance and insight. FPC wrote the first draft of the manuscript with assistance from MK and TWVD. All authors frequently discussed the work and commented and contributed to future drafts of the manuscript.</p>
</sec>
<sec id="s7">
<title>Additional information</title>
<sec id="s7a">
<title>Competing interests</title>
<p>The authors declare no competing interests.</p>
</sec>
<sec id="s7b">
<title>Data Governance and ethics</title>
<p>This work received ethics approval from the University of Southampton&#x2019;s Faculty of Engineering and Physical Science Research Ethics Committee (ERGO/FEPS/53164). Approval was also obtained from the NHS Health Research authority (20/HRA/1102, IRAS project ID 275577).</p>
</sec>
<sec id="s7c">
<title>Data availability</title>
<p>The data that support the findings of this study are available from UHS, but restrictions apply to the availability of these data, which were used under license for the current study, and so are not publicly available. Data are however available from the authors upon reasonable request and with permission of UHS.</p>
</sec>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="other"><string-name><surname>Berchet</surname>, <given-names>C.</given-names></string-name>, <source>Emergency care services: trends, drivers and interventions to man-age the demand</source>. <year>2015</year>)</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Baier</surname>, <given-names>N.</given-names></string-name>, <etal>et al.</etal> <article-title>Emergency and urgent care systems in Australia, Denmark, England, France, Germany and the Nether-lands&#x2013;Analyzing organization, payment and reforms</article-title>. <source>Health Policy</source> <volume>123</volume>, <fpage>1</fpage>&#x2013;<lpage>10</lpage> (<year>2019</year>)</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Bernstein</surname>, <given-names>S. L.</given-names></string-name>, <etal>et al.</etal> <article-title>The effect of emergency department crowding on clinically oriented outcomes</article-title>. <source>Academic Emergency Medicine</source> <volume>16</volume>, <fpage>1</fpage>&#x2013;<lpage>10</lpage> (<year>2009</year>)</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Guttmann</surname>, <given-names>A.</given-names></string-name>, <etal>et al.</etal> <article-title>Association between waiting times and short term mortality and hospital admission after departure from emergency department: population based cohort study from Ontario, Canada</article-title>. <source>BMJ</source> <volume>342</volume>, <fpage>d2983</fpage> (<year>2011</year>)</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="other"><string-name><surname>Besga</surname>, <given-names>A.</given-names></string-name>, <etal>et al.</etal> <article-title>Risk factors for emergency department short time readmission in stratified population</article-title>. <source>BioMed research international</source> (<year>2015</year>)</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Deschodt</surname>, <given-names>M.</given-names></string-name>, <etal>et al.</etal> <article-title>Characteristics of older adults admitted to the emergency department</article-title> (ED) and their risk factors for ED reattendance based on comprehensive geriatric assessment: a prospective cohort study. <source>BMC geriatrics</source> <volume>15</volume>, <fpage>1</fpage> (<year>2015</year>)</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Martin-Gill</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Reiser</surname>, <given-names>R.C.</given-names></string-name> <article-title>Risk factors for 72-hour admission to the</article-title> ED. <source>The American journal of emergency medicine</source> <volume>22</volume> <issue>6</issue>, <fpage>448</fpage>&#x2013;<lpage>453</lpage> (<year>2004</year>)</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Arendts</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Fitzhardinge</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Pronk</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Hutton</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Nagree</surname>, <given-names>Y.</given-names></string-name> and <string-name><surname>Donaldson</surname>, <given-names>M.</given-names></string-name> <article-title>Derivation of a nomogram to estimate probability of revisit in at-risk older adults discharged from the emergency department</article-title>. <source>Internal and emergency medicine</source> <volume>8</volume> <issue>3</issue>, <fpage>249</fpage>&#x2013;<lpage>254</lpage> (<year>2013</year>)</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Hao.</surname> <given-names>S.</given-names></string-name>, <etal>et al.</etal> <article-title>Risk prediction of emergency department revisit 30 days post discharge: a prospective study</article-title>. <source>PLoS one</source> <volume>9</volume> <issue>11</issue>,p e112944 (<year>2014</year>)</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Hong</surname>, <given-names>W.S.</given-names></string-name>, <string-name><surname>Haimovich</surname>, <given-names>A.D.</given-names></string-name> and <string-name><surname>Taylor</surname>, <given-names>R.A.</given-names></string-name> <article-title>Predicting 72-hour and 9-day return to the emergency department using machine learning</article-title>. <source>JAMIA open</source> <volume>2</volume> <issue>3</issue>, <fpage>346</fpage>&#x2013;<lpage>352</lpage> (<year>2019</year>)</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="other"><string-name><surname>Huang</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Altosaar</surname> <given-names>J.</given-names></string-name> and <string-name><surname>Ranganath</surname> <given-names>R.</given-names></string-name> <article-title>Clinicalbert: Modeling clinical notes and predicting hospital readmission</article-title>. <source>arXiv</source>, arXiv:<pub-id pub-id-type="arxiv">1904.05342</pub-id> (<year>2019</year>)</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Sterling</surname>, <given-names>N. W.</given-names></string-name>, <string-name><surname>Patzer</surname>, <given-names>R. E.</given-names></string-name>, <string-name><surname>Di</surname>, <given-names>M.</given-names></string-name>, and <string-name><surname>Schrager</surname>, <given-names>J. D.</given-names></string-name> <article-title>Prediction of emergency department patient disposition based on natural language processing of triage notes</article-title>. <source>International journal of medical informatics</source>, <volume>129</volume>, <fpage>184</fpage>&#x2013;<lpage>188</lpage> (<year>2019</year>)</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Micci-Barreca</surname>, <given-names>D.</given-names></string-name> <article-title>A preprocessing scheme for high-cardinality categorical attributes in classification and prediction problems</article-title>. <source>ACM SIGKDD Explorations Newsletter</source>, <volume>3</volume> <issue>1</issue>, <fpage>27</fpage>&#x2013;<lpage>32</lpage> (<year>2001</year>)</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="other"><string-name><surname>Bergstra</surname>, <given-names>J.S.</given-names></string-name>, <string-name><surname>Bardenet</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name> and <string-name><surname>K&#x00E9;gl</surname>, <given-names>B.</given-names></string-name> <article-title>Algorithms for hyper-parameter optimization</article-title>. <source>In Advances in neural information processing systems</source>, <fpage>2546</fpage>&#x2013;<lpage>2554</lpage> (<year>2011</year>)</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="other"><string-name><surname>Bergstra</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Yamins</surname>, <given-names>D.</given-names></string-name>, and <string-name><surname>Cox</surname>, <given-names>D. D.</given-names></string-name> <article-title>Making a Science of Model Search: Hyperparameter Optimization in Hundreds of Dimensions for Vision Architectures</article-title>. <source>In International Conference on Machine Learning</source>, <fpage>115</fpage>&#x2013;<lpage>123</lpage> (<year>2013</year>)</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="patent"><string-name><surname>Chen</surname>, <given-names>T.</given-names></string-name> and <string-name><surname>Guestrin</surname>, <given-names>C.</given-names></string-name> <article-title>XGBoost: A scalable tree boosting system</article-title>. <source>In Proceedings of the 22nd ACM sigkdd international conference on knowledge discovery and data mining</source>, <fpage>785</fpage>&#x2013;<lpage>794</lpage> (<year>2016</year>)</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="other"><string-name><surname>Lundberg</surname>, <given-names>S. M.</given-names></string-name>, and <string-name><surname>Su-In</surname> <given-names>L.</given-names></string-name> <article-title>A unified approach to interpreting model predictions</article-title>. <source>In Advances in neural information processing systems</source>, <fpage>4765</fpage>&#x2013;<lpage>4774</lpage> (<year>2017</year>)</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Lundberg</surname>, <given-names>S. M.</given-names></string-name>, <etal>et al.</etal> <article-title>From local explanations to global understanding with explainable AI for trees</article-title>. <source>Nature machine intelligence</source> <volume>2</volume> <issue>1</issue>, <fpage>2522</fpage>&#x2013;<lpage>5839</lpage> (<year>2020</year>)</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Lundberg</surname>, <given-names>S. M.</given-names></string-name>, <etal>et al.</etal> <article-title>Explainable machine-learning predictions for the prevention of hypoxaemia during surgery</article-title>. <source>Nature biomedical engineering</source> <volume>2</volume> <issue>10</issue>, <fpage>749</fpage>&#x2013;<lpage>760</lpage> (<year>2018</year>)</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="other"><string-name><surname>McInnes</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Healy</surname>, <given-names>J.</given-names></string-name> <article-title>UMAP: Uniform Manifold Approximation and Projection for Dimension Reduction</article-title>, <source>arXiv 2</source> arXiv:<pub-id pub-id-type="arxiv">1802.03426</pub-id> (<year>2018</year>)</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Becht</surname>, <given-names>E.</given-names></string-name>, <etal>et al.</etal> <article-title>Dimensionality reduction for visualizing single-cell data using UMAP</article-title>. <source>Nature biotechnology</source> <volume>37</volume> <issue>1</issue>,<fpage>38</fpage>&#x2013;<lpage>44</lpage> (<year>2019</year>)</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Diaz-Papkovich</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Anderson-Trocm&#x00E9;</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Gravel</surname>, <given-names>S.</given-names></string-name> <article-title>UMAP reveals cryptic population structure and phenotype heterogeneity in large genomic cohorts</article-title>. <source>PLoS genetics</source> <volume>15</volume> <issue>11</issue>, <fpage>e1008432</fpage> (<year>2019</year>)</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Kahlon</surname>, <given-names>S.</given-names></string-name>, <etal>et al.</etal> <article-title>Association between frailty and 30-day outcomes after discharge from hospital</article-title>. <source>Cmaj</source> <volume>187</volume> <issue>11</issue>, <fpage>799</fpage>&#x2013;<lpage>804</lpage> (<year>2015</year>)</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>LaCalle</surname>, <given-names>E.</given-names></string-name> and <string-name><surname>Rabin</surname>, <given-names>E.</given-names></string-name> <article-title>Frequent users of emergency departments: the myths, the data, and the policy implications</article-title>. <source>Annals of emergency medicine</source> <volume>56</volume> <issue>1</issue>, <fpage>42</fpage>&#x2013;<lpage>48</lpage> (<year>2010</year>)</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Joseph</surname>, <given-names>J.W.</given-names></string-name>, <etal>et al.</etal> <article-title>Deep-Learning Approaches to Identify Critically Ill Patients at Emergency Department Triage Using Limited Information</article-title>. <source>JACEP Open</source> <volume>1</volume>, <fpage>773</fpage>&#x2013;<lpage>781</lpage> (<year>2020</year>)</mixed-citation></ref>
</ref-list>
</back>
</article>