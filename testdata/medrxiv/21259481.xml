<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MEDRXIV</journal-id>
<journal-title-group>
<journal-title>medRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">medRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/2021.06.24.21259481</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Health Informatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A Web-based Tool for Automatically linking Clinical Trials to their Publications</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-1079-3406</contrib-id>
<name><surname>Smalheiser</surname><given-names>Neil R.</given-names></name>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Holt</surname><given-names>Arthur W.</given-names></name>
</contrib>
<aff><institution>Department of Psychiatry, University of Illinois College of Medicine</institution>, 1601 W. Taylor Street, MC912, Chicago, IL 60612 <country>USA</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label><email>neils@uic.edu</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2021</year>
</pub-date>
<elocation-id>2021.06.24.21259481</elocation-id>
<history>
<date date-type="received">
<day>24</day>
<month>6</month>
<year>2021</year>
</date>
<date date-type="rev-recd">
<day>24</day>
<month>6</month>
<year>2021</year>
</date>
<date date-type="accepted">
<day>26</day>
<month>6</month>
<year>2021</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2021</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution-NonCommercial 4.0 International), CC BY-NC 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc/4.0/">http://creativecommons.org/licenses/by-nc/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="21259481.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>ABSTRACT</title>
<sec>
<title>Objective</title>
<p>Evidence synthesis teams, physicians, policy makers, and patients and their families all have an interest in following the outcomes of clinical trials and would benefit from being able to evaluate both the results posted in trial registries and in the publications that arise from them. Manual searching for publications arising from a given trial is a laborious and uncertain process. We sought to create a statistical model to automatically identify PubMed articles likely to report clinical outcome results from each registered trial in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link>.</p></sec>
<sec>
<title>Materials and Methods</title>
<p>A machine learning-based model was trained on pairs (publications linked to specific registered trials). Multiple features were constructed based on the degree of matching between the PubMed article metadata and specific fields of the trial registry, as well as matching with the set of publications already known to be linked to that trial.</p></sec>
<sec>
<title>Results</title>
<p>Evaluation of the model using NCT-linked articles as gold standard showed that they tend to be top ranked (median best rank = 1.0), and 91&#x0025; of them are ranked in the top ten.</p></sec>
<sec>
<title>Discussion</title>
<p>Based on this model, we have created a free, public web based tool at <ext-link ext-link-type="uri" xlink:href="http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/TrialPubLinking/trial_pub_link_start.cgi">http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/TrialPubLinking/trial_pub_link_start.cgi</ext-link>that, given any registered trial in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link>, presents a ranked list of the PubMed articles in order of estimated probability that they report clinical outcome data from that trial. The tool should greatly facilitate studies of trial outcome results and their relation to the original trial designs.</p></sec>
</abstract>
<kwd-group kwd-group-type="author">
<title>KEYWORDS</title>
<kwd>clinical trials as topic</kwd>
<kwd>clinicaltrials.gov</kwd>
<kwd>evidence based medicine</kwd>
<kwd>bibliometrics</kwd>
<kwd>systematic reviews</kwd>
</kwd-group>
<counts>
<page-count count="25"/>
</counts>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<notes notes-type="financial-disclosure">
<title>Funding Statement</title><p>This work was supported by National Library of Medicine grant R01LM010817 and National Institute on Aging grant P01AG039347. The funders did not have any role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p></notes>
<notes notes-type="disclosures">
<title>Author Declarations</title><p>I confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.</p><p>Yes</p><p>The details of the IRB/oversight body that provided approval or exemption for the research described are given below:</p><p>no human subjects, this section is not applicable</p><p>All necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived.</p><p>Yes</p><p>I understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).</p><p>Yes</p><p>I have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.</p><p>Yes</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<title>OBJECTIVE</title>
<p>Clinical trials are the engine that drives improvements in health care. Evidence-based medicine seeks to collect and evaluate all possible evidence on a given question, giving highest priority to randomized controlled trials when available.[<xref ref-type="bibr" rid="c1">1</xref>] Evidence may reside in peer-reviewed publications that report trial clinical outcome data; clinical outcome data that is deposited in trial registries; grey literature; and patient-level trial data. Posted trial results often give more information about adverse events than those in the corresponding publications, and even such basic information as primary clinical outcome measures may differ between these sources.[<xref ref-type="bibr" rid="c2">2</xref>-<xref ref-type="bibr" rid="c6">6</xref>] Although it is unclear how often the conclusions of a systematic review are altered by including posted trial results,[<xref ref-type="bibr" rid="c7">7</xref>-<xref ref-type="bibr" rid="c9">9</xref>] physicians, policy makers, and patients and their families all have an interest in following the outcomes of registered trials,[<xref ref-type="bibr" rid="c10">10</xref>] and would benefit from being able to evaluate both the results posted in the trial registry and the publications that arise from them.</p>
<p>Finding the publications that arise from a given clinical trial is no easy matter, however, since only about half of trials give rise to any publications,[<xref ref-type="bibr" rid="c11">11</xref>-<xref ref-type="bibr" rid="c13">13</xref>] and of those that do, fewer than half mention the trial registry number to permit unambiguous linkage back to the trial.[<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>] Manual searching for publications arising from a given trial is a laborious and uncertain process. [<xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>] Several machine learning methods employ textual similarity and other features to link publications to individual trials,[<xref ref-type="bibr" rid="c16">16</xref>-<xref ref-type="bibr" rid="c18">18</xref>] although there are currently no web based systems available for the biomedical community. In the present paper, we have created a free, public web based tool that, given any registered trial in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link>, presents a ranked list of the PubMed articles in order of the estimated probability that they report clinical outcome data from that trial.</p>
</sec>
<sec id="s2">
<title>BACKGROUND AND SIGNIFICANCE</title>
<p>Linking publications to a given clinical trial is not a straightforward problem, for several reasons. First, the number of trials is large (&#x223C;390,000 in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> as of December 1, 2020) and the number of potentially linked publications is even larger (&#x223C;32 million articles indexed in PubMed, of which &#x223C;1.9 million articles mention the words trial or trials in title or abstract). Second, there is great variability among trials in the number of publications and their publication lags:[<xref rid="c11" ref-type="bibr">11</xref>, <xref rid="c12" ref-type="bibr">12</xref>, <xref rid="c19" ref-type="bibr">19</xref>-<xref rid="c22" ref-type="bibr">22</xref>] Although half of trials lack any publications, and most of those that do have only 1 or 2 publications, yet there is a long tail with some having &#x003E;20 publications. Most are published between 2-5 years after the completion of the trial, but a few may be published after 10 or more years. Third, previously proposed methods of linking trials to publications (e.g., overall matching of textual similarity [<xref ref-type="bibr" rid="c18">18</xref>] or shared authors between trials and publications [<xref ref-type="bibr" rid="c14">14</xref>]) have limited predictive performance on their own. Fourth, the textual fields and metadata of trial registries are not well standardized,[<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c24">24</xref>] which complicates the process of matching specific textual fields of trials to those of publications. Finally, ancillary publications may arise from a trial concerning a wide variety of issues, such as questionnaire development, GWAS studies carried out on trial subjects, reanalysis of data across multiple trials, and so on, which may not share word usage, topics, or investigators with the registered trial entry. Thus, similarity-based methods may be expected to be more successful for clinical outcome articles than for ancillary articles.</p>
<p>We built our Trials to Publications tool specifically for <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> and PubMed because they allow comprehensive and regularly updated XML-formatted downloading of all their trials and publications, which are not available for other trial registries and bibliographic databases. We have employed some of the features used in previous studies [<xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c18">18</xref>] but have carried ou additional trial-publication feature engineering, and have added a new feature based on the Aggregator model,[<xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c26">26</xref>] which scores the degree of matching between a given candidate publication and the set of publications that are definitely known to be linked to the trial. As we will show, this substantially improves the performance of the model and surpasses previous efforts.</p>
</sec>
<sec id="s3">
<title>MATERIALS AND METHODS</title>
<p>This section provides only a brief summary of methods. See the Supplementary File for full details regarding Methods.</p>
<sec id="s3a">
<title>definitions and overview</title>
<p>Each registered trial in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> is assigned a unique NCT number and has a trial registry entry consisting of multiple templated fields (e.g., start date, sponsor, inclusion and exclusion criteria, etc.). Publications that arise from a given trial are said to be &#x201C;linked&#x201D; to that trial, and comprise three different cases:</p>
<list list-type="order">
<list-item><p>Some publications mention the NCT number explicitly in the abstract and/or are indexed in the PubMed record. Most of these are automatically recognized and posted as a templated field in the <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> registry. However, articles that only mention the NCT number within the full-text will be missed. As well, we have found that the automatic recognition system misses some textual variants of how the NCT number is written, as well as NCT numbers mentioned in the Corporate Author field; therefore, we have supplemented the automatically recognized set of NCT-linked articles with additional articles found using our own algorithms (Supplementary Methods). These were utilized as gold-standard training data for our modeling, excluding publications that contained multiple NCT numbers.</p></list-item>
<list-item><p>Some trials contain publications that were submitted by the trial investigators, but that do not contain NCT numbers. These comprise a heterogeneous set of articles (<xref rid="fig1" ref-type="fig">Figure 1</xref>); some provide clinical outcome results of the trial, but some are earlier studies or reviews which provided motivation for carrying out the trial. We attempted to identify the clinical outcome articles by making restrictions on publication date and requiring the article be listed in the specific results_reference field of <ext-link ext-link-type="uri" xlink:href="http://clinicaltrials.gov">clinicaltrials.gov</ext-link> (see Supplementary Methods for details). These were utilized as silver-standard training data for our modeling.</p></list-item>
<list-item><p>Finally, the goal of our modeling is to identify the set of PubMed-indexed publications that arise from a given trial, but that are not listed or explicitly attached to the <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> registry. The potential scope of our interest includes all PubMed articles -- whether or not they are clinical trial articles, and whether or not they have been assigned Medical Subject Headings or Publication Types.</p></list-item>
</list>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Relationship between trial start date and linked article publication dates for all registered trials in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link>.</title>
<p>Data were collected in February, 2020. Publications with an explicit NCT link (shown in gold) most commonly appear 3 to 4 years after the start date of a trial. In contrast, investigator-submitted publications (shown in grey) exhibit a bimodal distribution of publication dates: Some are reviews or other publications that predate the start of a trial and provide motivation for carrying out the trial; in contrast, those published after the start of a trial appear to comprise primarily articles that arose from the trial itself.</p></caption>
<graphic xlink:href="21259481v1_fig1.tif"/>
</fig>
</sec>
<sec id="s3b">
<title>data preparation</title>
<p>We downloaded all public data as provided by the U.S. National Library of Medicine on the <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> website (<ext-link ext-link-type="uri" xlink:href="https://clinicaltrials.gov/ct2/resources/download">https://clinicaltrials.gov/ct2/resources/download</ext-link> on 2/20/2020). The full dataset contained approximately 330,000 unique clinical trial registrations with all public data supplied in XML format. All xml fields were imported into a relational database for efficient data retrieval with a filter that retains only alpha-numeric characters and common punctuation. We also obtained PubMed records (metadata) readily available for all (then &#x223C;30 million) articles at pubmed.gov.</p>
</sec>
<sec id="s3c">
<title>machine learning</title>
<p>Our strategy was to create positive training sets comprised of trial-publication pairs (using the gold-standard and/or silver standard data) vs. an equal sized negative training set constructed by randomly pairing trials with publications from other trials, matched such that they study the same condition or intervention. We extracted multiple features based on different aspects of matching between the trial and its linked publication, and used this to create a monotonic multi-dimensional measure of similarity that optimally distinguishes pairs in the positive vs. negative training sets. Finally, the similarity score between a trial and a publication is further modeled to estimate the probability that the publication arose from that trial (Supplementary Methods).</p>
</sec>
</sec>
<sec id="s4">
<title>RESULTS</title>
<p>The machine learning performance for the fitted model among the hold-out test cases, assuming a binary decision threshold of 0.5, was precision = 90.43&#x0025; and recall = 84.57&#x0025;, with F1 = 87.41&#x0025;. Overall accuracy was 87.81&#x0025; with an AUC of 0.95. These results, particularly the AUC value, indicate that the model is inherently able to discriminate positive vs. negative examples quite well.</p>
<p>However, it is more relevant to evaluate the model in the context of the implemented web-based ranking tool, which first identifies a pool of 5,000 candidate articles and then uses the model to make a ranked list according to their similarity scores. As gold standard, we employed NCT-linked articles but removed articles that were linked to more than one registered trial, as well as articles with publication dates prior to the trial start date. Note that this may provide an under-estimate of true performance, since it assumes that only the known NCT-linked articles are true positives; investigator-submitted articles, and true-positive articles that are not explicitly linked to them, are all counted as negatives in this evaluation. As discussed below, we carried out the evaluation separately for three cases: trials with two or more NCT-linked articles, trials with exactly one NCT-linked article, and trials with no NCT-linked articles.</p>
<sec id="s4a">
<title>trials with two or more NCT-linked articles</title>
<p>In this situation, each test article is compared not only to the registered trial, but to each of the other articles known to be linked to the trial (including the NCT-linked articles as well as any investigator-submitted articles having publication dates later than the trial start date). A test article is not compared against itself, however. This situation provides the most accurate assessment of performance, including the contribution of the Aggregator feature, i.e., computing similarity between the test article and each of the articles known to be linked to the trial, which overall is the most powerful single feature in our model (Supplementary Methods).</p>
<p>As shown in <xref rid="tbl1" ref-type="table">Table 1</xref>, the model ranks NCT-linked articles extremely well, with a median first rank of 1.0 and median first similarity score of 0.993. Overall, about 78&#x0025; of the NCT-linked articles arising from a trial are ranked in the top 10. (Note that the theoretical maximum recall is less than 100&#x0025; for this category, since some trials have more than 10 linked articles.)</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><title>Performance parameters for registered trials having &#x2265;2 NCT-linked articles.</title></caption>
<graphic xlink:href="21259481v1_tbl1.tif"/>
</table-wrap>
<p>If the Aggregator feature is removed entirely from the model, then the performance drops to a median first rank of 2.0 and median first score of 0.951 -- significantly lower (p = 1.04 &#x00D7; 10<sup>&#x2212;05</sup>) but still quite respectable (<xref rid="tbl1" ref-type="table">Table 1</xref>).</p>
</sec>
<sec id="s4b">
<title>trials with exactly one NCT-linked article</title>
<p>Overall, trials in this situation (<xref rid="tbl2" ref-type="table">Table 2</xref>, row a) produce a ranked list of articles whose median first rank is 1.0 and median first similarity score is 0.993, essentially the same as observed above in the case of two or more NCT-linked articles. However, we were concerned that this might be an overestimate of the true performance since when there is only one article linked to a trial, the model allows that article to be compared with itself. In order to assess the performance a bit more realistically, we examined trials that had one NCT-linked article but also had one or more investigator-submitted articles -- in this situation, the test article is compared against the other investigator-submitted articles but <underline>not</underline> against itself. <xref rid="tbl2" ref-type="table">Table 2</xref> row b shows that the median score of the NCT-linked article remains very high, 0.969.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><title>Performance parameters for registered trials having one NCT-linked article.</title></caption>
<graphic xlink:href="21259481v1_tbl2.tif"/>
</table-wrap>
<p>Although the median rank of the NCT-linked article falls from 1.0 to 3.0, this effect is more apparent than real, since the investigator-submitted articles are competing for the top ranks, yet are not counted as positives in this Gold Standard evaluation. <xref rid="tbl2" ref-type="table">Table 2</xref> row c corrects for this by counting both NCT-linked and investigator-submitted articles as positives, and in this case, the median first rank is 1.5 and median first similarity score is 0.984 -- this may be the fairest estimate of the performance of the model applied to trials that have a single NCT-linked article. As shown in <xref rid="tbl2" ref-type="table">Table 2</xref> row d, if the Aggregator feature is removed entirely from the model, the performance falls substantially and with statistical significance (note the non-overlapping confidence intervals), with the median score of the NCT-linked article centered at 0.887 (compare with 0.993 observed in <xref rid="tbl2" ref-type="table">Table 2</xref> row a).</p>
</sec>
<sec id="s4c">
<title>trials with no NCT-linked articles</title>
<p>This category comprises three different subcases: a) Roughly half of trials do not generate any publications at all, so for these the model could never hope to identify relevant outcome articles. b) An unknown percentage of trials generate publications that are not indexed in PubMed. Again, the model would not be able to find such articles. c) Finally, of greatest interest, a minority of trials generate PubMed articles that are not identifiable by <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> nor our own scraping efforts, because they do not specify NCT numbers in the abstract or record metadata. Some of these can be verified by manual inspection of full-text (i.e., the NCT number is sometimes given in the Methods section), whereas others are not clearly linked to a specific registered trial even after inspecting the full-text.</p>
<p>We created a random sample of 100 registered trials lacking any NCT-linked and investigator submitted articles, made a ranked list of 5,000 PubMed articles for each trial, and plotted the best predictive score for each trial. As shown in <xref rid="fig2" ref-type="fig">Figure 2</xref>, only 12 of the 100 trials had best similarity scores above 0.98, in contrast to 79 of 100 randomly chosen trials that had two or more NCT-linked articles (<xref rid="fig2" ref-type="fig">Figure 2</xref>). Examining the best-scoring article in the 9 trials having scores above 0.99, two were definitely linked to the trial in question (the NCT number was listed within the full-text) and two probably belonged (same topic, investigator and institution). Two were associated with different trials (different NCT number given in full text) but were closely related, for example, the same investigator studying &#x201C;&#x201D;Hepatic Function During and Following Three Days of Acetaminophen Dosing vs. &#x201C;Aminotransferase Trends During Prolonged Acetaminophen Dosing&#x201D;. This suggests that screening trials with no known linked articles for very high-scoring candidate articles can find at least some true positives or those associated with closely related trials.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Best model-derived similarity scores for ranked article lists processed for 100 trials with no known results publications vs. 100 trials with 2 or more NCT-linked publications.</title></caption>
<graphic xlink:href="21259481v1_fig2.tif"/>
</fig>
</sec>
<sec id="s4d">
<title>comparison of our model to previous published automated methods</title>
<p>Goodwin et al has published a deep learning-based, multi-feature model to identify publications that are linked to registered trials.[<xref ref-type="bibr" rid="c17">17</xref>] It is not possible to make a direct comparison between our model and theirs, because their system is not currently available, and because their reported performance parameters are not based on the same corpus of trials or articles as ours. Nevertheless, we computed the same information retrieval performance metrics as Goodwin et al did, in order to make an approximate comparison of methods. <xref rid="tbl3" ref-type="table">Table 3</xref> row b shows the performance of our most accurate evaluation situation (i.e., trials with two or more NCT-linked articles), compared to Goodwin&#x2019;s best and most comparable evaluation situation (<xref rid="tbl3" ref-type="table">Table 3</xref> row a). Our method exceeds substantially all parameters compared to Goodwin et al.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><title>Performance parameters to compare our methods vs. Goodwin et al [<xref ref-type="bibr" rid="c17">17</xref>].</title></caption>
<graphic xlink:href="21259481v1_tbl3.tif"/>
</table-wrap>
<p>Dunn et al have also published a trials to publications model based on textual and conceptual similarity between article and trial metadata.[<xref ref-type="bibr" rid="c18">18</xref>] Their code is archived publicly at <ext-link ext-link-type="uri" xlink:href="https://github.com/pmartin23/tfidf">https://github.com/pmartin23/tfidf</ext-link> and so we were able to compare their methods directly with ours. We used the same test corpus of 300 trials as reported in <xref rid="tbl1" ref-type="table">Table 1</xref> (except that a few articles could not be parsed by Dunn&#x2019;s system and were removed from our evaluation as well). As shown in <xref rid="tbl4" ref-type="table">Table 4</xref>, our performance was greater for all parameters, and the difference was statistically highly significant. Further analysis (see above and data not shown) suggests that our improved performance is largely due to the Aggregator feature, which complements textual and semantic similarity measures.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4.</label>
<caption><title>Performance parameters to compare our methods vs. Dunn et al [<xref ref-type="bibr" rid="c18">18</xref>].</title></caption>
<graphic xlink:href="21259481v1_tbl4.tif"/>
</table-wrap>
</sec>
<sec id="s4e">
<title>error analysis</title>
<p>We manually examined a selection of articles that were given predictive scores &#x003E;0.99 yet definitely did not arise from the registered trial as predicted (e.g., associated with different NCT numbers). The most common source of errors were caused by investigators who have individually produced numerous trials and numerous publications regarding the same condition or treatment. Thus, articles may be predicted to belong to one registered trial when, in fact, they belong to a related or follow-up trial (e.g., a phase III trial rather than phase II). A similar type of error could also occur for heavily studied conditions (e.g., metformin to treat diabetes) in which many similar trials produced many similar publications. Even these errors do not entirely reduce the utility of our tool, however: Since most trials generate only a few publications at most, displaying the top 10 publications (along with any that explicitly list NCT or other trial registry numbers) should point to the most related trials.</p>
</sec>
<sec id="s4f">
<title>implementing the tool based on the model</title>
<p>A web-based query interface that implements our model is shown in <xref rid="fig3" ref-type="fig">Figure 3</xref>. The user is prompted to enter a valid NCT number of a registered trial in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link>. In the basic search mode, the model is applied to a preselected list of 5,000 candidate PubMed articles based on shared conditions or interventions and/or some degree of textual similarity (Supplementary Methods). The advanced search interface allows the user to specify which PubMed articles should be processed; one can retrieve up to 100,000 articles that satisfy a user-specified PubMed query (Supplementary Methods). In the back end of the web service, our database is automatically incremented for newly registered trials and newly published articles on a weekly basis.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Screenshot of the Trials to Publications query interface. Visitors may view top-ranked articles for any valid <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> NCT number with a predetermined candidate set (Basic Search) or a <ext-link ext-link-type="uri" xlink:href="http://PubMed.gov">PubMed.gov</ext-link> compatible query (Advanced Search).</title>
<p>In the Advanced Search, the user is offered a PubMed query that is pre-populated with suggested terms taken from the condition, intervention and investigator fields of the registered trial, but can be freely edited so that, in effect, the user can enter any PubMed query at all, and create a candidate set of PubMed articles of possibly any size. This allows maximal flexibility. However, some guidance will be required since such queries cannot be pre-calculated but must be run in real time, and large sets may potentially take hours to process.</p></caption>
<graphic xlink:href="21259481v1_fig3.tif"/>
</fig>
<p>As shown in <xref rid="fig3" ref-type="fig">Figure 3</xref>, the user enters a valid NCT number of a trial registered in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link>, and receives a list of PubMed articles ranked according to similarity score (<xref rid="fig4" ref-type="fig">Figure 4</xref>). Note that in the Basic Search, we have restricted the pool of candidate articles to those which were published after the trial start date, and that share at least some minimal features with the registered trial (Supplementary Methods). If more than 5,000 articles satisfy these criteria, then the pool is limited to the 5,000 which match best on the initial feature set. A pool of 5,000 articles can be scored and ranked in real time within &#x223C;10 minutes. Because most trials have no or very few publications associated with them, displaying the top 10 articles will capture nearly all relevant articles in most cases. However, if all 10 have similarity scores &#x003E;0.8, then the display is extended to show all articles that have scores <underline>&#x003E;</underline> 0.8. In addition to displaying the similarity score for each article, we also display the estimated probability that the article arose from the given trial (see <xref rid="fig4" ref-type="fig">Figure 4</xref> and Supplementary Methods). Note that probabilities are not simply proportional to similarity scores, so that a similarity score of 76.3&#x0025; implies only a 1.9&#x0025; chance that the article arose from that trial (<xref rid="fig4" ref-type="fig">Figure 4</xref>). Articles that share the same NCT number as the trial are displayed at the top of the page, along with investigator-submitted articles, regardless of their similarity score. Finally, we have scraped registry numbers for a large number of international trial registries (Supplementary Methods); if a ranked article is linked to any of these registries, we display the registry number next to the article.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Screenshot of the Results page for the query shown in <xref ref-type="fig" rid="fig3">Figure 3</xref>.</title></caption>
<graphic xlink:href="21259481v1_fig4.tif"/>
</fig>
</sec>
</sec>
<sec id="s5">
<title>DISCUSSION</title>
<p>We present a machine learning based model and web-based tool that automatically predicts, for any given registered trial in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link>, which PubMed articles are the most likely to present its clinical outcome results. The underlying assumption is that articles that describe clinical outcomes from a trial will tend to share similarities with the trial registry in terms of text, MeSH terms, and/or investigator names. In addition, we introduced an additional type of &#x201C;Aggregator&#x201D; feature [<xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c26">26</xref>], in which articles were also compared for similarity with any articles known to be linked to the trial by virtue of having listed explicit NCT numbers or having been manually submitted by the trial investigators. The similarity metrics were trained using a corpus of positive and negative examples taken from <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link>, and evaluated on different test sets of articles and trials.</p>
<p>Our evaluations, using NCT-linked articles and investigator-submitted articles as gold and silver standards, verified the similarity assumption and showed that the model placed the majority of known linked articles in the top 5. Conversely, articles that had extremely high similarity scores with a given registered trial (e.g., &#x003E;0.99) often arose from that trial. Direct comparisons with previous efforts suggest that our method exceeds the current state of the art, and that the &#x201C;Aggregator&#x201D; feature contributes significantly to the overall performance. The web-based tool is free and publicly available at <ext-link ext-link-type="uri" xlink:href="http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/TrialPubLinking/trial_pub_link_start.cgi">http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/TrialPubLinking/trial_pub_link_start.cgi</ext-link>.</p>
<p>Several important limitations should be noted. Our tool is restricted to matching <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> with PubMed articles, so it does not include other registries or other bibliographic databases. Although the matching is based on multiple aspects of similarity, which should capture most articles that present clinical outcome results, we will miss a small proportion of articles that arise from the trial, such as questionnaire development studies. Preselecting 5,000 candidate articles reduces the time for presenting ranked results to under 10 minutes at present. However, we are currently in the process of pre-processing all existing trials and their candidate publications, which will allow almost instantaneous display in most cases.</p>
</sec>
<sec id="s6">
<title>CONCLUSION</title>
<p>The ability to find articles that are closely related to a given registered trial should provide value for physicians, patients and their families who seek to follow up on individual trials, as well as evidence synthesis teams seeking to find relevant publications. Future refinements to the tool, for example the Advanced search option, will depend on user feedback. Depending on the interest from the research community, we may seek to learn if there is sufficient interest to engineer the tool in the reverse direction, that is, given a PubMed clinical trial article, to identify its most similar registered trials.</p>
</sec>
<sec sec-type="supplementary-material">
<title>Supporting information</title>
<supplementary-material>
<label>Supplementary File</label>
<media xlink:href="supplements/259481_file06.docx" />
</supplementary-material>
</sec>
</body>
<back>
<sec sec-type="data-availability">
<title>Data Availability</title>
<p>The web-based tool is free and publicly available at http://arrowsmith.psych.uic.edu/cgi-bin/arrowsmith_uic/TrialPubLinking/trial_pub_link_start.cgi.</p>
</sec>
<sec id="s7">
<title>Declarations of interest</title>
<p>none</p>
</sec>
<sec id="s8">
<title>Funding</title>
<p>This work was supported by National Library of Medicine grant R01LM010817 and National Institute on Aging grant P01AG039347. The funders did not have any role in the study design, data collection and analysis, decision to publish, or preparation of the manuscript.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>Thanks to Adam Dunn and Shifeng Liu for their cooperation and advice in evaluating their previously published model in comparison with ours.</p>
</ack>
<sec id="s9">
<title>Supplementary File</title>
<p>This file contains the details of methods employed in our research and implementation of the web-based tool.</p>
</sec>
<sec id="s10">
<title>AUTHOR CONTRIBUTIONS</title>
<p>Neil Smalheiser: conceptualization, methodology, writing-original draft, writing -review and editing, supervision, funding acquisition.</p>
<p>Arthur Holt: methodology, software, validation, formal analysis, investigation, writing - original draft, writing -review and editing, visualization.</p>
</sec>
<ref-list>
<title>REFERENCES</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Murad</surname> <given-names>MH</given-names></string-name>, <string-name><surname>Asi</surname> <given-names>N</given-names></string-name>, <string-name><surname>Alsawas</surname> <given-names>M</given-names></string-name>, <string-name><surname>Alahdab</surname> <given-names>F.</given-names></string-name> <article-title>New evidence pyramid</article-title>. <source>Evid Based Med</source>. <year>2016</year> <month>Aug</month>;<volume>21</volume>(<issue>4</issue>):<fpage>125</fpage>&#x2013;<lpage>7</lpage>. doi: <pub-id pub-id-type="doi">10.1136/ebmed-2016-110401</pub-id>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Hartung</surname> <given-names>DM</given-names></string-name>, <string-name><surname>Zarin</surname> <given-names>DA</given-names></string-name>, <string-name><surname>Guise</surname> <given-names>JM</given-names></string-name>, <string-name><surname>McDonagh</surname> <given-names>M</given-names></string-name>, <string-name><surname>Paynter</surname> <given-names>R</given-names></string-name>, <string-name><surname>Helfand</surname> <given-names>M.</given-names></string-name> <article-title>Reporting discrepancies between the <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> results database and peer-reviewed publications</article-title>. <source>Ann Intern Med</source>. <year>2014</year> <month>Apr</month> 1;<volume>160</volume>(<issue>7</issue>):<fpage>477</fpage>&#x2013;<lpage>83</lpage>. doi: <pub-id pub-id-type="doi">10.7326/M13-0480</pub-id>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>van Lent</surname> <given-names>M</given-names></string-name>, <string-name><surname>IntHout</surname> <given-names>J</given-names></string-name>, <string-name><surname>Out</surname> <given-names>HJ</given-names></string-name>. <article-title>Differences between information in registries and articles did not influence publication acceptance</article-title>. <source>J Clin Epidemiol</source>. <year>2015</year> <month>Sep</month>;<volume>68</volume>(<issue>9</issue>):<fpage>1059</fpage>&#x2013;<lpage>67</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jclinepi.2014.11.019</pub-id>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Jones</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Keil</surname> <given-names>LG</given-names></string-name>, <string-name><surname>Holland</surname> <given-names>WC</given-names></string-name>, <string-name><surname>Caughey</surname> <given-names>MC</given-names></string-name>, <string-name><surname>Platts-Mills</surname> <given-names>TF</given-names></string-name>. <article-title>Comparison of registered and published outcomes in randomized controlled trials: a systematic review</article-title>. <source>BMC Med</source>. <year>2015</year> <month>Nov</month> 18;<volume>13</volume>:<fpage>282</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s12916-015-0520-3</pub-id>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Earley</surname> <given-names>A</given-names></string-name>, <string-name><surname>Lau</surname> <given-names>J</given-names></string-name>, <string-name><surname>Uhlig</surname> <given-names>K.</given-names></string-name> <article-title>Haphazard reporting of deaths in clinical trials: a review of cases of <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> records and matched publications-a cross-sectional study</article-title>. <source>BMJ Open</source>. <year>2013</year> <month>Jan</month> 18;<volume>3</volume>(<issue>1</issue>):<fpage>e001963</fpage>. doi: <pub-id pub-id-type="doi">10.1136/bmjopen-2012-001963</pub-id>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="journal"><string-name><surname>Riveros</surname> <given-names>C</given-names></string-name>, <string-name><surname>Dechartres</surname> <given-names>A</given-names></string-name>, <string-name><surname>Perrodeau</surname> <given-names>E</given-names></string-name>, <string-name><surname>Haneef</surname> <given-names>R</given-names></string-name>, <string-name><surname>Boutron</surname> <given-names>I</given-names></string-name>, <string-name><surname>Ravaud</surname> <given-names>P.</given-names></string-name> <article-title>Timing and completeness of trial results posted at <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> and published in journals</article-title>. <source>PLoS Med</source>. <year>2013</year> <month>Dec</month>;<volume>10</volume>(<issue>12</issue>):<fpage>e1001566.</fpage> discussion e1001566. doi: <pub-id pub-id-type="doi">10.1371/journal.pmed.1001566</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Adam</surname> <given-names>GP</given-names></string-name>, <string-name><surname>Springs</surname> <given-names>S</given-names></string-name>, <string-name><surname>Trikalinos</surname> <given-names>T</given-names></string-name>, <string-name><given-names>Williams JW</given-names> <surname>Jr</surname></string-name>, <string-name><surname>Eaton</surname> <given-names>JL</given-names></string-name>, <string-name><surname>Von Isenburg</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gierisch</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Wilson</surname> <given-names>LM</given-names></string-name>, <string-name><surname>Robinson</surname> <given-names>KA</given-names></string-name>, <string-name><surname>Viswanathan</surname> <given-names>M</given-names></string-name>, <string-name><surname>Middleton</surname> <given-names>JC</given-names></string-name>, <string-name><surname>Forman-Hoffman</surname> <given-names>VL</given-names></string-name>, <string-name><surname>Berliner</surname> <given-names>E</given-names></string-name>, <string-name><surname>Kaplan</surname> <given-names>RM</given-names></string-name>. <article-title>Does information from <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> increase transparency and reduce bias? Results from a five-report case series</article-title>. <source>Syst Rev</source>. <year>2018</year> <month>Apr</month> 16;<volume>7</volume>(<issue>1</issue>):<fpage>59</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s13643-018-0726-5</pub-id>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Wilson</surname> <given-names>LM</given-names></string-name>, <string-name><surname>Sharma</surname> <given-names>R</given-names></string-name>, <string-name><surname>Dy</surname> <given-names>SM</given-names></string-name>, <string-name><surname>Waldfogel</surname> <given-names>JM</given-names></string-name>, <string-name><surname>Robinson</surname> <given-names>KA</given-names></string-name>. <article-title>Searching <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> did not change the conclusions of a systematic review</article-title>. <source>J Clin Epidemiol</source>. <year>2017</year> <month>Oct</month>;<volume>90</volume>:<fpage>127</fpage>&#x2013;<lpage>135</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jclinepi.2017.07.009</pub-id>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Isojarvi</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wood</surname> <given-names>H</given-names></string-name>, <string-name><surname>Lefebvre</surname> <given-names>C</given-names></string-name>, <string-name><surname>Glanville</surname> <given-names>J.</given-names></string-name> <article-title>Challenges of identifying unpublished data from clinical trials: Getting the best out of clinical trials registers and other novel sources</article-title>. <source>Res Synth Methods</source>. <year>2018</year> <month>Dec</month>;<volume>9</volume>(<issue>4</issue>):<fpage>561</fpage>&#x2013;<lpage>578</lpage>. doi: <pub-id pub-id-type="doi">10.1002/jrsm.1294</pub-id>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Jones</surname> <given-names>CW</given-names></string-name>, <string-name><surname>Keil</surname> <given-names>LG</given-names></string-name>, <string-name><surname>Weaver</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Platts-Mills</surname> <given-names>TF</given-names></string-name>. <article-title>Clinical trials registries are under-utilized in the conduct of systematic reviews: a cross-sectional analysis</article-title>. <source>Syst Rev</source>. <year>2014</year> <month>Oct</month> 27;<volume>3</volume>:<fpage>126</fpage>. doi: <pub-id pub-id-type="doi">10.1186/2046-4053-3-126</pub-id>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Manzoli</surname> <given-names>L</given-names></string-name>, <string-name><surname>Flacco</surname> <given-names>ME</given-names></string-name>, <string-name><surname>D&#x2019;Addario</surname> <given-names>M</given-names></string-name>, <string-name><surname>Capasso</surname> <given-names>L</given-names></string-name>, <string-name><surname>De Vito</surname> <given-names>C</given-names></string-name>, <string-name><surname>Marzuillo</surname> <given-names>C</given-names></string-name>, <string-name><surname>Villari</surname> <given-names>P</given-names></string-name>, <string-name><surname>Ioannidis</surname> <given-names>JP</given-names></string-name>. <article-title>Non-publication and delayed publication of randomized trials on vaccines: survey</article-title>. <source>BMJ</source>. <year>2014</year> <month>May</month> 16;<volume>348</volume>:<fpage>g3058</fpage>. doi: <pub-id pub-id-type="doi">10.1136/bmj.g3058</pub-id>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="journal"><string-name><surname>Sreekrishnan</surname> <given-names>A</given-names></string-name>, <string-name><surname>Mampre</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ormseth</surname> <given-names>C</given-names></string-name>, <string-name><surname>Miyares</surname> <given-names>L</given-names></string-name>, <string-name><surname>Leasure</surname> <given-names>A</given-names></string-name>, <string-name><surname>Ross</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Sheth</surname> <given-names>KN</given-names></string-name>. <article-title>Publication and Dissemination of Results in Clinical Trials of Neurology</article-title>. <source>JAMA Neurol</source>. <year>2018</year> <month>Jul</month> 1;<volume>75</volume>(<issue>7</issue>):<fpage>890</fpage>&#x2013;<lpage>891</lpage>. doi: <pub-id pub-id-type="doi">10.1001/jamaneurol.2018.0674</pub-id>.</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Ross</surname> <given-names>JS</given-names></string-name>, <string-name><surname>Mulvey</surname> <given-names>GK</given-names></string-name>, <string-name><surname>Hines</surname> <given-names>EM</given-names></string-name>, <string-name><surname>Nissen</surname> <given-names>SE</given-names></string-name>, <string-name><surname>Krumholz</surname> <given-names>HM</given-names></string-name>. <article-title>Trial publication after registration in ClinicalTrials. Gov: a cross-sectional analysis</article-title>. <source>PloS medicine</source>. <year>2009</year>;<volume>6</volume>(<issue>9</issue>):<fpage>e1000144</fpage>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Huser</surname> <given-names>V</given-names></string-name>, <string-name><surname>Cimino</surname> <given-names>JJ.</given-names></string-name> <string-name><surname>Linking</surname> <given-names>ClinicalTrials.</given-names></string-name> <article-title>gov and PubMed to track results of interventional human clinical trials</article-title>. <source>PloS one</source>. <year>2013</year>;<volume>8</volume>(<issue>7</issue>):<fpage>e68409</fpage>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Bashir</surname> <given-names>R</given-names></string-name>, <string-name><surname>Bourgeois</surname> <given-names>FT</given-names></string-name>, <string-name><surname>Dunn</surname> <given-names>AG</given-names></string-name>. <article-title>A systematic review of the processes used to link clinical trial registrations to their published results</article-title>. <source>Syst Rev</source>. <year>2017</year> <month>Jul</month> 3;<volume>6</volume>(<issue>1</issue>):<fpage>123</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s13643-017-0518-3</pub-id>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Huser</surname> <given-names>V</given-names></string-name>, <string-name><surname>Cimino</surname> <given-names>JJ</given-names></string-name>. <article-title>Precision and negative predictive value of links between <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> and PubMed</article-title>. <source>AMIA Annu Symp Proc</source>. <year>2012</year>;<volume>2012</volume>:<fpage>400</fpage>&#x2013;<lpage>8</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="journal"><string-name><surname>Goodwin</surname> <given-names>TR</given-names></string-name>, <string-name><surname>Skinner</surname> <given-names>MA</given-names></string-name>, <string-name><surname>Harabagiu</surname> <given-names>SM</given-names></string-name>. <article-title>Automatically Linking Registered Clinical Trials to their Published Results with Deep Highway Networks</article-title>. <source>AMIA Jt Summits Transl Sci Proc</source>. <year>2018</year> <month>May</month> 18;<volume>2017</volume>:<fpage>54</fpage>&#x2013;<lpage>63</lpage>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="journal"><string-name><surname>Dunn</surname> <given-names>AG</given-names></string-name>, <string-name><surname>Coiera</surname> <given-names>E</given-names></string-name>, <string-name><surname>Bourgeois</surname> <given-names>FT</given-names></string-name>. <article-title>Unreported links between trial registrations and published articles were identified using document similarity measures in a cross-sectional analysis of <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link></article-title>. <source>J Clin Epidemiol</source>. <year>2018</year> <month>Mar</month>;<volume>95</volume>:<fpage>94</fpage>&#x2013;<lpage>101</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.jclinepi.2017.12.007</pub-id>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="journal"><string-name><surname>Asiimwe</surname> <given-names>IG</given-names></string-name>, <string-name><surname>Rumona</surname> <given-names>D.</given-names></string-name> <article-title>Publication proportions for registered breast cancer trials: before and following the introduction of the <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link> results database</article-title>. <source>Res Integr Peer Rev</source>. <year>2016</year> <month>Jul</month> 18;<volume>1</volume>:<fpage>10</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s41073-016-0017-4</pub-id>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Al-Durra</surname> <given-names>M</given-names></string-name>, <string-name><surname>Nolan</surname> <given-names>RP</given-names></string-name>, <string-name><surname>Seto</surname> <given-names>E</given-names></string-name>, <string-name><surname>Cafazzo</surname> <given-names>JA</given-names></string-name>, <string-name><surname>Eysenbach</surname> <given-names>G.</given-names></string-name> <article-title>Nonpublication Rates and Characteristics of Registered Randomized Clinical Trials in Digital Health: Cross-Sectional Analysis</article-title>. <source>J Med Internet Res</source>. <year>2018</year> <month>Dec</month> 18;<volume>20</volume>(<issue>12</issue>):<fpage>e11924</fpage>. doi: <pub-id pub-id-type="doi">10.2196/11924</pub-id>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Zwierzyna</surname> <given-names>M</given-names></string-name>, <string-name><surname>Davies</surname> <given-names>M</given-names></string-name>, <string-name><surname>Hingorani</surname> <given-names>AD</given-names></string-name>, <string-name><surname>Hunter</surname> <given-names>J.</given-names></string-name> <article-title>Clinical trial design and dissemination: comprehensive analysis of <ext-link ext-link-type="uri" xlink:href="http://clinicaltrials.gov">clinicaltrials.gov</ext-link> and PubMed data since 2005</article-title>. <source>BMJ</source>. <year>2018</year> <month>Jun</month> 6;<volume>361</volume>:<fpage>k2130</fpage>. doi: <pub-id pub-id-type="doi">10.1136/bmj.k2130</pub-id>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Schmucker</surname> <given-names>C</given-names></string-name>, <string-name><surname>Schell</surname> <given-names>LK</given-names></string-name>, <string-name><surname>Portalupi</surname> <given-names>S</given-names></string-name>, <string-name><surname>Oeller</surname> <given-names>P</given-names></string-name>, <string-name><surname>Cabrera</surname> <given-names>L</given-names></string-name>, <string-name><surname>Bassler</surname> <given-names>D</given-names></string-name>, <string-name><surname>Schwarzer</surname> <given-names>G</given-names></string-name>, <string-name><surname>Scherer</surname> <given-names>RW</given-names></string-name>, <string-name><surname>Antes</surname> <given-names>G</given-names></string-name>, <string-name><surname>von Elm</surname> <given-names>E</given-names></string-name>, <string-name><surname>Meerpohl</surname> <given-names>JJ</given-names></string-name>; <article-title>OPEN consortium. Extent of non-publication in cohorts of studies approved by research ethics committees or included in trial registries</article-title>. <source>PLoS One</source>. <year>2014</year> <month>Dec</month> 23;<volume>9</volume>(<issue>12</issue>):<fpage>e114023</fpage>. doi: <pub-id pub-id-type="doi">10.1371/journal.pone.0114023</pub-id>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Miron</surname> <given-names>L</given-names></string-name>, <string-name><surname>Gon&#x00E7;alves</surname> <given-names>RS</given-names></string-name>, <string-name><surname>Musen</surname> <given-names>MA</given-names></string-name>. <article-title>Obstacles to the reuse of study metadata in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link></article-title>. <source>Sci Data</source>. <year>2020</year> <month>Dec</month> 18;<volume>7</volume>(<issue>1</issue>):<fpage>443</fpage>. doi: <pub-id pub-id-type="doi">10.1038/s41597-020-00780-z</pub-id>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Chaturvedi</surname> <given-names>N</given-names></string-name>, <string-name><surname>Mehrotra</surname> <given-names>B</given-names></string-name>, <string-name><surname>Kumari</surname> <given-names>S</given-names></string-name>, <string-name><surname>Gupta</surname> <given-names>S</given-names></string-name>, <string-name><surname>Subramanya</surname> <given-names>HS</given-names></string-name>, <string-name><surname>Saberwal</surname> <given-names>G.</given-names></string-name> <article-title>Some data quality issues at <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link></article-title>. <source>Trials</source>. <year>2019</year> <month>Jun</month> 24;<volume>20</volume>(<issue>1</issue>):<fpage>378</fpage>. doi: <pub-id pub-id-type="doi">10.1186/s13063-019-3408-2</pub-id>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Shao</surname> <given-names>W</given-names></string-name>, <string-name><surname>Adams</surname> <given-names>CE</given-names></string-name>, <string-name><surname>Cohen</surname> <given-names>AM</given-names></string-name>, <string-name><surname>Davis</surname> <given-names>JM</given-names></string-name>, <string-name><surname>McDonagh</surname> <given-names>MS</given-names></string-name>, <string-name><surname>Thakurta</surname> <given-names>S</given-names></string-name>, <string-name><surname>Yu</surname> <given-names>PS</given-names></string-name>, <string-name><surname>Smalheiser</surname> <given-names>NR</given-names></string-name>. <article-title>Aggregator: a machine learning approach to identifying MEDLINE articles that derive from the same underlying clinical trial</article-title>. <source>Methods</source>. <year>2015</year> <month>Mar</month>;<volume>74</volume>:<fpage>65</fpage>&#x2013;<lpage>70</lpage>. doi: <pub-id pub-id-type="doi">10.1016/j.ymeth.2014.11.006</pub-id>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Smalheiser</surname> <given-names>NR</given-names></string-name>, <string-name><surname>Holt</surname> <given-names>AW</given-names></string-name>. <article-title>New improved Aggregator: predicting which clinical trial articles derive from the same registered clinical trial</article-title>. <source>JAMIA Open</source>. <year>2020</year> <month>Oct</month> 28;<volume>3</volume>(<issue>3</issue>):<fpage>338</fpage>&#x2013;<lpage>341</lpage>. doi: <pub-id pub-id-type="doi">10.1093/jamiaopen/ooaa042</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
</article>