<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MEDRXIV</journal-id>
<journal-title-group>
<journal-title>medRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">medRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/2021.09.30.21264287</article-id>
<article-version>1.2</article-version>
<article-categories>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Health Informatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Adaptive, Unlabeled and Real-time Approximate-Learning Platform (AURA) for Personalized Epileptic Seizure Forecasting</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Yang</surname><given-names>Yikai</given-names></name>
<xref ref-type="author-notes" rid="n1">&#x2020;</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Truong</surname><given-names>Nhan Duy</given-names></name>
<xref ref-type="author-notes" rid="n1">&#x2020;</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Eshraghian</surname><given-names>Jason K.</given-names></name>
<xref ref-type="author-notes" rid="n1">&#x2020;</xref>
<xref ref-type="aff" rid="a4">4</xref>
<xref ref-type="aff" rid="a5">5</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Nikpour</surname><given-names>Armin</given-names></name>
<xref ref-type="aff" rid="a6">6</xref>
<xref ref-type="aff" rid="a7">7</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Kavehei</surname><given-names>Omid</given-names></name>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution>School of Biomedical Engineering, Faculty of Engineering, The University of Sydney</institution>, NSW 2006, <country>Australia</country></aff>
<aff id="a2"><label>2</label><institution>Australian Research Council Training Centre for Innovative BioEngineering</institution>, NSW 2006, <country>Australia</country></aff>
<aff id="a3"><label>3</label><institution>The University of Sydney Nano Institute</institution>, NSW 2006, <country>Australia</country></aff>
<aff id="a4"><label>4</label><institution>Department of Electrical Engineering and Computer Science, University of Michigan</institution>, <country>USA</country></aff>
<aff id="a5"><label>5</label><institution>School of Medicine, University of Western Australia</institution>, WA 6009, <country>Australia</country></aff>
<aff id="a6"><label>6</label><institution>Comprehensive Epilepsy Services, The Royal Prince Alfred Hospital</institution>, NSW 2050, <country>Australia</country></aff>
<aff id="a7"><label>7</label><institution>Faculty of Medicine and Health, The University of Sydney</institution>, NSW 2006, <country>Australia</country></aff>
</contrib-group>
<author-notes>
<fn id="n1" fn-type="equal"><label>&#x2020;</label><p>Equal contribution</p></fn>
<fn id="n2" fn-type="others"><p><email>yikai.yang@sydney.edu.au</email>, <email>duy.truong@sydney.edu.au</email>, <email>armin.nikpour@sydney.edu.au</email>, <email>omid.kavehei@sydney.edu.au</email>, <email>jasonesh@umich.edu</email></p></fn>
<corresp id="cor1"><label>&#x002A;</label>Corresponding author, <email>omid.kavehei@sydney.edu.au</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2021</year>
</pub-date>
<elocation-id>2021.09.30.21264287</elocation-id>
<history>
<date date-type="received">
<day>30</day>
<month>9</month>
<year>2021</year>
</date>
<date date-type="rev-recd">
<day>02</day>
<month>11</month>
<year>2021</year>
</date>
<date date-type="accepted">
<day>03</day>
<month>11</month>
<year>2021</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2021</copyright-year>
<license><license-p>The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.</license-p></license>
</permissions>
<self-uri xlink:href="21264287.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>ABSTRACT</title>
<p>A high performance event detection system is all you need for some predictive studies. Here, we present AURA: an <underline>A</underline>daptive forecasting model trained with <underline>U</underline>nlabeled, <underline>R</underline>eal-time data using internally generated <underline>A</underline>pproximate labels on-the-fly. By harnessing the correlated nature of time-series data, a pair of detection and prediction models are coupled together such that the detection model generates labels automatically, which are then used to train the prediction model. AURA relies on several simple principles and assumptions: (i) the performance of an event prediction/forecasting model in the target application remains below the performance of an event detection model, (ii) detected events are treated as weak labels and deemed reliable enough for online training of a predictive model, and (iii) system performance and/or system responsive feedback characteristics can be tuned for a subject-under-test. For example, in medical patient monitoring, this enables personalizing forecasting models. Seizure prediction is identified as an ideal test case of AURA, as pre-ictal brainwaves are patient-specific and tailoring models to individual patients can significantly improve forecasting performance. AURA is used to generate an individual forecasting model for 10 patients, showing an average relative improvement in sensitivity by 14.30&#x0025; and reduction in false alarms by 19.61&#x0025;. This paper presents a proof-of-concept for the feasibility of online transfer-learning on a stream of time-series neurophysiological data that pave the way towards a low-power neuromorphic neuromodulation system.</p>
</abstract>
<counts>
<page-count count="18"/>
</counts>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>NDT and OK are shareholders in BrainConnect Pty Ltd, an Australian startup developing physiological and neurophysiological and interventional solutions for a range of neurological disorders. OK is a shareholder and currently the Managing Director at BrainConnect Pty Ltd. A provisional patent (Australian Provisional Patent Application No. 2021902957) related to the application of AURA to physiological signal forecasting and stimulation has been filed.</p></notes>
<notes notes-type="financial-disclosure">
<title>Funding Statement</title><p>Yikai Yang would like to acknowledge the Research Training Program (RTP) support provided by the Australia Government.</p></notes>
<notes notes-type="disclosures">
<title>Author Declarations</title><p>I confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.</p><p>Yes</p><p>The details of the IRB/oversight body that provided approval or exemption for the research described are given below:</p><p>This study on the RPAH clinical data is approved by the local Research Ethics Committee. Ethics approval number X19-0323-2019/STE16040 on Validating epileptic seizure detection, prediction and classification algorithms} approved on 19 September 2019 by the NSW Local Health District (LHD) for implementation at the Comprehensive Epilepsy Services, Department of Neurology, The Royal Prince Alfred Hospital (RPAH). The RPAH data is not openly available to the public but the other datasets used in this study (EPILEPSIAE and TUH) are available publicly either via registration or application for access. Access to EPILEPSIAE dataset requires payment.</p><p>I confirm that all necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived, and that any patient/participant/sample identifiers included were not known to anyone (e.g., hospital staff, patients or participants themselves) outside the research group so cannot be used to identify individuals.</p><p>Yes</p><p>I understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).</p><p>Yes</p><p>I have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.</p><p>Yes</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>Harm prevention and mitigation are often far more desirable than dealing with the fallout of deleterious events. Machine forecasting of future events provides an opportunity to integrate preventative systems across a variety of domains. In healthcare, disease prevention is preferable over disease management for both better patient outcomes and for medical resource management, and the same goes for symptoms. In general, the performance of supervised machine learning models are subject to the quantity and quality of training data [<xref ref-type="bibr" rid="c1">1</xref>]. This poses a major challenge in healthcare where labeled data is often lacking, and generalization across patients can be difficult to achieve and quantify [<xref ref-type="bibr" rid="c2">2</xref>, <xref ref-type="bibr" rid="c3">3</xref>, <xref ref-type="bibr" rid="c4">4</xref>, <xref ref-type="bibr" rid="c5">5</xref>]. In many instances, labeled data is only available at the time of the event, or a brief period of time preceding the event [<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c7">7</xref>]. This significantly limits the flexibility of forecasting models. The relative scarcity of labeled datasets for event prediction and forecasting results in the under-performance of machine learning models for the early detection of many tasks [<xref ref-type="bibr" rid="c8">8</xref>, <xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c10">10</xref>].</p>
<p>In this paper, we present a novel and computationally self-sufficient forecasting artificial intelligence (AI) system called &#x2018;AURA&#x2019; in the context of physiological signal recording and stimulation, which trains a forecasting network using unlabeled, real-time data that relies on a detection network to provide autonomously generated labels. This is a special case of semi-supervised learning [<xref ref-type="bibr" rid="c11">11</xref>, <xref ref-type="bibr" rid="c12">12</xref>], where the Bayes error of the fixed network (detection) is assumed to be less than that of the adjustable network (forecasting), even if the latter were to be considered &#x2018;perfectly&#x2019; trained. In AURA, the temporal distance between detection and forecasting tasks allows this assumption to hold. Several principles are utilized in using AURA:</p>
<list list-type="bullet">
<list-item><p><bold>Detection outperforms prediction:</bold> In many applications, the performance of a forecasting model degrades as the time between prediction and event (or absence of event) increases. Indicators and bio-markers of events characteristically strengthen as the onset of an event approaches closer in time. The proposed method exploits this fact and uses a detection system to label data which then trains the forecasting model. This is performed with the expectation that incorrectly labeled data by the detection system is unlikely to be correctly predicted by the forecasting system. So emphasis is placed on enabling the predictive system to converge towards the performance of the detector, rather than pushing towards a potentially unrealistic goal of 100&#x0025; accuracy. Although the asymptotic error of prediction is not shown to converge to that of detection, we show practical examples that demonstrate it works almost as well.</p></list-item>
<list-item><p><bold>New data is more informative than old data:</bold> Online learning can potentially suffer from catastrophic interference (or catastrophic forgetting), where the onset of new training data &#x2018;overrides&#x2019; the latent representations of historical data in a neural network [<xref ref-type="bibr" rid="c13">13</xref>]. In certain cases, it may be that new data is more representative of present circumstances, so it is preferable to learn from more recent information. More precisely, time-series data is often non-stationary, and the statistical properties of the incoming data are likely to evolve. Online learning could train a system to adapt to changing patient conditions over time.</p></list-item>
<list-item><p><bold>Patient-specific tuning:</bold> While the above point focuses on &#x2018;new&#x2019; data in the temporal sense, it also holds true for &#x2018;new&#x2019; patients. A model tuned to an individual patient is likely to perform better for that particular individual over a model trained to generalize across a multitude of patients (as is typically the case for most machine learning models in use today). This observation holds true beyond medical diagnostics, for example, geography-specific weather forecasting. Historically, the cost of manually labeling individual patient data to designing patient-specific models has been prohibitively expensive for large-scale deployment. AURA overcomes this using the semi-supervised approach described in <xref ref-type="sec" rid="s2e">Section 2.5</xref>.</p></list-item>
</list>
<sec id="s1a">
<label>1.1</label>
<title>Novelty and significance</title>
<p>Designing microelectronic circuits and systems for medical implants and electroceuticals is challenging and bounded by several constraints, such as area dimensions, energy consumption, safety, and the need for continuous or very regular data telemetry [<xref ref-type="bibr" rid="c35">35</xref>]. While it is not difficult to find medical devices with different capacities of performing on-chip analog or digital signal processing, active on-chip learning use in the neuromodulation or neuromonitoring domain is at its infancy [<xref ref-type="bibr" rid="c36">36</xref>].</p>
<p><xref rid="fig1" ref-type="fig">Fig. 1</xref> demonstrates four general types of loops in medical devices, as applied to neurotechnologies (<xref rid="fig1" ref-type="fig">Fig. 1(a)</xref>). In an open-loop system (<xref rid="fig1" ref-type="fig">Fig. 1(b)</xref>), decision-making is reviewed by a trained human expert who may perform visits to reprogram the device. This indicates stimulation parameters such as amplitude, frequency, and duty cycle are pre-identified and are indefinitely fixed for the duration of device operation, unless changed manually. This method lacks individualization, may require additional training to equip doctors with the programming skills to re-parameterize the device, exhausts the battery, and results in a very high frequency of unnecessarily applied neurostimulation. The high count of unnecessary stimulation can be considered equivalent to a high number of false positives in a closed-loop system, and hence causes side-effects that push the efficacy of the system into a degree of diminishing returns [<xref ref-type="bibr" rid="c37">37</xref>]. An adaptive closed-loop system (<xref rid="fig1" ref-type="fig">Fig. 1(c)</xref>), however, can control its stimulation via a feedback loop using extracted bio-markers. Accepting a slightly higher risk of automation in feature extraction by reducing the significance of <italic>expert-in-the-loop</italic> intervention enables significant energy savings, cost benefits and capabilities relative to conventional systems such as deep-brain stimulation (DBS) [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c21">21</xref>].</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><p>(a) Neuromonitoring (recording) and neuromodulation (stimulation) as part of a medical device and their different system types. While this method in theory can be used with any physiological signal, the most promising are electroencephalogram (EEG), intracranial electroencephalography (iEEG), and local field potentials (LFP), as part of neuromodulation systems such as vagus nerve stimulation (VNS) or deep brain stimulation (DBS). (b) An open-loop system with a human <italic>expert in the loop</italic> that engages occasionally in manual programming and parameter adjustment. (c) An adaptive closed-loop system with an automated bio-marker or feature detection and real-time signal processing that controls simulation. Examples include [<xref ref-type="bibr" rid="c9">9</xref>, <xref ref-type="bibr" rid="c14">14</xref>, <xref ref-type="bibr" rid="c15">15</xref>, <xref ref-type="bibr" rid="c16">16</xref>, <xref ref-type="bibr" rid="c17">17</xref>, <xref ref-type="bibr" rid="c18">18</xref>, <xref ref-type="bibr" rid="c19">19</xref>, <xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c21">21</xref>]. (d) An example of a <italic>cloud or smartphone in the loop</italic> system that allows for online adjustments of detection or prediction models, but retraining of the models using the stream of incoming data must be conducted on the cloud. These systems rely on either continuous or regular data telemetry of the data stored in the database. Examples include [<xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c30">30</xref>, <xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c32">32</xref>]. (e) AURA operates on the basis of a <italic>neuromorphic neuromodulation system</italic>, where the medical device hosts online training and active learning without any reliance on external computing resources. <italic>Approximate learning</italic> is used to train the active learning model, which pushes the performance of the probabilistic forecasting system towards the non-patient specific inference machine-learning detection model. Once implemented on a low-power neuromorphic chip, system personalization is achieved via its computationally self-sufficient re-training of the forecasting model without the need for data telemetry to the outside world. There are an increasing body of evidence that highly customized low-power neuromorphic systems and models can deliver our vision [<xref ref-type="bibr" rid="c33">33</xref>, <xref ref-type="bibr" rid="c34">34</xref>].</p></caption>
<graphic xlink:href="21264287v2_fig1.tif"/>
</fig>
<p><xref rid="fig1" ref-type="fig">Fig. 1(d)</xref> illustrates how novel adaptive closed-loop systems are addressing the shortcomings of standard closed-loop systems by incorporating a more complex system architecture with heavy reliance on external computational power to manage control algorithm and feedback signal optimization [<xref ref-type="bibr" rid="c20">20</xref>, <xref ref-type="bibr" rid="c38">38</xref>]. These system models that can still be identified as <italic>cloud/expert-in-the-loop</italic> or <italic>phone/patient-in-the-loop</italic>, require continuous or, if pre-identified, regular data telemetry for their machine learning models to be trained on the cloud or smartphone. Many works can be identically or partially identified as offloading resource intensive tasks externally, with reliance on distributed software at the heart of these closed-loop systems [<xref ref-type="bibr" rid="c22">22</xref>, <xref ref-type="bibr" rid="c23">23</xref>, <xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c25">25</xref>, <xref ref-type="bibr" rid="c26">26</xref>, <xref ref-type="bibr" rid="c27">27</xref>, <xref ref-type="bibr" rid="c28">28</xref>, <xref ref-type="bibr" rid="c29">29</xref>, <xref ref-type="bibr" rid="c30">30</xref>, <xref ref-type="bibr" rid="c31">31</xref>, <xref ref-type="bibr" rid="c32">32</xref>]. To list a few examples, the role of a processing unit, in innovations such as [<xref ref-type="bibr" rid="c32">32</xref>], is limited to the controller of system operation. Another example is outsourcing training, improvement, and optimization of on-chip models to the cloud by regular and continuous transfer of device database [<xref ref-type="bibr" rid="c30">30</xref>]. It should be noted that some of the aforementioned methods may offer active adjustments to the system on-the-fly, but none enable on-chip training and re-training, which should be at the core of a successful and highly personalized seizure forecasting system.</p>
<p>Our alternative is &#x2018;AURA&#x2019;, shown in <xref rid="fig1" ref-type="fig">Fig. 1(e)</xref>. We believe the combination of an on-chip and actively evolving forecasting model with a <italic>brain loop-recorder</italic> and a dependable detection model, provides a non-trivial, novel, complex and yet, elegant adaptive and personalized system with innovative potential for closed-loop neuromodulation. The alternative we are offering is ambitious with the vision of removing the need for continuous and demanding data telemetry to and from external entities from the loop. The AURA platform still allows for on-demand data telemetry for system diagnostics and performance monitoring.</p>
<p>Personalization in bio-marker discovery and response to therapies continue to demonstrate its profound significance in the field, but it is poorly understood [<xref ref-type="bibr" rid="c39">39</xref>, <xref ref-type="bibr" rid="c40">40</xref>]. With respect to seizures, studies in drug-resistant focal epilepsy shows multi-dimensional individualization not only across different patients, but also between seizures in one patient [<xref ref-type="bibr" rid="c40">40</xref>, <xref ref-type="bibr" rid="c41">41</xref>]. Personalization is also reported in studies concerning seizure cycles, while more should be done to properly address possibilities for seizure triggers, and accommodate protocols associated with circadian studies [<xref ref-type="bibr" rid="c24">24</xref>, <xref ref-type="bibr" rid="c42">42</xref>, <xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c44">44</xref>, <xref ref-type="bibr" rid="c45">45</xref>, <xref ref-type="bibr" rid="c46">46</xref>].</p>
<p>To assess the performance of AURA, we have identified seizure forecasting as an optimal use-case, illustrated in <xref rid="fig1" ref-type="fig">Figure 1</xref>. Firstly, the early prediction of a seizure allows for preventative action to take place, such as closed-form feedback via neurostimulation. Secondly, early warning signs manifest in different ways across patients, such as varying brain-wave patterns, and adapting a network to learn the neural signature of a patient could lead to better prediction results. Finally, the largest publicly available labeled scalp electroencephalography (EEG) seizure dataset lacks sufficient information prior to the onset of seizures [<xref ref-type="bibr" rid="c6">6</xref>]. The absence of such data means seizure forecasting has been a challenging task for deep learning models, and there is a need to develop techniques that can train and tune models from unlabeled (or indirectly labeled) datasets as well. AURA is perfectly poised to fill this void.</p>
</sec>
<sec id="s1b">
<label>1.2</label>
<title>Towards on-chip online-learning for neuromorphic neuromodulation systems</title>
<p>AURA is envisioned as the first step toward designing a patient-specific and highly customized low-power neuromorphic neuromodulation system (nRNS), where sufficient performance for a given patient may justify closed-loop neurostimulation for seizure avoidance. Developing a continuously updated, always-on neuromorphic system that adapts to a patient&#x2019;s bio-markers requires a low-power, portable learning system that can be ambiently deployed for outpatient care [<xref ref-type="bibr" rid="c47">47</xref>, <xref ref-type="bibr" rid="c48">48</xref>]. Deep learning, and particularly training models, is notorious for its large energy consumption which arises due to the huge number of parameters in large-scale models [<xref ref-type="bibr" rid="c49">49</xref>, <xref ref-type="bibr" rid="c50">50</xref>, <xref ref-type="bibr" rid="c51">51</xref>, <xref ref-type="bibr" rid="c52">52</xref>, <xref ref-type="bibr" rid="c53">53</xref>], and corresponds to frequent memory accesses and data movement across a chip and between chips. While our prototypical demonstration of AURA provides much promise in the potential of targeted deep learning models in seizure forecasting, extending usage beyond inpatients requires overcoming the energy and latency bottlenecks of on-chip learning [<xref ref-type="bibr" rid="c54">54</xref>, <xref ref-type="bibr" rid="c55">55</xref>, <xref ref-type="bibr" rid="c56">56</xref>].</p>
<p>The fields of neuromorphic computing and emerging memory technologies are ushering in new algorithms and architectures that demonstrate how modern deep learning and neuromorphic event-driven systems can be modified to cater for resource-constrained environments. For example, the use of spiking neural networks can reduce the power consumption of equivalent deep learning algorithms by several orders of magnitude [<xref ref-type="bibr" rid="c57">57</xref>, <xref ref-type="bibr" rid="c58">58</xref>, <xref ref-type="bibr" rid="c59">59</xref>, <xref ref-type="bibr" rid="c60">60</xref>], and in-memory computing architectures that co-locate processing with network parameter storage can achieve similar performance improvements. Although online/transfer learning and real-time variants of backpropagation algorithms are not often used in practice, AURA as applied to at-risk outpatient tuning motivates a compelling use-case for new generation, online techniques for handling deep learning algorithms, tailored to highly-customized low-power neuromorphic neuromodulation systems [<xref ref-type="bibr" rid="c33">33</xref>, <xref ref-type="bibr" rid="c34">34</xref>, <xref ref-type="bibr" rid="c61">61</xref>]. Event-driven neuromorphic computing allows tremendous energy efficiency in both training and inference, but the focus has been primarily on inference engines due to its ubiquity in the IoT (Internet of Things). Recently, significant energy reduction in edge-based training has been demonstrated, where an online transfer learning image processing neuromorphic chip is reported to operate on 23.1 mW (23.6 mW) with 0.8 V supply voltage at 20 MHz, while processing 93k 28 &#x00D7;28 images/s (100k 28&#x00D7; 28 images/s) during training (inference) [<xref ref-type="bibr" rid="c33">33</xref>]. While the simplicity of the network reported here may not be suitable for complex neurophysiological data processing at this point in time<sup><xref ref-type="fn" rid="fn1">1</xref></sup>, a highly-customized low-power neuromorphic neuromodulation system is a promising avenue to implement and deliver this paper&#x2019;s vision beyond power-hungry complex deep learning models.</p>
</sec>
</sec>
<sec id="s2">
<label>2</label>
<title>Background</title>
<sec id="s2a">
<label>2.1</label>
<title>Seizure Forecasting</title>
<p>It was long thought that epileptic seizures were abrupt events that would materialize without prior warning [<xref ref-type="bibr" rid="c63">63</xref>], but the advent of long-term EEG recordings changed this. In the early 1970s, it was shown that seizures could develop over long time scales [<xref ref-type="bibr" rid="c64">64</xref>] which pointed to seizure forecasting potentially being within reach. Since then, evidence has amassed to show that seizures are often preceded by detectable changes in brain activity [<xref ref-type="bibr" rid="c65">65</xref>, <xref ref-type="bibr" rid="c66">66</xref>], where, for example, a significant increase in blood flow occurs within the epileptic hippocampus prior to temporal lobe epilepsy [<xref ref-type="bibr" rid="c67">67</xref>, <xref ref-type="bibr" rid="c68">68</xref>].</p>
<p>An early seizure warning system could improve patient quality of life by triggering pre-emptive administration of therapies, such as anti-epilepsy medication or electrical stimulation [<xref ref-type="bibr" rid="c69">69</xref>], which could avert impending seizures and minimize risk of injury. The minimum time interval between an alarm being raised and the occurrence of the seizure while still rendering an intervention to be possible is known as the seizure prediction horizon (SPH).</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Detection is easier than prediction</title>
<p>Detecting a seizure at the time of or immediately after onset has had far more success over forecasting seizures in advance [<xref ref-type="bibr" rid="c70">70</xref>]. Several machine learning techniques have been used to augment neurologist readings, leading to faster conclusions whilst maintaining specialist-level EEG-reading performance for the identification of seizures as they happen [<xref ref-type="bibr" rid="c71">71</xref>, <xref ref-type="bibr" rid="c72">72</xref>, <xref ref-type="bibr" rid="c73">73</xref>, <xref ref-type="bibr" rid="c74">74</xref>]. Unfortunately, seizure aversion is no longer an option when relying on detection mechanisms alone. There are several challenges that face early onset seizure prediction:</p>
<list list-type="bullet">
<list-item><p>onset patterns vary greatly between patients [<xref ref-type="bibr" rid="c75">75</xref>];</p></list-item>
<list-item><p>pre-ictal recordings in one patient can be very similar to non-seizure recordings in another patient [<xref ref-type="bibr" rid="c76">76</xref>];</p></list-item>
<list-item><p>the transition to a pre-ictal state consists of subtle changes that can easily go undetected [<xref ref-type="bibr" rid="c77">77</xref>].</p></list-item>
</list>
<p>The first two challenges highlight the difficulty of developing techniques that generalize across patients. These can be addressed by integrating precision medicine techniques that adapt predictive models tailored to the needs of individual patients.</p>
<p>The third point relates to the challenges of function estimation in temporal data analysis. In deep learning, the goal is to learn a function that maps an input (EEG signals) to an output (whether a seizure will occur after the SPH). The output is treated as a random variable. As the SPH increases, the signal of measurable bio-markers is reduced causing the variance of the output to increase. An intuitive interpretation is that the unpredictable component of the output dominates the predictable component as the time window of forecasting is increased. Reducing the variance of deep learning models can generally be achieved by gathering more data. Unsurprisingly, unlabeled data is far more accessible than labeled data.</p>
</sec>
<sec id="s2c">
<label>2.3</label>
<title>The bulk of medical data is unlabeled</title>
<p>Patient-specific models and training with large datasets are somewhat conflicting notions. Individual patients cannot contribute the same scale of data as a whole population of patients. While the availability of long-term EEG recordings has renewed interest in designing patient-specific forecasting algorithms [<xref ref-type="bibr" rid="c78">78</xref>, <xref ref-type="bibr" rid="c79">79</xref>, <xref ref-type="bibr" rid="c80">80</xref>], these algorithms still underperform when compared to seizure detection.</p>
<p>The world&#x2019;s largest public seizure database, the Temple University Hospital (TUH) seizure corpus, contains EEG recordings of over 4,000 patients, and is commonly used for testing and validating the performance of seizure detection systems that achieve close to expert clinician performance [<xref ref-type="bibr" rid="c6">6</xref>, <xref ref-type="bibr" rid="c71">71</xref>]. The recordings commence between 5 to 35 minutes pre-ictally which limits the length of the SPH. While there is a plethora of unlabeled data, the lack of formally trained EEG readers available to provide precise temporal annotations, with confirmatory secondary readings, means this huge source of data cannot be directly used in supervised learning methods. The bulk of medical data remains unlabeled and underutilized.</p>
<p>This challenge can be addressed by relying on high performance seizure detection models to annotate this data for us. Weak supervision has previously been applied by obtaining inaccurate labels from a mix of experts and novices for real-time seizure detection [<xref ref-type="bibr" rid="c81">81</xref>]. Our approach can be distinguished as we wholly do away with manual annotations, and instead use a detection model shown to perform similarly to neurologists [<xref ref-type="bibr" rid="c71">71</xref>]. These machine-generated detection labels are then used as targets for the prediction model. Some of the detected seizures may be misclassified (and thus, inaccurate labels for prediction), which raises concerns that noisy labels could mislead the prediction system [<xref ref-type="bibr" rid="c82">82</xref>].</p>
<p>Fortunately, in the real world, the fact that temporal data is inherently correlated is extremely useful. A seizure that is misclassified at its onset (real-time detection) is unlikely to be successfully predicted pre-ictally (forecasting), as the unpredictability of seizures generally increases with a longer SPH. Therefore, such errors are treated as inevitable; the larger amount of correctly classified data is instead used to offset potential performance degradation from noisy labels. Training a prediction system using approximate labels derived from a detection system makes better use of temporal correlations in the real world [<xref ref-type="bibr" rid="c82">82</xref>, <xref ref-type="bibr" rid="c83">83</xref>, <xref ref-type="bibr" rid="c84">84</xref>].</p>
</sec>
<sec id="s2d">
<label>2.4</label>
<title>Learning patient-specific patterns</title>
<p>Seizures may be regarded to follow patient-specific cyclic patterns. This has been long observed since 1939, when Griffiths and Fox observed that some patients experience seizures at certain times of the day, while others followed monthly cycles [<xref ref-type="bibr" rid="c85">85</xref>]. Confounding variables also contribute to the variance between patients, including medication, stress, circadian effects, and hormonal effects, amongst others [<xref ref-type="bibr" rid="c86">86</xref>, <xref ref-type="bibr" rid="c87">87</xref>, <xref ref-type="bibr" rid="c88">88</xref>, <xref ref-type="bibr" rid="c89">89</xref>]. Circadian (days) and multidien (multi-days) seizure cycles have also recently been studied with patient self-reported diaries and retrospectively on some long-term intracranial EEG data, which shows peaks in seizure cycles as long as 30 days apart [<xref ref-type="bibr" rid="c43">43</xref>, <xref ref-type="bibr" rid="c90">90</xref>, <xref ref-type="bibr" rid="c91">91</xref>, <xref ref-type="bibr" rid="c92">92</xref>]. Whether the observed cycles are valid and whether they can be linked to triggers such as missed medication, mental and emotional states, the menstrual cycle, and the duration and severity of seizures require objective and prospective studies [<xref ref-type="bibr" rid="c93">93</xref>]. It is known that mammalian physiology and behavior is widely influenced by light and other environmental factors, which means circadian or multidien studies require well-developed protocols before the study is conducted [<xref ref-type="bibr" rid="c94">94</xref>].</p>
<p>This poses a challenge in developing models that generalize across populations. The present approach to designing personalized forecasting models relies on individualized labeled data, which demands precise temporal annotations for each future time window during training. While this may be feasible for small-scale datasets, it is not a long-term tenable solution for challenging tasks, such as seizure forecasting, or for patient-specific tuning with a large population of patients.</p>
</sec>
<sec id="s2e">
<label>2.5</label>
<title>AURA</title>
<p>This work proposes AURA, an adaptive, unlabeled, real-time and approximate approach to online learning, and its performance is demonstrated on patient-specific seizure forecasting. An overview of AURA as applied to seizure forecasting using several datasets procured across three different continents is illustrated in <xref rid="fig2" ref-type="fig">Figure 2</xref> (described in further detail in Methods). AURA consists of a real-time detection network and a forecasting network. The detection network classifies the onset of seizures in real-time with acceptable accuracy, and the forecasting network uses the output of the detection network as labels. This allows training to take place with the plethora of unlabeled data that is available, and pre-trained forecasting networks can be retrained to adapt to individual patients in order to learn patient-specific pre-ictal signatures.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><p>AURA Methodology as applied to seizure prediction. The detection model is trained using a U.S. dataset, and the prediction model is pre-trained with an EU dataset. The AURA patient-specific tuning phase assigns a replica of the pre-trained prediction model to each patient from the AU dataset, and all ground-truth labels are censored. The global detection model generates labels in real-time which are used to train the 10 patient-specific prediction models across 59 sessions of EEG recordings. Each patient has a personalized forecasting model that has been tuned to their pre-ictal signatures. To provide a measure of forecasting performance, the labels are declassified and compared to the predictions generated during the AURA patient-specific tuning process.</p></caption>
<graphic xlink:href="21264287v2_fig2.tif"/>
</fig>
<p>This approach is a narrow form of semi-supervised learning, where a pre-trained detection model achieves acceptable performance on a modestly sized dataset, while the forecasting network is updated using initially unlabeled data. Although inaccurately labeled data may deceive the forecasting network, AURA is implemented with the inductive prior that the forecasting network is unlikely to predict what fails detection. The irreducible error of the detection model must therefore be less than that of the prediction model, which is a reasonable assumption for temporally correlated prediction and detection. Performance degradation is compensated for by expanding the pool of usable data by the forecasting network for training.</p>
<p>We perform a pseudo-prospective study using AURA across 10 patients. The detection network is trained on patients from a U.S.-based hospital, which generates labels during the AURA online learning process on a sample of patients from the Royal Prince Alfred Hospital (RPAH) in Sydney, Australia. The AURA-trained forecasting networks show an average improvement in relative sensitivity by 14.30&#x0025;, and a reduction in false alarms by 19.61&#x0025;. A high-level overview of the AURA training process is depicted in <xref rid="fig2" ref-type="fig">Figure 2</xref>.</p>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Datasets</title>
<p>The seizure detection model is trained on the Temple University Hospital (TUH) seizure corpus [<xref ref-type="bibr" rid="c95">95</xref>] from the U.S., while the prediction model is pre-trained using the European (EU) EPILEPSIAE dataset [<xref ref-type="bibr" rid="c96">96</xref>]. The AURA self-learning process is applied to the Australian test set from the RPAH where all human-annotated labels have been censored [<xref ref-type="bibr" rid="c71">71</xref>], and each patient starts with the same pre-trained prediction model that adapts over the course of their multiple monitoring sessions. Upon completion of all sessions, the sequence of predictions generated by the forecasting network is compared to the uncensored ground truth to provide a performance measure of sensitivity and the number of false alarms. It is important to note that each prediction for a given time window takes place 30 minutes prior to the detection network generating a label that corresponds to the same window. This ensures our metric for performance using any given sample is reported before the forecasting network is updated on the basis of the same sample. This reduces the risk of future time leakage into our measure of performance, and emulates the operation of AURA in practice.</p>
<sec id="s3a">
<label>3.1</label>
<title>TUH dataset</title>
<p>The TUH dataset [<xref ref-type="bibr" rid="c95">95</xref>] is the world&#x2019;s largest open EEG database for seizure research. It includes 592 patients in the training dataset and 50 patients in the test set. Due to the lengthy sessions, much of the recordings that do not include seizure onset have been removed. The temporal discontinuity of the data and the lack of sufficient pre-ictal content means the TUH dataset is not suitable for use with AURA, and would not be representative of real-world usage. However, it is an ideal dataset for training the seizure detection model, despite the seizure and background information imbalance. The details are shown in <xref rid="tbl1" ref-type="table">Table 1</xref>, in which the total seizure and background duration in the Train/Dev datasets are 46.7 h and 752.3 h, respectively. Public access to TUH dataset is possible via online registration and application for access.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1.</label>
<caption><p>Summary of TUH dataset</p></caption>
<graphic xlink:href="21264287v2_tbl1.tif"/>
</table-wrap>
</sec>
<sec id="s3b">
<label>3.2</label>
<title>EPILEPSIAE dataset</title>
<p>The EPILEPSIAE dataset is the largest continuous EEG database in Europe which contains a total of 275 patients [<xref ref-type="bibr" rid="c96">96</xref>], among which, scalp-EEG recordings taken from 30 patients are made publicly available. Although this number is much less than the TUH dataset, the recordings of all patients are significantly longer in duration, ranging between [92.9, 266.4] hours. A summary of patient details are provided in <xref rid="tbl2" ref-type="table">Table 2</xref> with a total of 238 seizures across a 4604 h recording duration. This dataset is used to pre-train the seizure prediction model. Public access to EPILEPSIAE dataset is possible and requires payment, registration and application for access.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2.</label>
<caption><p>Summary of EPILEPSIAE scalp-EEG dataset.</p></caption>
<graphic xlink:href="21264287v2_tbl2.tif"/>
</table-wrap>
</sec>
<sec id="s3c">
<label>3.3</label>
<title>RPAH dataset</title>
<p>Our selection procedure is detailed in <xref rid="fig2" ref-type="fig">Fig. 2</xref>. There are a total of 212 adult patients with surface EEG recordings at the RPAH (Sydney, Australia), where 192 patients have reliable EEG recordings (excluding 15 patients that are lacking full electrode information, and other 5 patients that experience more than ten seizures/24 hours). Among the remaining potential subjects, 111 patients have seizures recorded. The pool of patients is narrowed to those with focal epilepsy who: i) do not experience generalized or secondary generalized seizures, as the initial source of each seizure varies, ii) experience at most three seizures per day on average to provide sufficient inter-ictal training time (<xref rid="fig3" ref-type="fig">Figure 3a</xref>), and iii) have at minimum three sessions (&#x007E; three days) recorded. 50 patients are assessed for eligibility; among these patients, 10 patients are used as subject-under-test for real-time AURA training across a total duration of 949.9 hours. Detailed information for each patient is provided in <xref rid="tbl3" ref-type="table">Table 3</xref>. Each patient starts with an identical pre-trained forecasting model, which is adapted during the AURA process.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3.</label>
<caption><p>Summary of RPAH selected dataset</p></caption>
<graphic xlink:href="21264287v2_tbl3.tif"/>
</table-wrap>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><p>Online learning procedure. (a) The prediction and detection models are initially pre-trained offline. The EEG recording from a given patient from the RPAH dataset is streamed as a real-time signal. It is used to generate a real-time detection (detection result) and a 30-minute forecast (prediction result). The detection result i) determines whether the sample is used to train the prediction model, and ii) is used as the target label for the prediction model outcome from 30-minutes prior. The red arrow between &#x2018;prediction results &#x2192;prepare training data&#x2019; indicates that prediction results can be used to govern the training of the prediction model; e.g., if the prediction results are aligned with the detection results, there is no need to update the prediction model. (b) Training data preparation. If the detection result indicates an inter-ictal or pre-ictal (within 30 minutes of onset) reading, online training of the prediction model is enabled. If the reading is ictal (within 5 minutes of the seizure onset), post-ictal (within 1.5 hours after seizure onset), online training is disabled as the signal is considered &#x2018;contaminated&#x2019;. Training is disabled during the first 30 minutes of the buffer due to the absence of corresponding forecast labels, and also during the final 30 minutes of the buffer as the prediction results fall outside of the range of the buffer. To ensure forecasted seizures in the final 30 minutes are still accounted for, incoming data sequentially replaces the oldest data in the buffer, emulating the function of a loop recorder. The minimum usable buffer size must account for the 30-minute pre-ictal duration, the 1.5-hour gap between ictal and inter-ictal period, 30-minutes at either end of the buffer, and the seizure duration itself. Our experiments use a 4 hour buffer length.</p></caption>
<graphic xlink:href="21264287v2_fig3.tif"/>
</fig>
<p>This study on the RPAH clinical data is approved by the local Research Ethics Committee. Ethics approval number <italic>X</italic> 19-0323-2019/STE16040 on <italic>Validating epileptic seizure detection, prediction and classification algorithms</italic> approved on 19 September 2019 by the NSW Local Health District (LHD) for implementation at the Comprehensive Epilepsy Services, Department of Neurology, The Royal Prince Alfred Hospital (RPAH). The RPAH data is not openly available to the public.</p>
</sec>
</sec>
<sec id="s4">
<label>4</label>
<title>Methods</title>
<sec id="s4a">
<label>4.1</label>
<title>Seizure prediction using AURA online learning</title>
<p>The online learning process using real-time streamed EEG data is shown in <xref rid="fig3" ref-type="fig">Figure 3</xref>. The surface EEG signal of a given patient is read into the buffer in <xref rid="fig3" ref-type="fig">Figure 3(a)</xref> once per second, where it is stored until it reaches <italic>T</italic> hours. In our implementation, our buffer was limited to <italic>T</italic> = 4 hours. Once the total duration of the recording exceeds <italic>T</italic>, new data is loaded into the buffer while earlier data is sequentially cleared which ensures positive forecasts in the final 30 mins of the buffer are accounted for. Concurrently, the two models generate detection and prediction outputs for batches of 12 s and 30 s signals, respectively. Once the buffer reaches <italic>T</italic> hours, the training data for the prediction model is prepared based on the detection result (weak label), as illustrated in <xref rid="fig3" ref-type="fig">Figure 3(b)</xref>. EEG signals associated with inter-ictal and pre-ictal (up to 30 mins) data is included in the online training process. Ictal and post-ictal (up to 1.5 hours) data is excluded from the online learning process, as generating forecasts at seizure onset would be based on contaminated signals. The first 30 mins of EEG recordings in the buffer is also excluded as there is no guarantee the patient is not in a post-ictal state, and also due to the absence of forecasted labels in the first 30 mins. The final 30 mins is excluded as there is no knowledge of the state of the patient, e.g., a seizure may occur right after the buffer. This &#x2018;right-censored&#x2019; recording is accounted for in subsequent steps once the buffer is updated over time, and the data becomes uncensored by shifting along the buffer&#x2019;s storage. Once the system has flagged a data sample for inclusion in the online training process, the weak label from the detection model is compared to the prediction result using a negative log-likelihood loss function, followed by a gradient calculation step via the backpropagation algorithm.</p>
<sec id="s4a1">
<label>4.1.1</label>
<title>Real-time signal pre-processing</title>
<p>Once the patient&#x2019;s real-time signal accumulates to a 12 second window, independent component analysis (ICA) [<xref ref-type="bibr" rid="c97">97</xref>] and short-time Fourier Transform (STFT) are applied to the EEG signal before being passed to the pre-trained seizure detection model. ICA is applied to decompose the signal into several statistically independent components. The electro-oculography (EOG) channel records eye movement information, and is physically proximate to the &#x2018;FP1&#x2019; and &#x2018;FP2&#x2019; EEG channels. Independent components of noise-prone EEG channels above a defined Pearson correlation threshold with the EOG channel are removed. STFT is then applied to the clean EEG waveform with a 250 sample window (1 second) length and 50&#x0025; overlap. The DC component of the transform is also removed as it is known to have no relation to seizure occurrences. The same technique is used on the real-time stream of EEG data for the prediction model, but using 30 second windows instead.</p>
</sec>
<sec id="s4a2">
<label>4.1.2</label>
<title>Seizure detection and prediction pre-trained models</title>
<p>All pre-training takes place offline, where the seizure detection model is trained using the TUH dataset (see <xref ref-type="sec" rid="s3a">Section 3.1</xref>) and the prediction model using the EPILEPSIAE dataset (see <xref ref-type="sec" rid="s3b">Section 3.2</xref>). The detection and prediction models both consist of convolutional long short-term memory (ConvLSTM) modules [<xref ref-type="bibr" rid="c98">98</xref>] combined with a pair of fully-connected layers, based on our previous work on seizure detection [<xref ref-type="bibr" rid="c71">71</xref>]. A summary of the architecture is provided in <xref rid="tbl4" ref-type="table">Table 4</xref>.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4.</label>
<caption><p>Network Architecture</p></caption>
<graphic xlink:href="21264287v2_tbl4.tif"/>
</table-wrap>
</sec>
<sec id="s4a3">
<label>4.1.3</label>
<title>Buffering</title>
<p>In our system, the buffer has a size of four hours of loop EEG recording. Specifically, every two hours, new EEG signals are added to the buffer and old signals are flushed in a first-in-first-out fashion. The buffer also contains timestamps of the EEG signals, which are used to prepare the training data. Note that the size of the buffer (four hours in this work) and the frequency of updating the buffer (two hours in this work) are subject to the available computation and memory resources. In other words, the online training process that uses the buffered data must finish before the next buffer update. This process is depicted in the illustration of the memory-limited buffer in <xref rid="fig3" ref-type="fig">Figure 3b</xref>.</p>
</sec>
<sec id="s4a4">
<label>4.1.4</label>
<title>Preparation of training data</title>
<p>The forecasting model&#x2019;s online training data preparation process commences once the buffer reaches <italic>T</italic>&#x2212; hours (<italic>T</italic> = 4 for our experiments). The feedforward detection model labels all suspicious instances of seizure onset. There are three possible cases that may arise in the 4-hour buffer. <bold>Case 1</bold>: if no seizure is labeled in the T-hour buffer duration, the entire duration of the buffer will be labeled inter-ictal (negative sample), other than the first and final 30 minutes. <bold>Case 2</bold>: if only one seizure is labeled in the <italic>T</italic>&#x2212; hour buffer, the 30 minutes preceding the seizure is labeled pre-ictal (positive sample), and any information that falls 1.5 hours away from the seizure onset within the buffer is labeled inter-ictal (negative sample). <bold>Case 3</bold>: if more than one seizure is marked during the <italic>T</italic>&#x2212; hour buffer, as before, a positive (pre-ictal) label is assigned 30 minutes preceding the seizure, and a negative (inter-ictal) label is assigned at least 1.5 hours away from all seizures. Once the entire buffer consists of labeled EEG information, only those with inter-ictal and pre-ictal labels are further pre-processed using 30 second time windows and STFT as described in 4.1.1.</p>
</sec>
<sec id="s4a5">
<label>4.1.5</label>
<title>Online training</title>
<p>During the real-time prediction phase, the prediction model is continuously updated based on the results of the detection labels. An adaptive batch size (varied from 5 to 32) is used, with the exact size based on the number of training samples, noting that even for a fixed buffer size, the criterion in <xref ref-type="sec" rid="s4a4">Section 4.1.4</xref> alters the number of samples flagged for training based on the occurrence and timing of seizure alarms. The Adam optimizer is used with a learning rate of 5 &#x00D7; 10<sup>&#x2212;8</sup>. The purpose of using a small learning rate and batch size is to avoid overfitting caused by the small amount of training data within the <italic>T</italic> &#x2212;hour buffer.</p>
</sec>
<sec id="s4a6">
<label>4.1.6</label>
<title>Post processing</title>
<p>During the online training process, raw prediction results are further post processed by calculating the moving average value during a given period, as shown on the <xref rid="fig4" ref-type="fig">Figure 4</xref>. In our experiments, we use a window of 30 minutes. A patient-specific threshold is applied, where if exceeded, an alarm is raised, predicting the patient will experience a seizure within the next hour.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><p>Real-time prediction comparison of a sample patient session without AURA learning (left figure) and with AURA learning (right figure). The dashed vertical red line represents the ground truth seizure onset time, and the solid green line is the weak label generated by the seizure detection model. In the above example, these two lines overlap which means the detection model correctly classified the actual seizure onset. The peak that precedes the seizure event corresponds to the prediction system forecasting a high probability that a seizure will occur within the next hour. The peak in AURA learning is far more distinguishable than that without AURA learning. The sample is taken from the second session of EEG recordings, resulting in different probabilities at <italic>t</italic> = 0 <italic>s</italic> as the model has undergone one session of AURA training.</p></caption>
<graphic xlink:href="21264287v2_fig4.tif"/>
</fig>
</sec>
<sec id="s4a7">
<label>4.1.7</label>
<title>Performance metrics</title>
<p>The sensitivity and number of false alarms per 24 hours are used to evaluate the performance of AURA in real-time seizure prediction for clinical usage. When the prediction results are greater than a specific patient-based threshold, one alarm is raised. The thresholds are chosen for each patient to achieve a balance between sensitivity and false alarm. An alarm is considered correct if it is raised within one hour of the actual seizure onset. Where multiple incorrect alarms occur within the same hour, they are collectively regarded as one false alarm. Note that during the training process, we define pre-ictal window of 30 minutes as it has empirically proven to be effective in training a seizure prediction system [<xref ref-type="bibr" rid="c99">99</xref>]. This temporal discrepancy arises because the timing of pre-ictal bio-marker onset remains an open question.The sensitivity of the prediction network is calculated by finding the number of correctly predicted seizures over the total number of seizures. The total number of false alarms over all recording sessions is normalized to calculate the number of false alarms per 24 hours. The time-in-warning is also calculated to show the amount of time each patient is on high alert, and is calculated by dividing the total time spent in a warning state following an alarm (TP&#x002B;FP) by the total recording time.</p>
<p>The prediction performance score is also calculated based on the sensitivity and false alarm, inspired by the score formula proposed in the Neureka 2020 Epilepsy Challenge [<xref ref-type="bibr" rid="c100">100</xref>]:
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="21264287v2_eqn1.gif"/></alternatives>
</disp-formula>
</p>
<p>As the predictor alarm is considered to last for an hour, the upper bound on false alarms per 24 hours is 24. The coefficients of the score formula are selected to fit the score within a range of 0 to 1. The Wilcoxon signed-rank statistic is used to evaluate the performance of the AURA system compared with the baseline. To account for both sensitivity and the number of false alarms, the <italic>p</italic>-value is calculated based on the patients&#x2019; prediction performance score to indicate the significance of performance improvement. The statistical significance threshold was set to 0.01.</p>
</sec>
</sec>
</sec>
<sec id="s5">
<label>5</label>
<title>Results</title>
<p>The following pseudo-prospective tests are applied to the RPAH patients:</p>
<list list-type="bullet">
<list-item><p><bold>Detection</bold>: The detection model is pre-trained on the TUH dataset and is pseudo-prospectively inference-only real-time tested on the RPAH dataset.</p></list-item>
<list-item><p><bold>Without AURA</bold>: The prediction model is pre-trained on the EPILEPSIAE dataset and is pseudo-prospectively inference-only real-time tested on the RPAH dataset.</p></list-item>
<list-item><p><bold>With AURA</bold>: The prediction model is pre-trained on the EPILEPSIAE dataset and is trained online using the AURA system, using labels that are simultaneously generated by the pre-trained seizure detection model (teacher model), and pseudo-prospectively inference-only real-time tested on the RPAH dataset.</p></list-item>
</list>
<p>The recordings of each patient from the RPAH dataset are pseudo-prospectively tested on the prediction model with AURA learning, by streaming their scalp-EEG readings into our system in real-time. Additionally, the same data is used on the pre-trained prediction model (on the EPILEPSIAE dataset) without AURA learning to identify the effectiveness of the proposed framework. As shown in Table. 5, all ten patients show varying degrees of improvement. Patients 1, 2, and 5 have significant improvement, as their sensitivity increases by 33.34&#x0025;, 25.00&#x0025;, and 14.28&#x0025;, respectively, while the number of FA/24hrs decrease by 0.62, 2.01, 0.90, respectively. The result for patient 3 is quite promising as the sensitivity is maintained at 100.00&#x0025; with approximately 2 FA/24hrs with AURA learning. The probability of the null hypothesis, that AURA does not improve the predictive performance score of the forecasting model without AURA, was calculated to be <italic>p</italic> = 0.003, which is smaller than 0.01. The average result across patients without AURA is 55.26&#x0025; sensitivity, 8.21 FA/24hrs, and across patients with AURA is 63.16&#x0025; sensitivity, and 6.60 FA/24hrs. These results are quite promising considering these are non-patient-specific continental generalized tests without human labeling. Other patients 4,6,7,8,9,10 show varying levels of FA/24hrs, but upon AURA training, there is a consistent decrease of both FA/24hrs and time warning, for a constant sensitivity.</p>
<p><xref rid="fig4" ref-type="fig">Fig. 4</xref> shows a sample taken from the second session of patient 2 experiencing focal epilepsy. The dashed vertical red line shows the ground truth seizure onset time, and the solid green line represents the weak label generated by the seizure detection model. In this case, the detection model correctly labels the actual seizure onset such that they are almost perfectly overlaid. The first row shows the raw prediction results, and the subsequent rows show a moving average of 5, 15, 30 minutes results, respectively. From the graph, we can see that without AURA, the inference-only test shows a very low probability of seizure occurrence, while with the AURA training process, the model becomes more sensitive to seizures by showing a higher probability of an alarm being raised prior to seizure onset. This is achieved concurrently with reducing the number of FA/24hrs for each patient.</p>
</sec>
<sec id="s6">
<label>6</label>
<title>Discussion</title>
<p>In this study, we present the AURA online learning system that uses patient-specific semi-supervision with a pair of temporally correlated tasks, and demonstrate that it consistently improves (or maintains) patient-specific seizure prediction results in terms of both sensitivity and the number of false alarms. Based on the average of ten patients&#x2019; results, the real-time seizure detection model outperforms the prediction model, which reaches an average of 73.68&#x0025; sensitivity, 4.17 FA/24hrs, and only 0.50&#x0025; time warning. Averaging the sensitivity and FA/24hrs across all patients shows the prediction model achieves 63.16&#x0025; sensitivity, 6.60 FA/24hrs with AURA learning, and 55.26&#x0025; sensitivity, 8.21 FA/24hrs without AURA learning. With the AURA system learning, the seizure prediction model moves closer to the performance of the detection model. We can see that the seizure prediction result improves across all ten patients with only several sessions per patient, with an absolute average improvement of sensitivity by 14.30&#x0025;, and an average reduction of 1.61 FA/24hrs. The duration a patient is in time warning also decreased by 16.67&#x0025;, which can reduce alarm fatigue in clinical settings.</p>
<sec id="s6a">
<label>6.1</label>
<title>Adapting to patient-specific biomarkers</title>
<p>In 2001, a five-patient clinical study was conducted that suggested epileptic seizures commence after a cascade of electrophysiological events which occur far earlier than clinical onset [<xref ref-type="bibr" rid="c101">101</xref>]. Our recent work [<xref ref-type="bibr" rid="c102">102</xref>] postulates that slowing inter-ictal activities are a potential biomarker for epileptic seizure prediction. The gradual improvement of results using AURA, to some extent, supports the hypothesis that patient-specific early warning signs are regularly raised before the seizure onset.</p>
<p>The three patients with the largest margin of improvement (1, 2 and 5) interestingly have focal epilepsy with different specific seizure foci: left occipital, right frontal and left temporal, respectively. Additional details are provided in <xref rid="tbl3" ref-type="table">Table 3</xref>. Thus, for patient-specific online training, if a biomarker exists and the detection model can continuously and correctly generate labels of seizure onsets, the forecasting model can theoretically learn to identify seizure prediction biomarkers for that specific patient.</p>
</sec>
<sec id="s6b">
<label>6.2</label>
<title>Dataset Generalization</title>
<p>AURA is demonstrated on an out-of-distribution dataset to what the detection and prediction models are pre-trained on, and is representative of different populations and recording practices. There are two instances where the system is required to generalize in our experimental system. Firstly, the detection model is trained on the U.S.-based TUH dataset but must generate labels for the Australian RPAH dataset. Secondly, the prediction model is initialized with pre-trained parameters from the European dataset, but performance is reported on the Australian patients. This means that when the prediction model reports (or misses) the <italic>first</italic> pre-ictal stage in the first session for any given patient, it will take another 30 minutes before the model is exposed to its first sample of seizure onset data from the RPAH dataset. Therefore, performance is reported 30 minutes prior to updating the model via backpropagation using that particular prediction in the calculation of the loss. This reduces the risk of future-time leakage.</p>
<p>The performance of the detection model for each patient is also reported in <xref rid="tbl5" ref-type="table">Table 5</xref>, where the average performance of detection is better than that of the prediction system with AURA learning. While this result is unsurprising, i.e., AURA is implemented on the basis that the upstream task of detection is easier than the downstream task of prediction, it is interesting to see AURA leads to better forecasting for patients 1 and 3 in both sensitivity and FA/24hrs than detection. The detection model evidently does not impose an upper-bound on performance, but this counterintuitive result may be attributed to the detection network struggling to generalize. For example, if pre-training of the detection network were to take place on the same RPAH cohort, then the irreducible error of the detection system would likely be less than that of the prediction network, even with AURA learning. This is consistent across all ten patients, who experience seizure prediction performance that moves closer to that of detection. The patients show varying levels of improvement, and more patient tests and experiments from a wider variety of seizures types must be implemented to instill higher confidence of the proposed system.</p>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5.</label>
<caption><p>Continental generalization pseudo-prospective results comparison</p></caption>
<graphic xlink:href="21264287v2_tbl5.tif"/>
</table-wrap>
</sec>
</sec>
<sec id="s7">
<label>7</label>
<title>Conclusion</title>
<p>Human labeling of EEG data is an expensive and laborious process. Our approach to semi-supervised learning using the proposed AURA system shows a potential direction in overcoming the challenges and costs of individualized labeling to deploying patient-specific models that adapt to patient-specific bio-markers. AURA shows robustness to the use of prediction and detection models that are pre-trained on out-of-distribution data, and beyond precision medicine applications in seizure detection, AURA is a potential way to harness the multitude of unlabeled time-series clinical data that remains underutilized in deep learning. The RPAH data set is limited in the number of sessions (and therefore, ictal events) per patients which adds to the difficulty of training AURA, but we successfully demonstrated an improvement for each tested patient despite this constraint, all without the use of clinician labels. Although more experiments need to be conducted to verify the efficacy of our proposed system on wider populations and broader range of seizure types, our early demonstration shows promising utility for real-world clinical utility.</p>
</sec>
</body>
<back>
<sec sec-type="data-availability">
<title>Data Availability</title>
<p>The Temple University Hospital dataset is publicly available at <ext-link ext-link-type="uri" xlink:href="https://www.isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml">https://www.isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml</ext-link>. The training on the publicly available TUH dataset provides readers with sufficient level of ability to independently confirm some of the results reported. The EPILEPSIAE dataset is available at cost via <ext-link ext-link-type="uri" xlink:href="http://www.epilepsiae.eu/project_outputs/european_database_on_epilepsy">http://www.epilepsiae.eu/project_outputs/european_database_on_epilepsy</ext-link>. The Royal Prince Alfred Hospital was used under ethics Review Board approval for our use only.</p>
<p>
<ext-link ext-link-type="uri" xlink:href="https://www.isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml">https://www.isip.piconepress.com/projects/tuh_eeg/html/downloads.shtml</ext-link>
</p>
</sec>
<ack>
<label>8</label>
<title>Acknowledgement</title>
<p>The authors would like to thank Ms. Christina Maher at the School of Biomedical Engineering, Faculty of Engineering, The University of Sydney for her contribution on our ethics process and revisions.</p>
</ack>
<sec id="s8">
<label>9</label>
<title>Competing interests</title>
<p>NDT and OK are shareholders in BrainConnect Pty Ltd, an Australian startup developing physiological and neurophysiological and interventional solutions for a range of neurological disorders. OK is a shareholder and currently the Managing Director at BrainConnect Pty Ltd. A provisional patent (Australian Provisional Patent Application No. 2021902957) related to the application of AURA to physiological signal forecasting and stimulation has been filed.</p>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Topol</surname>, <given-names>E. J.</given-names></string-name> <article-title>High-performance medicine: the convergence of human and artificial intelligence</article-title>. <source>Nat. Medicine</source> <volume>25</volume>, <fpage>44</fpage>&#x2013;<lpage>56</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Lee</surname>, <given-names>C. H.</given-names></string-name> &#x0026; <string-name><surname>Yoon</surname>, <given-names>H.-J.</given-names></string-name> <article-title>Medical big data: promise and challenges</article-title>. <source>Kidney Res. Clin. Pract</source>. <volume>36</volume>, <fpage>3</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Futoma</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Simons</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Panch</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Doshi-Velez</surname>, <given-names>F.</given-names></string-name> &#x0026; <string-name><surname>Celi</surname>, <given-names>L. A.</given-names></string-name> <article-title>The myth of generalisability in clinical research and machine learning in health care</article-title>. <source>The Lancet Digit. Heal</source>. <volume>2</volume>, <fpage>e489</fpage>&#x2013;<lpage>e492</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Brinkmann</surname>, <given-names>B. H.</given-names></string-name> <etal>et al.</etal> <article-title>Seizure diaries and forecasting with wearables: Epilepsy monitoring outside the clinic</article-title>. <source>Front. Neurol</source>. <volume>12</volume> (<year>2021</year>).</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Nasseri</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Non-invasive wearable seizure detection using long&#x2013;short&#x2013;term memory networks with transfer learning</article-title>. <source>J. Neural Eng</source>. <volume>18</volume>, <fpage>056017</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="other"><string-name><surname>Golmohammadi</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>The TUH EEG seizure corpus</article-title>. <source>Proc. Am. Clin. Neurophysiol. Soc. Annu. Meet</source>. 1 (<year>2017</year>).</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Moody</surname>, <given-names>G. B.</given-names></string-name> &#x0026; <string-name><surname>Mark</surname>, <given-names>R. G.</given-names></string-name> <article-title>The impact of the MIT-BIH arrhythmia database</article-title>. <source>IEEE Eng. Medicine Biol. Mag</source>. <volume>20</volume>, <fpage>45</fpage>&#x2013;<lpage>50</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Truong</surname>, <given-names>N. D.</given-names></string-name> <etal>et al.</etal> <article-title>Epileptic seizure forecasting with generative adversarial networks</article-title>. <source>IEEE Access</source> <volume>7</volume>, <fpage>143999</fpage>&#x2013;<lpage>144009</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="website"><string-name><surname>Baldassano</surname>, <given-names>S. N.</given-names></string-name>, <string-name><surname>Litt</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Wulsin</surname>, <given-names>D.</given-names></string-name> &#x0026; <string-name><surname>Fox</surname>, <given-names>E.</given-names></string-name> <source>Real-time seizure prediction informed by hidden Markov model event states</source>. <ext-link ext-link-type="uri" xlink:href="https://patents.google.com/patent/US10245431B2">https://patents.google.com/patent/US10245431B2</ext-link> (<year>2019</year>). US Patent 10,245,431 B2.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Ramgopal</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title>Seizure detection, seizure prediction, and closed-loop warning systems in epilepsy</article-title>. <source>Epilepsy &#x0026; behavior</source> <volume>37</volume>, <fpage>291</fpage>&#x2013;<lpage>307</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Scudder</surname>, <given-names>H.</given-names></string-name> <article-title>Probability of error of some adaptive pattern-recognition machines</article-title>. <source>IEEE Transactions on Inf. Theory</source> <volume>11</volume>, <fpage>363</fpage>&#x2013;<lpage>371</lpage> (<year>1965</year>).</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="other"><string-name><surname>Chapelle</surname>, <given-names>O.</given-names></string-name>, <string-name><surname>Scholkopf</surname>, <given-names>B.</given-names></string-name> &#x0026; <string-name><surname>Zien</surname>, <given-names>A.</given-names></string-name> <article-title>Semi-supervised learning. 2006</article-title>. <source>Cambridge, Massachusettes: The MIT Press. View Article</source> (<year>2006</year>).</mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="journal"><string-name><surname>Kirkpatrick</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal> <article-title>Overcoming catastrophic forgetting in neural networks</article-title>. <source>Proc. Natl. Acad. Sci</source>. <volume>114</volume>, <fpage>3521</fpage>&#x2013;<lpage>3526</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="journal"><string-name><surname>Little</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title>Adaptive deep brain stimulation for Parkinson&#x2019;s disease demonstrates reduced speech side effects compared to conventional stimulation in the acute setting</article-title>. <source>J. Neurol. Neurosurg. &#x0026; Psychiatry</source> <volume>87</volume>, <fpage>1388</fpage>&#x2013;<lpage>1389</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="website"><string-name><surname>Giftakis</surname>, <given-names>J. E.</given-names></string-name>, <string-name><surname>Wu</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Nelson</surname>, <given-names>D. E.</given-names></string-name> <source>Seizure probability metrics</source>. <ext-link ext-link-type="uri" xlink:href="https://patents.google.com/patent/US8812098B2">https://patents.google.com/patent/US8812098B2</ext-link> (<year>2014</year>). US Patent 8,812,098 B2.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="website"><string-name><surname>Denison</surname>, <given-names>T. J.</given-names></string-name> &#x0026; <string-name><surname>Santa</surname>, <given-names>W. A.</given-names></string-name> <source>Seizure prediction</source>. <ext-link ext-link-type="uri" xlink:href="https://patents.google.com/patent/US9788750B2">https://patents.google.com/patent/US9788750B2</ext-link> (<year>2017</year>). US Patent 9,788,750 B2.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="website"><string-name><surname>Liao</surname>, <given-names>W.</given-names></string-name> <source>Identifying seizures using heart rate decrease</source>. <ext-link ext-link-type="uri" xlink:href="https://patents.google.com/patent/US8725239B2">https://patents.google.com/patent/US8725239B2</ext-link> (<year>2014</year>). US Patent 8,725,239 B2.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="website"><string-name><surname>Snyder</surname>, <given-names>D.</given-names></string-name> &#x0026; <string-name><surname>Leyde</surname>, <given-names>K. W.</given-names></string-name> <source>Methods and systems for characterizing and generating a patient-specific seizure advisory system</source>. <ext-link ext-link-type="uri" xlink:href="https://patents.google.com/patent/US20080208074A1">https://patents.google.com/patent/US20080208074A1</ext-link> (<year>2008</year>). US Patent 2008/0208074 A1, Abandoned.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="website"><string-name><surname>Starr</surname>, <given-names>P. A.</given-names></string-name>, <string-name><surname>Hemptinne</surname>, <given-names>C. d.</given-names></string-name>, <string-name><surname>Ostrem</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Swann</surname>, <given-names>N.</given-names></string-name> <source>Methods and systems for treating neurological movement disorders</source>. <ext-link ext-link-type="uri" xlink:href="https://patents.google.com/patent/US9295838B2">https://patents.google.com/patent/US9295838B2</ext-link> (<year>2016</year>). US Patent 9,295,838 B2.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="journal"><string-name><surname>Meidahl</surname>, <given-names>A. C.</given-names></string-name> <etal>et al.</etal> <article-title>Adaptive deep brain stimulation for movement disorders: the long road to clinical therapy</article-title>. <source>Mov. Disord</source>. <volume>32</volume>, <fpage>810</fpage>&#x2013;<lpage>819</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="other"><string-name><surname>Xiao</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Iasemidis</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Wong</surname>, <given-names>S.</given-names></string-name> &#x0026; <string-name><surname>Chaovalitwongse</surname>, <given-names>W. A.</given-names></string-name> <article-title>An adaptive pattern learning framework to personalize online seizure prediction</article-title>. <source>IEEE Transactions on Big Data</source> (<year>2017</year>).</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="journal"><string-name><surname>Gilron</surname>, <given-names>R.</given-names></string-name> <etal>et al.</etal> <article-title>Long-term wireless streaming of neural recordings for circuit discovery and adaptive stimulation in individuals with Parkinson&#x2019;s disease</article-title>. <source>Nat. Biotechnol</source>. <volume>39</volume>, <fpage>1078</fpage>&#x2013;<lpage>1085</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="journal"><string-name><surname>Chen</surname>, <given-names>W.</given-names></string-name> <etal>et al.</etal> <article-title>The role of large-scale data infrastructure in developing next-generation deep brain stimulation therapies</article-title>. <source>Front. Hum. Neurosci</source>. <volume>15</volume> (<year>2021</year>).</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="other"><string-name><surname>Sladky</surname>, <given-names>V.</given-names></string-name> <etal>et al.</etal> <article-title>Distributed brain co-processor for neurophysiologic tracking and adaptive stimulation: Application to drug resistant epilepsy</article-title>. <source>bioRxiv preprint</source> 2021.03.08.434476 (<year>2021</year>).</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Stanslaski</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title>A chronically implantable neural coprocessor for investigating the treatment of neurological disorders</article-title>. <source>IEEE Transactions on Biomed. Circuits Syst</source>. <volume>12</volume>, <fpage>1230</fpage>&#x2013;<lpage>1245</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="journal"><string-name><surname>Kremen</surname>, <given-names>V.</given-names></string-name> <etal>et al.</etal> <article-title>Integrating brain implants with local and distributed computing devices: a next generation epilepsy management system</article-title>. <source>IEEE J. Transl. Eng. Heal. Medicine</source> <volume>6</volume>, <fpage>1</fpage>&#x2013;<lpage>12</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="other"><string-name><surname>Mivalt</surname>, <given-names>F.</given-names></string-name> <etal>et al.</etal> <article-title>Electrical brain stimulation and continuous behavioral state tracking in ambulatory humans</article-title>. <source>medRxiv preprint</source> 2021.08.10.21261645 (<year>2021</year>).</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="website"><string-name><surname>Kamousi</surname>, <given-names>B.</given-names></string-name> <etal>et al.</etal> <source>Systems and methods for seizure prediction and detection</source>. <ext-link ext-link-type="uri" xlink:href="https://patents.google.com/patent/US10743809B1">https://patents.google.com/patent/US10743809B1</ext-link> (<year>2014</year>). US Patent 10,743,809 B1.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Karuppiah Ramachandran</surname>, <given-names>V. R.</given-names></string-name>, <string-name><surname>Alblas</surname>, <given-names>H. J.</given-names></string-name>, <string-name><surname>Le</surname>, <given-names>D. V.</given-names></string-name> &#x0026; <string-name><surname>Meratnia</surname>, <given-names>N.</given-names></string-name> <article-title>Towards an online seizure advisory system&#x2014;an adaptive seizure prediction framework using active learning heuristics</article-title>. <source>Sensors</source> <volume>18</volume>, <fpage>1698</fpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="website"><string-name><surname>Harrer</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Kiral-Kornek</surname>, <given-names>F. I.</given-names></string-name>, <string-name><surname>Mashford</surname>, <given-names>B. S.</given-names></string-name>, <string-name><surname>Subhrajit</surname>, <given-names>R.</given-names></string-name> &#x0026; <string-name><surname>Saha</surname>, <given-names>S.</given-names></string-name> <source>Seizure detection, prediction and prevention using neurostimulation technology and deep neural network</source>. <ext-link ext-link-type="uri" xlink:href="https://patents.google.com/patent/US10596377B2">https://patents.google.com/patent/US10596377B2</ext-link> (<year>2020</year>). US Patent 10,596,377 B2.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Stirling</surname>, <given-names>R. E.</given-names></string-name> <etal>et al.</etal> <article-title>Seizure forecasting using a novel sub-scalp ultra-long term EEG monitoring system</article-title>. <source>Front. Neurol</source>. <volume>12</volume>, <fpage>713794</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="website"><string-name><surname>Pepin</surname>, <given-names>B. M.</given-names></string-name> &#x0026; <string-name><surname>Kotzev</surname>, <given-names>M. T.</given-names></string-name> <source>Neuromodulation therapy monitoring and continuous therapy reprogramming</source>. <ext-link ext-link-type="uri" xlink:href="https://patents.google.com/patent/US20210052901A1">https://patents.google.com/patent/US20210052901A1</ext-link> (<year>2021</year>). US Patent 2021/0052901 A1, Pending.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="other"><string-name><surname>Park</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Jeon</surname>, <given-names>D.</given-names></string-name> <article-title>A 65 nm 236.5 nj/classification neuromorphic processor with 7.5&#x0025; energy overhead on-chip learning using direct spike-only feedback</article-title>. In <source>IEEE International Solid-State Circuits Conference-(ISSCC)</source>, <fpage>140</fpage>&#x2013;<lpage>142</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="journal"><string-name><surname>Bohnstingl</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Scherr</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Pehle</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Meier</surname>, <given-names>K.</given-names></string-name> &#x0026; <string-name><surname>Maass</surname>, <given-names>W.</given-names></string-name> <article-title>Neuromorphic hardware learns to learn</article-title>. <source>Front. Neurosci</source>. <volume>13</volume>, <fpage>483</fpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="book"><string-name><surname>Cl&#x00E9;ment</surname>, <given-names>C.</given-names></string-name> <source>Brain-Computer Interface Technologies</source> (<publisher-name>Springer</publisher-name>, <year>2019</year>).</mixed-citation></ref>
<ref id="c36"><label>36.</label><mixed-citation publication-type="journal"><string-name><surname>Karageorgos</surname>, <given-names>I.</given-names></string-name> <etal>et al.</etal> <article-title>Balancing specialized versus flexible computation in brain&#x2013;computer interfaces</article-title>. <source>IEEE Micro</source> <volume>41</volume>, <fpage>87</fpage>&#x2013;<lpage>94</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c37"><label>37.</label><mixed-citation publication-type="journal"><string-name><surname>Bronstein</surname>, <given-names>J. M.</given-names></string-name> <etal>et al.</etal> <article-title>Deep brain stimulation for parkinson disease: an expert consensus and review of key issues</article-title>. <source>Arch. Neurol</source>. <volume>68</volume>, <fpage>165</fpage>&#x2013;<lpage>165</lpage> (<year>2011</year>).</mixed-citation></ref>
<ref id="c38"><label>38.</label><mixed-citation publication-type="journal"><string-name><surname>Swann</surname>, <given-names>N. C.</given-names></string-name> <etal>et al.</etal> <article-title>Adaptive deep brain stimulation for parkinson&#x2019;s disease using motor cortex sensing</article-title>. <source>J. Neural Eng</source>. <volume>15</volume>, <fpage>046006</fpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c39"><label>39.</label><mixed-citation publication-type="journal"><string-name><surname>da Silva Castanheira</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Orozco Perez</surname>, <given-names>H. D.</given-names></string-name>, <string-name><surname>Misic</surname>, <given-names>B.</given-names></string-name> &#x0026; <string-name><surname>Baillet</surname>, <given-names>S.</given-names></string-name> <article-title>Brief segments of neurophysiological activity enable individual differentiation</article-title>. <source>Nat. Commun</source>. <volume>12</volume>, <fpage>1</fpage>&#x2013;<lpage>11</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c40"><label>40.</label><mixed-citation publication-type="journal"><string-name><surname>Shah</surname>, <given-names>P.</given-names></string-name> <etal>et al.</etal> <article-title>Characterizing the role of the structural connectome in seizure dynamics</article-title>. <source>Brain</source> <volume>142</volume>, <fpage>1955</fpage>&#x2013;<lpage>1972</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c41"><label>41.</label><mixed-citation publication-type="other"><string-name><surname>Schroeder</surname>, <given-names>G. M.</given-names></string-name> <etal>et al.</etal> <article-title>Seizure pathways and seizure durations can vary independently within individual patients with focal epilepsy</article-title>. <source>arXiv preprint</source> 2109.06672 (<year>2021</year>).</mixed-citation></ref>
<ref id="c42"><label>42.</label><mixed-citation publication-type="journal"><string-name><surname>Karoly</surname>, <given-names>P. J.</given-names></string-name> <etal>et al.</etal> <article-title>Multiday cycles of heart rate are associated with seizure likelihood: An observational cohort study</article-title>. <source>EBioMedicine</source> <volume>72</volume>, <fpage>103619</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c43"><label>43.</label><mixed-citation publication-type="journal"><string-name><surname>Karoly</surname>, <given-names>P. J.</given-names></string-name> <etal>et al.</etal> <article-title>Cycles in epilepsy</article-title>. <source>Nat. Rev. Neurol</source>. <volume>17</volume>, <fpage>267</fpage>&#x2013;<lpage>284</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c44"><label>44.</label><mixed-citation publication-type="journal"><string-name><surname>Viana</surname>, <given-names>P. F.</given-names></string-name> <etal>et al.</etal> <article-title>230 days of ultra long-term subcutaneous EEG: seizure cycle analysis and comparison to patient diary</article-title>. <source>Annals Clin. Transl. Neurol</source>. <volume>8</volume>, <fpage>288</fpage>&#x2013;<lpage>293</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c45"><label>45.</label><mixed-citation publication-type="journal"><string-name><surname>Stirling</surname>, <given-names>R. E.</given-names></string-name>, <string-name><surname>Cook</surname>, <given-names>M. J.</given-names></string-name>, <string-name><surname>Grayden</surname>, <given-names>D. B.</given-names></string-name> &#x0026; <string-name><surname>Karoly</surname>, <given-names>P. J.</given-names></string-name> <article-title>Seizure forecasting and cyclic control of seizures</article-title>. <source>Epilepsia</source> <volume>62</volume>, <fpage>S2</fpage>&#x2013;<lpage>S14</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c46"><label>46.</label><mixed-citation publication-type="journal"><string-name><surname>Karoly</surname>, <given-names>P. J.</given-names></string-name> <etal>et al.</etal> <article-title>Interictal spikes and epileptic seizures: their relationship and underlying rhythmicity</article-title>. <source>Brain</source> <volume>139</volume>, <fpage>1066</fpage>&#x2013;<lpage>1078</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c47"><label>47.</label><mixed-citation publication-type="journal"><string-name><surname>Denison</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal> <article-title>A 2M-5W 100 nV/rtHz chopper-stabilized instrumentation amplifier for chronic measurement of neural field potentials</article-title>. <source>IEEE J. Solid-State Circuits</source> <volume>42</volume>, <fpage>2934</fpage>&#x2013;<lpage>2945</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c48"><label>48.</label><mixed-citation publication-type="journal"><string-name><surname>Denison</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Santa</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Molnar</surname>, <given-names>G.</given-names></string-name> &#x0026; <string-name><surname>Miesel</surname>, <given-names>K.</given-names></string-name> <article-title>Micropower sensors for neuroprosthetics</article-title>. <source>Proc. IEEE SENSORS</source> <fpage>1105</fpage>&#x2013;<lpage>1108</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c49"><label>49.</label><mixed-citation publication-type="other"><string-name><surname>Thompson</surname>, <given-names>N. C.</given-names></string-name>, <string-name><surname>Greenewald</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Lee</surname>, <given-names>K.</given-names></string-name> &#x0026; <string-name><surname>Manso</surname>, <given-names>G. F.</given-names></string-name> <article-title>The computational limits of deep learning</article-title>. <source>arXiv preprint</source> 2007.05558 (<year>2020</year>).</mixed-citation></ref>
<ref id="c50"><label>50.</label><mixed-citation publication-type="website"><string-name><surname>Amodei</surname>, <given-names>D.</given-names></string-name> &#x0026; <string-name><surname>Hernandez</surname>, <given-names>D.</given-names></string-name> <source>AI and compute</source>. <ext-link ext-link-type="uri" xlink:href="https://openai.com/blog/ai-and-compute">https://openai.com/blog/ai-and-compute</ext-link> (<year>2018</year>).</mixed-citation></ref>
<ref id="c51"><label>51.</label><mixed-citation publication-type="other"><string-name><surname>Brown</surname>, <given-names>T. B.</given-names></string-name> <etal>et al.</etal> <article-title>Language models are few-shot learners</article-title>. <source>arXiv preprint</source> 2005.14165 (<year>2020</year>).</mixed-citation></ref>
<ref id="c52"><label>52.</label><mixed-citation publication-type="journal"><string-name><surname>Dhar</surname>, <given-names>P.</given-names></string-name> <article-title>The carbon impact of artificial intelligence</article-title>. <source>Nat. Mach. Intell</source>. <volume>2</volume>, <fpage>423</fpage>&#x2013;<lpage>5</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c53"><label>53.</label><mixed-citation publication-type="other"><string-name><surname>Anthony</surname>, <given-names>L. F. W.</given-names></string-name>, <string-name><surname>Kanding</surname>, <given-names>B.</given-names></string-name> &#x0026; <string-name><surname>Selvan</surname>, <given-names>R.</given-names></string-name> <article-title>Carbontracker: Tracking and predicting the carbon footprint of training deep learning models</article-title>. <source>arXiv preprint</source> 2007.03051 (<year>2020</year>).</mixed-citation></ref>
<ref id="c54"><label>54.</label><mixed-citation publication-type="other"><string-name><surname>Azimi</surname>, <given-names>I.</given-names></string-name> <etal>et al.</etal> <article-title>Empowering healthcare IoT systems with hierarchical edge-based deep learning</article-title>. In <source>Proc. IEEE/ACM International Conference on Connected Health: Applications, Systems and Engineering Technologies</source>, <fpage>63</fpage>&#x2013;<lpage>68</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c55"><label>55.</label><mixed-citation publication-type="journal"><string-name><surname>Deng</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Han</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Shi</surname>, <given-names>L.</given-names></string-name> &#x0026; <string-name><surname>Xie</surname>, <given-names>Y.</given-names></string-name> <article-title>Model compression and hardware acceleration for neural networks: A comprehensive survey</article-title>. <source>Proc. The IEEE</source> <volume>108</volume>, <fpage>485</fpage>&#x2013;<lpage>532</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c56"><label>56.</label><mixed-citation publication-type="journal"><string-name><surname>Sze</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Y.-H.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>T.-J.</given-names></string-name> &#x0026; <string-name><surname>Emer</surname>, <given-names>J. S.</given-names></string-name> <article-title>Efficient processing of deep neural networks: A tutorial and survey</article-title>. <source>Proc. The IEEE</source> <volume>105</volume>, <fpage>2295</fpage>&#x2013;<lpage>2329</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c57"><label>57.</label><mixed-citation publication-type="journal"><string-name><surname>Davies</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Loihi: A neuromorphic manycore processor with on-chip learning</article-title>. <source>IEEE Micro</source> <volume>38</volume>, <fpage>82</fpage>&#x2013;<lpage>99</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c58"><label>58.</label><mixed-citation publication-type="journal"><string-name><surname>Merolla</surname>, <given-names>P. A.</given-names></string-name> <etal>et al.</etal> <article-title>A million spiking-neuron integrated circuit with a scalable communication network and interface</article-title>. <source>Science</source> <volume>345</volume>, <fpage>668</fpage>&#x2013;<lpage>673</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c59"><label>59.</label><mixed-citation publication-type="other"><string-name><surname>Eshraghian</surname>, <given-names>J. K.</given-names></string-name> <etal>et al.</etal> <article-title>Training spiking neural networks using lessons from deep learning</article-title>. <source>arXiv preprint</source> 2109.12894 (<year>2021</year>).</mixed-citation></ref>
<ref id="c60"><label>60.</label><mixed-citation publication-type="journal"><string-name><surname>Roy</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Jaiswal</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Panda</surname>, <given-names>P.</given-names></string-name> <article-title>Towards spike-based machine intelligence with neuromorphic computing</article-title>. <source>Nature</source> <volume>575</volume>, <fpage>607</fpage>&#x2013;<lpage>617</lpage> (<year>2019</year>).</mixed-citation></ref>
<ref id="c61"><label>61.</label><mixed-citation publication-type="journal"><string-name><surname>Sharifshazileh</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Burelo</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Sarnthein</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Indiveri</surname>, <given-names>G.</given-names></string-name> <article-title>An electronic neuromorphic system for real-time detection of high frequency oscillations (HFO) in intracranial EEG</article-title>. <source>Nat. Commun</source>. <volume>12</volume>, <fpage>1</fpage>&#x2013;<lpage>14</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c62"><label>62.</label><mixed-citation publication-type="other"><string-name><surname>Griewank</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Walther</surname>, <given-names>A.</given-names></string-name> <source>Evaluating derivatives: principles and techniques of algorithmic differentiation</source> (Society for Industrial and Applied Mathematics (SIAM), <year>2008</year>).</mixed-citation></ref>
<ref id="c63"><label>63.</label><mixed-citation publication-type="journal"><string-name><surname>Rajna</surname>, <given-names>P.</given-names></string-name> <etal>et al.</etal> <article-title>Hungarian multicentre epidemiologic study of the warning and initial symptoms (prodrome, aura) of epileptic seizures</article-title>. <source>Seizure</source> <volume>6</volume>, <fpage>361</fpage>&#x2013;<lpage>368</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c64"><label>64.</label><mixed-citation publication-type="other"><string-name><surname>Viglione</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Ordon</surname>, <given-names>V.</given-names></string-name> &#x0026; <string-name><surname>Risch</surname>, <given-names>F.</given-names></string-name> <article-title>A methodology for detecting ongoing changes in the EEG prior to clinical seizures</article-title>. <source>21st West. Inst. on Epilepsy</source> <fpage>27</fpage>&#x2013;<lpage>8</lpage> (<year>1970</year>).</mixed-citation></ref>
<ref id="c65"><label>65.</label><mixed-citation publication-type="journal"><string-name><surname>Litt</surname>, <given-names>B.</given-names></string-name> &#x0026; <string-name><surname>Echauz</surname>, <given-names>J.</given-names></string-name> <article-title>Prediction of epileptic seizures</article-title>. <source>The Lancet Neurol</source>. <volume>1</volume>, <fpage>22</fpage>&#x2013;<lpage>30</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c66"><label>66.</label><mixed-citation publication-type="journal"><string-name><surname>Badawy</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Macdonell</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Jackson</surname>, <given-names>G.</given-names></string-name> &#x0026; <string-name><surname>Berkovic</surname>, <given-names>S.</given-names></string-name> <article-title>The peri-ictal state: cortical excitability changes within 24 h of a seizure</article-title>. <source>Brain</source> <volume>132</volume>, <fpage>1013</fpage>&#x2013;<lpage>1021</lpage> (<year>2009</year>).</mixed-citation></ref>
<ref id="c67"><label>67.</label><mixed-citation publication-type="journal"><string-name><surname>Baumgartner</surname>, <given-names>C.</given-names></string-name> <etal>et al.</etal> <article-title>Preictal SPECT in temporal lobe epilepsy: regional cerebral blood flow is increased prior to electroencephalography-seizure onset</article-title>. <source>J. Nucl. Medicine</source> <volume>39</volume>, <fpage>978</fpage>&#x2013;<lpage>981</lpage> (<year>1998</year>).</mixed-citation></ref>
<ref id="c68"><label>68.</label><mixed-citation publication-type="journal"><string-name><surname>Weinand</surname>, <given-names>M. E.</given-names></string-name> <etal>et al.</etal> <article-title>Cerebral blood flow and temporal lobe epileptogenicity</article-title>. <source>J. Neurosurg</source>. <volume>86</volume>, <fpage>226</fpage>&#x2013;<lpage>232</lpage> (<year>1997</year>).</mixed-citation></ref>
<ref id="c69"><label>69.</label><mixed-citation publication-type="other"><string-name><surname>Litt</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>D&#x2019;Alessandro</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Esteller</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Echauz</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Vachtsevanos</surname>, <given-names>G.</given-names></string-name> <article-title>Translating seizure detection, prediction and brain stimulation into implantable devices for epilepsy</article-title>. <source>Proc. IEEE EMBS Conf. on Neural Eng</source>. <fpage>485</fpage>&#x2013;<lpage>488</lpage> (<year>2003</year>).</mixed-citation></ref>
<ref id="c70"><label>70.</label><mixed-citation publication-type="journal"><string-name><surname>Mormann</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Andrzejak</surname>, <given-names>R. G.</given-names></string-name>, <string-name><surname>Elger</surname>, <given-names>C. E.</given-names></string-name> &#x0026; <string-name><surname>Lehnertz</surname>, <given-names>K.</given-names></string-name> <article-title>Seizure prediction: The long and winding road</article-title>. <source>Brain</source> <volume>130</volume>, <fpage>314</fpage>&#x2013;<lpage>333</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c71"><label>71.</label><mixed-citation publication-type="other"><string-name><surname>Yang</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Truong</surname>, <given-names>N. D.</given-names></string-name>, <string-name><surname>Maher</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Nikpour</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Kavehei</surname>, <given-names>O.</given-names></string-name> <article-title>Continental generalization of an AI system for clinical seizure recognition</article-title>. <source>arXiv preprint</source> 2103.10900 (<year>2021</year>).</mixed-citation></ref>
<ref id="c72"><label>72.</label><mixed-citation publication-type="other"><string-name><surname>Yang</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal> <article-title>A multimodal ai system for out-of-distribution generalization of seizure detection</article-title>. <source>bioRxiv preprint</source> 2021.07.02.450974 (<year>2021</year>).</mixed-citation></ref>
<ref id="c73"><label>73.</label><mixed-citation publication-type="journal"><string-name><surname>Roy</surname>, <given-names>S.</given-names></string-name> <etal>et al.</etal> <article-title>Evaluation of artificial intelligence systems for assisting neurologists with fast and accurate annotations of scalp electroencephalography data</article-title>. <source>EBioMedicine</source> <volume>66</volume>, <fpage>103275</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c74"><label>74.</label><mixed-citation publication-type="journal"><string-name><surname>Kassahun</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal> <article-title>Automatic classification of epilepsy types using ontology-based and genetics-based machine learning</article-title>. <source>Artif. Intell. Medicine</source> <volume>61</volume>, <fpage>79</fpage>&#x2013;<lpage>88</lpage> (<year>2014</year>).</mixed-citation></ref>
<ref id="c75"><label>75.</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname>, <given-names>Y.</given-names></string-name> <etal>et al.</etal> <article-title>Mechanisms underlying different onset patterns of focal seizures</article-title>. <source>PLoS Comput. Biol</source>. <volume>13</volume>, <fpage>e1005475</fpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c76"><label>76.</label><mixed-citation publication-type="journal"><string-name><surname>Minasyan</surname>, <given-names>G. R.</given-names></string-name>, <string-name><surname>Chatten</surname>, <given-names>J. B.</given-names></string-name>, <string-name><surname>Chatten</surname>, <given-names>M. J.</given-names></string-name> &#x0026; <string-name><surname>Harner</surname>, <given-names>R. N.</given-names></string-name> <article-title>Patient-specific early seizure detection from scalp EEG</article-title>. <source>J. Clin. Neurophysiol</source>. <volume>27</volume>, <fpage>163</fpage> (<year>2010</year>).</mixed-citation></ref>
<ref id="c77"><label>77.</label><mixed-citation publication-type="journal"><string-name><surname>Le Van Quyen</surname>, <given-names>M.</given-names></string-name> <etal>et al.</etal> <article-title>Preictal state identification by synchronization changes in long-term intracranial EEG recordings</article-title>. <source>Clin. Neurophysiol</source>. <volume>116</volume>, <fpage>559</fpage>&#x2013;<lpage>568</lpage> (<year>2005</year>).</mixed-citation></ref>
<ref id="c78"><label>78.</label><mixed-citation publication-type="journal"><string-name><surname>Freestone</surname>, <given-names>D. R.</given-names></string-name> <etal>et al.</etal> <article-title>Seizure prediction: science fiction or soon to become reality?</article-title> <source>Curr. Neurol. Neurosci. Reports</source> <volume>15</volume>, <fpage>1</fpage>&#x2013;<lpage>9</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c79"><label>79.</label><mixed-citation publication-type="journal"><string-name><surname>Gadhoumi</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Lina</surname>, <given-names>J.-M.</given-names></string-name>, <string-name><surname>Mormann</surname>, <given-names>F.</given-names></string-name> &#x0026; <string-name><surname>Gotman</surname>, <given-names>J.</given-names></string-name> <article-title>Seizure prediction for therapeutic devices: A review</article-title>. <source>J. Neurosci. Methods</source> <volume>260</volume>, <fpage>270</fpage>&#x2013;<lpage>282</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c80"><label>80.</label><mixed-citation publication-type="journal"><string-name><surname>Mormann</surname>, <given-names>F.</given-names></string-name> &#x0026; <string-name><surname>Andrzejak</surname>, <given-names>R. G.</given-names></string-name> <article-title>Seizure prediction: making mileage on the long and winding road</article-title>. <source>Brain</source> <volume>139</volume>, <fpage>1625</fpage>&#x2013;<lpage>1627</lpage> (<year>2016</year>).</mixed-citation></ref>
<ref id="c81"><label>81.</label><mixed-citation publication-type="journal"><string-name><surname>Saab</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Dunnmon</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>R&#x00E9;</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Rubin</surname>, <given-names>D.</given-names></string-name> &#x0026; <string-name><surname>Lee-Messer</surname>, <given-names>C.</given-names></string-name> <article-title>Weak supervision as an efficient approach for automated seizure detection in electroencephalography</article-title>. <source>npj Digit. Medicine</source> <volume>3</volume>, <fpage>1</fpage>&#x2013;<lpage>12</lpage> (<year>2020</year>).</mixed-citation></ref>
<ref id="c82"><label>82.</label><mixed-citation publication-type="other"><string-name><surname>Zhang</surname>, <given-names>Z.-Y.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Jiang</surname>, <given-names>Y.</given-names></string-name> &#x0026; <string-name><surname>Zhou</surname>, <given-names>Z.-H.</given-names></string-name> <article-title>Learning from incomplete and inaccurate supervision</article-title>. <source>IEEE Transactions on Knowl. Data Eng</source>. (<year>2021</year>).</mixed-citation></ref>
<ref id="c83"><label>83.</label><mixed-citation publication-type="journal"><string-name><surname>Natarajan</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Dhillon</surname>, <given-names>I. S.</given-names></string-name>, <string-name><surname>Ravikumar</surname>, <given-names>P. K.</given-names></string-name> &#x0026; <string-name><surname>Tewari</surname>, <given-names>A.</given-names></string-name> <article-title>Learning with noisy labels</article-title>. <source>Adv. Neural Inf. Process. Syst</source>. <volume>26</volume>, <fpage>1196</fpage>&#x2013;<lpage>1204</lpage> (<year>2013</year>).</mixed-citation></ref>
<ref id="c84"><label>84.</label><mixed-citation publication-type="journal"><string-name><surname>Menon</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Van Rooyen</surname>, <given-names>B.</given-names></string-name> &#x0026; <string-name><surname>Natarajan</surname>, <given-names>N.</given-names></string-name> <article-title>Learning from binary labels with instance-dependent noise</article-title>. <source>Mach. Learn</source>. <volume>107</volume>, <fpage>1561</fpage>&#x2013;<lpage>1595</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c85"><label>85.</label><mixed-citation publication-type="journal"><string-name><surname>Griffiths</surname>, <given-names>G.</given-names></string-name> &#x0026; <string-name><surname>Fox</surname>, <given-names>J. T.</given-names></string-name> <article-title>Rhythm in epilepsy</article-title>. <source>The Lancet</source> <volume>232</volume>, <fpage>409</fpage>&#x2013;<lpage>416</lpage> (<year>1938</year>).</mixed-citation></ref>
<ref id="c86"><label>86.</label><mixed-citation publication-type="journal"><string-name><surname>Pinto</surname>, <given-names>M. F.</given-names></string-name> <etal>et al.</etal> <article-title>A personalized and evolutionary algorithm for interpretable eeg epilepsy seizure prediction</article-title>. <source>Sci. Reports</source> <volume>11</volume>, <fpage>1</fpage>&#x2013;<lpage>12</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c87"><label>87.</label><mixed-citation publication-type="journal"><string-name><surname>Bandarabadi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Rasekhi</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Teixeira</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Karami</surname>, <given-names>M. R.</given-names></string-name> &#x0026; <string-name><surname>Dourado</surname>, <given-names>A.</given-names></string-name> <article-title>On the proper selection of preictal period for seizure prediction</article-title>. <source>Epilepsy &#x0026; Behav</source>. <volume>46</volume>, <fpage>158</fpage>&#x2013;<lpage>166</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c88"><label>88.</label><mixed-citation publication-type="journal"><string-name><surname>Assi</surname>, <given-names>E. B.</given-names></string-name>, <string-name><surname>Nguyen</surname>, <given-names>D. K.</given-names></string-name>, <string-name><surname>Rihana</surname>, <given-names>S.</given-names></string-name> &#x0026; <string-name><surname>Sawan</surname>, <given-names>M.</given-names></string-name> <article-title>Towards accurate prediction of epileptic seizures: A review</article-title>. <source>Biomed. Signal Process. Control</source>. <volume>34</volume>, <fpage>144</fpage>&#x2013;<lpage>157</lpage> (<year>2017</year>).</mixed-citation></ref>
<ref id="c89"><label>89.</label><mixed-citation publication-type="journal"><string-name><surname>Baud</surname>, <given-names>M. O.</given-names></string-name> <etal>et al.</etal> <article-title>Multi-day rhythms modulate seizure risk in epilepsy</article-title>. <source>Nat. Commun</source>. <volume>9</volume>, <fpage>1</fpage>&#x2013;<lpage>10</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c90"><label>90.</label><mixed-citation publication-type="journal"><string-name><surname>Haut</surname>, <given-names>S. R.</given-names></string-name>, <string-name><surname>Hall</surname>, <given-names>C. B.</given-names></string-name>, <string-name><surname>Masur</surname>, <given-names>J.</given-names></string-name> &#x0026; <string-name><surname>Lipton</surname>, <given-names>R. B.</given-names></string-name> <article-title>Seizure occurrence: precipitants and prediction</article-title>. <source>Neurology</source> <volume>69</volume>, <fpage>1905</fpage>&#x2013;<lpage>1910</lpage> (<year>2007</year>).</mixed-citation></ref>
<ref id="c91"><label>91.</label><mixed-citation publication-type="journal"><string-name><surname>Leguia</surname>, <given-names>M. G.</given-names></string-name> <etal>et al.</etal> <article-title>Seizure cycles in focal epilepsy</article-title>. <source>JAMA Neurol</source>. <volume>78</volume>, <fpage>454</fpage>&#x2013;<lpage>463</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c92"><label>92.</label><mixed-citation publication-type="journal"><string-name><surname>Proix</surname>, <given-names>T.</given-names></string-name> <etal>et al.</etal> <article-title>Forecasting seizure risk in adults with focal epilepsy: A development and validation study</article-title>. <source>The Lancet Neurol</source>. <volume>20</volume>, <fpage>127</fpage>&#x2013;<lpage>135</lpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c93"><label>93.</label><mixed-citation publication-type="journal"><string-name><surname>Bosl</surname>, <given-names>W. J.</given-names></string-name>, <string-name><surname>Leviton</surname>, <given-names>A.</given-names></string-name> &#x0026; <string-name><surname>Loddenkemper</surname>, <given-names>T.</given-names></string-name> <article-title>Prediction of seizure recurrence. A note of caution</article-title>. <source>Front. Neurol</source>. <volume>12</volume>, <fpage>773</fpage> (<year>2021</year>).</mixed-citation></ref>
<ref id="c94"><label>94.</label><mixed-citation publication-type="journal"><string-name><surname>Duffy</surname>, <given-names>J. F.</given-names></string-name> &#x0026; <string-name><surname>Dijk</surname>, <given-names>D.-J.</given-names></string-name> <article-title>Getting through to circadian oscillators: Why use constant routines?</article-title> <source>J. Biol. Rhythm</source>. <volume>17</volume>, <fpage>4</fpage>&#x2013;<lpage>13</lpage> (<year>2002</year>).</mixed-citation></ref>
<ref id="c95"><label>95.</label><mixed-citation publication-type="journal"><string-name><surname>Shah</surname>, <given-names>V.</given-names></string-name> <etal>et al.</etal> <article-title>The Temple University Hospital seizure detection corpus</article-title>. <source>Front. Neuroinformatics</source> <volume>12</volume>, <fpage>83</fpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c96"><label>96.</label><mixed-citation publication-type="other"><string-name><surname>Klatt</surname>, <given-names>J.</given-names></string-name> <etal>et al.</etal> <source>The EPILEPSIAE database: An extensive electroencephalography database of epilepsy patients</source> (<year>2012</year>).</mixed-citation></ref>
<ref id="c97"><label>97.</label><mixed-citation publication-type="journal"><string-name><surname>Comon</surname>, <given-names>P.</given-names></string-name> <article-title>Independent component analysis, a new concept?</article-title> <source>Signal Process</source>. <volume>36</volume>, <fpage>287</fpage>&#x2013;<lpage>314</lpage> (<year>1994</year>).</mixed-citation></ref>
<ref id="c98"><label>98.</label><mixed-citation publication-type="journal"><string-name><surname>Shi</surname>, <given-names>X.</given-names></string-name> <etal>et al.</etal> <article-title>Convolutional LSTM network: A machine learning approach for precipitation nowcasting</article-title>. <source>Adv. Neural Inf. Process. Syst</source>. <volume>2015</volume>, <fpage>802</fpage>&#x2013;<lpage>810</lpage> (<year>2015</year>).</mixed-citation></ref>
<ref id="c99"><label>99.</label><mixed-citation publication-type="journal"><string-name><surname>Truong</surname>, <given-names>N. D.</given-names></string-name> <etal>et al.</etal> <article-title>Convolutional neural networks for seizure prediction using intracranial and scalp electroencephalo-gram</article-title>. <source>Neural Networks</source> <volume>105</volume>, <fpage>104</fpage>&#x2013;<lpage>111</lpage> (<year>2018</year>).</mixed-citation></ref>
<ref id="c100"><label>100.</label><mixed-citation publication-type="other"><string-name><surname>Shah</surname>, <given-names>V.</given-names></string-name> <etal>et al.</etal> <article-title>Validation of temporal scoring metrics for automatic seizure detection</article-title>. In <source>2020 IEEE Signal Processing in Medicine and Biology Symposium (SPMB), 1&#x2013;5 (IEEE, 2020)</source>.</mixed-citation></ref>
<ref id="c101"><label>101.</label><mixed-citation publication-type="journal"><string-name><surname>Litt</surname>, <given-names>B.</given-names></string-name> <etal>et al.</etal> <article-title>Epileptic seizures may begin hours in advance of clinical onset: a report of five patients</article-title>. <source>Neuron</source> <volume>30</volume>, <fpage>51</fpage>&#x2013;<lpage>64</lpage> (<year>2001</year>).</mixed-citation></ref>
<ref id="c102"><label>102.</label><mixed-citation publication-type="other"><string-name><surname>Truong</surname>, <given-names>N. D.</given-names></string-name> <etal>et al.</etal> <article-title>Seizure susceptibility prediction in uncontrolled epilepsy</article-title>. <source>Front. Neurol</source>. 1466 (<year>2021</year>).</mixed-citation></ref>
</ref-list>
<fn-group>
<fn id="fn1">
<label><sup>1</sup></label>
<p>See the cheap gradient principle [<xref ref-type="bibr" rid="c62">62</xref>].</p></fn>
</fn-group>
</back>
</article>