<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MEDRXIV</journal-id>
<journal-title-group>
<journal-title>medRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">medRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/2021.04.05.21254684</article-id>
<article-version>1.5</article-version>
<article-categories>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Health Informatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>A human-interpretable machine learning approach to predict mortality in severe mental illness</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0001-7748-9885</contrib-id>
<name><surname>Banerjee</surname><given-names>Soumya</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Li&#x00F2;</surname><given-names>Pietro</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-0387-880X</contrib-id>
<name><surname>Jones</surname><given-names>Peter B.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<contrib contrib-type="author">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0002-8751-5167</contrib-id>
<name><surname>Cardinal</surname><given-names>Rudolf N.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Department of Psychiatry, University of Cambridge</institution>, <country>UK</country></aff>
<aff id="a2"><label>2</label><institution>Department of Computer Science and Technology, University of Cambridge</institution>, <country>UK</country></aff>
<aff id="a3"><label>3</label><institution>Cambridgeshire and Peterborough NHS Foundation Trust</institution>, <country>UK</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Corresponding author E-mail: <email>sb2333@cam.ac.uk</email></corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2021</year>
</pub-date>
<elocation-id>2021.04.05.21254684</elocation-id>
<history>
<date date-type="received">
<day>05</day>
<month>4</month>
<year>2021</year>
</date>
<date date-type="rev-recd">
<day>16</day>
<month>10</month>
<year>2021</year>
</date>
<date date-type="accepted">
<day>17</day>
<month>10</month>
<year>2021</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2021</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="21254684.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>Abstract</title>
<p>Machine learning (ML), one aspect of artificial intelligence (AI), involves computer algorithms that train themselves. They have been widely applied in the healthcare domain. However, many trained ML algorithms operate as &#x201C;black boxes&#x201D;, producing a prediction from input data without a clear explanation of their workings. Non-transparent predictions are of limited utility in many clinical domains, where decisions must be justifiable.</p>
<p>Here, we apply class-contrastive counterfactual reasoning to ML to demonstrate how specific changes in inputs lead to different predictions of mortality in people with severe mental illness (SMI), a major public health challenge. We produce predictions accompanied by visual and textual explanations as to how the prediction would have differed given specific changes to the input. We apply it to routinely collected data from a mental health secondary care provider in patients with schizophrenia. Using a data structuring framework informed by clinical knowledge, we captured information on physical health, mental health, and social predisposing factors. We then trained an ML algorithm and other statistical learning techniques to predict the risk of death.</p>
<p>The ML algorithm predicted mortality with an area under receiver operating characteristic curve (AUROC) of 0.80 (95&#x0025; confidence intervals [0.78, 0.82]). We used class-contrastive analysis to produce explanations for the model predictions. We outline the scenarios in which class-contrastive analysis is likely to be successful in producing explanations for model predictions. Our aim is not to advocate for a particular model but show an application of the class-contrastive analysis technique to electronic healthcare record data for a disease of public health significance.</p>
<p>In patients with schizophrenia, our work suggests that use or prescription of medications like antide-pressants was associated with lower risk of death. Abuse of alcohol/drugs and a diagnosis of delirium were associated with higher risk of death. Our ML models highlight the role of co-morbidities in determining mortality in patients with SMI and the need to manage them. We hope that some of these bio-social factors can be targeted therapeutically by either patient-level or service-level interventions. Our approach combines clinical knowledge, health data, and statistical learning, to make predictions interpretable to clinicians using class-contrastive reasoning. This is a step towards interpretable AI in the management of patients with SMI and potentially other diseases.</p>
</abstract>
<counts>
<page-count count="45"/>
</counts>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>RNC consults for Campden Instruments Ltd and receives royalties from Cambridge University Press, Cambridge Enterprise, and Routledge. SB, PL and PJ declare they have no conflicts of interest to disclose.</p></notes>
<notes notes-type="financial-disclosure">
<title>Funding Statement</title><p>This work was funded by an MRC Mental Health Data Pathfinder grant (MC_PC_17213). PBJ is supported
by the NIHR Applied Research Collaboration East of England. The funders had no role in study
design, data collection and analysis, decision to publish, or preparation of the manuscript. This research was supported in part by the NIHR Cambridge Biomedical Research Centre. The views expressed are
those of the authors and not necessarily those of the MRC, the NHS, the NIHR, or the Department of
Health and Social Care.</p></notes>
<notes notes-type="disclosures">
<title>Author Declarations</title><p>I confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.</p><p>Yes</p><p>The details of the IRB/oversight body that provided approval or exemption for the research described are given below:</p><p>The CPFT Research Database operates under UK NHS Research Ethics approvals (REC references 12/EE/0407, 17/EE/0442; IRAS project ID 237953).</p><p>I confirm that all necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived, and that any patient/participant/sample identifiers included were not known to anyone (e.g., hospital staff, patients or participants themselves) outside the research group so cannot be used to identify individuals.</p><p>Yes</p><p>I understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).</p><p>Yes</p><p>I have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.</p><p>Yes</p></notes>
<fn-group content-type="summary-of-updates">
<title>Summary of Updates:</title>
<fn fn-type="update"><p>Changed abstract and edited funding information</p></fn>
</fn-group>
</notes>
</front>
<body>
<sec id="s1">
<title>Introduction</title>
<p>In this article we apply a recent development in machine learning, termed class-contrastive analysis, to the major public health problem of premature mortality in schizophrenia. Schizophrenia affects approxi-mately 0.5&#x0025; of the population [<xref ref-type="bibr" rid="c1">1</xref>]. It is a severe mental illness (SMI), along with bipolar affective disorder, personality disorders, and recurrent depressive disorder. Patients with schizophrenia or other SMI more broadly have substantially increased mortality and reduced life expectancy, often due to physical comorbidities [<xref ref-type="bibr" rid="c2">2</xref>] [<xref ref-type="bibr" rid="c3">3</xref>] [<xref ref-type="bibr" rid="c4">4</xref>] [<xref ref-type="bibr" rid="c5">5</xref>]. A challenge for clinical practice is therefore to identify patients at particularly high risk of adverse events (including premature death) and seek to intervene early.</p>
<p>Machine learning (ML) offers a potential route to risk prediction in the field of SMI as elsewhere. ML, a sub-field of artificial intelligence (AI), involves computer algorithms that automatically adjust in response to training data (&#x201C;train themselves&#x201D;). Their attractiveness relates to their ability to create predictive models from complex data sets with minimal human intervention, to a degree that may exceed the accuracy of classical statistical models such as logistic regression. ML achieves this through a variety of techniques. In a basic technique such as a multi-layer artificial neural network, for example, a layer of hidden nodes is trained by the algorithm to respond to weighted combinations of inputs; there may be further such layers responding to weighted combinations of the first layer, and these layers may interact recurrently. The &#x201C;output&#x201D; layer, giving the prediction or classification, responds to weighted combinations of preceding nodes. The algorithm seeks to minimize output prediction error. As a result, the output may predict accurately (if validated on independent data to avoid overfitting), but it may be very hard for a human to discern how the decision was reached. Clinically, it may be impractical to rely on such a black box predictor.</p>
<p>Here, we develop ML models of mortality in schizophrenia and apply the technique of class-contrastive reasoning to improve their explicability. Class-contrastive reasoning is a technique from the social sciences [<xref ref-type="bibr" rid="c7">7</xref>]: the contrast is to an alternative class of exemplars. An example of a class-contrastive explanation is: &#x201C;The selected patient is at high risk of mortality because the patient has dementia in Alzheimer&#x2019;s disease and has cardiovascular disease. If the patient did not have both of these characteristics, the predicted risk would be much lower.&#x201D;</p>
<p>We apply an ML and class-contrastive framework to data on clinically relevant bio-social variables spanning physical health, mental health, personal history, and social predisposing factors. We collate this information from an electronic clinical records system and use clinician knowledge to transform them into features that are used to train an ML system (<xref rid="fig1" ref-type="fig">Fig. 1</xref>). We use the ML model to predict mortality and apply class-contrastive reasoning to explain the model.</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1.</label>
<caption><title>Overview of approach.</title>
<p>Bio-social factors that are relevant in severe mental illnesses (SMI) are derived from the electronic healthcare record system and used as inputs to statistical and machine learning algorithms. The algorithms are made interpretable using class-contrastive reasoning. The class-contrastive textual statements and heatmaps aid the understanding of models by domain experts such as clinicians, patients, and data scientists.</p></caption>
<graphic xlink:href="21254684v5_fig1.tif"/>
</fig>
<p>We also use a visualization technique for machine learning models (class-contrastive heatmaps) that allows us to map the effect of changing a set of features.</p>
<p>Our approach can be helpful when explicit causal structure is modelled, and when there are a few features which are binary (categorical) in nature. Our approach may not be successful when there are continuous features or many (hundreds) features. If features are hard to define and have to be discovered (for example, by semi-supervised techniques), our approach may not be helpful. Most of our features are binary (categorical) in nature and hence the class-contrastive approach can be applied successfully.</p>
<p>The class-contrastive approach may also be used to evaluate the practical limits of explainability of some models. For example, if a model has hundreds or thousands of features, it may be computationally intractable to exhaustively explore how changing combinations of these features affects the model output.</p>
<p>Our aim is not to advocate for a particular statistical model or black box model. Our objective is to give an example of how class contrastive reasoning can be used to explain black box models with binary categorical features in real world electronic healthcare record data, in a disease of public health significance.</p>
<p>Our aim is not to exhaustively compare all possible statistical models but merely briefly survey and analyse some techniques. We note that our aim is not to demonstrate that some machine learning models can perform better than others.</p>
<p>We show a practical demonstration on a clinical dataset in a disease of public health relevance. We also outline the instances in which class-contrastive reasoning can be successfully applied to electronic health care record data. We suggest class-contrastive reasoning as a method to begin understanding ML and statistical models that have non-linearities. To the best of our knowledge this is the first application of this technique to real world electronic healthcare record data.</p>
<p>Our work is a step towards personalised medicine and interpretable AI in mental health and has the potential to be applicable more broadly in healthcare.</p>
</sec>
<sec id="s2">
<title>Data and Methods</title>
<sec id="s2a">
<title>Overview of Methods</title>
<p>We give a brief overview of our approach in this section. Our approach is summarised in <xref rid="fig1" ref-type="fig">Fig. 1</xref>.</p>
<list list-type="order">
<list-item><p>We take de-identified data from an electronic patient record system for mental health.</p></list-item>
<list-item><p>We define a set of high-level features that are in this example time independent. These include age, diagnostic categories (time-independent coded diagnosis at any point during the study period), and medication categories (time-independent prescription of or use of medications). We also include bio-social factors that are important in SMI like information on mental health diagnosis, relevant risk history such as a prior suicide attempt, substance abuse, and social factors such as lack of family support.</p></list-item>
<list-item><p>We use these features to predict death during the time of observation.</p></list-item>
<list-item><p>We use classical statistical models including logistic regression, survival models, and standardised mortality ratios.</p></list-item>
<list-item><p>We then fit machine learning models, comparing predictive accuracy to the classical statistical models.</p></list-item>
<list-item><p>Class-contrastive heatmaps are used to visualize the explanations of the statistical models and machine learning predictions. The corresponding class-contrastive statements also aid human interpretation.</p></list-item>
</list>
</sec>
<sec id="s2b">
<title>Mental health clinical record database</title>
<p>We used data from the Cambridgeshire and Peterborough NHS Foundation Trust (CPFT) Research Database. This comprises electronic healthcare records from CPFT, the single provider of secondary care mental health services for Cambridgeshire and Peterborough, UK, an area in which approximately 856,000 people reside. The records are de-identified using the CRATE software [<xref ref-type="bibr" rid="c8">8</xref>] under NHS Research Ethics approval (12/EE/0407, 17/EE/0442).</p>
<p>Data included patient demographics, mental health and physical co-morbidity diagnoses: these were derived from coded ICD-10 diagnoses and analysis of free text through natural language processing (NLP) tools [<xref ref-type="bibr" rid="c9">9</xref>] [<xref ref-type="bibr" rid="c10">10</xref>].</p>
<p>Dates of death are automatically updated via the National Health Service (NHS) Spine. We considered all patients with coded diagnoses of schizophrenia who had records in the electronic healthcare system from 2013 onwards. There were a total of 1706 patients diagnosed with schizophrenia defined by coded ICD-10 diagnosis (diagnosis code F20). We note there is under-coding of schizophrenia.</p>
</sec>
<sec id="s2c">
<title>Medicine information on prescribed drugs</title>
<p>We extracted medicine information for each patient by using natural language processing on clinical free text data using the GATE software [<xref ref-type="bibr" rid="c9">9</xref>] [<xref ref-type="bibr" rid="c11">11</xref>].</p>
</sec>
<sec id="s2d">
<title>Population mortality data</title>
<p>Population mortality data for England and Wales was used from the Office for National Statistics (ONS) [<xref ref-type="bibr" rid="c12">12</xref>].</p>
</sec>
<sec id="s2e">
<title>Data input to statistical algorithms</title>
<p>The features fed in to our statistical and machine learning algorithms included age, gender, high-level diagnosis categories and medication categories. We also included other bio-social factors important in SMI. All these features are used to predict mortality. The full list of features was as follows:</p>
<list list-type="order">
<list-item><p>High-level medication categories were created based on domain-specific knowledge from a clinician [RNC]. These medication categories are: second-generation antipsychotics (SGA: clozapine, olanzapine, risperidone, quetiapine, aripiprazole, asenapine, amisulpride, iloperidone, lurasidone, paliperidone, sertindole, sulpiride, ziprasidone, zotepine); first-generation antipsychotics (FGA: haloperidol, benperidol, chlorpromazine, flupentixol, fluphenazine, levomepromazine, pericyazine, perphenazine, pimozide, pipotiazine, prochlor-perazine, promazine, trifluoperazine, zuclopenthixol); antidepressants (agomelatine, amitriptyline, bupropion, clomipramine, dosulepin, doxepin, duloxetine, imipramine, isocarboxazid, lofepramine, maprotiline, mianserin, mirtazapine, moclobemide, nefazodone, nortriptyline, phenelzine, reboxetine, tranylcypromine, trazodone, trimipramine, tryptophan, sertraline, citalopram, escitalopram, fluoxetine, fluvoxamine, paroxetine, vortioxetine and venlafaxine); diuretics (furosemide); thyroid medication (drug mention of levothyroxine); antimanic drugs (lithium) and medications for dementia (memantine and donepezil).</p></list-item>
<list-item><p>Relevant co-morbidities we included were diabetes (inferred from ICD-10 codes E10, E11, E12, E13 and E14 and any mentions of the drugs metformin and insulin), cardiovascular diseases (inferred from ICD-10 diagnoses codes I10, I11, I26, I82, G45 and drug mentions of atorvastatin, simvastatin and aspirin), respiratory illnesses (J44 and J45) and anti-hypertensives (mentions of the drugs bisoprolol and amlodipine).</p></list-item>
<list-item><p>We included all patients with a coded diagnosis of schizophrenia (F20). For these patients with schizophrenia, we also included any additional coded diagnosis from the following broad diagnostic categories: dementia in Alzheimer&#x2019;s disease (ICD-10 code starting with F00), delirium (F05), mild cognitive disorder (F06.7), depressive disorders (F32, F33) and personality disorders (F60).</p></list-item>
<list-item><p>We also included relevant social factors: lack of family support (ICD-10 chapter code Z63) and personal risk factors (Z91: a code encompassing allergies other than to drugs and biological substances, medication noncompliance, a history of psychological trauma, and unspecified personal risk factors); alcohol and substance abuse (this was inferred from ICD-10 coded diagnoses of Z86, F10, F12, F17, F19 and references to thiamine which is prescribed for alcohol abuse). Other features included are self-harm (ICD-10 codes T39, T50, X60, X61, X62, X63, X64, X78 and Z91.5), non-compliance and personal risk factors (Z91.1), referral to a crisis team at CPFT (recorded in the electronic healthcare record system) and any prior suicide attempt (in the last 6 months or any time in the past) coded in structured risk assessments.</p></list-item>
</list>
<p>These broad categories constituted our representation of simplified clinician-based knowledge. We use these features (including age of the patient) to predict whether a patient died any time during the time period observed (from first referral to CPFT to the present day). We do not attempt to predict the risk of dying, for instance, 1 year after first referral to CPFT. The features we use to predict mortality are also time-independent. This represents a simplified time-independent model. More detailed modelling would include temporal effects of such predictors.</p>
<p>Age is a predictor in all our models, including survival models. We consider time of death and time of feature collection. The observed outcome (death) was binary and this is the outcome the models are predicting but models do so via a continuous variable related to risk/probability, so this is simultaneously predicted. Our model predictions, if independently validated in another clinical setting, can be converted in to a risk or probability.</p>
<p>All our models, including the machine learning model, include age as a predictor. However the class-contrastive analysis and the class-contrastive heatmaps do not include age since the feature changes (one at a time or pairwise) can be achieved only for binary (categorical) features. Hence, the class-contrastive heatmaps show the effect of changing predictors on the model prediction, over and above the contribution of age.</p>
</sec>
<sec id="s2f">
<title>Data pre-processing</title>
<p>Diagnostic codes were based on the International Classification of Diseases (ICD-10) coding system [<xref ref-type="bibr" rid="c13">13</xref>]. Age of patients was normalised (feature scaled) by subtracting the mean age from the age of each patient and then dividing by the standard deviation. All categorical variables, such as diagnosis and medications (described above), were converted using a one-hot encoding scheme. This is explained in detail in the Supplementary Section.</p>
</sec>
<sec id="s2g">
<title>Machine learning and statistical techniques</title>
<p>We performed logistic regression using generalized linear models [<xref ref-type="bibr" rid="c14">14</xref>] [<xref ref-type="bibr" rid="c15">15</xref>]. We used age (feature scaled) as a continuous predictor. There are categorical features (medications, co-morbidities and other social and personal predisposing factors) which are encoded using a one-hot representation. Additional details are available in the Supplementary Section.</p>
<p>For our machine learning approach, we used artificial neural networks (autoencoders) to integrate data from different sources giving a holistic picture of mental health, physical health and social factors contributing to mortality in SMI. We use the same set of features for all algorithms.</p>
<p>Artificial neural networks are composed of computational nodes (artificial neurons) that are connected to form a network. Each artificial neuron performs a simple computation (much like logistic regression). The neurons are organised in layers. The input layer takes in the input features, transforms them, and passes it to one or more intermediate layers called hidden layers. The hidden layer performs further transformations and passes the result to the output layer. The final output layer is used to make a prediction (in this case, about mortality).</p>
<p>The autoencoder is a type of artificial neural network that also performs dimensionality reduction since the hidden layer has fewer neurons that the input layer [<xref ref-type="bibr" rid="c16">16</xref>]. In our framework, the reduced dimensions of the autoencoder (output of the hidden layer) were used as input to a random forest model to predict mortality (<xref rid="fig2" ref-type="fig">Fig. 2</xref>). Random forests are machine learning models that build collections of decision trees [<xref ref-type="bibr" rid="c17">17</xref>]. Each decision tree makes a prediction after making a series of choices based on the input data. These decision trees are combined to build a collection (forest) that together has better predictive ability than a single tree.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>Architecture of autoencoder.</title>
<p>The autoencoder takes as input the bio-social features. The output layer is used to reconstruct the input. The hidden layer of the autoencoder is used for dimensionality reduction. We use the hidden layer as input to a random forest model to predict mortality. The hidden layer is composed of 10 neurons.</p></caption>
<graphic xlink:href="21254684v5_fig2.tif"/>
</fig>
<p>We split the data into training set (50&#x0025;), validation set (25&#x0025;) and test set (25&#x0025;). We performed 10-fold cross-validation and regularization to penalize for model complexity. Additional details are available in the Supplementary Section and summarised in <xref rid="fig2" ref-type="fig">Fig. 2</xref>.</p>
<p>We used the following models to predict mortality:</p>
<list list-type="order">
<list-item><p>Logistic regression model with all the original input features;</p></list-item>
<list-item><p>An autoencoder with the bio-social features as input. We then use the reduced dimensions from the autoencoder as input features to a random forest model (<xref rid="fig2" ref-type="fig">Fig. 2</xref>).</p></list-item>
</list>
</sec>
<sec id="s2h">
<title>Class-contrastive reasoning</title>
<p>We explain our models using class-contrastive reasoning and class-contrastive heatmaps. The technique works as follows. The model is trained on the training set. For each patient in the test set, we independently mutate (change from 0 to 1, or 1 to 0) each categorical feature. For each patient in the test set, we use the trained model to compute the change in the predicted probability of death.</p>
<p>We repeat this procedure independently for each feature and each patient in the test set. We do not retrain the model when we mutate the features. The predictions are made using the trained machine learning model on the test set.</p>
<p>We visualize the amount of change in the model predicted probability of mortality, achieved by setting a particular feature to 1 versus 0, using a class-contrastive heatmap. The rows represent patients and columns represent the feature that has been changed from 0 to 1. The heatmaps also show a hierarchical clustering dendrogram, which is performed using an Euclidean distance metric and complete linkage [<xref ref-type="bibr" rid="c17">17</xref>].</p>
<p>In another variant, we also simultaneously change all pairs of features in the test set from 0 and 0 to 1 and 1. As before, for each patient in the test set, we use the trained model to compute the change in the predicted probability of death. In this case, the class-contrastive heatmap shows the amount of change in the predicted probability of mortality, achieved by setting a particular combination of features to 1 versus 0. The rows represent patients and columns represent the combination of features that are changed simultaneously.</p>
<p>The class-contrastive heatmap shows patient-specific predictions. Predictions for individual patients are made in the following way: the trained model makes a prediction for the probability of death based on the modified features as input. This process is repeated for each patient and each feature (or feature combination).</p>
</sec>
<sec id="s2i">
<title>Survival analysis and standardized mortality ratios</title>
<p>For survival analysis, we use the entry date (exposure) as the date of referral. In cases where there were multiple referrals for a patient, we considered the earliest date. If this calculated date was earlier than the start date of our mental health clinical database (called RiO), we set it to the start date of RiO (1st December 2012). The event was death. The date of death was derived from the National Health Service (NHS) Spine.</p>
<p>We used a Cox proportional hazards model for patients with schizophrenia, using age (feature scaled) and the bio-social features (as outlined before) as input features.</p>
<p>We calculated age-standardized mortality ratios (SMR) to standardise and control for age and population structure. For calculating SMRs, we defined five-year age groups (0-4, 5-9, &#x2026;, 85-90, and <italic>&#x003E;</italic> 90 years). Population mortality data was used from the Office for National Statistics (ONS) [<xref ref-type="bibr" rid="c12">12</xref>]. We calculated SMRs for patients with a coded diagnosis of schizophrenia. SMRs were calculated using the indirect method of standardisation [<xref ref-type="bibr" rid="c18">18</xref>]. The denominator is the expected number of deaths in the study population and the numerator is the number of observed deaths in the study population. 95&#x0025; confidence intervals were calculated as described in [<xref ref-type="bibr" rid="c18">18</xref>]. Additional details are available in the Supplementary Section.</p>
</sec>
<sec id="s2j">
<title>Logistic regression models</title>
<p>We used a logistic regression model to predict mortality in patients with schizophrenia. Age (feature scaled) and the bio-social factors were used as input. The model, in R notation, was as follows:
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="21254684v5_ueqn1.gif"/></alternatives>
</disp-formula>
</p>
<p>This same model was also fit using an <italic>L</italic><sub>1</sub> regularized logistic regression model (details are available in the Supplementary Section, Subsection Sensitivity analysis).</p>
<p>We also fit a logistic regression model with main effects and an interaction term between dementia in Alzheimer&#x2019;s disease and cardiovascular disease. The model, in R notation, was as follows:
<disp-formula id="ueqn2">
<alternatives><graphic xlink:href="21254684v5_ueqn2.gif"/></alternatives>
</disp-formula>
</p>
</sec>
<sec id="s2k">
<title>Software</title>
<p>All software was written in the R [<xref ref-type="bibr" rid="c19">19</xref>] and Python programming languages. Visualizations were performed using the <italic>ggplot</italic> package in R [<xref ref-type="bibr" rid="c20">20</xref>]. Generalized linear model (GLM) regression was performed using the <italic>glm</italic> function in R [<xref ref-type="bibr" rid="c21">21</xref>] [<xref ref-type="bibr" rid="c15">15</xref>]. Hierarchical clustering and visualization were performed using heatmaps in the <italic>pheatmap</italic> package [<xref ref-type="bibr" rid="c22">22</xref>]. Survival analysis was conducted using the <italic>survminer</italic> package in R [<xref ref-type="bibr" rid="c23">23</xref>]. <italic>L</italic><sub>1</sub> regularized logistic regression was performed using the <italic>glmnet</italic> package [<xref ref-type="bibr" rid="c24">24</xref>].</p>
</sec>
<sec id="s2l">
<title>Data availability</title>
<p>This study reports on human clinical data which cannot be published directly due to reasonable privacy concerns, as per NHS research ethics approvals and information governance rules.</p>
</sec>
<sec id="s2m">
<title>Code availability</title>
<p>The code used in this study is available from the corresponding author upon reasonable request.</p>
</sec>
</sec>
<sec id="s3">
<title>Results</title>
<sec id="s3a">
<title>Summary of results</title>
<p>We used a range of statistical and ML techniques to predict mortality in patients with schizophrenia. Class-contrastive reasoning and class-contrastive heatmaps were used to generate human-oriented explanations of statistical and ML model predictions.</p>
<p>Abuse of alcohol and drugs, and a diagnosis of delirium were risk factors for mortality (across all our techniques). Use of antidepressants was associated with lower risk of death via all our techniques.</p>
<p>The machine learning models emphasized combinations of features (like Alzheimer&#x2019;s disease) with other co-morbidities. This highlights the role of co-morbidities in determining mortality in patients with SMI and the need to manage them.</p>
</sec>
<sec id="s3b">
<title>Survival analysis and standardized mortality ratios</title>
<p>Our explainable machine learning techniques complement classical statistical analysis like survival models and standardised mortality ratios. In this section, we outline these approaches.</p>
<p>For survival analysis, we use age (feature scaled) and the bio-social features (as outlined in Subsection Data input to statistical algorithms) as input features for patients with schizophrenia. For patients with schizophrenia, we show the hazard ratios associated with each feature in <xref rid="fig3" ref-type="fig">Fig. 3</xref> using a Cox proportional hazards model. Use of second-generation antipsychotics (SGA) and antidepressants was associated with reduced risk of death in patients with schizophrenia. Alcohol/substance abuse was associated with an elevated risk of death consistent with a previous study [<xref ref-type="bibr" rid="c25">25</xref>]. A diagnosis of delirium was similarly associated with increased mortality.</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure 3.</label>
<caption><title>Survival analysis for patients with schizophrenia using a Cox proportional hazards model.</title>
<p>We show the hazard ratios associated with each feature and the confidence intervals. Use of second-generation antipsychotics (SGA) and antidepressants was associated with reduced risk of death in patients with schizophrenia. Alcohol/substance abuse and a diagnosis of delirium was associated with increased mortality.</p></caption>
<graphic xlink:href="21254684v5_fig3.tif"/>
</fig>
<p>The standardized mortality ratio (SMR) for patients with schizophrenia was 7.4 (95&#x0025; confidence interval: [5.5, 9.2]). This is consistent with SMRs reported in the UK [<xref ref-type="bibr" rid="c25">25</xref>]. Additional details are available in the Supplementary Section (Subsection Calculation of standardized mortality ratios).</p>
</sec>
<sec id="s3c">
<title>Logistic regression models</title>
<p>We used a logistic regression model to predict mortality in patients with schizophrenia. We show the odds ratios and their confidence intervals in <xref rid="fig4" ref-type="fig">Fig. 4</xref>. Age, diagnosis of delirium and alcohol/substance abuse were associated with a high risk of death. Use of second-generation antipsychotics and antidepressants were associated with a reduced risk of death.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure 4.</label>
<caption><title>Logistic regression model to predict mortality in patients with schizophrenia.</title>
<p>Log odds ratio of features in a logistic regression model to predict mortality in patients with schizophrenia. Shown are confidence intervals and statistical significance (filled dark circles: p-value <italic>&#x003C;</italic> 0.05, open circles: not significant). Age, alcohol/substance abuse and a diagnosis of delirium were associated with a high risk of death. Use of second-generation antipsychotics (SGA) and antidepressants were associated with reduced risk of death.</p></caption>
<graphic xlink:href="21254684v5_fig4.tif"/>
</fig>
</sec>
<sec id="s3d">
<title>Class contrastive heatmaps and counter-factual statements for logistic regression</title>
<p>The class-contrastive explanatory technique is applicable to machine learning models and statistical models such as logistic regression. We first demonstrate our approach by using class-contrastive reasoning on the logistic regression model for predicting mortality. We show the amount of change (predicted by the trained logistic regression model on the test set) in the probability of death by changing one particular feature from 0 to 1 (in the test set). We visualize this using a heatmap (<xref rid="fig5" ref-type="fig">Fig. 5</xref>) where rows represent patients and columns represent features in the test set that have been changed. Predictions are made using the trained logistic regression model on the test set.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure 5.</label>
<caption><title>Class-contrastive heatmap for the logistic regression model.</title>
<p>Visualization of the amount of change predicted in the probability of death by setting a particular feature to 1 versus 0 (using a logistic regression model). Rows represent patients and columns represent features. Predictions are made on the test set using the trained logistic regression model. The arrows indicate groups of patients with low predicted risk of death (shown in blue on the heatmap) and high predicted risk of death (shown in red). The arrow on the top left indicates a group of patients having a counter-intuitive characteristic of having diabetes and still have low predicted risk of death. The second arrow on the top left indicates another group of patients on antidepressants. These patients are predicted (using the logistic regression model) to have a lower risk of death. There is a third group of patients with delirium or dementia in Alzheimer&#x2019;s disease (shown with an arrow) who are predicted to have a higher risk of death. The heatmap also shows a hierarchical clustering dendrogram which is performed using an Euclidean distance metric and complete linkage.</p></caption>
<graphic xlink:href="21254684v5_fig5.tif"/>
</fig>
<p>The class-contrastive heatmap shows patient-specific predictions. Predictions for individual patients are made in the following way: the trained logistic regression model makes a prediction for the probability of death based on the modified features as input. This process is repeated for each patient and each feature.</p>
<p>We observe that a diagnosis of delirium or dementia predisposes a group of patients towards a higher probability of predicted mortality (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). Patients (with schizophrenia) who were taking antidepressants were less likely to die during the period observed (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). The class-contrastive and counterfactual analysis suggests that antidepressants may be associated with lower mortality in a group of patients (<xref rid="fig5" ref-type="fig">Fig. 5</xref>).</p>
<p>The heatmap also highlights counter-intuitive predictions. For example, the heatmap suggests that there is a small sub-group of patients (<xref rid="fig5" ref-type="fig">Fig. 5</xref>: top left hand corner indicated with an arrow) who have diabetes and have a lower risk of death. The use of a probability scale illustrates that the effect of each predictor varies in terms of its effect on probability (according to the baseline probability determined by other variables); of course, in log odds terms, changes in a given predictor will have a constant effect across all subjects.</p>
<p>We note that the counter-intuitive observations we observe in the class-contrastive heatmaps (on the test set) may also be as a result of imbalances in the training set. For example, a particular binary feature may be 0 for 100 patients and 1 for 10 patients.</p>
<p>In order to address this, we can add synthetic training data with these imbalances and visualize the class-contrastive predictions on the test set. We can artificially introduce an imbalance (for example, add more zeros than ones to a binary feature) in the test set and training set, and then observe the class contrastive heatmaps.</p>
<p>We note that age is a predictor in all models that we use. However the class-contrastive heatmaps do not include age. This is because the class-contrastive analysis changes features one at a time (or pairwise), and this can be achieved only for binary categorical features. Hence, the class-contrastive heatmaps show the effect of changing predictors on the model predicted probability of mortality, over and above the contribution of age.</p>
</sec>
<sec id="s3e">
<title>Class-contrastive analysis for machine learning models</title>
<p>We used artificial neural networks to predict mortality in patients with schizophrenia. We performed class-contrastive analysis for this machine learning model (<xref rid="fig2" ref-type="fig">Fig. 2</xref>) to make it explainable.</p>
<p>We first show a heatmap for a simple version of class-contrastive reasoning where we mutate only one feature at a time on the test set (<xref rid="fig6" ref-type="fig">Fig. 6</xref>). We show the amount of change (predicted by the trained model on the test set) in the probability of death by setting one particular feature to 1 versus 0. We visualize this using a heatmap as before, where rows represent patients and columns represent features. We note that even though we cluster the features, our aim is not to demonstrate any similarity between them.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure 6.</label>
<caption><title>Class contrastive heatmap for the deep learning model.</title>
<p>Visualization of the amount of change predicted in the probability of death by setting a particular feature to 1 versus 0. Predictions are made on the test set using a random forest model built on top of the autoencoder. Columns represent patients and rows represent features. The arrows at the top indicate counter-intuitive examples. If these patients had a respiratory diseases or Alzheimer&#x2019;s disease, the model predicts low risk of death. The arrows at the bottom indicate a group of patients on antidepressants and SGA who are predicted to have low risk of death. The heatmap also shows a hierarchical clustering dendrogram which is performed using an Euclidean distance metric and complete linkage. We note that even though we cluster the features (columns) we do not aim to imply any similarity between them.</p></caption>
<graphic xlink:href="21254684v5_fig6.tif"/>
</fig>
<p>The heatmap suggests there is a subgroup of patients in whom use or prescription of medications like second-generation antipsychotics (SGA) and antidepressants is associated with a lower risk of death (<xref rid="fig6" ref-type="fig">Fig. 6</xref>). There is another subgroup of patients in whom personal risk factors (ICD-10 coded diagnosis; see Methods) are associated with increased risk of mortality.</p>
<p>The class-contrastive heatmaps also reveal counter-intuitive aspects of the data and model. Looking at the effect of individual features in isolation in <xref rid="fig6" ref-type="fig">Fig. 6</xref>, we observe small sub-groups of patients in whom having respiratory diseases or having Alzheimer&#x2019;s disease is associated with a lower risk of death (indicated with arrows in <xref rid="fig6" ref-type="fig">Fig. 6</xref>).</p>
<p>These counter-intuitive results may be due to the fact that the class-contrastive approach is sensitive to the training data and any imbalances in features. For example, a binary feature may have mostly zeros in the training set. This can lead to a counter-intuitive result on the test set. Correlations across features may also help explain these counter-intuitive results.</p>
<p>We show an additional representative class-contrastive heatmap for the ML model in the Supplementary Section (<xref rid="figS1" ref-type="fig">Supp. Fig. 1</xref>). This ML model was run using a different split of the training and test data. This heatmap is consistent with previous results (<xref rid="fig6" ref-type="fig">Fig. 6</xref>), with the exception that it shows SGA are associated with an increased probability of mortality (<xref rid="figS1" ref-type="fig">Supp. Fig. 1</xref>, bottom left arrow). This is not consistent with previous results from the logistic regression model and survival analysis for the effect of SGA (<xref rid="fig4" ref-type="fig">Figs. 4</xref> and <xref rid="fig3" ref-type="fig">3</xref>).</p>
<p>Deep learning models combine input features to create higher-order representations using hidden layers. Features are also often correlated and there are non-linearities involved. To account for some higher-order (non-linear) correlations and to better highlight the combinations of features, we simultaneously change all possible combinations of two features from 0 to 1 (in the test set). Specifically, we set a particular combination of two features to 1 simultaneously (versus 0) in the test set. We then repeat this for all possible pairs of features in the test set. We visualize the change in model output on the test set in <xref rid="fig7" ref-type="fig">Fig. 7</xref>. This technique can be used to investigate the role of combinations of different features that deep learning models exploit to build higher-order representations.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure 7.</label>
<caption><title>Advanced class-contrastive heatmap for the deep learning model.</title>
<p>Class contrastive heatmap for deep learning models showing the effect of combinations of features. Visualization of the amount of change predicted in the probability of death by setting a particular combination of two features to 1 simultaneously (versus 0). Rows represent patients and columns represent feature groupings (all combinations of two features). Predictions are made on the test set using a random forest model built on top of the autoencoder. Delirium and dementia in Alzheimer&#x2019;s disease seem to predispose some patients towards greater risk of mortality (shown in the lower left region of the heatmap in red). Diuretics appear to be associated with lower mortality in a group of patients with cardiovascular disease (shown in the blue region in the lower right-hand corner of the heatmap). The heatmap also shows a hierarchical clustering dendrogram which is performed using an Euclidean distance metric and complete linkage.</p></caption>
<graphic xlink:href="21254684v5_fig7.tif"/>
</fig>
<p>We found combinations of cardiovascular disease and use of diuretics. Diuretic use was associated with lower risk of mortality in a group of patients with cardiovascular disease (shown in the blue region of the heatmap in the lower right-hand corner which is the region of greatest decrease in predicted probability of death) (<xref rid="fig7" ref-type="fig">Fig. 7</xref>). There are also combinations of delirium and dementia in Alzheimer&#x2019;s disease that predispose some patients towards greater risk of mortality (shown in the lower left region of the heatmap in red) (<xref rid="fig7" ref-type="fig">Fig. 7</xref>).</p>
<p>Other co-morbidities that are together associated with greater mortality in a sub-group of patients (<xref rid="fig7" ref-type="fig">Fig. 7</xref>) included: dementia in Alzheimer&#x2019;s disease with an additional coded diagnosis of cardiovascular disease, and dementia in Alzheimer&#x2019;s disease with a coded history of abuse of alcohol and drugs.</p>
<p>This highlights the role of co-morbidities in determining mortality in a sub-group of patients with SMI and the need for multiple conditions to be managed simultaneously in patients. A class-contrastive statement for one of these patients in this sub-group (<xref rid="fig7" ref-type="fig">Fig. 7</xref>) is: &#x201C;The selected patient is at high risk of mortality because the patient has dementia in Alzheimer&#x2019;s disease and has cardiovascular disease. If the patient did not have both of these characteristics, the predicted risk would be much lower.&#x201D;</p>
<p>Our deep learning models emphasize combinations of different features. Therefore, as a very simple approximation, we also fit a more complex logistic regression model with interaction effects. We fit a logistic regression model with main effects and an interaction term between dementia in Alzheimer&#x2019;s disease and cardiovascular disease (<xref rid="figS2" ref-type="fig">Supp. Fig. 2</xref>). The log-odds ratio for this interaction term is greater than 0 although it is not statistically significant. This may suggest that there is only a small sub-group of patients in whom dementia and cardiovascular disease co-occur and predispose towards an increased risk of death. Additional details are available in the Supplementary Section.</p>
</sec>
<sec id="s3f">
<title>Performance</title>
<p>We show the predictive performance of each model in this section. The models we used to predict mortality are:</p>
<list list-type="order">
<list-item><p>A logistic regression model with the bio-social features as input. The area under receiver operating curve (AUC) from the logistic regression model was 0.68 (95&#x0025; confidence interval [0.65, 0.70]).</p></list-item>
<list-item><p>An autoencoder with the bio-social features as input. We then used the reduced dimensions from the autoencoder as input features to a random forest model. The predicted AUC from random forests built on top of the autoencoder-reduced dimensions was 0.80 (95&#x0025; confidence interval [0.78, 0.82]).</p></list-item>
</list>
<p>We also use other statistical learning techniques to predict mortality and these are discussed in the Supplementary Section (Section Additional analysis). We do not aim to exhaustively compare all possible statistical models but merely briefly survey and analyse some techniques. Our aim is to apply classcontrastive analysis to a machine learning model and show that in some scenarios the model predictions can be explained. We note that our aim is not to demonstrate that some machine learning models can perform better than others.</p>
</sec>
</sec>
<sec id="s4">
<title>Discussion</title>
<sec id="s4a">
<title>Overview</title>
<p>Mortality among patients with severe mental illnesses (SMI) is too often premature [<xref ref-type="bibr" rid="c4">4</xref>] [<xref ref-type="bibr" rid="c3">3</xref>]. Routinely collected clinical data can help generate insights that can result in more effective treatment of these patients.</p>
<p>We used routinely collected clinical data in an observational study to answer questions of mortality in patients with SMI. We implemented an interpretable computational framework for integrating clinical data in mental health and interrogating it with statistical and machine learning techniques.</p>
<p>Our framework starts with a database that is a knowledge repository of expertise. This database was created based on consultations with clinicians and maps low-level features (for example, medications such as simvastatin) to broader categories (for example, cardiovascular medication). These features are relevant for SMI and were used to predict mortality.</p>
<p>Our architecture captures clinical information on physical health, mental health, personal history and social predisposing factors to create a profile for a patient. We then used a number of statistical and machine learning techniques to predict mortality using these features.</p>
<p>We make our predictions interpretable by using class-contrastive reasoning [<xref ref-type="bibr" rid="c6">6</xref>] [<xref ref-type="bibr" rid="c7">7</xref>]. Our approach has similarities to case-based reasoning [<xref ref-type="bibr" rid="c26">26</xref>] and analogy-based reasoning [<xref ref-type="bibr" rid="c27">27</xref>], where predictions are made based on similar patient histories cases. The approach presented here complements other techniques like Shapley explanations that are used to improve interpretability of machine learning models.</p>
</sec>
<sec id="s4b">
<title>Summary of findings</title>
<p>We used a range of statistical and machine learning techniques to predict mortality in patients with schizophrenia. Since machine learning models may also be difficult to explain, we make them explainable using class-contrastive reasoning and class-contrastive heatmaps.</p>
<p>In patients with schizophrenia, abuse of alcohol and drugs, and a diagnosis of delirium were risk factors for mortality (across all techniques). Use or prescription of antidepressants and second-generation antipsychotics (SGA) were associated with lower mortality in our logistic regression and survival models. However use or prescription of SGA was associated with an increased probability of mortality in one of our ML models.</p>
<p>The logistic regression model predicted that Alzheimer&#x2019;s disease is a risk factor for mortality. The deep learning model emphasized Alzheimer&#x2019;s disease in combination with other co-morbidities. This highlights the role of co-morbidities in determining mortality in patients with SMI and the need to manage them.</p>
</sec>
<sec id="s4c">
<title>Implications of findings</title>
<p>The class-contrastive and survival analysis suggest that antidepressants are associated with lower mortality in a group of patients with schizophrenia. Alcohol/substance misuse was consistently associated with elevated mortality, suggesting the requirement to address the needs of so-called &#x201C;dual diagnosis&#x201D; patients (with SMI and comorbid substance misuse) as part of a strategy to improve life expectancy in patients with SMI.</p>
<p>The association between delirium and excess mortality is notable but not unexpected [<xref ref-type="bibr" rid="c2">2</xref>] [<xref ref-type="bibr" rid="c3">3</xref>] [<xref ref-type="bibr" rid="c4">4</xref>]. A weakness of the current family of models is their lack of temporal structure (for example, consideration of the time between delirium and death) but this finding serves to emphasize that delirium should not be taken lightly.</p>
<p>The association of antidepressant use with reduced mortality was unexpected but consistent across analytical methods. Our data do not support a mechanistic interpretation (for example, mode of death is not recorded in these structured clinical records) but this question would bear further investigation.</p>
<p>Illicit substance abuse and lack of family involvement was associated with increased risk of mortality [<xref ref-type="bibr" rid="c25">25</xref>]. Alcohol/substance abuse was also pointed out as a critical factor in our class-contrastive reasoning analysis and survival analysis. Provisioning of family support and involving family members and carers could be part of health management plans [<xref ref-type="bibr" rid="c28">28</xref>].</p>
<p>We hope that some of these bio-social factors can be targeted therapeutically by either patient-level interventions (like provisioning of family support [<xref ref-type="bibr" rid="c28">28</xref>]) or service-level improvements [<xref ref-type="bibr" rid="c29">29</xref>].</p>
<p>Overall, we observed that abuse of alcohol and drugs and a diagnosis of delirium are risk factors for mortality (in both logistic regression models and survival models). Use of SGA and antidepressants were associated with lower mortality from both our logistic regression models and survival models. This may be important given that some clinicians may hesitate to prescribe given what is known about short-to medium-term side effects of these drugs that include adverse impact on cardiovascular risk profiles. While our findings on this and other points is not conclusive evidence of causality, it is in accord with observational clinical data at the national level [<xref ref-type="bibr" rid="c30">30</xref>].</p>
<p>The machine learning model emphasized (for example) Alzheimer&#x2019;s disease along with other comorbidities (<xref rid="fig7" ref-type="fig">Fig. 7</xref>). This highlights the role of co-morbidities in determining mortality in patients with SMI and points to the need for multiple conditions to be treated simultaneously in patients. This also suggests that a pragmatic trial of robust management of co-morbidities may be justified.</p>
</sec>
<sec id="s4d">
<title>Interpretable algorithms for personalized clinical decision making</title>
<p>Interpretability is a major design consideration of machine learning algorithms applied in healthcare. We made our predictions interpretable by using class-contrastive reasoning and counterfactual statements [<xref ref-type="bibr" rid="c6">6</xref>]. This approach has the capability to make some black-box models explainable, which might be very useful for clinical decision support systems. We demonstrate the approach here using logistic regression and artificial neural networks. These techniques could ultimately be used to build a conversational AI that could explain its predictions to a clinician.</p>
<p>Our work can also be used to make clinical decision support systems. This may lead to automated alerts in electronic healthcare record systems, after thorough validation in follow-up studies.</p>
</sec>
<sec id="s4e">
<title>Limitations and future work</title>
<p>Our study is observational in nature and we do not imply causation. Our data is a naturalistic sample from a clinic and should not be used to alter clinical practice. Our aim is to raise hypotheses that will need to be tested in randomized controlled trials.</p>
<p>There may also be other unknown confounds and hence causal conclusions cannot be drawn from an observational study. For example, a drug that is associated with better outcomes may be preferred by clinical teams, and a drug that is associated with poorer outcomes may still be prescribed for severely ill patients because it is perceived to be effective.</p>
<p>There may also be under-coding of schizophrenia diagnoses. The data was from a secondary care mental health service provider and may miss important risk factors coded in primary care.</p>
<p>Psychiatric diagnoses are challenging and there can be potential issues related to the reliability of diagnostic categories in SMI. Sampling bias is another issue in real world electronic healthcare record data. For example, it is possible that only the most severely ill patients seek clinical help and get referred to secondary care. Hence the data may reflect a category of patients who are more severely ill.</p>
<p>Our data also lacks temporal structure which is likely to be important in determining progression of disease. The current work relates observable features to the risk of death within the observation period. Clearly this is not as satisfactory as a model that predicts a time-based risk. It would be expected that the temporal risk conferred by different features would vary &#x2013; for example, diabetes increases cardiovascular risk over decades, whereas delirium is often associated with critical illness and may be associated with an elevated mortality risk that is very immediate or proximal. A comprehensive model might involve autodiscovery of those temporal risk factors, at the price of a considerable increase in model complexity. This will require building more complex recurrent neural network models like long short-term memory models (LSTM), which will require even more data.</p>
<p>Important readouts like statistical significance cannot be judged from the class-contrastive heatmaps. For example, lack of family support appeared to be associated with higher mortality in the class-contrastive heatmap for the logistic regression model (<xref rid="fig5" ref-type="fig">Fig. 5</xref>). However this association was not statistically significant, even though the odds ratio for lack of family support is greater than 1 in a logistic regression model (<xref rid="fig4" ref-type="fig">Fig. 4</xref>).</p>
<p>We combined several medications into the category of second-generation antipsychotics, which itself consists of a heterogenous group of medications [<xref ref-type="bibr" rid="c30">30</xref>], and make other simplifications in our treatment of medications.</p>
<p>Because of heterogeneity in training data and correlations across features, reproducibility of heatmaps is a limitation. We show an additional representative example in <xref rid="figS1" ref-type="fig">Supp. Fig. 1</xref>. There are a few differences between these heatmaps (<xref rid="figS1" ref-type="fig">Supp. Fig. 1</xref> and <xref rid="fig6" ref-type="fig">Fig. 6</xref>). This heatmap is consistent with previous results (<xref rid="fig6" ref-type="fig">Fig. 6</xref>), with the exception that it shows SGA are associated with an increased probability of mortality (<xref rid="figS1" ref-type="fig">Supp. Fig. 1</xref>, bottom left arrow). This is not consistent with previous results from the logistic regression model and survival analysis for the effect of SGA (<xref rid="fig4" ref-type="fig">Figs. 4</xref> and <xref rid="fig3" ref-type="fig">3</xref>). Reconciling these results will require additional analysis and validation in an independent cohort with more patients.</p>
<p>Our results suggest that the class-contrastive approach is sensitive to the training data and any imbalances in features. For example, a particular binary feature may be 0 for 100 patients and 1 for 10 patients. One way to determine this sensitivity is to artificially introduce more zeros and then observe the class contrastive heatmaps.</p>
<p>It is possible that the counter-intuitive observations we see in the class-contrastive heatmaps (on the test set) are likely as a result of such imbalances in the training set. Because of this reproducibility of heatmaps is a limitation of our approach.</p>
<p>Our approach can be helpful when explicit causal structure is modelled, and when there are binary (categorical) features and a few features which can be modified at a time. We account for correlations between features by modifying all pairs of features at a time and then observing the effect on model predictions (<xref rid="fig7" ref-type="fig">Fig. 7</xref>). However, this approach can become computationally challenging for higher combinations of features (all triples, quadruples, all possible combinations), or as the number of features increase.</p>
</sec>
<sec id="s4f">
<title>Concluding remarks</title>
<p>Our framework combines bio-social factors relevant for SMI with statistical learning, and makes them interpretable using class-contrastive techniques. Our work suggests that medications like antidepressants were associated with a reduced risk of death in a group of patients with schizophrenia. Abuse of alcohol and drugs, and a diagnosis of delirium were risk factors for death.</p>
<p>Our machine learning models highlight the role of co-morbidities in determining mortality in patients with SMI and the need to manage them. We hope that some of these bio-social factors can be targeted therapeutically by either patient-level or service-level interventions.</p>
<p>We complement explainable machine learning techniques with classical statistical analysis like logistic regression, survival models and standardised mortality ratios. This may be a prudent and pragmatic approach for building explainable models in healthcare. We admit that the distinction between ML models and classical statistical models (like logistic regression) is artificial. Models lie on a continuum and a pragmatic approach towards explainable AI would combine and contrast all of these techniques.</p>
<p>The approach of combining explainable techniques and clinical knowledge with machine learning approaches may be more broadly applicable when data scientists need to work closely with domain experts (clinicians and patients).</p>
<p>Our approach combines clinical knowledge, health data, and statistical learning, to make predictions interpretable to clinicians using class-contrastive reasoning. We view our work as a step towards interpretable AI and personalized medicine for patients with SMI and potentially other diseases.</p>
</sec>
</sec>
</body>
<back>
<sec sec-type="data-availability">
<title>Data Availability</title>
<p>This study reports on human clinical data which cannot be published directly due to reasonable privacy concerns, as per NHS research ethics approvals and information governance rules.</p>
</sec>
<ack>
<title>Acknowledgements</title>
<p>We thank Jenny Nelder and Jonathan Lewis for all their support during this project and Irene Egli for inspiring us to think about patients with schizophrenia. This work is dedicated to the memory of Patrick Winston.</p>
</ack>
<sec id="s5">
<title>Funding statement</title>
<p>This work was funded by an MRC Mental Health Data Pathfinder grant (MC PC 17213). PBJ is supported by the NIHR Applied Research Collaboration East of England. The funders had no role in study design, data collection and analysis, decision to publish, or preparation of the manuscript. This research was supported in part by the NIHR Cambridge Biomedical Research Centre. The views expressed are those of the authors and not necessarily those of the MRC, the NHS, the NIHR, or the Department of Health and Social Care.</p>
</sec>
<sec id="s6">
<title>Conflicts of interests</title>
<p>RNC consults for Campden Instruments Ltd and receives royalties from Cambridge University Press, Cambridge Enterprise, and Routledge. SB, PL and PJ declare they have no conflicts of interest to disclose.</p>
</sec>
<sec id="s7">
<title>Ethics</title>
<p>The CPFT Research Database operates under UK NHS Research Ethics approvals (REC references 12/EE/0407, 17/EE/0442; IRAS project ID 237953).</p>
</sec>
<sec id="s8">
<title>Data accessibility</title>
<p>This study reports on human clinical data which cannot be published directly due to reasonable privacy concerns, as per NHS research ethics approvals and information governance rules.</p>
</sec>
<sec id="s9">
<title>Author contributions</title>
<p>SB, PL, PBJ, and RNC designed the study. SB and RNC verified the underlying data. SB conducted the analyses and wrote the original draft of the manuscript. All authors edited the manuscript and gave final approval for publication.</p>
</sec>
<sec id="s10">
<title>Supplementary Information</title>
<sec id="s10a">
<title>Supplementary Methods</title>
<sec id="s10a1">
<title>Machine learning methods</title>
<p>We used an artificial neural network, called an autoencoder, to integrate data from different sources and predict mortality. The input features are age (normalised), gender, diagnosis categories, lifestyle risk factors, social factors and medication categories. We use the same set of features for all algorithms.</p>
<p>Categorical features (such as medication categories) are encoded using a one-hot representation. This involves taking a vector that is as long as the number of unique values of the feature. Each position on this vector corresponds to a unique value that the categorical feature can take. Whenever a categorical feature (say, did a patient take cardiovascular medication) takes on a particular value (say True), we place a 1 (&#x201C;hot&#x201D;) corresponding to that position on the vector and 0 everywhere else.</p>
<p>We show the architecture of the autoencoder in <xref rid="fig2" ref-type="fig">Fig. 2</xref>. The autoencoder is an artificial neural network with an input layer, hidden layer and an output layer. The input layer takes in the bio-social features. The output layer is used to reconstruct the input. The hidden layer of the autoencoder is used for dimensionality reduction.</p>
<p>The autoencoder has one hidden layer of 10 neurons. We use the hidden layer as input to a random forest model to predict mortality. A similar architecture was applied previously to electronic healthcare record data [<xref ref-type="bibr" rid="c31">31</xref>]. The choice of an autoencoder allows reduction of the feature space.</p>
<p>An artificial neural network has an input layer, hidden layer(s) and output layer. An activation function is used to project the input data (<italic>X</italic>) into another feature space using weights (<italic>W</italic>).
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="21254684v5_eqn1.gif"/></alternatives>
</disp-formula>
</p>
<p>The weights <italic>W</italic> are determined using a technique called backpropagation [<xref ref-type="bibr" rid="c32">32</xref>].</p>
<p>We used a ReLU (Rectified Linear Unit) activation function for the hidden layer. The form of the ReLU function is shown below:
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="21254684v5_eqn2.gif"/></alternatives>
</disp-formula>
</p>
<p>We used a sigmoid activation function for the final layer:
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="21254684v5_eqn3.gif"/></alternatives>
</disp-formula>
</p>
<p>The output of the sigmoid function is positive even for negative input.</p>
<p>We also experimented with a hyperbolic tangent (tanh) function shown below:
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="21254684v5_eqn4.gif"/></alternatives>
</disp-formula>
</p>
<p>However the cross-validation results (see discussion later) were inferior to that of the ReLU activation function.</p>
<p>An artificial feed-forward neural network optimizes a loss function of the form:
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="21254684v5_eqn5.gif"/></alternatives>
</disp-formula>
</p>
<p>This is the negative log-likelihood. There are <italic>d</italic> data points. The <italic>i</italic> th data point has a label denoted by <italic>y</italic><sub><italic>i</italic></sub> and input feature vector represented by <italic>x</italic><sub><italic>i</italic></sub>. The weights of the artificial neural network are represented by a vector <italic>&#x03B8;. &#x03BB;</italic> is a regularization parameter to prevent overfitting and reduce model complexity. <italic>&#x03BB;</italic> is usually determined by cross-validation. Shown here is the <italic>L</italic><sub>1</sub> norm of the parameter vector (<italic>&#x03B8;</italic>). The weights of the artificial neural network are determined using a technique called backpropagation [<xref ref-type="bibr" rid="c32">32</xref>].</p>
<p>The autoencoder used a cross-entropy loss function, which is a measure of discrepancy between the input layer and reconstructed hidden layer. The cross-entropy loss function used for the autoencoder had the following form:
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="21254684v5_eqn6.gif"/></alternatives>
</disp-formula>
where there are <italic>m</italic> features in the input layer. <italic>u</italic> represents the input layer and <italic>v</italic> represents the hidden layer. The layers are computed by applying the appropriate activation functions (<xref ref-type="disp-formula" rid="eqn1">Equations 1</xref>, <xref ref-type="disp-formula" rid="eqn2">2</xref> and <xref ref-type="disp-formula" rid="eqn3">3</xref>).</p>
<p>The final cost function is given below:
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="21254684v5_eqn7.gif"/></alternatives>
</disp-formula>
where the vector <italic>&#x03B8;</italic> represents all the weights of the artificial neural network. There are <italic>m</italic> features in the input layer. <italic>u</italic> represents the input layer and <italic>v</italic> represents the hidden layer. We added an <italic>L</italic><sub>1</sub> penalty term on the weights to perform regularization and prevent overfitting. This is denoted by the term <italic>&#x03BB;</italic>&#x007C;&#x007C;<italic>&#x03B8;</italic>&#x007C;&#x007C;. <italic>&#x03BB;</italic> is a regularization parameter which we determined by 10-fold cross-validation.</p>
<p>We performed a 50&#x0025;-25&#x0025;-25&#x0025; training-validation-test split of the data. We used the <italic>keras</italic> package [<xref ref-type="bibr" rid="c33">33</xref>] with the <italic>Tensorflow</italic> backend [<xref ref-type="bibr" rid="c34">34</xref>].</p>
<p>The artificial neural network was trained on the training data for a number of epochs. In one epoch the network is trained on the training dataset. The model fit is then refined over subsequent epochs. Our neural network was trained for 1000 epochs, which was assessed as being sufficient to reach convergence. We used the <italic>Adadelta</italic> method of optimization [<xref ref-type="bibr" rid="c35">35</xref>].</p>
<p>We selected all hyperparameters, including the number of neurons in a hidden layer and activation functions, based on a uniform search and 10-fold cross-validation. We split the data into training set (50&#x0025;), validation set (25&#x0025;) and test set (25&#x0025;). We trained the model on the training set. We carried out cross-validation on the validation set. The architectural parameters and regularization parameters are then selected. This final model is then evaluated on the test set. This process of splitting the data (into training, validation and test sets), training the model and performing cross-validation is repeated 10 times.</p>
<p>We varied the number of neurons in the hidden layer from 2 to 20. For activation functions, we tried sigmoid, rectified linear unit (ReLU) and hyperbolic tangent (tanh). We do not use dropout regularization to keep a simple architecture and simplify the process of model selection. A hidden layer of 10 neurons and ReLU and sigmoid activation functions (for the first and second layers, respectively), were found to have the least cross-validation error.</p>
<p>We repeated the stochastic process of splitting the data into training and test sets and performing cross-validation 10 times. This yielded a mean AUC of 0.80 (95&#x0025; confidence intervals [0.78, 0.82]).</p>
</sec>
<sec id="s10a2">
<title>Calculation of standardized mortality ratios</title>
<p>Standardized mortality ratios (SMR) are a method to standardise and control for age and population structure [<xref ref-type="bibr" rid="c18">18</xref>]. We calculated SMRs using the indirect method of standardisation [<xref ref-type="bibr" rid="c18">18</xref>]. The denominator is the expected number of deaths in the study population and the numerator is the number of observed deaths in the study population.</p>
<p>Hence the indirectly standardised SMR is the ratio of the number of deaths observed in a study population to the number expected if the age-specific rates of a standard population had applied:
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="21254684v5_eqn8.gif"/></alternatives>
</disp-formula>
where <italic>d</italic> is the number of deaths in the study population. Say there are <italic>k</italic> age groups in the study and standard population. <italic>n</italic><sub><italic>i</italic></sub> is the number of people in the <italic>i</italic>th group of the study population and <italic>R</italic><sub><italic>i</italic></sub> is the crude death rate in the <italic>i</italic>th group of the standard population. The 95&#x0025; confidence intervals are SMR &#x00B1; 1.96 &#x00B7; SE(SMR) [<xref ref-type="bibr" rid="c18">18</xref>] where SE(SMR) is given by:
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="21254684v5_eqn9.gif"/></alternatives>
</disp-formula>
</p>
<p>Here <italic>O</italic> is the observed number of deaths in the study population and <italic>E</italic> is the expected number of deaths in the study population.</p>
</sec>
</sec>
<sec id="s10b">
<title>Sensitivity analysis</title>
<sec id="s10b1">
<title>Additional analysis</title>
<p>For the ML model (random forest built on features from the autoencoder), we performed additional sensitivity analysis. We repeated the stochastic process of splitting the data into training and test sets and performing cross-validation 10 times. We then performed stability analysis of heatmaps. We generated heatmaps for each of the 10 iterations mentioned above. We show a representative heatmap in <xref rid="figS1" ref-type="fig">Supp. Fig. 1</xref>.</p>
<p>Because of heterogeneity in training data and correlations across features, reproducibility of heatmaps is a challenge. We acknowledge this limitation. We show a representative example in <xref rid="figS1" ref-type="fig">Supp. Fig. 1</xref>. This heatmap is consistent with previous results (<xref rid="fig6" ref-type="fig">Fig. 6</xref>), with the exception that it shows use or prescription of SGA is associated with an increased probability of mortality (<xref rid="figS1" ref-type="fig">Supp. Fig. 1</xref>, shown by arrow on bottom left corner). This is not consistent with previous results from the logistic regression model and survival analysis (<xref rid="fig4" ref-type="fig">Fig. 4</xref> and <xref rid="fig3" ref-type="fig">Fig. 3</xref>). Reconciling these results will require additional analysis in an independent cohort with more patients.</p>
<p>Consistent with the previous results (<xref rid="fig6" ref-type="fig">Fig. 6</xref>), this new heatmap (<xref rid="figS1" ref-type="fig">Supp. Fig. 1</xref>) also shows the counter-intuitive result that for some patients with respiratory disease or Alzheimer&#x2019;s disease, the model predicts a lower risk of death.</p>
<p>Our results suggest that the class-contrastive approach is sensitive to the training data and any imbalances in features (e.g. a particular binary feature may be 0 for 100 patients and 1 for 10 patients). Correlations across features may also help explain these counter-intuitive results.</p>
<p>We also used the following models to predict mortality: 1) a random forest model operating on the original features (95&#x0025; CI of AUC: [0.71, 0.79]), 2) performing PCA on the original features and using these reduced dimensions as features to a random forest model (95&#x0025; CI of AUC: [0.51, 0.76]) and logistic regression model (95&#x0025; CI of AUC: [0.52, 0.77]), and 3) <italic>L</italic><sub>1</sub> regularized logistic regression model using the original features (95&#x0025; CI of AUC: [0.72, 0.74]). We performed PCA on the original input features. The top 10 principal components were then used as input to a logistic regression model and (independently) a random forest model.</p>
<p>For the <italic>L</italic><sub>1</sub> regularized logistic regression model, we optimized the regularization hyperparameter as described before. Briefly, we split the data into training set (50&#x0025;), validation set (25&#x0025;) and test set (25&#x0025;). We trained the model on the training set. We carried out cross-validation on the validation set. The regularization parameter for an <italic>L</italic><sub>1</sub> penalized logistic regression model is then selected. This final model is then evaluated on the test set. This process of splitting the data (into training, validation and test sets), training the model and performing cross-validation is repeated 10 times.</p>
<p>Finally, we also fit a <italic>L</italic><sub>1</sub> regularized logistic regression model where age was divided by 100 (instead of being scaled by subtracting the mean and dividing by the standard deviation). This model had similar predictive power compared to a model where age was standardized (95&#x0025; CI of AUC [0.69, 0.73]). Hence we use the standardization method throughout for the age variable (subtracting the mean and dividing by the standard deviation).</p>
<p>Our aim is not to exhaustively compare all possible statistical models but merely briefly survey and analyse some techniques. Our aim is to apply class-contrastive analysis to a few machine learning models and show that in some scenarios the model predictions can be explained. We note that our aim is not to demonstrate that machine learning models can perform better than others.</p>
<p>Our objective is not to show that a particular ML algorithm is better but to show that ML approaches can be made interpretable in some scenarios using class-contrastive reasoning. We show a practical demonstration on a clinical dataset in a disease of public health relevance.</p>
</sec>
<sec id="s10b2">
<title>Logistic regression models with interaction effects</title>
<p>Our deep learning models emphasize combinations of different features. Hence, as a very simple approximation, we also fit a more logistic regression model with interaction effects and main effects.</p>
<p>We fit a logistic regression model with main effects and an interaction term to account for comorbidities: dementia and cardiovascular disease (<xref rid="figS2" ref-type="fig">Supp. Fig. 2</xref>).</p>
<p>The model, in R notation, was as follows:
<disp-formula id="ueqn3">
<alternatives><graphic xlink:href="21254684v5_ueqn3.gif"/></alternatives>
</disp-formula>
</p>
<p>We also fit a logistic regression model where age interacts with all other features (<xref rid="figS3" ref-type="fig">Supp. Fig. 3</xref>). The model is:
<disp-formula id="ueqn4">
<alternatives><graphic xlink:href="21254684v5_ueqn4.gif"/></alternatives>
</disp-formula>
</p>
</sec></sec></sec>
<sec id="s11">
<title>Supplementary Figures</title>
<fig id="figS1" position="float" fig-type="figure">
<label>Supplementary Figure 1.</label>
<caption><title>Sensitivity analysis for class contrastive heatmap for the deep learning model.</title>
<p>Visualization of the amount of change predicted in the probability of death by setting a particular feature to 1 versus 0. Predictions are made on the test set using a random forest model built on top of the autoencoder. Columns represent patients and rows represent features. The arrows at the bottom right indicate counter-intuitive examples. If these patients had a respiratory diseases or Alzheimer&#x2019;s disease, the model predicts low risk of death. The arrow at the bottom left indicates a group of patients on SGA who are predicted to have high risk of death. This is inconsistent with analysis from the logistic regression and survival models. The heatmap also shows a hierarchical clustering dendrogram which is performed using an Euclidean distance metric and complete linkage. We note that even though we cluster the features (columns) we do not aim to imply any similarity between them.</p></caption>
<graphic xlink:href="21254684v5_figS1.tif"/>
</fig>
<fig id="figS2" position="float" fig-type="figure">
<label>Supplementary Figure 2.</label>
<caption><title>A logistic regression model with main effects and an interaction effect between dementia and cardiovascular disease.</title>
<p>Log odds ratio for each feature from a logistic regression model for predicting mortality in patients with schizophrenia. The logistic regression model has main effects and an interaction between dementia and cardiovascular disease. Shown are confidence intervals and statistical significance (filled dark circles: p-value <italic>&#x003C;</italic> 0.05, open circles: not significant).</p></caption>
<graphic xlink:href="21254684v5_figS2.tif"/>
</fig>
<fig id="figS3" position="float" fig-type="figure">
<label>Supplementary Figure 3.</label>
<caption><title>Logistic regression model with main effects and all pairwise interactions with age.</title>
<p>Log odds ratio for each feature from a logistic regression model for predicting mortality in patients with schizophrenia. The logistic regression model has main effects and all pairwise interactions with age. Shown are confidence intervals and statistical significance (filled dark circles: p-value <italic>&#x003C;</italic> 0.05, open circles: not significant).</p></caption>
<graphic xlink:href="21254684v5_figS3.tif"/>
</fig>
</sec>
<ref-list>
<title>References</title>
<ref id="c1"><label>1.</label><mixed-citation publication-type="journal"><string-name><surname>Goldner</surname> <given-names>EM</given-names></string-name>, <string-name><surname>Hsu</surname> <given-names>L</given-names></string-name>, <string-name><surname>Waraich</surname> <given-names>P</given-names></string-name>, <string-name><surname>Somers</surname> <given-names>JM</given-names></string-name> (<year>2002</year>) <article-title>Prevalence and incidence studies of schizophrenic disorders: A systematic review of the literature</article-title>. <source>Can J Psychiatry</source> <volume>47</volume>: <fpage>833</fpage>&#x2013;<lpage>843</lpage>.</mixed-citation></ref>
<ref id="c2"><label>2.</label><mixed-citation publication-type="journal"><string-name><surname>Hayes</surname> <given-names>JF</given-names></string-name>, <string-name><surname>Marston</surname> <given-names>L</given-names></string-name>, <string-name><surname>Walters</surname> <given-names>K</given-names></string-name>, <string-name><surname>King</surname> <given-names>MB</given-names></string-name>, <string-name><surname>Osborn</surname> <given-names>DP</given-names></string-name> (<year>2017</year>) <article-title>Mortality gap for people with bipolar disorder and schizophrenia: UK-based cohort study 2000-2014</article-title>. <source>Br J Psychiatry</source> <volume>211</volume>: <fpage>175</fpage>&#x2013;<lpage>181</lpage>.</mixed-citation></ref>
<ref id="c3"><label>3.</label><mixed-citation publication-type="journal"><string-name><surname>Chang</surname> <given-names>CK</given-names></string-name>, <string-name><surname>Hayes</surname> <given-names>RD</given-names></string-name>, <string-name><surname>Perera</surname> <given-names>G</given-names></string-name>, <string-name><surname>Broadbent</surname> <given-names>MT</given-names></string-name>, <string-name><surname>Fernandes</surname> <given-names>AC</given-names></string-name>, <etal>et al.</etal> (<year>2011</year>) <article-title>Life expectancy at birth for people with serious mental illness and other major disorders from a secondary mental health care case register in London</article-title>. <source>PLoS One</source> <volume>6</volume>.</mixed-citation></ref>
<ref id="c4"><label>4.</label><mixed-citation publication-type="journal"><string-name><surname>Olfson</surname> <given-names>M</given-names></string-name>, <string-name><surname>Gerhard</surname> <given-names>T</given-names></string-name>, <string-name><surname>Huang</surname> <given-names>C</given-names></string-name>, <string-name><surname>Crystal</surname> <given-names>S</given-names></string-name>, <string-name><surname>Stroup</surname> <given-names>TS</given-names></string-name> (<year>2015</year>) <article-title>Premature mortality among adults with schizophrenia in the United States</article-title>. <source>JAMA Psychiatry</source> <volume>72</volume>: <fpage>1172</fpage>&#x2013;<lpage>1181</lpage>.</mixed-citation></ref>
<ref id="c5"><label>5.</label><mixed-citation publication-type="journal"><string-name><surname>Pedersen</surname> <given-names>CB</given-names></string-name>, <string-name><surname>Mors</surname> <given-names>O</given-names></string-name>, <string-name><surname>Bertelsen</surname> <given-names>A</given-names></string-name>, <string-name><surname>LindumWaltoft</surname> <given-names>B</given-names></string-name>, <string-name><surname>Agerbo</surname> <given-names>E</given-names></string-name>, <etal>et al.</etal> (<year>2014</year>) <article-title>A comprehensive nationwide study of the incidence rate and lifetime risk for treated mental disorders</article-title>. <source>JAMA Psychiatry</source> <volume>71</volume>: <fpage>573</fpage>&#x2013;<lpage>581</lpage>.</mixed-citation></ref>
<ref id="c6"><label>6.</label><mixed-citation publication-type="other"><string-name><surname>Sokol</surname> <given-names>K</given-names></string-name>, <string-name><surname>Flach</surname> <given-names>P</given-names></string-name> (<year>2018</year>) <article-title>Conversational Explanations of Machine Learning Predictions Through Class-contrastive Counterfactual Statements</article-title>. <source>In: Proc. Twenty-Seventh Int. Jt. Conf. Artif. Intell. California: International Joint Conferences on Artificial Intelligence Organization</source>, pp. <fpage>5785</fpage>&#x2013;<lpage>5786</lpage>. doi:<pub-id pub-id-type="doi">10.24963/ijcai.2018/836</pub-id>.</mixed-citation></ref>
<ref id="c7"><label>7.</label><mixed-citation publication-type="journal"><string-name><surname>Miller</surname> <given-names>T</given-names></string-name> (<year>2019</year>) <article-title>Explanation in artificial intelligence: Insights from the social sciences</article-title>. <source>Artif Intell</source> <volume>267</volume>: <fpage>1</fpage>&#x2013;<lpage>38</lpage>.</mixed-citation></ref>
<ref id="c8"><label>8.</label><mixed-citation publication-type="journal"><string-name><surname>Cardinal</surname> <given-names>RN</given-names></string-name> (<year>2017</year>) <article-title>Clinical records anonymisation and text extraction (CRATE): An open-source software system</article-title>. <source>BMC Med Inform Decis Mak</source> <volume>17</volume>: <fpage>50</fpage>.</mixed-citation></ref>
<ref id="c9"><label>9.</label><mixed-citation publication-type="journal"><string-name><surname>Cunningham</surname> <given-names>H</given-names></string-name>, <string-name><surname>Tablan</surname> <given-names>V</given-names></string-name>, <string-name><surname>Roberts</surname> <given-names>A</given-names></string-name>, <string-name><surname>Bontcheva</surname> <given-names>K</given-names></string-name> (<year>2013</year>) <article-title>Getting More Out of Biomedical Documents with GATE&#x2019;s Full Lifecycle Open Source Text Analytics</article-title>. <source>PLoS Comput Biol</source> <volume>9</volume>: <fpage>e1002854</fpage>.</mixed-citation></ref>
<ref id="c10"><label>10.</label><mixed-citation publication-type="journal"><string-name><surname>Wang</surname> <given-names>T</given-names></string-name>, <string-name><surname>Oliver</surname> <given-names>D</given-names></string-name>, <string-name><surname>Msosa</surname> <given-names>Y</given-names></string-name>, <string-name><surname>Colling</surname> <given-names>C</given-names></string-name>, <string-name><surname>Spada</surname> <given-names>G</given-names></string-name>, <etal>et al.</etal> (<year>2020</year>) <article-title>Implementation of a real-time psychosis risk detection and alerting system based on electronic health records using cogstack</article-title>. <source>J Vis Exp</source> <volume>2020</volume>.</mixed-citation></ref>
<ref id="c11"><label>11.</label><mixed-citation publication-type="journal"><string-name><surname>Sultana</surname> <given-names>J</given-names></string-name>, <string-name><surname>Chang</surname> <given-names>CK</given-names></string-name>, <string-name><surname>Hayes</surname> <given-names>RD</given-names></string-name>, <string-name><surname>Broadbent</surname> <given-names>M</given-names></string-name>, <string-name><surname>Stewart</surname> <given-names>R</given-names></string-name>, <etal>et al.</etal> (<year>2014</year>) <article-title>Associations between risk of mortality and atypical antipsychotic use in vascular dementia: A clinical cohort study</article-title>. <source>Int J Geriatr Psychiatry</source> <volume>29</volume>: <fpage>1249</fpage>&#x2013;<lpage>1254</lpage>.</mixed-citation></ref>
<ref id="c12"><label>12.</label><mixed-citation publication-type="website"><collab>ONS</collab>. <source>Death registrations summary tables - England and Wales - Office for National Statistics</source>. URL <ext-link ext-link-type="uri" xlink:href="https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/datasets/">https://www.ons.gov.uk/peoplepopulationandcommunity/birthsdeathsandmarriages/deaths/datasets/</ext-link></mixed-citation></ref>
<ref id="c13"><label>13.</label><mixed-citation publication-type="book"><collab>WHO</collab> (<year>1992</year>) <source>The ICD-10 classification of mental and behavioural disorders : clinical de-scriptions and diagnostic guidelines</source>. <publisher-name>World Health Organization</publisher-name>. <collab>Technical report</collab>. URL <ext-link ext-link-type="uri" xlink:href="https://apps.who.int/iris/handle/10665/37958">https://apps.who.int/iris/handle/10665/37958</ext-link>.</mixed-citation></ref>
<ref id="c14"><label>14.</label><mixed-citation publication-type="other"><string-name><surname>Winter</surname> <given-names>B</given-names></string-name> (<year>2013</year>) <source>Linear models and linear mixed effects models in R with linguistic applications. arXiv Prepr</source> <pub-id pub-id-type="arxiv">1308.5499</pub-id>.</mixed-citation></ref>
<ref id="c15"><label>15.</label><mixed-citation publication-type="journal"><string-name><surname>Bates</surname> <given-names>D</given-names></string-name>, <string-name><surname>Ma&#x00E4;chler</surname> <given-names>M</given-names></string-name>, <string-name><surname>Bolker</surname> <given-names>B</given-names></string-name>, <string-name><surname>Walker</surname> <given-names>S</given-names></string-name> (<year>2015</year>) <article-title>Fitting Linear Mixed-Effects Models Using lme4</article-title>. <source>J Stat Softw</source> <volume>67</volume>: <fpage>1</fpage>&#x2013;<lpage>48</lpage>.</mixed-citation></ref>
<ref id="c16"><label>16.</label><mixed-citation publication-type="journal"><string-name><surname>Bourlard</surname> <given-names>H</given-names></string-name>, <string-name><surname>Kamp</surname> <given-names>Y</given-names></string-name> (<year>1988</year>) <article-title>Auto-association by multilayer perceptrons and singular value decomposition</article-title>. <source>Biol Cybern</source> <volume>59</volume>: <fpage>291</fpage>&#x2013;<lpage>294</lpage>.</mixed-citation></ref>
<ref id="c17"><label>17.</label><mixed-citation publication-type="book"><string-name><surname>Gareth</surname> <given-names>J</given-names></string-name>, <string-name><surname>Daniela</surname> <given-names>W</given-names></string-name>, <string-name><surname>Trevor</surname> <given-names>H</given-names></string-name>, <string-name><surname>Robert</surname> <given-names>T</given-names></string-name> (<year>2017</year>) <source>Introduction to Statistical Learning with Applications in R</source>. <publisher-name>Springer</publisher-name>. URL <ext-link ext-link-type="uri" xlink:href="http://www-bcf.usc.edu/gareth/ISL/">http://www-bcf.usc.edu/gareth/ISL/</ext-link>.</mixed-citation></ref>
<ref id="c18"><label>18.</label><mixed-citation publication-type="website"><string-name><surname>Higham</surname> <given-names>J</given-names></string-name>, <string-name><surname>Flowers</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hall</surname> <given-names>P</given-names></string-name> (<year>2005</year>) <article-title>Standardisation</article-title>. <source>Technical report, Eastern Region Public Health Observatory</source>. URL <ext-link ext-link-type="uri" xlink:href="https://www.scotpho.org.uk/media/1403/inphorm-6-final.pdf">https://www.scotpho.org.uk/media/1403/inphorm-6-final.pdf</ext-link>.</mixed-citation></ref>
<ref id="c19"><label>19.</label><mixed-citation publication-type="website"><collab>R Core Team</collab> (<year>2017</year>). <source>R: A Language and Environment for Statistical Computing</source>. URL <ext-link ext-link-type="uri" xlink:href="https://www.r-project.org/">https://www.r-project.org/</ext-link>.</mixed-citation></ref>
<ref id="c20"><label>20.</label><mixed-citation publication-type="book"><string-name><surname>Wickham</surname> <given-names>H</given-names></string-name> (<year>2016</year>) <source>ggplot2 : elegant graphics for data analysis</source>. <publisher-loc>New York</publisher-loc>: <publisher-name>Springer-Verlag</publisher-name>, <fpage>212</fpage> pp. URL <ext-link ext-link-type="uri" xlink:href="http://ggplot2.org">http://ggplot2.org</ext-link>.</mixed-citation></ref>
<ref id="c21"><label>21.</label><mixed-citation publication-type="journal"><string-name><surname>Kuznetsova</surname> <given-names>A</given-names></string-name>, <string-name><surname>Brockhoff</surname> <given-names>PB</given-names></string-name>, <string-name><surname>Christensen</surname> <given-names>RHB</given-names></string-name> (<year>2017</year>) <article-title>lmerTest Package: Tests in Linear Mixed Effects Models</article-title>. <source>J Stat Softw</source> <volume>82</volume>: <fpage>1</fpage>&#x2013;<lpage>26</lpage>.</mixed-citation></ref>
<ref id="c22"><label>22.</label><mixed-citation publication-type="website"><string-name><surname>Kolde</surname> <given-names>R</given-names></string-name> (<year>2018</year>). <source>pheatmap: Pretty Heatmaps</source>. URL <ext-link ext-link-type="uri" xlink:href="https://cran.r-project.org/package=pheatmap">https://cran.r-project.org/package=pheatmap</ext-link>.</mixed-citation></ref>
<ref id="c23"><label>23.</label><mixed-citation publication-type="website"><string-name><surname>Kassambara</surname> <given-names>A</given-names></string-name> (<year>2019</year>). <source>survminer: Survival Analysis and Visualization</source>. URL <ext-link ext-link-type="uri" xlink:href="https://github.com/kassambara/survminer">https://github.com/kassambara/survminer</ext-link>.</mixed-citation></ref>
<ref id="c24"><label>24.</label><mixed-citation publication-type="journal"><string-name><surname>Friedman</surname> <given-names>J</given-names></string-name>, <string-name><surname>Hastie</surname> <given-names>T</given-names></string-name>, <string-name><surname>Tibshirani</surname> <given-names>R</given-names></string-name> (<year>2010</year>) <article-title>Regularization paths for generalized linear models via coordinate descent</article-title>. <source>J Stat Softw</source> <volume>33</volume>: <fpage>1</fpage>&#x2013;<lpage>22</lpage>.</mixed-citation></ref>
<ref id="c25"><label>25.</label><mixed-citation publication-type="journal"><string-name><surname>Reininghaus</surname> <given-names>U</given-names></string-name>, <string-name><surname>Dutta</surname> <given-names>R</given-names></string-name>, <string-name><surname>Dazzan</surname> <given-names>P</given-names></string-name>, <string-name><surname>Doody</surname> <given-names>GA</given-names></string-name>, <string-name><surname>Fearon</surname> <given-names>P</given-names></string-name>, <etal>et al.</etal> (<year>2015</year>) <article-title>Mortality in schizophrenia and other psychoses: A 10-year follow-up of the &#x00C6;sOP first-episode cohort</article-title>. <source>Schizophr Bull</source> <volume>41</volume>: <fpage>664</fpage>&#x2013;<lpage>673</lpage>.</mixed-citation></ref>
<ref id="c26"><label>26.</label><mixed-citation publication-type="book"><string-name><surname>Kolodner</surname> <given-names>J</given-names></string-name> (<year>2014</year>) <source>Case-Based Reasoning</source>. <publisher-name>Elsevier Science</publisher-name>, <fpage>687</fpage> pp. doi: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/C2009-0-27670-7">https://doi.org/10.1016/C2009-0-27670-7</ext-link>.</mixed-citation></ref>
<ref id="c27"><label>27.</label><mixed-citation publication-type="journal"><string-name><surname>Gentner</surname> <given-names>D</given-names></string-name>, <string-name><surname>Forbus</surname> <given-names>KD</given-names></string-name> (<year>2011</year>) <article-title>Computational models of analogy</article-title>. <source>Wiley Interdiscip Rev Cogn Sci</source> <volume>2</volume>: <fpage>266</fpage>&#x2013;<lpage>276</lpage>.</mixed-citation></ref>
<ref id="c28"><label>28.</label><mixed-citation publication-type="journal"><string-name><surname>Power</surname> <given-names>PJ</given-names></string-name>, <string-name><surname>Bell</surname> <given-names>RJ</given-names></string-name>, <string-name><surname>Mills</surname> <given-names>R</given-names></string-name>, <string-name><surname>Herman-Doig</surname> <given-names>T</given-names></string-name>, <string-name><surname>Davern</surname> <given-names>M</given-names></string-name>, <etal>et al.</etal> (<year>2003</year>) <article-title>Suicide prevention in first episode psychosis: The development of a randomised controlled trial of cognitive therapy for acutely suicidal patients with early psychosis</article-title>. <source>Aust N Z J Psychiatry</source> <volume>37</volume>: <fpage>414</fpage>&#x2013;<lpage>420</lpage>.</mixed-citation></ref>
<ref id="c29"><label>29.</label><mixed-citation publication-type="journal"><string-name><surname>Sahakian</surname> <given-names>BJ</given-names></string-name>, <string-name><surname>Bruhl</surname> <given-names>AB</given-names></string-name>, <string-name><surname>Cook</surname> <given-names>J</given-names></string-name>, <string-name><surname>Killikelly</surname> <given-names>C</given-names></string-name>, <string-name><surname>Savulich</surname> <given-names>G</given-names></string-name>, <etal>et al.</etal> (<year>2015</year>) <article-title>The impact of neuroscience on society: Cognitive enhancement in neuropsychiatric disorders and in healthy people</article-title>. <source>Philos Trans R Soc B Biol Sci</source> <volume>370</volume>: <fpage>20140214</fpage>.</mixed-citation></ref>
<ref id="c30"><label>30.</label><mixed-citation publication-type="journal"><string-name><surname>Tiihonen</surname> <given-names>J</given-names></string-name>, <string-name><surname>Lo&#x00F6;nnqvist</surname> <given-names>J</given-names></string-name>, <string-name><surname>Wahlbeck</surname> <given-names>K</given-names></string-name>, <string-name><surname>Klaukka</surname> <given-names>T</given-names></string-name>, <string-name><surname>Niskanen</surname> <given-names>L</given-names></string-name>, <etal>et al.</etal> (<year>2009</year>) <article-title>11-year follow-up of mortality in patients with schizophrenia: a population-based cohort study (FIN11 study)</article-title>. <source>Lancet</source> <volume>374</volume>: <fpage>620</fpage>&#x2013;<lpage>627</lpage>.</mixed-citation></ref>
<ref id="c31"><label>31.</label><mixed-citation publication-type="journal"><string-name><surname>Beaulieu-Jones</surname> <given-names>BK</given-names></string-name>, <string-name><surname>Greene</surname> <given-names>CS</given-names></string-name> (<year>2016</year>) <article-title>Semi-supervised learning of the electronic health record for phenotype stratification</article-title>. <source>J Biomed Inform</source> <volume>64</volume>: <fpage>168</fpage>&#x2013;<lpage>178</lpage>.</mixed-citation></ref>
<ref id="c32"><label>32.</label><mixed-citation publication-type="journal"><string-name><surname>Linnainmaa</surname> <given-names>S</given-names></string-name> (<year>1976</year>) <article-title>Taylor expansion of the accumulated rounding error</article-title>. <source>BIT</source> <volume>16</volume>: <fpage>146</fpage>&#x2013;<lpage>160</lpage>.</mixed-citation></ref>
<ref id="c33"><label>33.</label><mixed-citation publication-type="website"><string-name><surname>Chollet</surname> <given-names>F</given-names></string-name> (<year>2015</year>). <source>keras</source>. URL <ext-link ext-link-type="uri" xlink:href="https://github.com/keras-team/keras">https://github.com/keras-team/keras</ext-link>.</mixed-citation></ref>
<ref id="c34"><label>34.</label><mixed-citation publication-type="other"><string-name><surname>Abadi</surname> <given-names>M</given-names></string-name>, <string-name><surname>Barham</surname> <given-names>P</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>J</given-names></string-name>, <string-name><surname>Chen</surname> <given-names>Z</given-names></string-name>, <string-name><surname>Davis</surname> <given-names>A</given-names></string-name>, <etal>et al.</etal> (<year>2016</year>) <article-title>TensorFlow: A system for large-scale machine learning</article-title>. <source>In: Proc. 12th USENIX Conf. Oper. Syst. Des. Implement</source>.</mixed-citation></ref>
<ref id="c35"><label>35.</label><mixed-citation publication-type="other"><string-name><surname>Zeiler</surname> <given-names>MD</given-names></string-name> (<year>2012</year>) <source>ADADELTA: An Adaptive Learning Rate Method. arXiv Prepr</source> <pub-id pub-id-type="arxiv">1212.5701</pub-id>.</mixed-citation></ref>
</ref-list>
</back>
</article>