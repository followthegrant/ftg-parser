<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MEDRXIV</journal-id>
<journal-title-group>
<journal-title>medRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">medRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/2021.04.15.21255573</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Health Informatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Classifying Drug Ratings Using User Reviews with Transformer-Based Language Models</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Shiju</surname><given-names>Akhil</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<contrib-id contrib-id-type="orcid">http://orcid.org/0000-0003-3608-0244</contrib-id>
<name><surname>He</surname><given-names>Zhe</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<aff id="a1"><label>1</label><institution>Florida State University, Tallahassee</institution>, Florida, <country>USA</country></aff>
<aff id="a2"><label>2</label><institution>School of Information, Florida State University, Tallahassee</institution>, Florida, <country>USA</country></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label> Corresponding author; email: <email>zhe.he@cci.fsu.edu</email></corresp>
<fn fn-type="other"><p><email>aks19m@my.fsu.edu</email></p></fn>
<fn fn-type="other"><p><email>Zhe.He@cci.fsu.edu</email></p></fn>
</author-notes>
<pub-date pub-type="epub">
<year>2021</year>
</pub-date>
<elocation-id>2021.04.15.21255573</elocation-id>
<history>
<date date-type="received">
<day>15</day>
<month>4</month>
<year>2021</year>
</date>
<date date-type="rev-recd">
<day>15</day>
<month>4</month>
<year>2021</year>
</date>
<date date-type="accepted">
<day>20</day>
<month>4</month>
<year>2021</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2021</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="21255573.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>ABSTRACT</title>
<p>Social web contains a large amount of information with user sentiment and opinions across different fields. For example, drugs.com provides users&#x2019; textual review and numeric ratings of drugs. However, text reviews may not always be consistent with the numeric ratings. In this project, we built different classification models to classify user ratings of drugs with their textual review. Multiple supervised machine learning models including Random Forest and Naive Bayesian classifiers were built with drug reviews using TF-IDF features as input. Also, transformer-based neural network models including BERT, BioBERT, RoBERTa, XLNet, ELECTRA, and ALBERT were built for classification using the raw text as input. Overall, BioBERT model outperformed the other models with the overall accuracy of 87&#x0025;. This research demonstrated that transformer-based classification models can be used to classify drug reviews and identify reviews that are inconsistent with the ratings.</p>
<sec>
<title>CCS CONCEPTS</title>
<list list-type="bullet">
<list-item><p><bold>Computing methodologies &#x2192; Artificial intelligence; Machine learning; &#x2022; Applied computing &#x2192; Document management and text processing</bold>.</p>
</list-item>
</list>
</sec>
<sec>
<title>ACM Reference format</title>
<p>Akhil Shiju and Zhe He. 2021. Classifying Drug Ratings Using User Reviews with Transformer-Based Language Models. XXXX</p>
</sec>
</abstract>
<kwd-group kwd-group-type="author">
<title>KEYWORDS</title>
<kwd>Drug reviews</kwd>
<kwd>Transformer models</kwd>
<kwd>Text classification</kwd>
</kwd-group>
<counts>
<page-count count="6"/>
</counts>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<notes notes-type="financial-disclosure">
<title>Funding Statement</title><p>This study was partially supported by the National Institute on Aging (NIA) of the National Institutes of Health (NIH) under Award Number R21AG061431; and in part by Florida State University-University of Florida Clinical and Translational Science Award funded by National Center for Advancing Translational Sciences under Award Number UL1TR001427. The first author would like to thank eHealth Lab at FSU and the Undergraduate Research Opportunity Program at Florida State University for the mentorship and guidance.</p></notes>
<notes notes-type="disclosures">
<title>Author Declarations</title><p>I confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.</p><p>Yes</p><p>The details of the IRB/oversight body that provided approval or exemption for the research described are given below:</p><p>This project did not involve human subjects therefore IRB is not needed.</p><p>All necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived.</p><p>Yes</p><p>I understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).</p><p>Yes</p><p>I have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.</p><p>Yes</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<label>1</label>
<title>Introduction</title>
<p>The evaluation of the efficacy and safety of drugs heavily relies on the randomized controlled trials with rigorous inclusion and exclusion criteria [<xref ref-type="bibr" rid="c1">1</xref>]. However, such processes are limited to a small number of individuals enrolled in the study and are often constrained to participants in the target population that meet possibly restrictive eligibility criteria, limiting the population representativeness and subsequent study generalizability [<xref ref-type="bibr" rid="c2">2</xref>] [<xref ref-type="bibr" rid="c3">3</xref>]. The ramifications of these acclimations could potentially have resulted in the overestimate of the efficacy of the product and misidentification of adverse events/side effects in the diverse population [<xref ref-type="bibr" rid="c4">4</xref>]. To counter such issues, approaches such as post-marketing drug surveillance have been introduced to optimize the safety of the drug after its regulatory approval and mass production [<xref ref-type="bibr" rid="c5">5</xref>].</p>
<p>There are two major forms of post-marketing drug surveillance. Some are formed by government regulators such as the Vaccine Adverse Event Reporting System (VAERS) by the United States Food and Drug Administration [<xref ref-type="bibr" rid="c6">6</xref>] or the Yellow Card Scheme by the United Kingdom Medicines and Healthcare Products Regulatory Agency [<xref ref-type="bibr" rid="c7">7</xref>]. Also, public/private organizations have a system to monitor drug side-effects such as the Research on Adverse Drug events And Reports and various websites [<xref ref-type="bibr" rid="c8">8</xref>].</p>
<p>Prior methodologies consisted of the use of statistical measures to determine adverse events such as side effects. The typical methodology involved looking at query logs or other categorical variables for the identification of these events but did not focus specifically on the sentiment of the user through actual reviews [<xref ref-type="bibr" rid="c9">9</xref>].</p>
<p>The application of post-market drug surveillance has been successfully applied in the identification of adverse events through safety reports by the introduction of deep learning-based methods including the extraction of temporal events, the procedure performed, and social circumstance [<xref ref-type="bibr" rid="c10">10</xref>]. Adverse events have also been utilized for the identification of drug compounds, but also molecular drug compositions have also been used to predict adverse side effects [<xref ref-type="bibr" rid="c11">11</xref>].</p>
<p>In the era of Web 2.0, the Internet has opened up new unique pathways to obtain information about consumers&#x2019; drug reviews through websites on drug reviews. These reviews have contained a plethora of information regarding individual experiences associated with the drugs. Such reviews have contained an extensive amount of user sentiment related to a particular condition, which could be leveraged to detect the side effects and efficacy of drugs [<xref ref-type="bibr" rid="c12">12</xref>].</p>
<p>However, many barriers exist in the extraction of sentiment from these online medical reviews. For instance, user reviews of drugs in such online forms are typically unconventional and most reviewers lack medical knowledge which may pose barriers for meaningful extraction of information. In addition, many review websites have some form of numerical rating that has served the role of quantifying such a sentiment. Nevertheless, such applications may have introduced biases as individual users may have different understandings as to what a high score means versus what would have constituted a low score. Users have tended to reduce the effort required in reporting values by rating all qualities as highly important, thus resulting in overtly positive ratings [<xref ref-type="bibr" rid="c13">13</xref>]. This could lead to an unintended positive view of the overrated drugs by the general public, albeit less effective for certain population subgroups. Prior research [<xref ref-type="bibr" rid="c14">14</xref>] has found that web-based reviews have the potential to be viewed as an applicable source of information for analysis, but the direct reliance on consumer ratings could be biased by the consumer experience. For example, addictive drugs have been observed to be typically highly rated in comparison to other drugs which have treated the same condition, even if these additive drugs underperformed [<xref ref-type="bibr" rid="c14">14</xref>]. Thus, the ratings of those drugs may be skewed, thus a potential solution could be focusing on the relationship between the review and the rating, to identify differentiation between the skewed rating and what was typed in by the user [<xref ref-type="bibr" rid="c15">15</xref>].</p>
<p>Publicly available information on the Internet offers an easily attainable resource that could be potentially leveraged to gain a deep understanding of the drug reviews by the users. Entire user reviews are fully available on drug review websites, on which users can comment on their personal experiences of the drugs they have taken for a specific condition. Unlike many other forms of medical data, this information is not filtered through medical professionals. Since these reviews are given by anonymous users, there is no risk of patient health record violation for confidentiality.</p>
<p>The application of machine learning, especially through transformer-based language models pretrained with enormous amount of data, offers a unique approach to classify textual information through natural language processing [<xref ref-type="bibr" rid="c16">16</xref>]. In this project, we evaluated the feasibility of leveraging machine learning and natural language processing to classify user ratings based on their textual review to identify the locations of contingency. In addition, the model can be used to identify overtly positive or negative scores. Overtly positive or negative scores are user rating which was incorrectly classified by the model in order to identify some generalizations. We also used a computational technique to highlight phrases in the text that have positive or negative impact on the classification results.</p>
</sec>
<sec id="s2">
<label>2</label>
<title>Methods</title>
<sec id="s2a">
<label>2.1</label>
<title>Dataset Preparation</title>
<p>We obtained the dataset from the UCI Machine Learning Repository [<xref ref-type="bibr" rid="c17">17</xref>]. These instances were collected from Drugs.com using Beautiful Soup. As can be seen in <xref rid="tbl1" ref-type="table">Table 1</xref>, the dataset consists of user drug reviews, drug names, related medical conditions, and a 10-point rating. <xref rid="fig1" ref-type="fig">Figure 1</xref> shows the distribution of reviews by ratings. The ratings were shown to be skewed to the left to suggest that most drugs received a relatively high score. Prior analysis of this dataset focused primarily on the sentiment analysis [<xref ref-type="bibr" rid="c1">1</xref>]. They did not focus on classification of reviews [<xref ref-type="bibr" rid="c18">18</xref>]. Neither was there an emphasis on the error analysis of the models.</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1:</label>
<caption><title>Two examples of a high review versus a low review along with the information including condition, drug name, and rating.</title></caption>
<graphic xlink:href="21255573v1_tbl1.tif"/>
</table-wrap>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure 1:</label>
<caption><title>Total number of reviews in the dataset. The rating were integer values ranging from 1 to 10 with 10 being the highest possible rating.</title></caption>
<graphic xlink:href="21255573v1_fig1.tif"/>
</fig>
<p>In total, the dataset consists of 215,063 instances [<xref ref-type="bibr" rid="c19">19</xref>]. The dataset ratings had a mean of 7.00 with a standard deviation of 3.27. There are 836 classified medical conditions in the dataset.</p>
<p>Since the primary focus of this study was to classify textual reviews, the data was broken down using a median of the ratings: ratings 8 or above were considered <bold>above average</bold> and below 8 were considered as <bold>below average</bold>. Binary classification was chosen over multiple classes since the other objective of this project was to identify overtly positive and overtly negative scores which would be identified by misclassification of the system versus the actual score. Thus, misclassification identification in its simplest sense would only be possible with a binary system. Instances in which the reviews contained more than 514 tokens were removed from the study due to the input size limit of the transformer-based language models.</p>
</sec>
<sec id="s2b">
<label>2.2</label>
<title>Model Construction</title>
<sec id="s2b1">
<label>2.2.1</label>
<title>Transformer-Based Models</title>
<p>The common methodology for transfer learning has been through the application of pre-training on a large unannotated corpus that was capable of understanding the composition of the data type such as patterns in the language. This process could be considered as self-supervised learning. This pre-trained model is then followed by the fine-tuning process which focused on the training on an application-specific dataset.</p>
<sec id="s2b1a">
<title>BERT</title>
<p>Some common language models are pre-trained by predicting the next word in a sequence, but Bidirectional encoder representation from transformer (BERT) looked at bidirectional predicting context masked intermediate text tokens in the pretraining from Wikipedia and BookCorpus and next sentence prediction. Bert-base-uncased was used for this project[<xref ref-type="bibr" rid="c20">20</xref>].</p>
<p>In addition, BERT models such as clinical <bold>BioBERT</bold> have been pre-trained with a medical corpus from publicly available data from Pubmed and PMC [<xref ref-type="bibr" rid="c21">21</xref>]. The model which was used was from Huggingface labeled Bio_ClinicalBERT.</p>
</sec>
<sec id="s2b1b">
<title>ALBERT</title>
<p>A Lite BERT (ALBERT) is a model which focused on being a less memory-heavy and faster version of BERT through the separation of the word embedding into two matrixes and by cross-layer parameter sharing[<xref ref-type="bibr" rid="c22">22</xref>]. Albert-base-v2 was used for this model.</p>
</sec>
<sec id="s2b1c">
<title>RoBERTa</title>
<p>Robustly Optimized BERT Approach (RoBERTa) has been considered a pretraining model that eliminates the next sentence prediction task and adapts a novel approach of dynamic masking which randomized the masked token between training epochs[<xref ref-type="bibr" rid="c23">23</xref>]. RoBERTa out-performed BERT of multiple results such as GLUE, RACE, and SQuAD. Roberta-base was the model selected for this project.</p>
</sec>
<sec id="s2b1d">
<title>XLNet</title>
<p>As a more computationally expensive model, the Generalized Auto-Regressive model (XLNet) implemented a system where all masked tokens were predicted, but in a randomized fashion [<xref ref-type="bibr" rid="c24">24</xref>]. Contrary, to BERT where only 15&#x0025; of the masked token were predicted. XLNet-base-cased was the model selected for this project.</p>
</sec>
<sec id="s2b1e">
<title>ELECTRA</title>
<p>Efficiently Learning an Encoder that Classifies Token Replacements Accurately (ELECTRA) replaced the masked language task with a generator and pre-trains the model to identify which token has been replaced[<xref ref-type="bibr" rid="c25">25</xref>]. The Electra-base-discriminator was used for this project.</p>
</sec>
</sec>
<sec id="s2b2">
<label>2.2.2</label>
<title>Classification Model</title>
<p>We split the dataset into a training set (60&#x0025;), a validation set (20&#x0025;), and the test set (20&#x0025;). These datasets were further classified into lists which were then converted into Transformer dataset that could be trained by a neural network to generate a model.</p>
<p>We constructed these transformer-based text classification models utilizing the Huggingface transformers using the Python k-train pipeline wrapper class for text classification. The models used for this project consisted of BioBERT, ELECTRA, RoBERTa, XLNet, ALBERT, and BERT. The parameter included a 514 max token length, a 5e&#x005E;-5 learning rate, and a batch size of 6. The train test dataset was fed into the neural network trained to minimize validation data loss. After the training was completed, a confusion matrix of the test data was generated to determine F1 scores for the classes and the accuracy in comparison to the user ratings.</p>
<p>As a baseline measure for the comparison of these models with the transformer-based models, bag-of-words (BOW) models were constructed based on term frequency and inverse document frequency (TF-IDF). The textual reviews were converted into a bag of word representation. Afterward, a term frequency-inverse document frequency score matrix was computed for the bag of words representation. A Random Forest classifier and a Na&#x00EF;ve-Bayes classifier were evaluated with the BOW features.</p>
</sec>
<sec id="s2b3">
<label>2.2.3</label>
<title>Classification Modeling Interpretability</title>
<p>After the best performing transformer model was selected, to provide some expandability for the model, Eli5 metrics were applied to the model. Eli5 has been used to understand why a certain classification through the identification of important features such as highlighting significant text features [<xref ref-type="bibr" rid="c26">26</xref>]. This is accomplished by inspecting the model parameters to discover the global implications. This was performed for many reviews to establish some sense of how the model performed these classifications. Top scores were also computed through the Eli5 metrics.</p>
</sec>
<sec id="s2b4">
<label>2.2.4</label>
<title>Condition Specific Classification Modeling</title>
<p>The test data was stratified for the top 10 ten conditions based on the test data user reviews as seen in <xref rid="tbl2" ref-type="table">Table 2</xref>. The transformer models were then used to classify each of the different conditions to determine condition-specific f1 score and accuracy. The overall workflow is outlined in <xref rid="fig2" ref-type="fig">Figure 2</xref>.</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2:</label>
<caption><title>Condition-specific statistics. Birth Control was the most common condition which users reviewed followed by depression, pain, anxiety, and acne.</title></caption>
<graphic xlink:href="21255573v1_tbl2.tif"/>
</table-wrap>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure 2.</label>
<caption><title>The workflow of the project.</title></caption>
<graphic xlink:href="21255573v1_fig2.tif"/>
</fig>
</sec>
</sec>
</sec>
<sec id="s3">
<label>3</label>
<title>Results</title>
<p>Overall, the model generated by the BioBERT and ELECTRA outperformed the other models on a variety of metrics as displayed in <xref rid="tbl3" ref-type="table">Table 3</xref>. The BOW models showed lower accuracy compared to the other constructions. XLNet had the longest training time compared to the other models.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3:</label>
<caption><title>Overall condition validation from the test dataset for the minimized loss for the top preforming models</title></caption>
<graphic xlink:href="21255573v1_tbl3.tif"/>
</table-wrap>
<p><xref rid="tbl4" ref-type="table">Table 4</xref> shows the condition-specific classification for the top 10 conditions. The classification accuracy of instances of drugs used for pain, obesity, and insomnia are slightly lower than the other conditions.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4:</label>
<caption><title>Condition-specific statistics for the top 10 conditions.</title></caption>
<graphic xlink:href="21255573v1_tbl4.tif"/>
</table-wrap>
<p>The results generated in <xref rid="tbl5" ref-type="table">Table 5</xref> are produced using the Eli5 metrics using the BioBERT trained model. There is a clear relationship between the words highlighted and the classification that was made by the model. Terms highlighted in green supports the classification generated by the model, while terms generated in red opposes the predictions. Phrases related to side-effects were typically highlighted as below average features. An example for a incorrectly classified below average review revealed that terms such as burping, nausea, and diarrhea had a significant impact on the model classification for a below average review. Terms for different medications often had a strong impact on the classification. One factor to note was that &#x201C;Bactrim&#x201D;, the drug, was highlighted as an above-average feature even though it is a drug. This suggested that the model considered this term as important which could be classified as an example of overfitting that occurred in this model. It also indicates that the overall experience of this drug is positive.</p>
<table-wrap id="tbl5" orientation="portrait" position="float">
<label>Table 5:</label>
<caption><p>Example classification and interpretation generated by the Eli5 score metrics.</p></caption>
<graphic xlink:href="21255573v1_tbl5.tif"/>
</table-wrap>
</sec>
<sec id="s4">
<label>4</label>
<title>Discussion</title>
<p>We built multiple classification models through transformer-based architecture. These models were then to classify test data including condition-specific data. Afterward, the Eli5 toolkit was applied to help explain the models classification.</p>
<p>From these results, it was clear that the consumers&#x2019; online drug reviews contain a vast quantity of information regarding the sentiment expressed by the user. Transformer-based models have the potential to serve as a methodology to discriminate between overtly positive and truly positive scores. Overall, this research outlined a potential process to identify consumer drug review bias. This was concurrent with other studies which have found that subjective effects are often distorted in rating systems [<xref ref-type="bibr" rid="c27">27</xref>].</p>
<p>On a comparison of the transformer models, the BioBERT and ELECTRA model outperformed the other models on a multitude of metrics when the same amount of information was present, which was consistent with other research papers that involved the application of transformer-based models [<xref ref-type="bibr" rid="c28">28</xref>]. Surprisingly, BioBERT outperformed many other models such as RoBERTa, XLNet, and BERT. One potential reason for this occurrence was the fact that BioBERT model was pretrained through medical texts which were topically related to the drug reviews [<xref ref-type="bibr" rid="c29">29</xref>]. Since these drug reviews had reference to different condition and medication, this reviled that pretraining with text discussing these ideas is beneficial.</p>
<p>Overtly positive and negative scores could be identified by this model through the comparison of the model predicted score versus the score which the user rating (More examples are available on <ext-link ext-link-type="uri" xlink:href="https://github.com/akhilfsu/BCBACM">https://github.com/akhilfsu/BCBACM</ext-link>) Overtly positive tend to suggest that the review given by the user does not reflect the rating that the user gave and conversely for overtly negative scores. Disparities between user reviews and rating may signify that there may be a knowledge gap for the score criteria in the users or might indicate bias. The low classification accuracy of the model for pain-specific ELECTRA model indicated that many pain medications are addictive [<xref ref-type="bibr" rid="c30">30</xref>] which may result in overtly high classification even though the review may indicate that there have been issues with the medication such as side-effects or other adverse events.</p>
<sec id="s4a">
<label>4.1</label>
<title>Future Work</title>
<p>The binary classification application of ELECTRA and other transformer models could serve the potential of finding user reviews that contain complaints about medication. Another area of focus could be expanding this model for multi-class identification as this may be much more beneficial in the identification of highly negative reviews. In addition, this dataset could be applied to identify adverse effects for medication based solely on online social media data.</p>
</sec>
<sec id="s4b">
<label>4.2</label>
<title>Limitations</title>
<p>Although this model was able to successfully classify reviews in a binary system, the ability for large class identification is still unknown. One important issue with many transformer models was the issue of over-fitting. As seen in the misclassification there was a reliance on drug names in determining the classification. In addition, many transformer models such as XLNet are computationally expensive which may result in long training times.</p>
</sec>
</sec>
<sec id="s5">
<label>5</label>
<title>Conclusion</title>
<p>This study covered the construction of a transformer-based model for the classification of drug reviews from drugs.com. The most successful model in this project was the BioBERT model with the high F1 scores. Overall, the transformer models outperformed the bag of words models. These binary transformer models tended to be effective at decerning highly optimistic reviews from reviews that contain a mixture of positive and negative feedback.</p>
</sec>
</body>
<back>
<sec sec-type="data-availability">
<title>Data Availability</title>
<p>The dataset can be downloaded from <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29">https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29</ext-link>.</p>
<p>
<ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29">https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29</ext-link>
</p>
</sec>
<ack>
<title>ACKNOWLEDGMENTS</title>
<p>This study was partially supported by the National Institute on Aging (NIA) of the National Institutes of Health (NIH) under Award Number R21AG061431; and in part by Florida State University-University of Florida Clinical and Translational Science Award funded by National Center for Advancing Translational Sciences under Award Number UL1TR001427. The first author would like to thank eHealth Lab at FSU and the Undergraduate Research Opportunity Program at Florida State University for the mentorship and guidance.</p>
</ack>
<ref-list>
<title>REFERENCES</title>
<ref id="c1"><label>[1]</label><mixed-citation publication-type="journal"><string-name><given-names>Robert M.</given-names> <surname>Califf</surname></string-name>. <year>2012</year>. <article-title>Characteristics of Clinical Trials Registered in <ext-link ext-link-type="uri" xlink:href="http://ClinicalTrials.gov">ClinicalTrials.gov</ext-link>, 2007-2010</article-title>. <source>JAMA</source> <volume>307</volume>, <issue>17</issue> (<month>May</month> 2012), <fpage>1838</fpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1001/jama.2012.3424">https://doi.org/10.1001/jama.2012.3424</ext-link></mixed-citation></ref>
<ref id="c2"><label>[2]</label><mixed-citation publication-type="journal"><string-name><given-names>Kevin C.</given-names> <surname>Farmer</surname></string-name>. <year>1999</year>. <article-title>Methods for measuring and monitoring medication regimen adherence in clinical trials and clinical practice</article-title>. <source>Clinical Therapeutics</source> <volume>21</volume>, <issue>6</issue> (<month>June</month> 1999), <fpage>1074</fpage>&#x2013;<lpage>1090</lpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0149-2918(99)80026-5">https://doi.org/10.1016/S0149-2918(99)80026-5</ext-link></mixed-citation></ref>
<ref id="c3"><label>[3]</label><mixed-citation publication-type="journal"><string-name><given-names>Zhe</given-names> <surname>He</surname></string-name>, <string-name><given-names>Xiang</given-names> <surname>Tang</surname></string-name>, <string-name><given-names>Xi</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>Yi</given-names> <surname>Guo</surname></string-name>, <string-name><given-names>Thomas J.</given-names> <surname>George</surname></string-name>, <string-name><given-names>Neil</given-names> <surname>Charness</surname></string-name>, <string-name><given-names>Kelsa Bartley Quan</given-names> <surname>Hem</surname></string-name>, <string-name><given-names>William</given-names> <surname>Hogan</surname></string-name>, and <string-name><given-names>Jiang</given-names> <surname>Bian</surname></string-name>. <year>2020</year>. <article-title>Clinical Trial Generalizability Assessment in the Big Data Era: A Review</article-title>. <source>Clin Transl Sci</source> <volume>13</volume>, <issue>4</issue> (<month>July</month> 2020), <fpage>675</fpage>&#x2013;<lpage>684</lpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/cts.12764">https://doi.org/10.1111/cts.12764</ext-link></mixed-citation></ref>
<ref id="c4"><label>[4]</label><mixed-citation publication-type="journal"><string-name><given-names>Edward J</given-names> <surname>Mills</surname></string-name>, <string-name><given-names>Dugald</given-names> <surname>Seely</surname></string-name>, <string-name><given-names>Beth</given-names> <surname>Rachlis</surname></string-name>, <string-name><given-names>Lauren</given-names> <surname>Griffith</surname></string-name>, <string-name><given-names>Ping</given-names> <surname>Wu</surname></string-name>, <string-name><given-names>Kumanan</given-names> <surname>Wilson</surname></string-name>, <string-name><given-names>Peter</given-names> <surname>Ellis</surname></string-name>, and <string-name><given-names>James R</given-names> <surname>Wright</surname></string-name>. <year>2006</year>. <article-title>Barriers to participation in clinical trials of cancer: a meta-analysis and systematic review of patient-reported factors</article-title>. <source>The Lancet Oncology</source> <volume>7</volume>, <issue>2</issue> (<month>February</month> 2006), <fpage>141</fpage>&#x2013;<lpage>148</lpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S1470-2045(06)70576-9">https://doi.org/10.1016/S1470-2045(06)70576-9</ext-link></mixed-citation></ref>
<ref id="c5"><label>[5]</label><mixed-citation publication-type="journal"><string-name><given-names>Ik</given-names> <surname>Crombie</surname></string-name>. <year>1986</year>. <article-title>The role of record linkage in post-marketing drug surveillance</article-title>. <source>British Journal of Clinical Pharmacology</source> <volume>22</volume>, <issue>S1</issue> (<month>February</month> 1986), <fpage>77S</fpage>&#x2013;<lpage>82S</lpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1365-2125.1986.tb02987.x">https://doi.org/10.1111/j.1365-2125.1986.tb02987.x</ext-link></mixed-citation></ref>
<ref id="c6"><label>[6]</label><mixed-citation publication-type="journal"><string-name><surname>Tom</surname> <given-names>T. Shimabukuro</given-names></string-name>, <string-name><surname>Michael</surname> <given-names>Nguyen</given-names></string-name>, <string-name><surname>David</surname> <given-names>Martin</given-names></string-name>, and <string-name><surname>Frank</surname> <given-names>DeStefano.</given-names></string-name> <year>2015</year>. <article-title>Safety monitoring in the Vaccine Adverse Event Reporting System (VAERS)</article-title>. <source>Vaccine</source> <volume>33</volume>, <issue>36</issue> (<month>August</month> 2015), <fpage>4398</fpage>&#x2013;<lpage>4405</lpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.vaccine.2015.07.035">https://doi.org/10.1016/j.vaccine.2015.07.035</ext-link></mixed-citation></ref>
<ref id="c7"><label>[7]</label><mixed-citation publication-type="journal"><string-name><given-names>B.</given-names> <surname>O&#x2019; Donovan</surname></string-name>, <string-name><given-names>Ruth M.</given-names> <surname>Rodgers</surname></string-name>, <string-name><given-names>Anthony R.</given-names> <surname>Cox</surname></string-name>, and <string-name><given-names>Janet</given-names> <surname>Krska</surname></string-name>. <year>2019</year>. <article-title>Making medicines safer: analysis of patient reports to the UK&#x2019;s Yellow Card Scheme</article-title>. <source>Expert Opinion on Drug Safety</source> <volume>18</volume>, <issue>12</issue> (<month>December</month> 2019), <fpage>1237</fpage>&#x2013;<lpage>1243</lpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/14740338.2019.1669559">https://doi.org/10.1080/14740338.2019.1669559</ext-link></mixed-citation></ref>
<ref id="c8"><label>[8]</label><mixed-citation publication-type="journal"><string-name><given-names>Elad</given-names> <surname>Yom-Tov</surname></string-name> and <string-name><given-names>Evgeniy</given-names> <surname>Gabrilovich</surname></string-name>. <year>2013</year>. <article-title>Postmarket Drug Surveillance Without Trial Costs: Discovery of Adverse Drug Reactions Through Large-Scale Analysis of Web Search Queries</article-title>. <source>J Med Internet Res</source> <volume>15</volume>, <issue>6</issue> (<month>June</month> 2013), <fpage>e124</fpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2196/jmir.2614">https://doi.org/10.2196/jmir.2614</ext-link></mixed-citation></ref>
<ref id="c9"><label>[9]</label><mixed-citation publication-type="journal"><string-name><given-names>Martin</given-names> <surname>Kulldorff</surname></string-name>, <string-name><given-names>Robert L.</given-names> <surname>Davis</surname></string-name>, <string-name><surname>Margarette</surname> <given-names>Kolczak&#x2020;</given-names></string-name>, <string-name><given-names>Edwin</given-names> <surname>Lewis</surname></string-name>, <string-name><given-names>Tracy</given-names> <surname>Lieu</surname></string-name>, and <string-name><given-names>Richard</given-names> <surname>Platt</surname></string-name>. <year>2011</year>. <article-title>A Maximized Sequential Probability Ratio Test for Drug and Vaccine Safety Surveillance</article-title>. <source>Sequential Analysis</source> <volume>30</volume>, <issue>1</issue> (<month>January</month> 2011), <fpage>58</fpage>&#x2013;<lpage>78</lpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1080/07474946.2011.539924">https://doi.org/10.1080/07474946.2011.539924</ext-link></mixed-citation></ref>
<ref id="c10"><label>[10]</label><mixed-citation publication-type="website"><string-name><given-names>Jingcheng</given-names> <surname>Du</surname></string-name>, <string-name><given-names>Yang</given-names> <surname>Xiang</surname></string-name>, <string-name><given-names>Madhuri</given-names> <surname>Sankaranarayanapillai</surname></string-name>, <string-name><given-names>Meng</given-names> <surname>Zhang</surname></string-name>, <string-name><given-names>Jingqi</given-names> <surname>Wang</surname></string-name>, <string-name><given-names>Yuqi</given-names> <surname>Si</surname></string-name>, <string-name><given-names>Huy Anh</given-names> <surname>Pham</surname></string-name>, <string-name><given-names>Hua</given-names> <surname>Xu</surname></string-name>, <string-name><given-names>Yong</given-names> <surname>Chen</surname></string-name>, and <string-name><given-names>Cui</given-names> <surname>Tao</surname></string-name>. <year>2021</year>. <article-title>Extracting postmarketing adverse events from safety reports in the vaccine adverse event reporting system (VAERS) using deep learning</article-title>. <source>Journal of the American Medical Informatics Association</source> (<month>February</month> 2021), <fpage>ocab014</fpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/jamia/ocab014">https://doi.org/10.1093/jamia/ocab014</ext-link></mixed-citation></ref>
<ref id="c11"><label>[11]</label><mixed-citation publication-type="journal"><string-name><given-names>Sanjoy</given-names> <surname>Dey</surname></string-name>, <string-name><given-names>Heng</given-names> <surname>Luo</surname></string-name>, <string-name><given-names>Achille</given-names> <surname>Fokoue</surname></string-name>, <string-name><given-names>Jianying</given-names> <surname>Hu</surname></string-name>, and <string-name><given-names>Ping</given-names> <surname>Zhang</surname></string-name>. <year>2018</year>. <article-title>Predicting adverse drug reactions through interpretable deep learning framework</article-title>. <source>BMC Bioinformatics</source> <volume>19</volume>, <issue>S21</issue> (<month>December</month> 2018), <fpage>476</fpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s12859-018-2544-0">https://doi.org/10.1186/s12859-018-2544-0</ext-link></mixed-citation></ref>
<ref id="c12"><label>[12]</label><mixed-citation publication-type="other"><string-name><given-names>Thu</given-names> <surname>Dinh</surname></string-name> and <string-name><given-names>Goutam</given-names> <surname>Chakraborty</surname></string-name>. 2020. <article-title>Detecting Side Effects and Evaluating the Effectiveness of Drugs from Customers&#x2019; Online Reviews using Text Analytics, Sentiment Analysis, and Machine Learning Models</article-title>. <source>sas-global-forum-proceedings</source> (<year>2020</year>), <fpage>1</fpage>&#x2013;<lpage>23</lpage>.</mixed-citation></ref>
<ref id="c13"><label>[13]</label><mixed-citation publication-type="journal"><string-name><given-names>Airo</given-names> <surname>Hino</surname></string-name> and <string-name><given-names>Ryosuke</given-names> <surname>Imai</surname></string-name>. <year>2019</year>. <article-title>Ranking and Rating: Neglected Biases in Factor Analysis of Postmaterialist Values</article-title>. <source>International Journal of Public Opinion Research</source> <volume>31</volume>, <issue>2</issue> (<month>June</month> 2019), <fpage>368</fpage>&#x2013;<lpage>381</lpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/ijpor/edy007">https://doi.org/10.1093/ijpor/edy007</ext-link></mixed-citation></ref>
<ref id="c14"><label>[14]</label><mixed-citation publication-type="journal"><string-name><given-names>Paula</given-names> <surname>Tanabe</surname></string-name> and <string-name><given-names>MaryBeth</given-names> <surname>Buschmann</surname></string-name>. <year>1999</year>. <article-title>A prospective study of ED pain management practices and the patient&#x2019;s perspective</article-title>. <source>Journal of Emergency Nursing</source> <volume>25</volume>, <issue>3</issue> (<month>June</month> 1999), <fpage>171</fpage>&#x2013;<lpage>177</lpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/S0099-1767(99)70200-X">https://doi.org/10.1016/S0099-1767(99)70200-X</ext-link></mixed-citation></ref>
<ref id="c15"><label>[15]</label><mixed-citation publication-type="journal"><string-name><given-names>Swarnaseetha</given-names> <surname>Adusumalli</surname></string-name>, <string-name><given-names>HueyTyng</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>Qiangze</given-names> <surname>Hoi</surname></string-name>, <string-name><given-names>Si-Lin</given-names> <surname>Koo</surname></string-name>, <string-name><given-names>Iain Beehuat</given-names> <surname>Tan</surname></string-name>, and <string-name><given-names>Pauline Crystal</given-names> <surname>Ng</surname></string-name>. <year>2015</year>. <article-title>Assessment of Web-Based Consumer Reviews as a Resource for Drug Performance</article-title>. <source>J Med Internet Res</source> <volume>17</volume>, <issue>8</issue> (<month>August</month> 2015), <fpage>e211</fpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.2196/jmir.4396">https://doi.org/10.2196/jmir.4396</ext-link></mixed-citation></ref>
<ref id="c16"><label>[16]</label><mixed-citation publication-type="website"><string-name><given-names>David D.</given-names> <surname>Lewis</surname></string-name>. <year>1996</year>. <article-title>Challenges in machine learning for text classification</article-title>. In <source>Proceedings of the ninth annual conference on Computational learning theory - COLT &#x2018;96, ACM Press, Desenzano del Garda, Italy, 1-ff</source>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1145/238061.238062">https://doi.org/10.1145/238061.238062</ext-link></mixed-citation></ref>
<ref id="c17"><label>[17]</label><mixed-citation publication-type="website"><collab>UCI</collab>. <source>Drug Review Dataset (Drugs.com) Data Set</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29">https://archive.ics.uci.edu/ml/datasets/Drug+Review+Dataset+%28Drugs.com%29</ext-link></mixed-citation></ref>
<ref id="c18"><label>[18]</label><mixed-citation publication-type="website"><collab>Sairamvinay Vijayaraghavan and Debraj Basu</collab>. <source>Sentiment Analysis in Drug Reviews using Supervised Machine Learning Algorithms</source>. Retrieved from <ext-link ext-link-type="uri" xlink:href="https://arxiv.org/abs/2003.11643">https://arxiv.org/abs/2003.11643</ext-link></mixed-citation></ref>
<ref id="c19"><label>[19]</label><mixed-citation publication-type="website"><string-name><surname>Felix</surname> <given-names>Gr&#x00E4;&#x00DF;er</given-names></string-name>, <string-name><given-names>Surya</given-names> <surname>Kallumadi</surname></string-name>, <string-name><given-names>Hagen</given-names> <surname>Malberg</surname></string-name>, and <string-name><given-names>Sebastian</given-names> <surname>Zaunseder</surname></string-name>. <year>2018</year>. <article-title>Aspect-Based Sentiment Analysis of Drug Reviews Applying Cross- Domain and Cross-Data Learning</article-title>. In <source>Proceedings of the 2018 International Conference on Digital Health, ACM, Lyon France, 121&#x2013;125</source>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1145/3194658.3194677">https://doi.org/10.1145/3194658.3194677</ext-link></mixed-citation></ref>
<ref id="c20"><label>[20]</label><mixed-citation publication-type="website"><string-name><given-names>Jacob</given-names> <surname>Devlin</surname></string-name>, <string-name><given-names>Ming-Wei</given-names> <surname>Chang</surname></string-name>, <string-name><given-names>Kenton</given-names> <surname>Lee</surname></string-name>, and <string-name><given-names>Kristina</given-names> <surname>Toutanova</surname></string-name>. <year>2019</year>. <source>BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</source>. <pub-id pub-id-type="arxiv">1810.04805</pub-id> [cs] (May 2019). Retrieved March 5, 2021 from <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1810.04805">http://arxiv.org/abs/1810.04805</ext-link></mixed-citation></ref>
<ref id="c21"><label>[21]</label><mixed-citation publication-type="website"><string-name><given-names>Jinhyuk</given-names> <surname>Lee</surname></string-name>, <string-name><given-names>Wonjin</given-names> <surname>Yoon</surname></string-name>, <string-name><given-names>Sungdong</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>Donghyeon</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>Sunkyu</given-names> <surname>Kim</surname></string-name>, <string-name><given-names>Chan Ho</given-names> <surname>So</surname></string-name>, and <string-name><given-names>Jaewoo</given-names> <surname>Kang</surname></string-name>. <year>2019</year>. <article-title>BioBERT: a pre-trained biomedical language representation model for biomedical text mining</article-title>. <source>Bioinformatics</source> (<month>September</month> 2019), <fpage>btz682</fpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/bioinformatics/btz682">https://doi.org/10.1093/bioinformatics/btz682</ext-link></mixed-citation></ref>
<ref id="c22"><label>[22]</label><mixed-citation publication-type="journal"><string-name><given-names>Zhenzhong</given-names> <surname>Lan</surname></string-name>, <string-name><given-names>Mingda</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Sebastian</given-names> <surname>Goodman</surname></string-name>, <string-name><given-names>Kevin</given-names> <surname>Gimpel</surname></string-name>, <string-name><given-names>Piyush</given-names> <surname>Sharma</surname></string-name>, and <string-name><given-names>Radu</given-names> <surname>Soricut</surname></string-name>. <year>2020</year>. <source>ALBERT: A Lite BERT for Self-supervised Learning of Language Representations</source>. <pub-id pub-id-type="arxiv">1909.11942</pub-id> [cs] (<month>February</month> 2020). Retrieved February <volume>28</volume>, <issue>2021 from</issue> <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1909.11942">http://arxiv.org/abs/1909.11942</ext-link></mixed-citation></ref>
<ref id="c23"><label>[23]</label><mixed-citation publication-type="website"><string-name><given-names>Yinhan</given-names> <surname>Liu</surname></string-name>, <string-name><given-names>Myle</given-names> <surname>Ott</surname></string-name>, <string-name><given-names>Naman</given-names> <surname>Goyal</surname></string-name>, <string-name><given-names>Jingfei</given-names> <surname>Du</surname></string-name>, <string-name><given-names>Mandar</given-names> <surname>Joshi</surname></string-name>, <string-name><given-names>Danqi</given-names> <surname>Chen</surname></string-name>, <string-name><given-names>Omer</given-names> <surname>Levy</surname></string-name>, <string-name><given-names>Mike</given-names> <surname>Lewis</surname></string-name>, <string-name><given-names>Luke</given-names> <surname>Zettlemoyer</surname></string-name>, and <string-name><given-names>Veselin</given-names> <surname>Stoyanov</surname></string-name>. <year>2019</year>. <source>RoBERTa: A Robustly Optimized BERT Pretraining Approach</source>. <pub-id pub-id-type="arxiv">1907.11692</pub-id> [cs] (<month>July</month> 2019). Retrieved March 5, 2021 from <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1907.11692">http://arxiv.org/abs/1907.11692</ext-link></mixed-citation></ref>
<ref id="c24"><label>[24]</label><mixed-citation publication-type="website"><string-name><given-names>Zhilin</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>Zihang</given-names> <surname>Dai</surname></string-name>, <string-name><given-names>Yiming</given-names> <surname>Yang</surname></string-name>, <string-name><given-names>Jaime</given-names> <surname>Carbonell</surname></string-name>, <string-name><given-names>Ruslan</given-names> <surname>Salakhutdinov</surname></string-name>, and <string-name><given-names>Quoc V.</given-names> <surname>Le</surname></string-name>. <year>2020</year>. <source>XLNet: Generalized Autoregressive Pretraining for Language Understanding</source>. <pub-id pub-id-type="arxiv">1906.08237</pub-id> [cs] (January 2020). Retrieved February 28, 2021 from <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1906.08237">http://arxiv.org/abs/1906.08237</ext-link></mixed-citation></ref>
<ref id="c25"><label>[25]</label><mixed-citation publication-type="website"><string-name><given-names>Kevin</given-names> <surname>Clark</surname></string-name>, <string-name><given-names>Minh-Thang</given-names> <surname>Luong</surname></string-name>, <string-name><given-names>Quoc V.</given-names> <surname>Le</surname></string-name>, and <string-name><given-names>Christopher D.</given-names> <surname>Manning</surname></string-name>. <year>2020</year>. <source>ELECTRA: Pre-training Text Encoders as Discriminators Rather Than Generators</source>. <pub-id pub-id-type="arxiv">2003.10555</pub-id> [cs] (March 2020). Retrieved February 28, 2021 from <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/2003.10555">http://arxiv.org/abs/2003.10555</ext-link></mixed-citation></ref>
<ref id="c26"><label>[26]</label><mixed-citation publication-type="website"><string-name><given-names>Namita</given-names> <surname>Agarwal</surname></string-name> and <string-name><given-names>Saikat</given-names> <surname>Das</surname></string-name>. <year>2020</year>. <source>Interpretable Machine Learning Tools: A Survey. In 2020 IEEE Symposium Series on Computational Intelligence (SSCI), IEEE, Canberra, ACT, Australia, 1528&#x2013;1534</source>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/SSCI47803.2020.9308260">https://doi.org/10.1109/SSCI47803.2020.9308260</ext-link></mixed-citation></ref>
<ref id="c27"><label>[27]</label><mixed-citation publication-type="journal"><string-name><given-names>M. Abou</given-names> <surname>Taam</surname></string-name>, <string-name><given-names>C.</given-names> <surname>Rossard</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Cantaloube</surname></string-name>, <string-name><given-names>N.</given-names> <surname>Bouscaren</surname></string-name>, <string-name><given-names>G.</given-names> <surname>Roche</surname></string-name>, <string-name><given-names>L.</given-names> <surname>Pochard</surname></string-name>, <string-name><given-names>F.</given-names> <surname>Montastruc</surname></string-name>, <string-name><given-names>A.</given-names> <surname>Herxheimer</surname></string-name>, <string-name><given-names>J. L.</given-names> <surname>Montastruc</surname></string-name>, and <string-name><given-names>H.</given-names> <surname>Bagheri</surname></string-name>. <year>2014</year>. <article-title>Analysis of patients&#x2019; narratives posted on social media websites on benfluorex&#x2019;s (Mediator &#x00AE;) withdrawal in France</article-title>. <source>J Clin Pharm Ther</source> <volume>39</volume>, <issue>1</issue> (<month>February</month> 2014), <fpage>53</fpage>&#x2013;<lpage>55</lpage>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/jcpt.12103">https://doi.org/10.1111/jcpt.12103</ext-link></mixed-citation></ref>
<ref id="c28"><label>[28]</label><mixed-citation publication-type="other"><string-name><given-names>Laiba</given-names> <surname>Mehnaz</surname></string-name>. <year>2020</year>. <source>Automatic Classification of Tweets Mentioning a Medication Using Pre-trained Sentence Encoders. (2020)</source>.</mixed-citation></ref>
<ref id="c29"><label>[29]</label><mixed-citation publication-type="website"><string-name><given-names>Keval</given-names> <surname>Pipalia</surname></string-name>, <string-name><given-names>Rahul</given-names> <surname>Bhadja</surname></string-name>, and <string-name><given-names>Madhu</given-names> <surname>Shukla</surname></string-name>. <year>2020</year>. <article-title>Comparative Analysis of Different Transformer Based Architectures Used in Sentiment Analysis</article-title>. In <source>2020 9th International Conference System Modeling and Advancement in Research Trends (SMART), IEEE, Moradabad, India, 411&#x2013; 415</source>. DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/SMART50582.2020.9337081">https://doi.org/10.1109/SMART50582.2020.9337081</ext-link></mixed-citation></ref>
<ref id="c30"><label>[30]</label><mixed-citation publication-type="website"><string-name><given-names>Jan Christian Blaise</given-names> <surname>Cruz</surname></string-name> and <string-name><given-names>Charibeth</given-names> <surname>Cheng</surname></string-name>. 2019. <source>Evaluating Language Model Finetuning Techniques for Low-resource Languages</source>. <pub-id pub-id-type="arxiv">1907.00409</pub-id> [cs] (<year>2019</year>). DOI: <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.13140/RG.2.2.23028.40322">https://doi.org/10.13140/RG.2.2.23028.40322</ext-link></mixed-citation></ref>
</ref-list>
</back>
</article>