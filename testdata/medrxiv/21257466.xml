<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE article PUBLIC "-//NLM//DTD JATS (Z39.96) Journal Archiving and Interchange DTD v1.2d1 20170631//EN" "JATS-archivearticle1.dtd">
<article xmlns:mml="http://www.w3.org/1998/Math/MathML" xmlns:xlink="http://www.w3.org/1999/xlink" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" article-type="article" dtd-version="1.2d1" specific-use="production" xml:lang="en">
<front>
<journal-meta>
<journal-id journal-id-type="publisher-id">MEDRXIV</journal-id>
<journal-title-group>
<journal-title>medRxiv</journal-title>
<abbrev-journal-title abbrev-type="publisher">medRxiv</abbrev-journal-title>
</journal-title-group>
<publisher>
<publisher-name>Cold Spring Harbor Laboratory</publisher-name>
</publisher>
</journal-meta>
<article-meta>
<article-id pub-id-type="doi">10.1101/2021.05.19.21257466</article-id>
<article-version>1.1</article-version>
<article-categories>
<subj-group subj-group-type="hwp-journal-coll">
<subject>Health Informatics</subject>
</subj-group>
</article-categories>
<title-group>
<article-title>Deep Neural Networks for Human&#x2019;s Fall-risk Prediction using Force-Plate Time Series Signal</article-title>
</title-group>
<contrib-group>
<contrib contrib-type="author">
<name><surname>Savadkoohi</surname><given-names>M.</given-names></name>
<xref ref-type="aff" rid="a1">1</xref>
</contrib>
<contrib contrib-type="author" corresp="yes">
<name><surname>Oladunni</surname><given-names>T.</given-names></name>
<xref ref-type="aff" rid="a2">2</xref>
<xref ref-type="corresp" rid="cor1">&#x002A;</xref>
</contrib>
<contrib contrib-type="author">
<name><surname>Thompson</surname><given-names>L.A.</given-names></name>
<xref ref-type="aff" rid="a3">3</xref>
</contrib>
<aff id="a1"><label>1</label><institution>School of Engineering and Applied Sciences, University of District of Columbia</institution>, Washington DC, <country>USA</country>, Email: <email>marzieh.savadkoohi@udc.edu</email></aff>
<aff id="a2"><label>2</label><institution>Department of Computer Science, University of District of Columbia</institution>, Washington DC, <country>USA</country>, Email: <email>timothy.oladunni@udc.edu</email></aff>
<aff id="a3"><label>3</label><institution>Department of Mechanical Engineering, University of District of Columbia</institution>, Washington DC, <country>USA</country>, Email: <email>lara.thompson@udc.edu</email></aff>
</contrib-group>
<author-notes>
<corresp id="cor1"><label>&#x002A;</label>Corresponding author: T. Oladunni (e-mail: <email>timothy.oladunni@udc.edu</email>).</corresp>
</author-notes>
<pub-date pub-type="epub">
<year>2021</year>
</pub-date>
<elocation-id>2021.05.19.21257466</elocation-id>
<history>
<date date-type="received">
<day>19</day>
<month>5</month>
<year>2021</year>
</date>
<date date-type="rev-recd">
<day>19</day>
<month>5</month>
<year>2021</year>
</date>
<date date-type="accepted">
<day>21</day>
<month>5</month>
<year>2021</year>
</date>
</history>
<permissions>
<copyright-statement>&#x00A9; 2021, Posted by Cold Spring Harbor Laboratory</copyright-statement>
<copyright-year>2021</copyright-year>
<license license-type="creative-commons" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/"><license-p>This pre-print is available under a Creative Commons License (Attribution-NonCommercial-NoDerivs 4.0 International), CC BY-NC-ND 4.0, as described at <ext-link ext-link-type="uri" xlink:href="http://creativecommons.org/licenses/by-nc-nd/4.0/">http://creativecommons.org/licenses/by-nc-nd/4.0/</ext-link></license-p></license>
</permissions>
<self-uri xlink:href="21257466.pdf" content-type="pdf" xlink:role="full-text"/>
<abstract>
<title>ABSTRACT</title>
<p>Early and accurate identification of the balance deficits could reduce falls, in particular for older adults, a prone population. Our work investigates deep neural networks&#x2019; capacity to identify human balance patterns towards predicting fall-risk. Human balance ability can be characterized based on commonly-used balance metrics, such as those derived from the force-plate time series. We hypothesized that low, moderate, and high risk of falling can be characterized based on balance metrics, derived from the force-plate time series, in conjunction with deep learning algorithms. Further, we predicted that our proposed One-One-One Deep Neural Networks algorithm provides a considerable increase in performance compared to other algorithms. Here, an open source force-plate dataset, which quantified human balance from a wide demographic of human participants (163 females and males aged 18-86) for varied standing conditions (eyes-open firm surface, eyes-closed firm surface, eyes-open foam surface, eyes-closed foam surface) was used. Classification was based on one of the several indicators of fall-risk tied to the fear of falling: the clinically-used Falls Efficacy Scale (FES) assessment. For human fall-risk prediction, the deep learning architecture implemented comprised of: Recurrent Neural Network (RNN), Long-Short Time Memory (LSTM), One Dimensional Convolutional Neural Network (1D-CNN), and a proposed One-One-One Deep Neural Network. Results showed that our One-One-One Deep Neural Networks algorithm outperformed the other aforementioned algorithms and state-of-the-art models on the same dataset. With an accuracy, precision, and sensitivity of 99.9&#x0025;, 100&#x0025;, 100&#x0025;, respectively at the 12th epoch, we found that our proposed One-One-One Deep Neural Network model is the most efficient neural network in predicting human&#x2019;s fall-risk (based on the FES measure) using the force-plate time series signal. This is a novel methodology for an accurate prediction of human risk of fall.</p>
</abstract>
<kwd-group kwd-group-type="author">
<title>Keywords</title>
<kwd>Aging</kwd>
<kwd>Balance disorder</kwd>
<kwd>Balance impairment</kwd>
<kwd>CNN</kwd>
<kwd>C-LSTM</kwd>
<kwd>Deep Learning</kwd>
<kwd>Fall-risk</kwd>
<kwd>Force-plate</kwd>
<kwd>LSTM</kwd>
<kwd>Neural Network</kwd>
<kwd>RNN</kwd>
</kwd-group>
<counts>
<page-count count="19"/>
</counts>
</article-meta>
<notes>
<notes notes-type="competing-interest-statement">
<title>Competing Interest Statement</title><p>The authors have declared no competing interest.</p></notes>
<notes notes-type="financial-disclosure">
<title>Funding Statement</title><p>We would like to acknowledge the University of the District of Columbia. Further, we would like to acknowledge the Department on Aging and Community Living (DACL) for their sponsorship. We also like to acknowledge the following federal funding sources: National Science Foundation (NSF) Award#s 2032345, 1654474, and1700219.</p></notes>
<notes notes-type="disclosures">
<title>Author Declarations</title><p>I confirm all relevant ethical guidelines have been followed, and any necessary IRB and/or ethics committee approvals have been obtained.</p><p>Yes</p><p>The details of the IRB/oversight body that provided approval or exemption for the research described are given below:</p><p>This paper is based on an open-source data.
The main research provided open access data can be found here:
<ext-link ext-link-type="uri" xlink:href="https://peerj.com/articles/2648/">https://peerj.com/articles/2648/</ext-link></p><p>All necessary patient/participant consent has been obtained and the appropriate institutional forms have been archived.</p><p>Yes</p><p>I understand that all clinical trials and any other prospective interventional studies must be registered with an ICMJE-approved registry, such as ClinicalTrials.gov. I confirm that any such study reported in the manuscript has been registered and the trial registration ID is provided (note: if posting a prospective study registered retrospectively, please provide a statement in the trial ID field explaining why the study was not registered in advance).</p><p>Yes</p><p>I have followed all appropriate research reporting guidelines and uploaded the relevant EQUATOR Network research reporting checklist(s) and other pertinent material as supplementary files, if applicable.</p><p>Yes</p></notes>
</notes>
</front>
<body>
<sec id="s1">
<label>I.</label>
<title>Introduction</title>
<p>The detection of fall-risk linked balance impairment is of significant societal relevance. Falling has been reported as the second most common reason of accidental injuries and death, with road traffic accidents being the first (World Health Organization-Falls, n.d.). Treating fall-related injuries is extremely costly. In the United States, costs related to fatal and nonfatal falls in year 2000 was estimated as &#x0024;0.2 billion and &#x0024;19 billion respectively for the adults over the age of 65 (<xref ref-type="bibr" rid="c62">Stevens et al., 2006</xref>). This number increased to &#x0024;50 billion in 2015 (<xref ref-type="bibr" rid="c19">Florence et al., 2018</xref>). Balance impairment can have devastating effects on all individuals; though, particularly, older individuals are a vulnerable population. Thus, studying the balance characteristics and comparing the underlying patterns of balance attributes could be significantly helpful in predicting fall and reduce its associated risk.</p>
<p>Balance aids us in maintaining stability and preventing falls during a variety of daily activities that we often take for granted, such as getting up out of bed or from a chair, standing, and walking (Balance Disorders &#x2014; Causes, Types &#x0026; Treatment &#x007C; NIDCD, n.d.; <xref ref-type="bibr" rid="c66">Winter, 1995</xref>). However, musculoskeletal, vestibular, visual, somatosensory, and proprioceptive disorders can lead to balance disorders in wide range of people (Balance Problems - Symptoms and Causes - Mayo Clinic, n.d.; <xref ref-type="bibr" rid="c50">Pialasse et al., 2016</xref>). Numerous studies have shown that older people, in particular, are more affected by balance impairment (<xref ref-type="bibr" rid="c1">Abrahamov&#x00E1; D, 2008</xref>; <xref ref-type="bibr" rid="c2">Alexander, 1996</xref>; <xref ref-type="bibr" rid="c11">Brooke, 2010</xref>). Older adults are more prone to balance impairment due to the natural process of aging which results in degeneration of the above systems, confounded by muscle weakness and other age-related disorders, such as Parkinson&#x2019;s disease, Stroke, Chronic Tremor, Multiple Sclerosis, and osteoporosis. Older people who suffer from these impairments are highly prone to fall and fall-related injuries (<xref ref-type="bibr" rid="c3">Alshammari et al., 2018</xref>; <xref ref-type="bibr" rid="c9">Beghi et al., 2018</xref>; <xref ref-type="bibr" rid="c49">Ozcan et al., 2005</xref>; <xref ref-type="bibr" rid="c63">Thompson et al., 2018</xref>).</p>
<p>Aside from physical injury due to falling, according to the National Institute of Aging (NIA), fear of falling increases as people age. As a result, older people tend to isolate themselves and avoid regular social activities (Prevent Falls and Fractures &#x007C; National Institute on Aging, n.d.). This situation leads to other physical and mental disorders (e.g., decrease in bone mineral density, fractures, loss of independence, loss of confidence, anxiety, depression, panic attacks). Studies have shown that 13&#x0025; of adults experience imbalance during the age range of 65-69 years old and this number increases to 46&#x0025; percent after the age of 85 (<xref ref-type="bibr" rid="c13">Burns &#x0026; Kakara, 2018</xref>; <xref ref-type="bibr" rid="c48">Osoba et al., 2019</xref>).</p>
<p>This paper is organized as follows: Section II overviews the available literature and highlights some of the studies conducted on the human balance and gait characteristics; Section III explains the materials and methods for the study and our methodology; Section IV explains the experimental results and V our discussions. We present our conclusions in Section VI.</p>
</sec>
<sec id="s2">
<label>II.</label>
<title>Literature Review</title>
<p>Researchers have employed various techniques to record human static and dynamic balance characteristics towards the ultimate goal of preventing falls. Using various equipment and analytical methods, scientists have gained a broad perspective towards human balance underlying patterns and factors that might affect the ability of humans in having a safe and normal life.</p>
<p>Kinematics and kinetics metrics are valuable indicators of human balance and postural control and are acquired using technologies, such as motion capture, force-plate, electromyography (EMG), sensors, accelerometers (<xref ref-type="bibr" rid="c66">Winter, 1995</xref>). The force-plate is perhaps the most popular equipment used to measure standing balance and gait. To identify and treat balance disorders, appropriate identification methods must be employed. Physicians and/or physical therapists often use conventional clinical methods to determine what is considered &#x201C;good&#x201D; or &#x201C;poor&#x201D; balance.</p>
<p>Clinical tests evaluate postural control of people and their stability (balance) while doing several static and/or dynamic motor tasks. Some examples are Activities-Specific Balance Confidence (ABC), Berg Balance Scale (BBS), Timed Up to Go test (TUG), Fall Efficacy Scale (FES) and Balance Error Scoring System (BESS). The advantages of these assessments are that they are easy to use, require minimal (if any) equipment, are quick to administer and inexpensive. However, they provide limited information to quantify the underlying balance metrics and provide a general understanding of balance ability.</p>
<p>Force-plates are practical devices used in research and clinical studies to characterizes gait, balance, and other biomechanics features. Sport and performance monitoring, balance impairment detection, occupational safety and motion analysis are some of the main applications of this measuring instrument. Time series signals recorded by force-plate sensors from which features, such as Center of Pressure (CoP), Forces (GRFs) and Moment (M) of forces as one moves across them, can be extracted.</p>
<p>The reliability of force-plate time series data with different test conditions has been proved and discussed by several researchers (<xref ref-type="bibr" rid="c8">Bauer et al., 2010</xref>; <xref ref-type="bibr" rid="c23">Golriz et al., 2012</xref>; <xref ref-type="bibr" rid="c42">Martina Mancini et al., 2012</xref>). The displacement of Center-of-Pressure (CoP), derived from the force-plate, is often used to characterize gait and balance (<xref ref-type="bibr" rid="c30">Hof et al., 2005</xref>; <xref ref-type="bibr" rid="c56">Ruhe et al., 2010</xref>). The CoP represents body motion in space as detected at the interface between the feet and the ground. The COP displacement time series represents the location of the (resultant) vertical Ground Reaction Force vector. This is used as a mean to quantify one&#x2019;s balance: greater displacement of the CoP position could mean greater instability. Features such as Root-Mean-Square (RMS) of medial-lateral (M/L) and anterior-posterior (A/P) directions, Sway area, Axis length, etc. could be also extracted from time series.</p>
<p>Combining functional tests results with sensor-based measurement (e.g., force-plate) can provide valuable information for gait and balance analysis. Force-plate measurement provides more sensitive and precise measurement due to its application in the experimental environments and has decreased: test variability, subjectivity of the scoring system and sensitivity to small changes (<xref ref-type="bibr" rid="c40">M. Mancini &#x0026; Horak, 2010a</xref>).</p>
<p>To draw a complete picture of the human&#x2019;s gait and balance and investigate the motion&#x2019;s kinetics and kinematics, dos Santos et al. used 42 markers, integrated with a 3-D motion capture system, on each subject&#x2019;s full body. They recorded different parameters such as Ground Reaction Forces (GRF), Center of Pressure (CoP), Center of Gravity and participants&#x2019; joint angles through the combination of both motion capture and force-plate measurements. Using this approach, they managed to create a rich quantitative evaluation of human balance (<xref ref-type="bibr" rid="c17">dos Santos et al., 2017</xref>).</p>
<p>In <xref rid="tbl1" ref-type="table">Table 1</xref>, we summarize several studies that used combination of force-plate and other tools to record human&#x2019;s biomechanical gait and balance features and investigated the effect of various factors on postural control. Each of the summarized studies have used various techniques to analyze human balance. Giovanini et al. classified balance characteristics of older adults as low or high risk of falling. They used the same dataset in this study (<xref ref-type="bibr" rid="c16">dos Santos &#x0026; Duarte, 2016</xref>) which contains subjects&#x2019; CoP information in the form of time series signals. By applying six different Machine Learning (ML) techniques and extracting 34 temporal/spatial features from the subjects&#x2019; CoP, they showed high discriminative powers in the 60 seconds-time series. Among all ML methods in the study, the highest accuracy they achieved, was 64.9&#x0025; by Random Forest (RF) classification method (<xref ref-type="bibr" rid="c22">Giovanini et al., 2018</xref>).</p>
<table-wrap id="tbl1" orientation="portrait" position="float">
<label>Table 1</label>
<caption><p>Overview of studies on commonly used balance/gait metrics and different analyzing techniques</p></caption>
<graphic xlink:href="21257466v1_tbl1.tif"/>
</table-wrap>
<p>Reilly used (<xref ref-type="bibr" rid="c54">Reilly, 2019</xref>), the same open-source dataset (<xref ref-type="bibr" rid="c16">dos Santos &#x0026; Duarte, 2016</xref>) to study risk of fall. At the first stage, they extracted 528 features in the time and frequency domain. Feature selection methods such as a filter-based feature selection algorithm called ReliefF, Self-adapting feature evaluation (SAFE), etc. were employed to find the optimal number of features for classification. With 18 features through the SAFE method, the experiment result showed the highest classification of accuracy of 80&#x0025; using Multiple Layer Perceptron (MLP). The experiment was based on 73 older subjects (out of 163 total participants) of the dataset, who were either at the low or high risk of fall. Other classifiers used were Support Vector Machine (SVM), K-Nearest Neighbors (K-NN) and Na&#x00EF;ve Bayes (NB) with performance range of 75 to77 &#x0025; accuracy (<xref ref-type="bibr" rid="c54">Reilly, 2019</xref>).</p>
<p>Another work on the same data (<xref ref-type="bibr" rid="c16">dos Santos &#x0026; Duarte, 2016</xref>), was done by Cetin and his colleague. In their work, they discriminated between young-aged groups using different machine learning techniques such as SVM, K-NN, Decision Tree (DT), Linear Discriminant Analysis (LDA), etc. Employing force signals of the dataset, the experimental result showed the highest classification accuracy of 81.67&#x0025; by SVMs (<xref ref-type="bibr" rid="c14">Cetin &#x0026; Bilgin, 2019</xref>).</p>
<p>In the above studies, statistical analysis and/or machine learning techniques, were employed by a domain expert who had related research experiences and extracted relevant features for fall risk detection or group discrimination. Santos and Duarte employed the &#x2018;shallow&#x2019; Neural Networks approach to analyze the same data used in this study (<xref ref-type="bibr" rid="c16">dos Santos &#x0026; Duarte, 2016</xref>). The results of their experiment showed the highest accuracy of up to 80&#x0025;; suggesting that extracted features were not sufficient in improving classification results (<xref ref-type="bibr" rid="c22">Giovanini et al., 2018</xref>; <xref ref-type="bibr" rid="c54">Reilly, 2019</xref>).</p>
<p>Cetin and Bilgin, (<xref ref-type="bibr" rid="c14">Cetin &#x0026; Bilgin, 2019</xref>) argued that achieving a relatively high classification performance is a function of only force signals and not the whole force-plate measures. However, the maximum accuracy of their study was still limited to 81.67&#x0025;. These results agree with (<xref ref-type="bibr" rid="c57">Safuan et al., 2017</xref>) conclusion that extracting suitable features from gait/balance data and choosing the optimal feature extraction/selection methods are complicated and time-consuming processes. Their work showed that nonlinearities, high dimensionality, and high variability of time-series signals are major constrains.</p>
<p>As shown in <xref rid="tbl1" ref-type="table">Table 1</xref>, a Machine Learning (ML) algorithm or Statistical Method has the capability of interpreting the gait and balance biomechanical features and finding the relationship between variables. However as mentioned above, these methodologies typically require domains expertise and advanced experience levels which could be highly time and energy consuming and prone to error. Wang et al. used simple Neural Network (NN) along with Bayesian optimization algorithm to analyze human walking speed. The study involved feature extraction and feature selection stages for generating input features for a classifier (<xref ref-type="bibr" rid="c65">Wang et al., 2021</xref>).</p>
<p><xref rid="tbl1" ref-type="table">Table 1</xref> suggests that methodologies used by other scientists in research studies on falls are not adequate. It also shows that fall detection and human balance characterization can be a challenging task. Deep Learning (DL) models have been shown to have the capability of scanning a large dataset for relevant informative features without passing through the manual feature extraction stage of the traditional ML or statistical models (<xref ref-type="bibr" rid="c32">Horsak et al., 2020</xref>). Hoffman et al. took advantage of recurrent neural network (RNN) based on Long Short-Term Memory (LSTM) to investigate gait patterns of 42 participants. They experimented with a capacitive sensor floor to record walking kinematics of subjects. According to their result, using combination of sensor-based data and NN is a promising approach to be applied in in health and care (<xref ref-type="bibr" rid="c31">Hoffmann et al., 2021</xref>).</p>
<p>If adequately utilized, DL algorithms have the capability of providing automatic feature extraction, flexibility, and higher accuracy on huge amount of data. This is because unlike traditional ML algorithms, deep learnings can learn high-level features from high-dimensional data in a hierarchical manner which eliminates the need of domain expertise and the complex process of feature extractions (<xref ref-type="bibr" rid="c25">Goodfellow et al., 2016</xref>; <xref ref-type="bibr" rid="c45">Najafabadi et al., 2015</xref>). The supremacy of deep learning algorithms to reveal underlying patterns of big data without the need of performing prior feature extraction and feature selection processes, can result in considerably higher predictive powers, and more accurate results. Therefore, for a better result and balanced study, our experiment employed deep neural network algorithms to classify force-plate balance time-series signal to predict human&#x2019;s balance impairment. We argue that this is a better approach.</p>
<p>Exploring this capability and superiority of the DL, we investigate the balance patterns in different people for an effective characterization, using the same open-source dataset used by researchers in <xref rid="tbl1" ref-type="table">table 1</xref>. Dataset was produced by Santos et al. (<xref ref-type="bibr" rid="c59">Santos &#x0026; Duarte, 2016</xref>). The dataset contains the force-plate time-series signals recorded from 163 young and older individuals. Alongside the force-plate dataset there is another large meta data file composed of personal and other health characteristics of the subject such as age, gender, history of fall, background disease, functional tests&#x2019; results etc.</p>
<p>Although the available meta data is composed of different types of information about participants which could be used as binary classes, e.g. gender (male vs. female) or age group (young vs. old), vision (open vs. closed), surface (firm vs. foam) etc. we decided to discriminate the study subjects based on their Falls Efficacy Scale (FES) test score. FES is an international known test which measures fear of falling. It implies a person&#x2019;s level of confidence for carrying out everyday activities (<xref ref-type="bibr" rid="c34">Kempen et al., 2008</xref>; <xref ref-type="bibr" rid="c44">Morgan et al., 2013</xref>).</p>
<p>We hypothesized that low, moderate, and high risk of falling can be characterized based on commonly-used balance metrics, such as those derived from the force-plate time series, in conjunction with deep learning algorithms: Recurrent Neural Network (RNN), Long-Short Time Memory (LSTM), One Dimensional Convolutional Neural Network (1D-CNN), and our developed One-One-One Deep Neural Network. Further, we hypothesized that our proposed One-One-One neural network is the most efficient neural network model in predicting human&#x2019;s balance impairment using the force-plate time series signal.</p>
</sec>
<sec id="s3">
<label>III.</label>
<title>Materials and Methods</title>
<sec id="s3a">
<label>A.</label>
<title>Materials: Force-Plate and Meta Data</title>
<p>As explained above, the data used in this study is a publicly available dataset. It is accessible through both PhysioNet (DOI: 10.13026/ C2WW2W) and Figshare (DOI: 10.6084/ m9. figshare. 3394432) websites. The study in which the dataset was created, and its detailed description, can be found here (<xref ref-type="bibr" rid="c59">Santos &#x0026; Duarte, 2016</xref>). The data was collected from 163 male and female participants of different ages (18-86 years old) and varied health conditions. Each participant completed a 1-2-hour study session, and all data were collected during this single session. To evaluate a person&#x2019;s balance, he/she was asked to stand still on the force-plate for 60 seconds with arms at his/her sides and repeated it three times for four different test conditions.</p>
<p>Test conditions were defined as standing eyes-open on a firm surface, eyes-closed on a firm surface, eyes-open on a foam and finally eyes-closed on a foam. Both rigid surface and foam tests were done on a force-platform and the participants&#x2019; balance characteristics of Force, Moments of forces, and Centers of Pressure were measured. Participants were barefooted and looked at a 3 centimeters round target in front of them, located at a wall 3 meters away (<xref ref-type="bibr" rid="c16">dos Santos &#x0026; Duarte, 2016</xref>; <xref ref-type="bibr" rid="c59">Santos &#x0026; Duarte, 2016</xref>).</p>
<p>The force-plate data was acquired at 100Hz frequency. Since each person did twelve 60 seconds trials in this study, twelve .txt files, each composing of 6000 rows and 9 columns exist for each subject. Therefore, after merging data files, each person has 72000 row time-series signal and 9 feature columns specified as: Time, as well as tri-axial Force (Fx, Fy, Fz), and Moment (Mx, My, Mz), along the x, y, and z axes respectively (as shown in <xref rid="fig1" ref-type="fig">Figure 1</xref>), and Center of Pressure in ML and AP (i.e., CoPx, CoPy) recorded by the force-plate. Moment of force (<xref ref-type="bibr" rid="c36">Latash, 2012a</xref>), and can be determined by the following formulas:</p>
<fig id="fig1" position="float" fig-type="figure">
<label>Figure. 1.</label>
<caption><p>Measuring three components of the force vector (FX, FY, FZ) and three components of the moment-of-force vector (MX, MY, MZ) by force-plate; Retrieved from (<xref ref-type="bibr" rid="c37">Latash, 2012b</xref>)</p></caption>
<graphic xlink:href="21257466v1_fig1.tif"/>
</fig>
<p>
<disp-formula id="eqn1">
<alternatives><graphic xlink:href="21257466v1_eqn1.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn2">
<alternatives><graphic xlink:href="21257466v1_eqn2.gif"/></alternatives>
</disp-formula>
where M stands for Moment of force, F stands for force, dx and dy stand for the lever arm of the shear forces of F<sub>x</sub> and F<sub>y</sub> along the Z axis, respectively. Through those metrics, we can also determine Center of Pressure (CoP) with the help of the following simplified equations; (<xref ref-type="bibr" rid="c37">Latash, 2012b</xref>)
<disp-formula id="eqn3">
<alternatives><graphic xlink:href="21257466v1_eqn3.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn4">
<alternatives><graphic xlink:href="21257466v1_eqn4.gif"/></alternatives>
</disp-formula>
where CoPx and CoPy are the CoP coordinates along the X and Y axis, respectively.</p>
<p>Along with the main dataset which contains the subjects&#x2019; balance metrics, there is another information file, called BDSinfo, provided by the researchers. This supplementary file contains meta data about the subjects (e.g., vision, gender, height, BMI, illness, use of medication, number of falls, and disability). It also includes the results of some well-known conventional clinical evaluations such as Falls Efficacy Scale (FES), International Physical Activity Questionnaire (IPAQ), and Trail Making Test (TMT); these tests focus on assessing a specific parameter such as cognition level, concern of falling during different tasks and likelihood of fall and evaluate postural control of people and their stability (balance) while doing several static and/or dynamic motor tasks. (M. <xref ref-type="bibr" rid="c41">Mancini &#x0026; Horak, 2010b</xref>). To understand the concept of each evaluation method and the whole meta data, reading the main source (<xref ref-type="bibr" rid="c59">Santos &#x0026; Duarte, 2016</xref>) is highly recommended.</p>
<p>Due to its comprehensive information, the meta data is very resourceful for categorizing human subjects. In other words, each of the columns of this dataset can be used as a proper label for classification purposes. The available meta data is composed of different types of information about participants which could be used as binary classes, e.g., gender (male vs. female) or age group (young vs. old), vision (open vs. closed), surface (firm vs. foam), etc. However, we decided to discriminate the study subjects based on their Falls Efficacy Scale (FES) test score. The Falls Efficacy Scale International test (FES) is a well-known evaluation methodology used for individuals with vestibular or balance dysfunction to quantify his/her fear of falling. Participants answer to the questions about some of their regular daily activities and specify how concerned they are about the possibility of falling. Reliability and validity of FES to measure concerns of falling in people with imbalance and postural control deficits have been explained by several researchers (<xref ref-type="bibr" rid="c34">Kempen et al., 2008</xref>; <xref ref-type="bibr" rid="c44">Morgan et al., 2013</xref>; <xref ref-type="bibr" rid="c70">Yardley et al., 2005</xref>).</p>
</sec>
<sec id="s3b">
<label>B.</label>
<title>Data Preparation</title>
<p>The code was written in Python 3.7.3. As the first step, we merged all .txt files recorded with the force-plate for all subjects. As described earlier, time series were recorded by 100 Hz frequency which produced 6000 rows for each 60 second trial. Since each of the 163 subjects completed the 12 trials, therefore we had 1956 .txt files. However, 26 of these .txt files are missing for five subjects who were not able to complete the most challenging exercises. Consequently, there are 11 580 000 rows of data recorded for all subjects.</p>
</sec>
<sec id="s3c">
<label>C.</label>
<title>Label Selection</title>
<p>In this study, a supervised learning approach was used for the design, development, and evaluation of our learning algorithm. Using this approach, suppose we have a set of N training examples {(<italic>x</italic><sub>1</sub>, <italic>y</italic><sub>1</sub>), &#x2026; (<italic>x</italic><sub><italic>N</italic></sub> <italic>y</italic><sub><italic>N</italic></sub>)}, where <italic>x</italic><sub><italic>i</italic></sub> and <italic>y</italic><sub><italic>i</italic></sub> are the <italic>i</italic><sup><italic>th</italic></sup> feature vector and label respectively. The goal of the learning algorithm is to choose the optimal function <italic>g: X &#x2192; Y</italic>, where <italic>X</italic> and <italic>Y</italic> are the input and output states respectively, function g belonging to a hypothesis space G. This hypothesis space represents all possible functions of G.</p>
<p>We chose 14 columns of meta data available at (<xref ref-type="bibr" rid="c16">dos Santos &#x0026; Duarte, 2016</xref>) containing the most important information about participants and added those features to our main force-plate dataset. As discussed in section III, the main balance metrics recorded by force-plate were Time, Force in x, y and z directions (Fx, Fy, Fz), Moment of force in x, y and z directions (Mx, My, Mz), Center of Pressure in x and y directions (CoPx and CoPy). Thus, our feature size increased to 23 after adding the 14 columns of vision, surface, age group, gender, Bone Mineral Density (BMI), illness, Number of medications, disability, falls12month, IPAQ_S, TMT_timeA, TMT_timeB, Best_T, FES_S of meta data. IPAQ is an International Physical Activity Questionnaire Short Version test (IPAQ) which measures health-related physical activity (PA) in populations (<xref ref-type="bibr" rid="c27">Hagstr&#x00F6;mer et al., 2006</xref>). TMT is abbreviation of Trail Making Test which screens dementia by assessing cognition level in two different parts A and B, and the goal is to complete the tests accurately and as quickly as possible (<xref ref-type="bibr" rid="c58">Salthouse, 2011</xref>). Mini Balance Evaluation Systems Test (Mini-BESTest) predicts the likelihood of fall (<xref ref-type="bibr" rid="c72">Yingyongyudha et al., 2016</xref>).</p>
<p>In this research, we merged the force plate and meta data file to create our dataset and used the Falls Efficacy Scale (FES) as the label. The proposed classifier in this study is based on the FES test result which provides three different classes: low, moderate and high fear of falling. The reliability and convergent validity of this test has been proven by different researchers (<xref ref-type="bibr" rid="c34">Kempen et al., 2008</xref>; <xref ref-type="bibr" rid="c44">Morgan et al., 2013</xref>). Using FES test results, subjects in this study are categorized into low fear (scores 2-9), moderate fear (9-13), and high fear (&#x003E;14) of falling. We aim to distinguish between them using deep neural networks.</p>
</sec>
<sec id="s3d">
<label>D.</label>
<title>Neural Network</title>
<p>Inspired by the human&#x2019;s brain, Neural Network (NN) is a set of interconnected artificial neurons which recognize underlying relationships between datapoints. Each neuron or perceptron is a mathematical function that takes the input data from the input layer (x<sub>1</sub>, x<sub>2</sub>&#x2026;), multiply them by a weight (w<sub>1</sub>, w<sub>2</sub>&#x2026;), and add a bias (b) to the weighted inputs (hidden layer). To introduce nonlinearity to the network, the result is then passed through an activation function (f). Through feeding neurons in a forward way and consecutive computational processes, patterns are recognized by the network and the output is predicted (output layer). To achieve the best estimation of desired outputs, the system adjusts the weights and bias continuously using backpropagation of error (<xref ref-type="bibr" rid="c4">B. Wankhede, 2014</xref>; <xref ref-type="bibr" rid="c28">Hecht-Nielsen, 1989</xref>). <xref rid="fig2" ref-type="fig">Figure 2</xref> demonstrates a simple architecture of neural network composed of three layers. For a more complex decisions, networks consist of several hidden layers and neurons are recommended.</p>
<fig id="fig2" position="float" fig-type="figure">
<label>Figure. 2.</label>
<caption><p>A 3-layer neural network architecture</p></caption>
<graphic xlink:href="21257466v1_fig2.tif"/>
</fig>
</sec>
<sec id="s3e">
<label>E.</label>
<title>Experimental design</title>
<p><xref rid="fig3" ref-type="fig">Figure 3</xref> summarizes the flowchart of our experimental design. As shown in the diagram, our datasets comprise of two separate files: force-plate time series and meta data files. Thus, the first step was merging the two files. The time vector was removed from the input data since it just represented the elapsed time and did not contain any other information about subjects&#x2019; balance characteristics. Samples were randomly selected. Random sample selection reduces skewness, class imbalance and overfitting. It is also possible to generate several samples. This strategy has the advantage of repeatability of experiment. Besides being time and space efficient, random sampling provides an equal chance for each datapoint to be selected. Thus, it improves the dependability, reliability, and efficiency of the deep learning models (<xref ref-type="bibr" rid="c24">Gon&#x00E7;alves et al., 2012</xref>).</p>
<fig id="fig3" position="float" fig-type="figure">
<label>Figure. 3.</label>
<caption><p>System Architectural flowchart</p></caption>
<graphic xlink:href="21257466v1_fig3.tif"/>
</fig>
<p>Features were scaled, and labels were encoded in the preprocessing stage. Data was split into 70&#x0025; train and 30&#x0025; test data. Different deep neural network models were selected for the experiment. Optimal hyperparameters were calculated for each model and data was fed into the learning algorithms. Getting the exact values of the hyperparameters are critical because these parameters guide the training process; hyperparameters have a strong influence on the performance of a deep learning model. In other words, &#x201C;wrong&#x201D; choices of hyperparameter values are most likely to produce poor performance of any learning algorithm (<xref ref-type="bibr" rid="c39">Liu et al., 2006</xref>).</p>
<p>Unlike other parameters which are learned in the training process, values of hyperparameters are set prior to the training. In most deep learning applications, some important hyperparameters include number of epochs, batch size, number of hidden layers, optimizers, activation function, regularizations etc. In this study, we used the Grid Search approach of hyperparameter search for the optimal values of required hyperparameters. Therefore, our systems&#x2019; structure was based on the values obtained from this tuning process. Building the models&#x2019; architecture using the optimal hyperparameters values reduce the risk of overfitting thereby improving generalizability.</p>
<p>Deep learning algorithms categorize data through layers of computational neurons. Each neuron has a certain weight and works with an activation function, such as the &#x201C;sigmoid&#x201D;. In each iteration, the output is determined by the system based on the learnt information, error is calculated and fed back to the system using the back-propagation techniques. For an optimal performance, difference between the expected label and the predicted outcome should be minimal. But in most experiments, it takes more than one iteration to achieve the minimum error. Therefore, weights are adjusted at each iteration. This process is called optimization and continues until the maximum accuracy is achieved with the lowest error. Each neural network model has a capacity or complexity which is defined by its structure (number of weights) and parameters (values of weights). Therefore, to avoid/fix overfitting, the system&#x2019;s complexity can be modified by various regularization techniques such as: Weight Regularization, Activity Regularization, Weight constraints, Dropout, Noise and Early Stopping (Brownlee, n.d.; <xref ref-type="bibr" rid="c71">Ying, 2019</xref>).</p>
<p>For validation purposes, 20&#x0025; of the training data was assigned for validation. As an evidence of generalizability, we expect a consistent overlap behavior between the training and validation learning curves. However, optimal consistency is not guaranteed. This can be due to the problem of overfitting. Overfitting occurs when a model learns the training dataset too well but does not perform well on the validation data.</p>
<p>The loss function computation for the proposed neural network models is &#x201C;Cross-entropy&#x201D;. Loss functions measures the difference between actual value of target variables and how robust the system works. To determine the loss score through &#x201C;Cross-entropy&#x201D; the following equation is used:
<disp-formula id="eqn5">
<alternatives><graphic xlink:href="21257466v1_eqn5.gif"/></alternatives>
</disp-formula>
where <italic>n</italic> is the number of training samples, <italic>y</italic><sub><italic>i</italic></sub> is the predicted value and <italic>y</italic><sub><italic>0</italic></sub> is the actual value of label. A small loss value represents good performance of our used classifier (<xref ref-type="bibr" rid="c29">Ho &#x0026; Wookey, 2020</xref>). After each iteration, the loss score is calculated. Then a selected optimizer, was used to update the weights in a back-propagation manner to minimize the loss and increase accuracy. The model was trained, optimized, and validated continuously. The model training stops when the loss of validation set stops decreasing.</p>
<p>The reliability, effectiveness and repeatability of our experiment was demonstrated with multiple neural network models. We compared the performance of the models to determine the most efficient one for predicting human&#x2019;s fall-risk using the force-plate signal dataset. Performance comparison of the models were based on accuracy, losses, and number of iterations to attain optimization. We also compared precision and specificity. For easy comparison, experimental results are shown in graphical and tabular formats.</p>
<sec id="s3e1">
<label>E-II.</label>
<title>Multiple Layer Perceptron (MLP)</title>
<p>The Multiple Layer Perceptron (or MLP) is a variant of the deep learning neural network family. It consists of an input layer, two or more hidden layers and an output layer.</p>
<p>For D input features x<sub>1</sub>, &#x2026;., x<sub>D</sub> and M numbers of nodes j, <italic>j =</italic> 1,&#x2026;, <italic>M</italic>. The M linear combinations of the input features at the Hidden Layer L1 (Hidden Layer L1 is the second layer of the network) is given as;
<disp-formula id="eqn6">
<alternatives><graphic xlink:href="21257466v1_eqn6.gif"/></alternatives>
</disp-formula>
Where <inline-formula><alternatives><inline-graphic xlink:href="21257466v1_inline1.gif"/></alternatives></inline-formula> is the weight parameters connecting the <italic>i</italic><sup><italic>th</italic></sup> node at the first layer to the <italic>j</italic><sup><italic>th</italic></sup> node at the second layer.<inline-formula><alternatives><inline-graphic xlink:href="21257466v1_inline2.gif"/></alternatives></inline-formula> is the bias parameter a<sub>j</sub> is then transformed using a differentiable non-linear activation function h such as the &#x201C;sigmoid&#x201D;;
<disp-formula id="eqn7">
<alternatives><graphic xlink:href="21257466v1_eqn7.gif"/></alternatives>
</disp-formula>
Z<sub>j</sub> is passed to Hidden Layer L2 (Hidden Layer L2 is the third layer of the network)
<disp-formula id="eqn8">
<alternatives><graphic xlink:href="21257466v1_eqn8.gif"/></alternatives>
</disp-formula>
<inline-formula><alternatives><inline-graphic xlink:href="21257466v1_inline3.gif"/></alternatives></inline-formula> is the bias parameter for L2.</p>
<p>a<sub>k</sub>, is transformed using an activation function.</p>
<p>The process continues.</p>
<p>Combining <xref ref-type="disp-formula" rid="eqn6">equations 6</xref> and <xref ref-type="disp-formula" rid="eqn8">8</xref>, the sets of weight and bias parameters can be represented as a vector W, and the input features as a vector X.</p>
<p>Mathematically,</p>
<p>The output <italic>y</italic><sub><italic>k</italic></sub> (<italic>X,W</italic>) =
<disp-formula id="eqn9">
<alternatives><graphic xlink:href="21257466v1_eqn9.gif"/></alternatives>
</disp-formula>
<xref ref-type="disp-formula" rid="eqn9">Equation 9</xref> suggests that the output y<sub>k</sub> is a nonlinear function of sets of input features {x<sub>i</sub>} and adjustable parameters vector <italic>W</italic>. We can reduce the size of <xref ref-type="disp-formula" rid="eqn9">equation 9</xref> by defining a variable <italic>x</italic><sub><italic>0</italic></sub> such that its value equals 1, thereby the bias parameter is represented in the weight parameters vector W. Then, <xref ref-type="disp-formula" rid="eqn9">equation 9</xref> becomes;
<disp-formula id="eqn10">
<alternatives><graphic xlink:href="21257466v1_eqn10.gif"/></alternatives>
</disp-formula>
In general, given an output label y with input vector X, an MLP finds the best function <italic>f</italic> mapping <italic>y= f(X, W)</italic> while learning the optimal value of the parameter W.</p>
<p>MLPs are also called feedforward neural networks because of the flow of information from the input to the output via the intermediate layers. It exhibits a directed acyclic architectural graph represented as a chain structural function of the form;
<disp-formula id="eqn11">
<alternatives><graphic xlink:href="21257466v1_eqn11.gif"/></alternatives>
</disp-formula>
Where <italic>f</italic><sub><italic>n</italic></sub>, <italic>f</italic><sub>2</sub> and <italic>f</italic><sub>1</sub> are the <italic>n</italic><sup><italic>th</italic></sup>, second- and first-layers non-linear functions, respectively.</p>
<p>An example of MLP comprising of an input layer, two hidden layers and an output layer is shown in <xref rid="fig4" ref-type="fig">figure 4</xref>. As shown, the architectural layout of an MLP depicts that all layers in the network are fully connected. This implies that all nodes in the middle layer are connected to all nodes in the next and previous layers. All nodes in the input and output layers are connected to all nodes in the next and previous layers respectively. For example, as shown in the diagram, each node in layer 1 is connected to all the nodes in layer 2, all nodes in layer 2 are also connected to all nodes in layer 3, the process continues till the output layer.</p>
<fig id="fig4" position="float" fig-type="figure">
<label>Figure. 4.</label>
<caption><p>A Multiple Layer Perceptron consisting of an input layer with 2 input features x1 and x2, and 2 hidden layers each with 3 neurons and an output layer with 2 neurons</p></caption>
<graphic xlink:href="21257466v1_fig4.tif"/>
</fig>
<p>For a complex MLP network, layers can be in hundreds or thousands. The input layer is considered as the first layer, hidden layer 1 as the second layer, hidden layer 2 as the third layer, etc. Edges between nodes from one layer to the next are denoted as w<sub>ij</sub><sup>n</sup>, where <italic>n</italic> is the layer number, <italic>ij</italic> is the weighted edges connecting the <italic>j</italic><sup><italic>th</italic></sup> node in the <italic>n</italic><sup><italic>th</italic></sup> layer to the <italic>i</italic><sup><italic>th</italic></sup> node in the <italic>(n &#x002B; 1)</italic> <sup><italic>th</italic></sup> layer. For example, the weight connecting the second node in the first layer (input layer) to the third node in the second layer (hidden layer 1) is denoted as w<sup>1</sup>23. Using the annotated diagram in <xref rid="fig4" ref-type="fig">figure 4</xref>, the above relationship can be represented in matrix form for easy computation. The input features are vectorized:
<disp-formula id="eqn12">
<alternatives><graphic xlink:href="21257466v1_eqn12.gif"/></alternatives>
</disp-formula>
The weight matrix at Hidden Layer L1 is computed and multiplied by the input vector. Result sent through an activation function &#x03C3; (e.g sigmoid) for non-linearization.
<disp-formula id="eqn13">
<alternatives><graphic xlink:href="21257466v1_eqn13.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn14">
<alternatives><graphic xlink:href="21257466v1_eqn14.gif"/></alternatives>
</disp-formula>
The weight matrix at Hidden Layer L2 is computed
<disp-formula id="eqn15">
<alternatives><graphic xlink:href="21257466v1_eqn15.gif"/></alternatives>
</disp-formula>
The output of Hidden Layer L1 is passed to the Hidden Layer L2 and multiplied by the activation function
<disp-formula id="eqn16">
<alternatives><graphic xlink:href="21257466v1_eqn16.gif"/></alternatives>
</disp-formula>
Depending on the number of hidden layers, the chain continues, and the final layer is passed to the output layer</p>
<p>The architectural arrangement of an MLP shows that it has the mechanism of performing complex computation, however, at a high cost. Furthermore, it suggests that an MLP is a global connected neural network, lacking the capability of exploiting a spatial or temporal representation of a dataset. This high space and time complexity of an MLP is its major drawback.</p>
<p>Since our dataset is spatial as well as temporal, our models are built on the flavors of convolutional and recurrent neural networks. Therefore, the experimental design comprises of the following deep learning models: 1D-Convolutional Neural Networks (CNN), Vanilla Recurrent Neural Network (VRNN), Long-Short-term Memory (LSTM) and a proposed One-One-One Neural Networks. The next section discusses the architectures of each of the four models.</p>
</sec>
<sec id="s3e2">
<label>E-III.</label>
<title>1D Convolutional Neural Network (CNN) Model</title>
<p>Convolutional Neural Network (CNN) is a popular method in deep learning. Convolutional layers are made of basic structures known as feature detectors or kernels. Unlike the MPL where weights are assigned directly to each feature, CNN is based on kernel feature engineering. Each kernel is a matrix of integers sliding on the input data as a filter to detect necessary informative features for an efficient representation and characterization of the dataset. There is an abundant application of CNN to images and videos. Poma et al. investigated optimization of CNNs using Fuzzy Gravitational Search Algorithm method (FGSA) for pattern recognition and image classification (<xref ref-type="bibr" rid="c52">Poma, Melin, Gonz&#x00E1;lez, &#x0026; Martinez, 2020</xref>; <xref ref-type="bibr" rid="c51">Poma, Melin, Gonz&#x00E1;lez, &#x0026; Mart&#x00ED;nez, 2020</xref>). However, it has been proven that 1D-CNN can be applied efficiently for time series signals analysis (<xref ref-type="bibr" rid="c33">Jiang et al., 2019</xref>).</p>
<p>As shown in <xref rid="fig5" ref-type="fig">figure 5</xref>, the architecture of our 1D CNN model comprises of first two consecutive convolutional layers, follows by a max pooling layer. For this experiment, using two consecutive convolutional layers at the initial stage of learning before max pooling has the advantage of preserving the true spatial representation of the dataset. Unlike images and videos that may need more convolutional layers, we limited the consecutive convolutional layers to only 2. Intuitively, information lost is minimized. This is logical because we are experimenting with force-plate time series signal. There are 32 filters in each of the convolutional layers.</p>
<fig id="fig5" position="float" fig-type="figure">
<label>Figure. 5.</label>
<caption><p>Schematic architectural diagram of the 1D-CNN used in this study, composed of three convolutional layers, Max Pooling and Global Average Pooling</p></caption>
<graphic xlink:href="21257466v1_fig5.tif"/>
</fig>
<p>From a mathematical viewpoint, convolution is a dot product of input and kernel functions which ultimately results in convolved features, also known as feature or activation maps (<xref ref-type="bibr" rid="c68">Wu, 2017</xref>). There is an activation function called Rectified Linear Units (RELU) on top of each convolutional step. This adds non-linearity to the extracted features and improves the discriminatory capability of the system (<xref ref-type="bibr" rid="c35">Kuo, 2016</xref>).</p>
<p>Features were extracted by the 1D-Convolution Network from each segment of force-plate data using the following equation:
<disp-formula id="eqn17">
<alternatives><graphic xlink:href="21257466v1_eqn17.gif"/></alternatives>
</disp-formula>
In <xref ref-type="disp-formula" rid="eqn17">equation (17)</xref>, <italic>f<sub>ij</sub></italic> is the extracted features vector from the jth neuron of the ith filter in the hidden layer, &#x03C6; is the activation function which was assigned as &#x201C;RELU&#x201D; in this work, <italic>b<sub>i</sub></italic> is the i-th filter corresponding overall bias, <italic>w</italic><sub><italic>ik</italic></sub> the featuring weight matrix, and <italic>x</italic><sub><italic>j&#x002B;k-1</italic></sub> represents the input signals vector (<xref ref-type="bibr" rid="c33">Jiang et al., 2019</xref>). &#x201C;RELU&#x201D; provides the non-linear transformation of the input data for a better hypothesis space generated from its deeper representation. Without the non-linear activation function, the model will only be limited to the dot product and addition linear operations. &#x201C;RELU&#x201D; outputs the input number if it is greater than zero otherwise it outputs zero. Mathematically, &#x201C;RELU&#x201D; is represented as; g<italic>(z)=max (0, z)</italic>, where z is the input number.</p>
<p>At the pooling layer, we reduced the variance and computational complexity of the dataset. Pooling is the dimensionality reduction path of the 1D CNN model. Pooling operation can be minimum, average, or maximum, summarizing the least, average, and most activated features in each patch of the feature map respectively (<xref ref-type="bibr" rid="c69">Yamashita et al., 2018</xref>). The most popular approaches are the maximum and average pooling, minimum pooling is rarely used. In this study, we used max pooling because unlike the average pooling, max pooling provides the maximum presence of a feature. Therefore, max pooling tends to preserve the most valuable information. We used a 2 by 2 window with the stride of 2 for the max pooling layer. After the pooling layer we have another convolutional layer and finally a global average layer. The third convolutional layer has 64 filters. Each of the filters has a kernels size of 1&#x002A;3.</p>
<p>The conventional approach is feeding information extracted through the convolution and pooling layers into a fully connected dense layer. This completes the process of data characterization. However, for this experiment, we did not use a fully connected layer. Instead, the output of the last convolution layer is fed into a global average pooling layer. The global average pooling layer computes the average value of each feature map. Computed averages are sent directly into the &#x201C;softmax&#x201D; layer for classification. It has been shown that global average pooling is less prone to overfitting and more robust to spatial data translations when compared with the fully connected layer (<xref ref-type="bibr" rid="c38">Lin et al., 2013</xref>). The output layer is made of 3 neurons and &#x201C;softmax&#x201D; activation function. To get the best out of our network, we also performed Grid Search and determined the optimal value for the hyperparameters.</p>
</sec>
<sec id="s3e3">
<label>E-IV.</label>
<title>Recurrent Neural Network (RNN) and Long Short-Term Memory Models</title>
<p>We continued our investigation by training a Vanilla Recurrent neural networks (RNN) deep learning model. RNNs are variants of Neural Networks that process input data through number of layers in which the output of each step is dependent on previous computations. In other words, RNNs have a short-term memory which saves the calculated information and uses it for further analysis in the next layer. In fact, RNNs are several copies of the same structure consist of loops which allow the information to persist. This chain-like nature makes RNNs as powerful tools for different applications such as speech recognition, language processing, translation, image captioning, etc. The problem with RNNs is their short memory and looking at just the recent information disables the model to look back longer. A proposed strategy for solving this drawback is using a long short-term memory network (LSTM).</p>
<p><xref rid="fig6" ref-type="fig">Figure 6</xref> shows the architecture of an LSTM. As shown in <xref rid="fig6" ref-type="fig">figure 6</xref>, each memory cell is composed of input, forget and output gates <italic>f</italic><sub><italic>t</italic></sub>, <italic>i</italic><sub><italic>t</italic></sub> <italic>and o</italic><sub><italic>t</italic></sub> respectively. The &#x201C;sigmoid&#x201D; function <italic>&#x03C3;</italic> in the forget gate &#x2018;looks&#x2019; at the previous state <italic>h</italic><sub><italic>t</italic>-1</sub> and current input <italic>x(t)</italic> and decides what information should be discarded at the forget gate. Using &#x201C;sigmoid&#x201D; and &#x201C;tanh&#x201D; functions, the input gate decides about which input values should be. Finally, the output gate uses a &#x201C;sigmoid&#x201D; function to decide what parts of the cell we are going to output (<italic>O</italic><sub><italic>t</italic></sub>) and then employs a &#x201C;tanh&#x201D; function which is multiplied by the output of &#x201C;sigmoid&#x201D; and gives weights to the values based on their level of importance <italic>(h</italic><sub><italic>t</italic></sub><italic>)</italic>.</p>
<fig id="fig6" position="float" fig-type="figure">
<label>Figure. 6.</label>
<caption><p>Memory cell of a long short-term memory network (LSTM); (Olah, n.d.; <xref ref-type="bibr" rid="c61">Staudemeyer &#x0026; Morris, 2019</xref>)</p></caption>
<graphic xlink:href="21257466v1_fig6.tif"/>
</fig>
<p>The mathematical formulation of an LSTM is shown below;
<disp-formula id="eqn18">
<alternatives><graphic xlink:href="21257466v1_eqn18.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn19">
<alternatives><graphic xlink:href="21257466v1_eqn19.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn20">
<alternatives><graphic xlink:href="21257466v1_eqn20.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn21">
<alternatives><graphic xlink:href="21257466v1_eqn21.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn22">
<alternatives><graphic xlink:href="21257466v1_eqn22.gif"/></alternatives>
</disp-formula>
<disp-formula id="eqn23">
<alternatives><graphic xlink:href="21257466v1_eqn23.gif"/></alternatives>
</disp-formula>
As shown in <xref ref-type="disp-formula" rid="eqn18">equations (18</xref> to <xref ref-type="disp-formula" rid="eqn23">23)</xref> <italic>W<sub>f</sub> W</italic><sub><italic>i</italic></sub> <italic>and W</italic><sub><italic>o</italic></sub> are the weight matrices at the forget, input and output gates respectively, while <italic>b</italic><sub><italic>f</italic></sub>, <italic>b</italic><sub><italic>i</italic></sub> and <italic>b</italic><sub><italic>c</italic></sub> are the biases in the same order. <italic>f</italic><sub><italic>t</italic></sub> and <italic>i</italic><sub><italic>t</italic></sub> are the activation vectors for the forget and input vectors. Detailed Mathematical description of LSTM and its architecture can be found at (Olah, n.d.; <xref ref-type="bibr" rid="c61">Staudemeyer &#x0026; Morris, 2019</xref>; <xref ref-type="bibr" rid="c73">Zhou et al., 2015</xref>).</p>
<p>Due to this advanced hierarchical manner, it was hypothesized that better result is achievable using LSTM system rather than RNN. In fact, it is assumed that by using LSTMs we can overcome the Vanishing Gradient problem of RNNs and get a more accurate classification at lower computational cost (<xref ref-type="bibr" rid="c64">Tiwang, Oladunni &#x0026; Xu. 2019</xref>). To test this hypothesis, we employed both the simple RNN and LSTM models. RNN was designed with 64 units along with a dense layer of 3 neurons and &#x201C;softmax&#x201D; activation. The LSTM architecture was designed with one LSTM layer of 256 units along with two dense layers each made of 128 neurons and an output layer of 3 neurons with &#x201C;softmax&#x201D; activation.</p>
</sec>
<sec id="s3e4">
<label>E-V.</label>
<title>Proposed Model &#x2013; The One-One-One Neural Network for Human&#x2019;s Balance Impairment Prediction</title>
<p>The performance of models built with CNN, RNN and LSTM architectures described in sections E-III and E-IV proved to be inadequate; i) 1D-CNN attained 99.3 &#x0025; accuracy at the 50<sup>th</sup> epoch, ii) RNN and LSTM learnt faster when compared with the 1D-CNN but achieved accuracies of 96.9&#x0025; and 98.3&#x0025; respectively. Therefore, we explored a combination of 1D-CNN, LSTM and the Dense.</p>
<p><italic>We hypothesized that the proposed one-one-one neural network is the most efficient neural network model in predicting human&#x2019;s balance impairment using the force-plate time series signal</italic>. The optimization of the proposed model is based on; i) random sampling for data selection, ii) architectural simplicity and minimum complexity approach, and iii) Exhaustive search technique of hyper parameters&#x2019; values using the grid searching methodology. The proposed optimization approach is in line with Occam razor principle of parsimony and plurality which have been shown to improve generalization (Clark, n.d.). It is also in line with the Isaac Newton rule 1 of scientific reasoning (Four Rules of Scientific Reasoning from Principia Mathematica, n.d.). Furthermore, it agrees with Minimum Description Length (MDL) principle. MDL is a trade-off between the complexity of the model and the goodness of fit. Overly complex modeling has been linked to overfitting (<xref ref-type="bibr" rid="c26">Gr&#x00FC;nwald, 2007</xref>).</p>
<sec id="s3e4a">
<label>i.</label>
<title>Random Sampling</title>
<p>As described in section III, our dataset comprised of 11 580 000 rows recorded for all subjects. A Microsoft Surface Laptop 2, Core i7 processor, 8 GB RAM was available for the experiment. It took 24 hours just to merge the files. Since merging data files was highly time-expensive on the laptop, intuitively, using this device for running deep learning algorithms with large number of epochs could be dramatically more expensive, laborious and may lead to an unsuccessful experimental outcome. The question here is; <italic>do we need 11M records of the dataset to build the proposed model?</italic> If the answer to this question is no, then the next question is; <italic>can we reduce the number of records and still maintain a balanced class for a reliable experiment?</italic> To answer these questions, we used a random sampling approach. A code was written which randomly selected a subset of the dataset. The result of our experiment shows the effectiveness of the approach.</p>
</sec>
<sec id="s3e4b">
<label>ii.</label>
<title>Architectural Simplicity and Minimum Complexity of the Proposed Neural Network Architecture</title>
<p>To test our hypothesis and investigate the efficiency of architectural simplicity and minimum complexity approach, we designed, developed, and evaluated three models from high to low complexity level: 1) One-One-Three, 2) One-One-Two, and 3) One-One-One neural networks. The first and second layers of all the three models have one 1D-CNN and one LSTM comprising of 64 filters with a kernel size of 1&#x002A;3 and 256 units, respectively. However, we designed different dense layers for each architecture. In One-One-Three, there are three dense layers of 128, 64 and 32 neurons. In One-One-Two, there are two dense layers of 128 and 64 neurons. The proposed One-One-One deep neural network comprises of only one dense layer of 128 neurons.</p>
<p>As shown in <xref rid="fig7" ref-type="fig">figure 7</xref>, feature extraction was done at the convolutional layer. The filters &#x2018;looks&#x2019; through the window for a true characterization of the dataset. Unlike the CNN architecture at section E-III where we used two consecutive convolutional layers at the beginning, here we used only one layer. Using one layer reduces complexity.</p>
<fig id="fig7" position="float" fig-type="figure">
<label>Figure. 7.</label>
<caption><p>Proposed One-One-One Neural Networks Architecture; composed of one 1D-convolutional layer, one LSTM layer, and one dense layer</p></caption>
<graphic xlink:href="21257466v1_fig7.tif"/>
</fig>
<p>After the 1D-convolutional layer, we employed one LSTM layer composed of 256 units. LSTM provides information about the temporal associations of the features extracted at the Convolutional layer. &#x201C;Tanh&#x201D; activation function was used for non-linearity. Output of the LSTM was passed to a fully dense connected layer. The output layer comprises of 3 neurons with the &#x201C;softmax&#x201D; activation function.</p>
</sec>
<sec id="s3e4c">
<label>iii.</label>
<title>Hyperparameter Tuning</title>
<p>Building an efficient deep learning model is a very challenging task. One of these challenges is the selection of hyperparameters&#x2019; values. Choice of hyperparameters&#x2019; values affect the generalization capability and the overall classifier performance (<xref ref-type="bibr" rid="c10">Bergstra &#x0026; Bengio, 2012</xref>; <xref ref-type="bibr" rid="c39">Liu et al., 2006</xref>). <xref rid="fig8" ref-type="fig">Figures 8</xref> and <xref rid="fig9" ref-type="fig">9</xref> show the accuracy and loss graph of an un-tuned classifier using some randomly selected hyper-parameters&#x2019; values.</p>
<fig id="fig8" position="float" fig-type="figure">
<label>Figure. 8.</label>
<caption><p>Training vs. Validation Accuracy of an un-tuned classifier</p></caption>
<graphic xlink:href="21257466v1_fig8.tif"/>
</fig>
<fig id="fig9" position="float" fig-type="figure">
<label>Figure. 9.</label>
<caption><p>Training vs. Validation Loss of an un-tuned classifier</p></caption>
<graphic xlink:href="21257466v1_fig9.tif"/>
</fig>
<p>Looking at the figures, it is obvious that the training and validation graphs at some point show convergence, however, after a while they became unstable. Therefore, choosing the appropriate hyperparameters&#x2019; values is a crucial step in this experiment. The question here is, <italic>how do we choose the best values of hyperparameters for a reliable and optimal performance of the proposed model?</italic> We answered this question by computing a Grid Search of hyperparameters&#x2019; values for the experiment. Random search and manual selection are other popular approaches of choosing the values of hyperparameters. Grid Search is our preferred choice because it is the most exhaustive search approach when compared with the manual and random search. Successful implementation of the manual selection in a reasonable time depends to a large extent on the experience of the researcher. On the other hand, time and space constrain of the random search makes its iterations non-exhaustive. Grid Search produces better accuracy at a higher computational cost.</p>
<p>We imported GridSearchCV from the sklearn library in python programming environment and defined our desired model at the estimator component of the GridSearchCV module. We did this process for the 1D CNN, RNN, LSTM and the proposed One-One-One Neural Networks. The best values of each hyperparameter were determined. Through Grid Search we obtained the best values for the number of epochs, batch size, activation function, optimizer etc.</p>
</sec>
</sec>
</sec>
</sec>
<sec id="s4">
<label>IV.</label>
<title>Results</title>
<p>We implemented our experiment based on the architectural designs of section E explained in methodology. 1D CNN, VANILLA RNN, LSTM and the proposed One-One-One Neural Networks models were trained, tested, and evaluated. Results of each model is discussed in this section.</p>
<sec id="s4a">
<label>A.</label>
<title>Performance Evaluation</title>
<p>To evaluate our models&#x2019; performance, we used confusion matrix and its four different outcomes, namely true positives (TP), true negatives (TN), false positives (FP), and false negatives (FN) (<xref rid="tbl2" ref-type="table">Table 2</xref>). These metrics are produced as a result of classification predictions and are employed to evaluate the model&#x2019;s performance by calculating its sensitivity, precision and accuracy through the following formulas:</p>
<table-wrap id="tbl2" orientation="portrait" position="float">
<label>Table 2</label>
<caption><p>Summary of experimental results</p></caption>
<graphic xlink:href="21257466v1_tbl2.tif"/>
</table-wrap>
<p>
<disp-formula id="eqn24">
<alternatives><graphic xlink:href="21257466v1_eqn24.gif"/></alternatives>
</disp-formula>
Sensitivity is the ratio of truly predicted labels belonging to a class to all samples that truly belong to that class. A higher value of sensitivity represents higher value of true positive and thus lower value of false negative predictions.
<disp-formula id="eqn25">
<alternatives><graphic xlink:href="21257466v1_eqn25.gif"/></alternatives>
</disp-formula>
Precision is the ratio of truly predicted labels belonging to a class to all samples that were predicted to belong to that class by the classifier. Precision shows the relevance of positive detections.
<disp-formula id="eqn26">
<alternatives><graphic xlink:href="21257466v1_eqn26.gif"/></alternatives>
</disp-formula>
Accuracy is the ratio of correct samples predictions to total number of all predictions and shows the general model&#x2019;s performance in terms of correct classification. Determined high value of all used metrics can be representative of the model&#x2019;s high dependability and discriminative power.</p>
</sec>
<sec id="s4b">
<label>B.</label>
<title>CNN Model</title>
<p>As discussed earlier, the model used two 1-dimensional convolutional layers, Max Pooling and Global Average Pooling. Since we are working with numerical force-plate time-series signal here, and not pictures, using 1-D Convolutional Neural Network turns out to be more appropriate. <xref rid="fig10" ref-type="fig">Figures 10 (a &#x0026; b)</xref> show the accuracy and loss results of our designed model along with validation results. As it is seen in the graphs, there is a high consistency between accuracy and loss of both training and validation data.</p>
<fig id="fig10" position="float" fig-type="figure">
<label>Figure. 10.</label>
<caption><p>CNN classifier&#x2019;s Training vs. Validation (a) Accuracy (b) loss (c) Receiver operating characteristics.</p></caption>
<graphic xlink:href="21257466v1_fig10.tif"/>
</fig>
<p>The highest classification accuracy of 0.993 was achieved at the 50th epoch. The reliable performance of the model in predicting true labels can be also observed through the receiver operating characteristics graph shown in <xref rid="fig10" ref-type="fig">figure 10 (c)</xref>.</p>
</sec>
<sec id="s4c">
<label>C.</label>
<title>RNN and LSTM Models</title>
<p>We also trained and evaluated the RNN and LSTM models. As discussed earlier, for the RNN model, we used a simple RNN. The number of units and neurons were defined as 64 and 3 for RNN and dense layer, respectively. To improve results of the RNN classifier, we also performed LSTM. The highest classification of 0.969 and 0.983 were attained by RNN and LSTM models, respectively. As the results imply, LSTM has almost same accuracy as the 1-D CNN but with lower number of epochs. Lower number of epochs suggests that LSTM has a lower computational cost. However, a more detailed look at the LSTM graphs, shows some level of instability after the 17th epoch.</p>
</sec>
<sec id="s4d">
<label>D.</label>
<title>The One-One-One deep neural network Model</title>
<p>As discussed above and in section E-V of our methodology, there are significant shortcomings of RNN, CNN and LSTM. Therefore, we proposed the One-One-One Deep Neural Network Architecture to discriminate between people based on their balance abilities. The loss and accuracy graphs, shown in <xref rid="fig13" ref-type="fig">figures 13 (a &#x0026; b)</xref>, of train and validation data gave excellent results with significantly high consistency. As shown in the graphs, the validation and train data started to converge at about the 12th epoch and remained totally stable. This level of stability was not observed in any other models despite their high classification performance. <xref rid="fig13" ref-type="fig">Figure 13 (c)</xref> shows the receiver operating characteristics graph of the proposed One-One-One Neural Networks classifier performance.</p>
<fig id="fig11" position="float" fig-type="figure">
<label>Figure. 11.</label>
<caption><p>RNN classifier&#x2019;s Training vs. Validation (a) Accuracy (b) loss (c) Receiver operating characteristics.</p></caption>
<graphic xlink:href="21257466v1_fig11.tif"/>
</fig>
<fig id="fig12" position="float" fig-type="figure">
<label>Figure. 12.</label>
<caption><p>LSTM classifier&#x2019;s Training vs. Validation (a) Accuracy (b) loss (c) Receiver operating characteristics.</p></caption>
<graphic xlink:href="21257466v1_fig12.tif"/>
</fig>
<fig id="fig13" position="float" fig-type="figure">
<label>Figure. 13.</label>
<caption><p>One-One-one Neural Networks classifier&#x2019;s Training vs. Validation (a) Accuracy (b) loss (c) Receiver operating characteristics.</p></caption>
<graphic xlink:href="21257466v1_fig13.tif"/>
</fig>
<p><xref rid="tbl2" ref-type="table">Table 2</xref> shows the experimental summary using confusion matrix, precision, sensitivity, and accuracy. Based on this table, the experimental result suggests that the proposed model is the most efficient with a precision, sensitivity, and accuracy of 100 &#x0025;, 100&#x0025; and 99.9&#x0025; respectively at the 12<sup>th</sup> epoch.</p>
<p>As shown on <xref rid="tbl2" ref-type="table">table 2</xref>, the proposed One-One-One model provides higher performance and accuracy than more complex systems of One-One-Three and One-One-Two Neural Networks. This suggests that architectural simplicity can be prior to complexity while designing NN models. Thus, the proposed One-One-One model is computationally less expensive for the given input size.</p>
</sec>
</sec>
<sec id="s5">
<label>V.</label>
<title>DISCUSSION</title>
<p>Although we got almost the same classification accuracy by all four models, they may not be equally efficient in analyzing the force-plate dataset. As shown in <xref rid="fig10" ref-type="fig">figures (10</xref>-<xref rid="fig11" ref-type="fig">11)</xref>, CNN was time-expensive; it needed at least 50 epochs to experience stability and high system performance of 99.3&#x0025; accuracy. This may be due to the fact the optimal performance of a CNN architecture is influenced by the number of convolutional layers used. To reduce the influence of multiple layers, we minimized the number of CNN convolutional layers.</p>
<p>RNN gave us an accuracy of 96.9&#x0025;, as discussed earlier. The low accuracy may be due to the inherent problem of vanishing gradient. We addressed this shortcoming using its variant; LSTM version. LSTM gave a better result, however, at the 17th epoch it shown some degrees of instability; figures 16 and 17. The ineffectiveness and shortcomings of CNN, RNN and LSTM necessitated the design of the of the proposed One-One-One Neural Networks model.</p>
<p>The proposed One-One-One Neural Networks classifier system was designed using only one 1D-convolutional layer on top of one LSTM and one dense layer. Therefore, the proposed approach reduced complexity and improves fitness. For example, using only one 1D CNN layer eliminates the complexity of multiple layers. It also ensures that the model does not remove too many informative features during convolution. In fact, through the following formula we can determine the number of output features by each convolutional layer:
<disp-formula id="eqn24a">
<alternatives><graphic xlink:href="21257466v1_eqn24a.gif"/></alternatives>
</disp-formula>
in which <italic>n</italic><sub><italic>out</italic></sub> is number of output features, <italic>n</italic><sub><italic>in</italic></sub> is the number of input features and <italic>k</italic> is the kernel size (<xref ref-type="bibr" rid="c18">Dumoulin et al., 2018</xref>). Here, we have 21 input features and a 1D-convolutional layer with kernel size:3. Using <xref ref-type="disp-formula" rid="eqn24">equation 24</xref>, the number of output features <italic>n</italic><sub><italic>out</italic></sub> is givens as:
<disp-formula id="ueqn1">
<alternatives><graphic xlink:href="21257466v1_ueqn1.gif"/></alternatives>
</disp-formula>
Therefore, only 2 features are removed after data is filtered by 1D-convolutional layer in the proposed One-One-One Neural Networks classifier architecture. Thus, information loss is minimized. Furthermore, the calculated result is consistent with the model summary generated from keras. As shown in <xref rid="tbl3" ref-type="table">table 3</xref>, the output of the Conv1d displayed -None, 19, 64.</p>
<table-wrap id="tbl3" orientation="portrait" position="float">
<label>Table 3</label>
<caption><p>Model Summary</p></caption>
<graphic xlink:href="21257466v1_tbl3.tif"/>
</table-wrap>
<p>The batch_size is not fixed; this is shown as None values in each of the output shapes. The numbers of features output at the Conv1d is shown as 19, this agrees with value we computed using <xref ref-type="disp-formula" rid="eqn24">equation 24</xref> above. 64 is the number of filters used.</p>
<p>The param # is the number of parameters or weights that are produced. These parameters are learned during the training of the model. The LSTM and the Dense produced 328 794 and 32 896 parameters, respectively. The large value of the weight produced at the LSTM shows the impact of the 256 filters in learning the temporal nature of the dataset. The &#x201C;softmax&#x201D; layer (dense_4) has 3 output shape because our dataset is classified into 3 classes.</p>
<p>The param # of the &#x201C;softmax&#x201D; shows 387, this implies that each node in dense_3 (128) is mapped to each of the 3 nodes in the &#x201C;softmax&#x201D; layer with an added 3 for the bias: 3 &#x002A; 128 &#x002B;3 =387. The total params at the bottom of the table is the sum total of all the parameters learned in the network; 256 &#x002B; 328 704 &#x002B; 32 896 &#x002B; 387 = 362 243. The trainable parameters are the total number of parameters or weights that the networked learned and adjusted their values for the optimization of the model.</p>
<p>As shown in the experimental result, among four models, the proposed One-One-One Neural Networks classifier can be considered as the least computationally expensive model for classification of the human balance dataset in this study. This is because it took only 12 epochs to the reach 99.9&#x0025; accuracy and maintain stability.</p>
</sec>
<sec id="s6">
<label>VI.</label>
<title>Conclusion</title>
<p>According to Occam razor principle, simplicity is prior to complexity until proven otherwise (<xref ref-type="bibr" rid="c46">Oladunni &#x0026; Sharma, 2017</xref>). In this work, simple architecture of the proposed One-One-one Neural Networks classifier produced the best result. Thus, eliminated the need for a more complex architecture. Our results also prove that the proposed One-One-One Neural Networks classifier has the capability of extracting the maximum amount of required spatiotemporal information from the force-plate using the randomized sample datasets. The extracted information from the dataset turns out to be necessary and sufficient for training and testing the proposed model with maximum accuracy, sensitivity, and precision without unnecessary architectural complexity. Generalizability of the model was further improved by hyperparameter tuning based on the exhaustive search of the grid for the optimal values of its hyperparameters&#x2019; values. Section IV illustrates the effectiveness of this methodology.</p>
<p>The outcome of our experiments (<xref rid="tbl2" ref-type="table">Table 2</xref>) shows that we do not have enough evidence to reject our hypothesis. Therefore, we contend that <italic>the proposed one-one-one neural network demonstrated to be the most efficient neural network model in predicting human&#x2019;s fall-risk using the force-plate time series signal</italic>.</p>
<p>Intuitively, the hybrid of the proposed One-One-One Neural Networks classifier benefits from advantages of both CNN, LSTM and Dense. Therefore, it is logical that the model is effective in analyzing the 1D data with a spatiotemporal structure such as force-plate time series. In fact, CNN does the feature extraction process and prepares data for LSTM which interprets the features across time steps (Brownlee, n.d.; <xref ref-type="bibr" rid="c73">Zhou et al., 2015</xref>).</p>
<p><xref rid="tbl4" ref-type="table">Table 4</xref> compares the performance of our experiment with the state-of-the-art on the same dataset. Balance metrics of 163 subjects were used by different researchers to differentiate people based on their gender, age, risk of fall, etc. We focused on a non-binary classification and discriminated people based on their balance abilities not only on their gender or age as done in previous studies.</p>
<table-wrap id="tbl4" orientation="portrait" position="float">
<label>Table 4</label>
<caption><p>Comparison with the state-of-the-art</p></caption>
<graphic xlink:href="21257466v1_tbl4.tif"/>
</table-wrap>
<p>Based on the outcome of our experiment, we argue that the proposed model is reliable and efficient in predicting risk of fall in human subjects of different ages based on their fall concern and balance abilities. In other words, this model can detect balance impairment in different range of people with age, gender, health status, fall history, illness, medication use, impairment background and other specifications. The dataset for this work was retrieved from (<xref ref-type="bibr" rid="c16">dos Santos &#x0026; Duarte, 2016</xref>; <xref ref-type="bibr" rid="c59">Santos &#x0026; Duarte, 2016</xref>) and contains the balance characteristics of many human subjects recorded by a force-plate.</p>
<p>This study shows the effectiveness and performance of deep neural networks in building an accurate predictive model. Its effectiveness without the feature extraction stage of the traditional machine learning is evident as compared with our previous experiments (<xref ref-type="bibr" rid="c60">Savadkoohi et al., 2020</xref>). The promising result of the present study is a motivation in exploring the architecture of the proposed One-One-One Deep Neural Networks in discerning patterns and discovering knowledge in other scientific problems. However, experimental result may not be the same for all datasets. This is a limitation of this work because architectural simplicity and minimum complexity approach may not be adequate for all problems.</p>
<p>Major contributions of this work are as follows.</p>
<list list-type="alpha-lower">
<list-item><p><xref rid="tbl4" ref-type="table">Table 4</xref> shows that the worst classification accuracy of our work, 96.9&#x0025; using RNN, is far above and beyond the highest accuracy of 80 and 81.67&#x0025; achieved by other researchers in 2019 (<xref ref-type="bibr" rid="c14">Cetin &#x0026; Bilgin, 2019</xref>; <xref ref-type="bibr" rid="c54">Reilly, 2019</xref>). To the best of our knowledge, we do not find any other study on this dataset with higher classification results. Therefore, we consider this work as the new baseline.</p></list-item>
<list-item><p>4 deep neural network models were designed, developed, and evaluated to predict human&#x2019;s balance impairment using the force-plate time series signal. With an accuracy of 99.9&#x0025; at the 12<sup>th</sup> epoch, our experiment shows that the proposed One-One-One Neural Networks has computational cost advantage over other models.</p></list-item>
<list-item><p>Optimization of the proposed One-One-One Neural Networks classifier architecture was based on a combination of: i) random sampling for data selection, ii) architectural simplicity and minimum complexity approach, and iii) Exhaustive search technique of hyperparameters&#x2019; values using the grid searching methodology.</p></list-item>
<list-item><p>Classification was based on the Short Falls Efficacy Scale International test (FES) for the identification of individuals&#x2019; concern (fear) of a fall. Subjects were classified as low, moderate, and high concern groups due to their FES test results which is a standard test to measure the fall risk.</p></list-item>
</list>
<p>The implications of the study are as follows:</p>
<list list-type="order">
<list-item><p>Balance impairment in human is predictable using deep neural networks. Our experiment employed this state-of-the-art learning algorithms to classify force-plate balance time-series signal to predict human&#x2019;s balance impairment. Classification was based on low, moderate, and high risk of a fall.</p></list-item>
<list-item><p>Combining one layer of 1D CNN with one layer of LSTM and a Dense layer produces the most efficient neural network model in predicting human&#x2019;s balance impairment using the force-plate time series signal. The proposed One-One-One Neural Networks classifier model provides a considerable increase in performance compared to other algorithms. Our experimental results show precision, sensitivity, and accuracy of 100 &#x0025;, 100&#x0025; and 99.9&#x0025; respectively at the 12<sup>th</sup> epoch.</p></list-item>
<list-item><p>Ultimately, using faster computers with higher CPU and more powerful processors, can lead to achieving more insightful perspective and gain a new knowledge regarding the human balance underlying patterns and its characteristics.</p></list-item>
<list-item><p>Our experiment suggests that architectural simplicity and minimum complexity approach is critical in building efficient deep neural networks. The proposed One-One-One Neural Networks classifier demonstrated the capability of extracting maximum spatiotemporal information from the randomized sample datasets. The extracted information turned out to be necessary and sufficient for training and testing the proposed model. The outcome of our experiment showed the effectiveness of the strategy.</p></list-item>
</list>
<p>In the future, we will consider the following:</p>
<list list-type="order">
<list-item><p>A multiclass identification of individuals&#x2019; concern (fear) of a fall into very low, low, moderate, high, and very high.</p></list-item>
<list-item><p>Dimensionality reduction of the explanatory variables to improve computational efficiency.</p></list-item>
</list>
</sec>
</body>
<back>
<sec sec-type="data-availability">
<title>Data Availability</title>
<p>Data used in this study is a publicly available dataset. It is accessible through both PhysioNet (DOI: 10.13026/ C2WW2W) and Figshare (DOI: 10.6084/ m9. figshare. 3394432) websites.</p>
<p>
<ext-link ext-link-type="uri" xlink:href="https://physionet.org/content/hbedb/1.0.0/">https://physionet.org/content/hbedb/1.0.0/</ext-link>
</p>
<p>
<ext-link ext-link-type="uri" xlink:href="https://figshare.com/articles/dataset/A_public_data_set_of_quantitative_and_qualitative_evaluations_of_human_balance/3394432">https://figshare.com/articles/dataset/A_public_data_set_of_quantitative_and_qualitative_evaluations_of_human_balance/3394432</ext-link>
</p>
</sec>
<ack>
<label>VIII.</label>
<title>Acknowledgment</title>
<p>We would like to acknowledge the University of the District of Columbia. Further, we would like to acknowledge the Department on Aging and Community Living (DACL) for their sponsorship. We also like to acknowledge the following federal funding sources: National Science Foundation (NSF) Award #&#x2019;s 2032345, 1654474, and1700219.</p>
</ack>
<ref-list>
<title>REFERENCES</title>
<ref id="c1"><mixed-citation publication-type="journal"><string-name><surname>Abrahamov&#x00E1;</surname>, <given-names>D H. F.</given-names></string-name> (<year>2008</year>). <article-title>Age-related changes of human balance during quiet stance - PubMed</article-title>. <source>Physiol Res</source>, <volume>57</volume>(<issue>6</issue>), <fpage>957</fpage>&#x2013;<lpage>964</lpage>. <ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/18052683/">https://pubmed.ncbi.nlm.nih.gov/18052683/</ext-link></mixed-citation></ref>
<ref id="c2"><mixed-citation publication-type="book"><string-name><surname>Alexander</surname>, <given-names>N. B.</given-names></string-name> (<year>1996</year>). <chapter-title>Gait disorders in older adults</chapter-title>. <source>In Journal of the American Geriatrics Society (Vol</source>. <volume>44</volume>, Issue <issue>4</issue>, pp. <fpage>434</fpage>&#x2013;<lpage>451</lpage>). <publisher-name>Blackwell Publishing Inc</publisher-name>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/j.1532-5415.1996.tb06417.x">https://doi.org/10.1111/j.1532-5415.1996.tb06417.x</ext-link></mixed-citation></ref>
<ref id="c3"><mixed-citation publication-type="journal"><string-name><surname>Alshammari</surname>, <given-names>S. A.</given-names></string-name>, <string-name><surname>Alhassan</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Aldawsari</surname>, <given-names>M. A.</given-names></string-name>, <string-name><surname>Bazuhair</surname>, <given-names>F. O.</given-names></string-name>, <string-name><surname>Alotaibi</surname>, <given-names>F. K.</given-names></string-name>, <string-name><surname>Aldakhil</surname>, <given-names>A. A.</given-names></string-name>, &#x0026; <string-name><surname>Abdulfattah</surname>, <given-names>F. W.</given-names></string-name> (<year>2018</year>). <article-title>Falls among elderly and its relation with their health problems and surrounding environmental factors in Riyadh</article-title>. <source>Journal of Family &#x0026; Community Medicine</source>, <volume>25</volume>(<issue>1</issue>), <fpage>29</fpage>&#x2013;<lpage>34</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.4103/jfcm.JFCM_48_17">https://doi.org/10.4103/jfcm.JFCM_48_17</ext-link></mixed-citation></ref>
<ref id="c4"><mixed-citation publication-type="journal"><string-name><surname>B. Wankhede</surname>, <given-names>S.</given-names></string-name> (<year>2014</year>). <article-title>Analytical Study of Neural Network Techniques: SOM, MLP and Classifier-A Survey</article-title>. <source>IOSR Journal of Computer Engineering</source>, <volume>16</volume>(<issue>3</issue>), <fpage>86</fpage>&#x2013;<lpage>92</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.9790/0661-16378692">https://doi.org/10.9790/0661-16378692</ext-link></mixed-citation></ref>
<ref id="c5"><mixed-citation publication-type="other"><collab>Balance Disorders &#x2014; Causes</collab>, <source>Types &#x0026; Treatment &#x007C; NIDCD. (n.d.). Retrieved</source> <month>August</month> 8, <year>2020</year>, from <ext-link ext-link-type="uri" xlink:href="https://www.nidcd.nih.gov/health/balance-disorders">https://www.nidcd.nih.gov/health/balance-disorders</ext-link></mixed-citation></ref>
<ref id="c6"><mixed-citation publication-type="other"><collab>Balance problems - Symptoms and causes - Mayo Clinic. (n.d.). Retrieved August 8, 2020, from</collab> <ext-link ext-link-type="uri" xlink:href="https://www.mayoclinic.org/diseases-conditions/balance-problems/symptoms-causes/syc-20350474">https://www.mayoclinic.org/diseases-conditions/balance-problems/symptoms-causes/syc-20350474</ext-link></mixed-citation></ref>
<ref id="c7"><mixed-citation publication-type="journal"><string-name><surname>Balestrucci</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Daprati</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Lacquaniti</surname>, <given-names>F.</given-names></string-name>, &#x0026; <string-name><surname>Maffei</surname>, <given-names>V.</given-names></string-name> (<year>2017</year>). <article-title>Effects of visual motion consistent or inconsistent with gravity on postural sway</article-title>. <source>Experimental Brain Research</source>, <volume>235</volume>(<issue>7</issue>), <fpage>1999</fpage>&#x2013;<lpage>2010</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s00221-017-4942-3">https://doi.org/10.1007/s00221-017-4942-3</ext-link></mixed-citation></ref>
<ref id="c8"><mixed-citation publication-type="journal"><string-name><surname>Bauer</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Gr&#x00F6;ger</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Rupprecht</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Meichtry</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Tibesku</surname>, <given-names>C. O.</given-names></string-name>, &#x0026; <string-name><surname>Ga&#x00DF;mann</surname>, <given-names>K. G.</given-names></string-name> (<year>2010</year>). <article-title>Reliability analysis of time series force plate data of community dwelling older adults</article-title>. <source>Archives of Gerontology and Geriatrics</source>, <volume>51</volume>(<issue>3</issue>). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.archger.2010.01.009">https://doi.org/10.1016/j.archger.2010.01.009</ext-link></mixed-citation></ref>
<ref id="c9"><mixed-citation publication-type="journal"><string-name><surname>Beghi</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Gervasoni</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Pupillo</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Bianchi</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Montesano</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Aprile</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Agostini</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Rovaris</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Cattaneo</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Iacobone</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Jonsdottir</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Rodan&#x00F2;</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Romi</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Russo</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Tettamanzi</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Cruciani</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Imbimbo</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Polli</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Turolla</surname>, <given-names>A.</given-names></string-name> (<year>2018</year>). <article-title>Prediction of Falls in Subjects Suffering From Parkinson Disease, Multiple Sclerosis, and Stroke</article-title>. <source>Archives of Physical Medicine and Rehabilitation</source>, <volume>99</volume>(<issue>4</issue>), <fpage>641</fpage>&#x2013;<lpage>651</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.apmr.2017.10.009">https://doi.org/10.1016/j.apmr.2017.10.009</ext-link></mixed-citation></ref>
<ref id="c10"><mixed-citation publication-type="journal"><string-name><surname>Bergstra</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name> (<year>2012</year>). <article-title>Random Search for Hyper-Parameter Optimization Yoshua Bengio</article-title>. <source>Journal of Machine Learning Research</source>, <volume>13</volume>, <fpage>281</fpage>&#x2013;<lpage>305</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.5555/2188385.2188395">https://doi.org/10.5555/2188385.2188395</ext-link></mixed-citation></ref>
<ref id="c11"><mixed-citation publication-type="journal"><string-name><surname>Brooke</surname>, <given-names>S.</given-names></string-name> (<year>2010</year>). <article-title>Gait and balance disorders in older adults</article-title>. <source>American Family Physician</source>, <volume>82</volume>(<issue>1</issue>), <fpage>61</fpage>&#x2013;<lpage>68</lpage>.</mixed-citation></ref>
<ref id="c12"><mixed-citation publication-type="other"><string-name><surname>Brownlee</surname>, <given-names>J.</given-names></string-name> <source>(n.d.). How to Avoid Overfitting in Deep Learning Neural Networks</source>. Retrieved August 10, 2020, from <ext-link ext-link-type="uri" xlink:href="https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/">https://machinelearningmastery.com/introduction-to-regularization-to-reduce-overfitting-and-improve-generalization-error/</ext-link></mixed-citation></ref>
<ref id="c13"><mixed-citation publication-type="book"><string-name><surname>Burns</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Kakara</surname>, <given-names>R.</given-names></string-name> (<year>2018</year>). <chapter-title>Deaths from Falls Among Persons Aged &#x2265;65 Years &#x2014; United States, 2007&#x2013;2016</chapter-title>. <source>In MMWR. Morbidity and Mortality Weekly Report (Vol</source>. <volume>67</volume>, Issue <issue>18</issue>). <publisher-name>Centers for Disease Control MMWR Office</publisher-name>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.15585/mmwr.mm6718a1">https://doi.org/10.15585/mmwr.mm6718a1</ext-link></mixed-citation></ref>
<ref id="c14"><mixed-citation publication-type="journal"><string-name><surname>Cetin</surname>, <given-names>E.</given-names></string-name>, &#x0026; <string-name><surname>Bilgin</surname>, <given-names>S.</given-names></string-name> (<year>2019</year>). <article-title>Investigating effects of force and pressure centre signals on stabilogram analysis</article-title>. <source>IET Science, Measurement and Technology</source>, <volume>13</volume>(<issue>9</issue>), <fpage>1305</fpage>&#x2013; <lpage>1310</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1049/iet-smt.2019.0078">https://doi.org/10.1049/iet-smt.2019.0078</ext-link></mixed-citation></ref>
<ref id="c15"><mixed-citation publication-type="other"><string-name><surname>Clark</surname>, <given-names>J.</given-names></string-name> <source>(n.d.). How Occam&#x2019;s Razor Works &#x007C; HowStuffWorks</source>. Retrieved August 10, 2020, from <ext-link ext-link-type="uri" xlink:href="https://science.howstuffworks.com/innovation/scientific-experiments/occams-razor.htm">https://science.howstuffworks.com/innovation/scientific-experiments/occams-razor.htm</ext-link></mixed-citation></ref>
<ref id="c16"><mixed-citation publication-type="other"><string-name><surname>dos Santos</surname>, <given-names>D. A.</given-names></string-name>, &#x0026; <string-name><surname>Duarte</surname>, <given-names>M.</given-names></string-name> (<year>2016</year>). <article-title>A public data set of human balance evaluations</article-title>. <source>Figshare.Dataset</source>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.6084/m9.figshare.3394432.v2">https://doi.org/10.6084/m9.figshare.3394432.v2</ext-link></mixed-citation></ref>
<ref id="c17"><mixed-citation publication-type="journal"><string-name><surname>dos Santos</surname>, <given-names>D. A.</given-names></string-name>, <string-name><surname>Fukuchi</surname>, <given-names>C. A.</given-names></string-name>, <string-name><surname>Fukuchi</surname>, <given-names>R. K.</given-names></string-name>, &#x0026; <string-name><surname>Duarte</surname>, <given-names>M.</given-names></string-name> (<year>2017</year>). <article-title>A data set with kinematic and ground reaction forces of human balance</article-title>. <source>PeerJ</source>, <volume>2017</volume>(<issue>7</issue>), <fpage>e3626</fpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7717/peerj.3626">https://doi.org/10.7717/peerj.3626</ext-link></mixed-citation></ref>
<ref id="c18"><mixed-citation publication-type="other"><string-name><surname>Dumoulin</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Visin</surname>, <given-names>F.</given-names></string-name>, &#x0026; <string-name><surname>Box</surname>, <given-names>G. E. P.</given-names></string-name> (<year>2018</year>). <article-title>A guide to convolution arithmetic for deep learning</article-title>. <source>ArXiv</source>.</mixed-citation></ref>
<ref id="c19"><mixed-citation publication-type="journal"><string-name><surname>Florence</surname>, <given-names>C. S.</given-names></string-name>, <string-name><surname>Bergen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Atherly</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Burns</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Stevens</surname>, <given-names>J.</given-names></string-name>, &#x0026; <string-name><surname>Drake</surname>, <given-names>C.</given-names></string-name> (<year>2018</year>). <article-title>Medical Costs of Fatal and Nonfatal Falls in Older Adults</article-title>. <source>Journal of the American Geriatrics Society</source>, <volume>66</volume>(<issue>4</issue>), <fpage>693</fpage>&#x2013;<lpage>698</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1111/jgs.15304">https://doi.org/10.1111/jgs.15304</ext-link></mixed-citation></ref>
<ref id="c20"><mixed-citation publication-type="other"><collab>Four Rules of Scientific Reasoning from Principia Mathematica. (n.d.)</collab>. Retrieved August 10, 2020, from <ext-link ext-link-type="uri" xlink:href="https://apex.ua.edu/uploads/2/8/7/3/28731065/four_rules_of_reasoning_apex_website.pdf">https://apex.ua.edu/uploads/2/8/7/3/28731065/four_rules_of_reasoning_apex_website.pdf</ext-link></mixed-citation></ref>
<ref id="c21"><mixed-citation publication-type="journal"><string-name><surname>Fukuchi</surname>, <given-names>R. K.</given-names></string-name>, <string-name><surname>Fukuchi</surname>, <given-names>C. A.</given-names></string-name>, &#x0026; <string-name><surname>Duarte</surname>, <given-names>M.</given-names></string-name> (<year>2017</year>). <article-title>A public dataset of running biomechanics and the effects of running speed on lower extremity kinematics and kinetics</article-title>. <source>PeerJ</source>, <volume>2017</volume>(<issue>5</issue>), <fpage>3298</fpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7717/peerj.3298">https://doi.org/10.7717/peerj.3298</ext-link></mixed-citation></ref>
<ref id="c22"><mixed-citation publication-type="journal"><string-name><surname>Giovanini</surname>, <given-names>L. H. F.</given-names></string-name>, <string-name><surname>Manffra</surname>, <given-names>E. F.</given-names></string-name>, &#x0026; <string-name><surname>Nievola</surname>, <given-names>J. C.</given-names></string-name> (<year>2018</year>). <article-title>Discriminating Postural Control Behaviors from Posturography with Statistical Tests and Machine Learning Models: Does Time Series Length Matter?</article-title> <source>Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</source>, <volume>10862 LNCS</volume>, <fpage>350</fpage>&#x2013;<lpage>357</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-319-93713-7_28">https://doi.org/10.1007/978-3-319-93713-7_28</ext-link></mixed-citation></ref>
<ref id="c23"><mixed-citation publication-type="journal"><string-name><surname>Golriz</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Hebert</surname>, <given-names>J. J.</given-names></string-name>, <string-name><surname>Foreman</surname>, <given-names>K. B.</given-names></string-name>, &#x0026; <string-name><surname>Walker</surname>, <given-names>B. F.</given-names></string-name> (<year>2012</year>). <article-title>The reliability of a portable clinical force plate used for the assessment of static postural control: repeated measures reliability study</article-title>. <source>Chiropractic and Manual Therapies</source>, <volume>20</volume>(<issue>1</issue>). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/2045-709X-20-14">https://doi.org/10.1186/2045-709X-20-14</ext-link></mixed-citation></ref>
<ref id="c24"><mixed-citation publication-type="journal"><string-name><surname>Gon&#x00E7;alves</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Silva</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Melo</surname>, <given-names>J. B.</given-names></string-name>, &#x0026; <string-name><surname>Carreiras</surname>, <given-names>J. M. B.</given-names></string-name> (<year>2012</year>). <article-title>Random sampling technique for overfitting control in genetic programming</article-title>. <source>Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)</source>, <volume>7244</volume> LNCS, <fpage>218</fpage>&#x2013;<lpage>229</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-642-29139-5_19">https://doi.org/10.1007/978-3-642-29139-5_19</ext-link></mixed-citation></ref>
<ref id="c25"><mixed-citation publication-type="book"><string-name><surname>Goodfellow</surname>, <given-names>I.</given-names></string-name>, <string-name><surname>Bengio</surname>, <given-names>Y.</given-names></string-name>, &#x0026; <string-name><surname>Courville</surname>, <given-names>A.</given-names></string-name> (<year>2016</year>). <source>Deep Learning -</source>. <publisher-name>The MIT Press</publisher-name>. <ext-link ext-link-type="uri" xlink:href="https://books.google.com/books?hl=en&#x0026;lr=&#x0026;id=omivDQAAQBAJ&#x0026;oi=fnd&#x0026;pg=PR5&#x0026;ots=MMV59ukBOV&#x0026;sig=bbjL-KBjpCpPIrwIQmr3SxThi1U#v=onepage&#x0026;q&#x0026;f=false">https://books.google.com/books?hl=en&#x0026;lr=&#x0026;id=omivDQAAQBAJ&#x0026;oi=fnd&#x0026;pg=PR5&#x0026;ots=MMV59ukBOV&#x0026;sig=bbjL-KBjpCpPIrwIQmr3SxThi1U#v=onepage&#x0026;q&#x0026;f=false</ext-link></mixed-citation></ref>
<ref id="c26"><mixed-citation publication-type="book"><string-name><surname>Gr&#x00FC;nwald</surname>, <given-names>P. D.</given-names></string-name> (<year>2007</year>). <source>The Minimum Description Length Principle &#x007C; The MIT Press</source>. <publisher-name>The MIT Press</publisher-name>. <ext-link ext-link-type="uri" xlink:href="https://mitpress.mit.edu/books/minimum-description-length-principle">https://mitpress.mit.edu/books/minimum-description-length-principle</ext-link></mixed-citation></ref>
<ref id="c27"><mixed-citation publication-type="journal"><string-name><surname>Hagstr&#x00F6;mer</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Oja</surname>, <given-names>P.</given-names></string-name>, &#x0026; <string-name><surname>Sj&#x00F6;str&#x00F6;m</surname>, <given-names>M.</given-names></string-name> (<year>2006</year>). <article-title>The International Physical Activity Questionnaire (IPAQ): a study of concurrent and construct validity</article-title>. <source>Public Health Nutrition</source>, <volume>9</volume>(<issue>6</issue>), <fpage>755</fpage>&#x2013;<lpage>762</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1079/phn2005898">https://doi.org/10.1079/phn2005898</ext-link></mixed-citation></ref>
<ref id="c28"><mixed-citation publication-type="other"><string-name><surname>Hecht-Nielsen</surname>, <given-names>R.</given-names></string-name> (<year>1989</year>). <source>Theory of the backpropagation neural network</source>. <fpage>593</fpage>&#x2013;<lpage>605</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/ijcnn.1989.118638">https://doi.org/10.1109/ijcnn.1989.118638</ext-link></mixed-citation></ref>
<ref id="c29"><mixed-citation publication-type="journal"><string-name><surname>Ho</surname>, <given-names>Y.</given-names></string-name>, &#x0026; <string-name><surname>Wookey</surname>, <given-names>S.</given-names></string-name> (<year>2020</year>). <article-title>The Real-World-Weight Cross-Entropy Loss Function: Modeling the Costs of Mislabeling</article-title>. <source>IEEE Access</source>, <volume>8</volume>, <fpage>4806</fpage>&#x2013;<lpage>4813</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/ACCESS.2019.2962617">https://doi.org/10.1109/ACCESS.2019.2962617</ext-link></mixed-citation></ref>
<ref id="c30"><mixed-citation publication-type="journal"><string-name><surname>Hof</surname>, <given-names>A. L.</given-names></string-name>, <string-name><surname>Gazendam</surname>, <given-names>M. G. J.</given-names></string-name>, &#x0026; <string-name><surname>Sinke</surname>, <given-names>W. E.</given-names></string-name> (<year>2005</year>). <article-title>The condition for dynamic stability</article-title>. <source>Journal of Biomechanics</source>, <volume>38</volume>(<issue>1</issue>), <fpage>1</fpage>&#x2013;<lpage>8</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jbiomech.2004.03.025">https://doi.org/10.1016/j.jbiomech.2004.03.025</ext-link></mixed-citation></ref>
<ref id="c31"><mixed-citation publication-type="journal"><string-name><surname>Hoffmann</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Brodowski</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Steinhage</surname>, <given-names>A.</given-names></string-name>, &#x0026; <string-name><surname>Grzegorzek</surname>, <given-names>M.</given-names></string-name> (<year>2021</year>). <article-title>Detecting Walking Challenges in Gait Patterns Using a Capacitive Sensor Floor and Recurrent Neural Networks</article-title>. <source>Sensors</source>, <volume>21</volume>(<issue>4</issue>), <fpage>1086</fpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3390/s21041086">https://doi.org/10.3390/s21041086</ext-link></mixed-citation></ref>
<ref id="c32"><mixed-citation publication-type="journal"><string-name><surname>Horsak</surname>, <given-names>B.</given-names></string-name>, <string-name><surname>Slijepcevic</surname>, <given-names>D.</given-names></string-name>, <string-name><surname>Raberger</surname>, <given-names>A. M.</given-names></string-name>, <string-name><surname>Schwab</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Worisch</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Zeppelzauer</surname>, <given-names>M.</given-names></string-name> (<year>2020</year>). <article-title>GaitRec, a large-scale ground reaction force dataset of healthy and impaired gait</article-title>. <source>Scientific Data</source>, <volume>7</volume>(<issue>1</issue>), <fpage>1</fpage>&#x2013;<lpage>8</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1038/s41597-020-0481-z">https://doi.org/10.1038/s41597-020-0481-z</ext-link></mixed-citation></ref>
<ref id="c33"><mixed-citation publication-type="journal"><string-name><surname>Jiang</surname>, <given-names>Z.</given-names></string-name>, <string-name><surname>Lai</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Zhang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Zhao</surname>, <given-names>H.</given-names></string-name>, &#x0026; <string-name><surname>Mao</surname>, <given-names>Z.</given-names></string-name> (<year>2019</year>). <article-title>Multi-Factor Operating Condition Recognition Using 1D Convolutional Long Short-Term Network</article-title>. <source>Sensors</source>, <volume>19</volume>(<issue>24</issue>), <fpage>5488</fpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3390/s19245488">https://doi.org/10.3390/s19245488</ext-link></mixed-citation></ref>
<ref id="c34"><mixed-citation publication-type="journal"><string-name><surname>Kempen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Yardley</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>van Haastregt</surname>, <given-names>J.</given-names></string-name>, &#x0026; <etal>et al.</etal> (<year>2008</year>). <article-title>The Short FES-I: a shortened version of the falls efficacy scale-international to assess fear of falling - PubMed</article-title>. <source>Age Ageing</source>, <volume>37</volume>(<issue>1</issue>), <fpage>45</fpage>&#x2013;<lpage>50</lpage>. <ext-link ext-link-type="uri" xlink:href="https://pubmed.ncbi.nlm.nih.gov/18032400/">https://pubmed.ncbi.nlm.nih.gov/18032400/</ext-link></mixed-citation></ref>
<ref id="c35"><mixed-citation publication-type="journal"><string-name><surname>Kuo</surname>, <given-names>C.-C. J.</given-names></string-name> (<year>2016</year>). <article-title>Understanding Convolutional Neural Networks with A Mathematical Model</article-title>. <source>Journal of Visual Communication and Image Representation</source>, <volume>41</volume>, <fpage>406</fpage>&#x2013;<lpage>413</lpage>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1609.04112">http://arxiv.org/abs/1609.04112</ext-link></mixed-citation></ref>
<ref id="c36"><mixed-citation publication-type="book"><string-name><surname>Latash</surname>, <given-names>M. L.</given-names></string-name> (<year>2012a</year>). <chapter-title>Exemplary behaviors</chapter-title>. <source>In Fundamentals of Motor Control</source> (pp. <fpage>211</fpage>&#x2013;<lpage>259</lpage>). <publisher-name>Elsevier</publisher-name>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/b978-0-12-415956-3.00011-7">https://doi.org/10.1016/b978-0-12-415956-3.00011-7</ext-link></mixed-citation></ref>
<ref id="c37"><mixed-citation publication-type="book"><string-name><surname>Latash</surname>, <given-names>M. L.</given-names></string-name> (<year>2012b</year>). <chapter-title>Methods in motor control studies</chapter-title>. <source>In Fundamentals of Motor Control</source> (pp. <fpage>285</fpage>&#x2013;<lpage>321</lpage>). <publisher-name>Elsevier</publisher-name>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/b978-0-12-415956-3.00013-0">https://doi.org/10.1016/b978-0-12-415956-3.00013-0</ext-link></mixed-citation></ref>
<ref id="c38"><mixed-citation publication-type="other"><string-name><surname>Lin</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>Q.</given-names></string-name>, &#x0026; <string-name><surname>Yan</surname>, <given-names>S.</given-names></string-name> (<year>2013</year>). <article-title>Network In Network (paper)</article-title>. <source>ArXiv Preprint</source>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1312.4400">http://arxiv.org/abs/1312.4400</ext-link></mixed-citation></ref>
<ref id="c39"><mixed-citation publication-type="book"><string-name><surname>Liu</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>E.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Li</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Wang</surname>, <given-names>F.</given-names></string-name> (<year>2006</year>). <chapter-title>Optimizing the Hyper-parameters for SVM by Combining Evolution Strategies with a Grid Search</chapter-title>. <source>In Intelligent Control and Automation</source> (pp. <fpage>712</fpage>&#x2013;<lpage>721</lpage>). <publisher-name>Springer Berlin Heidelberg</publisher-name>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-540-37256-1_87">https://doi.org/10.1007/978-3-540-37256-1_87</ext-link></mixed-citation></ref>
<ref id="c40"><mixed-citation publication-type="journal"><string-name><surname>Mancini</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Horak</surname>, <given-names>F. B.</given-names></string-name> (<year>2010a</year>). <article-title>The relevance of clinical balance assessment tools to differentiate balance deficits</article-title>. <source>European Journal of Physical and Rehabilitation Medicine</source>, <volume>46</volume>(<issue>2</issue>), <fpage>239</fpage>&#x2013;<lpage>248</lpage>. /pmc/articles/PMC3033730/?report=abstract</mixed-citation></ref>
<ref id="c41"><mixed-citation publication-type="journal"><string-name><surname>Mancini</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Horak</surname>, <given-names>F. B.</given-names></string-name> (<year>2010b</year>). <article-title>The relevance of clinical balance assessment tools to differentiate balance deficits</article-title>. <source>European Journal of Physical and Rehabilitation Medicine</source>, <volume>46</volume>(<issue>2</issue>), <fpage>239</fpage>&#x2013;<lpage>248</lpage>. /pmc/articles/PMC3033730/?report=abstract</mixed-citation></ref>
<ref id="c42"><mixed-citation publication-type="journal"><string-name><surname>Mancini</surname>, <given-names>Martina</given-names></string-name>, <string-name><surname>Salarian</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Carlson-Kuhta</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Zampieri</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>King</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Chiari</surname>, <given-names>L.</given-names></string-name>, &#x0026; <string-name><surname>Horak</surname>, <given-names>F. B.</given-names></string-name> (<year>2012</year>). <article-title>ISway: A sensitive, valid and reliable measure of postural control</article-title>. <source>Journal of NeuroEngineering and Rehabilitation</source>, <volume>9</volume>(<issue>1</issue>), <fpage>1</fpage>&#x2013;<lpage>8</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/1743-0003-9-59">https://doi.org/10.1186/1743-0003-9-59</ext-link></mixed-citation></ref>
<ref id="c43"><mixed-citation publication-type="journal"><string-name><surname>Montesinos</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Castaldo</surname>, <given-names>R.</given-names></string-name>, &#x0026; <string-name><surname>Pecchia</surname>, <given-names>L.</given-names></string-name> (<year>2018</year>). <article-title>On the use of approximate entropy and sample entropy with centre of pressure time-series</article-title>. <source>Journal of NeuroEngineering and Rehabilitation</source>, <volume>15</volume>(<issue>1</issue>), <fpage>116</fpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s12984-018-0465-9">https://doi.org/10.1186/s12984-018-0465-9</ext-link></mixed-citation></ref>
<ref id="c44"><mixed-citation publication-type="journal"><string-name><surname>Morgan</surname>, <given-names>M. T.</given-names></string-name>, <string-name><surname>Friscia</surname>, <given-names>L. A.</given-names></string-name>, <string-name><surname>Whitney</surname>, <given-names>S. L.</given-names></string-name>, <string-name><surname>Furman</surname>, <given-names>J. M.</given-names></string-name>, &#x0026; <string-name><surname>Sparto</surname>, <given-names>P. J.</given-names></string-name> (<year>2013</year>). <article-title>Reliability and validity of the falls efficacy scale-international (FES-I) in individuals with dizziness and imbalance</article-title>. <source>Otology and Neurotology</source>, <volume>34</volume>(<issue>6</issue>), <fpage>1104</fpage>&#x2013;<lpage>1108</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1097/MAO.0b013e318281df5d">https://doi.org/10.1097/MAO.0b013e318281df5d</ext-link></mixed-citation></ref>
<ref id="c45"><mixed-citation publication-type="journal"><string-name><surname>Najafabadi</surname>, <given-names>M. M.</given-names></string-name>, <string-name><surname>Villanustre</surname>, <given-names>F.</given-names></string-name>, <string-name><surname>Khoshgoftaar</surname>, <given-names>T. M.</given-names></string-name>, <string-name><surname>Seliya</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Wald</surname>, <given-names>R.</given-names></string-name>, &#x0026; <string-name><surname>Muharemagic</surname>, <given-names>E.</given-names></string-name> (<year>2015</year>). <article-title>Deep learning applications and challenges in big data analytics</article-title>. <source>Journal of Big Data</source>, <volume>2</volume>(<issue>1</issue>), <fpage>1</fpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/s40537-014-0007-7">https://doi.org/10.1186/s40537-014-0007-7</ext-link></mixed-citation></ref>
<ref id="c46"><mixed-citation publication-type="other"><string-name><surname>Oladunni</surname>, <given-names>T.O.</given-names></string-name>, <string-name><surname>Sharma</surname>, <given-names>S.</given-names></string-name> (<year>2017</year>). &#x201C;<article-title>An Occam&#x2019;s Razor Approach to Hedonic Pricing Theory</article-title>,&#x201D; <source>2017 International Conference on Computational Science and Computational Intelligence (CSCI), Las Vegas, NV, 2017</source>, pp. <fpage>240</fpage>&#x2013;<lpage>245</lpage>, doi: <pub-id pub-id-type="doi">10.1109/CSCI.2017.38</pub-id>.</mixed-citation></ref>
<ref id="c47"><mixed-citation publication-type="other"><string-name><surname>Olah</surname>, <given-names>C.</given-names></string-name> <source>(n.d.). Understanding LSTM Networks -- colah&#x2019;s blog</source>. Retrieved August 10, 2020, from <ext-link ext-link-type="uri" xlink:href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">https://colah.github.io/posts/2015-08-Understanding-LSTMs/</ext-link></mixed-citation></ref>
<ref id="c48"><mixed-citation publication-type="journal"><string-name><surname>Osoba</surname>, <given-names>M. Y.</given-names></string-name>, <string-name><surname>Rao</surname>, <given-names>A. K.</given-names></string-name>, <string-name><surname>Agrawal</surname>, <given-names>S. K.</given-names></string-name>, &#x0026; <string-name><surname>Lalwani</surname>, <given-names>A. K.</given-names></string-name> (<year>2019</year>). <article-title>Balance and gait in the elderly: A contemporary review</article-title>. <source>Laryngoscope Investigative Otolaryngology</source>, <volume>4</volume>(<issue>1</issue>), <fpage>143</fpage>&#x2013;<lpage>153</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1002/lio2.252">https://doi.org/10.1002/lio2.252</ext-link></mixed-citation></ref>
<ref id="c49"><mixed-citation publication-type="journal"><string-name><surname>Ozcan</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Donat</surname>, <given-names>H.</given-names></string-name>, <string-name><surname>Gelecek</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Ozdirenc</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Karadibak</surname>, <given-names>D.</given-names></string-name> (<year>2005</year>). <article-title>The relationship between risk factors for falling and the quality of life in older adults</article-title>. <source>BMC Public Health</source>, <volume>5</volume>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1186/1471-2458-5-90">https://doi.org/10.1186/1471-2458-5-90</ext-link></mixed-citation></ref>
<ref id="c50"><mixed-citation publication-type="journal"><string-name><surname>Pialasse</surname>, <given-names>J. P.</given-names></string-name>, <string-name><surname>Mercier</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Descarreaux</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Simoneau</surname>, <given-names>M.</given-names></string-name> (<year>2016</year>). <article-title>Sensorimotor Control Impairment in Young Adults With Idiopathic Scoliosis Compared With Healthy Controls</article-title>. <source>Journal of Manipulative and Physiological Therapeutics</source>, <volume>39</volume>(<issue>7</issue>), <fpage>473</fpage>&#x2013;<lpage>479</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.jmpt.2016.06.001">https://doi.org/10.1016/j.jmpt.2016.06.001</ext-link></mixed-citation></ref>
<ref id="c51"><mixed-citation publication-type="book"><string-name><surname>Poma</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Melin</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Gonz&#x00E1;lez</surname>, <given-names>C. I.</given-names></string-name>, &#x0026; <string-name><surname>Mart&#x00ED;nez</surname>, <given-names>G. E.</given-names></string-name> (<year>2020</year>). <chapter-title>Filter Size Optimization on a Convolutional Neural Network Using FGSA</chapter-title>. <source>In Studies in Computational Intelligence (Vol</source>. <volume>862</volume>, pp. <fpage>391</fpage>&#x2013;<lpage>403</lpage>). <publisher-name>Springer</publisher-name>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-030-35445-9_29">https://doi.org/10.1007/978-3-030-35445-9_29</ext-link></mixed-citation></ref>
<ref id="c52"><mixed-citation publication-type="book"><string-name><surname>Poma</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Melin</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Gonz&#x00E1;lez</surname>, <given-names>C. I.</given-names></string-name>, &#x0026; <string-name><surname>Martinez</surname>, <given-names>G. E.</given-names></string-name> (<year>2020</year>). <chapter-title>Optimal Recognition Model Based on Convolutional Neural Networks and Fuzzy Gravitational Search Algorithm Method</chapter-title>. <source>In Studies in Computational Intelligence (Vol</source>. <volume>827</volume>, pp. <fpage>71</fpage>&#x2013;<lpage>81</lpage>). <publisher-name>Springer</publisher-name>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/978-3-030-34135-0_6">https://doi.org/10.1007/978-3-030-34135-0_6</ext-link></mixed-citation></ref>
<ref id="c53"><mixed-citation publication-type="other"><collab>Prevent Falls and Fractures &#x007C; National Institute on Aging. (n.d.). Retrieved August 8, 2020, from</collab> <ext-link ext-link-type="uri" xlink:href="https://www.nia.nih.gov/health/prevent-falls-and-fractures">https://www.nia.nih.gov/health/prevent-falls-and-fractures</ext-link></mixed-citation></ref>
<ref id="c54"><mixed-citation publication-type="other"><string-name><surname>Reilly</surname>, <given-names>D.</given-names></string-name> (<year>2019</year>). <article-title>Feature selection for the classification of fall-risk in older subjects: a combinational approach using static force-plate measures</article-title>. <source>BioRxiv</source>, <fpage>807818</fpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1101/807818">https://doi.org/10.1101/807818</ext-link></mixed-citation></ref>
<ref id="c55"><mixed-citation publication-type="journal"><string-name><surname>Ren</surname>, <given-names>P.</given-names></string-name>, <string-name><surname>Huang</surname>, <given-names>S.</given-names></string-name>, <string-name><surname>Feng</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Chen</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Wang</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Guo</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Yuan</surname>, <given-names>Q.</given-names></string-name>, <string-name><surname>Yao</surname>, <given-names>D.</given-names></string-name>, &#x0026; <string-name><surname>Ma</surname>, <given-names>D.</given-names></string-name> (<year>2020</year>). <article-title>Assessment of Balance Control Subsystems by Artificial Intelligence</article-title>. <source>IEEE Transactions on Neural Systems and Rehabilitation Engineering</source>, <volume>28</volume>(<issue>3</issue>), <fpage>658</fpage>&#x2013;<lpage>668</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1109/TNSRE.2020.2966784">https://doi.org/10.1109/TNSRE.2020.2966784</ext-link></mixed-citation></ref>
<ref id="c56"><mixed-citation publication-type="journal"><string-name><surname>Ruhe</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Fejer</surname>, <given-names>R.</given-names></string-name>, &#x0026; <string-name><surname>Walker</surname>, <given-names>B.</given-names></string-name> (<year>2010</year>). <article-title>The test-retest reliability of centre of pressure measures in bipedal static task conditions - A systematic review of the literature</article-title>. <source>Gait and Posture</source>, <volume>32</volume>(<issue>4</issue>), <fpage>436</fpage>&#x2013;<lpage>445</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.gaitpost.2010.09.012">https://doi.org/10.1016/j.gaitpost.2010.09.012</ext-link></mixed-citation></ref>
<ref id="c57"><mixed-citation publication-type="journal"><string-name><surname>Safuan</surname>, <given-names>N. S. A.</given-names></string-name>, <string-name><surname>Ismail</surname>, <given-names>M.</given-names></string-name>, &#x0026; <string-name><surname>Jamil</surname>, <given-names>N.</given-names></string-name> (<year>2017</year>). <article-title>Feature extraction technique for human gait video analysis</article-title>. <source>Journal of Engineering and Applied Sciences</source>, <volume>12</volume>(<issue>3</issue>), <fpage>534</fpage>&#x2013; <lpage>541</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.3923/jeasci.2017.534.541">https://doi.org/10.3923/jeasci.2017.534.541</ext-link></mixed-citation></ref>
<ref id="c58"><mixed-citation publication-type="journal"><string-name><surname>Salthouse</surname>, <given-names>T. A.</given-names></string-name> (<year>2011</year>). <article-title>What cognitive abilities are involved in trail-making performance?</article-title> <source>Intelligence</source>, <volume>39</volume>(<issue>4</issue>), <fpage>222</fpage>&#x2013;<lpage>232</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.intell.2011.03.001">https://doi.org/10.1016/j.intell.2011.03.001</ext-link></mixed-citation></ref>
<ref id="c59"><mixed-citation publication-type="journal"><string-name><surname>Santos</surname>, <given-names>D. A.</given-names></string-name>, &#x0026; <string-name><surname>Duarte</surname>, <given-names>M.</given-names></string-name> (<year>2016</year>). <article-title>A public data set of human balance evaluations</article-title>. <source>PeerJ</source>, <volume>2016</volume>(<issue>11</issue>). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.7717/peerj.2648">https://doi.org/10.7717/peerj.2648</ext-link></mixed-citation></ref>
<ref id="c60"><mixed-citation publication-type="journal"><string-name><surname>Savadkoohi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Oladunni</surname>, <given-names>T.</given-names></string-name>, &#x0026; <string-name><surname>Thompson</surname>, <given-names>L.</given-names></string-name> (<year>2020</year>). <article-title>A machine learning approach to epileptic seizure prediction using Electroencephalogram (EEG) Signal</article-title>. <source>Biocybernetics and Biomedical Engineering</source>, <volume>40</volume>(<issue>3</issue>), <fpage>1328</fpage>&#x2013;<lpage>1341</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/j.bbe.2020.07.004">https://doi.org/10.1016/j.bbe.2020.07.004</ext-link></mixed-citation></ref>
<ref id="c61"><mixed-citation publication-type="other"><string-name><surname>Staudemeyer</surname>, <given-names>R. C.</given-names></string-name>, &#x0026; <string-name><surname>Morris</surname>, <given-names>E. R.</given-names></string-name> (<year>2019</year>). <source>Understanding LSTM -- a tutorial into Long Short-Term Memory Recurrent Neural Networks. ArXiv:1909.09586</source>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1909.09586">http://arxiv.org/abs/1909.09586</ext-link></mixed-citation></ref>
<ref id="c62"><mixed-citation publication-type="journal"><string-name><surname>Stevens</surname>, <given-names>J. A.</given-names></string-name>, <string-name><surname>Corso</surname>, <given-names>P. S.</given-names></string-name>, <string-name><surname>Finkelstein</surname>, <given-names>E. A.</given-names></string-name>, &#x0026; <string-name><surname>Miller</surname>, <given-names>T. R.</given-names></string-name> (<year>2006</year>). <article-title>The costs of fatal and non-fatal falls among older adults</article-title>. <source>Injury Prevention</source>, <volume>12</volume>(<issue>5</issue>), <fpage>290</fpage>&#x2013;<lpage>295</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1136/ip.2005.011015">https://doi.org/10.1136/ip.2005.011015</ext-link></mixed-citation></ref>
<ref id="c63"><mixed-citation publication-type="other"><string-name><surname>Thompson</surname>, <given-names>L. A.</given-names></string-name>, <string-name><surname>Brusamolin</surname>, <given-names>J. A. R.</given-names></string-name>, <string-name><surname>Guise</surname>, <given-names>J.</given-names></string-name>, <string-name><surname>Badache</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Estrada</surname>, <given-names>S. C.</given-names></string-name>, <string-name><surname>Behera</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Savadkoohi</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Coombs</surname>, <given-names>T.</given-names></string-name>, <string-name><surname>Guerrero</surname>, <given-names>P. S.</given-names></string-name>, &#x0026; <string-name><surname>Shetty</surname>, <given-names>D.</given-names></string-name> (<year>2018</year>, <month>November</month> 9). <source>Exploring Training Methodologies Towards the Improvement of Elderly Balance</source>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1115/imece2018-86815">https://doi.org/10.1115/imece2018-86815</ext-link></mixed-citation></ref>
<ref id="c64"><mixed-citation publication-type="other"><string-name><surname>Tiwang</surname> <given-names>R.</given-names></string-name>, <string-name><surname>Oladunni</surname>, <given-names>T.</given-names></string-name>, &#x0026; <string-name><surname>Xu</surname>, <given-names>W.</given-names></string-name> <source>&#x201C;A Deep Learning Model for Source Code Generation,&#x201D; 2019 SoutheastCon, Huntsville, AL, USA</source>, <year>2019</year>, pp. <fpage>1</fpage>&#x2013;<lpage>7</lpage>, doi: <pub-id pub-id-type="doi">10.1109/SoutheastCon42311.2019.9020360</pub-id>.</mixed-citation></ref>
<ref id="c65"><mixed-citation publication-type="other"><string-name><surname>Wang</surname>, <given-names>W.</given-names></string-name>, <string-name><surname>Yang</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Zhu</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Qian</surname>, <given-names>Y.</given-names></string-name>, <string-name><surname>Wan</surname>, <given-names>C.</given-names></string-name>, &#x0026; <string-name><surname>Li</surname>, <given-names>M.</given-names></string-name> (<year>2021</year>). <article-title>Walking Speed Estimation From a Wearable Insole Pressure System Embedded with an Accelerometer Using a Bayesian Neural Network</article-title>. <source>Journal of Engineering and Science in Medical Diagnostics and Therapy</source>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1115/1.4049964">https://doi.org/10.1115/1.4049964</ext-link></mixed-citation></ref>
<ref id="c66"><mixed-citation publication-type="journal"><string-name><surname>Winter</surname>, <given-names>D. A.</given-names></string-name> (<year>1995</year>). <article-title>Human balance and posture control during standing and walking</article-title>. <source>Gait and Posture</source>, <volume>3</volume>(<issue>4</issue>), <fpage>193</fpage>&#x2013;<lpage>214</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1016/0966-6362(96)82849-9">https://doi.org/10.1016/0966-6362(96)82849-9</ext-link></mixed-citation></ref>
<ref id="c67"><mixed-citation publication-type="other"><collab>World Health Organization-Falls. (n.d.). Retrieved August 26, 2020, from</collab> <ext-link ext-link-type="uri" xlink:href="https://www.who.int/news-room/fact-sheets/detail/falls">https://www.who.int/news-room/fact-sheets/detail/falls</ext-link></mixed-citation></ref>
<ref id="c68"><mixed-citation publication-type="other"><string-name><surname>Wu</surname>, <given-names>J.</given-names></string-name> (<year>2017</year>). <source>Introduction to Convolutional Neural Networks</source>. <ext-link ext-link-type="uri" xlink:href="https://cs.nju.edu.cn/wujx/paper/CNN.pdf">https://cs.nju.edu.cn/wujx/paper/CNN.pdf</ext-link></mixed-citation></ref>
<ref id="c69"><mixed-citation publication-type="journal"><string-name><surname>Yamashita</surname>, <given-names>R.</given-names></string-name>, <string-name><surname>Nishio</surname>, <given-names>M.</given-names></string-name>, <string-name><surname>Do</surname>, <given-names>R. K. G.</given-names></string-name>, &#x0026; <string-name><surname>Togashi</surname>, <given-names>K.</given-names></string-name> (<year>2018</year>). <article-title>Convolutional neural networks: an overview and application in radiology</article-title>. <source>Insights into Imaging</source>, <volume>9</volume>(<issue>4</issue>), <fpage>611</fpage>&#x2013; <lpage>629</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1007/s13244-018-0639-9">https://doi.org/10.1007/s13244-018-0639-9</ext-link></mixed-citation></ref>
<ref id="c70"><mixed-citation publication-type="journal"><string-name><surname>Yardley</surname>, <given-names>L.</given-names></string-name>, <string-name><surname>Beyer</surname>, <given-names>N.</given-names></string-name>, <string-name><surname>Hauer</surname>, <given-names>K.</given-names></string-name>, <string-name><surname>Kempen</surname>, <given-names>G.</given-names></string-name>, <string-name><surname>Piot-Ziegler</surname>, <given-names>C.</given-names></string-name>, &#x0026; <string-name><surname>Todd</surname>, <given-names>C.</given-names></string-name> (<year>2005</year>). <article-title>Development and initial validation of the Falls Efficacy Scale-International (FES-I)</article-title>. <source>Age and Ageing</source>, <volume>34</volume>(<issue>6</issue>), <fpage>614</fpage>&#x2013;<lpage>619</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1093/ageing/afi196">https://doi.org/10.1093/ageing/afi196</ext-link></mixed-citation></ref>
<ref id="c71"><mixed-citation publication-type="journal"><string-name><surname>Ying</surname>, <given-names>X.</given-names></string-name> (<year>2019</year>). <article-title>An Overview of Overfitting and its Solutions</article-title>. <source>Journal of Physics: Conference Series</source>, <volume>1168</volume>(<issue>2</issue>). <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1088/1742-6596/1168/2/022022">https://doi.org/10.1088/1742-6596/1168/2/022022</ext-link></mixed-citation></ref>
<ref id="c72"><mixed-citation publication-type="journal"><string-name><surname>Yingyongyudha</surname>, <given-names>A.</given-names></string-name>, <string-name><surname>Saengsirisuwan</surname>, <given-names>V.</given-names></string-name>, <string-name><surname>Panichaporn</surname>, <given-names>W.</given-names></string-name>, &#x0026; <string-name><surname>Boonsinsukh</surname>, <given-names>R.</given-names></string-name> (<year>2016</year>). <article-title>The Mini-Balance Evaluation Systems Test (Mini-BESTest) Demonstrates Higher Accuracy in Identifying Older Adult Participants with History of Falls Than Do the BESTest, Berg Balance Scale, or Timed Up and Go Test</article-title>. <source>Journal of Geriatric Physical Therapy</source>, <volume>39</volume>(<issue>2</issue>), <fpage>64</fpage>&#x2013;<lpage>70</lpage>. <ext-link ext-link-type="uri" xlink:href="https://doi.org/10.1519/JPT.0000000000000050">https://doi.org/10.1519/JPT.0000000000000050</ext-link></mixed-citation></ref>
<ref id="c73"><mixed-citation publication-type="other"><string-name><surname>Zhou</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Sun</surname>, <given-names>C.</given-names></string-name>, <string-name><surname>Liu</surname>, <given-names>Z.</given-names></string-name>, &#x0026; <string-name><surname>Lau</surname>, <given-names>F. C. M.</given-names></string-name> (<year>2015</year>). <source>A C-LSTM Neural Network for Text Classification</source>. <pub-id pub-id-type="arxiv">1511.08630</pub-id>. <ext-link ext-link-type="uri" xlink:href="http://arxiv.org/abs/1511.08630">http://arxiv.org/abs/1511.08630</ext-link></mixed-citation></ref>
</ref-list>
</back>
</article>